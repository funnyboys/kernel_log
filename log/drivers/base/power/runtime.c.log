commit 3618bbaaa898cf48e859736120a775fcb56f3838
Author: Andy Shevchenko <andriy.shevchenko@linux.intel.com>
Date:   Fri May 22 18:09:55 2020 +0300

    PM: runtime: Make clear what we do when conditions are wrong in rpm_suspend()
    
    rpm_suspend() simple bails out when conditions are wrong. But this is not
    immediately obvious from the code.  Make it clear what we do when conditions
    are wrong in rpm_suspend().
    
    Signed-off-by: Andy Shevchenko <andriy.shevchenko@linux.intel.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 99c7da112c95..9f62790f644c 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -523,13 +523,11 @@ static int rpm_suspend(struct device *dev, int rpmflags)
 
  repeat:
 	retval = rpm_check_suspend_allowed(dev);
-
 	if (retval < 0)
-		;	/* Conditions are wrong. */
+		goto out;	/* Conditions are wrong. */
 
 	/* Synchronous suspends are not allowed in the RPM_RESUMING state. */
-	else if (dev->power.runtime_status == RPM_RESUMING &&
-	    !(rpmflags & RPM_ASYNC))
+	if (dev->power.runtime_status == RPM_RESUMING && !(rpmflags & RPM_ASYNC))
 		retval = -EAGAIN;
 	if (retval)
 		goto out;

commit c111566bea7ccd8a05e2c56f1fb3cbb6f4b7b441
Author: Sakari Ailus <sakari.ailus@linux.intel.com>
Date:   Tue Feb 25 11:31:02 2020 +0200

    PM: runtime: Add pm_runtime_get_if_active()
    
    pm_runtime_get_if_in_use() bumps up the PM-runtime usage count if it
    is not equal to zero and the device's PM-runtime status is 'active'.
    This works for drivers that do not use autoidle, but for those that
    do, the function returns zero even when the device is active.
    
    In order to maintain sane device state while the device is powered on
    in the hope that it'll be needed, pm_runtime_get_if_active(dev, true)
    returns a positive value if the device's PM-runtime status is 'active'
    when it is called, in which case it also increments the device's usage
    count.
    
    If the second argument of pm_runtime_get_if_active() is 'false', the
    function behaves just like pm_runtime_get_if_in_use(), so redefine
    the latter as a wrapper around the former.
    
    Signed-off-by: Sakari Ailus <sakari.ailus@linux.intel.com>
    [ rjw: Changelog ]
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 16134a69bf6f..99c7da112c95 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -1087,29 +1087,47 @@ int __pm_runtime_resume(struct device *dev, int rpmflags)
 EXPORT_SYMBOL_GPL(__pm_runtime_resume);
 
 /**
- * pm_runtime_get_if_in_use - Conditionally bump up the device's usage counter.
+ * pm_runtime_get_if_active - Conditionally bump up the device's usage counter.
  * @dev: Device to handle.
  *
  * Return -EINVAL if runtime PM is disabled for the device.
  *
- * If that's not the case and if the device's runtime PM status is RPM_ACTIVE
- * and the runtime PM usage counter is nonzero, increment the counter and
- * return 1.  Otherwise return 0 without changing the counter.
+ * Otherwise, if the device's runtime PM status is RPM_ACTIVE and either
+ * ign_usage_count is true or the device's usage_count is non-zero, increment
+ * the counter and return 1. Otherwise return 0 without changing the counter.
+ *
+ * If ign_usage_count is true, the function can be used to prevent suspending
+ * the device when its runtime PM status is RPM_ACTIVE.
+ *
+ * If ign_usage_count is false, the function can be used to prevent suspending
+ * the device when both its runtime PM status is RPM_ACTIVE and its usage_count
+ * is non-zero.
+ *
+ * The caller is resposible for putting the device's usage count when ther
+ * return value is greater than zero.
  */
-int pm_runtime_get_if_in_use(struct device *dev)
+int pm_runtime_get_if_active(struct device *dev, bool ign_usage_count)
 {
 	unsigned long flags;
 	int retval;
 
 	spin_lock_irqsave(&dev->power.lock, flags);
-	retval = dev->power.disable_depth > 0 ? -EINVAL :
-		dev->power.runtime_status == RPM_ACTIVE
-			&& atomic_inc_not_zero(&dev->power.usage_count);
+	if (dev->power.disable_depth > 0) {
+		retval = -EINVAL;
+	} else if (dev->power.runtime_status != RPM_ACTIVE) {
+		retval = 0;
+	} else if (ign_usage_count) {
+		retval = 1;
+		atomic_inc(&dev->power.usage_count);
+	} else {
+		retval = atomic_inc_not_zero(&dev->power.usage_count);
+	}
 	trace_rpm_usage_rcuidle(dev, 0);
 	spin_unlock_irqrestore(&dev->power.lock, flags);
+
 	return retval;
 }
-EXPORT_SYMBOL_GPL(pm_runtime_get_if_in_use);
+EXPORT_SYMBOL_GPL(pm_runtime_get_if_active);
 
 /**
  * __pm_runtime_set_status - Set runtime PM status of a device.

commit d229290689ae0f6eae068ef142de4fd61ab4ba50
Author: Michał Mirosław <mirq-linux@rere.qmqm.pl>
Date:   Sat Jan 4 17:27:57 2020 +0100

    PM-runtime: add tracepoints for usage_count changes
    
    Add tracepoints to remaining places where device's power.usage_count
    is changed.
    
    This helps debugging where and why autosuspend is prevented.
    
    Signed-off-by: Michał Mirosław <mirq-linux@rere.qmqm.pl>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 48616f358854..16134a69bf6f 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -1006,8 +1006,10 @@ int __pm_runtime_idle(struct device *dev, int rpmflags)
 	int retval;
 
 	if (rpmflags & RPM_GET_PUT) {
-		if (!atomic_dec_and_test(&dev->power.usage_count))
+		if (!atomic_dec_and_test(&dev->power.usage_count)) {
+			trace_rpm_usage_rcuidle(dev, rpmflags);
 			return 0;
+		}
 	}
 
 	might_sleep_if(!(rpmflags & RPM_ASYNC) && !dev->power.irq_safe);
@@ -1038,8 +1040,10 @@ int __pm_runtime_suspend(struct device *dev, int rpmflags)
 	int retval;
 
 	if (rpmflags & RPM_GET_PUT) {
-		if (!atomic_dec_and_test(&dev->power.usage_count))
+		if (!atomic_dec_and_test(&dev->power.usage_count)) {
+			trace_rpm_usage_rcuidle(dev, rpmflags);
 			return 0;
+		}
 	}
 
 	might_sleep_if(!(rpmflags & RPM_ASYNC) && !dev->power.irq_safe);
@@ -1101,6 +1105,7 @@ int pm_runtime_get_if_in_use(struct device *dev)
 	retval = dev->power.disable_depth > 0 ? -EINVAL :
 		dev->power.runtime_status == RPM_ACTIVE
 			&& atomic_inc_not_zero(&dev->power.usage_count);
+	trace_rpm_usage_rcuidle(dev, 0);
 	spin_unlock_irqrestore(&dev->power.lock, flags);
 	return retval;
 }
@@ -1434,6 +1439,8 @@ void pm_runtime_allow(struct device *dev)
 	dev->power.runtime_auto = true;
 	if (atomic_dec_and_test(&dev->power.usage_count))
 		rpm_idle(dev, RPM_AUTO | RPM_ASYNC);
+	else
+		trace_rpm_usage_rcuidle(dev, RPM_AUTO | RPM_ASYNC);
 
  out:
 	spin_unlock_irq(&dev->power.lock);
@@ -1501,6 +1508,8 @@ static void update_autosuspend(struct device *dev, int old_delay, int old_use)
 		if (!old_use || old_delay >= 0) {
 			atomic_inc(&dev->power.usage_count);
 			rpm_resume(dev, 0);
+		} else {
+			trace_rpm_usage_rcuidle(dev, 0);
 		}
 	}
 

commit 1f7d290a7275edb270dbee13212c37cb59940221
Merge: fe38bd686207 ca7ce5a2710a
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Sep 18 10:04:39 2019 -0700

    Merge tag 'driver-core-5.4-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/gregkh/driver-core
    
    Pull driver core updates from Greg Kroah-Hartman:
     "Here is the big driver core update for 5.4-rc1.
    
      There was a bit of a churn in here, with a number of core and OF
      platform patches being added to the tree, and then after much
      discussion and review and a day-long in-person meeting, they were
      decided to be reverted and a new set of patches is currently being
      reviewed on the mailing list.
    
      Other than that churn, there are two "persistent" branches in here
      that other trees will be pulling in as well during the merge window.
      One branch to add support for drivers to have the driver core
      automatically add sysfs attribute files when a driver is bound to a
      device so that the driver doesn't have to manually do it (and then
      clean it up, as it always gets it wrong).
    
      There's another branch in here for generic lookup helpers for the
      driver core that lots of busses are starting to use. That's the
      majority of the non-driver-core changes in this patch series.
    
      There's also some on-going debugfs file creation cleanup that has been
      slowly happening over the past few releases, with the goal to
      hopefully get that done sometime next year.
    
      All of these have been in linux-next for a while now with no reported
      issues"
    
    [ Note that the above-mentioned generic lookup helpers branch was
      already brought in by the LED merge (commit 4feaab05dc1e) that had
      shared it.
    
      Also note that that common branch introduced an i2c bug due to a bad
      conversion, which got fixed here. - Linus ]
    
    * tag 'driver-core-5.4-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/gregkh/driver-core: (49 commits)
      coccinelle: platform_get_irq: Fix parse error
      driver-core: add include guard to linux/container.h
      sysfs: add BIN_ATTR_WO() macro
      driver core: platform: Export platform_get_irq_optional()
      hwmon: pwm-fan: Use platform_get_irq_optional()
      driver core: platform: Introduce platform_get_irq_optional()
      Revert "driver core: Add support for linking devices during device addition"
      Revert "driver core: Add edit_links() callback for drivers"
      Revert "of/platform: Add functional dependency link from DT bindings"
      Revert "driver core: Add sync_state driver/bus callback"
      Revert "of/platform: Pause/resume sync state during init and of_platform_populate()"
      Revert "of/platform: Create device links for all child-supplier depencencies"
      Revert "of/platform: Don't create device links for default busses"
      Revert "of/platform: Fix fn definitons for of_link_is_valid() and of_link_property()"
      Revert "of/platform: Fix device_links_supplier_sync_state_resume() warning"
      Revert "of/platform: Disable generic device linking code for PowerPC"
      devcoredump: fix typo in comment
      devcoredump: use memory_read_from_buffer
      of/platform: Disable generic device linking code for PowerPC
      device.h: Fix warnings for mismatched parameter names in comments
      ...

commit c2fa1e1bfa5b74558854a70b8afd797d43eb2743
Author: Joel Fernandes (Google) <joel@joelfernandes.org>
Date:   Tue Jul 16 18:12:25 2019 -0400

    driver/core: Convert to use built-in RCU list checking
    
    This commit applies the consolidated hlist_for_each_entry_rcu() support
    for lockdep conditions.
    
    Acked-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Joel Fernandes (Google) <joel@joelfernandes.org>
    Signed-off-by: Paul E. McKenney <paulmck@linux.ibm.com>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index b75335508d2c..50def99df970 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -287,7 +287,8 @@ static int rpm_get_suppliers(struct device *dev)
 {
 	struct device_link *link;
 
-	list_for_each_entry_rcu(link, &dev->links.suppliers, c_node) {
+	list_for_each_entry_rcu(link, &dev->links.suppliers, c_node,
+				device_links_read_lock_held()) {
 		int retval;
 
 		if (!(link->flags & DL_FLAG_PM_RUNTIME) ||
@@ -309,7 +310,8 @@ static void rpm_put_suppliers(struct device *dev)
 {
 	struct device_link *link;
 
-	list_for_each_entry_rcu(link, &dev->links.suppliers, c_node) {
+	list_for_each_entry_rcu(link, &dev->links.suppliers, c_node,
+				device_links_read_lock_held()) {
 		if (READ_ONCE(link->status) == DL_STATE_SUPPLIER_UNBIND)
 			continue;
 
@@ -1640,7 +1642,8 @@ void pm_runtime_clean_up_links(struct device *dev)
 
 	idx = device_links_read_lock();
 
-	list_for_each_entry_rcu(link, &dev->links.consumers, s_node) {
+	list_for_each_entry_rcu(link, &dev->links.consumers, s_node,
+				device_links_read_lock_held()) {
 		if (link->flags & DL_FLAG_STATELESS)
 			continue;
 
@@ -1662,7 +1665,8 @@ void pm_runtime_get_suppliers(struct device *dev)
 
 	idx = device_links_read_lock();
 
-	list_for_each_entry_rcu(link, &dev->links.suppliers, c_node)
+	list_for_each_entry_rcu(link, &dev->links.suppliers, c_node,
+				device_links_read_lock_held())
 		if (link->flags & DL_FLAG_PM_RUNTIME) {
 			link->supplier_preactivated = true;
 			refcount_inc(&link->rpm_active);
@@ -1683,7 +1687,8 @@ void pm_runtime_put_suppliers(struct device *dev)
 
 	idx = device_links_read_lock();
 
-	list_for_each_entry_rcu(link, &dev->links.suppliers, c_node)
+	list_for_each_entry_rcu(link, &dev->links.suppliers, c_node,
+				device_links_read_lock_held())
 		if (link->supplier_preactivated) {
 			link->supplier_preactivated = false;
 			if (refcount_dec_not_one(&link->rpm_active))

commit 515db266a9dace92b0cbaed9a6044dd5304b8ca9
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Tue Jul 16 17:21:06 2019 +0200

    driver core: Remove device link creation limitation
    
    If device_link_add() is called for a consumer/supplier pair with an
    existing device link between them and the existing link's type is
    not in agreement with the flags passed to that function by its
    caller, NULL will be returned.  That is seriously inconvenient,
    because it forces the callers of device_link_add() to worry about
    what others may or may not do even if that is not relevant to them
    for any other reasons.
    
    It turns out, however, that this limitation can be made go away
    relatively easily.
    
    The underlying observation is that if DL_FLAG_STATELESS has been
    passed to device_link_add() in flags for the given consumer/supplier
    pair at least once, calling either device_link_del() or
    device_link_remove() to release the link returned by it should work,
    but there are no other requirements associated with that flag.  In
    turn, if at least one of the callers of device_link_add() for the
    given consumer/supplier pair has not passed DL_FLAG_STATELESS to it
    in flags, the driver core should track the status of the link and act
    on it as appropriate (ie. the link should be treated as "managed").
    This means that DL_FLAG_STATELESS needs to be set for managed device
    links and it should be valid to call device_link_del() or
    device_link_remove() to drop references to them in certain
    sutiations.
    
    To allow that to happen, introduce a new (internal) device link flag
    called DL_FLAG_MANAGED and make device_link_add() set it automatically
    whenever DL_FLAG_STATELESS is not passed to it.  Also make it take
    additional references to existing device links that were previously
    stateless (that is, with DL_FLAG_STATELESS set and DL_FLAG_MANAGED
    unset) and will need to be managed going forward and initialize
    their status (which has been DL_STATE_NONE so far).
    
    Accordingly, when a managed device link is dropped automatically
    by the driver core, make it clear DL_FLAG_MANAGED, reset the link's
    status back to DL_STATE_NONE and drop the reference to it associated
    with DL_FLAG_MANAGED instead of just deleting it right away (to
    allow it to stay around in case it still needs to be released
    explicitly by someone).
    
    With that, since setting DL_FLAG_STATELESS doesn't mean that the
    device link in question is not managed any more, replace all of the
    status-tracking checks against DL_FLAG_STATELESS with analogous
    checks against DL_FLAG_MANAGED and update the documentation to
    reflect these changes.
    
    While at it, make device_link_add() reject flags that it does not
    recognize, including DL_FLAG_MANAGED.
    
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Reviewed-by: Saravana Kannan <saravanak@google.com>
    Tested-by: Marek Szyprowski <m.szyprowski@samsung.com>
    Review-by: Saravana Kannan <saravanak@google.com>
    Link: https://lore.kernel.org/r/2305283.AStDPdUUnE@kreacher
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index b75335508d2c..45a8fbe6987a 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -1624,7 +1624,7 @@ void pm_runtime_remove(struct device *dev)
  * runtime PM references to the device, drop the usage counter of the device
  * (as many times as needed).
  *
- * Links with the DL_FLAG_STATELESS flag set are ignored.
+ * Links with the DL_FLAG_MANAGED flag unset are ignored.
  *
  * Since the device is guaranteed to be runtime-active at the point this is
  * called, nothing else needs to be done here.
@@ -1641,7 +1641,7 @@ void pm_runtime_clean_up_links(struct device *dev)
 	idx = device_links_read_lock();
 
 	list_for_each_entry_rcu(link, &dev->links.consumers, s_node) {
-		if (link->flags & DL_FLAG_STATELESS)
+		if (!(link->flags & DL_FLAG_MANAGED))
 			continue;
 
 		while (refcount_dec_not_one(&link->rpm_active))

commit 8262331eaaf751076fb2c781f492bafd8344591d
Author: Viresh Kumar <viresh.kumar@linaro.org>
Date:   Thu Jul 4 13:06:18 2019 +0530

    PM / QOS: Rename __dev_pm_qos_read_value() and dev_pm_qos_raw_read_value()
    
    dev_pm_qos_read_value() will soon need to support more constraint types
    (min/max frequency) and will have another argument to it, i.e. type of
    the constraint. While that is fine for the existing users of
    dev_pm_qos_read_value(), but not that optimal for the callers of
    __dev_pm_qos_read_value() and dev_pm_qos_raw_read_value() as all the
    callers of these two routines are only looking for resume latency
    constraint.
    
    Lets make these two routines care only about the resume latency
    constraint and rename them to __dev_pm_qos_resume_latency() and
    dev_pm_qos_raw_resume_latency().
    
    Suggested-by: Rafael J. Wysocki <rjw@rjwysocki.net>
    Signed-off-by: Viresh Kumar <viresh.kumar@linaro.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 952a1e7057c7..b75335508d2c 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -275,7 +275,7 @@ static int rpm_check_suspend_allowed(struct device *dev)
 	    || (dev->power.request_pending
 			&& dev->power.request == RPM_REQ_RESUME))
 		retval = -EAGAIN;
-	else if (__dev_pm_qos_read_value(dev) == 0)
+	else if (__dev_pm_qos_resume_latency(dev) == 0)
 		retval = -EPERM;
 	else if (dev->power.runtime_status == RPM_SUSPENDED)
 		retval = 1;

commit 5de363b66a37a0193e28a2de64fa4996159bd5ee
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Tue Apr 2 15:32:01 2019 +0200

    drivers: base: power: add proper SPDX identifiers on files that did not have them.
    
    There were a few files in the driver core power code that did not have
    SPDX identifiers on them, so fix that up.  At the same time, remove the
    "free form" text that specified the license of the file, as that is
    impossible for any tool to properly parse.
    
    Cc: "Rafael J. Wysocki" <rafael@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 977db40378b0..952a1e7057c7 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -1,12 +1,10 @@
+// SPDX-License-Identifier: GPL-2.0
 /*
  * drivers/base/power/runtime.c - Helper functions for device runtime PM
  *
  * Copyright (c) 2009 Rafael J. Wysocki <rjw@sisk.pl>, Novell Inc.
  * Copyright (C) 2010 Alan Stern <stern@rowland.harvard.edu>
- *
- * This file is released under the GPLv2.
  */
-
 #include <linux/sched/mm.h>
 #include <linux/ktime.h>
 #include <linux/hrtimer.h>

commit 9352ca585b2ac7b67d2119b9386573b2a4c0ef4b
Merge: 9bc446100334 b444e1aa3e48
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Mar 14 10:30:06 2019 -0700

    Merge tag 'pm-5.1-rc1-2' of git://git.kernel.org/pub/scm/linux/kernel/git/rafael/linux-pm
    
    Pull more power management updates from Rafael Wysocki:
     "These are mostly fixes and cleanups on top of the previously merged
      power management material for 5.1-rc1 with one cpupower utility update
      that wasn't pushed earlier due to unfortunate timing.
    
      Specifics:
    
       - Fix registration of new cpuidle governors partially broken during
         the 5.0 development cycle by mistake (Rafael Wysocki).
    
       - Avoid integer overflows in the menu cpuidle governor by making it
         discard the overflowing data points upfront (Rafael Wysocki).
    
       - Fix minor mistake in the recent update of the iowait boost
         computation in the intel_pstate driver (Rafael Wysocki).
    
       - Drop incorrect __init annotation from one function in the pxa2xx
         cpufreq driver (Arnd Bergmann).
    
       - Fix the operating performance points (OPP) framework initialization
         for devices in multiple power domains if only one of them is
         scalable (Rajendra Nayak).
    
       - Fix mistake in dev_pm_opp_set_rate() which causes it to skip
         updating the performance state if the new frequency is the same as
         the old one (Viresh Kumar).
    
       - Rework the cancellation of wakeup source timers to avoid potential
         issues with it and do some cleanups unlocked by that change (Viresh
         Kumar, Rafael Wysocki).
    
       - Clean up the code computing the active/suspended time of devices in
         the PM-runtime framework after recent changes (Ulf Hansson).
    
       - Make the power management infrastructure code use pr_fmt()
         consistently (Joe Perches).
    
       - Clean up the generic power domains (genpd) framework somewhat
         (Aisheng Dong).
    
       - Improve kerneldoc comments for two functions in the cpufreq core
         (Rafael Wysocki).
    
       - Fix typo in a PM QoS file description comment (Aisheng Dong).
    
       - Update the handling of CPU boost frequencies in the cpupower
         utility (Abhishek Goel)"
    
    * tag 'pm-5.1-rc1-2' of git://git.kernel.org/pub/scm/linux/kernel/git/rafael/linux-pm:
      cpuidle: governor: Add new governors to cpuidle_governors again
      cpufreq: intel_pstate: Fix up iowait_boost computation
      PM / OPP: Update performance state when freq == old_freq
      PM / wakeup: Drop wakeup_source_drop()
      PM / wakeup: Rework wakeup source timer cancellation
      PM / domains: Remove one unnecessary blank line
      PM / Domains: Return early for all errors in _genpd_power_off()
      PM / Domains: Improve warn for multiple states but no governor
      OPP: Fix handling of multiple power domains
      PM / QoS: Fix typo in file description
      cpufreq: pxa2xx: remove incorrect __init annotation
      PM-runtime: Call pm_runtime_active|suspended_time() from sysfs
      PM-runtime: Consolidate code to get active/suspended time
      PM: Add and use pr_fmt()
      cpufreq: Improve kerneldoc comments for cpufreq_cpu_get/put()
      cpuidle: menu: Avoid overflows when computing variance
      tools/power/cpupower: Display boost frequency separately

commit 0996584b3026bed7f38abe02e8535e6a6c474118
Author: Ulf Hansson <ulf.hansson@linaro.org>
Date:   Tue Mar 5 13:55:35 2019 +0100

    PM-runtime: Call pm_runtime_active|suspended_time() from sysfs
    
    Avoid the open-coding of the accounted time acquisition in
    runtime_active|suspend_time_show() and make them call
    pm_runtime_active|suspended_time() instead.
    
    Note that this change also indirectly avoids holding dev->power.lock
    around the do_div() computation and the sprintf() call which is an
    additional improvement.
    
    Signed-off-by: Ulf Hansson <ulf.hansson@linaro.org>
    [ rjw: Changelog ]
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 32f6bf076bd7..a2d22e3ecf3a 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -64,7 +64,7 @@ static int rpm_suspend(struct device *dev, int rpmflags);
  * runtime_status field is updated, to account the time in the old state
  * correctly.
  */
-void update_pm_runtime_accounting(struct device *dev)
+static void update_pm_runtime_accounting(struct device *dev)
 {
 	u64 now, last, delta;
 

commit fdc56c073270af2f4d223c96a5fff3048352fc03
Author: Ulf Hansson <ulf.hansson@linaro.org>
Date:   Tue Mar 5 13:55:26 2019 +0100

    PM-runtime: Consolidate code to get active/suspended time
    
    In a step to consolidate the code for fetching the PM-runtime
    active/suspended time for a device, add a common function for that
    and make the existing pm_runtime_suspended_time() call it.
    
    Also add a corresponding pm_runtime_active_time() calling the new
    common function.
    
    Signed-off-by: Ulf Hansson <ulf.hansson@linaro.org>
    [ rjw: Changelog, function rename ]
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 78937c45278c..32f6bf076bd7 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -98,7 +98,7 @@ static void __update_runtime_status(struct device *dev, enum rpm_status status)
 	dev->power.runtime_status = status;
 }
 
-u64 pm_runtime_suspended_time(struct device *dev)
+static u64 rpm_get_accounted_time(struct device *dev, bool suspended)
 {
 	u64 time;
 	unsigned long flags;
@@ -106,12 +106,22 @@ u64 pm_runtime_suspended_time(struct device *dev)
 	spin_lock_irqsave(&dev->power.lock, flags);
 
 	update_pm_runtime_accounting(dev);
-	time = dev->power.suspended_time;
+	time = suspended ? dev->power.suspended_time : dev->power.active_time;
 
 	spin_unlock_irqrestore(&dev->power.lock, flags);
 
 	return time;
 }
+
+u64 pm_runtime_active_time(struct device *dev)
+{
+	return rpm_get_accounted_time(dev, false);
+}
+
+u64 pm_runtime_suspended_time(struct device *dev)
+{
+	return rpm_get_accounted_time(dev, true);
+}
 EXPORT_SYMBOL_GPL(pm_runtime_suspended_time);
 
 /**

commit e431f2d74e1b91e00e71e97cadcadffc4cda8a9b
Merge: 45763bf4bc1e 36cf3b1363f4
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Mar 6 14:52:48 2019 -0800

    Merge tag 'driver-core-5.1-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/gregkh/driver-core
    
    Pull driver core updates from Greg KH:
     "Here is the big driver core patchset for 5.1-rc1
    
      More patches than "normal" here this merge window, due to some work in
      the driver core by Alexander Duyck to rework the async probe
      functionality to work better for a number of devices, and independant
      work from Rafael for the device link functionality to make it work
      "correctly".
    
      Also in here is:
    
       - lots of BUS_ATTR() removals, the macro is about to go away
    
       - firmware test fixups
    
       - ihex fixups and simplification
    
       - component additions (also includes i915 patches)
    
       - lots of minor coding style fixups and cleanups.
    
      All of these have been in linux-next for a while with no reported
      issues"
    
    * tag 'driver-core-5.1-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/gregkh/driver-core: (65 commits)
      driver core: platform: remove misleading err_alloc label
      platform: set of_node in platform_device_register_full()
      firmware: hardcode the debug message for -ENOENT
      driver core: Add missing description of new struct device_link field
      driver core: Fix PM-runtime for links added during consumer probe
      drivers/component: kerneldoc polish
      async: Add cmdline option to specify drivers to be async probed
      driver core: Fix possible supplier PM-usage counter imbalance
      PM-runtime: Fix __pm_runtime_set_status() race with runtime resume
      driver: platform: Support parsing GpioInt 0 in platform_get_irq()
      selftests: firmware: fix verify_reqs() return value
      Revert "selftests: firmware: remove use of non-standard diff -Z option"
      Revert "selftests: firmware: add CONFIG_FW_LOADER_USER_HELPER_FALLBACK to config"
      device: Fix comment for driver_data in struct device
      kernfs: Allocating memory for kernfs_iattrs with kmem_cache.
      sysfs: remove unused include of kernfs-internal.h
      driver core: Postpone DMA tear-down until after devres release
      driver core: Document limitation related to DL_FLAG_RPM_ACTIVE
      PM-runtime: Take suppliers into account in __pm_runtime_set_status()
      device.h: Add __cold to dev_<level> logging functions
      ...

commit 656f72bb2ef33cd832a0f8e80893cce09f3d43df
Merge: 74fb44863084 85945c28b5a8
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Sun Feb 24 21:20:27 2019 +0100

    Merge back earlier PM core material for v5.1.

commit 74fb44863084275b952f21ec6a024af0e2e75cb8
Author: Vincent Guittot <vincent.guittot@linaro.org>
Date:   Thu Feb 21 08:59:02 2019 +0100

    PM-runtime: Fix deadlock when canceling hrtimer
    
    When rpm_resume() desactivates the autosuspend timer, it should only
    try to cancel hrtimer but not wait for the handler to finish, because
    both rpm_resume() and pm_suspend_timer_fn() take the power.lock.
    
    A deadlock is possible as follows:
    
    CPU0                              CPU1
    rpm_resume()
      spin_lock_irqsave
                                      pm_suspend_timer_fn()
                                        spin_lock_irqsave
      pm_runtime_deactivate_timer()
        hrtimer_cancel()
    
    It is sufficient to call hrtimer_try_to_cancel() from
    pm_runtime_deactivate_timer(), because dev->power.timer_expires
    reset to 0 by it, so use that function instead of hrtimer_cancel().
    
    Fixes: 8234f6734c5d ("PM-runtime: Switch autosuspend over to using hrtimers")
    Reported-by: Sunzhaosheng Sun(Zhaosheng) <sunzhaosheng@hisilicon.com>
    Signed-off-by: Vincent Guittot <vincent.guittot@linaro.org>
    [ rjw: Changelog ]
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 0ea2139c50d8..ccd296dbb95c 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -95,7 +95,7 @@ static void __update_runtime_status(struct device *dev, enum rpm_status status)
 static void pm_runtime_deactivate_timer(struct device *dev)
 {
 	if (dev->power.timer_expires > 0) {
-		hrtimer_cancel(&dev->power.suspend_timer);
+		hrtimer_try_to_cancel(&dev->power.suspend_timer);
 		dev->power.timer_expires = 0;
 	}
 }

commit 36003d4cf57ca431fb3f94d317bcca426a2394d6
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Tue Feb 19 17:53:26 2019 +0100

    driver core: Fix PM-runtime for links added during consumer probe
    
    Commit 4c06c4e6cf63 ("driver core: Fix possible supplier PM-usage
    counter imbalance") introduced a regression that causes suppliers
    to be suspended prematurely for device links added during consumer
    driver probe if the initial PM-runtime status of the consumer is
    "suspended" and the consumer is resumed after adding the link and
    before pm_runtime_put_suppliers() is called.  In that case,
    pm_runtime_put_suppliers() will drop the rpm_active refcount for
    the link by one and (since rpm_active is equal to two after the
    preceding consumer resume) the supplier's PM-runtime usage counter
    will be decremented, which may cause the supplier to suspend even
    though the consumer's PM-runtime status is "active".
    
    For this reason, partially revert commit 4c06c4e6cf63 as the problem
    it tried to fix needs to be addressed somewhat differently, and
    change pm_runtime_get_suppliers() and pm_runtime_put_suppliers() so
    that the latter only drops rpm_active references acquired by the
    former.  [This requires adding a new field to struct device_link,
    but I coulnd't find a cleaner way to address the issue that would
    work in all cases.]
    
    This causes pm_runtime_put_suppliers() to effectively ignore device
    links added during consumer probe, so device_link_add() doesn't need
    to worry about ensuring that suppliers will remain active after
    pm_runtime_put_suppliers() for links created with DL_FLAG_RPM_ACTIVE
    set and it only needs to bump up rpm_active by one for those links,
    so pm_runtime_active_link() is not necessary any more.
    
    Fixes: 4c06c4e6cf63 ("driver core: Fix possible supplier PM-usage counter imbalance")
    Reported-by: Jon Hunter <jonathanh@nvidia.com>
    Tested-by: Jon Hunter <jonathanh@nvidia.com>
    Tested-by: Ulf Hansson <ulf.hansson@linaro.org>
    Reviewed-by: Ulf Hansson <ulf.hansson@linaro.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Tested-by: Thierry Reding <treding@nvidia.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 6b8aa6bed064..70d2cb188601 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -1626,6 +1626,7 @@ void pm_runtime_get_suppliers(struct device *dev)
 
 	list_for_each_entry_rcu(link, &dev->links.suppliers, c_node)
 		if (link->flags & DL_FLAG_PM_RUNTIME) {
+			link->supplier_preactivated = true;
 			refcount_inc(&link->rpm_active);
 			pm_runtime_get_sync(link->supplier);
 		}
@@ -1645,9 +1646,11 @@ void pm_runtime_put_suppliers(struct device *dev)
 	idx = device_links_read_lock();
 
 	list_for_each_entry_rcu(link, &dev->links.suppliers, c_node)
-		if (link->flags & DL_FLAG_PM_RUNTIME &&
-		    refcount_dec_not_one(&link->rpm_active))
-			pm_runtime_put(link->supplier);
+		if (link->supplier_preactivated) {
+			link->supplier_preactivated = false;
+			if (refcount_dec_not_one(&link->rpm_active))
+				pm_runtime_put(link->supplier);
+		}
 
 	device_links_read_unlock(idx);
 }
@@ -1659,26 +1662,6 @@ void pm_runtime_new_link(struct device *dev)
 	spin_unlock_irq(&dev->power.lock);
 }
 
-/**
- * pm_runtime_active_link - Set up new device link as active for PM-runtime.
- * @link: Device link to be set up as active.
- * @supplier: Supplier end of the link.
- *
- * Add 2 to the rpm_active refcount of @link and increment the PM-runtime
- * usage counter of @supplier once more in case the link is being added while
- * the consumer driver is probing and pm_runtime_put_suppliers() will be called
- * subsequently.
- *
- * Note that this doesn't prevent rpm_put_suppliers() from decreasing the link's
- * rpm_active refcount down to one, so runtime suspend of the consumer end of
- * @link is not affected.
- */
-void pm_runtime_active_link(struct device_link *link, struct device *supplier)
-{
-	refcount_add(2, &link->rpm_active);
-	pm_runtime_get_noresume(supplier);
-}
-
 void pm_runtime_drop_link(struct device *dev)
 {
 	spin_lock_irq(&dev->power.lock);

commit 4c06c4e6cf63d7f3d5dfe62593a073253d750a59
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Tue Feb 12 13:08:10 2019 +0100

    driver core: Fix possible supplier PM-usage counter imbalance
    
    If a stateless device link to a certain supplier with
    DL_FLAG_PM_RUNTIME set in the flags is added and then removed by the
    consumer driver's probe callback, the supplier's PM-runtime usage
    counter will be nonzero after that which effectively causes the
    supplier to remain "always on" going forward.
    
    Namely, device_link_add() called to add the link invokes
    device_link_rpm_prepare() which notices that the consumer driver is
    probing, so it increments the supplier's PM-runtime usage counter
    with the assumption that the link will stay around until
    pm_runtime_put_suppliers() is called by driver_probe_device(),
    but if the link goes away before that point, the supplier's
    PM-runtime usage counter will remain nonzero.
    
    To prevent that from happening, first rework pm_runtime_get_suppliers()
    and pm_runtime_put_suppliers() to use the rpm_active refounts of device
    links and make the latter only drop rpm_active and the supplier's
    PM-runtime usage counter for each link by one, unless rpm_active is
    one already for it.  Next, modify device_link_add() to bump up the
    new link's rpm_active refcount and the suppliers PM-runtime usage
    counter by two, to prevent pm_runtime_put_suppliers(), if it is
    called subsequently, from suspending the supplier prematurely (in
    case its PM-runtime usage counter goes down to 0 in there).
    
    Due to the way rpm_put_suppliers() works, this change does not
    affect runtime suspend of the consumer ends of new device links (or,
    generally, device links for which DL_FLAG_PM_RUNTIME has just been
    set).
    
    Fixes: e2f3cd831a28 ("driver core: Fix handling of runtime PM flags in device_link_add()")
    Reported-by: Ulf Hansson <ulf.hansson@linaro.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Reviewed-by: Ulf Hansson <ulf.hansson@linaro.org>
    Tested-by: Ulf Hansson <ulf.hansson@linaro.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index af23eb327f57..6b8aa6bed064 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -1625,8 +1625,10 @@ void pm_runtime_get_suppliers(struct device *dev)
 	idx = device_links_read_lock();
 
 	list_for_each_entry_rcu(link, &dev->links.suppliers, c_node)
-		if (link->flags & DL_FLAG_PM_RUNTIME)
+		if (link->flags & DL_FLAG_PM_RUNTIME) {
+			refcount_inc(&link->rpm_active);
 			pm_runtime_get_sync(link->supplier);
+		}
 
 	device_links_read_unlock(idx);
 }
@@ -1643,7 +1645,8 @@ void pm_runtime_put_suppliers(struct device *dev)
 	idx = device_links_read_lock();
 
 	list_for_each_entry_rcu(link, &dev->links.suppliers, c_node)
-		if (link->flags & DL_FLAG_PM_RUNTIME)
+		if (link->flags & DL_FLAG_PM_RUNTIME &&
+		    refcount_dec_not_one(&link->rpm_active))
 			pm_runtime_put(link->supplier);
 
 	device_links_read_unlock(idx);
@@ -1656,6 +1659,26 @@ void pm_runtime_new_link(struct device *dev)
 	spin_unlock_irq(&dev->power.lock);
 }
 
+/**
+ * pm_runtime_active_link - Set up new device link as active for PM-runtime.
+ * @link: Device link to be set up as active.
+ * @supplier: Supplier end of the link.
+ *
+ * Add 2 to the rpm_active refcount of @link and increment the PM-runtime
+ * usage counter of @supplier once more in case the link is being added while
+ * the consumer driver is probing and pm_runtime_put_suppliers() will be called
+ * subsequently.
+ *
+ * Note that this doesn't prevent rpm_put_suppliers() from decreasing the link's
+ * rpm_active refcount down to one, so runtime suspend of the consumer end of
+ * @link is not affected.
+ */
+void pm_runtime_active_link(struct device_link *link, struct device *supplier)
+{
+	refcount_add(2, &link->rpm_active);
+	pm_runtime_get_noresume(supplier);
+}
+
 void pm_runtime_drop_link(struct device *dev)
 {
 	spin_lock_irq(&dev->power.lock);

commit c1567f813a9992a64f8d0f6cfb912c3922812c35
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Tue Feb 12 13:04:12 2019 +0100

    PM-runtime: Fix __pm_runtime_set_status() race with runtime resume
    
    Commit 4080ab083000 ("PM-runtime: Take suppliers into account in
    __pm_runtime_set_status()") introduced a race condition that may
    trigger if __pm_runtime_set_status() is used incorrectly (that is,
    if it is called when PM-runtime is enabled for the target device
    and working).
    
    In that case, if the original PM-runtime status of the device is
    RPM_SUSPENDED, a runtime resume of the device may occur after
    __pm_runtime_set_status() has dropped its power.lock spinlock
    and before deactivating its suppliers, so the suppliers may be
    deactivated while the device is PM-runtime-active which may lead
    to functional issues.
    
    To avoid that, modify __pm_runtime_set_status() to check whether
    or not PM-runtime is enabled for the device before activating its
    suppliers (if the new status is RPM_ACTIVE) and either return an
    error if that's the case or increment the device's disable_depth
    counter to prevent PM-runtime from being enabled for it while
    the remaining part of the function is running (disable_depth is
    then decremented on the way out).
    
    Fixes: 4080ab083000 ("PM-runtime: Take suppliers into account in __pm_runtime_set_status()")
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Reviewed-by: Ulf Hansson <ulf.hansson@linaro.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index ac54f65b6d63..af23eb327f57 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -1106,6 +1106,22 @@ int __pm_runtime_set_status(struct device *dev, unsigned int status)
 	if (status != RPM_ACTIVE && status != RPM_SUSPENDED)
 		return -EINVAL;
 
+	spin_lock_irq(&dev->power.lock);
+
+	/*
+	 * Prevent PM-runtime from being enabled for the device or return an
+	 * error if it is enabled already and working.
+	 */
+	if (dev->power.runtime_error || dev->power.disable_depth)
+		dev->power.disable_depth++;
+	else
+		error = -EAGAIN;
+
+	spin_unlock_irq(&dev->power.lock);
+
+	if (error)
+		return error;
+
 	/*
 	 * If the new status is RPM_ACTIVE, the suppliers can be activated
 	 * upfront regardless of the current status, because next time
@@ -1124,12 +1140,6 @@ int __pm_runtime_set_status(struct device *dev, unsigned int status)
 
 	spin_lock_irq(&dev->power.lock);
 
-	if (!dev->power.runtime_error && !dev->power.disable_depth) {
-		status = dev->power.runtime_status;
-		error = -EAGAIN;
-		goto out;
-	}
-
 	if (dev->power.runtime_status == status || !parent)
 		goto out_set;
 
@@ -1182,6 +1192,8 @@ int __pm_runtime_set_status(struct device *dev, unsigned int status)
 		device_links_read_unlock(idx);
 	}
 
+	pm_runtime_enable(dev);
+
 	return error;
 }
 EXPORT_SYMBOL_GPL(__pm_runtime_set_status);

commit 9481caf39bf55a862067007ffc53621b4305a387
Merge: 344c0152d878 d13937116f1e
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Mon Feb 11 09:09:02 2019 +0100

    Merge 5.0-rc6 into driver-core-next
    
    We need the debugfs fixes in here as well.
    
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 4080ab083000a1e9656b0d1607e238e7001e0c84
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Thu Feb 7 19:38:56 2019 +0100

    PM-runtime: Take suppliers into account in __pm_runtime_set_status()
    
    If the target device has any suppliers, as reflected by device links
    to them, __pm_runtime_set_status() does not take them into account,
    which is not consistent with the other parts of the PM-runtime
    framework and may lead to programming mistakes.
    
    Modify __pm_runtime_set_status() to take suppliers into account by
    activating them upfront if the new status is RPM_ACTIVE and
    deactivating them on exit if the new status is RPM_SUSPENDED.
    
    If the activation of one of the suppliers fails, the new status
    will be RPM_SUSPENDED and the (remaining) suppliers will be
    deactivated on exit (the child count of the device's parent
    will be dropped too then).
    
    Of course, adding device links locking to __pm_runtime_set_status()
    means that it cannot be run fron interrupt context, so make it use
    spin_lock_irq() and spin_unlock_irq() instead of spin_lock_irqsave()
    and spin_unlock_irqrestore(), respectively.
    
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index fd5c4a7b96f0..a0e55065817b 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -1089,20 +1089,43 @@ EXPORT_SYMBOL_GPL(pm_runtime_get_if_in_use);
  * and the device parent's counter of unsuspended children is modified to
  * reflect the new status.  If the new status is RPM_SUSPENDED, an idle
  * notification request for the parent is submitted.
+ *
+ * If @dev has any suppliers (as reflected by device links to them), and @status
+ * is RPM_ACTIVE, they will be activated upfront and if the activation of one
+ * of them fails, the status of @dev will be changed to RPM_SUSPENDED (instead
+ * of the @status value) and the suppliers will be deacticated on exit.  The
+ * error returned by the failing supplier activation will be returned in that
+ * case.
  */
 int __pm_runtime_set_status(struct device *dev, unsigned int status)
 {
 	struct device *parent = dev->parent;
-	unsigned long flags;
 	bool notify_parent = false;
 	int error = 0;
 
 	if (status != RPM_ACTIVE && status != RPM_SUSPENDED)
 		return -EINVAL;
 
-	spin_lock_irqsave(&dev->power.lock, flags);
+	/*
+	 * If the new status is RPM_ACTIVE, the suppliers can be activated
+	 * upfront regardless of the current status, because next time
+	 * rpm_put_suppliers() runs, the rpm_active refcounts of the links
+	 * involved will be dropped down to one anyway.
+	 */
+	if (status == RPM_ACTIVE) {
+		int idx = device_links_read_lock();
+
+		error = rpm_get_suppliers(dev);
+		if (error)
+			status = RPM_SUSPENDED;
+
+		device_links_read_unlock(idx);
+	}
+
+	spin_lock_irq(&dev->power.lock);
 
 	if (!dev->power.runtime_error && !dev->power.disable_depth) {
+		status = dev->power.runtime_status;
 		error = -EAGAIN;
 		goto out;
 	}
@@ -1134,19 +1157,31 @@ int __pm_runtime_set_status(struct device *dev, unsigned int status)
 
 		spin_unlock(&parent->power.lock);
 
-		if (error)
+		if (error) {
+			status = RPM_SUSPENDED;
 			goto out;
+		}
 	}
 
  out_set:
 	__update_runtime_status(dev, status);
-	dev->power.runtime_error = 0;
+	if (!error)
+		dev->power.runtime_error = 0;
+
  out:
-	spin_unlock_irqrestore(&dev->power.lock, flags);
+	spin_unlock_irq(&dev->power.lock);
 
 	if (notify_parent)
 		pm_request_idle(parent);
 
+	if (status == RPM_SUSPENDED) {
+		int idx = device_links_read_lock();
+
+		rpm_put_suppliers(dev);
+
+		device_links_read_unlock(idx);
+	}
+
 	return error;
 }
 EXPORT_SYMBOL_GPL(__pm_runtime_set_status);

commit fed7e88c0702e30fcd55563ca6eecd548a5d13af
Author: Vincent Guittot <vincent.guittot@linaro.org>
Date:   Mon Feb 4 17:25:53 2019 +0100

    PM-runtime: update time accounting only when enabled
    
    Update the accounting_timestamp field only when PM runtime is enabled
    and don't forget to account the last state before disabling it.
    
    Suggested-by: Ulf Hansson <ulf.hansson@linaro.org>
    Signed-off-by: Vincent Guittot <vincent.guittot@linaro.org>
    Reviewed-by: Ulf Hansson <ulf.hansson@linaro.org>
    [ rjw: Minor cleanups ]
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 6a58bb77a018..04407d9f76fd 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -66,10 +66,14 @@ static int rpm_suspend(struct device *dev, int rpmflags);
  */
 void update_pm_runtime_accounting(struct device *dev)
 {
-	u64 now = ktime_get_mono_fast_ns();
-	u64 last = dev->power.accounting_timestamp;
-	u64 delta;
+	u64 now, last, delta;
 
+	if (dev->power.disable_depth > 0)
+		return;
+
+	last = dev->power.accounting_timestamp;
+
+	now = ktime_get_mono_fast_ns();
 	dev->power.accounting_timestamp = now;
 
 	/*
@@ -82,9 +86,6 @@ void update_pm_runtime_accounting(struct device *dev)
 
 	delta = now - last;
 
-	if (dev->power.disable_depth > 0)
-		return;
-
 	if (dev->power.runtime_status == RPM_SUSPENDED)
 		dev->power.suspended_time += delta;
 	else
@@ -1298,6 +1299,9 @@ void __pm_runtime_disable(struct device *dev, bool check_resume)
 		pm_runtime_put_noidle(dev);
 	}
 
+	/* Update time accounting before disabling PM-runtime. */
+	update_pm_runtime_accounting(dev);
+
 	if (!dev->power.disable_depth++)
 		__pm_runtime_barrier(dev);
 
@@ -1521,7 +1525,6 @@ void pm_runtime_init(struct device *dev)
 	dev->power.request_pending = false;
 	dev->power.request = RPM_REQ_NONE;
 	dev->power.deferred_resume = false;
-	dev->power.accounting_timestamp = 0;
 	INIT_WORK(&dev->power.work, pm_runtime_work);
 
 	dev->power.timer_expires = 0;

commit c155f6499f9797f200aa46eb3ccbf198f4206970
Author: Vincent Guittot <vincent.guittot@linaro.org>
Date:   Mon Feb 4 17:25:52 2019 +0100

    PM-runtime: Switch accounting over to ktime_get_mono_fast_ns()
    
    Similar to what happened whith autosuspend, a deadlock has been
    reported with PM-runtime accounting in the call path:
    
    change_clocksource
        ...
        write_seqcount_begin
        ...
        timekeeping_update
            ...
            sh_cmt_clocksource_enable
                ...
                rpm_resume
                    update_pm_runtime_accounting
                        ktime_get
                            do
                                read_seqcount_begin
                            while read_seqcount_retry
        ....
        write_seqcount_end
    
    Make PM-runtime accounting use ktime_get_mono_fast_ns() to avoid this
    problem.
    
    With ktime_get_mono_fast_ns(), the timestamp is not guaranteed to be
    monotonic across an update of timekeeping and as a result time can go
    backward. Add a test to skip accounting for such situation which should
    stay exceptional.
    
    Fixes: a08c2a5a3194 ("PM-runtime: Replace jiffies-based accounting with ktime-based accounting")
    Reported-by: Biju Das <biju.das@bp.renesas.com>
    Signed-off-by: Vincent Guittot <vincent.guittot@linaro.org>
    Reviewed-by: Ulf Hansson <ulf.hansson@linaro.org>
    [ rjw: Subject, changelog, comment cleanup ]
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 1caa3944898f..6a58bb77a018 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -66,13 +66,22 @@ static int rpm_suspend(struct device *dev, int rpmflags);
  */
 void update_pm_runtime_accounting(struct device *dev)
 {
-	u64 now = ktime_to_ns(ktime_get());
+	u64 now = ktime_get_mono_fast_ns();
+	u64 last = dev->power.accounting_timestamp;
 	u64 delta;
 
-	delta = now - dev->power.accounting_timestamp;
-
 	dev->power.accounting_timestamp = now;
 
+	/*
+	 * Because ktime_get_mono_fast_ns() is not monotonic during
+	 * timekeeping updates, ensure that 'now' is after the last saved
+	 * timesptamp.
+	 */
+	if (now < last)
+		return;
+
+	delta = now - last;
+
 	if (dev->power.disable_depth > 0)
 		return;
 
@@ -1312,7 +1321,7 @@ void pm_runtime_enable(struct device *dev)
 
 		/* About to enable runtime pm, set accounting_timestamp to now */
 		if (!dev->power.disable_depth)
-			dev->power.accounting_timestamp = ktime_to_ns(ktime_get());
+			dev->power.accounting_timestamp = ktime_get_mono_fast_ns();
 	} else {
 		dev_warn(dev, "Unbalanced %s!\n", __func__);
 	}

commit f800ea320c09fbc8bf15aecd5c05e8e6b27ae64e
Author: Ladislav Michl <ladis@linux-mips.org>
Date:   Wed Jan 30 22:40:17 2019 +0100

    PM-runtime: Optimize pm_runtime_autosuspend_expiration()
    
    pm_runtime_autosuspend_expiration calls ktime_get_mono_fast_ns()
    even when its returned value may be unused. Therefore get the
    current time later and remove gotos while there.
    
    Signed-off-by: Ladislav Michl <ladis@linux-mips.org>
    Acked-by: Tony Lindgren <tony@atomide.com>
    Acked-by: Vincent Guittot <vincent.guittot@linaro.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 4eaf166d7de1..1caa3944898f 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -145,24 +145,21 @@ static void pm_runtime_cancel_pending(struct device *dev)
 u64 pm_runtime_autosuspend_expiration(struct device *dev)
 {
 	int autosuspend_delay;
-	u64 last_busy, expires = 0;
-	u64 now = ktime_get_mono_fast_ns();
+	u64 expires;
 
 	if (!dev->power.use_autosuspend)
-		goto out;
+		return 0;
 
 	autosuspend_delay = READ_ONCE(dev->power.autosuspend_delay);
 	if (autosuspend_delay < 0)
-		goto out;
-
-	last_busy = READ_ONCE(dev->power.last_busy);
+		return 0;
 
-	expires = last_busy + (u64)autosuspend_delay * NSEC_PER_MSEC;
-	if (expires <= now)
-		expires = 0;	/* Already expired. */
+	expires  = READ_ONCE(dev->power.last_busy);
+	expires += (u64)autosuspend_delay * NSEC_PER_MSEC;
+	if (expires > ktime_get_mono_fast_ns())
+		return expires;	/* Expires in the future */
 
- out:
-	return expires;
+	return 0;
 }
 EXPORT_SYMBOL_GPL(pm_runtime_autosuspend_expiration);
 

commit 1cc9c59569e0ec69e9beadfe6ba8b2b7b22d57f0
Merge: 15efb47dc560 a08c2a5a3194
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Fri Feb 1 11:53:35 2019 +0100

    Merge back earlier PM core material for v5.1.

commit a1fdbfbb1da2063ba98a12eb6f1bdd07451c7145
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Fri Feb 1 01:52:45 2019 +0100

    driver core: Do not call rpm_put_suppliers() in pm_runtime_drop_link()
    
    Calling rpm_put_suppliers() from pm_runtime_drop_link() is excessive
    as it affects all suppliers of the consumer device and not just the
    one pointed to by the device link being dropped.  Worst case it may
    cause the consumer device to stop working unexpectedly.  Moreover, in
    principle it is racy with respect to runtime PM of the consumer
    device.
    
    To avoid these problems drop runtime PM references on the particular
    supplier pointed to by the link in question only and do that after
    the link has been dropped from the consumer device's list of links to
    suppliers, which is in device_link_free().
    
    Fixes: a0504aecba76 ("PM / runtime: Drop usage count for suppliers at device link removal")
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 8bc9a432de70..fd5c4a7b96f0 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -1611,8 +1611,6 @@ void pm_runtime_new_link(struct device *dev)
 
 void pm_runtime_drop_link(struct device *dev)
 {
-	rpm_put_suppliers(dev);
-
 	spin_lock_irq(&dev->power.lock);
 	WARN_ON(dev->power.links_count == 0);
 	dev->power.links_count--;

commit e2f3cd831a280fc226118d9369bf3f77aab58c56
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Fri Feb 1 01:49:14 2019 +0100

    driver core: Fix handling of runtime PM flags in device_link_add()
    
    After commit ead18c23c263 ("driver core: Introduce device links
    reference counting"), if there is a link between the given supplier
    and the given consumer already, device_link_add() will refcount it
    and return it unconditionally without updating its flags.  It is
    possible, however, that the second (or any subsequent) caller of
    device_link_add() for the same consumer-supplier pair will pass
    DL_FLAG_PM_RUNTIME, possibly along with DL_FLAG_RPM_ACTIVE, in flags
    to it and the existing link may not behave as expected then.
    
    First, if DL_FLAG_PM_RUNTIME is not set in the existing link's flags
    at all, it needs to be set like during the original initialization of
    the link.
    
    Second, if DL_FLAG_RPM_ACTIVE is passed to device_link_add() in flags
    (in addition to DL_FLAG_PM_RUNTIME), the existing link should to be
    updated to reflect the "active" runtime PM configuration of the
    consumer-supplier pair and extra care must be taken here to avoid
    possible destructive races with runtime PM of the consumer.
    
    To that end, redefine the rpm_active field in struct device_link
    as a refcount, initialize it to 1 and make rpm_resume() (for the
    consumer) and device_link_add() increment it whenever they acquire
    a runtime PM reference on the supplier device.  Accordingly, make
    rpm_suspend() (for the consumer) and pm_runtime_clean_up_links()
    decrement it and drop runtime PM references to the supplier
    device in a loop until rpm_active becones 1 again.
    
    Fixes: ead18c23c263 ("driver core: Introduce device links reference counting")
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 457be03b744d..8bc9a432de70 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -259,11 +259,8 @@ static int rpm_get_suppliers(struct device *dev)
 	list_for_each_entry_rcu(link, &dev->links.suppliers, c_node) {
 		int retval;
 
-		if (!(link->flags & DL_FLAG_PM_RUNTIME))
-			continue;
-
-		if (READ_ONCE(link->status) == DL_STATE_SUPPLIER_UNBIND ||
-		    link->rpm_active)
+		if (!(link->flags & DL_FLAG_PM_RUNTIME) ||
+		    READ_ONCE(link->status) == DL_STATE_SUPPLIER_UNBIND)
 			continue;
 
 		retval = pm_runtime_get_sync(link->supplier);
@@ -272,7 +269,7 @@ static int rpm_get_suppliers(struct device *dev)
 			pm_runtime_put_noidle(link->supplier);
 			return retval;
 		}
-		link->rpm_active = true;
+		refcount_inc(&link->rpm_active);
 	}
 	return 0;
 }
@@ -281,12 +278,13 @@ static void rpm_put_suppliers(struct device *dev)
 {
 	struct device_link *link;
 
-	list_for_each_entry_rcu(link, &dev->links.suppliers, c_node)
-		if (link->rpm_active &&
-		    READ_ONCE(link->status) != DL_STATE_SUPPLIER_UNBIND) {
+	list_for_each_entry_rcu(link, &dev->links.suppliers, c_node) {
+		if (READ_ONCE(link->status) == DL_STATE_SUPPLIER_UNBIND)
+			continue;
+
+		while (refcount_dec_not_one(&link->rpm_active))
 			pm_runtime_put(link->supplier);
-			link->rpm_active = false;
-		}
+	}
 }
 
 /**
@@ -1539,7 +1537,7 @@ void pm_runtime_remove(struct device *dev)
  *
  * Check links from this device to any consumers and if any of them have active
  * runtime PM references to the device, drop the usage counter of the device
- * (once per link).
+ * (as many times as needed).
  *
  * Links with the DL_FLAG_STATELESS flag set are ignored.
  *
@@ -1561,10 +1559,8 @@ void pm_runtime_clean_up_links(struct device *dev)
 		if (link->flags & DL_FLAG_STATELESS)
 			continue;
 
-		if (link->rpm_active) {
+		while (refcount_dec_not_one(&link->rpm_active))
 			pm_runtime_put_noidle(dev);
-			link->rpm_active = false;
-		}
 	}
 
 	device_links_read_unlock(idx);

commit a08c2a5a31941131c41feaa0429e4c8854cf48f2
Author: Thara Gopinath <thara.gopinath@linaro.org>
Date:   Wed Jan 23 08:50:14 2019 +0100

    PM-runtime: Replace jiffies-based accounting with ktime-based accounting
    
    Replace jiffies-based accounting for runtime_active_time and
    runtime_suspended_time with ktime-based accounting. This makes the
    runtime debug counters inline with genpd and other PM subsytems which
    use ktime-based accounting.
    
    Timekeeping is initialized before driver_init(). It's only at that time
    that PM-runtime can be enabled.
    
    Signed-off-by: Thara Gopinath <thara.gopinath@linaro.org>
    [switch from ktime to raw nsec]
    Signed-off-by: Vincent Guittot <vincent.guittot@linaro.org>
    Reviewed-by: Ulf Hansson <ulf.hansson@linaro.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index f23b7ecfce3b..eb1a3b878e1e 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -66,8 +66,8 @@ static int rpm_suspend(struct device *dev, int rpmflags);
  */
 void update_pm_runtime_accounting(struct device *dev)
 {
-	unsigned long now = jiffies;
-	unsigned long delta;
+	u64 now = ktime_to_ns(ktime_get());
+	u64 delta;
 
 	delta = now - dev->power.accounting_timestamp;
 
@@ -77,9 +77,9 @@ void update_pm_runtime_accounting(struct device *dev)
 		return;
 
 	if (dev->power.runtime_status == RPM_SUSPENDED)
-		dev->power.suspended_jiffies += delta;
+		dev->power.suspended_time += delta;
 	else
-		dev->power.active_jiffies += delta;
+		dev->power.active_time += delta;
 }
 
 static void __update_runtime_status(struct device *dev, enum rpm_status status)
@@ -90,16 +90,17 @@ static void __update_runtime_status(struct device *dev, enum rpm_status status)
 
 u64 pm_runtime_suspended_time(struct device *dev)
 {
-	unsigned long flags, time;
+	u64 time;
+	unsigned long flags;
 
 	spin_lock_irqsave(&dev->power.lock, flags);
 
 	update_pm_runtime_accounting(dev);
-	time = dev->power.suspended_jiffies;
+	time = dev->power.suspended_time;
 
 	spin_unlock_irqrestore(&dev->power.lock, flags);
 
-	return jiffies_to_nsecs(time);
+	return time;
 }
 EXPORT_SYMBOL_GPL(pm_runtime_suspended_time);
 
@@ -1314,7 +1315,7 @@ void pm_runtime_enable(struct device *dev)
 
 		/* About to enable runtime pm, set accounting_timestamp to now */
 		if (!dev->power.disable_depth)
-			dev->power.accounting_timestamp = jiffies;
+			dev->power.accounting_timestamp = ktime_to_ns(ktime_get());
 	} else {
 		dev_warn(dev, "Unbalanced %s!\n", __func__);
 	}

commit 58456488e0e3793f2f95a3d2e2a78b6eba0ad0aa
Author: Vincent Guittot <vincent.guittot@linaro.org>
Date:   Wed Jan 23 08:50:13 2019 +0100

    PM-runtime: update accounting_timestamp on enable
    
    Initializing accounting_timestamp to something different from 0 during
    pm_runtime_init() doesn't make sense and puts an artificial ordering
    constraint between timekeeping_init() and pm_runtime_init().
    
    PM-runtime should start time accounting only when it is enabled and
    discard the period when disabled.
    
    Set accounting_timestamp to now when enabling PM-runtime.
    
    Suggested-by: "Rafael J. Wysocki" <rjw@rjwysocki.net>
    Signed-off-by: Vincent Guittot <vincent.guittot@linaro.org>
    Reviewed-by: Ulf Hansson <ulf.hansson@linaro.org>
    [ rjw: Subject & changelog ]
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index a453090c9449..f23b7ecfce3b 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -1309,10 +1309,15 @@ void pm_runtime_enable(struct device *dev)
 
 	spin_lock_irqsave(&dev->power.lock, flags);
 
-	if (dev->power.disable_depth > 0)
+	if (dev->power.disable_depth > 0) {
 		dev->power.disable_depth--;
-	else
+
+		/* About to enable runtime pm, set accounting_timestamp to now */
+		if (!dev->power.disable_depth)
+			dev->power.accounting_timestamp = jiffies;
+	} else {
 		dev_warn(dev, "Unbalanced %s!\n", __func__);
+	}
 
 	WARN(!dev->power.disable_depth &&
 	     dev->power.runtime_status == RPM_SUSPENDED &&
@@ -1509,7 +1514,7 @@ void pm_runtime_init(struct device *dev)
 	dev->power.request_pending = false;
 	dev->power.request = RPM_REQ_NONE;
 	dev->power.deferred_resume = false;
-	dev->power.accounting_timestamp = jiffies;
+	dev->power.accounting_timestamp = 0;
 	INIT_WORK(&dev->power.work, pm_runtime_work);
 
 	dev->power.timer_expires = 0;

commit 15efb47dc560849d0c07db96fdad5121f2cf736e
Author: Vincent Guittot <vincent.guittot@linaro.org>
Date:   Wed Jan 30 18:26:02 2019 +0100

    PM-runtime: Fix deadlock with ktime_get()
    
    A deadlock has been seen when swicthing clocksources which use
    PM-runtime.  The call path is:
    
    change_clocksource
        ...
        write_seqcount_begin
        ...
        timekeeping_update
            ...
            sh_cmt_clocksource_enable
                ...
                rpm_resume
                    pm_runtime_mark_last_busy
                        ktime_get
                            do
                                read_seqcount_begin
                            while read_seqcount_retry
        ....
        write_seqcount_end
    
    Although we should be safe because we haven't yet changed the
    clocksource at that time, we can't do that because of seqcount
    protection.
    
    Use ktime_get_mono_fast_ns() instead which is lock safe for such
    cases.
    
    With ktime_get_mono_fast_ns, the timestamp is not guaranteed to be
    monotonic across an update and as a result can goes backward.
    According to update_fast_timekeeper() description: "In the worst
    case, this can result is a slightly wrong timestamp (a few
    nanoseconds)". For PM-runtime autosuspend, this means only that
    the suspend decision may be slightly suboptimal.
    
    Fixes: 8234f6734c5d ("PM-runtime: Switch autosuspend over to using hrtimers")
    Reported-by: Biju Das <biju.das@bp.renesas.com>
    Signed-off-by: Vincent Guittot <vincent.guittot@linaro.org>
    Reviewed-by: Ulf Hansson <ulf.hansson@linaro.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 457be03b744d..0ea2139c50d8 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -130,7 +130,7 @@ u64 pm_runtime_autosuspend_expiration(struct device *dev)
 {
 	int autosuspend_delay;
 	u64 last_busy, expires = 0;
-	u64 now = ktime_to_ns(ktime_get());
+	u64 now = ktime_get_mono_fast_ns();
 
 	if (!dev->power.use_autosuspend)
 		goto out;
@@ -909,7 +909,7 @@ static enum hrtimer_restart  pm_suspend_timer_fn(struct hrtimer *timer)
 	 * If 'expires' is after the current time, we've been called
 	 * too early.
 	 */
-	if (expires > 0 && expires < ktime_to_ns(ktime_get())) {
+	if (expires > 0 && expires < ktime_get_mono_fast_ns()) {
 		dev->power.timer_expires = 0;
 		rpm_suspend(dev, dev->power.timer_autosuspends ?
 		    (RPM_ASYNC | RPM_AUTO) : RPM_ASYNC);
@@ -928,7 +928,7 @@ static enum hrtimer_restart  pm_suspend_timer_fn(struct hrtimer *timer)
 int pm_schedule_suspend(struct device *dev, unsigned int delay)
 {
 	unsigned long flags;
-	ktime_t expires;
+	u64 expires;
 	int retval;
 
 	spin_lock_irqsave(&dev->power.lock, flags);
@@ -945,8 +945,8 @@ int pm_schedule_suspend(struct device *dev, unsigned int delay)
 	/* Other scheduled or pending requests need to be canceled. */
 	pm_runtime_cancel_pending(dev);
 
-	expires = ktime_add(ktime_get(), ms_to_ktime(delay));
-	dev->power.timer_expires = ktime_to_ns(expires);
+	expires = ktime_get_mono_fast_ns() + (u64)delay * NSEC_PER_MSEC;
+	dev->power.timer_expires = expires;
 	dev->power.timer_autosuspends = 0;
 	hrtimer_start(&dev->power.suspend_timer, expires, HRTIMER_MODE_ABS);
 

commit 8a62ffe2753a845272f4f2100b5fca0b6053ff6f
Author: Vincent Guittot <vincent.guittot@linaro.org>
Date:   Fri Dec 21 11:33:54 2018 +0100

    PM-runtime: Add new interface to get accounted time
    
    Some drivers (like i915/drm) needs to get the accounted suspended time.
    pm_runtime_suspended_time() will return the suspended accounted time
    in ns unit.
    
    Reviewed-by: Ulf Hansson <ulf.hansson@linaro.org>
    Signed-off-by: Vincent Guittot <vincent.guittot@linaro.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 457be03b744d..a453090c9449 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -88,6 +88,21 @@ static void __update_runtime_status(struct device *dev, enum rpm_status status)
 	dev->power.runtime_status = status;
 }
 
+u64 pm_runtime_suspended_time(struct device *dev)
+{
+	unsigned long flags, time;
+
+	spin_lock_irqsave(&dev->power.lock, flags);
+
+	update_pm_runtime_accounting(dev);
+	time = dev->power.suspended_jiffies;
+
+	spin_unlock_irqrestore(&dev->power.lock, flags);
+
+	return jiffies_to_nsecs(time);
+}
+EXPORT_SYMBOL_GPL(pm_runtime_suspended_time);
+
 /**
  * pm_runtime_deactivate_timer - Deactivate given device's suspend timer.
  * @dev: Device to handle.

commit ca27e4cd0bdd87e33fda38e6e3d18d36d54356d4
Author: Vincent Guittot <vincent.guittot@linaro.org>
Date:   Thu Jan 10 10:00:40 2019 +0100

    PM-runtime: Fix autosuspend_delay on 32bits arch
    
    Cast autosuspend_delay to u64 to make sure that the full computation
    of 'expires' or slack will be done in u64, even on 32bits arch.
    
    Otherwise, any delay greater than 2^31 nsec can overflow if signed
    32bits is used when converting delay from msec to nsec.
    
    Fixes: 8234f6734c5d (PM-runtime: Switch autosuspend over to using hrtimers)
    Reported-by: Tony Lindgren <tony@atomide.com>
    Tested-by: Tony Lindgren <tony@atomide.com>
    Signed-off-by: Vincent Guittot <vincent.guittot@linaro.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index a282e74d1a16..457be03b744d 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -141,7 +141,7 @@ u64 pm_runtime_autosuspend_expiration(struct device *dev)
 
 	last_busy = READ_ONCE(dev->power.last_busy);
 
-	expires = last_busy + autosuspend_delay * NSEC_PER_MSEC;
+	expires = last_busy + (u64)autosuspend_delay * NSEC_PER_MSEC;
 	if (expires <= now)
 		expires = 0;	/* Already expired. */
 
@@ -525,7 +525,7 @@ static int rpm_suspend(struct device *dev, int rpmflags)
 				 * We add a slack of 25% to gather wakeups
 				 * without sacrificing the granularity.
 				 */
-				u64 slack = READ_ONCE(dev->power.autosuspend_delay) *
+				u64 slack = (u64)READ_ONCE(dev->power.autosuspend_delay) *
 						    (NSEC_PER_MSEC >> 2);
 
 				dev->power.timer_expires = expires;

commit 1f7b7081568bca281f4ef42096206180cfaced00
Author: Ladislav Michl <ladis@linux-mips.org>
Date:   Thu Jan 10 00:19:44 2019 +0100

    PM-runtime: Fix 'jiffies' in comments after switch to hrtimers
    
    PM-runtime now uses the hrtimers infrastructure for autosuspend, however
    comments still reference 'jiffies'.
    
    Fixes: 8234f6734c5d (PM-runtime: Switch autosuspend over to using hrtimers)
    Signed-off-by: Ladislav Michl <ladis@linux-mips.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 70624695b6d5..a282e74d1a16 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -121,7 +121,7 @@ static void pm_runtime_cancel_pending(struct device *dev)
  * Compute the autosuspend-delay expiration time based on the device's
  * power.last_busy time.  If the delay has already expired or is disabled
  * (negative) or the power.use_autosuspend flag isn't set, return 0.
- * Otherwise return the expiration time in jiffies (adjusted to be nonzero).
+ * Otherwise return the expiration time in nanoseconds (adjusted to be nonzero).
  *
  * This function may be called either with or without dev->power.lock held.
  * Either way it can be racy, since power.last_busy may be updated at any time.
@@ -905,7 +905,10 @@ static enum hrtimer_restart  pm_suspend_timer_fn(struct hrtimer *timer)
 	spin_lock_irqsave(&dev->power.lock, flags);
 
 	expires = dev->power.timer_expires;
-	/* If 'expire' is after 'jiffies' we've been called too early. */
+	/*
+	 * If 'expires' is after the current time, we've been called
+	 * too early.
+	 */
 	if (expires > 0 && expires < ktime_to_ns(ktime_get())) {
 		dev->power.timer_expires = 0;
 		rpm_suspend(dev, dev->power.timer_autosuspends ?

commit 8234f6734c5d74ac794e5517437f51c57d65f865
Author: Vincent Guittot <vincent.guittot@linaro.org>
Date:   Fri Dec 14 15:22:25 2018 +0100

    PM-runtime: Switch autosuspend over to using hrtimers
    
    PM-runtime uses the timer infrastructure for autosuspend. This implies
    that the minimum time before autosuspending a device is in the range
    of 1 tick included to 2 ticks excluded
     -On arm64 this means between 4ms and 8ms with default jiffies
      configuration
     -And on arm, it is between 10ms and 20ms
    
    These values are quite high for embedded systems which sometimes want
    the duration to be in the range of 1 ms.
    
    It is possible to switch autosuspend over to using hrtimers to get
    finer granularity for short durations and take advantage of slack to
    retain some margins and get long timeouts with minimum wakeups.
    
    On an arm64 platform that uses 1ms for autosuspending timeout of its
    GPU, idle power is reduced by 10% with hrtimer.
    
    The latency impact on arm64 hikey octo cores is:
     - mark_last_busy: from 1.11 us to 1.25 us
     - rpm_suspend: from 15.54 us to 15.38 us
    [Only the code path of rpm_suspend() that starts hrtimer has been
    measured.]
    
    arm64 image (arm64 default defconfig) decreases by around 3KB
    with following details:
    
    $ size vmlinux-timer
       text    data     bss     dec     hex filename
    12034646        6869268  386840 19290754        1265a82 vmlinux
    
    $ size vmlinux-hrtimer
       text    data     bss     dec     hex filename
    12030550        6870164  387032 19287746        1264ec2 vmlinux
    
    The latency impact on arm 32bits snowball dual cores is :
     - mark_last_busy: from 0.31 us usec to 0.77 us
     - rpm_suspend: from 6.83 us to 6.67 usec
    
    The increase of the image for snowball platform that I used for
    testing performance impact, is neglictable (244B).
    
    $ size vmlinux-timer
       text    data     bss     dec     hex filename
    7157961 2119580  264120 9541661  91981d build-ux500/vmlinux
    
    size vmlinux-hrtimer
       text    data     bss     dec     hex filename
    7157773 2119884  264248 9541905  919911 vmlinux-hrtimer
    
    And arm 32bits image (multi_v7_defconfig) increases by around 1.7KB
    with following details:
    
    $ size vmlinux-timer
       text    data     bss     dec     hex filename
    13304443        6803420  402768 20510631        138f7a7 vmlinux
    
    $ size vmlinux-hrtimer
       text    data     bss     dec     hex filename
    13304299        6805276  402768 20512343        138fe57 vmlinux
    
    Signed-off-by: Vincent Guittot <vincent.guittot@linaro.org>
    Reviewed-by: Ulf Hansson <ulf.hansson@linaro.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index beb85c31f3fa..70624695b6d5 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -8,6 +8,8 @@
  */
 
 #include <linux/sched/mm.h>
+#include <linux/ktime.h>
+#include <linux/hrtimer.h>
 #include <linux/export.h>
 #include <linux/pm_runtime.h>
 #include <linux/pm_wakeirq.h>
@@ -93,7 +95,7 @@ static void __update_runtime_status(struct device *dev, enum rpm_status status)
 static void pm_runtime_deactivate_timer(struct device *dev)
 {
 	if (dev->power.timer_expires > 0) {
-		del_timer(&dev->power.suspend_timer);
+		hrtimer_cancel(&dev->power.suspend_timer);
 		dev->power.timer_expires = 0;
 	}
 }
@@ -124,12 +126,11 @@ static void pm_runtime_cancel_pending(struct device *dev)
  * This function may be called either with or without dev->power.lock held.
  * Either way it can be racy, since power.last_busy may be updated at any time.
  */
-unsigned long pm_runtime_autosuspend_expiration(struct device *dev)
+u64 pm_runtime_autosuspend_expiration(struct device *dev)
 {
 	int autosuspend_delay;
-	long elapsed;
-	unsigned long last_busy;
-	unsigned long expires = 0;
+	u64 last_busy, expires = 0;
+	u64 now = ktime_to_ns(ktime_get());
 
 	if (!dev->power.use_autosuspend)
 		goto out;
@@ -139,19 +140,9 @@ unsigned long pm_runtime_autosuspend_expiration(struct device *dev)
 		goto out;
 
 	last_busy = READ_ONCE(dev->power.last_busy);
-	elapsed = jiffies - last_busy;
-	if (elapsed < 0)
-		goto out;	/* jiffies has wrapped around. */
 
-	/*
-	 * If the autosuspend_delay is >= 1 second, align the timer by rounding
-	 * up to the nearest second.
-	 */
-	expires = last_busy + msecs_to_jiffies(autosuspend_delay);
-	if (autosuspend_delay >= 1000)
-		expires = round_jiffies(expires);
-	expires += !expires;
-	if (elapsed >= expires - last_busy)
+	expires = last_busy + autosuspend_delay * NSEC_PER_MSEC;
+	if (expires <= now)
 		expires = 0;	/* Already expired. */
 
  out:
@@ -515,7 +506,7 @@ static int rpm_suspend(struct device *dev, int rpmflags)
 	/* If the autosuspend_delay time hasn't expired yet, reschedule. */
 	if ((rpmflags & RPM_AUTO)
 	    && dev->power.runtime_status != RPM_SUSPENDING) {
-		unsigned long expires = pm_runtime_autosuspend_expiration(dev);
+		u64 expires = pm_runtime_autosuspend_expiration(dev);
 
 		if (expires != 0) {
 			/* Pending requests need to be canceled. */
@@ -528,10 +519,20 @@ static int rpm_suspend(struct device *dev, int rpmflags)
 			 * expire; pm_suspend_timer_fn() will take care of the
 			 * rest.
 			 */
-			if (!(dev->power.timer_expires && time_before_eq(
-			    dev->power.timer_expires, expires))) {
+			if (!(dev->power.timer_expires &&
+					dev->power.timer_expires <= expires)) {
+				/*
+				 * We add a slack of 25% to gather wakeups
+				 * without sacrificing the granularity.
+				 */
+				u64 slack = READ_ONCE(dev->power.autosuspend_delay) *
+						    (NSEC_PER_MSEC >> 2);
+
 				dev->power.timer_expires = expires;
-				mod_timer(&dev->power.suspend_timer, expires);
+				hrtimer_start_range_ns(&dev->power.suspend_timer,
+						ns_to_ktime(expires),
+						slack,
+						HRTIMER_MODE_ABS);
 			}
 			dev->power.timer_autosuspends = 1;
 			goto out;
@@ -895,23 +896,25 @@ static void pm_runtime_work(struct work_struct *work)
  *
  * Check if the time is right and queue a suspend request.
  */
-static void pm_suspend_timer_fn(struct timer_list *t)
+static enum hrtimer_restart  pm_suspend_timer_fn(struct hrtimer *timer)
 {
-	struct device *dev = from_timer(dev, t, power.suspend_timer);
+	struct device *dev = container_of(timer, struct device, power.suspend_timer);
 	unsigned long flags;
-	unsigned long expires;
+	u64 expires;
 
 	spin_lock_irqsave(&dev->power.lock, flags);
 
 	expires = dev->power.timer_expires;
 	/* If 'expire' is after 'jiffies' we've been called too early. */
-	if (expires > 0 && !time_after(expires, jiffies)) {
+	if (expires > 0 && expires < ktime_to_ns(ktime_get())) {
 		dev->power.timer_expires = 0;
 		rpm_suspend(dev, dev->power.timer_autosuspends ?
 		    (RPM_ASYNC | RPM_AUTO) : RPM_ASYNC);
 	}
 
 	spin_unlock_irqrestore(&dev->power.lock, flags);
+
+	return HRTIMER_NORESTART;
 }
 
 /**
@@ -922,6 +925,7 @@ static void pm_suspend_timer_fn(struct timer_list *t)
 int pm_schedule_suspend(struct device *dev, unsigned int delay)
 {
 	unsigned long flags;
+	ktime_t expires;
 	int retval;
 
 	spin_lock_irqsave(&dev->power.lock, flags);
@@ -938,10 +942,10 @@ int pm_schedule_suspend(struct device *dev, unsigned int delay)
 	/* Other scheduled or pending requests need to be canceled. */
 	pm_runtime_cancel_pending(dev);
 
-	dev->power.timer_expires = jiffies + msecs_to_jiffies(delay);
-	dev->power.timer_expires += !dev->power.timer_expires;
+	expires = ktime_add(ktime_get(), ms_to_ktime(delay));
+	dev->power.timer_expires = ktime_to_ns(expires);
 	dev->power.timer_autosuspends = 0;
-	mod_timer(&dev->power.suspend_timer, dev->power.timer_expires);
+	hrtimer_start(&dev->power.suspend_timer, expires, HRTIMER_MODE_ABS);
 
  out:
 	spin_unlock_irqrestore(&dev->power.lock, flags);
@@ -1491,7 +1495,8 @@ void pm_runtime_init(struct device *dev)
 	INIT_WORK(&dev->power.work, pm_runtime_work);
 
 	dev->power.timer_expires = 0;
-	timer_setup(&dev->power.suspend_timer, pm_suspend_timer_fn, 0);
+	hrtimer_init(&dev->power.suspend_timer, CLOCK_MONOTONIC, HRTIMER_MODE_ABS);
+	dev->power.suspend_timer.function = pm_suspend_timer_fn;
 
 	init_waitqueue_head(&dev->power.wait_queue);
 }

commit b06c0b2f087ab498d51d50f5ae353133b602f614
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Tue Jun 12 10:24:13 2018 +0200

    Revert "PM / runtime: Fixup reference counting of device link suppliers at probe"
    
    Revert commit 1e8378619841 (PM / runtime: Fixup reference counting of
    device link suppliers at probe), as it has introduced a regression
    and the condition it was designed to address should be covered by the
    existing code.
    
    Reported-by: Marek Szyprowski <m.szyprowski@samsung.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index c6030f100c08..beb85c31f3fa 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -1563,16 +1563,37 @@ void pm_runtime_clean_up_links(struct device *dev)
 }
 
 /**
- * pm_runtime_resume_suppliers - Resume supplier devices.
+ * pm_runtime_get_suppliers - Resume and reference-count supplier devices.
  * @dev: Consumer device.
  */
-void pm_runtime_resume_suppliers(struct device *dev)
+void pm_runtime_get_suppliers(struct device *dev)
 {
+	struct device_link *link;
 	int idx;
 
 	idx = device_links_read_lock();
 
-	rpm_get_suppliers(dev);
+	list_for_each_entry_rcu(link, &dev->links.suppliers, c_node)
+		if (link->flags & DL_FLAG_PM_RUNTIME)
+			pm_runtime_get_sync(link->supplier);
+
+	device_links_read_unlock(idx);
+}
+
+/**
+ * pm_runtime_put_suppliers - Drop references to supplier devices.
+ * @dev: Consumer device.
+ */
+void pm_runtime_put_suppliers(struct device *dev)
+{
+	struct device_link *link;
+	int idx;
+
+	idx = device_links_read_lock();
+
+	list_for_each_entry_rcu(link, &dev->links.suppliers, c_node)
+		if (link->flags & DL_FLAG_PM_RUNTIME)
+			pm_runtime_put(link->supplier);
 
 	device_links_read_unlock(idx);
 }

commit a0504aecba76baa1cddbc23512eb8be14df74cef
Author: Ulf Hansson <ulf.hansson@linaro.org>
Date:   Thu May 24 10:33:36 2018 +0200

    PM / runtime: Drop usage count for suppliers at device link removal
    
    In the case consumer device is runtime resumed, while the link to the
    supplier is removed, the earlier call to pm_runtime_get_sync() made from
    rpm_get_suppliers() does not get properly balanced with a corresponding
    call to pm_runtime_put(). This leads to that suppliers remains to be
    runtime resumed forever, while they don't need to.
    
    Let's fix the behaviour by calling rpm_put_suppliers() when dropping a
    device link. Not that, since rpm_put_suppliers() checks the
    link->rpm_active flag, we can correctly avoid to call pm_runtime_put() in
    cases when we shouldn't.
    
    Reported-by: Todor Tomov <todor.tomov@linaro.org>
    Fixes: 21d5c57b3726 (PM / runtime: Use device links)
    Signed-off-by: Ulf Hansson <ulf.hansson@linaro.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 6f4f50e196c1..c6030f100c08 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -1586,6 +1586,8 @@ void pm_runtime_new_link(struct device *dev)
 
 void pm_runtime_drop_link(struct device *dev)
 {
+	rpm_put_suppliers(dev);
+
 	spin_lock_irq(&dev->power.lock);
 	WARN_ON(dev->power.links_count == 0);
 	dev->power.links_count--;

commit 1e8378619841ef1d621b130bbd3fc3b7e6739b50
Author: Ulf Hansson <ulf.hansson@linaro.org>
Date:   Fri May 18 10:48:49 2018 +0200

    PM / runtime: Fixup reference counting of device link suppliers at probe
    
    In the driver core, before it invokes really_probe() it runtime resumes the
    suppliers for the device via calling pm_runtime_get_suppliers(), which also
    increases the runtime PM usage count for each of the available supplier.
    
    This makes sense, as to be able to allow the consumer device to be probed
    by its driver. However, if the driver decides to add a new supplier link
    during ->probe(), hence updating the list of suppliers, the following call
    to pm_runtime_put_suppliers(), invoked after really_probe() in the driver
    core, we get into trouble.
    
    More precisely, pm_runtime_put() gets called also for the new supplier(s),
    which is wrong as the driver core, didn't trigger pm_runtime_get_sync() to
    be called for it in the first place. In other words, the new supplier may
    be runtime suspended even in cases when it shouldn't.
    
    Fix this behaviour, by runtime resume suppliers according to the same
    conditions as managed by the runtime PM core, when runtime resume callbacks
    are being invoked.
    
    Additionally, don't try to runtime suspend any of the suppliers after
    really_probe(), but instead rely on that to happen via the consumer device,
    when it becomes runtime suspended.
    
    Fixes: 21d5c57b3726 (PM / runtime: Use device links)
    Signed-off-by: Ulf Hansson <ulf.hansson@linaro.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 8bef3cb2424d..6f4f50e196c1 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -1563,37 +1563,16 @@ void pm_runtime_clean_up_links(struct device *dev)
 }
 
 /**
- * pm_runtime_get_suppliers - Resume and reference-count supplier devices.
+ * pm_runtime_resume_suppliers - Resume supplier devices.
  * @dev: Consumer device.
  */
-void pm_runtime_get_suppliers(struct device *dev)
+void pm_runtime_resume_suppliers(struct device *dev)
 {
-	struct device_link *link;
 	int idx;
 
 	idx = device_links_read_lock();
 
-	list_for_each_entry_rcu(link, &dev->links.suppliers, c_node)
-		if (link->flags & DL_FLAG_PM_RUNTIME)
-			pm_runtime_get_sync(link->supplier);
-
-	device_links_read_unlock(idx);
-}
-
-/**
- * pm_runtime_put_suppliers - Drop references to supplier devices.
- * @dev: Consumer device.
- */
-void pm_runtime_put_suppliers(struct device *dev)
-{
-	struct device_link *link;
-	int idx;
-
-	idx = device_links_read_lock();
-
-	list_for_each_entry_rcu(link, &dev->links.suppliers, c_node)
-		if (link->flags & DL_FLAG_PM_RUNTIME)
-			pm_runtime_put(link->supplier);
+	rpm_get_suppliers(dev);
 
 	device_links_read_unlock(idx);
 }

commit 617fcb673090e495f58565ff0171d07abdad53a7
Author: Ulf Hansson <ulf.hansson@linaro.org>
Date:   Tue Jan 16 09:01:27 2018 +0100

    PM / runtime: Allow no callbacks in pm_runtime_force_suspend|resume()
    
    The pm_runtime_force_suspend|resume() helpers currently requires the device
    to at some level (PM domain, bus, etc), have the ->runtime_suspend|resume()
    callbacks assigned for it, else -ENOSYS is returned as an error.
    
    However, there are no reason for this requirement, so let's simply remove
    it by allowing these callbacks to be NULL.
    
    Signed-off-by: Ulf Hansson <ulf.hansson@linaro.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index cb5e48b86453..8bef3cb2424d 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -1640,7 +1640,7 @@ static bool pm_runtime_need_not_resume(struct device *dev)
 int pm_runtime_force_suspend(struct device *dev)
 {
 	int (*callback)(struct device *);
-	int ret = 0;
+	int ret;
 
 	pm_runtime_disable(dev);
 	if (pm_runtime_status_suspended(dev))
@@ -1648,12 +1648,7 @@ int pm_runtime_force_suspend(struct device *dev)
 
 	callback = RPM_GET_CALLBACK(dev, runtime_suspend);
 
-	if (!callback) {
-		ret = -ENOSYS;
-		goto err;
-	}
-
-	ret = callback(dev);
+	ret = callback ? callback(dev) : 0;
 	if (ret)
 		goto err;
 
@@ -1704,7 +1699,7 @@ int pm_runtime_force_resume(struct device *dev)
 
 	callback = RPM_GET_CALLBACK(dev, runtime_resume);
 
-	ret = callback ? callback(dev) : -ENOSYS;
+	ret = callback ? callback(dev) : 0;
 	if (ret) {
 		pm_runtime_set_suspended(dev);
 		goto out;

commit 1f5c6855260141ac3115e9a065491ee2ac07f9bc
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Mon Jan 15 01:46:25 2018 +0100

    PM / runtime: Check ignore_children in pm_runtime_need_not_resume()
    
    Modify pm_runtime_need_not_resume() to make it avoid taking
    power.child_count for devices with power.ignore_children which
    is consistent with the runtime PM usage of these fields.
    
    Suggested-by: Ulf Hansson <ulf.hansson@linaro.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Reviewed-by: Ulf Hansson <ulf.hansson@linaro.org>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 84832f1a75bf..cb5e48b86453 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -1616,7 +1616,8 @@ void pm_runtime_drop_link(struct device *dev)
 static bool pm_runtime_need_not_resume(struct device *dev)
 {
 	return atomic_read(&dev->power.usage_count) <= 1 &&
-		atomic_read(&dev->power.child_count) == 0;
+		(atomic_read(&dev->power.child_count) == 0 ||
+		 dev->power.ignore_children);
 }
 
 /**

commit 4918e1f87c5fb7fc8f73a7d8fb118beeb94e05f7
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Fri Jan 12 14:12:05 2018 +0100

    PM / runtime: Rework pm_runtime_force_suspend/resume()
    
    One of the limitations of pm_runtime_force_suspend/resume() is that
    if a parent driver wants to use these functions, all of its child
    drivers generally have to do that too because of the parent usage
    counter manipulations necessary to get the correct state of the parent
    during system-wide transitions to the working state (system resume).
    However, that limitation turns out to be artificial, so remove it.
    
    Namely, pm_runtime_force_suspend() only needs to update the children
    counter of its parent (if there's is a parent) when the device can
    stay in suspend after the subsequent system resume transition, as
    that counter is correct already otherwise.  Now, if the parent's
    children counter is not updated, it is not necessary to increment
    the parent's usage counter in that case any more, as long as the
    children counters of devices are checked along with their usage
    counters in order to decide whether or not the devices may be left
    in suspend after the subsequent system resume transition.
    
    Accordingly, modify pm_runtime_force_suspend() to only call
    pm_runtime_set_suspended() for devices whose usage and children
    counters are at the "no references" level (the runtime PM status
    of the device needs to be updated to "suspended" anyway in case
    this function is called once again for the same device during the
    transition under way), drop the parent usage counter incrementation
    from it and update pm_runtime_force_resume() to compensate for these
    changes.
    
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Reviewed-by: Ulf Hansson <ulf.hansson@linaro.org>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 6e89b51ea3d9..84832f1a75bf 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -1613,17 +1613,28 @@ void pm_runtime_drop_link(struct device *dev)
 	spin_unlock_irq(&dev->power.lock);
 }
 
+static bool pm_runtime_need_not_resume(struct device *dev)
+{
+	return atomic_read(&dev->power.usage_count) <= 1 &&
+		atomic_read(&dev->power.child_count) == 0;
+}
+
 /**
  * pm_runtime_force_suspend - Force a device into suspend state if needed.
  * @dev: Device to suspend.
  *
  * Disable runtime PM so we safely can check the device's runtime PM status and
- * if it is active, invoke it's .runtime_suspend callback to bring it into
- * suspend state. Keep runtime PM disabled to preserve the state unless we
- * encounter errors.
+ * if it is active, invoke its ->runtime_suspend callback to suspend it and
+ * change its runtime PM status field to RPM_SUSPENDED.  Also, if the device's
+ * usage and children counters don't indicate that the device was in use before
+ * the system-wide transition under way, decrement its parent's children counter
+ * (if there is a parent).  Keep runtime PM disabled to preserve the state
+ * unless we encounter errors.
  *
  * Typically this function may be invoked from a system suspend callback to make
- * sure the device is put into low power state.
+ * sure the device is put into low power state and it should only be used during
+ * system-wide PM transitions to sleep states.  It assumes that the analogous
+ * pm_runtime_force_resume() will be used to resume the device.
  */
 int pm_runtime_force_suspend(struct device *dev)
 {
@@ -1646,17 +1657,18 @@ int pm_runtime_force_suspend(struct device *dev)
 		goto err;
 
 	/*
-	 * Increase the runtime PM usage count for the device's parent, in case
-	 * when we find the device being used when system suspend was invoked.
-	 * This informs pm_runtime_force_resume() to resume the parent
-	 * immediately, which is needed to be able to resume its children,
-	 * when not deferring the resume to be managed via runtime PM.
+	 * If the device can stay in suspend after the system-wide transition
+	 * to the working state that will follow, drop the children counter of
+	 * its parent, but set its status to RPM_SUSPENDED anyway in case this
+	 * function will be called again for it in the meantime.
 	 */
-	if (dev->parent && atomic_read(&dev->power.usage_count) > 1)
-		pm_runtime_get_noresume(dev->parent);
+	if (pm_runtime_need_not_resume(dev))
+		pm_runtime_set_suspended(dev);
+	else
+		__update_runtime_status(dev, RPM_SUSPENDED);
 
-	pm_runtime_set_suspended(dev);
 	return 0;
+
 err:
 	pm_runtime_enable(dev);
 	return ret;
@@ -1669,13 +1681,9 @@ EXPORT_SYMBOL_GPL(pm_runtime_force_suspend);
  *
  * Prior invoking this function we expect the user to have brought the device
  * into low power state by a call to pm_runtime_force_suspend(). Here we reverse
- * those actions and brings the device into full power, if it is expected to be
- * used on system resume. To distinguish that, we check whether the runtime PM
- * usage count is greater than 1 (the PM core increases the usage count in the
- * system PM prepare phase), as that indicates a real user (such as a subsystem,
- * driver, userspace, etc.) is using it. If that is the case, the device is
- * expected to be used on system resume as well, so then we resume it. In the
- * other case, we defer the resume to be managed via runtime PM.
+ * those actions and bring the device into full power, if it is expected to be
+ * used on system resume.  In the other case, we defer the resume to be managed
+ * via runtime PM.
  *
  * Typically this function may be invoked from a system resume callback.
  */
@@ -1684,32 +1692,18 @@ int pm_runtime_force_resume(struct device *dev)
 	int (*callback)(struct device *);
 	int ret = 0;
 
-	callback = RPM_GET_CALLBACK(dev, runtime_resume);
-
-	if (!callback) {
-		ret = -ENOSYS;
-		goto out;
-	}
-
-	if (!pm_runtime_status_suspended(dev))
+	if (!pm_runtime_status_suspended(dev) || pm_runtime_need_not_resume(dev))
 		goto out;
 
 	/*
-	 * Decrease the parent's runtime PM usage count, if we increased it
-	 * during system suspend in pm_runtime_force_suspend().
-	*/
-	if (atomic_read(&dev->power.usage_count) > 1) {
-		if (dev->parent)
-			pm_runtime_put_noidle(dev->parent);
-	} else {
-		goto out;
-	}
+	 * The value of the parent's children counter is correct already, so
+	 * just update the status of the device.
+	 */
+	__update_runtime_status(dev, RPM_ACTIVE);
 
-	ret = pm_runtime_set_active(dev);
-	if (ret)
-		goto out;
+	callback = RPM_GET_CALLBACK(dev, runtime_resume);
 
-	ret = callback(dev);
+	ret = callback ? callback(dev) : -ENOSYS;
 	if (ret) {
 		pm_runtime_set_suspended(dev);
 		goto out;

commit 31eb7431805493e10f4731f366cf4d4e3e952035
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Fri Dec 1 14:58:34 2017 +0100

    PM / runtime: Fix handling of suppliers with disabled runtime PM
    
    Prevent rpm_get_suppliers() from returning an error code if runtime
    PM is disabled for one or more of the supplier devices it wants to
    runtime-resume, so as to make runtime PM work for devices with links
    to suppliers that don't use runtime PM (such links may be created
    during device enumeration even before it is known whether or not
    runtime PM will be enabled for the devices in question, for example).
    
    Fixes: 21d5c57b3726 (PM / runtime: Use device links)
    Reported-by: Adrian Hunter <adrian.hunter@intel.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Reviewed-by: Lukas Wunner <lukas@wunner.de>
    Tested-by: Adrian Hunter <adrian.hunter@intel.com>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 027d159ac381..6e89b51ea3d9 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -276,7 +276,8 @@ static int rpm_get_suppliers(struct device *dev)
 			continue;
 
 		retval = pm_runtime_get_sync(link->supplier);
-		if (retval < 0) {
+		/* Ignore suppliers with disabled runtime PM. */
+		if (retval < 0 && retval != -EACCES) {
 			pm_runtime_put_noidle(link->supplier);
 			return retval;
 		}

commit f8817f61e8215b0ff1b73a0d33fa04ef9e6bce8b
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Thu Nov 16 22:51:22 2017 +0100

    PM / runtime: Drop children check from __pm_runtime_set_status()
    
    The check for "active" children in __pm_runtime_set_status(), when
    trying to set the parent device status to "suspended", doesn't
    really make sense, because in fact it is not invalid to set the
    status of a device with runtime PM disabled to "suspended" in any
    case.  It is invalid to enable runtime PM for a device with its
    status set to "suspended" while its child_count reference counter
    is nonzero, but the check in __pm_runtime_set_status() doesn't
    really cover that situation.
    
    For this reason, drop the children check from __pm_runtime_set_status()
    and add a check against child_count reference counters of "suspended"
    devices to pm_runtime_enable().
    
    Fixes: a8636c89648a (PM / Runtime: Don't allow to suspend a device with an active child)
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Reviewed-by: Ulf Hansson <ulf.hansson@linaro.org>
    Reviewed-by: Johan Hovold <johan@kernel.org>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 2362b9e9701e..027d159ac381 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -1101,29 +1101,13 @@ int __pm_runtime_set_status(struct device *dev, unsigned int status)
 		goto out;
 	}
 
-	if (dev->power.runtime_status == status)
+	if (dev->power.runtime_status == status || !parent)
 		goto out_set;
 
 	if (status == RPM_SUSPENDED) {
-		/*
-		 * It is invalid to suspend a device with an active child,
-		 * unless it has been set to ignore its children.
-		 */
-		if (!dev->power.ignore_children &&
-			atomic_read(&dev->power.child_count)) {
-			dev_err(dev, "runtime PM trying to suspend device but active child\n");
-			error = -EBUSY;
-			goto out;
-		}
-
-		if (parent) {
-			atomic_add_unless(&parent->power.child_count, -1, 0);
-			notify_parent = !parent->power.ignore_children;
-		}
-		goto out_set;
-	}
-
-	if (parent) {
+		atomic_add_unless(&parent->power.child_count, -1, 0);
+		notify_parent = !parent->power.ignore_children;
+	} else {
 		spin_lock_nested(&parent->power.lock, SINGLE_DEPTH_NESTING);
 
 		/*
@@ -1307,6 +1291,13 @@ void pm_runtime_enable(struct device *dev)
 	else
 		dev_warn(dev, "Unbalanced %s!\n", __func__);
 
+	WARN(!dev->power.disable_depth &&
+	     dev->power.runtime_status == RPM_SUSPENDED &&
+	     !dev->power.ignore_children &&
+	     atomic_read(&dev->power.child_count) > 0,
+	     "Enabling runtime PM for inactive device (%s) with active children\n",
+	     dev_name(dev));
+
 	spin_unlock_irqrestore(&dev->power.lock, flags);
 }
 EXPORT_SYMBOL_GPL(pm_runtime_enable);

commit bd2cd7d5a8f83ddc761025f42a3ca8e56351a6cc
Merge: b29c6ef7bb12 990a848d537e
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Nov 13 19:43:50 2017 -0800

    Merge tag 'pm-4.15-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/rafael/linux-pm
    
    Pull power management updates from Rafael Wysocki:
     "There are no real big ticket items here this time.
    
      The most noticeable change is probably the relocation of the OPP
      (Operating Performance Points) framework to its own directory under
      drivers/ as it has grown big enough for that. Also Viresh is now going
      to maintain it and send pull requests for it to me, so you will see
      this change in the git history going forward (but still not right
      now).
    
      Another noticeable set of changes is the modifications of the PM core,
      the PCI subsystem and the ACPI PM domain to allow of more integration
      between system-wide suspend/resume and runtime PM. For now it's just a
      way to avoid resuming devices from runtime suspend unnecessarily
      during system suspend (if the driver sets a flag to indicate its
      readiness for that) and in the works is an analogous mechanism to
      allow devices to stay suspended after system resume.
    
      In addition to that, we have some changes related to supporting
      frequency-invariant CPU utilization metrics in the scheduler and in
      the schedutil cpufreq governor on ARM and changes to add support for
      device performance states to the generic power domains (genpd)
      framework.
    
      The rest is mostly fixes and cleanups of various sorts.
    
      Specifics:
    
       - Relocate the OPP (Operating Performance Points) framework to its
         own directory under drivers/ and add support for power domain
         performance states to it (Viresh Kumar).
    
       - Modify the PM core, the PCI bus type and the ACPI PM domain to
         support power management driver flags allowing device drivers to
         specify their capabilities and preferences regarding the handling
         of devices with enabled runtime PM during system suspend/resume and
         clean up that code somewhat (Rafael Wysocki, Ulf Hansson).
    
       - Add frequency-invariant accounting support to the task scheduler on
         ARM and ARM64 (Dietmar Eggemann).
    
       - Fix PM QoS device resume latency framework to prevent "no
         restriction" requests from overriding requests with specific
         requirements and drop the confusing PM_QOS_FLAG_REMOTE_WAKEUP
         device PM QoS flag (Rafael Wysocki).
    
       - Drop legacy class suspend/resume operations from the PM core and
         drop legacy bus type suspend and resume callbacks from ARM/locomo
         (Rafael Wysocki).
    
       - Add min/max frequency support to devfreq and clean it up somewhat
         (Chanwoo Choi).
    
       - Rework wakeup support in the generic power domains (genpd)
         framework and update some of its users accordingly (Geert
         Uytterhoeven).
    
       - Convert timers in the PM core to use timer_setup() (Kees Cook).
    
       - Add support for exposing the SLP_S0 (Low Power S0 Idle) residency
         counter based on the LPIT ACPI table on Intel platforms (Srinivas
         Pandruvada).
    
       - Add per-CPU PM QoS resume latency support to the ladder cpuidle
         governor (Ramesh Thomas).
    
       - Fix a deadlock between the wakeup notify handler and the notifier
         removal in the ACPI core (Ville Syrjälä).
    
       - Fix a cpufreq schedutil governor issue causing it to use stale
         cached frequency values sometimes (Viresh Kumar).
    
       - Fix an issue in the system suspend core support code causing wakeup
         events detection to fail in some cases (Rajat Jain).
    
       - Fix the generic power domains (genpd) framework to prevent the PM
         core from using the direct-complete optimization with it as that is
         guaranteed to fail (Ulf Hansson).
    
       - Fix a minor issue in the cpuidle core and clean it up a bit (Gaurav
         Jindal, Nicholas Piggin).
    
       - Fix and clean up the intel_idle and ARM cpuidle drivers (Jason
         Baron, Len Brown, Leo Yan).
    
       - Fix a couple of minor issues in the OPP framework and clean it up
         (Arvind Yadav, Fabio Estevam, Sudeep Holla, Tobias Jordan).
    
       - Fix and clean up some cpufreq drivers and fix a minor issue in the
         cpufreq statistics code (Arvind Yadav, Bhumika Goyal, Fabio
         Estevam, Gautham Shenoy, Gustavo Silva, Marek Szyprowski, Masahiro
         Yamada, Robert Jarzmik, Zumeng Chen).
    
       - Fix minor issues in the system suspend and hibernation core, in
         power management documentation and in the AVS (Adaptive Voltage
         Scaling) framework (Helge Deller, Himanshu Jha, Joe Perches, Rafael
         Wysocki).
    
       - Fix some issues in the cpupower utility and document that Shuah
         Khan is going to maintain it going forward (Prarit Bhargava, Shuah
         Khan)"
    
    * tag 'pm-4.15-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/rafael/linux-pm: (88 commits)
      tools/power/cpupower: add libcpupower.so.0.0.1 to .gitignore
      tools/power/cpupower: Add 64 bit library detection
      intel_idle: Graceful probe failure when MWAIT is disabled
      cpufreq: schedutil: Reset cached_raw_freq when not in sync with next_freq
      freezer: Fix typo in freezable_schedule_timeout() comment
      PM / s2idle: Clear the events_check_enabled flag
      cpufreq: stats: Handle the case when trans_table goes beyond PAGE_SIZE
      cpufreq: arm_big_little: make cpufreq_arm_bL_ops structures const
      cpufreq: arm_big_little: make function arguments and structure pointer const
      cpuidle: Avoid assignment in if () argument
      cpuidle: Clean up cpuidle_enable_device() error handling a bit
      ACPI / PM: Fix acpi_pm_notifier_lock vs flush_workqueue() deadlock
      PM / Domains: Fix genpd to deal with drivers returning 1 from ->prepare()
      cpuidle: ladder: Add per CPU PM QoS resume latency support
      PM / QoS: Fix device resume latency framework
      PM / domains: Rework governor code to be more consistent
      PM / Domains: Remove gpd_dev_ops.active_wakeup() callback
      soc: rockchip: power-domain: Use GENPD_FLAG_ACTIVE_WAKEUP
      soc: mediatek: Use GENPD_FLAG_ACTIVE_WAKEUP
      ARM: shmobile: pm-rmobile: Use GENPD_FLAG_ACTIVE_WAKEUP
      ...

commit 1efef68262dc567f0c09da9d11924e8287cd3a8b
Merge: 05d658b5b572 05087360fd7a
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Mon Nov 13 01:41:26 2017 +0100

    Merge branch 'pm-core'
    
    * pm-core:
      ACPI / PM: Take SMART_SUSPEND driver flag into account
      PCI / PM: Take SMART_SUSPEND driver flag into account
      PCI / PM: Drop unnecessary invocations of pcibios_pm_ops callbacks
      PM / core: Add SMART_SUSPEND driver flag
      PCI / PM: Use the NEVER_SKIP driver flag
      PM / core: Add NEVER_SKIP and SMART_PREPARE driver flags
      PM / core: Convert timers to use timer_setup()
      PM / core: Fix kerneldoc comments of four functions
      PM / core: Drop legacy class suspend/resume operations

commit 0759e80b84e34a84e7e46e2b1adb528c83d84a47
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Tue Nov 7 11:33:49 2017 +0100

    PM / QoS: Fix device resume latency framework
    
    The special value of 0 for device resume latency PM QoS means
    "no restriction", but there are two problems with that.
    
    First, device resume latency PM QoS requests with 0 as the
    value are always put in front of requests with positive
    values in the priority lists used internally by the PM QoS
    framework, causing 0 to be chosen as an effective constraint
    value.  However, that 0 is then interpreted as "no restriction"
    effectively overriding the other requests with specific
    restrictions which is incorrect.
    
    Second, the users of device resume latency PM QoS have no
    way to specify that *any* resume latency at all should be
    avoided, which is an artificial limitation in general.
    
    To address these issues, modify device resume latency PM QoS to
    use S32_MAX as the "no constraint" value and 0 as the "no
    latency at all" one and rework its users (the cpuidle menu
    governor, the genpd QoS governor and the runtime PM framework)
    to follow these changes.
    
    Also add a special "n/a" value to the corresponding user space I/F
    to allow user space to indicate that it cannot accept any resume
    latencies at all for the given device.
    
    Fixes: 85dc0b8a4019 (PM / QoS: Make it possible to expose PM QoS latency constraints)
    Link: https://bugzilla.kernel.org/show_bug.cgi?id=197323
    Reported-by: Reinette Chatre <reinette.chatre@intel.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Tested-by: Reinette Chatre <reinette.chatre@intel.com>
    Tested-by: Geert Uytterhoeven <geert+renesas@glider.be>
    Tested-by: Tero Kristo <t-kristo@ti.com>
    Reviewed-by: Ramesh Thomas <ramesh.thomas@intel.com>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 7bcf80fa9ada..13e015905543 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -253,7 +253,7 @@ static int rpm_check_suspend_allowed(struct device *dev)
 	    || (dev->power.request_pending
 			&& dev->power.request == RPM_REQ_RESUME))
 		retval = -EAGAIN;
-	else if (__dev_pm_qos_read_value(dev) < 0)
+	else if (__dev_pm_qos_read_value(dev) == 0)
 		retval = -EPERM;
 	else if (dev->power.runtime_status == RPM_SUSPENDED)
 		retval = 1;

commit 6aa7de059173a986114ac43b8f50b297a86f09a8
Author: Mark Rutland <mark.rutland@arm.com>
Date:   Mon Oct 23 14:07:29 2017 -0700

    locking/atomics: COCCINELLE/treewide: Convert trivial ACCESS_ONCE() patterns to READ_ONCE()/WRITE_ONCE()
    
    Please do not apply this to mainline directly, instead please re-run the
    coccinelle script shown below and apply its output.
    
    For several reasons, it is desirable to use {READ,WRITE}_ONCE() in
    preference to ACCESS_ONCE(), and new code is expected to use one of the
    former. So far, there's been no reason to change most existing uses of
    ACCESS_ONCE(), as these aren't harmful, and changing them results in
    churn.
    
    However, for some features, the read/write distinction is critical to
    correct operation. To distinguish these cases, separate read/write
    accessors must be used. This patch migrates (most) remaining
    ACCESS_ONCE() instances to {READ,WRITE}_ONCE(), using the following
    coccinelle script:
    
    ----
    // Convert trivial ACCESS_ONCE() uses to equivalent READ_ONCE() and
    // WRITE_ONCE()
    
    // $ make coccicheck COCCI=/home/mark/once.cocci SPFLAGS="--include-headers" MODE=patch
    
    virtual patch
    
    @ depends on patch @
    expression E1, E2;
    @@
    
    - ACCESS_ONCE(E1) = E2
    + WRITE_ONCE(E1, E2)
    
    @ depends on patch @
    expression E;
    @@
    
    - ACCESS_ONCE(E)
    + READ_ONCE(E)
    ----
    
    Signed-off-by: Mark Rutland <mark.rutland@arm.com>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: davem@davemloft.net
    Cc: linux-arch@vger.kernel.org
    Cc: mpe@ellerman.id.au
    Cc: shuah@kernel.org
    Cc: snitzer@redhat.com
    Cc: thor.thayer@linux.intel.com
    Cc: tj@kernel.org
    Cc: viro@zeniv.linux.org.uk
    Cc: will.deacon@arm.com
    Link: http://lkml.kernel.org/r/1508792849-3115-19-git-send-email-paulmck@linux.vnet.ibm.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 7bcf80fa9ada..41d7c2b99f69 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -134,11 +134,11 @@ unsigned long pm_runtime_autosuspend_expiration(struct device *dev)
 	if (!dev->power.use_autosuspend)
 		goto out;
 
-	autosuspend_delay = ACCESS_ONCE(dev->power.autosuspend_delay);
+	autosuspend_delay = READ_ONCE(dev->power.autosuspend_delay);
 	if (autosuspend_delay < 0)
 		goto out;
 
-	last_busy = ACCESS_ONCE(dev->power.last_busy);
+	last_busy = READ_ONCE(dev->power.last_busy);
 	elapsed = jiffies - last_busy;
 	if (elapsed < 0)
 		goto out;	/* jiffies has wrapped around. */

commit 96428e98aebe5db8a164711f102808651c7f518d
Author: Kees Cook <keescook@chromium.org>
Date:   Mon Oct 16 16:20:55 2017 -0700

    PM / core: Convert timers to use timer_setup()
    
    In preparation for unconditionally passing the struct timer_list pointer to
    all timer callbacks, switch to using the new timer_setup() and from_timer()
    to pass the timer pointer explicitly. Removes test of .data field, since
    that will be going away.
    
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 7bcf80fa9ada..1cea431c0adf 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -894,9 +894,9 @@ static void pm_runtime_work(struct work_struct *work)
  *
  * Check if the time is right and queue a suspend request.
  */
-static void pm_suspend_timer_fn(unsigned long data)
+static void pm_suspend_timer_fn(struct timer_list *t)
 {
-	struct device *dev = (struct device *)data;
+	struct device *dev = from_timer(dev, t, power.suspend_timer);
 	unsigned long flags;
 	unsigned long expires;
 
@@ -1499,8 +1499,7 @@ void pm_runtime_init(struct device *dev)
 	INIT_WORK(&dev->power.work, pm_runtime_work);
 
 	dev->power.timer_expires = 0;
-	setup_timer(&dev->power.suspend_timer, pm_suspend_timer_fn,
-			(unsigned long)dev);
+	timer_setup(&dev->power.suspend_timer, pm_suspend_timer_fn, 0);
 
 	init_waitqueue_head(&dev->power.wait_queue);
 }

commit 5b3cc15aff243cb518cbeed8b1a220cbfd023d9c
Author: Ingo Molnar <mingo@kernel.org>
Date:   Thu Feb 2 20:43:54 2017 +0100

    sched/headers: Prepare to move the memalloc_noio_*() APIs to <linux/sched/mm.h>
    
    Update the .c files that depend on these APIs.
    
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index a14fac6a01d3..7bcf80fa9ada 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -7,7 +7,7 @@
  * This file is released under the GPLv2.
  */
 
-#include <linux/sched.h>
+#include <linux/sched/mm.h>
 #include <linux/export.h>
 #include <linux/pm_runtime.h>
 #include <linux/pm_wakeirq.h>

commit a9306a63631493afc75893a4ac405d4e1cbae6aa
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Sat Feb 4 00:44:36 2017 +0100

    PM / runtime: Avoid false-positive warnings from might_sleep_if()
    
    The might_sleep_if() assertions in __pm_runtime_idle(),
    __pm_runtime_suspend() and __pm_runtime_resume() may generate
    false-positive warnings in some situations.  For example, that
    happens if a nested pm_runtime_get_sync()/pm_runtime_put() pair
    is executed with disabled interrupts within an outer
    pm_runtime_get_sync()/pm_runtime_put() section for the same device.
    [Generally, pm_runtime_get_sync() may sleep, so it should not be
    called with disabled interrupts, but in this particular case the
    previous pm_runtime_get_sync() guarantees that the device will not
    be suspended, so the inner pm_runtime_get_sync() will return
    immediately after incrementing the device's usage counter.]
    
    That started to happen in the i915 driver in 4.10-rc, leading to
    the following splat:
    
     BUG: sleeping function called from invalid context at drivers/base/power/runtime.c:1032
     in_atomic(): 1, irqs_disabled(): 0, pid: 1500, name: Xorg
     1 lock held by Xorg/1500:
      #0:  (&dev->struct_mutex){+.+.+.}, at:
      [<ffffffffa0680c13>] i915_mutex_lock_interruptible+0x43/0x140 [i915]
     CPU: 0 PID: 1500 Comm: Xorg Not tainted
     Call Trace:
      dump_stack+0x85/0xc2
      ___might_sleep+0x196/0x260
      __might_sleep+0x53/0xb0
      __pm_runtime_resume+0x7a/0x90
      intel_runtime_pm_get+0x25/0x90 [i915]
      aliasing_gtt_bind_vma+0xaa/0xf0 [i915]
      i915_vma_bind+0xaf/0x1e0 [i915]
      i915_gem_execbuffer_relocate_entry+0x513/0x6f0 [i915]
      i915_gem_execbuffer_relocate_vma.isra.34+0x188/0x250 [i915]
      ? trace_hardirqs_on+0xd/0x10
      ? i915_gem_execbuffer_reserve_vma.isra.31+0x152/0x1f0 [i915]
      ? i915_gem_execbuffer_reserve.isra.32+0x372/0x3a0 [i915]
      i915_gem_do_execbuffer.isra.38+0xa70/0x1a40 [i915]
      ? __might_fault+0x4e/0xb0
      i915_gem_execbuffer2+0xc5/0x260 [i915]
      ? __might_fault+0x4e/0xb0
      drm_ioctl+0x206/0x450 [drm]
      ? i915_gem_execbuffer+0x340/0x340 [i915]
      ? __fget+0x5/0x200
      do_vfs_ioctl+0x91/0x6f0
      ? __fget+0x111/0x200
      ? __fget+0x5/0x200
      SyS_ioctl+0x79/0x90
      entry_SYSCALL_64_fastpath+0x23/0xc6
    
    even though the code triggering it is correct.
    
    Unfortunately, the might_sleep_if() assertions in question are
    too coarse-grained to cover such cases correctly, so make them
    a bit less sensitive in order to avoid the false-positives.
    
    Reported-and-tested-by: Sedat Dilek <sedat.dilek@gmail.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 872eac4cb1df..a14fac6a01d3 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -966,13 +966,13 @@ int __pm_runtime_idle(struct device *dev, int rpmflags)
 	unsigned long flags;
 	int retval;
 
-	might_sleep_if(!(rpmflags & RPM_ASYNC) && !dev->power.irq_safe);
-
 	if (rpmflags & RPM_GET_PUT) {
 		if (!atomic_dec_and_test(&dev->power.usage_count))
 			return 0;
 	}
 
+	might_sleep_if(!(rpmflags & RPM_ASYNC) && !dev->power.irq_safe);
+
 	spin_lock_irqsave(&dev->power.lock, flags);
 	retval = rpm_idle(dev, rpmflags);
 	spin_unlock_irqrestore(&dev->power.lock, flags);
@@ -998,13 +998,13 @@ int __pm_runtime_suspend(struct device *dev, int rpmflags)
 	unsigned long flags;
 	int retval;
 
-	might_sleep_if(!(rpmflags & RPM_ASYNC) && !dev->power.irq_safe);
-
 	if (rpmflags & RPM_GET_PUT) {
 		if (!atomic_dec_and_test(&dev->power.usage_count))
 			return 0;
 	}
 
+	might_sleep_if(!(rpmflags & RPM_ASYNC) && !dev->power.irq_safe);
+
 	spin_lock_irqsave(&dev->power.lock, flags);
 	retval = rpm_suspend(dev, rpmflags);
 	spin_unlock_irqrestore(&dev->power.lock, flags);
@@ -1029,7 +1029,8 @@ int __pm_runtime_resume(struct device *dev, int rpmflags)
 	unsigned long flags;
 	int retval;
 
-	might_sleep_if(!(rpmflags & RPM_ASYNC) && !dev->power.irq_safe);
+	might_sleep_if(!(rpmflags & RPM_ASYNC) && !dev->power.irq_safe &&
+			dev->power.runtime_status != RPM_ACTIVE);
 
 	if (rpmflags & RPM_GET_PUT)
 		atomic_inc(&dev->power.usage_count);

commit 098c30557a9a19827240aaadc137e4668157dc6b
Merge: 72cca7baf4fb 5d47ec02c37e
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Dec 13 11:42:18 2016 -0800

    Merge tag 'driver-core-4.10-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/gregkh/driver-core
    
    Pull driver core updates from Greg KH:
     "Here's the new driver core patches for 4.10-rc1.
    
      Big thing here is the nice addition of "functional dependencies" to
      the driver core. The idea has been talked about for a very long time,
      great job to Rafael for stepping up and implementing it. It's been
      tested for longer than the 4.9-rc1 date, we held off on merging it
      earlier in order to feel more comfortable about it.
    
      Other than that, it's just a handful of small other patches, some good
      cleanups to the mess that is the firmware class code, and we have a
      test driver for the deferred probe logic.
    
      All of these have been in linux-next for a while with no reported
      issues"
    
    * tag 'driver-core-4.10-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/gregkh/driver-core: (30 commits)
      firmware: Correct handling of fw_state_wait() return value
      driver core: Silence device links sphinx warning
      firmware: remove warning at documentation generation time
      drivers: base: dma-mapping: Fix typo in dmam_alloc_non_coherent comments
      driver core: test_async: fix up typo found by 0-day
      firmware: move fw_state_is_done() into UHM section
      firmware: do not use fw_lock for fw_state protection
      firmware: drop bit ops in favor of simple state machine
      firmware: refactor loading status
      firmware: fix usermode helper fallback loading
      driver core: firmware_class: convert to use class_groups
      driver core: devcoredump: convert to use class_groups
      driver core: class: add class_groups support
      kernfs: Declare two local data structures static
      driver-core: fix platform_no_drv_owner.cocci warnings
      drivers/base/memory.c: Remove unused 'first_page' variable
      driver core: add CLASS_ATTR_WO()
      drivers: base: cacheinfo: support DT overrides for cache properties
      drivers: base: cacheinfo: add pr_fmt logging
      drivers: base: cacheinfo: fix boot error message when acpi is enabled
      ...

commit bed570307ed78f21b77cb04a1df781dee4a8f05a
Author: Tony Lindgren <tony@atomide.com>
Date:   Mon Dec 5 16:38:16 2016 -0800

    PM / wakeirq: Fix dedicated wakeirq for drivers not using autosuspend
    
    I noticed some wakeirq flakeyness with consumer drivers not using
    autosuspend. For drivers not using autosuspend, the wakeirq may never
    get unmasked in rpm_suspend() because of irq desc->depth.
    
    We are configuring dedicated wakeirqs to start with IRQ_NOAUTOEN as we
    naturally don't want them running until rpm_suspend() is called.
    
    However, when a consumer driver initially calls pm_runtime_get(), we
    now wrongly start with disable_irq_nosync() call on the dedicated
    wakeirq that is disabled to start with.
    
    This causes desc->depth to toggle between 1 and 2 instead of the usual
    0 and 1. This can prevent enable_irq() from unmasking the wakeirq as
    that only happens at desc->depth 1.
    
    This does not necessarily show up with drivers using autosuspend as
    there is time for disable_irq_nosync() before rpm_suspend() gets called
    after the autosuspend timeout.
    
    Let's fix the issue by adding wirq->status that lazily gets set on
    the first rpm_suspend(). We also need PM runtime core private functions
    for dev_pm_enable_wake_irq_check() and dev_pm_disable_wake_irq_check()
    so we can enable the dedicated wakeirq on the first rpm_suspend().
    
    While at it, let's also fix the comments for dev_pm_enable_wake_irq()
    and dev_pm_disable_wake_irq(). Those can still be used by the consumer
    drivers as needed because the IRQ core manages the interrupt usecount
    for us.
    
    Fixes: 4990d4fe327b (PM / Wakeirq: Add automated device wake IRQ handling)
    Signed-off-by: Tony Lindgren <tony@atomide.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index f0d863089345..26856d050037 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -516,7 +516,7 @@ static int rpm_suspend(struct device *dev, int rpmflags)
 
 	callback = RPM_GET_CALLBACK(dev, runtime_suspend);
 
-	dev_pm_enable_wake_irq(dev);
+	dev_pm_enable_wake_irq_check(dev, true);
 	retval = rpm_callback(callback, dev);
 	if (retval)
 		goto fail;
@@ -555,7 +555,7 @@ static int rpm_suspend(struct device *dev, int rpmflags)
 	return retval;
 
  fail:
-	dev_pm_disable_wake_irq(dev);
+	dev_pm_disable_wake_irq_check(dev);
 	__update_runtime_status(dev, RPM_ACTIVE);
 	dev->power.deferred_resume = false;
 	wake_up_all(&dev->power.wait_queue);
@@ -738,12 +738,12 @@ static int rpm_resume(struct device *dev, int rpmflags)
 
 	callback = RPM_GET_CALLBACK(dev, runtime_resume);
 
-	dev_pm_disable_wake_irq(dev);
+	dev_pm_disable_wake_irq_check(dev);
 	retval = rpm_callback(callback, dev);
 	if (retval) {
 		__update_runtime_status(dev, RPM_SUSPENDED);
 		pm_runtime_cancel_pending(dev);
-		dev_pm_enable_wake_irq(dev);
+		dev_pm_enable_wake_irq_check(dev, false);
 	} else {
  no_callback:
 		__update_runtime_status(dev, RPM_ACTIVE);

commit 1d9174fbc55ec99ccbfcafa3de2528ef78a849aa
Author: Ulf Hansson <ulf.hansson@linaro.org>
Date:   Thu Oct 13 16:58:54 2016 +0200

    PM / Runtime: Defer resuming of the device in pm_runtime_force_resume()
    
    When the pm_runtime_force_suspend|resume() helpers were invented, we still
    had CONFIG_PM_RUNTIME and CONFIG_PM_SLEEP as separate Kconfig options.
    
    To make sure these helpers worked for all combinations and without
    introducing too much of complexity, the device was always resumed in
    pm_runtime_force_resume().
    
    More precisely, when CONFIG_PM_SLEEP was set and CONFIG_PM_RUNTIME was
    unset, we needed to resume the device as the subsystem/driver couldn't
    rely on using runtime PM to do it.
    
    As the CONFIG_PM_RUNTIME option was merged into CONFIG_PM a while ago, it
    removed this combination, of using CONFIG_PM_SLEEP without the earlier
    CONFIG_PM_RUNTIME.
    
    For this reason we can now rely on the subsystem/driver to use runtime PM
    to resume the device, instead of forcing that to be done in all cases. In
    other words, let's defer the runtime resume to a later point when it's
    actually needed.
    
    Signed-off-by: Ulf Hansson <ulf.hansson@linaro.org>
    Tested-by: Marek Szyprowski <m.szyprowski@samsung.com>
    Tested-by: Geert Uytterhoeven <geert+renesas@glider.be>
    Acked-by: Kevin Hilman <khilman@baylibre.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 60ebb04d8140..f0d863089345 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -1489,6 +1489,16 @@ int pm_runtime_force_suspend(struct device *dev)
 	if (ret)
 		goto err;
 
+	/*
+	 * Increase the runtime PM usage count for the device's parent, in case
+	 * when we find the device being used when system suspend was invoked.
+	 * This informs pm_runtime_force_resume() to resume the parent
+	 * immediately, which is needed to be able to resume its children,
+	 * when not deferring the resume to be managed via runtime PM.
+	 */
+	if (dev->parent && atomic_read(&dev->power.usage_count) > 1)
+		pm_runtime_get_noresume(dev->parent);
+
 	pm_runtime_set_suspended(dev);
 	return 0;
 err:
@@ -1498,16 +1508,20 @@ int pm_runtime_force_suspend(struct device *dev)
 EXPORT_SYMBOL_GPL(pm_runtime_force_suspend);
 
 /**
- * pm_runtime_force_resume - Force a device into resume state.
+ * pm_runtime_force_resume - Force a device into resume state if needed.
  * @dev: Device to resume.
  *
  * Prior invoking this function we expect the user to have brought the device
  * into low power state by a call to pm_runtime_force_suspend(). Here we reverse
- * those actions and brings the device into full power. We update the runtime PM
- * status and re-enables runtime PM.
+ * those actions and brings the device into full power, if it is expected to be
+ * used on system resume. To distinguish that, we check whether the runtime PM
+ * usage count is greater than 1 (the PM core increases the usage count in the
+ * system PM prepare phase), as that indicates a real user (such as a subsystem,
+ * driver, userspace, etc.) is using it. If that is the case, the device is
+ * expected to be used on system resume as well, so then we resume it. In the
+ * other case, we defer the resume to be managed via runtime PM.
  *
- * Typically this function may be invoked from a system resume callback to make
- * sure the device is put into full power state.
+ * Typically this function may be invoked from a system resume callback.
  */
 int pm_runtime_force_resume(struct device *dev)
 {
@@ -1524,6 +1538,17 @@ int pm_runtime_force_resume(struct device *dev)
 	if (!pm_runtime_status_suspended(dev))
 		goto out;
 
+	/*
+	 * Decrease the parent's runtime PM usage count, if we increased it
+	 * during system suspend in pm_runtime_force_suspend().
+	*/
+	if (atomic_read(&dev->power.usage_count) > 1) {
+		if (dev->parent)
+			pm_runtime_put_noidle(dev->parent);
+	} else {
+		goto out;
+	}
+
 	ret = pm_runtime_set_active(dev);
 	if (ret)
 		goto out;

commit a8636c89648ab12e59d8f3aa667ec76fc96fd643
Author: Ulf Hansson <ulf.hansson@linaro.org>
Date:   Mon Oct 17 20:17:01 2016 +0200

    PM / Runtime: Don't allow to suspend a device with an active child
    
    When resuming a device in __pm_runtime_set_status(), the prerequisite is
    that its parent must already be active, else an error code is returned and
    the device's status remains suspended.
    
    When suspending a device there is no similar constraints being validated.
    Let's change this to make the behaviour consistent, by not allowing to
    suspend a device with an active child, unless it has been explicitly set to
    ignore its children.
    
    Signed-off-by: Ulf Hansson <ulf.hansson@linaro.org>
    Reviewed-by: Linus Walleij <linus.walleij@linaro.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 117db71e84cb..60ebb04d8140 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -1028,7 +1028,17 @@ int __pm_runtime_set_status(struct device *dev, unsigned int status)
 		goto out_set;
 
 	if (status == RPM_SUSPENDED) {
-		/* It always is possible to set the status to 'suspended'. */
+		/*
+		 * It is invalid to suspend a device with an active child,
+		 * unless it has been set to ignore its children.
+		 */
+		if (!dev->power.ignore_children &&
+			atomic_read(&dev->power.child_count)) {
+			dev_err(dev, "runtime PM trying to suspend device but active child\n");
+			error = -EBUSY;
+			goto out;
+		}
+
 		if (parent) {
 			atomic_add_unless(&parent->power.child_count, -1, 0);
 			notify_parent = !parent->power.ignore_children;

commit baa8809f60971d10220dfe79248f54b2b265f003
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Sun Oct 30 17:32:43 2016 +0100

    PM / runtime: Optimize the use of device links
    
    If the device has no links to suppliers that should be used for
    runtime PM (links with DEVICE_LINK_PM_RUNTIME set), there is no
    reason to walk the list of suppliers for that device during
    runtime suspend and resume.
    
    Add a simple mechanism to detect that case and possibly avoid the
    extra unnecessary overhead.
    
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 462f90e952f8..ba7b4a8c07e5 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -305,6 +305,7 @@ static int __rpm_callback(int (*cb)(struct device *), struct device *dev)
 	__releases(&dev->power.lock) __acquires(&dev->power.lock)
 {
 	int retval, idx;
+	bool use_links = dev->power.links_count > 0;
 
 	if (dev->power.irq_safe) {
 		spin_unlock(&dev->power.lock);
@@ -318,7 +319,7 @@ static int __rpm_callback(int (*cb)(struct device *), struct device *dev)
 		 * routine returns, so it is safe to read the status outside of
 		 * the lock.
 		 */
-		if (dev->power.runtime_status == RPM_RESUMING) {
+		if (use_links && dev->power.runtime_status == RPM_RESUMING) {
 			idx = device_links_read_lock();
 
 			retval = rpm_get_suppliers(dev);
@@ -341,8 +342,9 @@ static int __rpm_callback(int (*cb)(struct device *), struct device *dev)
 		 *
 		 * Do that if resume fails too.
 		 */
-		if ((dev->power.runtime_status == RPM_SUSPENDING && !retval)
-		    || (dev->power.runtime_status == RPM_RESUMING && retval)) {
+		if (use_links
+		    && ((dev->power.runtime_status == RPM_SUSPENDING && !retval)
+		    || (dev->power.runtime_status == RPM_RESUMING && retval))) {
 			idx = device_links_read_lock();
 
  fail:
@@ -1593,6 +1595,21 @@ void pm_runtime_put_suppliers(struct device *dev)
 	device_links_read_unlock(idx);
 }
 
+void pm_runtime_new_link(struct device *dev)
+{
+	spin_lock_irq(&dev->power.lock);
+	dev->power.links_count++;
+	spin_unlock_irq(&dev->power.lock);
+}
+
+void pm_runtime_drop_link(struct device *dev)
+{
+	spin_lock_irq(&dev->power.lock);
+	WARN_ON(dev->power.links_count == 0);
+	dev->power.links_count--;
+	spin_unlock_irq(&dev->power.lock);
+}
+
 /**
  * pm_runtime_force_suspend - Force a device into suspend state if needed.
  * @dev: Device to suspend.

commit 21d5c57b3726166421251e94dabab047baaf8ce4
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Sun Oct 30 17:32:31 2016 +0100

    PM / runtime: Use device links
    
    Modify the runtime PM framework to use device links to ensure that
    supplier devices will not be suspended if any of their consumer
    devices are active.
    
    The idea is to reference count suppliers on the consumer's resume
    and drop references to them on its suspend.  The information on
    whether or not the supplier has been reference counted by the
    consumer's (runtime) resume is stored in a new field (rpm_active)
    in the link object for each link.
    
    It may be necessary to clean up those references when the
    supplier is unbinding and that's why the links whose status is
    DEVICE_LINK_SUPPLIER_UNBIND are skipped by the runtime suspend
    and resume code.
    
    The above means that if the consumer device is probed in the
    runtime-active state, the supplier has to be resumed and reference
    counted by device_link_add() so the code works as expected on its
    (runtime) suspend.  There is a new flag, DEVICE_LINK_RPM_ACTIVE,
    to tell device_link_add() about that (in which case the caller
    is responsible for making sure that the consumer really will
    be runtime-active when runtime PM is enabled for it).
    
    The other new link flag, DEVICE_LINK_PM_RUNTIME, tells the core
    whether or not the link should be used for runtime PM at all.
    
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 82a081ea4317..462f90e952f8 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -12,6 +12,8 @@
 #include <linux/pm_runtime.h>
 #include <linux/pm_wakeirq.h>
 #include <trace/events/rpm.h>
+
+#include "../base.h"
 #include "power.h"
 
 typedef int (*pm_callback_t)(struct device *);
@@ -258,6 +260,42 @@ static int rpm_check_suspend_allowed(struct device *dev)
 	return retval;
 }
 
+static int rpm_get_suppliers(struct device *dev)
+{
+	struct device_link *link;
+
+	list_for_each_entry_rcu(link, &dev->links.suppliers, c_node) {
+		int retval;
+
+		if (!(link->flags & DL_FLAG_PM_RUNTIME))
+			continue;
+
+		if (READ_ONCE(link->status) == DL_STATE_SUPPLIER_UNBIND ||
+		    link->rpm_active)
+			continue;
+
+		retval = pm_runtime_get_sync(link->supplier);
+		if (retval < 0) {
+			pm_runtime_put_noidle(link->supplier);
+			return retval;
+		}
+		link->rpm_active = true;
+	}
+	return 0;
+}
+
+static void rpm_put_suppliers(struct device *dev)
+{
+	struct device_link *link;
+
+	list_for_each_entry_rcu(link, &dev->links.suppliers, c_node)
+		if (link->rpm_active &&
+		    READ_ONCE(link->status) != DL_STATE_SUPPLIER_UNBIND) {
+			pm_runtime_put(link->supplier);
+			link->rpm_active = false;
+		}
+}
+
 /**
  * __rpm_callback - Run a given runtime PM callback for a given device.
  * @cb: Runtime PM callback to run.
@@ -266,19 +304,55 @@ static int rpm_check_suspend_allowed(struct device *dev)
 static int __rpm_callback(int (*cb)(struct device *), struct device *dev)
 	__releases(&dev->power.lock) __acquires(&dev->power.lock)
 {
-	int retval;
+	int retval, idx;
 
-	if (dev->power.irq_safe)
+	if (dev->power.irq_safe) {
 		spin_unlock(&dev->power.lock);
-	else
+	} else {
 		spin_unlock_irq(&dev->power.lock);
 
+		/*
+		 * Resume suppliers if necessary.
+		 *
+		 * The device's runtime PM status cannot change until this
+		 * routine returns, so it is safe to read the status outside of
+		 * the lock.
+		 */
+		if (dev->power.runtime_status == RPM_RESUMING) {
+			idx = device_links_read_lock();
+
+			retval = rpm_get_suppliers(dev);
+			if (retval)
+				goto fail;
+
+			device_links_read_unlock(idx);
+		}
+	}
+
 	retval = cb(dev);
 
-	if (dev->power.irq_safe)
+	if (dev->power.irq_safe) {
 		spin_lock(&dev->power.lock);
-	else
+	} else {
+		/*
+		 * If the device is suspending and the callback has returned
+		 * success, drop the usage counters of the suppliers that have
+		 * been reference counted on its resume.
+		 *
+		 * Do that if resume fails too.
+		 */
+		if ((dev->power.runtime_status == RPM_SUSPENDING && !retval)
+		    || (dev->power.runtime_status == RPM_RESUMING && retval)) {
+			idx = device_links_read_lock();
+
+ fail:
+			rpm_put_suppliers(dev);
+
+			device_links_read_unlock(idx);
+		}
+
 		spin_lock_irq(&dev->power.lock);
+	}
 
 	return retval;
 }
@@ -1446,6 +1520,79 @@ void pm_runtime_remove(struct device *dev)
 	pm_runtime_reinit(dev);
 }
 
+/**
+ * pm_runtime_clean_up_links - Prepare links to consumers for driver removal.
+ * @dev: Device whose driver is going to be removed.
+ *
+ * Check links from this device to any consumers and if any of them have active
+ * runtime PM references to the device, drop the usage counter of the device
+ * (once per link).
+ *
+ * Links with the DL_FLAG_STATELESS flag set are ignored.
+ *
+ * Since the device is guaranteed to be runtime-active at the point this is
+ * called, nothing else needs to be done here.
+ *
+ * Moreover, this is called after device_links_busy() has returned 'false', so
+ * the status of each link is guaranteed to be DL_STATE_SUPPLIER_UNBIND and
+ * therefore rpm_active can't be manipulated concurrently.
+ */
+void pm_runtime_clean_up_links(struct device *dev)
+{
+	struct device_link *link;
+	int idx;
+
+	idx = device_links_read_lock();
+
+	list_for_each_entry_rcu(link, &dev->links.consumers, s_node) {
+		if (link->flags & DL_FLAG_STATELESS)
+			continue;
+
+		if (link->rpm_active) {
+			pm_runtime_put_noidle(dev);
+			link->rpm_active = false;
+		}
+	}
+
+	device_links_read_unlock(idx);
+}
+
+/**
+ * pm_runtime_get_suppliers - Resume and reference-count supplier devices.
+ * @dev: Consumer device.
+ */
+void pm_runtime_get_suppliers(struct device *dev)
+{
+	struct device_link *link;
+	int idx;
+
+	idx = device_links_read_lock();
+
+	list_for_each_entry_rcu(link, &dev->links.suppliers, c_node)
+		if (link->flags & DL_FLAG_PM_RUNTIME)
+			pm_runtime_get_sync(link->supplier);
+
+	device_links_read_unlock(idx);
+}
+
+/**
+ * pm_runtime_put_suppliers - Drop references to supplier devices.
+ * @dev: Consumer device.
+ */
+void pm_runtime_put_suppliers(struct device *dev)
+{
+	struct device_link *link;
+	int idx;
+
+	idx = device_links_read_lock();
+
+	list_for_each_entry_rcu(link, &dev->links.suppliers, c_node)
+		if (link->flags & DL_FLAG_PM_RUNTIME)
+			pm_runtime_put(link->supplier);
+
+	device_links_read_unlock(idx);
+}
+
 /**
  * pm_runtime_force_suspend - Force a device into suspend state if needed.
  * @dev: Device to suspend.

commit 216ef0b6b8c7f041a618913e94da52c3fdf82a99
Author: Ulf Hansson <ulf.hansson@linaro.org>
Date:   Mon Oct 17 20:16:59 2016 +0200

    PM / Runtime: Clarify comment in rpm_resume() when resuming the parent
    
    Signed-off-by: Ulf Hansson <ulf.hansson@linaro.org>
    Reviewed-by: Linus Walleij <linus.walleij@linaro.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 53b427dfc403..117db71e84cb 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -713,8 +713,8 @@ static int rpm_resume(struct device *dev, int rpmflags)
 
 		spin_lock(&parent->power.lock);
 		/*
-		 * We can resume if the parent's runtime PM is disabled or it
-		 * is set to ignore children.
+		 * Resume the parent if it has runtime PM enabled and not been
+		 * set to ignore its children.
 		 */
 		if (!parent->power.disable_depth
 		    && !parent->power.ignore_children) {

commit 62006c1702b3b1be0c0726949e0ee0ea2326be9c
Author: Ulf Hansson <ulf.hansson@linaro.org>
Date:   Mon Oct 17 20:16:58 2016 +0200

    PM / Runtime: Remove the exported function pm_children_suspended()
    
    The exported function pm_children_suspended() has only one caller, which is
    the runtime PM internal function, rpm_check_suspend_allowed().
    
    Let's clean-up this code, by removing pm_children_suspended() altogether
    and instead do the one-liner check directly in rpm_check_suspend_allowed().
    
    Signed-off-by: Ulf Hansson <ulf.hansson@linaro.org>
    Reviewed-by: Linus Walleij <linus.walleij@linaro.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 82a081ea4317..53b427dfc403 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -241,7 +241,8 @@ static int rpm_check_suspend_allowed(struct device *dev)
 		retval = -EACCES;
 	else if (atomic_read(&dev->power.usage_count) > 0)
 		retval = -EAGAIN;
-	else if (!pm_children_suspended(dev))
+	else if (!dev->power.ignore_children &&
+			atomic_read(&dev->power.child_count))
 		retval = -EBUSY;
 
 	/* Pending resume requests take precedence over suspends. */

commit 778935778c3b88e5152a88765850009006ef2e32
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Tue Apr 26 10:42:25 2016 -0700

    PM / runtime: Use _rcuidle for runtime suspend tracepoints
    
    Further testing with false negatives suppressed by commit 293e2421fe25
    ("rcu: Remove superfluous versions of rcu_read_lock_sched_held()")
    identified a few more unprotected uses of RCU from the idle loop.
    Because RCU actively ignores idle-loop code (for energy-efficiency
    reasons, among other things), using RCU from the idle loop can result
    in too-short grace periods, in turn resulting in arbitrary misbehavior.
    
    The affected function is rpm_suspend().
    
    The resulting lockdep-RCU splat is as follows:
    
    ------------------------------------------------------------------------
    
    Warning from omap3
    
    ===============================
    [ INFO: suspicious RCU usage. ]
    4.6.0-rc5-next-20160426+ #1112 Not tainted
    -------------------------------
    include/trace/events/rpm.h:63 suspicious rcu_dereference_check() usage!
    
    other info that might help us debug this:
    
    RCU used illegally from idle CPU!
    rcu_scheduler_active = 1, debug_locks = 0
    RCU used illegally from extended quiescent state!
    1 lock held by swapper/0/0:
     #0:  (&(&dev->power.lock)->rlock){-.-...}, at: [<c052ee24>] __pm_runtime_suspend+0x54/0x84
    
    stack backtrace:
    CPU: 0 PID: 0 Comm: swapper/0 Not tainted 4.6.0-rc5-next-20160426+ #1112
    Hardware name: Generic OMAP36xx (Flattened Device Tree)
    [<c0110308>] (unwind_backtrace) from [<c010c3a8>] (show_stack+0x10/0x14)
    [<c010c3a8>] (show_stack) from [<c047fec8>] (dump_stack+0xb0/0xe4)
    [<c047fec8>] (dump_stack) from [<c052d7b4>] (rpm_suspend+0x604/0x7e4)
    [<c052d7b4>] (rpm_suspend) from [<c052ee34>] (__pm_runtime_suspend+0x64/0x84)
    [<c052ee34>] (__pm_runtime_suspend) from [<c04bf3bc>] (omap2_gpio_prepare_for_idle+0x5c/0x70)
    [<c04bf3bc>] (omap2_gpio_prepare_for_idle) from [<c01255e8>] (omap_sram_idle+0x140/0x244)
    [<c01255e8>] (omap_sram_idle) from [<c0126b48>] (omap3_enter_idle_bm+0xfc/0x1ec)
    [<c0126b48>] (omap3_enter_idle_bm) from [<c0601db8>] (cpuidle_enter_state+0x80/0x3d4)
    [<c0601db8>] (cpuidle_enter_state) from [<c0183c74>] (cpu_startup_entry+0x198/0x3a0)
    [<c0183c74>] (cpu_startup_entry) from [<c0b00c0c>] (start_kernel+0x354/0x3c8)
    [<c0b00c0c>] (start_kernel) from [<8000807c>] (0x8000807c)
    
    ------------------------------------------------------------------------
    
    Reported-by: Tony Lindgren <tony@atomide.com>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Tested-by: Tony Lindgren <tony@atomide.com>
    Tested-by: Guenter Roeck <linux@roeck-us.net>
    [ rjw: Subject ]
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 17995fadebd7..82a081ea4317 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -419,7 +419,7 @@ static int rpm_suspend(struct device *dev, int rpmflags)
 	struct device *parent = NULL;
 	int retval;
 
-	trace_rpm_suspend(dev, rpmflags);
+	trace_rpm_suspend_rcuidle(dev, rpmflags);
 
  repeat:
 	retval = rpm_check_suspend_allowed(dev);
@@ -549,7 +549,7 @@ static int rpm_suspend(struct device *dev, int rpmflags)
 	}
 
  out:
-	trace_rpm_return_int(dev, _THIS_IP_, retval);
+	trace_rpm_return_int_rcuidle(dev, _THIS_IP_, retval);
 
 	return retval;
 

commit d7737ce964d944dd07e25b0f569edcd550ede18c
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Tue Apr 26 13:03:51 2016 -0700

    PM / runtime: Add _rcuidle suffix to allow rpm_idle() use from idle
    
    This commit appends a few _rcuidle suffixes to fix the following
    RCU-used-from-idle bug:
    
    > ===============================
    > [ INFO: suspicious RCU usage. ]
    > 4.6.0-rc5-next-20160426+ #1116 Not tainted
    > -------------------------------
    > include/trace/events/rpm.h:95 suspicious rcu_dereference_check() usage!
    >
    > other info that might help us debug this:
    >
    >
    > RCU used illegally from idle CPU!
    > rcu_scheduler_active = 1, debug_locks = 0
    > RCU used illegally from extended quiescent state!
    > 1 lock held by swapper/0/0:
    >  #0:  (&(&dev->power.lock)->rlock){-.-...}, at: [<c052cc2c>] __rpm_callback+0x58/0x60
    >
    > stack backtrace:
    > CPU: 0 PID: 0 Comm: swapper/0 Not tainted 4.6.0-rc5-next-20160426+ #1116
    > Hardware name: Generic OMAP36xx (Flattened Device Tree)
    > [<c0110290>] (unwind_backtrace) from [<c010c3a8>] (show_stack+0x10/0x14)
    > [<c010c3a8>] (show_stack) from [<c047fd68>] (dump_stack+0xb0/0xe4)
    > [<c047fd68>] (dump_stack) from [<c052d5d0>] (rpm_suspend+0x580/0x768)
    > [<c052d5d0>] (rpm_suspend) from [<c052ec58>] (__pm_runtime_suspend+0x64/0x84)
    > [<c052ec58>] (__pm_runtime_suspend) from [<c04bf25c>] (omap2_gpio_prepare_for_idle+0x5c/0x70)
    > [<c04bf25c>] (omap2_gpio_prepare_for_idle) from [<c0125568>] (omap_sram_idle+0x140/0x244)
    > [<c0125568>] (omap_sram_idle) from [<c01269dc>] (omap3_enter_idle_bm+0xfc/0x1ec)
    > [<c01269dc>] (omap3_enter_idle_bm) from [<c0601bdc>] (cpuidle_enter_state+0x80/0x3d4)
    > [<c0601bdc>] (cpuidle_enter_state) from [<c0183b08>] (cpu_startup_entry+0x198/0x3a0)
    > [<c0183b08>] (cpu_startup_entry) from [<c0b00c0c>] (start_kernel+0x354/0x3c8)
    > [<c0b00c0c>] (start_kernel) from [<8000807c>] (0x8000807c)
    
    In the immortal words of Steven Rostedt, "*Whack* *Whack* *Whack*!!!"
    
    Reported-by: Tony Lindgren <tony@atomide.com>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Tested-by: Tony Lindgren <tony@atomide.com>
    Tested-by: Guenter Roeck <linux@roeck-us.net>
    WhACKED-by: Steven Rostedt <rostedt@goodmis.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 76127e109ed2..17995fadebd7 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -301,7 +301,7 @@ static int rpm_idle(struct device *dev, int rpmflags)
 	int (*callback)(struct device *);
 	int retval;
 
-	trace_rpm_idle(dev, rpmflags);
+	trace_rpm_idle_rcuidle(dev, rpmflags);
 	retval = rpm_check_suspend_allowed(dev);
 	if (retval < 0)
 		;	/* Conditions are wrong. */
@@ -337,7 +337,7 @@ static int rpm_idle(struct device *dev, int rpmflags)
 			dev->power.request_pending = true;
 			queue_work(pm_wq, &dev->power.work);
 		}
-		trace_rpm_return_int(dev, _THIS_IP_, 0);
+		trace_rpm_return_int_rcuidle(dev, _THIS_IP_, 0);
 		return 0;
 	}
 
@@ -352,7 +352,7 @@ static int rpm_idle(struct device *dev, int rpmflags)
 	wake_up_all(&dev->power.wait_queue);
 
  out:
-	trace_rpm_return_int(dev, _THIS_IP_, retval);
+	trace_rpm_return_int_rcuidle(dev, _THIS_IP_, retval);
 	return retval ? retval : rpm_suspend(dev, rpmflags | RPM_AUTO);
 }
 

commit d44c950e9398e639e124014e5872480a37b67259
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Tue Apr 26 13:38:55 2016 -0700

    PM / runtime: Add _rcuidle suffix to allow rpm_resume() to be called from idle
    
    This commit applies another _rcuidle suffix to fix an RCU use from
    idle.
    
    > ===============================
    > [ INFO: suspicious RCU usage. ]
    > 4.6.0-rc5-next-20160426+ #1122 Not tainted
    > -------------------------------
    > include/trace/events/rpm.h:69 suspicious rcu_dereference_check() usage!
    >
    > other info that might help us debug this:
    >
    >
    > RCU used illegally from idle CPU!
    > rcu_scheduler_active = 1, debug_locks = 0
    > RCU used illegally from extended quiescent state!
    > 1 lock held by swapper/0/0:
    >  #0:  (&(&dev->power.lock)->rlock){-.-...}, at: [<c052e3dc>] __pm_runtime_resume+0x3c/0x64
    >
    > stack backtrace:
    > CPU: 0 PID: 0 Comm: swapper/0 Not tainted 4.6.0-rc5-next-20160426+ #1122
    > Hardware name: Generic OMAP36xx (Flattened Device Tree)
    > [<c0110290>] (unwind_backtrace) from [<c010c3a8>] (show_stack+0x10/0x14)
    > [<c010c3a8>] (show_stack) from [<c047fd68>] (dump_stack+0xb0/0xe4)
    > [<c047fd68>] (dump_stack) from [<c052e178>] (rpm_resume+0x5cc/0x7f4)
    > [<c052e178>] (rpm_resume) from [<c052e3ec>] (__pm_runtime_resume+0x4c/0x64)
    > [<c052e3ec>] (__pm_runtime_resume) from [<c04bf2c4>] (omap2_gpio_resume_after_idle+0x54/0x68)
    > [<c04bf2c4>] (omap2_gpio_resume_after_idle) from [<c01269dc>] (omap3_enter_idle_bm+0xfc/0x1ec)
    > [<c01269dc>] (omap3_enter_idle_bm) from [<c060198c>] (cpuidle_enter_state+0x80/0x3d4)
    > [<c060198c>] (cpuidle_enter_state) from [<c0183b08>] (cpu_startup_entry+0x198/0x3a0)
    > [<c0183b08>] (cpu_startup_entry) from [<c0b00c0c>] (start_kernel+0x354/0x3c8)
    > [<c0b00c0c>] (start_kernel) from [<8000807c>] (0x8000807c)
    
    Reported-by: Tony Lindgren <tony@atomide.com>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Tested-by: Tony Lindgren <tony@atomide.com>
    Tested-by: Guenter Roeck <linux@roeck-us.net>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index e097d355cc04..76127e109ed2 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -601,7 +601,7 @@ static int rpm_resume(struct device *dev, int rpmflags)
 	struct device *parent = NULL;
 	int retval = 0;
 
-	trace_rpm_resume(dev, rpmflags);
+	trace_rpm_resume_rcuidle(dev, rpmflags);
 
  repeat:
 	if (dev->power.runtime_error)
@@ -764,7 +764,7 @@ static int rpm_resume(struct device *dev, int rpmflags)
 		spin_lock_irq(&dev->power.lock);
 	}
 
-	trace_rpm_return_int(dev, _THIS_IP_, retval);
+	trace_rpm_return_int_rcuidle(dev, _THIS_IP_, retval);
 
 	return retval;
 }

commit fa70db3f19a183af5334edea5ad9e417c58faa5c
Merge: dbac75468eef fe7450b05fdd 498b5fdd40dd 7eb231c337e0 6ec39cf5cd6f
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Mon Jul 25 13:45:27 2016 +0200

    Merge branches 'pm-core', 'pm-clk', 'pm-domains' and 'pm-pci'
    
    * pm-core:
      PM / runtime: Asynchronous "idle" in pm_runtime_allow()
      PM / runtime: print error when activating a child to unactive parent
    
    * pm-clk:
      PM / clk: Add support for adding a specific clock from device-tree
      PM / clk: export symbols for existing pm_clk_<...> API fcns
    
    * pm-domains:
      PM / Domains: Convert pm_genpd_init() to return an error code
      PM / Domains: Stop/start devices during system PM suspend/resume in genpd
      PM / Domains: Allow runtime PM during system PM phases
      PM / Runtime: Avoid resuming devices again in pm_runtime_force_resume()
      PM / Domains: Remove redundant pm_request_idle() call in genpd
      PM / Domains: Remove redundant wrapper functions for system PM
      PM / Domains: Allow genpd to power on during system PM phases
    
    * pm-pci:
      PCI / PM: check all fields in pci_set_platform_pm()

commit fe7450b05fddebd5a76a5ad280a5ae9a82ce336f
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Wed Jun 29 02:53:48 2016 +0200

    PM / runtime: Asynchronous "idle" in pm_runtime_allow()
    
    Arjan reports that it takes a relatively long time to enable runtime
    PM for multiple devices at system startup, because all writes to the
    "control" attribute in sysfs are handled synchronously and if the
    device is suspended as a result of the write, it will block until
    that operation is complete.
    
    That may be avoided by passing the RPM_ASYNC flag to rpm_idle()
    in pm_runtime_allow() which will make it execute the device's
    "idle" callback asynchronously, so writes to "control" changing
    it from "on" to "auto" will return without waiting.
    
    Reported-by: Arjan van de Ven <arjan@linux.intel.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Acked-by: Alan Stern <stern@rowland.harvard.edu>
    Reviewed-by: Ulf Hansson <ulf.hansson@linaro.org>
    Reviewed-by: Kevin Hilman <khilman@baylibre.com>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index e7ee8293055b..aa3ea5e25377 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -1260,7 +1260,7 @@ void pm_runtime_allow(struct device *dev)
 
 	dev->power.runtime_auto = true;
 	if (atomic_dec_and_test(&dev->power.usage_count))
-		rpm_idle(dev, RPM_AUTO);
+		rpm_idle(dev, RPM_AUTO | RPM_ASYNC);
 
  out:
 	spin_unlock_irq(&dev->power.lock);

commit 71723f95463d284004bd0afe1825e6790a0c90d0
Author: Linus Walleij <linus.walleij@linaro.org>
Date:   Mon Jun 20 11:14:26 2016 +0200

    PM / runtime: print error when activating a child to unactive parent
    
    The code currently silently bails out with -EBUSY if you try to
    activate a child to an inactive parent.
    
    This typically happens when you have a runtime suspended parent
    and runtime resume your child, but forgot to set .ignore_children
    on the parent to true with pm_suspend_ignore_children(dev).
    
    Silently ignoring this error is not good as it gives rise to
    other strange behaviour like double-resume of devices after
    silently bailing out of the .runtime_resume() callback.
    
    Signed-off-by: Linus Walleij <linus.walleij@linaro.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index b74690418504..e7ee8293055b 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -1045,10 +1045,14 @@ int __pm_runtime_set_status(struct device *dev, unsigned int status)
 		 */
 		if (!parent->power.disable_depth
 		    && !parent->power.ignore_children
-		    && parent->power.runtime_status != RPM_ACTIVE)
+		    && parent->power.runtime_status != RPM_ACTIVE) {
+			dev_err(dev, "runtime PM trying to activate child device %s but parent (%s) is not active\n",
+				dev_name(dev),
+				dev_name(parent));
 			error = -EBUSY;
-		else if (dev->power.runtime_status == RPM_SUSPENDED)
+		} else if (dev->power.runtime_status == RPM_SUSPENDED) {
 			atomic_inc(&parent->power.child_count);
+		}
 
 		spin_unlock(&parent->power.lock);
 

commit 9f5b52747dbf83816dcd29ea1700813aeb668c0f
Author: Ulf Hansson <ulf.hansson@linaro.org>
Date:   Mon May 30 11:33:12 2016 +0200

    PM / Runtime: Avoid resuming devices again in pm_runtime_force_resume()
    
    If the runtime PM status of the device isn't RPM_SUSPENDED, prevent the
    pm_runtime_force_resume() from invoking the ->runtime_resume() callback
    for the device, as it's not the expected behaviour from the subsystem/driver.
    
    Signed-off-by: Ulf Hansson <ulf.hansson@linaro.org>
    Reviewed-by: Kevin Hilman <khilman@baylibre.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index b74690418504..09e4eb1a7286 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -1506,6 +1506,9 @@ int pm_runtime_force_resume(struct device *dev)
 		goto out;
 	}
 
+	if (!pm_runtime_status_suspended(dev))
+		goto out;
+
 	ret = pm_runtime_set_active(dev);
 	if (ret)
 		goto out;

commit 0ae3aeefabbeef26294e7a349b51f1c761d46c9f
Author: Ulf Hansson <ulf.hansson@linaro.org>
Date:   Fri Apr 8 13:10:23 2016 +0200

    PM / Runtime: Fix error path in pm_runtime_force_resume()
    
    As pm_runtime_set_active() may fail because the device's parent isn't
    active, we can end up executing the ->runtime_resume() callback for the
    device when it isn't allowed.
    
    Fix this by invoking pm_runtime_set_active() before running the callback
    and let's also deal with the error code.
    
    Fixes: 37f204164dfb (PM: Add pm_runtime_suspend|resume_force functions)
    Signed-off-by: Ulf Hansson <ulf.hansson@linaro.org>
    Reviewed-by: Linus Walleij <linus.walleij@linaro.org>
    Cc: 3.15+ <stable@vger.kernel.org> # 3.15+
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 4c7055009bd6..b74690418504 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -1506,11 +1506,16 @@ int pm_runtime_force_resume(struct device *dev)
 		goto out;
 	}
 
-	ret = callback(dev);
+	ret = pm_runtime_set_active(dev);
 	if (ret)
 		goto out;
 
-	pm_runtime_set_active(dev);
+	ret = callback(dev);
+	if (ret) {
+		pm_runtime_set_suspended(dev);
+		goto out;
+	}
+
 	pm_runtime_mark_last_busy(dev);
 out:
 	pm_runtime_enable(dev);

commit a436b6a19f57656a6557439523923d89eb4a880d
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Thu Dec 17 02:54:26 2015 +0100

    PM / runtime: Add new helper for conditional usage count incrementation
    
    Introduce a new runtime PM function, pm_runtime_get_if_in_use(),
    that will increment the device's runtime PM usage counter and
    return 1 if its status is RPM_ACTIVE and its usage counter
    is greater than 0 at the same time (0 will be returned otherwise).
    
    This is useful for things that should only be done if the device
    is active (from the runtime PM perspective) and used by somebody
    (as indicated by the usage counter) already and they are not worth
    bothering otherwise.
    
    Requested-by: Imre Deak <imre.deak@intel.com>
    Reviewed-by: Ulf Hansson <ulf.hansson@linaro.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index ab3fcd9f6c98..4c7055009bd6 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -965,6 +965,30 @@ int __pm_runtime_resume(struct device *dev, int rpmflags)
 }
 EXPORT_SYMBOL_GPL(__pm_runtime_resume);
 
+/**
+ * pm_runtime_get_if_in_use - Conditionally bump up the device's usage counter.
+ * @dev: Device to handle.
+ *
+ * Return -EINVAL if runtime PM is disabled for the device.
+ *
+ * If that's not the case and if the device's runtime PM status is RPM_ACTIVE
+ * and the runtime PM usage counter is nonzero, increment the counter and
+ * return 1.  Otherwise return 0 without changing the counter.
+ */
+int pm_runtime_get_if_in_use(struct device *dev)
+{
+	unsigned long flags;
+	int retval;
+
+	spin_lock_irqsave(&dev->power.lock, flags);
+	retval = dev->power.disable_depth > 0 ? -EINVAL :
+		dev->power.runtime_status == RPM_ACTIVE
+			&& atomic_inc_not_zero(&dev->power.usage_count);
+	spin_unlock_irqrestore(&dev->power.lock, flags);
+	return retval;
+}
+EXPORT_SYMBOL_GPL(pm_runtime_get_if_in_use);
+
 /**
  * __pm_runtime_set_status - Set runtime PM status of a device.
  * @dev: Device to handle.

commit 5de85b9d57aba3ed2e04759e6db3b9e826dd0b06
Author: Ulf Hansson <ulf.hansson@linaro.org>
Date:   Wed Nov 18 11:48:39 2015 +0100

    PM / runtime: Re-init runtime PM states at probe error and driver unbind
    
    There are two common expectations among several subsystems/drivers that
    deploys runtime PM support, but which isn't met by the driver core.
    
    Expectation 1)
    At ->probe() the subsystem/driver expects the runtime PM status of the
    device to be RPM_SUSPENDED, which is the initial status being assigned at
    device registration.
    
    This expectation is especially common among some of those subsystems/
    drivers that manages devices with an attached PM domain, as those requires
    the ->runtime_resume() callback at the PM domain level to be invoked
    during ->probe().
    
    Moreover these subsystems/drivers entirely relies on runtime PM resources
    being managed at the PM domain level, thus don't implement their own set
    of runtime PM callbacks.
    
    These are two scenarios that suffers from this unmet expectation.
    
    i) A failed ->probe() sequence requests probe deferral:
    
    ->probe()
      ...
      pm_runtime_enable()
      pm_runtime_get_sync()
      ...
    
    err:
      pm_runtime_put()
      pm_runtime_disable()
      ...
    
    As there are no guarantees that such sequence turns the runtime PM status
    of the device into RPM_SUSPENDED, the re-trying ->probe() may start with
    the status in RPM_ACTIVE.
    
    In such case the runtime PM core won't invoke the ->runtime_resume()
    callback because of a pm_runtime_get_sync(), as it considers the device to
    be already runtime resumed.
    
    ii) A driver re-bind sequence:
    
    At driver unbind, the subsystem/driver's >remove() callback invokes a
    sequence of runtime PM APIs, to undo actions during ->probe() and to put
    the device into low power state.
    
    ->remove()
      ...
      pm_runtime_put()
      pm_runtime_disable()
      ...
    
    Similar as in the failing ->probe() case, this sequence don't guarantee
    the runtime PM status of the device to turn into RPM_SUSPENDED.
    
    Trying to re-bind the driver thus causes the same issue as when re-trying
    ->probe(), in the probe deferral scenario.
    
    Expectation 2)
    Drivers that invokes the pm_runtime_irq_safe() API during ->probe(),
    triggers the runtime PM core to increase the usage count for the device's
    parent and permanently make it runtime resumed.
    
    The usage count is only dropped at device removal, which also allows it to
    be runtime suspended again.
    
    A re-trying ->probe() repeats the call to pm_runtime_irq_safe() and thus
    once more triggers the usage count of the device's parent to be increased.
    
    This leads to not only an imbalance issue of the usage count of the
    device's parent, but also to keep it runtime resumed permanently even if
    ->probe() fails.
    
    To address these issues, let's change the policy of the driver core to
    meet these expectations. More precisely, at ->probe() failures and driver
    unbind, restore the initial states of runtime PM.
    
    Although to still allow subsystem's to control PM for devices that doesn't
    ->probe() successfully, don't restore the initial states unless runtime PM
    is disabled.
    
    Signed-off-by: Ulf Hansson <ulf.hansson@linaro.org>
    Reviewed-by: Kevin Hilman <khilman@linaro.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index e1a10a03df8e..ab3fcd9f6c98 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -1389,6 +1389,25 @@ void pm_runtime_init(struct device *dev)
 	init_waitqueue_head(&dev->power.wait_queue);
 }
 
+/**
+ * pm_runtime_reinit - Re-initialize runtime PM fields in given device object.
+ * @dev: Device object to re-initialize.
+ */
+void pm_runtime_reinit(struct device *dev)
+{
+	if (!pm_runtime_enabled(dev)) {
+		if (dev->power.runtime_status == RPM_ACTIVE)
+			pm_runtime_set_suspended(dev);
+		if (dev->power.irq_safe) {
+			spin_lock_irq(&dev->power.lock);
+			dev->power.irq_safe = 0;
+			spin_unlock_irq(&dev->power.lock);
+			if (dev->parent)
+				pm_runtime_put(dev->parent);
+		}
+	}
+}
+
 /**
  * pm_runtime_remove - Prepare for removing a device from device hierarchy.
  * @dev: Device object being removed from device hierarchy.
@@ -1396,12 +1415,7 @@ void pm_runtime_init(struct device *dev)
 void pm_runtime_remove(struct device *dev)
 {
 	__pm_runtime_disable(dev, false);
-
-	/* Change the status back to 'suspended' to match the initial status. */
-	if (dev->power.runtime_status == RPM_ACTIVE)
-		pm_runtime_set_suspended(dev);
-	if (dev->power.irq_safe && dev->parent)
-		pm_runtime_put(dev->parent);
+	pm_runtime_reinit(dev);
 }
 
 /**

commit 4990d4fe327b9d9a7a3be7103a82699406fdde69
Author: Tony Lindgren <tony@atomide.com>
Date:   Mon May 18 15:40:29 2015 -0700

    PM / Wakeirq: Add automated device wake IRQ handling
    
    Turns out we can automate the handling for the device_may_wakeup()
    quite a bit by using the kernel wakeup source list as suggested
    by Rafael J. Wysocki <rjw@rjwysocki.net>.
    
    And as some hardware has separate dedicated wake-up interrupt
    in addition to the IO interrupt, we can automate the handling by
    adding a generic threaded interrupt handler that just calls the
    device PM runtime to wake up the device.
    
    This allows dropping code from device drivers as we currently
    are doing it in multiple ways, and often wrong.
    
    For most drivers, we should be able to drop the following
    boilerplate code from runtime_suspend and runtime_resume
    functions:
    
            ...
            device_init_wakeup(dev, true);
            ...
            if (device_may_wakeup(dev))
                    enable_irq_wake(irq);
            ...
            if (device_may_wakeup(dev))
                    disable_irq_wake(irq);
            ...
            device_init_wakeup(dev, false);
            ...
    
    We can replace it with just the following init and exit
    time code:
    
            ...
            device_init_wakeup(dev, true);
            dev_pm_set_wake_irq(dev, irq);
            ...
            dev_pm_clear_wake_irq(dev);
            device_init_wakeup(dev, false);
            ...
    
    And for hardware with dedicated wake-up interrupts:
    
            ...
            device_init_wakeup(dev, true);
            dev_pm_set_dedicated_wake_irq(dev, irq);
            ...
            dev_pm_clear_wake_irq(dev);
            device_init_wakeup(dev, false);
            ...
    
    Signed-off-by: Tony Lindgren <tony@atomide.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 4ffe4a2add76..e1a10a03df8e 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -10,6 +10,7 @@
 #include <linux/sched.h>
 #include <linux/export.h>
 #include <linux/pm_runtime.h>
+#include <linux/pm_wakeirq.h>
 #include <trace/events/rpm.h>
 #include "power.h"
 
@@ -514,6 +515,7 @@ static int rpm_suspend(struct device *dev, int rpmflags)
 
 	callback = RPM_GET_CALLBACK(dev, runtime_suspend);
 
+	dev_pm_enable_wake_irq(dev);
 	retval = rpm_callback(callback, dev);
 	if (retval)
 		goto fail;
@@ -552,6 +554,7 @@ static int rpm_suspend(struct device *dev, int rpmflags)
 	return retval;
 
  fail:
+	dev_pm_disable_wake_irq(dev);
 	__update_runtime_status(dev, RPM_ACTIVE);
 	dev->power.deferred_resume = false;
 	wake_up_all(&dev->power.wait_queue);
@@ -734,10 +737,12 @@ static int rpm_resume(struct device *dev, int rpmflags)
 
 	callback = RPM_GET_CALLBACK(dev, runtime_resume);
 
+	dev_pm_disable_wake_irq(dev);
 	retval = rpm_callback(callback, dev);
 	if (retval) {
 		__update_runtime_status(dev, RPM_SUSPENDED);
 		pm_runtime_cancel_pending(dev);
+		dev_pm_enable_wake_irq(dev);
 	} else {
  no_callback:
 		__update_runtime_status(dev, RPM_ACTIVE);

commit 56f487c78015936097474fd89b2ccb229d500d0f
Author: Tony Lindgren <tony@atomide.com>
Date:   Wed May 13 16:36:32 2015 -0700

    PM / Runtime: Update last_busy in rpm_resume
    
    If we don't update last_busy in rpm_resume, devices can go back
    to sleep immediately after resume. This happens at least in
    cases where the device has been powered off and does not have
    any interrupt pending until there's something in the FIFO.
    
    Signed-off-by: Tony Lindgren <tony@atomide.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 5070c4fe8542..4ffe4a2add76 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -741,6 +741,7 @@ static int rpm_resume(struct device *dev, int rpmflags)
 	} else {
  no_callback:
 		__update_runtime_status(dev, RPM_ACTIVE);
+		pm_runtime_mark_last_busy(dev);
 		if (parent)
 			atomic_inc(&parent->power.child_count);
 	}

commit d30d819dc83107812d9b2876e5e7194e511ed6af
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Thu Nov 27 22:38:05 2014 +0100

    PM: Drop CONFIG_PM_RUNTIME from the driver core
    
    After commit b2b49ccbdd54 (PM: Kconfig: Set PM_RUNTIME if PM_SLEEP is
    selected) PM_RUNTIME is always set if PM is set, so quite a few
    depend on CONFIG_PM or even may be dropped entirely in some cases.
    
    Replace CONFIG_PM_RUNTIME with CONFIG_PM in the PM core code.
    
    Reviewed-by: Ulf Hansson <ulf.hansson@linaro.org>
    Acked-by: Kevin Hilman <khilman@linaro.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 8f1ab8446caa..5070c4fe8542 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -45,8 +45,6 @@ static pm_callback_t __rpm_get_callback(struct device *dev, size_t cb_offset)
 #define RPM_GET_CALLBACK(dev, callback) \
 		__rpm_get_callback(dev, offsetof(struct dev_pm_ops, callback))
 
-#ifdef CONFIG_PM_RUNTIME
-
 static int rpm_resume(struct device *dev, int rpmflags);
 static int rpm_suspend(struct device *dev, int rpmflags);
 
@@ -1399,7 +1397,6 @@ void pm_runtime_remove(struct device *dev)
 	if (dev->power.irq_safe && dev->parent)
 		pm_runtime_put(dev->parent);
 }
-#endif
 
 /**
  * pm_runtime_force_suspend - Force a device into suspend state if needed.
@@ -1419,12 +1416,6 @@ int pm_runtime_force_suspend(struct device *dev)
 	int ret = 0;
 
 	pm_runtime_disable(dev);
-
-	/*
-	 * Note that pm_runtime_status_suspended() returns false while
-	 * !CONFIG_PM_RUNTIME, which means the device will be put into low
-	 * power state.
-	 */
 	if (pm_runtime_status_suspended(dev))
 		return 0;
 

commit dbcd2d7253009977d52d6c1cf50e0a2452dee4a8
Author: Andrzej Hajda <a.hajda@samsung.com>
Date:   Fri Oct 17 12:58:02 2014 +0200

    PM / Runtime: Rework RPM get callback routines
    
    PM uses three separate functions to fetch RPM callbacks.
    These functions uses quite complicated macro in their body.
    The patch replaces these routines with one small macro and
    one helper function.
    
    Signed-off-by: Andrzej Hajda <a.hajda@samsung.com>
    Acked-by: Pavel Machek <pavel@ucw.cz>
    Reviewed-by: Ulf Hansson <ulf.hansson@linaro.org>
    Acked-by: Kevin Hilman <khilman@linaro.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 67c7938e430b..8f1ab8446caa 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -13,42 +13,39 @@
 #include <trace/events/rpm.h>
 #include "power.h"
 
-#define RPM_GET_CALLBACK(dev, cb)				\
-({								\
-	int (*__rpm_cb)(struct device *__d);			\
-								\
-	if (dev->pm_domain)					\
-		__rpm_cb = dev->pm_domain->ops.cb;		\
-	else if (dev->type && dev->type->pm)			\
-		__rpm_cb = dev->type->pm->cb;			\
-	else if (dev->class && dev->class->pm)			\
-		__rpm_cb = dev->class->pm->cb;			\
-	else if (dev->bus && dev->bus->pm)			\
-		__rpm_cb = dev->bus->pm->cb;			\
-	else							\
-		__rpm_cb = NULL;				\
-								\
-	if (!__rpm_cb && dev->driver && dev->driver->pm)	\
-		__rpm_cb = dev->driver->pm->cb;			\
-								\
-	__rpm_cb;						\
-})
-
-static int (*rpm_get_suspend_cb(struct device *dev))(struct device *)
-{
-	return RPM_GET_CALLBACK(dev, runtime_suspend);
-}
+typedef int (*pm_callback_t)(struct device *);
 
-static int (*rpm_get_resume_cb(struct device *dev))(struct device *)
+static pm_callback_t __rpm_get_callback(struct device *dev, size_t cb_offset)
 {
-	return RPM_GET_CALLBACK(dev, runtime_resume);
+	pm_callback_t cb;
+	const struct dev_pm_ops *ops;
+
+	if (dev->pm_domain)
+		ops = &dev->pm_domain->ops;
+	else if (dev->type && dev->type->pm)
+		ops = dev->type->pm;
+	else if (dev->class && dev->class->pm)
+		ops = dev->class->pm;
+	else if (dev->bus && dev->bus->pm)
+		ops = dev->bus->pm;
+	else
+		ops = NULL;
+
+	if (ops)
+		cb = *(pm_callback_t *)((void *)ops + cb_offset);
+	else
+		cb = NULL;
+
+	if (!cb && dev->driver && dev->driver->pm)
+		cb = *(pm_callback_t *)((void *)dev->driver->pm + cb_offset);
+
+	return cb;
 }
 
+#define RPM_GET_CALLBACK(dev, callback) \
+		__rpm_get_callback(dev, offsetof(struct dev_pm_ops, callback))
+
 #ifdef CONFIG_PM_RUNTIME
-static int (*rpm_get_idle_cb(struct device *dev))(struct device *)
-{
-	return RPM_GET_CALLBACK(dev, runtime_idle);
-}
 
 static int rpm_resume(struct device *dev, int rpmflags);
 static int rpm_suspend(struct device *dev, int rpmflags);
@@ -347,7 +344,7 @@ static int rpm_idle(struct device *dev, int rpmflags)
 
 	dev->power.idle_notification = true;
 
-	callback = rpm_get_idle_cb(dev);
+	callback = RPM_GET_CALLBACK(dev, runtime_idle);
 
 	if (callback)
 		retval = __rpm_callback(callback, dev);
@@ -517,7 +514,7 @@ static int rpm_suspend(struct device *dev, int rpmflags)
 
 	__update_runtime_status(dev, RPM_SUSPENDING);
 
-	callback = rpm_get_suspend_cb(dev);
+	callback = RPM_GET_CALLBACK(dev, runtime_suspend);
 
 	retval = rpm_callback(callback, dev);
 	if (retval)
@@ -737,7 +734,7 @@ static int rpm_resume(struct device *dev, int rpmflags)
 
 	__update_runtime_status(dev, RPM_RESUMING);
 
-	callback = rpm_get_resume_cb(dev);
+	callback = RPM_GET_CALLBACK(dev, runtime_resume);
 
 	retval = rpm_callback(callback, dev);
 	if (retval) {
@@ -1431,7 +1428,7 @@ int pm_runtime_force_suspend(struct device *dev)
 	if (pm_runtime_status_suspended(dev))
 		return 0;
 
-	callback = rpm_get_suspend_cb(dev);
+	callback = RPM_GET_CALLBACK(dev, runtime_suspend);
 
 	if (!callback) {
 		ret = -ENOSYS;
@@ -1467,7 +1464,7 @@ int pm_runtime_force_resume(struct device *dev)
 	int (*callback)(struct device *);
 	int ret = 0;
 
-	callback = rpm_get_resume_cb(dev);
+	callback = RPM_GET_CALLBACK(dev, runtime_resume);
 
 	if (!callback) {
 		ret = -ENOSYS;

commit 36cc86e8ec1a0ab309052bc9b25e48a31288b8a5
Merge: 165f5fd04aa8 651665dbfdfc 33fe0ad946bb
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Thu Mar 20 13:25:54 2014 +0100

    Merge branches 'pm-runtime' and 'pm-sleep'
    
    * pm-runtime:
      PM / Runtime: Update runtime_idle() documentation for return value meaning
    
    * pm-sleep:
      PM / sleep: Correct whitespace errors in <linux/pm.h>
      PM: Add missing "freeze" state
      PM / Hibernate: Spelling s/anonymouns/anonymous/
      PM / Runtime: Add missing "it" in comment
      PM / suspend: Remove unnecessary !!
      PCI / PM: Resume runtime-suspended devices later during system suspend
      ACPI / PM: Resume runtime-suspended devices later during system suspend
      PM / sleep: Set pm_generic functions to NULL for !CONFIG_PM_SLEEP
      PM: fix typo in comment
      PM / hibernate: use name_to_dev_t to parse resume
      PM / wakeup: Include appropriate header file in kernel/power/wakelock.c
      PM / sleep: Move prototype declaration to header file kernel/power/power.h
      PM / sleep: Asynchronous threads for suspend_late
      PM / sleep: Asynchronous threads for suspend_noirq
      PM / sleep: Asynchronous threads for resume_early
      PM / sleep: Asynchronous threads for resume_noirq
      PM / sleep: Two flags for async suspend_noirq and suspend_late

commit 7b60894ff8c5c67ff1caaf89173c3aa5cf57311e
Author: Geert Uytterhoeven <geert+renesas@linux-m68k.org>
Date:   Tue Mar 11 11:23:40 2014 +0100

    PM / Runtime: Add missing "it" in comment
    
    Signed-off-by: Geert Uytterhoeven <geert+renesas@linux-m68k.org>
    Acked-by: Pavel Machek <pavel@ucw.cz>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 72e00e66ecc5..19224883ca8b 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -1130,7 +1130,7 @@ EXPORT_SYMBOL_GPL(pm_runtime_barrier);
  * @dev: Device to handle.
  * @check_resume: If set, check if there's a resume request for the device.
  *
- * Increment power.disable_depth for the device and if was zero previously,
+ * Increment power.disable_depth for the device and if it was zero previously,
  * cancel all pending runtime PM requests for the device and wait for all
  * operations in progress to complete.  The device can be either active or
  * suspended after its runtime PM has been disabled.

commit 37f204164dfb0186a0caf20bc3e3120080bcd788
Author: Ulf Hansson <ulf.hansson@linaro.org>
Date:   Sat Mar 1 11:56:05 2014 +0100

    PM: Add pm_runtime_suspend|resume_force functions
    
    This patch provides two new runtime PM helper functions which intend to
    be used from system suspend/resume callbacks, to make sure devices are
    put into low power state during system suspend and brought back to full
    power at system resume.
    
    The prerequisite is to have all levels of a device's runtime PM
    callbacks to be defined through the SET_PM_RUNTIME_PM_OPS macro, which
    means these are available for CONFIG_PM.
    
    By using the new runtime PM helper functions especially the two
    scenarios below will be addressed.
    
    1) The PM core prevents .runtime_suspend callbacks from being invoked
    during system suspend. That means even for a runtime PM centric
    subsystem and driver, the device needs to be put into low power state
    from a system suspend callback. Otherwise it may very well be left in
    full power state (runtime resumed) while the system is suspended. By
    using the new helper functions, we make sure to walk the hierarchy of
    a device's power domain, subsystem and driver.
    
    2) Subsystems and drivers need to cope with all the combinations of
    CONFIG_PM_SLEEP and CONFIG_PM_RUNTIME. The two new helper functions
    smothly addresses this.
    
    Signed-off-by: Ulf Hansson <ulf.hansson@linaro.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index ac495b1357fa..4776cf528d08 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -44,6 +44,7 @@ static int (*rpm_get_resume_cb(struct device *dev))(struct device *)
 	return RPM_GET_CALLBACK(dev, runtime_resume);
 }
 
+#ifdef CONFIG_PM_RUNTIME
 static int (*rpm_get_idle_cb(struct device *dev))(struct device *)
 {
 	return RPM_GET_CALLBACK(dev, runtime_idle);
@@ -1401,3 +1402,86 @@ void pm_runtime_remove(struct device *dev)
 	if (dev->power.irq_safe && dev->parent)
 		pm_runtime_put(dev->parent);
 }
+#endif
+
+/**
+ * pm_runtime_force_suspend - Force a device into suspend state if needed.
+ * @dev: Device to suspend.
+ *
+ * Disable runtime PM so we safely can check the device's runtime PM status and
+ * if it is active, invoke it's .runtime_suspend callback to bring it into
+ * suspend state. Keep runtime PM disabled to preserve the state unless we
+ * encounter errors.
+ *
+ * Typically this function may be invoked from a system suspend callback to make
+ * sure the device is put into low power state.
+ */
+int pm_runtime_force_suspend(struct device *dev)
+{
+	int (*callback)(struct device *);
+	int ret = 0;
+
+	pm_runtime_disable(dev);
+
+	/*
+	 * Note that pm_runtime_status_suspended() returns false while
+	 * !CONFIG_PM_RUNTIME, which means the device will be put into low
+	 * power state.
+	 */
+	if (pm_runtime_status_suspended(dev))
+		return 0;
+
+	callback = rpm_get_suspend_cb(dev);
+
+	if (!callback) {
+		ret = -ENOSYS;
+		goto err;
+	}
+
+	ret = callback(dev);
+	if (ret)
+		goto err;
+
+	pm_runtime_set_suspended(dev);
+	return 0;
+err:
+	pm_runtime_enable(dev);
+	return ret;
+}
+EXPORT_SYMBOL_GPL(pm_runtime_force_suspend);
+
+/**
+ * pm_runtime_force_resume - Force a device into resume state.
+ * @dev: Device to resume.
+ *
+ * Prior invoking this function we expect the user to have brought the device
+ * into low power state by a call to pm_runtime_force_suspend(). Here we reverse
+ * those actions and brings the device into full power. We update the runtime PM
+ * status and re-enables runtime PM.
+ *
+ * Typically this function may be invoked from a system resume callback to make
+ * sure the device is put into full power state.
+ */
+int pm_runtime_force_resume(struct device *dev)
+{
+	int (*callback)(struct device *);
+	int ret = 0;
+
+	callback = rpm_get_resume_cb(dev);
+
+	if (!callback) {
+		ret = -ENOSYS;
+		goto out;
+	}
+
+	ret = callback(dev);
+	if (ret)
+		goto out;
+
+	pm_runtime_set_active(dev);
+	pm_runtime_mark_last_busy(dev);
+out:
+	pm_runtime_enable(dev);
+	return ret;
+}
+EXPORT_SYMBOL_GPL(pm_runtime_force_resume);

commit 5f59df79837bb809f3945613aba5519cd9755a53
Author: Ulf Hansson <ulf.hansson@linaro.org>
Date:   Sat Mar 1 11:56:04 2014 +0100

    PM / runtime: Fetch runtime PM callbacks using a macro
    
    While fetching the proper runtime PM callback, we walk the hierarchy of
    device's power domains, subsystems and drivers.
    
    This is common for rpm_suspend(), rpm_idle() and rpm_resume(). Let's
    clean up the code by using a macro that handles this.
    
    Signed-off-by: Ulf Hansson <ulf.hansson@linaro.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 72e00e66ecc5..ac495b1357fa 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -13,6 +13,42 @@
 #include <trace/events/rpm.h>
 #include "power.h"
 
+#define RPM_GET_CALLBACK(dev, cb)				\
+({								\
+	int (*__rpm_cb)(struct device *__d);			\
+								\
+	if (dev->pm_domain)					\
+		__rpm_cb = dev->pm_domain->ops.cb;		\
+	else if (dev->type && dev->type->pm)			\
+		__rpm_cb = dev->type->pm->cb;			\
+	else if (dev->class && dev->class->pm)			\
+		__rpm_cb = dev->class->pm->cb;			\
+	else if (dev->bus && dev->bus->pm)			\
+		__rpm_cb = dev->bus->pm->cb;			\
+	else							\
+		__rpm_cb = NULL;				\
+								\
+	if (!__rpm_cb && dev->driver && dev->driver->pm)	\
+		__rpm_cb = dev->driver->pm->cb;			\
+								\
+	__rpm_cb;						\
+})
+
+static int (*rpm_get_suspend_cb(struct device *dev))(struct device *)
+{
+	return RPM_GET_CALLBACK(dev, runtime_suspend);
+}
+
+static int (*rpm_get_resume_cb(struct device *dev))(struct device *)
+{
+	return RPM_GET_CALLBACK(dev, runtime_resume);
+}
+
+static int (*rpm_get_idle_cb(struct device *dev))(struct device *)
+{
+	return RPM_GET_CALLBACK(dev, runtime_idle);
+}
+
 static int rpm_resume(struct device *dev, int rpmflags);
 static int rpm_suspend(struct device *dev, int rpmflags);
 
@@ -310,19 +346,7 @@ static int rpm_idle(struct device *dev, int rpmflags)
 
 	dev->power.idle_notification = true;
 
-	if (dev->pm_domain)
-		callback = dev->pm_domain->ops.runtime_idle;
-	else if (dev->type && dev->type->pm)
-		callback = dev->type->pm->runtime_idle;
-	else if (dev->class && dev->class->pm)
-		callback = dev->class->pm->runtime_idle;
-	else if (dev->bus && dev->bus->pm)
-		callback = dev->bus->pm->runtime_idle;
-	else
-		callback = NULL;
-
-	if (!callback && dev->driver && dev->driver->pm)
-		callback = dev->driver->pm->runtime_idle;
+	callback = rpm_get_idle_cb(dev);
 
 	if (callback)
 		retval = __rpm_callback(callback, dev);
@@ -492,19 +516,7 @@ static int rpm_suspend(struct device *dev, int rpmflags)
 
 	__update_runtime_status(dev, RPM_SUSPENDING);
 
-	if (dev->pm_domain)
-		callback = dev->pm_domain->ops.runtime_suspend;
-	else if (dev->type && dev->type->pm)
-		callback = dev->type->pm->runtime_suspend;
-	else if (dev->class && dev->class->pm)
-		callback = dev->class->pm->runtime_suspend;
-	else if (dev->bus && dev->bus->pm)
-		callback = dev->bus->pm->runtime_suspend;
-	else
-		callback = NULL;
-
-	if (!callback && dev->driver && dev->driver->pm)
-		callback = dev->driver->pm->runtime_suspend;
+	callback = rpm_get_suspend_cb(dev);
 
 	retval = rpm_callback(callback, dev);
 	if (retval)
@@ -724,19 +736,7 @@ static int rpm_resume(struct device *dev, int rpmflags)
 
 	__update_runtime_status(dev, RPM_RESUMING);
 
-	if (dev->pm_domain)
-		callback = dev->pm_domain->ops.runtime_resume;
-	else if (dev->type && dev->type->pm)
-		callback = dev->type->pm->runtime_resume;
-	else if (dev->class && dev->class->pm)
-		callback = dev->class->pm->runtime_resume;
-	else if (dev->bus && dev->bus->pm)
-		callback = dev->bus->pm->runtime_resume;
-	else
-		callback = NULL;
-
-	if (!callback && dev->driver && dev->driver->pm)
-		callback = dev->driver->pm->runtime_resume;
+	callback = rpm_get_resume_cb(dev);
 
 	retval = rpm_callback(callback, dev);
 	if (retval) {

commit d66e6db28df330c0e5b61f9863754fc2fd37f8ca
Author: Ulf Hansson <ulf.hansson@linaro.org>
Date:   Tue Oct 15 22:25:08 2013 +0200

    PM / Runtime: Respect autosuspend when idle triggers suspend
    
    For devices which don't have a .runtime_idle() callback or if it
    returns 0, rpm_idle() will end up in triggering a call to
    rpm_suspend(), thus trying to carry out a runtime suspend directly
    from runtime_idle().
    
    In the above situation we want to respect devices which has enabled
    autosuspend, we therfore append the flag sent to rpm_suspend with
    RPM_AUTO.
    
    Do note that drivers still needs to update the device last busy mark,
    to control the delay for this circumstance.
    
    Updated runtime PM documentation accordingly.
    
    Signed-off-by: Ulf Hansson <ulf.hansson@linaro.org>
    Acked-by: Kevin Hilman <khilman@linaro.org>
    Acked-by: Alan Stern <stern@rowland.harvard.edu>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 268a35097578..72e00e66ecc5 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -258,7 +258,8 @@ static int __rpm_callback(int (*cb)(struct device *), struct device *dev)
  * Check if the device's runtime PM status allows it to be suspended.  If
  * another idle notification has been started earlier, return immediately.  If
  * the RPM_ASYNC flag is set then queue an idle-notification request; otherwise
- * run the ->runtime_idle() callback directly.
+ * run the ->runtime_idle() callback directly. If the ->runtime_idle callback
+ * doesn't exist or if it returns 0, call rpm_suspend with the RPM_AUTO flag.
  *
  * This function must be called under dev->power.lock with interrupts disabled.
  */
@@ -331,7 +332,7 @@ static int rpm_idle(struct device *dev, int rpmflags)
 
  out:
 	trace_rpm_return_int(dev, _THIS_IP_, retval);
-	return retval ? retval : rpm_suspend(dev, rpmflags);
+	return retval ? retval : rpm_suspend(dev, rpmflags | RPM_AUTO);
 }
 
 /**

commit 45f0a85c8258741d11bda25c0a5669c06267204a
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Mon Jun 3 21:49:52 2013 +0200

    PM / Runtime: Rework the "runtime idle" helper routine
    
    The "runtime idle" helper routine, rpm_idle(), currently ignores
    return values from .runtime_idle() callbacks executed by it.
    However, it turns out that many subsystems use
    pm_generic_runtime_idle() which checks the return value of the
    driver's callback and executes pm_runtime_suspend() for the device
    unless that value is not 0.  If that logic is moved to rpm_idle()
    instead, pm_generic_runtime_idle() can be dropped and its users
    will not need any .runtime_idle() callbacks any more.
    
    Moreover, the PCI, SCSI, and SATA subsystems' .runtime_idle()
    routines, pci_pm_runtime_idle(), scsi_runtime_idle(), and
    ata_port_runtime_idle(), respectively, as well as a few drivers'
    ones may be simplified if rpm_idle() calls rpm_suspend() after 0 has
    been returned by the .runtime_idle() callback executed by it.
    
    To reduce overall code bloat, make the changes described above.
    
    Tested-by: Mika Westerberg <mika.westerberg@linux.intel.com>
    Tested-by: Kevin Hilman <khilman@linaro.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Acked-by: Kevin Hilman <khilman@linaro.org>
    Reviewed-by: Ulf Hansson <ulf.hansson@linaro.org>
    Acked-by: Alan Stern <stern@rowland.harvard.edu>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index ef13ad08afb2..268a35097578 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -293,11 +293,8 @@ static int rpm_idle(struct device *dev, int rpmflags)
 	/* Pending requests need to be canceled. */
 	dev->power.request = RPM_REQ_NONE;
 
-	if (dev->power.no_callbacks) {
-		/* Assume ->runtime_idle() callback would have suspended. */
-		retval = rpm_suspend(dev, rpmflags);
+	if (dev->power.no_callbacks)
 		goto out;
-	}
 
 	/* Carry out an asynchronous or a synchronous idle notification. */
 	if (rpmflags & RPM_ASYNC) {
@@ -306,7 +303,8 @@ static int rpm_idle(struct device *dev, int rpmflags)
 			dev->power.request_pending = true;
 			queue_work(pm_wq, &dev->power.work);
 		}
-		goto out;
+		trace_rpm_return_int(dev, _THIS_IP_, 0);
+		return 0;
 	}
 
 	dev->power.idle_notification = true;
@@ -326,14 +324,14 @@ static int rpm_idle(struct device *dev, int rpmflags)
 		callback = dev->driver->pm->runtime_idle;
 
 	if (callback)
-		__rpm_callback(callback, dev);
+		retval = __rpm_callback(callback, dev);
 
 	dev->power.idle_notification = false;
 	wake_up_all(&dev->power.wait_queue);
 
  out:
 	trace_rpm_return_int(dev, _THIS_IP_, retval);
-	return retval;
+	return retval ? retval : rpm_suspend(dev, rpmflags);
 }
 
 /**

commit db28dfac99983e70b5a93b6c81c43d2c74fde20d
Author: Ulf Hansson <ulf.hansson@linaro.org>
Date:   Fri Apr 12 09:41:30 2013 +0000

    PM / Runtime: Asyncronous idle|suspend parent devices at removal
    
    For irq safe devices return the runtime reference for the parent
    by using the asyncronous runtime PM API. Thus we don't have to
    wait for it to become idle|suspended. Instead we can move on and
    handle the next device in queue.
    
    Signed-off-by: Ulf Hansson <ulf.hansson@linaro.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 1244930e3d7a..ef13ad08afb2 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -1400,5 +1400,5 @@ void pm_runtime_remove(struct device *dev)
 	if (dev->power.runtime_status == RPM_ACTIVE)
 		pm_runtime_set_suspended(dev);
 	if (dev->power.irq_safe && dev->parent)
-		pm_runtime_put_sync(dev->parent);
+		pm_runtime_put(dev->parent);
 }

commit db88175f41a29c1ffff1a6938a7969d206a47326
Author: Ming Lei <ming.lei@canonical.com>
Date:   Fri Feb 22 16:34:19 2013 -0800

    pm / runtime: force memory allocation with no I/O during Runtime PM callbcack
    
    Apply the introduced memalloc_noio_save() and memalloc_noio_restore() to
    force memory allocation with no I/O during runtime_resume/runtime_suspend
    callback on device with the flag of 'memalloc_noio' set.
    
    Signed-off-by: Ming Lei <ming.lei@canonical.com>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Eric Dumazet <eric.dumazet@gmail.com>
    Cc: David Decotigny <david.decotigny@google.com>
    Cc: Tom Herbert <therbert@google.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Minchan Kim <minchan@kernel.org>
    Cc: Alan Stern <stern@rowland.harvard.edu>
    Cc: Oliver Neukum <oneukum@suse.de>
    Cc: Jiri Kosina <jiri.kosina@suse.com>
    Cc: Mel Gorman <mel@csn.ul.ie>
    Cc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: Michal Hocko <mhocko@suse.cz>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: "Rafael J. Wysocki" <rjw@sisk.pl>
    Cc: Greg KH <greg@kroah.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index cd92e1c77cb7..1244930e3d7a 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -348,7 +348,24 @@ static int rpm_callback(int (*cb)(struct device *), struct device *dev)
 	if (!cb)
 		return -ENOSYS;
 
-	retval = __rpm_callback(cb, dev);
+	if (dev->power.memalloc_noio) {
+		unsigned int noio_flag;
+
+		/*
+		 * Deadlock might be caused if memory allocation with
+		 * GFP_KERNEL happens inside runtime_suspend and
+		 * runtime_resume callbacks of one block device's
+		 * ancestor or the block device itself. Network
+		 * device might be thought as part of iSCSI block
+		 * device, so network device and its ancestor should
+		 * be marked as memalloc_noio too.
+		 */
+		noio_flag = memalloc_noio_save();
+		retval = __rpm_callback(cb, dev);
+		memalloc_noio_restore(noio_flag);
+	} else {
+		retval = __rpm_callback(cb, dev);
+	}
 
 	dev->power.runtime_error = retval;
 	return retval != -EACCES ? retval : -EIO;

commit e823407f7b11fa06ba8e7a2801eb9ed11268a7ec
Author: Ming Lei <ming.lei@canonical.com>
Date:   Fri Feb 22 16:34:11 2013 -0800

    pm / runtime: introduce pm_runtime_set_memalloc_noio()
    
    Introduce the flag memalloc_noio in 'struct dev_pm_info' to help PM core
    to teach mm not allocating memory with GFP_KERNEL flag for avoiding
    probable deadlock.
    
    As explained in the comment, any GFP_KERNEL allocation inside
    runtime_resume() or runtime_suspend() on any one of device in the path
    from one block or network device to the root device in the device tree
    may cause deadlock, the introduced pm_runtime_set_memalloc_noio() sets
    or clears the flag on device in the path recursively.
    
    Signed-off-by: Ming Lei <ming.lei@canonical.com>
    Cc: Minchan Kim <minchan@kernel.org>
    Cc: Alan Stern <stern@rowland.harvard.edu>
    Cc: Oliver Neukum <oneukum@suse.de>
    Cc: Jiri Kosina <jiri.kosina@suse.com>
    Cc: Mel Gorman <mel@csn.ul.ie>
    Cc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: Michal Hocko <mhocko@suse.cz>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: "Rafael J. Wysocki" <rjw@sisk.pl>
    Cc: Greg KH <greg@kroah.com>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Eric Dumazet <eric.dumazet@gmail.com>
    Cc: David Decotigny <david.decotigny@google.com>
    Cc: Tom Herbert <therbert@google.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 3148b10dc2e5..cd92e1c77cb7 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -124,6 +124,76 @@ unsigned long pm_runtime_autosuspend_expiration(struct device *dev)
 }
 EXPORT_SYMBOL_GPL(pm_runtime_autosuspend_expiration);
 
+static int dev_memalloc_noio(struct device *dev, void *data)
+{
+	return dev->power.memalloc_noio;
+}
+
+/*
+ * pm_runtime_set_memalloc_noio - Set a device's memalloc_noio flag.
+ * @dev: Device to handle.
+ * @enable: True for setting the flag and False for clearing the flag.
+ *
+ * Set the flag for all devices in the path from the device to the
+ * root device in the device tree if @enable is true, otherwise clear
+ * the flag for devices in the path whose siblings don't set the flag.
+ *
+ * The function should only be called by block device, or network
+ * device driver for solving the deadlock problem during runtime
+ * resume/suspend:
+ *
+ *     If memory allocation with GFP_KERNEL is called inside runtime
+ *     resume/suspend callback of any one of its ancestors(or the
+ *     block device itself), the deadlock may be triggered inside the
+ *     memory allocation since it might not complete until the block
+ *     device becomes active and the involed page I/O finishes. The
+ *     situation is pointed out first by Alan Stern. Network device
+ *     are involved in iSCSI kind of situation.
+ *
+ * The lock of dev_hotplug_mutex is held in the function for handling
+ * hotplug race because pm_runtime_set_memalloc_noio() may be called
+ * in async probe().
+ *
+ * The function should be called between device_add() and device_del()
+ * on the affected device(block/network device).
+ */
+void pm_runtime_set_memalloc_noio(struct device *dev, bool enable)
+{
+	static DEFINE_MUTEX(dev_hotplug_mutex);
+
+	mutex_lock(&dev_hotplug_mutex);
+	for (;;) {
+		bool enabled;
+
+		/* hold power lock since bitfield is not SMP-safe. */
+		spin_lock_irq(&dev->power.lock);
+		enabled = dev->power.memalloc_noio;
+		dev->power.memalloc_noio = enable;
+		spin_unlock_irq(&dev->power.lock);
+
+		/*
+		 * not need to enable ancestors any more if the device
+		 * has been enabled.
+		 */
+		if (enabled && enable)
+			break;
+
+		dev = dev->parent;
+
+		/*
+		 * clear flag of the parent device only if all the
+		 * children don't set the flag because ancestor's
+		 * flag was set by any one of the descendants.
+		 */
+		if (!dev || (!enable &&
+			     device_for_each_child(dev, NULL,
+						   dev_memalloc_noio)))
+			break;
+	}
+	mutex_unlock(&dev_hotplug_mutex);
+}
+EXPORT_SYMBOL_GPL(pm_runtime_set_memalloc_noio);
+
 /**
  * rpm_check_suspend_allowed - Test whether a device may be suspended.
  * @dev: Device to test.

commit 6f3c77b040fc24708228607bba504878de5236d1
Author: Kevin Hilman <khilman@ti.com>
Date:   Fri Sep 21 22:47:34 2012 +0000

    PM / Runtime: let rpm_resume() succeed if RPM_ACTIVE, even when disabled, v2
    
    There are several drivers where the return value of
    pm_runtime_get_sync() is used to decide whether or not it is safe to
    access hardware and that don't provide .suspend() callbacks for system
    suspend (but may use late/noirq callbacks.)  If such a driver happens
    to call pm_runtime_get_sync() during system suspend, after the core
    has disabled runtime PM, it will get the error code and will decide
    that the hardware should not be accessed, although this may be a wrong
    conclusion, depending on the state of the device when runtime PM was
    disabled.
    
    Drivers might work around this problem by using a test like:
    
       ret = pm_runtime_get_sync(dev);
       if (!ret || (ret == -EACCES && driver_private_data(dev)->suspended)) {
          /* access hardware */
       }
    
    where driver_private_data(dev)->suspended is a flag set by the
    driver's .suspend() method (that would have to be added for this
    purpose).  However, that potentially would need to be done by multiple
    drivers which means quite a lot of duplicated code and bloat.
    
    To avoid that we can use the observation that the core sets
    dev->power.is_suspended before disabling runtime PM and use that
    instead of the driver's private flag.  Still, potentially many drivers
    would need to repeat that same check in quite a few places, so it's
    better to let the core do it.
    
    Then we can be a bit smarter and check whether or not runtime PM was
    disabled by the core only (disable_depth == 1) or by someone else in
    addition to the core (disable_depth > 1).  In the former case
    rpm_resume() can return 1 if the runtime PM status is RPM_ACTIVE,
    because it means the device was active when the core disabled runtime
    PM.  In the latter case it should still return -EACCES, because it
    isn't clear why runtime PM has been disabled.
    
    Tested on AM3730/Beagle-xM where a wakeup IRQ firing during the late
    suspend phase triggers runtime PM activity in the I2C driver since the
    wakeup IRQ is on an I2C-connected PMIC.
    
    [rjw: Modified whitespace to follow the file's convention.]
    
    Signed-off-by: Kevin Hilman <khilman@ti.com>
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 7d9c1cb1c39a..3148b10dc2e5 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -509,6 +509,9 @@ static int rpm_resume(struct device *dev, int rpmflags)
  repeat:
 	if (dev->power.runtime_error)
 		retval = -EINVAL;
+	else if (dev->power.disable_depth == 1 && dev->power.is_suspended
+	    && dev->power.runtime_status == RPM_ACTIVE)
+		retval = 1;
 	else if (dev->power.disable_depth > 0)
 		retval = -EACCES;
 	if (retval)

commit 55d7ec4520e86d735d178c15d7df33d507bd43c6
Author: Rafael J. Wysocki <rjw@sisk.pl>
Date:   Wed Aug 15 21:32:04 2012 +0200

    PM / Runtime: Check device PM QoS setting before "no callbacks" check
    
    If __dev_pm_qos_read_value(dev) returns a negative value,
    rpm_suspend() should return -EPERM for dev even if its
    power.no_callbacks flag is set.  For this to happen, the device's
    power.no_callbacks flag has to be checked after the PM QoS check,
    so move the PM QoS check to rpm_check_suspend_allowed() (this will
    make it cover idle notifications as well as runtime suspend too).
    
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>
    Acked-by: Alan Stern <stern@rowland.harvard.edu>
    Cc: stable@vger.kernel.org

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index b6e9d9b7982d..7d9c1cb1c39a 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -147,6 +147,8 @@ static int rpm_check_suspend_allowed(struct device *dev)
 	    || (dev->power.request_pending
 			&& dev->power.request == RPM_REQ_RESUME))
 		retval = -EAGAIN;
+	else if (__dev_pm_qos_read_value(dev) < 0)
+		retval = -EPERM;
 	else if (dev->power.runtime_status == RPM_SUSPENDED)
 		retval = 1;
 
@@ -402,12 +404,6 @@ static int rpm_suspend(struct device *dev, int rpmflags)
 		goto out;
 	}
 
-	if (__dev_pm_qos_read_value(dev) < 0) {
-		/* Negative PM QoS constraint means "never suspend". */
-		retval = -EPERM;
-		goto out;
-	}
-
 	__update_runtime_status(dev, RPM_SUSPENDING);
 
 	if (dev->pm_domain)

commit 58a34de7b1a920d287d17d2ca08bc9aaf7e6d35b
Author: Rafael J. Wysocki <rjw@sisk.pl>
Date:   Wed Aug 15 21:31:55 2012 +0200

    PM / Runtime: Clear power.deferred_resume on success in rpm_suspend()
    
    The power.deferred_resume can only be set if the runtime PM status
    of device is RPM_SUSPENDING and it should be cleared after its
    status has been changed, regardless of whether or not the runtime
    suspend has been successful.  However, it only is cleared on
    suspend failure, while it may remain set on successful suspend and
    is happily leaked to rpm_resume() executed in that case.
    
    That shouldn't happen, so if power.deferred_resume is set in
    rpm_suspend() after the status has been changed to RPM_SUSPENDED,
    clear it before calling rpm_resume().  Then, it doesn't need to be
    cleared before changing the status to RPM_SUSPENDING any more,
    because it's always cleared after the status has been changed to
    either RPM_SUSPENDED (on success) or RPM_ACTIVE (on failure).
    
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>
    Acked-by: Alan Stern <stern@rowland.harvard.edu>
    Cc: stable@vger.kernel.org

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 9891a8559203..b6e9d9b7982d 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -388,7 +388,6 @@ static int rpm_suspend(struct device *dev, int rpmflags)
 		goto repeat;
 	}
 
-	dev->power.deferred_resume = false;
 	if (dev->power.no_callbacks)
 		goto no_callback;	/* Assume success. */
 
@@ -440,6 +439,7 @@ static int rpm_suspend(struct device *dev, int rpmflags)
 	wake_up_all(&dev->power.wait_queue);
 
 	if (dev->power.deferred_resume) {
+		dev->power.deferred_resume = false;
 		rpm_resume(dev, 0);
 		retval = -EAGAIN;
 		goto out;

commit 7f321c26c04807834fef4c524d2b21573423fc74
Author: Rafael J. Wysocki <rjw@sisk.pl>
Date:   Wed Aug 15 21:31:45 2012 +0200

    PM / Runtime: Fix rpm_resume() return value for power.no_callbacks set
    
    For devices whose power.no_callbacks flag is set, rpm_resume()
    should return 1 if the device's parent is already active, so that
    the callers of pm_runtime_get() don't think that they have to wait
    for the device to resume (asynchronously) in that case (the core
    won't queue up an asynchronous resume in that case, so there's
    nothing to wait for anyway).
    
    Modify the code accordingly (and make sure that an idle notification
    will be queued up on success, even if 1 is to be returned).
    
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>
    Acked-by: Alan Stern <stern@rowland.harvard.edu>
    Cc: stable@vger.kernel.org

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 59894873a3b3..9891a8559203 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -584,6 +584,7 @@ static int rpm_resume(struct device *dev, int rpmflags)
 		    || dev->parent->power.runtime_status == RPM_ACTIVE) {
 			atomic_inc(&dev->parent->power.child_count);
 			spin_unlock(&dev->parent->power.lock);
+			retval = 1;
 			goto no_callback;	/* Assume success. */
 		}
 		spin_unlock(&dev->parent->power.lock);
@@ -664,7 +665,7 @@ static int rpm_resume(struct device *dev, int rpmflags)
 	}
 	wake_up_all(&dev->power.wait_queue);
 
-	if (!retval)
+	if (retval >= 0)
 		rpm_idle(dev, RPM_ASYNC);
 
  out:

commit 76e267d822f2913893ad210ba431607aa8e2af94
Author: Rafael J. Wysocki <rjw@sisk.pl>
Date:   Sun Apr 29 22:54:36 2012 +0200

    PM / Runtime: Remove device fields related to suspend time, v2
    
    After the previous changes in default_stop_ok() and
    default_power_down_ok() for PM domains, there are two fields in
    struct dev_pm_info that aren't necessary any more,  suspend_time
    and max_time_suspended_ns.
    
    Remove those fields along with all of the code that accesses them,
    which simplifies the runtime PM framework quite a bit.
    
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index bd0f3949bcf9..59894873a3b3 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -282,47 +282,6 @@ static int rpm_callback(int (*cb)(struct device *), struct device *dev)
 	return retval != -EACCES ? retval : -EIO;
 }
 
-struct rpm_qos_data {
-	ktime_t time_now;
-	s64 constraint_ns;
-};
-
-/**
- * rpm_update_qos_constraint - Update a given PM QoS constraint data.
- * @dev: Device whose timing data to use.
- * @data: PM QoS constraint data to update.
- *
- * Use the suspend timing data of @dev to update PM QoS constraint data pointed
- * to by @data.
- */
-static int rpm_update_qos_constraint(struct device *dev, void *data)
-{
-	struct rpm_qos_data *qos = data;
-	unsigned long flags;
-	s64 delta_ns;
-	int ret = 0;
-
-	spin_lock_irqsave(&dev->power.lock, flags);
-
-	if (dev->power.max_time_suspended_ns < 0)
-		goto out;
-
-	delta_ns = dev->power.max_time_suspended_ns -
-		ktime_to_ns(ktime_sub(qos->time_now, dev->power.suspend_time));
-	if (delta_ns <= 0) {
-		ret = -EBUSY;
-		goto out;
-	}
-
-	if (qos->constraint_ns > delta_ns || qos->constraint_ns == 0)
-		qos->constraint_ns = delta_ns;
-
- out:
-	spin_unlock_irqrestore(&dev->power.lock, flags);
-
-	return ret;
-}
-
 /**
  * rpm_suspend - Carry out runtime suspend of given device.
  * @dev: Device to suspend.
@@ -349,7 +308,6 @@ static int rpm_suspend(struct device *dev, int rpmflags)
 {
 	int (*callback)(struct device *);
 	struct device *parent = NULL;
-	struct rpm_qos_data qos;
 	int retval;
 
 	trace_rpm_suspend(dev, rpmflags);
@@ -445,38 +403,14 @@ static int rpm_suspend(struct device *dev, int rpmflags)
 		goto out;
 	}
 
-	qos.constraint_ns = __dev_pm_qos_read_value(dev);
-	if (qos.constraint_ns < 0) {
-		/* Negative constraint means "never suspend". */
+	if (__dev_pm_qos_read_value(dev) < 0) {
+		/* Negative PM QoS constraint means "never suspend". */
 		retval = -EPERM;
 		goto out;
 	}
-	qos.constraint_ns *= NSEC_PER_USEC;
-	qos.time_now = ktime_get();
 
 	__update_runtime_status(dev, RPM_SUSPENDING);
 
-	if (!dev->power.ignore_children) {
-		if (dev->power.irq_safe)
-			spin_unlock(&dev->power.lock);
-		else
-			spin_unlock_irq(&dev->power.lock);
-
-		retval = device_for_each_child(dev, &qos,
-					       rpm_update_qos_constraint);
-
-		if (dev->power.irq_safe)
-			spin_lock(&dev->power.lock);
-		else
-			spin_lock_irq(&dev->power.lock);
-
-		if (retval)
-			goto fail;
-	}
-
-	dev->power.suspend_time = qos.time_now;
-	dev->power.max_time_suspended_ns = qos.constraint_ns ? : -1;
-
 	if (dev->pm_domain)
 		callback = dev->pm_domain->ops.runtime_suspend;
 	else if (dev->type && dev->type->pm)
@@ -529,8 +463,6 @@ static int rpm_suspend(struct device *dev, int rpmflags)
 
  fail:
 	__update_runtime_status(dev, RPM_ACTIVE);
-	dev->power.suspend_time = ktime_set(0, 0);
-	dev->power.max_time_suspended_ns = -1;
 	dev->power.deferred_resume = false;
 	wake_up_all(&dev->power.wait_queue);
 
@@ -704,9 +636,6 @@ static int rpm_resume(struct device *dev, int rpmflags)
 	if (dev->power.no_callbacks)
 		goto no_callback;	/* Assume success. */
 
-	dev->power.suspend_time = ktime_set(0, 0);
-	dev->power.max_time_suspended_ns = -1;
-
 	__update_runtime_status(dev, RPM_RESUMING);
 
 	if (dev->pm_domain)
@@ -1369,9 +1298,6 @@ void pm_runtime_init(struct device *dev)
 	setup_timer(&dev->power.suspend_timer, pm_suspend_timer_fn,
 			(unsigned long)dev);
 
-	dev->power.suspend_time = ktime_set(0, 0);
-	dev->power.max_time_suspended_ns = -1;
-
 	init_waitqueue_head(&dev->power.wait_queue);
 }
 
@@ -1389,28 +1315,3 @@ void pm_runtime_remove(struct device *dev)
 	if (dev->power.irq_safe && dev->parent)
 		pm_runtime_put_sync(dev->parent);
 }
-
-/**
- * pm_runtime_update_max_time_suspended - Update device's suspend time data.
- * @dev: Device to handle.
- * @delta_ns: Value to subtract from the device's max_time_suspended_ns field.
- *
- * Update the device's power.max_time_suspended_ns field by subtracting
- * @delta_ns from it.  The resulting value of power.max_time_suspended_ns is
- * never negative.
- */
-void pm_runtime_update_max_time_suspended(struct device *dev, s64 delta_ns)
-{
-	unsigned long flags;
-
-	spin_lock_irqsave(&dev->power.lock, flags);
-
-	if (delta_ns > 0 && dev->power.max_time_suspended_ns > 0) {
-		if (dev->power.max_time_suspended_ns > delta_ns)
-			dev->power.max_time_suspended_ns -= delta_ns;
-		else
-			dev->power.max_time_suspended_ns = 0;
-	}
-
-	spin_unlock_irqrestore(&dev->power.lock, flags);
-}

commit f2791d733a2f06997b573d1a3cfde21e6f529826
Author: Alan Stern <stern@rowland.harvard.edu>
Date:   Mon Mar 26 22:46:52 2012 +0200

    PM / Runtime: don't forget to wake up waitqueue on failure
    
    This patch (as1535) fixes a bug in the runtime PM core.  When a
    runtime suspend attempt completes, whether successfully or not, the
    device's power.wait_queue is supposed to be signalled.  But this
    doesn't happen in the failure pathway of rpm_suspend() when another
    autosuspend attempt is rescheduled.  As a result, a task can get stuck
    indefinitely on the wait queue (I have seen this happen in testing).
    
    The patch fixes the problem by moving the wake_up_all() call up near
    the start of the failure code.
    
    Signed-off-by: Alan Stern <stern@rowland.harvard.edu>
    CC: <stable@vger.kernel.org>
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 541f821d4ea6..bd0f3949bcf9 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -532,6 +532,8 @@ static int rpm_suspend(struct device *dev, int rpmflags)
 	dev->power.suspend_time = ktime_set(0, 0);
 	dev->power.max_time_suspended_ns = -1;
 	dev->power.deferred_resume = false;
+	wake_up_all(&dev->power.wait_queue);
+
 	if (retval == -EAGAIN || retval == -EBUSY) {
 		dev->power.runtime_error = 0;
 
@@ -547,7 +549,6 @@ static int rpm_suspend(struct device *dev, int rpmflags)
 	} else {
 		pm_runtime_cancel_pending(dev);
 	}
-	wake_up_all(&dev->power.wait_queue);
 	goto out;
 }
 

commit 0015afaa1f818d38ea9f8e81a84a6aeeca5fdaf0
Merge: b7ba68c4a072 00dc9ad18d70
Author: Rafael J. Wysocki <rjw@sisk.pl>
Date:   Sun Dec 25 23:43:05 2011 +0100

    Merge branch 'pm-runtime' into pm-for-linus
    
    * pm-runtime:
      PM / Runtime: Use device PM QoS constraints (v2)

commit 35cd133c6130c1eb52806808abee9d62e6854a27
Author: Rafael J. Wysocki <rjw@sisk.pl>
Date:   Sun Dec 18 00:34:13 2011 +0100

    PM: Run the driver callback directly if the subsystem one is not there
    
    Make the PM core execute driver PM callbacks directly if the
    corresponding subsystem callbacks are not present.
    
    There are three reasons for doing that.  First, it reflects the
    behavior of drivers/base/dd.c:really_probe() that runs the driver's
    .probe() callback directly if the bus type's one is not defined, so
    this change will remove one arbitrary difference between the PM core
    and the remaining parts of the driver core.  Second, it will allow
    some subsystems, whose PM callbacks don't do anything except for
    executing driver callbacks, to be simplified quite a bit by removing
    those "forward-only" callbacks.  Finally, it will allow us to remove
    one level of indirection in the system suspend and resume code paths
    where it is not necessary, which is going to lead to less debug noise
    with initcall_debug passed in the kernel command line (messages won't
    be printed for driverless devices whose subsystems don't provide
    PM callbacks among other things).
    
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 8c78443bca8f..c56efd756531 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -250,6 +250,9 @@ static int rpm_idle(struct device *dev, int rpmflags)
 	else
 		callback = NULL;
 
+	if (!callback && dev->driver && dev->driver->pm)
+		callback = dev->driver->pm->runtime_idle;
+
 	if (callback)
 		__rpm_callback(callback, dev);
 
@@ -413,6 +416,9 @@ static int rpm_suspend(struct device *dev, int rpmflags)
 	else
 		callback = NULL;
 
+	if (!callback && dev->driver && dev->driver->pm)
+		callback = dev->driver->pm->runtime_suspend;
+
 	retval = rpm_callback(callback, dev);
 	if (retval) {
 		__update_runtime_status(dev, RPM_ACTIVE);
@@ -633,6 +639,9 @@ static int rpm_resume(struct device *dev, int rpmflags)
 	else
 		callback = NULL;
 
+	if (!callback && dev->driver && dev->driver->pm)
+		callback = dev->driver->pm->runtime_resume;
+
 	retval = rpm_callback(callback, dev);
 	if (retval) {
 		__update_runtime_status(dev, RPM_SUSPENDED);

commit 00dc9ad18d707f36b2fb4af98fd2cf0548d2b258
Author: Rafael J. Wysocki <rjw@sisk.pl>
Date:   Thu Dec 1 00:01:31 2011 +0100

    PM / Runtime: Use device PM QoS constraints (v2)
    
    Make the runtime PM core use device PM QoS constraints to check if
    it is allowed to suspend a given device, so that an error code is
    returned if the device's own PM QoS constraint is negative or one of
    its children has already been suspended for too long.  If this is
    not the case, the maximum estimated time the device is allowed to be
    suspended, computed as the minimum of the device's PM QoS constraint
    and the PM QoS constraints of its children (reduced by the difference
    between the current time and their suspend times) is stored in a new
    device's PM field power.max_time_suspended_ns that can be used by
    the device's subsystem or PM domain to decide whether or not to put
    the device into lower-power (and presumably higher-latency) states
    later (if the constraint is 0, which means "no constraint", the
    power.max_time_suspended_ns is set to -1).
    
    Additionally, the time of execution of the subsystem-level
    .runtime_suspend() callback for the device is recorded in the new
    power.suspend_time field for later use by the device's subsystem or
    PM domain along with power.max_time_suspended_ns (it also is used
    by the core code when the device's parent is suspended).
    
    Introduce a new helper function,
    pm_runtime_update_max_time_suspended(), allowing subsystems and PM
    domains (or device drivers) to update the power.max_time_suspended_ns
    field, for example after changing the power state of a suspended
    device.
    
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 8c78443bca8f..068f7ed1f009 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -279,6 +279,47 @@ static int rpm_callback(int (*cb)(struct device *), struct device *dev)
 	return retval != -EACCES ? retval : -EIO;
 }
 
+struct rpm_qos_data {
+	ktime_t time_now;
+	s64 constraint_ns;
+};
+
+/**
+ * rpm_update_qos_constraint - Update a given PM QoS constraint data.
+ * @dev: Device whose timing data to use.
+ * @data: PM QoS constraint data to update.
+ *
+ * Use the suspend timing data of @dev to update PM QoS constraint data pointed
+ * to by @data.
+ */
+static int rpm_update_qos_constraint(struct device *dev, void *data)
+{
+	struct rpm_qos_data *qos = data;
+	unsigned long flags;
+	s64 delta_ns;
+	int ret = 0;
+
+	spin_lock_irqsave(&dev->power.lock, flags);
+
+	if (dev->power.max_time_suspended_ns < 0)
+		goto out;
+
+	delta_ns = dev->power.max_time_suspended_ns -
+		ktime_to_ns(ktime_sub(qos->time_now, dev->power.suspend_time));
+	if (delta_ns <= 0) {
+		ret = -EBUSY;
+		goto out;
+	}
+
+	if (qos->constraint_ns > delta_ns || qos->constraint_ns == 0)
+		qos->constraint_ns = delta_ns;
+
+ out:
+	spin_unlock_irqrestore(&dev->power.lock, flags);
+
+	return ret;
+}
+
 /**
  * rpm_suspend - Carry out runtime suspend of given device.
  * @dev: Device to suspend.
@@ -305,6 +346,7 @@ static int rpm_suspend(struct device *dev, int rpmflags)
 {
 	int (*callback)(struct device *);
 	struct device *parent = NULL;
+	struct rpm_qos_data qos;
 	int retval;
 
 	trace_rpm_suspend(dev, rpmflags);
@@ -400,8 +442,38 @@ static int rpm_suspend(struct device *dev, int rpmflags)
 		goto out;
 	}
 
+	qos.constraint_ns = __dev_pm_qos_read_value(dev);
+	if (qos.constraint_ns < 0) {
+		/* Negative constraint means "never suspend". */
+		retval = -EPERM;
+		goto out;
+	}
+	qos.constraint_ns *= NSEC_PER_USEC;
+	qos.time_now = ktime_get();
+
 	__update_runtime_status(dev, RPM_SUSPENDING);
 
+	if (!dev->power.ignore_children) {
+		if (dev->power.irq_safe)
+			spin_unlock(&dev->power.lock);
+		else
+			spin_unlock_irq(&dev->power.lock);
+
+		retval = device_for_each_child(dev, &qos,
+					       rpm_update_qos_constraint);
+
+		if (dev->power.irq_safe)
+			spin_lock(&dev->power.lock);
+		else
+			spin_lock_irq(&dev->power.lock);
+
+		if (retval)
+			goto fail;
+	}
+
+	dev->power.suspend_time = qos.time_now;
+	dev->power.max_time_suspended_ns = qos.constraint_ns ? : -1;
+
 	if (dev->pm_domain)
 		callback = dev->pm_domain->ops.runtime_suspend;
 	else if (dev->type && dev->type->pm)
@@ -414,27 +486,9 @@ static int rpm_suspend(struct device *dev, int rpmflags)
 		callback = NULL;
 
 	retval = rpm_callback(callback, dev);
-	if (retval) {
-		__update_runtime_status(dev, RPM_ACTIVE);
-		dev->power.deferred_resume = false;
-		if (retval == -EAGAIN || retval == -EBUSY) {
-			dev->power.runtime_error = 0;
+	if (retval)
+		goto fail;
 
-			/*
-			 * If the callback routine failed an autosuspend, and
-			 * if the last_busy time has been updated so that there
-			 * is a new autosuspend expiration time, automatically
-			 * reschedule another autosuspend.
-			 */
-			if ((rpmflags & RPM_AUTO) &&
-			    pm_runtime_autosuspend_expiration(dev) != 0)
-				goto repeat;
-		} else {
-			pm_runtime_cancel_pending(dev);
-		}
-		wake_up_all(&dev->power.wait_queue);
-		goto out;
-	}
  no_callback:
 	__update_runtime_status(dev, RPM_SUSPENDED);
 	pm_runtime_deactivate_timer(dev);
@@ -466,6 +520,29 @@ static int rpm_suspend(struct device *dev, int rpmflags)
 	trace_rpm_return_int(dev, _THIS_IP_, retval);
 
 	return retval;
+
+ fail:
+	__update_runtime_status(dev, RPM_ACTIVE);
+	dev->power.suspend_time = ktime_set(0, 0);
+	dev->power.max_time_suspended_ns = -1;
+	dev->power.deferred_resume = false;
+	if (retval == -EAGAIN || retval == -EBUSY) {
+		dev->power.runtime_error = 0;
+
+		/*
+		 * If the callback routine failed an autosuspend, and
+		 * if the last_busy time has been updated so that there
+		 * is a new autosuspend expiration time, automatically
+		 * reschedule another autosuspend.
+		 */
+		if ((rpmflags & RPM_AUTO) &&
+		    pm_runtime_autosuspend_expiration(dev) != 0)
+			goto repeat;
+	} else {
+		pm_runtime_cancel_pending(dev);
+	}
+	wake_up_all(&dev->power.wait_queue);
+	goto out;
 }
 
 /**
@@ -620,6 +697,9 @@ static int rpm_resume(struct device *dev, int rpmflags)
 	if (dev->power.no_callbacks)
 		goto no_callback;	/* Assume success. */
 
+	dev->power.suspend_time = ktime_set(0, 0);
+	dev->power.max_time_suspended_ns = -1;
+
 	__update_runtime_status(dev, RPM_RESUMING);
 
 	if (dev->pm_domain)
@@ -1279,6 +1359,9 @@ void pm_runtime_init(struct device *dev)
 	setup_timer(&dev->power.suspend_timer, pm_suspend_timer_fn,
 			(unsigned long)dev);
 
+	dev->power.suspend_time = ktime_set(0, 0);
+	dev->power.max_time_suspended_ns = -1;
+
 	init_waitqueue_head(&dev->power.wait_queue);
 }
 
@@ -1296,3 +1379,28 @@ void pm_runtime_remove(struct device *dev)
 	if (dev->power.irq_safe && dev->parent)
 		pm_runtime_put_sync(dev->parent);
 }
+
+/**
+ * pm_runtime_update_max_time_suspended - Update device's suspend time data.
+ * @dev: Device to handle.
+ * @delta_ns: Value to subtract from the device's max_time_suspended_ns field.
+ *
+ * Update the device's power.max_time_suspended_ns field by subtracting
+ * @delta_ns from it.  The resulting value of power.max_time_suspended_ns is
+ * never negative.
+ */
+void pm_runtime_update_max_time_suspended(struct device *dev, s64 delta_ns)
+{
+	unsigned long flags;
+
+	spin_lock_irqsave(&dev->power.lock, flags);
+
+	if (delta_ns > 0 && dev->power.max_time_suspended_ns > 0) {
+		if (dev->power.max_time_suspended_ns > delta_ns)
+			dev->power.max_time_suspended_ns -= delta_ns;
+		else
+			dev->power.max_time_suspended_ns = 0;
+	}
+
+	spin_unlock_irqrestore(&dev->power.lock, flags);
+}

commit 32aaeffbd4a7457bf2f7448b33b5946ff2a960eb
Merge: 208bca086040 67b84999b1a8
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sun Nov 6 19:44:47 2011 -0800

    Merge branch 'modsplit-Oct31_2011' of git://git.kernel.org/pub/scm/linux/kernel/git/paulg/linux
    
    * 'modsplit-Oct31_2011' of git://git.kernel.org/pub/scm/linux/kernel/git/paulg/linux: (230 commits)
      Revert "tracing: Include module.h in define_trace.h"
      irq: don't put module.h into irq.h for tracking irqgen modules.
      bluetooth: macroize two small inlines to avoid module.h
      ip_vs.h: fix implicit use of module_get/module_put from module.h
      nf_conntrack.h: fix up fallout from implicit moduleparam.h presence
      include: replace linux/module.h with "struct module" wherever possible
      include: convert various register fcns to macros to avoid include chaining
      crypto.h: remove unused crypto_tfm_alg_modname() inline
      uwb.h: fix implicit use of asm/page.h for PAGE_SIZE
      pm_runtime.h: explicitly requires notifier.h
      linux/dmaengine.h: fix implicit use of bitmap.h and asm/page.h
      miscdevice.h: fix up implicit use of lists and types
      stop_machine.h: fix implicit use of smp.h for smp_processor_id
      of: fix implicit use of errno.h in include/linux/of.h
      of_platform.h: delete needless include <linux/module.h>
      acpi: remove module.h include from platform/aclinux.h
      miscdevice.h: delete unnecessary inclusion of module.h
      device_cgroup.h: delete needless include <linux/module.h>
      net: sch_generic remove redundant use of <linux/module.h>
      net: inet_timewait_sock doesnt need <linux/module.h>
      ...
    
    Fix up trivial conflicts (other header files, and  removal of the ab3550 mfd driver) in
     - drivers/media/dvb/frontends/dibx000_common.c
     - drivers/media/video/{mt9m111.c,ov6650.c}
     - drivers/mfd/ab3550-core.c
     - include/linux/dmaengine.h

commit 886486b792e4f6f96d4fbe8ec5bf20811cab7d6a
Author: Alan Stern <stern@rowland.harvard.edu>
Date:   Thu Nov 3 23:39:18 2011 +0100

    PM / Runtime: Automatically retry failed autosuspends
    
    Originally, the runtime PM core would send an idle notification
    whenever a suspend attempt failed.  The idle callback routine could
    then schedule a delayed suspend for some time later.
    
    However this behavior was changed by commit
    f71648d73c1650b8b4aceb3856bebbde6daa3b86 (PM / Runtime: Remove idle
    notification after failing suspend).  No notifications were sent, and
    there was no clear mechanism to retry failed suspends.
    
    This caused problems for the usbhid driver, because it fails
    autosuspend attempts as long as a key is being held down.  Therefore
    this patch (as1492) adds a mechanism for retrying failed
    autosuspends.  If the callback routine updates the last_busy field so
    that the next autosuspend expiration time is in the future, the
    autosuspend will automatically be rescheduled.
    
    Signed-off-by: Alan Stern <stern@rowland.harvard.edu>
    Tested-by: Henrik Rydberg <rydberg@euromail.se>
    Cc: <stable@kernel.org>
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 18ef87e525fa..124dbf60c9bf 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -293,6 +293,9 @@ static int rpm_callback(int (*cb)(struct device *), struct device *dev)
  * the callback was running then carry it out, otherwise send an idle
  * notification for its parent (if the suspend succeeded and both
  * ignore_children of parent->power and irq_safe of dev->power are not set).
+ * If ->runtime_suspend failed with -EAGAIN or -EBUSY, and if the RPM_AUTO
+ * flag is set and the next autosuspend-delay expiration time is in the
+ * future, schedule another autosuspend attempt.
  *
  * This function must be called under dev->power.lock with interrupts disabled.
  */
@@ -413,10 +416,21 @@ static int rpm_suspend(struct device *dev, int rpmflags)
 	if (retval) {
 		__update_runtime_status(dev, RPM_ACTIVE);
 		dev->power.deferred_resume = false;
-		if (retval == -EAGAIN || retval == -EBUSY)
+		if (retval == -EAGAIN || retval == -EBUSY) {
 			dev->power.runtime_error = 0;
-		else
+
+			/*
+			 * If the callback routine failed an autosuspend, and
+			 * if the last_busy time has been updated so that there
+			 * is a new autosuspend expiration time, automatically
+			 * reschedule another autosuspend.
+			 */
+			if ((rpmflags & RPM_AUTO) &&
+			    pm_runtime_autosuspend_expiration(dev) != 0)
+				goto repeat;
+		} else {
 			pm_runtime_cancel_pending(dev);
+		}
 		wake_up_all(&dev->power.wait_queue);
 		goto out;
 	}

commit def0c0a37d02820497fcd5a74b6cc93dbce5dc06
Author: venu byravarasu <vbyravarasu@nvidia.com>
Date:   Thu Nov 3 10:12:14 2011 +0100

    PM / Runtime: Fix runtime accounting calculation error
    
    With delta type being int, its value is made zero
    for all values of now > 0x80000000.
    Hence fixing it.
    
    Signed-off-by: venu byravarasu <vbyravarasu@nvidia.com>
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 6bb3aafa85ed..18ef87e525fa 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -29,13 +29,10 @@ static int rpm_suspend(struct device *dev, int rpmflags);
 void update_pm_runtime_accounting(struct device *dev)
 {
 	unsigned long now = jiffies;
-	int delta;
+	unsigned long delta;
 
 	delta = now - dev->power.accounting_timestamp;
 
-	if (delta < 0)
-		delta = 0;
-
 	dev->power.accounting_timestamp = now;
 
 	if (dev->power.disable_depth > 0)

commit 1b6bc32f0a7380102499deb6aa99a59e789efb33
Author: Paul Gortmaker <paul.gortmaker@windriver.com>
Date:   Fri May 27 07:12:15 2011 -0400

    drivers/base: Add export.h for EXPORT_SYMBOL/THIS_MODULE as required.
    
    Most of these files were implicitly getting EXPORT_SYMBOL via
    device.h which was including module.h, but that path will be broken
    soon.
    
    [ with input from Stephen Rothwell <sfr@canb.auug.org.au> ]
    
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 6bb3aafa85ed..1079e030fd9e 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -8,6 +8,7 @@
  */
 
 #include <linux/sched.h>
+#include <linux/export.h>
 #include <linux/pm_runtime.h>
 #include <trace/events/rpm.h>
 #include "power.h"

commit 857b36c7b038ac56a882ee914df93e5985443074
Author: Ming Lei <ming.lei@canonical.com>
Date:   Wed Oct 12 22:59:33 2011 +0200

    PM / Runtime: Handle .runtime_suspend() failure correctly
    
    If .runtime_suspend() returns -EAGAIN or -EBUSY, the device should
    still be in ACTIVE state, so it is not necessary to send an idle
    notification to its parent.  If .runtime_suspend() returns other
    fatal failure, it doesn't make sense to send idle notification to
    its parent.
    
    Skip parent idle notification when failure is returned from
    .runtime_suspend() and update comments in rpm_suspend() to reflect
    that change.
    
    [rjw: Modified the subject and changelog slightly.]
    
    Signed-off-by: Ming Lei <ming.lei@canonical.com>
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index aa23a64ea33b..6bb3aafa85ed 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -291,11 +291,11 @@ static int rpm_callback(int (*cb)(struct device *), struct device *dev)
  * another suspend has been started earlier, either return immediately
  * or wait for it to finish, depending on the RPM_NOWAIT and RPM_ASYNC
  * flags. If the RPM_ASYNC flag is set then queue a suspend request;
- * otherwise run the ->runtime_suspend() callback directly. If a deferred
- * resume was requested while the callback was running then carry it out;
- * otherwise send an idle notification for its parent (if the suspend
- * succeeded and both ignore_children of parent->power and irq_safe of
- * dev->power are not set).
+ * otherwise run the ->runtime_suspend() callback directly. When
+ * ->runtime_suspend succeeded, if a deferred resume was requested while
+ * the callback was running then carry it out, otherwise send an idle
+ * notification for its parent (if the suspend succeeded and both
+ * ignore_children of parent->power and irq_safe of dev->power are not set).
  *
  * This function must be called under dev->power.lock with interrupts disabled.
  */
@@ -420,15 +420,16 @@ static int rpm_suspend(struct device *dev, int rpmflags)
 			dev->power.runtime_error = 0;
 		else
 			pm_runtime_cancel_pending(dev);
-	} else {
+		wake_up_all(&dev->power.wait_queue);
+		goto out;
+	}
  no_callback:
-		__update_runtime_status(dev, RPM_SUSPENDED);
-		pm_runtime_deactivate_timer(dev);
+	__update_runtime_status(dev, RPM_SUSPENDED);
+	pm_runtime_deactivate_timer(dev);
 
-		if (dev->parent) {
-			parent = dev->parent;
-			atomic_add_unless(&parent->power.child_count, -1, 0);
-		}
+	if (dev->parent) {
+		parent = dev->parent;
+		atomic_add_unless(&parent->power.child_count, -1, 0);
 	}
 	wake_up_all(&dev->power.wait_queue);
 

commit 47d8f0bac0fda4c15a030f92cd6da6c6bed87459
Author: Ming Lei <ming.lei@canonical.com>
Date:   Wed Oct 12 11:53:32 2011 +0800

    PM / Runtime: Fix kerneldoc comment for rpm_suspend()
    
    This patch fix kerneldoc comments for rpm_suspend():
    
     - 'Cancel a pending idle notification' should be put before, also
       should be changed to 'Cancel a pending idle notification,
       autosuspend or suspend'.
    
     - idle notification for the device after succeeding suspend has
       been removed, so update the comment accordingly.
    
    [rjw: Modified the subject and changelog slightly.]
    
    Signed-off-by: Ming Lei <ming.lei@canonical.com>
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 7a6fb5e34a0e..aa23a64ea33b 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -286,14 +286,16 @@ static int rpm_callback(int (*cb)(struct device *), struct device *dev)
  * @dev: Device to suspend.
  * @rpmflags: Flag bits.
  *
- * Check if the device's runtime PM status allows it to be suspended.  If
- * another suspend has been started earlier, either return immediately or wait
- * for it to finish, depending on the RPM_NOWAIT and RPM_ASYNC flags.  Cancel a
- * pending idle notification.  If the RPM_ASYNC flag is set then queue a
- * suspend request; otherwise run the ->runtime_suspend() callback directly.
- * If a deferred resume was requested while the callback was running then carry
- * it out; otherwise send an idle notification for the device (if the suspend
- * failed) or for its parent (if the suspend succeeded).
+ * Check if the device's runtime PM status allows it to be suspended.
+ * Cancel a pending idle notification, autosuspend or suspend. If
+ * another suspend has been started earlier, either return immediately
+ * or wait for it to finish, depending on the RPM_NOWAIT and RPM_ASYNC
+ * flags. If the RPM_ASYNC flag is set then queue a suspend request;
+ * otherwise run the ->runtime_suspend() callback directly. If a deferred
+ * resume was requested while the callback was running then carry it out;
+ * otherwise send an idle notification for its parent (if the suspend
+ * succeeded and both ignore_children of parent->power and irq_safe of
+ * dev->power are not set).
  *
  * This function must be called under dev->power.lock with interrupts disabled.
  */

commit c3dc2f14622a06488f11452b6efd1e02c5a8548b
Author: Ming Lei <ming.lei@canonical.com>
Date:   Tue Sep 27 22:54:41 2011 +0200

    PM / Runtime: Replace dev_dbg() with trace_rpm_*()
    
    This patch replaces dev_dbg with trace_rpm_* inside
    the three important functions:
    
            rpm_idle
            rpm_suspend
            rpm_resume
    
    Trace points have the below advantages compared with dev_dbg:
    
            - trace points include much runtime information(such as
            running cpu, current task, ...)
    
            - most of linux distributions may disable "verbose debug"
            driver debug compile switch, so it is very difficult to
            report/debug runtime pm related problems from distribution
            users without this kind of debug information.
    
            - for upstream kernel users, enableing the debug switch will
            produce many useless "rpm_resume" output, and it is very noise.
    
            - dev_dbg inside rpm_suspend/rpm_resume may have some effects
            on runtime pm behaviour of console devicer
    
    Signed-off-by: Ming Lei <ming.lei@canonical.com>
    Acked-by: Steven Rostedt <rostedt@goodmis.org>
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index aecb2a887ed7..7a6fb5e34a0e 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -9,6 +9,7 @@
 
 #include <linux/sched.h>
 #include <linux/pm_runtime.h>
+#include <trace/events/rpm.h>
 #include "power.h"
 
 static int rpm_resume(struct device *dev, int rpmflags);
@@ -196,6 +197,7 @@ static int rpm_idle(struct device *dev, int rpmflags)
 	int (*callback)(struct device *);
 	int retval;
 
+	trace_rpm_idle(dev, rpmflags);
 	retval = rpm_check_suspend_allowed(dev);
 	if (retval < 0)
 		;	/* Conditions are wrong. */
@@ -257,6 +259,7 @@ static int rpm_idle(struct device *dev, int rpmflags)
 	wake_up_all(&dev->power.wait_queue);
 
  out:
+	trace_rpm_return_int(dev, _THIS_IP_, retval);
 	return retval;
 }
 
@@ -301,7 +304,7 @@ static int rpm_suspend(struct device *dev, int rpmflags)
 	struct device *parent = NULL;
 	int retval;
 
-	dev_dbg(dev, "%s flags 0x%x\n", __func__, rpmflags);
+	trace_rpm_suspend(dev, rpmflags);
 
  repeat:
 	retval = rpm_check_suspend_allowed(dev);
@@ -445,7 +448,7 @@ static int rpm_suspend(struct device *dev, int rpmflags)
 	}
 
  out:
-	dev_dbg(dev, "%s returns %d\n", __func__, retval);
+	trace_rpm_return_int(dev, _THIS_IP_, retval);
 
 	return retval;
 }
@@ -474,7 +477,7 @@ static int rpm_resume(struct device *dev, int rpmflags)
 	struct device *parent = NULL;
 	int retval = 0;
 
-	dev_dbg(dev, "%s flags 0x%x\n", __func__, rpmflags);
+	trace_rpm_resume(dev, rpmflags);
 
  repeat:
 	if (dev->power.runtime_error)
@@ -639,7 +642,7 @@ static int rpm_resume(struct device *dev, int rpmflags)
 		spin_lock_irq(&dev->power.lock);
 	}
 
-	dev_dbg(dev, "%s returns %d\n", __func__, retval);
+	trace_rpm_return_int(dev, _THIS_IP_, retval);
 
 	return retval;
 }

commit ad3c36a534bc7b945d7bffdda1c62e13bf93489a
Author: Rafael J. Wysocki <rjw@sisk.pl>
Date:   Tue Sep 27 21:54:52 2011 +0200

    PM / Runtime: Don't run callbacks under lock for power.irq_safe set
    
    The rpm_suspend() and rpm_resume() routines execute subsystem or PM
    domain callbacks under power.lock if power.irq_safe is set for the
    given device.  This is inconsistent with that rpm_idle() does after
    commit 02b2677 (PM / Runtime: Allow _put_sync() from
    interrupts-disabled context) and is problematic for subsystems and PM
    domains wanting to use power.lock for synchronization in their
    runtime PM callbacks.
    
    This change requires the code checking if the device's runtime PM
    status is RPM_SUSPENDING or RPM_RESUMING to be modified too, to take
    the power.irq_safe set case into account (that code wasn't reachable
    before with power.irq_safe set, because it's executed with the
    device's power.lock held).
    
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>
    Reviewed-by: Ming Lei <tom.leiming@gmail.com>
    Reviewed-by: Kevin Hilman <khilman@ti.com>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 04e18abb50bb..aecb2a887ed7 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -154,6 +154,31 @@ static int rpm_check_suspend_allowed(struct device *dev)
 	return retval;
 }
 
+/**
+ * __rpm_callback - Run a given runtime PM callback for a given device.
+ * @cb: Runtime PM callback to run.
+ * @dev: Device to run the callback for.
+ */
+static int __rpm_callback(int (*cb)(struct device *), struct device *dev)
+	__releases(&dev->power.lock) __acquires(&dev->power.lock)
+{
+	int retval;
+
+	if (dev->power.irq_safe)
+		spin_unlock(&dev->power.lock);
+	else
+		spin_unlock_irq(&dev->power.lock);
+
+	retval = cb(dev);
+
+	if (dev->power.irq_safe)
+		spin_lock(&dev->power.lock);
+	else
+		spin_lock_irq(&dev->power.lock);
+
+	return retval;
+}
+
 /**
  * rpm_idle - Notify device bus type if the device can be suspended.
  * @dev: Device to notify the bus type about.
@@ -225,19 +250,8 @@ static int rpm_idle(struct device *dev, int rpmflags)
 	else
 		callback = NULL;
 
-	if (callback) {
-		if (dev->power.irq_safe)
-			spin_unlock(&dev->power.lock);
-		else
-			spin_unlock_irq(&dev->power.lock);
-
-		callback(dev);
-
-		if (dev->power.irq_safe)
-			spin_lock(&dev->power.lock);
-		else
-			spin_lock_irq(&dev->power.lock);
-	}
+	if (callback)
+		__rpm_callback(callback, dev);
 
 	dev->power.idle_notification = false;
 	wake_up_all(&dev->power.wait_queue);
@@ -252,22 +266,14 @@ static int rpm_idle(struct device *dev, int rpmflags)
  * @dev: Device to run the callback for.
  */
 static int rpm_callback(int (*cb)(struct device *), struct device *dev)
-	__releases(&dev->power.lock) __acquires(&dev->power.lock)
 {
 	int retval;
 
 	if (!cb)
 		return -ENOSYS;
 
-	if (dev->power.irq_safe) {
-		retval = cb(dev);
-	} else {
-		spin_unlock_irq(&dev->power.lock);
-
-		retval = cb(dev);
+	retval = __rpm_callback(cb, dev);
 
-		spin_lock_irq(&dev->power.lock);
-	}
 	dev->power.runtime_error = retval;
 	return retval != -EACCES ? retval : -EIO;
 }
@@ -347,6 +353,15 @@ static int rpm_suspend(struct device *dev, int rpmflags)
 			goto out;
 		}
 
+		if (dev->power.irq_safe) {
+			spin_unlock(&dev->power.lock);
+
+			cpu_relax();
+
+			spin_lock(&dev->power.lock);
+			goto repeat;
+		}
+
 		/* Wait for the other suspend running in parallel with us. */
 		for (;;) {
 			prepare_to_wait(&dev->power.wait_queue, &wait,
@@ -496,6 +511,15 @@ static int rpm_resume(struct device *dev, int rpmflags)
 			goto out;
 		}
 
+		if (dev->power.irq_safe) {
+			spin_unlock(&dev->power.lock);
+
+			cpu_relax();
+
+			spin_lock(&dev->power.lock);
+			goto repeat;
+		}
+
 		/* Wait for the operation carried out in parallel with us. */
 		for (;;) {
 			prepare_to_wait(&dev->power.wait_queue, &wait,

commit 311aab73d273eb22be976055f6cab224f7279d5e
Author: Colin Cross <ccross@android.com>
Date:   Mon Aug 8 23:39:36 2011 +0200

    PM / Runtime: Add might_sleep() to runtime PM functions
    
    Some of the entry points to pm runtime are not safe to
    call in atomic context unless pm_runtime_irq_safe() has
    been called.  Inspecting the code, it is not immediately
    obvious that the functions sleep at all, as they run
    inside a spin_lock_irqsave, but under some conditions
    they can drop the lock and turn on irqs.
    
    If a driver incorrectly calls the pm_runtime apis, it can
    cause sleeping and irq processing when it expects to stay
    in atomic context.
    
    Add might_sleep_if to the majority of the __pm_runtime_* entry points
    to enforce correct usage.
    
    Add pm_runtime_put_sync_autosuspend to the list of
    functions that can be called in atomic context.
    
    Signed-off-by: Colin Cross <ccross@android.com>
    Reviewed-by: Kevin Hilman <khilman@ti.com>
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index acb3f83b8079..04e18abb50bb 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -732,13 +732,16 @@ EXPORT_SYMBOL_GPL(pm_schedule_suspend);
  * return immediately if it is larger than zero.  Then carry out an idle
  * notification, either synchronous or asynchronous.
  *
- * This routine may be called in atomic context if the RPM_ASYNC flag is set.
+ * This routine may be called in atomic context if the RPM_ASYNC flag is set,
+ * or if pm_runtime_irq_safe() has been called.
  */
 int __pm_runtime_idle(struct device *dev, int rpmflags)
 {
 	unsigned long flags;
 	int retval;
 
+	might_sleep_if(!(rpmflags & RPM_ASYNC) && !dev->power.irq_safe);
+
 	if (rpmflags & RPM_GET_PUT) {
 		if (!atomic_dec_and_test(&dev->power.usage_count))
 			return 0;
@@ -761,13 +764,16 @@ EXPORT_SYMBOL_GPL(__pm_runtime_idle);
  * return immediately if it is larger than zero.  Then carry out a suspend,
  * either synchronous or asynchronous.
  *
- * This routine may be called in atomic context if the RPM_ASYNC flag is set.
+ * This routine may be called in atomic context if the RPM_ASYNC flag is set,
+ * or if pm_runtime_irq_safe() has been called.
  */
 int __pm_runtime_suspend(struct device *dev, int rpmflags)
 {
 	unsigned long flags;
 	int retval;
 
+	might_sleep_if(!(rpmflags & RPM_ASYNC) && !dev->power.irq_safe);
+
 	if (rpmflags & RPM_GET_PUT) {
 		if (!atomic_dec_and_test(&dev->power.usage_count))
 			return 0;
@@ -789,13 +795,16 @@ EXPORT_SYMBOL_GPL(__pm_runtime_suspend);
  * If the RPM_GET_PUT flag is set, increment the device's usage count.  Then
  * carry out a resume, either synchronous or asynchronous.
  *
- * This routine may be called in atomic context if the RPM_ASYNC flag is set.
+ * This routine may be called in atomic context if the RPM_ASYNC flag is set,
+ * or if pm_runtime_irq_safe() has been called.
  */
 int __pm_runtime_resume(struct device *dev, int rpmflags)
 {
 	unsigned long flags;
 	int retval;
 
+	might_sleep_if(!(rpmflags & RPM_ASYNC) && !dev->power.irq_safe);
+
 	if (rpmflags & RPM_GET_PUT)
 		atomic_inc(&dev->power.usage_count);
 

commit 02b26774afebb2d62695ba3230319d70d8c6cc2d
Author: Kevin Hilman <khilman@ti.com>
Date:   Fri Aug 5 21:45:20 2011 +0200

    PM / Runtime: Allow _put_sync() from interrupts-disabled context
    
    Currently the use of pm_runtime_put_sync() is not safe from
    interrupts-disabled context because rpm_idle() will release the
    spinlock and enable interrupts for the idle callbacks.  This enables
    interrupts during a time where interrupts were expected to be
    disabled, and can have strange side effects on drivers that expected
    interrupts to be disabled.
    
    This is not a bug since the documentation clearly states that only
    _put_sync_suspend() is safe in IRQ-safe mode.
    
    However, pm_runtime_put_sync() could be made safe when in IRQ-safe
    mode by releasing the spinlock but not re-enabling interrupts, which
    is what this patch aims to do.
    
    Problem was found when using some buggy drivers that set
    pm_runtime_irq_safe() and used _put_sync() in interrupts-disabled
    context.
    
    Reported-by: Colin Cross <ccross@google.com>
    Tested-by: Nishanth Menon <nm@ti.com>
    Signed-off-by: Kevin Hilman <khilman@ti.com>
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 8dc247c974af..acb3f83b8079 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -226,11 +226,17 @@ static int rpm_idle(struct device *dev, int rpmflags)
 		callback = NULL;
 
 	if (callback) {
-		spin_unlock_irq(&dev->power.lock);
+		if (dev->power.irq_safe)
+			spin_unlock(&dev->power.lock);
+		else
+			spin_unlock_irq(&dev->power.lock);
 
 		callback(dev);
 
-		spin_lock_irq(&dev->power.lock);
+		if (dev->power.irq_safe)
+			spin_lock(&dev->power.lock);
+		else
+			spin_lock_irq(&dev->power.lock);
 	}
 
 	dev->power.idle_notification = false;

commit 2cffff1281a74714c9e035322077ec52ffb1f838
Author: ShuoX Liu <shuox.liu@intel.com>
Date:   Fri Jul 8 20:53:55 2011 +0200

    PM / Runtime: Consistent utilization of deferred_resume
    
    dev->power.deferred_resume is used as a bool typically, so change
    one assignment to false from 0, like other places.
    
    Signed-off-by: ShuoX Liu <shuox.liu@intel.com>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index be7b982d252e..8dc247c974af 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -389,7 +389,7 @@ static int rpm_suspend(struct device *dev, int rpmflags)
 	retval = rpm_callback(callback, dev);
 	if (retval) {
 		__update_runtime_status(dev, RPM_ACTIVE);
-		dev->power.deferred_resume = 0;
+		dev->power.deferred_resume = false;
 		if (retval == -EAGAIN || retval == -EBUSY)
 			dev->power.runtime_error = 0;
 		else

commit 62052ab1d1a456f5f62f8b753e12d10ca1a83604
Author: Rafael J. Wysocki <rjw@sisk.pl>
Date:   Wed Jul 6 10:52:13 2011 +0200

    PM / Runtime: Replace "run-time" with "runtime" in documentation
    
    The runtime PM documentation and kerneldoc comments sometimes spell
    "runtime" with a dash (i.e. "run-time").  Replace all of those
    instances with "runtime" to make the naming consistent.
    
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index ee99025be6b3..be7b982d252e 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -1,5 +1,5 @@
 /*
- * drivers/base/power/runtime.c - Helper functions for device run-time PM
+ * drivers/base/power/runtime.c - Helper functions for device runtime PM
  *
  * Copyright (c) 2009 Rafael J. Wysocki <rjw@sisk.pl>, Novell Inc.
  * Copyright (C) 2010 Alan Stern <stern@rowland.harvard.edu>
@@ -159,7 +159,7 @@ static int rpm_check_suspend_allowed(struct device *dev)
  * @dev: Device to notify the bus type about.
  * @rpmflags: Flag bits.
  *
- * Check if the device's run-time PM status allows it to be suspended.  If
+ * Check if the device's runtime PM status allows it to be suspended.  If
  * another idle notification has been started earlier, return immediately.  If
  * the RPM_ASYNC flag is set then queue an idle-notification request; otherwise
  * run the ->runtime_idle() callback directly.
@@ -267,11 +267,11 @@ static int rpm_callback(int (*cb)(struct device *), struct device *dev)
 }
 
 /**
- * rpm_suspend - Carry out run-time suspend of given device.
+ * rpm_suspend - Carry out runtime suspend of given device.
  * @dev: Device to suspend.
  * @rpmflags: Flag bits.
  *
- * Check if the device's run-time PM status allows it to be suspended.  If
+ * Check if the device's runtime PM status allows it to be suspended.  If
  * another suspend has been started earlier, either return immediately or wait
  * for it to finish, depending on the RPM_NOWAIT and RPM_ASYNC flags.  Cancel a
  * pending idle notification.  If the RPM_ASYNC flag is set then queue a
@@ -430,11 +430,11 @@ static int rpm_suspend(struct device *dev, int rpmflags)
 }
 
 /**
- * rpm_resume - Carry out run-time resume of given device.
+ * rpm_resume - Carry out runtime resume of given device.
  * @dev: Device to resume.
  * @rpmflags: Flag bits.
  *
- * Check if the device's run-time PM status allows it to be resumed.  Cancel
+ * Check if the device's runtime PM status allows it to be resumed.  Cancel
  * any scheduled or pending requests.  If another resume has been started
  * earlier, either return immediately or wait for it to finish, depending on the
  * RPM_NOWAIT and RPM_ASYNC flags.  Similarly, if there's a suspend running in
@@ -551,7 +551,7 @@ static int rpm_resume(struct device *dev, int rpmflags)
 
 		spin_lock(&parent->power.lock);
 		/*
-		 * We can resume if the parent's run-time PM is disabled or it
+		 * We can resume if the parent's runtime PM is disabled or it
 		 * is set to ignore children.
 		 */
 		if (!parent->power.disable_depth
@@ -615,11 +615,11 @@ static int rpm_resume(struct device *dev, int rpmflags)
 }
 
 /**
- * pm_runtime_work - Universal run-time PM work function.
+ * pm_runtime_work - Universal runtime PM work function.
  * @work: Work structure used for scheduling the execution of this function.
  *
  * Use @work to get the device object the work is to be done for, determine what
- * is to be done and execute the appropriate run-time PM function.
+ * is to be done and execute the appropriate runtime PM function.
  */
 static void pm_runtime_work(struct work_struct *work)
 {
@@ -718,7 +718,7 @@ int pm_schedule_suspend(struct device *dev, unsigned int delay)
 EXPORT_SYMBOL_GPL(pm_schedule_suspend);
 
 /**
- * __pm_runtime_idle - Entry point for run-time idle operations.
+ * __pm_runtime_idle - Entry point for runtime idle operations.
  * @dev: Device to send idle notification for.
  * @rpmflags: Flag bits.
  *
@@ -747,7 +747,7 @@ int __pm_runtime_idle(struct device *dev, int rpmflags)
 EXPORT_SYMBOL_GPL(__pm_runtime_idle);
 
 /**
- * __pm_runtime_suspend - Entry point for run-time put/suspend operations.
+ * __pm_runtime_suspend - Entry point for runtime put/suspend operations.
  * @dev: Device to suspend.
  * @rpmflags: Flag bits.
  *
@@ -776,7 +776,7 @@ int __pm_runtime_suspend(struct device *dev, int rpmflags)
 EXPORT_SYMBOL_GPL(__pm_runtime_suspend);
 
 /**
- * __pm_runtime_resume - Entry point for run-time resume operations.
+ * __pm_runtime_resume - Entry point for runtime resume operations.
  * @dev: Device to resume.
  * @rpmflags: Flag bits.
  *
@@ -802,11 +802,11 @@ int __pm_runtime_resume(struct device *dev, int rpmflags)
 EXPORT_SYMBOL_GPL(__pm_runtime_resume);
 
 /**
- * __pm_runtime_set_status - Set run-time PM status of a device.
+ * __pm_runtime_set_status - Set runtime PM status of a device.
  * @dev: Device to handle.
- * @status: New run-time PM status of the device.
+ * @status: New runtime PM status of the device.
  *
- * If run-time PM of the device is disabled or its power.runtime_error field is
+ * If runtime PM of the device is disabled or its power.runtime_error field is
  * different from zero, the status may be changed either to RPM_ACTIVE, or to
  * RPM_SUSPENDED, as long as that reflects the actual state of the device.
  * However, if the device has a parent and the parent is not active, and the
@@ -852,7 +852,7 @@ int __pm_runtime_set_status(struct device *dev, unsigned int status)
 
 		/*
 		 * It is invalid to put an active child under a parent that is
-		 * not active, has run-time PM enabled and the
+		 * not active, has runtime PM enabled and the
 		 * 'power.ignore_children' flag unset.
 		 */
 		if (!parent->power.disable_depth
@@ -886,7 +886,7 @@ EXPORT_SYMBOL_GPL(__pm_runtime_set_status);
  * @dev: Device to handle.
  *
  * Flush all pending requests for the device from pm_wq and wait for all
- * run-time PM operations involving the device in progress to complete.
+ * runtime PM operations involving the device in progress to complete.
  *
  * Should be called under dev->power.lock with interrupts disabled.
  */
@@ -934,7 +934,7 @@ static void __pm_runtime_barrier(struct device *dev)
  * Prevent the device from being suspended by incrementing its usage counter and
  * if there's a pending resume request for the device, wake the device up.
  * Next, make sure that all pending requests for the device have been flushed
- * from pm_wq and wait for all run-time PM operations involving the device in
+ * from pm_wq and wait for all runtime PM operations involving the device in
  * progress to complete.
  *
  * Return value:
@@ -964,18 +964,18 @@ int pm_runtime_barrier(struct device *dev)
 EXPORT_SYMBOL_GPL(pm_runtime_barrier);
 
 /**
- * __pm_runtime_disable - Disable run-time PM of a device.
+ * __pm_runtime_disable - Disable runtime PM of a device.
  * @dev: Device to handle.
  * @check_resume: If set, check if there's a resume request for the device.
  *
  * Increment power.disable_depth for the device and if was zero previously,
- * cancel all pending run-time PM requests for the device and wait for all
+ * cancel all pending runtime PM requests for the device and wait for all
  * operations in progress to complete.  The device can be either active or
- * suspended after its run-time PM has been disabled.
+ * suspended after its runtime PM has been disabled.
  *
  * If @check_resume is set and there's a resume request pending when
  * __pm_runtime_disable() is called and power.disable_depth is zero, the
- * function will wake up the device before disabling its run-time PM.
+ * function will wake up the device before disabling its runtime PM.
  */
 void __pm_runtime_disable(struct device *dev, bool check_resume)
 {
@@ -988,7 +988,7 @@ void __pm_runtime_disable(struct device *dev, bool check_resume)
 
 	/*
 	 * Wake up the device if there's a resume request pending, because that
-	 * means there probably is some I/O to process and disabling run-time PM
+	 * means there probably is some I/O to process and disabling runtime PM
 	 * shouldn't prevent the device from processing the I/O.
 	 */
 	if (check_resume && dev->power.request_pending
@@ -1013,7 +1013,7 @@ void __pm_runtime_disable(struct device *dev, bool check_resume)
 EXPORT_SYMBOL_GPL(__pm_runtime_disable);
 
 /**
- * pm_runtime_enable - Enable run-time PM of a device.
+ * pm_runtime_enable - Enable runtime PM of a device.
  * @dev: Device to handle.
  */
 void pm_runtime_enable(struct device *dev)
@@ -1032,7 +1032,7 @@ void pm_runtime_enable(struct device *dev)
 EXPORT_SYMBOL_GPL(pm_runtime_enable);
 
 /**
- * pm_runtime_forbid - Block run-time PM of a device.
+ * pm_runtime_forbid - Block runtime PM of a device.
  * @dev: Device to handle.
  *
  * Increase the device's usage count and clear its power.runtime_auto flag,
@@ -1055,7 +1055,7 @@ void pm_runtime_forbid(struct device *dev)
 EXPORT_SYMBOL_GPL(pm_runtime_forbid);
 
 /**
- * pm_runtime_allow - Unblock run-time PM of a device.
+ * pm_runtime_allow - Unblock runtime PM of a device.
  * @dev: Device to handle.
  *
  * Decrease the device's usage count and set its power.runtime_auto flag.
@@ -1076,12 +1076,12 @@ void pm_runtime_allow(struct device *dev)
 EXPORT_SYMBOL_GPL(pm_runtime_allow);
 
 /**
- * pm_runtime_no_callbacks - Ignore run-time PM callbacks for a device.
+ * pm_runtime_no_callbacks - Ignore runtime PM callbacks for a device.
  * @dev: Device to handle.
  *
  * Set the power.no_callbacks flag, which tells the PM core that this
- * device is power-managed through its parent and has no run-time PM
- * callbacks of its own.  The run-time sysfs attributes will be removed.
+ * device is power-managed through its parent and has no runtime PM
+ * callbacks of its own.  The runtime sysfs attributes will be removed.
  */
 void pm_runtime_no_callbacks(struct device *dev)
 {
@@ -1157,8 +1157,8 @@ static void update_autosuspend(struct device *dev, int old_delay, int old_use)
  * @delay: Value of the new delay in milliseconds.
  *
  * Set the device's power.autosuspend_delay value.  If it changes to negative
- * and the power.use_autosuspend flag is set, prevent run-time suspends.  If it
- * changes the other way, allow run-time suspends.
+ * and the power.use_autosuspend flag is set, prevent runtime suspends.  If it
+ * changes the other way, allow runtime suspends.
  */
 void pm_runtime_set_autosuspend_delay(struct device *dev, int delay)
 {
@@ -1178,7 +1178,7 @@ EXPORT_SYMBOL_GPL(pm_runtime_set_autosuspend_delay);
  * @dev: Device to handle.
  * @use: New value for use_autosuspend.
  *
- * Set the device's power.use_autosuspend flag, and allow or prevent run-time
+ * Set the device's power.use_autosuspend flag, and allow or prevent runtime
  * suspends as needed.
  */
 void __pm_runtime_use_autosuspend(struct device *dev, bool use)
@@ -1195,7 +1195,7 @@ void __pm_runtime_use_autosuspend(struct device *dev, bool use)
 EXPORT_SYMBOL_GPL(__pm_runtime_use_autosuspend);
 
 /**
- * pm_runtime_init - Initialize run-time PM fields in given device object.
+ * pm_runtime_init - Initialize runtime PM fields in given device object.
  * @dev: Device object to initialize.
  */
 void pm_runtime_init(struct device *dev)

commit 632e270e01d8a1ee9e8ea56c83028727f17b1d17
Author: Rafael J. Wysocki <rjw@sisk.pl>
Date:   Fri Jul 1 22:29:15 2011 +0200

    PM / Runtime: Return special error code if runtime PM is disabled
    
    Some callers of pm_runtime_get_sync() and other runtime PM helper
    functions, scsi_autopm_get_host() and scsi_autopm_get_device() in
    particular, need to distinguish error codes returned when runtime PM
    is disabled (i.e. power.disable_depth is nonzero for the given
    device) from error codes returned in other situations.  For this
    reason, make the runtime PM helper functions return -EACCES when
    power.disable_depth is nonzero and ensure that this error code
    won't be returned by them in any other circumstances.  Modify
    scsi_autopm_get_host() and scsi_autopm_get_device() to check the
    error code returned by pm_runtime_get_sync() and ignore -EACCES.
    
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 5f5c4236f006..ee99025be6b3 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -135,8 +135,9 @@ static int rpm_check_suspend_allowed(struct device *dev)
 
 	if (dev->power.runtime_error)
 		retval = -EINVAL;
-	else if (atomic_read(&dev->power.usage_count) > 0
-	    || dev->power.disable_depth > 0)
+	else if (dev->power.disable_depth > 0)
+		retval = -EACCES;
+	else if (atomic_read(&dev->power.usage_count) > 0)
 		retval = -EAGAIN;
 	else if (!pm_children_suspended(dev))
 		retval = -EBUSY;
@@ -262,7 +263,7 @@ static int rpm_callback(int (*cb)(struct device *), struct device *dev)
 		spin_lock_irq(&dev->power.lock);
 	}
 	dev->power.runtime_error = retval;
-	return retval;
+	return retval != -EACCES ? retval : -EIO;
 }
 
 /**
@@ -458,7 +459,7 @@ static int rpm_resume(struct device *dev, int rpmflags)
 	if (dev->power.runtime_error)
 		retval = -EINVAL;
 	else if (dev->power.disable_depth > 0)
-		retval = -EAGAIN;
+		retval = -EACCES;
 	if (retval)
 		goto out;
 

commit 564b905ab10d17fb42f86aa8b7b9b796276d1336
Author: Rafael J. Wysocki <rjw@sisk.pl>
Date:   Thu Jun 23 01:52:55 2011 +0200

    PM / Domains: Rename struct dev_power_domain to struct dev_pm_domain
    
    The naming convention used by commit 7538e3db6e015e890825fbd9f86599b
    (PM: Add support for device power domains), which introduced the
    struct dev_power_domain type for representing device power domains,
    evidently confuses some developers who tend to think that objects
    of this type must correspond to "power domains" as defined by
    hardware, which is not the case.  Namely, at the kernel level, a
    struct dev_power_domain object can represent arbitrary set of devices
    that are mutually dependent power management-wise and need not belong
    to one hardware power domain.  To avoid that confusion, rename struct
    dev_power_domain to struct dev_pm_domain and rename the related
    pointers in struct device and struct pm_clk_notifier_block from
    pwr_domain to pm_domain.
    
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>
    Acked-by: Kevin Hilman <khilman@ti.com>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 0d4587b15c55..5f5c4236f006 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -213,8 +213,8 @@ static int rpm_idle(struct device *dev, int rpmflags)
 
 	dev->power.idle_notification = true;
 
-	if (dev->pwr_domain)
-		callback = dev->pwr_domain->ops.runtime_idle;
+	if (dev->pm_domain)
+		callback = dev->pm_domain->ops.runtime_idle;
 	else if (dev->type && dev->type->pm)
 		callback = dev->type->pm->runtime_idle;
 	else if (dev->class && dev->class->pm)
@@ -374,8 +374,8 @@ static int rpm_suspend(struct device *dev, int rpmflags)
 
 	__update_runtime_status(dev, RPM_SUSPENDING);
 
-	if (dev->pwr_domain)
-		callback = dev->pwr_domain->ops.runtime_suspend;
+	if (dev->pm_domain)
+		callback = dev->pm_domain->ops.runtime_suspend;
 	else if (dev->type && dev->type->pm)
 		callback = dev->type->pm->runtime_suspend;
 	else if (dev->class && dev->class->pm)
@@ -573,8 +573,8 @@ static int rpm_resume(struct device *dev, int rpmflags)
 
 	__update_runtime_status(dev, RPM_RESUMING);
 
-	if (dev->pwr_domain)
-		callback = dev->pwr_domain->ops.runtime_resume;
+	if (dev->pm_domain)
+		callback = dev->pm_domain->ops.runtime_resume;
 	else if (dev->type && dev->type->pm)
 		callback = dev->type->pm->runtime_resume;
 	else if (dev->class && dev->class->pm)

commit 4d27e9dcff00a6425d779b065ec8892e4f391661
Author: Rafael J. Wysocki <rjw@sisk.pl>
Date:   Fri Apr 29 00:35:50 2011 +0200

    PM: Make power domain callbacks take precedence over subsystem ones
    
    Change the PM core's behavior related to power domains in such a way
    that, if a power domain is defined for a given device, its callbacks
    will be executed instead of and not in addition to the device
    subsystem's PM callbacks.
    
    The idea behind the initial implementation of power domains handling
    by the PM core was that power domain callbacks would be executed in
    addition to subsystem callbacks, so that it would be possible to
    extend the subsystem callbacks by using power domains.  It turns out,
    however, that this wouldn't be really convenient in some important
    situations.
    
    For example, there are systems in which power can only be removed
    from entire power domains.  On those systems it is not desirable to
    execute device drivers' PM callbacks until it is known that power is
    going to be removed from the devices in question, which means that
    they should be executed by power domain callbacks rather then by
    subsystem (e.g. bus type) PM callbacks, because subsystems generally
    have no information about what devices belong to which power domain.
    Thus, for instance, if the bus type in question is the platform bus
    type, its PM callbacks generally should not be called in addition to
    power domain callbacks, because they run device drivers' callbacks
    unconditionally if defined.
    
    While in principle the default subsystem PM callbacks, or a subset of
    them, may be replaced with different functions, it doesn't seem
    correct to do so, because that would change the subsystem's behavior
    with respect to all devices in the system, regardless of whether or
    not they belong to any power domains.  Thus, the only remaining
    option is to make power domain callbacks take precedence over
    subsystem callbacks.
    
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>
    Acked-by: Grant Likely <grant.likely@secretlab.ca>
    Acked-by: Kevin Hilman <khilman@ti.com>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 3172c60d23a9..0d4587b15c55 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -168,7 +168,6 @@ static int rpm_check_suspend_allowed(struct device *dev)
 static int rpm_idle(struct device *dev, int rpmflags)
 {
 	int (*callback)(struct device *);
-	int (*domain_callback)(struct device *);
 	int retval;
 
 	retval = rpm_check_suspend_allowed(dev);
@@ -214,7 +213,9 @@ static int rpm_idle(struct device *dev, int rpmflags)
 
 	dev->power.idle_notification = true;
 
-	if (dev->type && dev->type->pm)
+	if (dev->pwr_domain)
+		callback = dev->pwr_domain->ops.runtime_idle;
+	else if (dev->type && dev->type->pm)
 		callback = dev->type->pm->runtime_idle;
 	else if (dev->class && dev->class->pm)
 		callback = dev->class->pm->runtime_idle;
@@ -223,19 +224,10 @@ static int rpm_idle(struct device *dev, int rpmflags)
 	else
 		callback = NULL;
 
-	if (dev->pwr_domain)
-		domain_callback = dev->pwr_domain->ops.runtime_idle;
-	else
-		domain_callback = NULL;
-
-	if (callback || domain_callback) {
+	if (callback) {
 		spin_unlock_irq(&dev->power.lock);
 
-		if (domain_callback)
-			retval = domain_callback(dev);
-
-		if (!retval && callback)
-			callback(dev);
+		callback(dev);
 
 		spin_lock_irq(&dev->power.lock);
 	}
@@ -382,7 +374,9 @@ static int rpm_suspend(struct device *dev, int rpmflags)
 
 	__update_runtime_status(dev, RPM_SUSPENDING);
 
-	if (dev->type && dev->type->pm)
+	if (dev->pwr_domain)
+		callback = dev->pwr_domain->ops.runtime_suspend;
+	else if (dev->type && dev->type->pm)
 		callback = dev->type->pm->runtime_suspend;
 	else if (dev->class && dev->class->pm)
 		callback = dev->class->pm->runtime_suspend;
@@ -400,8 +394,6 @@ static int rpm_suspend(struct device *dev, int rpmflags)
 		else
 			pm_runtime_cancel_pending(dev);
 	} else {
-		if (dev->pwr_domain)
-			rpm_callback(dev->pwr_domain->ops.runtime_suspend, dev);
  no_callback:
 		__update_runtime_status(dev, RPM_SUSPENDED);
 		pm_runtime_deactivate_timer(dev);
@@ -582,9 +574,8 @@ static int rpm_resume(struct device *dev, int rpmflags)
 	__update_runtime_status(dev, RPM_RESUMING);
 
 	if (dev->pwr_domain)
-		rpm_callback(dev->pwr_domain->ops.runtime_resume, dev);
-
-	if (dev->type && dev->type->pm)
+		callback = dev->pwr_domain->ops.runtime_resume;
+	else if (dev->type && dev->type->pm)
 		callback = dev->type->pm->runtime_resume;
 	else if (dev->class && dev->class->pm)
 		callback = dev->class->pm->runtime_resume;

commit 25985edcedea6396277003854657b5f3cb31a628
Author: Lucas De Marchi <lucas.demarchi@profusion.mobi>
Date:   Wed Mar 30 22:57:33 2011 -0300

    Fix common misspellings
    
    Fixes generated by 'codespell' and manually reviewed.
    
    Signed-off-by: Lucas De Marchi <lucas.demarchi@profusion.mobi>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 54597c859ecb..3172c60d23a9 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -443,7 +443,7 @@ static int rpm_suspend(struct device *dev, int rpmflags)
  *
  * Check if the device's run-time PM status allows it to be resumed.  Cancel
  * any scheduled or pending requests.  If another resume has been started
- * earlier, either return imediately or wait for it to finish, depending on the
+ * earlier, either return immediately or wait for it to finish, depending on the
  * RPM_NOWAIT and RPM_ASYNC flags.  Similarly, if there's a suspend running in
  * parallel with this function, either tell the other process to resume after
  * suspending (deferred_resume) or wait for it to finish.  If the RPM_ASYNC

commit 9659cc0678b954f187290c6e8b247a673c5d37e1
Author: Rafael J. Wysocki <rjw@sisk.pl>
Date:   Fri Feb 18 23:20:21 2011 +0100

    PM: Make system-wide PM and runtime PM treat subsystems consistently
    
    The code handling system-wide power transitions (eg. suspend-to-RAM)
    can in theory execute callbacks provided by the device's bus type,
    device type and class in each phase of the power transition.  In
    turn, the runtime PM core code only calls one of those callbacks at
    a time, preferring bus type callbacks to device type or class
    callbacks and device type callbacks to class callbacks.
    
    It seems reasonable to make them both behave in the same way in that
    respect.  Moreover, even though a device may belong to two subsystems
    (eg. bus type and device class) simultaneously, in practice power
    management callbacks for system-wide power transitions are always
    provided by only one of them (ie. if the bus type callbacks are
    defined, the device class ones are not and vice versa).  Thus it is
    possible to modify the code handling system-wide power transitions
    so that it follows the core runtime PM code (ie. treats the
    subsystem callbacks as mutually exclusive).
    
    On the other hand, the core runtime PM code will choose to execute,
    for example, a runtime suspend callback provided by the device type
    even if the bus type's struct dev_pm_ops object exists, but the
    runtime_suspend pointer in it happens to be NULL.  This is confusing,
    because it may lead to the execution of callbacks from different
    subsystems during different operations (eg. the bus type suspend
    callback may be executed during runtime suspend of the device, while
    the device type callback will be executed during system suspend).
    
    Make all of the power management code treat subsystem callbacks in
    a consistent way, such that:
    (1) If the device's type is defined (eg. dev->type is not NULL)
        and its pm pointer is not NULL, the callbacks from dev->type->pm
        will be used.
    (2) If dev->type is NULL or dev->type->pm is NULL, but the device's
        class is defined (eg. dev->class is not NULL) and its pm pointer
        is not NULL, the callbacks from dev->class->pm will be used.
    (3) If dev->type is NULL or dev->type->pm is NULL and dev->class is
        NULL or dev->class->pm is NULL, the callbacks from dev->bus->pm
        will be used provided that both dev->bus and dev->bus->pm are
        not NULL.
    
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>
    Acked-by: Kevin Hilman <khilman@ti.com>
    Reasoning-sounds-sane-to: Grant Likely <grant.likely@secretlab.ca>
    Acked-by: Greg Kroah-Hartman <gregkh@suse.de>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 25edc9a3a489..54597c859ecb 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -214,12 +214,12 @@ static int rpm_idle(struct device *dev, int rpmflags)
 
 	dev->power.idle_notification = true;
 
-	if (dev->bus && dev->bus->pm && dev->bus->pm->runtime_idle)
-		callback = dev->bus->pm->runtime_idle;
-	else if (dev->type && dev->type->pm && dev->type->pm->runtime_idle)
+	if (dev->type && dev->type->pm)
 		callback = dev->type->pm->runtime_idle;
 	else if (dev->class && dev->class->pm)
 		callback = dev->class->pm->runtime_idle;
+	else if (dev->bus && dev->bus->pm)
+		callback = dev->bus->pm->runtime_idle;
 	else
 		callback = NULL;
 
@@ -382,12 +382,12 @@ static int rpm_suspend(struct device *dev, int rpmflags)
 
 	__update_runtime_status(dev, RPM_SUSPENDING);
 
-	if (dev->bus && dev->bus->pm && dev->bus->pm->runtime_suspend)
-		callback = dev->bus->pm->runtime_suspend;
-	else if (dev->type && dev->type->pm && dev->type->pm->runtime_suspend)
+	if (dev->type && dev->type->pm)
 		callback = dev->type->pm->runtime_suspend;
 	else if (dev->class && dev->class->pm)
 		callback = dev->class->pm->runtime_suspend;
+	else if (dev->bus && dev->bus->pm)
+		callback = dev->bus->pm->runtime_suspend;
 	else
 		callback = NULL;
 
@@ -584,12 +584,12 @@ static int rpm_resume(struct device *dev, int rpmflags)
 	if (dev->pwr_domain)
 		rpm_callback(dev->pwr_domain->ops.runtime_resume, dev);
 
-	if (dev->bus && dev->bus->pm && dev->bus->pm->runtime_resume)
-		callback = dev->bus->pm->runtime_resume;
-	else if (dev->type && dev->type->pm && dev->type->pm->runtime_resume)
+	if (dev->type && dev->type->pm)
 		callback = dev->type->pm->runtime_resume;
 	else if (dev->class && dev->class->pm)
 		callback = dev->class->pm->runtime_resume;
+	else if (dev->bus && dev->bus->pm)
+		callback = dev->bus->pm->runtime_resume;
 	else
 		callback = NULL;
 

commit 7538e3db6e015e890825fbd9f8659952896ddd5b
Author: Rafael J. Wysocki <rjw@sisk.pl>
Date:   Wed Feb 16 21:53:17 2011 +0100

    PM: Add support for device power domains
    
    The platform bus type is often used to handle Systems-on-a-Chip (SoC)
    where all devices are represented by objects of type struct
    platform_device.  In those cases the same "platform" device driver
    may be used with multiple different system configurations, but the
    actions needed to put the devices it handles into a low-power state
    and back into the full-power state may depend on the design of the
    given SoC.  The driver, however, cannot possibly include all the
    information necessary for the power management of its device on all
    the systems it is used with.  Moreover, the device hierarchy in its
    current form also is not suitable for representing this kind of
    information.
    
    The patch below attempts to address this problem by introducing
    objects of type struct dev_power_domain that can be used for
    representing power domains within a SoC.  Every struct
    dev_power_domain object provides a sets of device power
    management callbacks that can be used to perform what's needed for
    device power management in addition to the operations carried out by
    the device's driver and subsystem.
    
    Namely, if a struct dev_power_domain object is pointed to by the
    pwr_domain field in a struct device, the callbacks provided by its
    ops member will be executed in addition to the corresponding
    callbacks provided by the device's subsystem and driver during all
    power transitions.
    
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>
    Tested-and-acked-by: Kevin Hilman <khilman@ti.com>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 42615b419dfb..25edc9a3a489 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -168,6 +168,7 @@ static int rpm_check_suspend_allowed(struct device *dev)
 static int rpm_idle(struct device *dev, int rpmflags)
 {
 	int (*callback)(struct device *);
+	int (*domain_callback)(struct device *);
 	int retval;
 
 	retval = rpm_check_suspend_allowed(dev);
@@ -222,10 +223,19 @@ static int rpm_idle(struct device *dev, int rpmflags)
 	else
 		callback = NULL;
 
-	if (callback) {
+	if (dev->pwr_domain)
+		domain_callback = dev->pwr_domain->ops.runtime_idle;
+	else
+		domain_callback = NULL;
+
+	if (callback || domain_callback) {
 		spin_unlock_irq(&dev->power.lock);
 
-		callback(dev);
+		if (domain_callback)
+			retval = domain_callback(dev);
+
+		if (!retval && callback)
+			callback(dev);
 
 		spin_lock_irq(&dev->power.lock);
 	}
@@ -390,6 +400,8 @@ static int rpm_suspend(struct device *dev, int rpmflags)
 		else
 			pm_runtime_cancel_pending(dev);
 	} else {
+		if (dev->pwr_domain)
+			rpm_callback(dev->pwr_domain->ops.runtime_suspend, dev);
  no_callback:
 		__update_runtime_status(dev, RPM_SUSPENDED);
 		pm_runtime_deactivate_timer(dev);
@@ -569,6 +581,9 @@ static int rpm_resume(struct device *dev, int rpmflags)
 
 	__update_runtime_status(dev, RPM_RESUMING);
 
+	if (dev->pwr_domain)
+		rpm_callback(dev->pwr_domain->ops.runtime_resume, dev);
+
 	if (dev->bus && dev->bus->pm && dev->bus->pm->runtime_resume)
 		callback = dev->bus->pm->runtime_resume;
 	else if (dev->type && dev->type->pm && dev->type->pm->runtime_resume)

commit c3810c88788d505d4ffd786addd111b745e42161
Author: Alan Stern <stern@rowland.harvard.edu>
Date:   Tue Jan 25 20:50:07 2011 +0100

    PM / Runtime: Don't enable interrupts while running in_interrupt
    
    This patch (as1445) fixes a bug in the runtime PM core left over from
    the addition of the no_callbacks flag.  If this flag is set then it is
    possible for rpm_suspend() to be called in_interrupt, so when
    releasing spinlocks it's important not to re-enable interrupts.
    
    To avoid an unnecessary save-and-restore of the interrupt flag, the
    patch also inlines a pm_request_idle() call.
    
    This fixes Bugzilla #27482.
    
    (The offending code was added in 2.6.37, so it's not necessary to apply
    this to any earlier stable kernels.)
    
    Signed-off-by: Alan Stern <stern@rowland.harvard.edu>
    Reported-by: tim blechmann <tim@klingt.org>
    CC: <stable@kernel.org>
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 656493a5e073..42615b419dfb 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -407,12 +407,15 @@ static int rpm_suspend(struct device *dev, int rpmflags)
 		goto out;
 	}
 
+	/* Maybe the parent is now able to suspend. */
 	if (parent && !parent->power.ignore_children && !dev->power.irq_safe) {
-		spin_unlock_irq(&dev->power.lock);
+		spin_unlock(&dev->power.lock);
 
-		pm_request_idle(parent);
+		spin_lock(&parent->power.lock);
+		rpm_idle(parent, RPM_ASYNC);
+		spin_unlock(&parent->power.lock);
 
-		spin_lock_irq(&dev->power.lock);
+		spin_lock(&dev->power.lock);
 	}
 
  out:

commit c7b61de5b7b17f0df34dc7d2f8b9576f8bd36fce
Author: Alan Stern <stern@rowland.harvard.edu>
Date:   Wed Dec 1 00:14:42 2010 +0100

    PM / Runtime: Add synchronous runtime interface for interrupt handlers (v3)
    
    This patch (as1431c) makes the synchronous runtime-PM interface
    suitable for use in interrupt handlers.  Subsystems can call the new
    pm_runtime_irq_safe() function to tell the PM core that a device's
    runtime_suspend and runtime_resume callbacks should be invoked with
    interrupts disabled and the spinlock held.  This permits the
    pm_runtime_get_sync() and the new pm_runtime_put_sync_suspend()
    routines to be called from within interrupt handlers.
    
    When a device is declared irq-safe in this way, the PM core increments
    the parent's usage count, so the parent will never be runtime
    suspended.  This prevents difficult situations in which an irq-safe
    device can't resume because it is forced to wait for its non-irq-safe
    parent.
    
    Signed-off-by: Alan Stern <stern@rowland.harvard.edu>
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 02c652be83e7..656493a5e073 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -250,13 +250,16 @@ static int rpm_callback(int (*cb)(struct device *), struct device *dev)
 	if (!cb)
 		return -ENOSYS;
 
-	spin_unlock_irq(&dev->power.lock);
+	if (dev->power.irq_safe) {
+		retval = cb(dev);
+	} else {
+		spin_unlock_irq(&dev->power.lock);
 
-	retval = cb(dev);
+		retval = cb(dev);
 
-	spin_lock_irq(&dev->power.lock);
+		spin_lock_irq(&dev->power.lock);
+	}
 	dev->power.runtime_error = retval;
-
 	return retval;
 }
 
@@ -404,7 +407,7 @@ static int rpm_suspend(struct device *dev, int rpmflags)
 		goto out;
 	}
 
-	if (parent && !parent->power.ignore_children) {
+	if (parent && !parent->power.ignore_children && !dev->power.irq_safe) {
 		spin_unlock_irq(&dev->power.lock);
 
 		pm_request_idle(parent);
@@ -527,10 +530,13 @@ static int rpm_resume(struct device *dev, int rpmflags)
 
 	if (!parent && dev->parent) {
 		/*
-		 * Increment the parent's resume counter and resume it if
-		 * necessary.
+		 * Increment the parent's usage counter and resume it if
+		 * necessary.  Not needed if dev is irq-safe; then the
+		 * parent is permanently resumed.
 		 */
 		parent = dev->parent;
+		if (dev->power.irq_safe)
+			goto skip_parent;
 		spin_unlock(&dev->power.lock);
 
 		pm_runtime_get_noresume(parent);
@@ -553,6 +559,7 @@ static int rpm_resume(struct device *dev, int rpmflags)
 			goto out;
 		goto repeat;
 	}
+ skip_parent:
 
 	if (dev->power.no_callbacks)
 		goto no_callback;	/* Assume success. */
@@ -584,7 +591,7 @@ static int rpm_resume(struct device *dev, int rpmflags)
 		rpm_idle(dev, RPM_ASYNC);
 
  out:
-	if (parent) {
+	if (parent && !dev->power.irq_safe) {
 		spin_unlock_irq(&dev->power.lock);
 
 		pm_runtime_put(parent);
@@ -1065,7 +1072,6 @@ EXPORT_SYMBOL_GPL(pm_runtime_allow);
  * Set the power.no_callbacks flag, which tells the PM core that this
  * device is power-managed through its parent and has no run-time PM
  * callbacks of its own.  The run-time sysfs attributes will be removed.
- *
  */
 void pm_runtime_no_callbacks(struct device *dev)
 {
@@ -1077,6 +1083,27 @@ void pm_runtime_no_callbacks(struct device *dev)
 }
 EXPORT_SYMBOL_GPL(pm_runtime_no_callbacks);
 
+/**
+ * pm_runtime_irq_safe - Leave interrupts disabled during callbacks.
+ * @dev: Device to handle
+ *
+ * Set the power.irq_safe flag, which tells the PM core that the
+ * ->runtime_suspend() and ->runtime_resume() callbacks for this device should
+ * always be invoked with the spinlock held and interrupts disabled.  It also
+ * causes the parent's usage counter to be permanently incremented, preventing
+ * the parent from runtime suspending -- otherwise an irq-safe child might have
+ * to wait for a non-irq-safe parent.
+ */
+void pm_runtime_irq_safe(struct device *dev)
+{
+	if (dev->parent)
+		pm_runtime_get_sync(dev->parent);
+	spin_lock_irq(&dev->power.lock);
+	dev->power.irq_safe = 1;
+	spin_unlock_irq(&dev->power.lock);
+}
+EXPORT_SYMBOL_GPL(pm_runtime_irq_safe);
+
 /**
  * update_autosuspend - Handle a change to a device's autosuspend settings.
  * @dev: Device to handle.
@@ -1199,4 +1226,6 @@ void pm_runtime_remove(struct device *dev)
 	/* Change the status back to 'suspended' to match the initial status. */
 	if (dev->power.runtime_status == RPM_ACTIVE)
 		pm_runtime_set_suspended(dev);
+	if (dev->power.irq_safe && dev->parent)
+		pm_runtime_put_sync(dev->parent);
 }

commit 78ca7c37efaa541006269aa3d3e560ea7926e245
Author: Kevin Winchester <kjwinchester@gmail.com>
Date:   Fri Oct 29 15:29:55 2010 +0200

    PM / Runtime: Fix typo in status comparison causing warning
    
    GCC version 4.5.1 gives the following warning:
    
    drivers/base/power/runtime.c: In function ‘rpm_check_suspend_allowed’:
    drivers/base/power/runtime.c:146:25: warning: comparison between ‘enum dpm_state’ and ‘enum rpm_status’
    
    which seems to be a typo in that dev->power.runtime_status
    should be compared instead of dev->power.status.
    
    Signed-off-by: Kevin Winchester <kjwinchester@gmail.com>
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 126ca492dd08..02c652be83e7 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -143,7 +143,7 @@ static int rpm_check_suspend_allowed(struct device *dev)
 
 	/* Pending resume requests take precedence over suspends. */
 	else if ((dev->power.deferred_resume
-			&& dev->power.status == RPM_SUSPENDING)
+			&& dev->power.runtime_status == RPM_SUSPENDING)
 	    || (dev->power.request_pending
 			&& dev->power.request == RPM_REQ_RESUME))
 		retval = -EAGAIN;

commit d63be5f924cf054e7ac18bb2761f9533039fb076
Author: Ming Lei <tom.leiming@gmail.com>
Date:   Fri Oct 22 23:48:14 2010 +0200

    PM / Runtime: fix recursive locking warning of lockdep from rpm_resume()
    
    For device with no_callbacks flag set, its power lock and its parent's
    power lock may be held nestedly in rpm_resume, so we should take
    spin_lock_nested(lock, SINGLE_DEPTH_NESTING) to acquire parent power lock
    to avoid lockdep warning.
    
    Signed-off-by: Ming Lei <tom.leiming@gmail.com>
    Acked-by: Alan Stern <stern@rowland.harvard.edu>
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 1dd8676d7f55..126ca492dd08 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -503,7 +503,7 @@ static int rpm_resume(struct device *dev, int rpmflags)
 	 * the resume will actually succeed.
 	 */
 	if (dev->power.no_callbacks && !parent && dev->parent) {
-		spin_lock(&dev->parent->power.lock);
+		spin_lock_nested(&dev->parent->power.lock, SINGLE_DEPTH_NESTING);
 		if (dev->parent->power.disable_depth > 0
 		    || dev->parent->power.ignore_children
 		    || dev->parent->power.runtime_status == RPM_ACTIVE) {

commit f71648d73c1650b8b4aceb3856bebbde6daa3b86
Author: Rafael J. Wysocki <rjw@sisk.pl>
Date:   Mon Oct 11 01:02:27 2010 +0200

    PM / Runtime: Remove idle notification after failing suspend
    
    If runtime suspend of a device fails returning -EAGAIN or -EBUSY,
    which means that it's safe to try to suspend it again, the PM core
    runs the runtime idle helper function for it.  Unfortunately this may
    lead to problems, for example for PCI devices whose drivers don't
    implement the ->runtime_idle() callback, because in that case the
    PCI bus type's ->runtime_idle() always calls pm_runtime_suspend()
    for the given device.  Then, if there's an automatic idle
    notification after the driver's ->runtime_suspend() returning -EAGAIN
    or -EBUSY, it will make the suspend happen again possibly causing a
    busy loop to appear.  To avoid that, remove the idle notification
    after failing runtime suspend of a device altogether and let the
    callers of pm_runtime_suspend() repeat the operation if need be.
    
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>
    Acked-by: Alan Stern <stern@rowland.harvard.edu>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index e957c496a1b1..1dd8676d7f55 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -281,7 +281,6 @@ static int rpm_suspend(struct device *dev, int rpmflags)
 {
 	int (*callback)(struct device *);
 	struct device *parent = NULL;
-	bool notify = false;
 	int retval;
 
 	dev_dbg(dev, "%s flags 0x%x\n", __func__, rpmflags);
@@ -383,13 +382,10 @@ static int rpm_suspend(struct device *dev, int rpmflags)
 	if (retval) {
 		__update_runtime_status(dev, RPM_ACTIVE);
 		dev->power.deferred_resume = 0;
-		if (retval == -EAGAIN || retval == -EBUSY) {
-			if (dev->power.timer_expires == 0)
-				notify = true;
+		if (retval == -EAGAIN || retval == -EBUSY)
 			dev->power.runtime_error = 0;
-		} else {
+		else
 			pm_runtime_cancel_pending(dev);
-		}
 	} else {
  no_callback:
 		__update_runtime_status(dev, RPM_SUSPENDED);
@@ -408,9 +404,6 @@ static int rpm_suspend(struct device *dev, int rpmflags)
 		goto out;
 	}
 
-	if (notify)
-		rpm_idle(dev, 0);
-
 	if (parent && !parent->power.ignore_children) {
 		spin_unlock_irq(&dev->power.lock);
 

commit 71c63122c4609a917f14a79c32067a68909fc487
Author: Rafael J. Wysocki <rjw@sisk.pl>
Date:   Mon Oct 4 22:08:01 2010 +0200

    PM / Runtime: Reduce code duplication in core helper functions
    
    Reduce code duplication in rpm_idle(), rpm_suspend() and rpm_resume()
    by using local pointers to store callback addresses and moving some
    duplicated code into a separate function.
    
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>
    Reviewed-by: Alan Stern <stern@rowland.harvard.edu>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index cd4e100a1362..e957c496a1b1 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -153,7 +153,6 @@ static int rpm_check_suspend_allowed(struct device *dev)
 	return retval;
 }
 
-
 /**
  * rpm_idle - Notify device bus type if the device can be suspended.
  * @dev: Device to notify the bus type about.
@@ -167,8 +166,8 @@ static int rpm_check_suspend_allowed(struct device *dev)
  * This function must be called under dev->power.lock with interrupts disabled.
  */
 static int rpm_idle(struct device *dev, int rpmflags)
-	__releases(&dev->power.lock) __acquires(&dev->power.lock)
 {
+	int (*callback)(struct device *);
 	int retval;
 
 	retval = rpm_check_suspend_allowed(dev);
@@ -214,23 +213,19 @@ static int rpm_idle(struct device *dev, int rpmflags)
 
 	dev->power.idle_notification = true;
 
-	if (dev->bus && dev->bus->pm && dev->bus->pm->runtime_idle) {
-		spin_unlock_irq(&dev->power.lock);
-
-		dev->bus->pm->runtime_idle(dev);
-
-		spin_lock_irq(&dev->power.lock);
-	} else if (dev->type && dev->type->pm && dev->type->pm->runtime_idle) {
-		spin_unlock_irq(&dev->power.lock);
-
-		dev->type->pm->runtime_idle(dev);
+	if (dev->bus && dev->bus->pm && dev->bus->pm->runtime_idle)
+		callback = dev->bus->pm->runtime_idle;
+	else if (dev->type && dev->type->pm && dev->type->pm->runtime_idle)
+		callback = dev->type->pm->runtime_idle;
+	else if (dev->class && dev->class->pm)
+		callback = dev->class->pm->runtime_idle;
+	else
+		callback = NULL;
 
-		spin_lock_irq(&dev->power.lock);
-	} else if (dev->class && dev->class->pm
-	    && dev->class->pm->runtime_idle) {
+	if (callback) {
 		spin_unlock_irq(&dev->power.lock);
 
-		dev->class->pm->runtime_idle(dev);
+		callback(dev);
 
 		spin_lock_irq(&dev->power.lock);
 	}
@@ -242,6 +237,29 @@ static int rpm_idle(struct device *dev, int rpmflags)
 	return retval;
 }
 
+/**
+ * rpm_callback - Run a given runtime PM callback for a given device.
+ * @cb: Runtime PM callback to run.
+ * @dev: Device to run the callback for.
+ */
+static int rpm_callback(int (*cb)(struct device *), struct device *dev)
+	__releases(&dev->power.lock) __acquires(&dev->power.lock)
+{
+	int retval;
+
+	if (!cb)
+		return -ENOSYS;
+
+	spin_unlock_irq(&dev->power.lock);
+
+	retval = cb(dev);
+
+	spin_lock_irq(&dev->power.lock);
+	dev->power.runtime_error = retval;
+
+	return retval;
+}
+
 /**
  * rpm_suspend - Carry out run-time suspend of given device.
  * @dev: Device to suspend.
@@ -261,6 +279,7 @@ static int rpm_idle(struct device *dev, int rpmflags)
 static int rpm_suspend(struct device *dev, int rpmflags)
 	__releases(&dev->power.lock) __acquires(&dev->power.lock)
 {
+	int (*callback)(struct device *);
 	struct device *parent = NULL;
 	bool notify = false;
 	int retval;
@@ -351,33 +370,16 @@ static int rpm_suspend(struct device *dev, int rpmflags)
 
 	__update_runtime_status(dev, RPM_SUSPENDING);
 
-	if (dev->bus && dev->bus->pm && dev->bus->pm->runtime_suspend) {
-		spin_unlock_irq(&dev->power.lock);
-
-		retval = dev->bus->pm->runtime_suspend(dev);
-
-		spin_lock_irq(&dev->power.lock);
-		dev->power.runtime_error = retval;
-	} else if (dev->type && dev->type->pm
-	    && dev->type->pm->runtime_suspend) {
-		spin_unlock_irq(&dev->power.lock);
-
-		retval = dev->type->pm->runtime_suspend(dev);
-
-		spin_lock_irq(&dev->power.lock);
-		dev->power.runtime_error = retval;
-	} else if (dev->class && dev->class->pm
-	    && dev->class->pm->runtime_suspend) {
-		spin_unlock_irq(&dev->power.lock);
-
-		retval = dev->class->pm->runtime_suspend(dev);
-
-		spin_lock_irq(&dev->power.lock);
-		dev->power.runtime_error = retval;
-	} else {
-		retval = -ENOSYS;
-	}
+	if (dev->bus && dev->bus->pm && dev->bus->pm->runtime_suspend)
+		callback = dev->bus->pm->runtime_suspend;
+	else if (dev->type && dev->type->pm && dev->type->pm->runtime_suspend)
+		callback = dev->type->pm->runtime_suspend;
+	else if (dev->class && dev->class->pm)
+		callback = dev->class->pm->runtime_suspend;
+	else
+		callback = NULL;
 
+	retval = rpm_callback(callback, dev);
 	if (retval) {
 		__update_runtime_status(dev, RPM_ACTIVE);
 		dev->power.deferred_resume = 0;
@@ -443,6 +445,7 @@ static int rpm_suspend(struct device *dev, int rpmflags)
 static int rpm_resume(struct device *dev, int rpmflags)
 	__releases(&dev->power.lock) __acquires(&dev->power.lock)
 {
+	int (*callback)(struct device *);
 	struct device *parent = NULL;
 	int retval = 0;
 
@@ -563,33 +566,16 @@ static int rpm_resume(struct device *dev, int rpmflags)
 
 	__update_runtime_status(dev, RPM_RESUMING);
 
-	if (dev->bus && dev->bus->pm && dev->bus->pm->runtime_resume) {
-		spin_unlock_irq(&dev->power.lock);
-
-		retval = dev->bus->pm->runtime_resume(dev);
-
-		spin_lock_irq(&dev->power.lock);
-		dev->power.runtime_error = retval;
-	} else if (dev->type && dev->type->pm
-	    && dev->type->pm->runtime_resume) {
-		spin_unlock_irq(&dev->power.lock);
-
-		retval = dev->type->pm->runtime_resume(dev);
-
-		spin_lock_irq(&dev->power.lock);
-		dev->power.runtime_error = retval;
-	} else if (dev->class && dev->class->pm
-	    && dev->class->pm->runtime_resume) {
-		spin_unlock_irq(&dev->power.lock);
-
-		retval = dev->class->pm->runtime_resume(dev);
-
-		spin_lock_irq(&dev->power.lock);
-		dev->power.runtime_error = retval;
-	} else {
-		retval = -ENOSYS;
-	}
+	if (dev->bus && dev->bus->pm && dev->bus->pm->runtime_resume)
+		callback = dev->bus->pm->runtime_resume;
+	else if (dev->type && dev->type->pm && dev->type->pm->runtime_resume)
+		callback = dev->type->pm->runtime_resume;
+	else if (dev->class && dev->class->pm)
+		callback = dev->class->pm->runtime_resume;
+	else
+		callback = NULL;
 
+	retval = rpm_callback(callback, dev);
 	if (retval) {
 		__update_runtime_status(dev, RPM_SUSPENDED);
 		pm_runtime_cancel_pending(dev);

commit 15bcb91d7e607d8a2e060f01f7784a7454668da4
Author: Alan Stern <stern@rowland.harvard.edu>
Date:   Sat Sep 25 23:35:21 2010 +0200

    PM / Runtime: Implement autosuspend support
    
    This patch (as1427) implements the "autosuspend" facility for runtime
    PM.  A few new fields are added to the dev_pm_info structure and
    several new PM helper functions are defined, for telling the PM core
    whether or not a device uses autosuspend, for setting the autosuspend
    delay, and for marking periods of device activity.
    
    Drivers that do not want to use autosuspend can continue using the
    same helper functions as before; their behavior will not change.  In
    addition, drivers supporting autosuspend can also call the old helper
    functions to get the old behavior.
    
    The details are all explained in Documentation/power/runtime_pm.txt
    and Documentation/ABI/testing/sysfs-devices-power.
    
    Signed-off-by: Alan Stern <stern@rowland.harvard.edu>
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 5bd4daa93ef1..cd4e100a1362 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -9,7 +9,6 @@
 
 #include <linux/sched.h>
 #include <linux/pm_runtime.h>
-#include <linux/jiffies.h>
 #include "power.h"
 
 static int rpm_resume(struct device *dev, int rpmflags);
@@ -79,6 +78,53 @@ static void pm_runtime_cancel_pending(struct device *dev)
 	dev->power.request = RPM_REQ_NONE;
 }
 
+/*
+ * pm_runtime_autosuspend_expiration - Get a device's autosuspend-delay expiration time.
+ * @dev: Device to handle.
+ *
+ * Compute the autosuspend-delay expiration time based on the device's
+ * power.last_busy time.  If the delay has already expired or is disabled
+ * (negative) or the power.use_autosuspend flag isn't set, return 0.
+ * Otherwise return the expiration time in jiffies (adjusted to be nonzero).
+ *
+ * This function may be called either with or without dev->power.lock held.
+ * Either way it can be racy, since power.last_busy may be updated at any time.
+ */
+unsigned long pm_runtime_autosuspend_expiration(struct device *dev)
+{
+	int autosuspend_delay;
+	long elapsed;
+	unsigned long last_busy;
+	unsigned long expires = 0;
+
+	if (!dev->power.use_autosuspend)
+		goto out;
+
+	autosuspend_delay = ACCESS_ONCE(dev->power.autosuspend_delay);
+	if (autosuspend_delay < 0)
+		goto out;
+
+	last_busy = ACCESS_ONCE(dev->power.last_busy);
+	elapsed = jiffies - last_busy;
+	if (elapsed < 0)
+		goto out;	/* jiffies has wrapped around. */
+
+	/*
+	 * If the autosuspend_delay is >= 1 second, align the timer by rounding
+	 * up to the nearest second.
+	 */
+	expires = last_busy + msecs_to_jiffies(autosuspend_delay);
+	if (autosuspend_delay >= 1000)
+		expires = round_jiffies(expires);
+	expires += !expires;
+	if (elapsed >= expires - last_busy)
+		expires = 0;	/* Already expired. */
+
+ out:
+	return expires;
+}
+EXPORT_SYMBOL_GPL(pm_runtime_autosuspend_expiration);
+
 /**
  * rpm_check_suspend_allowed - Test whether a device may be suspended.
  * @dev: Device to test.
@@ -234,6 +280,32 @@ static int rpm_suspend(struct device *dev, int rpmflags)
 	if (retval)
 		goto out;
 
+	/* If the autosuspend_delay time hasn't expired yet, reschedule. */
+	if ((rpmflags & RPM_AUTO)
+	    && dev->power.runtime_status != RPM_SUSPENDING) {
+		unsigned long expires = pm_runtime_autosuspend_expiration(dev);
+
+		if (expires != 0) {
+			/* Pending requests need to be canceled. */
+			dev->power.request = RPM_REQ_NONE;
+
+			/*
+			 * Optimization: If the timer is already running and is
+			 * set to expire at or before the autosuspend delay,
+			 * avoid the overhead of resetting it.  Just let it
+			 * expire; pm_suspend_timer_fn() will take care of the
+			 * rest.
+			 */
+			if (!(dev->power.timer_expires && time_before_eq(
+			    dev->power.timer_expires, expires))) {
+				dev->power.timer_expires = expires;
+				mod_timer(&dev->power.suspend_timer, expires);
+			}
+			dev->power.timer_autosuspends = 1;
+			goto out;
+		}
+	}
+
 	/* Other scheduled or pending requests need to be canceled. */
 	pm_runtime_cancel_pending(dev);
 
@@ -268,7 +340,8 @@ static int rpm_suspend(struct device *dev, int rpmflags)
 
 	/* Carry out an asynchronous or a synchronous suspend. */
 	if (rpmflags & RPM_ASYNC) {
-		dev->power.request = RPM_REQ_SUSPEND;
+		dev->power.request = (rpmflags & RPM_AUTO) ?
+		    RPM_REQ_AUTOSUSPEND : RPM_REQ_SUSPEND;
 		if (!dev->power.request_pending) {
 			dev->power.request_pending = true;
 			queue_work(pm_wq, &dev->power.work);
@@ -383,8 +456,15 @@ static int rpm_resume(struct device *dev, int rpmflags)
 	if (retval)
 		goto out;
 
-	/* Other scheduled or pending requests need to be canceled. */
-	pm_runtime_cancel_pending(dev);
+	/*
+	 * Other scheduled or pending requests need to be canceled.  Small
+	 * optimization: If an autosuspend timer is running, leave it running
+	 * rather than cancelling it now only to restart it again in the near
+	 * future.
+	 */
+	dev->power.request = RPM_REQ_NONE;
+	if (!dev->power.timer_autosuspends)
+		pm_runtime_deactivate_timer(dev);
 
 	if (dev->power.runtime_status == RPM_ACTIVE) {
 		retval = 1;
@@ -568,6 +648,9 @@ static void pm_runtime_work(struct work_struct *work)
 	case RPM_REQ_SUSPEND:
 		rpm_suspend(dev, RPM_NOWAIT);
 		break;
+	case RPM_REQ_AUTOSUSPEND:
+		rpm_suspend(dev, RPM_NOWAIT | RPM_AUTO);
+		break;
 	case RPM_REQ_RESUME:
 		rpm_resume(dev, RPM_NOWAIT);
 		break;
@@ -595,7 +678,8 @@ static void pm_suspend_timer_fn(unsigned long data)
 	/* If 'expire' is after 'jiffies' we've been called too early. */
 	if (expires > 0 && !time_after(expires, jiffies)) {
 		dev->power.timer_expires = 0;
-		rpm_suspend(dev, RPM_ASYNC);
+		rpm_suspend(dev, dev->power.timer_autosuspends ?
+		    (RPM_ASYNC | RPM_AUTO) : RPM_ASYNC);
 	}
 
 	spin_unlock_irqrestore(&dev->power.lock, flags);
@@ -627,6 +711,7 @@ int pm_schedule_suspend(struct device *dev, unsigned int delay)
 
 	dev->power.timer_expires = jiffies + msecs_to_jiffies(delay);
 	dev->power.timer_expires += !dev->power.timer_expires;
+	dev->power.timer_autosuspends = 0;
 	mod_timer(&dev->power.suspend_timer, dev->power.timer_expires);
 
  out:
@@ -670,7 +755,9 @@ EXPORT_SYMBOL_GPL(__pm_runtime_idle);
  * @dev: Device to suspend.
  * @rpmflags: Flag bits.
  *
- * Carry out a suspend, either synchronous or asynchronous.
+ * If the RPM_GET_PUT flag is set, decrement the device's usage count and
+ * return immediately if it is larger than zero.  Then carry out a suspend,
+ * either synchronous or asynchronous.
  *
  * This routine may be called in atomic context if the RPM_ASYNC flag is set.
  */
@@ -679,6 +766,11 @@ int __pm_runtime_suspend(struct device *dev, int rpmflags)
 	unsigned long flags;
 	int retval;
 
+	if (rpmflags & RPM_GET_PUT) {
+		if (!atomic_dec_and_test(&dev->power.usage_count))
+			return 0;
+	}
+
 	spin_lock_irqsave(&dev->power.lock, flags);
 	retval = rpm_suspend(dev, rpmflags);
 	spin_unlock_irqrestore(&dev->power.lock, flags);
@@ -980,7 +1072,7 @@ void pm_runtime_allow(struct device *dev)
 
 	dev->power.runtime_auto = true;
 	if (atomic_dec_and_test(&dev->power.usage_count))
-		rpm_idle(dev, 0);
+		rpm_idle(dev, RPM_AUTO);
 
  out:
 	spin_unlock_irq(&dev->power.lock);
@@ -1006,6 +1098,86 @@ void pm_runtime_no_callbacks(struct device *dev)
 }
 EXPORT_SYMBOL_GPL(pm_runtime_no_callbacks);
 
+/**
+ * update_autosuspend - Handle a change to a device's autosuspend settings.
+ * @dev: Device to handle.
+ * @old_delay: The former autosuspend_delay value.
+ * @old_use: The former use_autosuspend value.
+ *
+ * Prevent runtime suspend if the new delay is negative and use_autosuspend is
+ * set; otherwise allow it.  Send an idle notification if suspends are allowed.
+ *
+ * This function must be called under dev->power.lock with interrupts disabled.
+ */
+static void update_autosuspend(struct device *dev, int old_delay, int old_use)
+{
+	int delay = dev->power.autosuspend_delay;
+
+	/* Should runtime suspend be prevented now? */
+	if (dev->power.use_autosuspend && delay < 0) {
+
+		/* If it used to be allowed then prevent it. */
+		if (!old_use || old_delay >= 0) {
+			atomic_inc(&dev->power.usage_count);
+			rpm_resume(dev, 0);
+		}
+	}
+
+	/* Runtime suspend should be allowed now. */
+	else {
+
+		/* If it used to be prevented then allow it. */
+		if (old_use && old_delay < 0)
+			atomic_dec(&dev->power.usage_count);
+
+		/* Maybe we can autosuspend now. */
+		rpm_idle(dev, RPM_AUTO);
+	}
+}
+
+/**
+ * pm_runtime_set_autosuspend_delay - Set a device's autosuspend_delay value.
+ * @dev: Device to handle.
+ * @delay: Value of the new delay in milliseconds.
+ *
+ * Set the device's power.autosuspend_delay value.  If it changes to negative
+ * and the power.use_autosuspend flag is set, prevent run-time suspends.  If it
+ * changes the other way, allow run-time suspends.
+ */
+void pm_runtime_set_autosuspend_delay(struct device *dev, int delay)
+{
+	int old_delay, old_use;
+
+	spin_lock_irq(&dev->power.lock);
+	old_delay = dev->power.autosuspend_delay;
+	old_use = dev->power.use_autosuspend;
+	dev->power.autosuspend_delay = delay;
+	update_autosuspend(dev, old_delay, old_use);
+	spin_unlock_irq(&dev->power.lock);
+}
+EXPORT_SYMBOL_GPL(pm_runtime_set_autosuspend_delay);
+
+/**
+ * __pm_runtime_use_autosuspend - Set a device's use_autosuspend flag.
+ * @dev: Device to handle.
+ * @use: New value for use_autosuspend.
+ *
+ * Set the device's power.use_autosuspend flag, and allow or prevent run-time
+ * suspends as needed.
+ */
+void __pm_runtime_use_autosuspend(struct device *dev, bool use)
+{
+	int old_delay, old_use;
+
+	spin_lock_irq(&dev->power.lock);
+	old_delay = dev->power.autosuspend_delay;
+	old_use = dev->power.use_autosuspend;
+	dev->power.use_autosuspend = use;
+	update_autosuspend(dev, old_delay, old_use);
+	spin_unlock_irq(&dev->power.lock);
+}
+EXPORT_SYMBOL_GPL(__pm_runtime_use_autosuspend);
+
 /**
  * pm_runtime_init - Initialize run-time PM fields in given device object.
  * @dev: Device object to initialize.

commit 7490e44239e60293bca0c2663229050c36c660c2
Author: Alan Stern <stern@rowland.harvard.edu>
Date:   Sat Sep 25 23:35:15 2010 +0200

    PM / Runtime: Add no_callbacks flag
    
    Some devices, such as USB interfaces, cannot be power-managed
    independently of their parents, i.e., they cannot be put in low power
    while the parent remains at full power.  This patch (as1425) creates a
    new "no_callbacks" flag, which tells the PM core not to invoke the
    runtime-PM callback routines for the such devices but instead to
    assume that the callbacks always succeed.  In addition, the
    non-debugging runtime-PM sysfs attributes for the devices are removed,
    since they are pretty much meaningless.
    
    The advantage of this scheme comes not so much from avoiding the
    callbacks themselves, but rather from the fact that without the need
    for a process context in which to run the callbacks, more work can be
    done in interrupt context.
    
    Signed-off-by: Alan Stern <stern@rowland.harvard.edu>
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index ed227b7c1bb5..5bd4daa93ef1 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -10,8 +10,10 @@
 #include <linux/sched.h>
 #include <linux/pm_runtime.h>
 #include <linux/jiffies.h>
+#include "power.h"
 
 static int rpm_resume(struct device *dev, int rpmflags);
+static int rpm_suspend(struct device *dev, int rpmflags);
 
 /**
  * update_pm_runtime_accounting - Update the time accounting of power states
@@ -148,6 +150,12 @@ static int rpm_idle(struct device *dev, int rpmflags)
 	/* Pending requests need to be canceled. */
 	dev->power.request = RPM_REQ_NONE;
 
+	if (dev->power.no_callbacks) {
+		/* Assume ->runtime_idle() callback would have suspended. */
+		retval = rpm_suspend(dev, rpmflags);
+		goto out;
+	}
+
 	/* Carry out an asynchronous or a synchronous idle notification. */
 	if (rpmflags & RPM_ASYNC) {
 		dev->power.request = RPM_REQ_IDLE;
@@ -254,6 +262,10 @@ static int rpm_suspend(struct device *dev, int rpmflags)
 		goto repeat;
 	}
 
+	dev->power.deferred_resume = false;
+	if (dev->power.no_callbacks)
+		goto no_callback;	/* Assume success. */
+
 	/* Carry out an asynchronous or a synchronous suspend. */
 	if (rpmflags & RPM_ASYNC) {
 		dev->power.request = RPM_REQ_SUSPEND;
@@ -265,7 +277,6 @@ static int rpm_suspend(struct device *dev, int rpmflags)
 	}
 
 	__update_runtime_status(dev, RPM_SUSPENDING);
-	dev->power.deferred_resume = false;
 
 	if (dev->bus && dev->bus->pm && dev->bus->pm->runtime_suspend) {
 		spin_unlock_irq(&dev->power.lock);
@@ -305,6 +316,7 @@ static int rpm_suspend(struct device *dev, int rpmflags)
 			pm_runtime_cancel_pending(dev);
 		}
 	} else {
+ no_callback:
 		__update_runtime_status(dev, RPM_SUSPENDED);
 		pm_runtime_deactivate_timer(dev);
 
@@ -409,6 +421,23 @@ static int rpm_resume(struct device *dev, int rpmflags)
 		goto repeat;
 	}
 
+	/*
+	 * See if we can skip waking up the parent.  This is safe only if
+	 * power.no_callbacks is set, because otherwise we don't know whether
+	 * the resume will actually succeed.
+	 */
+	if (dev->power.no_callbacks && !parent && dev->parent) {
+		spin_lock(&dev->parent->power.lock);
+		if (dev->parent->power.disable_depth > 0
+		    || dev->parent->power.ignore_children
+		    || dev->parent->power.runtime_status == RPM_ACTIVE) {
+			atomic_inc(&dev->parent->power.child_count);
+			spin_unlock(&dev->parent->power.lock);
+			goto no_callback;	/* Assume success. */
+		}
+		spin_unlock(&dev->parent->power.lock);
+	}
+
 	/* Carry out an asynchronous or a synchronous resume. */
 	if (rpmflags & RPM_ASYNC) {
 		dev->power.request = RPM_REQ_RESUME;
@@ -449,6 +478,9 @@ static int rpm_resume(struct device *dev, int rpmflags)
 		goto repeat;
 	}
 
+	if (dev->power.no_callbacks)
+		goto no_callback;	/* Assume success. */
+
 	__update_runtime_status(dev, RPM_RESUMING);
 
 	if (dev->bus && dev->bus->pm && dev->bus->pm->runtime_resume) {
@@ -482,6 +514,7 @@ static int rpm_resume(struct device *dev, int rpmflags)
 		__update_runtime_status(dev, RPM_SUSPENDED);
 		pm_runtime_cancel_pending(dev);
 	} else {
+ no_callback:
 		__update_runtime_status(dev, RPM_ACTIVE);
 		if (parent)
 			atomic_inc(&parent->power.child_count);
@@ -954,6 +987,25 @@ void pm_runtime_allow(struct device *dev)
 }
 EXPORT_SYMBOL_GPL(pm_runtime_allow);
 
+/**
+ * pm_runtime_no_callbacks - Ignore run-time PM callbacks for a device.
+ * @dev: Device to handle.
+ *
+ * Set the power.no_callbacks flag, which tells the PM core that this
+ * device is power-managed through its parent and has no run-time PM
+ * callbacks of its own.  The run-time sysfs attributes will be removed.
+ *
+ */
+void pm_runtime_no_callbacks(struct device *dev)
+{
+	spin_lock_irq(&dev->power.lock);
+	dev->power.no_callbacks = 1;
+	spin_unlock_irq(&dev->power.lock);
+	if (device_is_registered(dev))
+		rpm_sysfs_remove(dev);
+}
+EXPORT_SYMBOL_GPL(pm_runtime_no_callbacks);
+
 /**
  * pm_runtime_init - Initialize run-time PM fields in given device object.
  * @dev: Device object to initialize.

commit 140a6c945211ee911dec776fafa52e03a7d7bb9a
Author: Alan Stern <stern@rowland.harvard.edu>
Date:   Sat Sep 25 23:35:07 2010 +0200

    PM / Runtime: Combine runtime PM entry points
    
    This patch (as1424) combines the various public entry points for the
    runtime PM routines into three simple functions: one for idle, one for
    suspend, and one for resume.  A new bitflag specifies whether or not
    to increment or decrement the usage_count field.
    
    The new entry points are named __pm_runtime_idle,
    __pm_runtime_suspend, and __pm_runtime_resume, to reflect that they
    are trampolines.  Simultaneously, the corresponding internal routines
    are renamed to rpm_idle, rpm_suspend, and rpm_resume.
    
    Signed-off-by: Alan Stern <stern@rowland.harvard.edu>
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index d7b5d84c235c..ed227b7c1bb5 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -11,7 +11,7 @@
 #include <linux/pm_runtime.h>
 #include <linux/jiffies.h>
 
-static int __pm_runtime_resume(struct device *dev, int rpmflags);
+static int rpm_resume(struct device *dev, int rpmflags);
 
 /**
  * update_pm_runtime_accounting - Update the time accounting of power states
@@ -107,7 +107,7 @@ static int rpm_check_suspend_allowed(struct device *dev)
 
 
 /**
- * __pm_runtime_idle - Notify device bus type if the device can be suspended.
+ * rpm_idle - Notify device bus type if the device can be suspended.
  * @dev: Device to notify the bus type about.
  * @rpmflags: Flag bits.
  *
@@ -118,7 +118,7 @@ static int rpm_check_suspend_allowed(struct device *dev)
  *
  * This function must be called under dev->power.lock with interrupts disabled.
  */
-static int __pm_runtime_idle(struct device *dev, int rpmflags)
+static int rpm_idle(struct device *dev, int rpmflags)
 	__releases(&dev->power.lock) __acquires(&dev->power.lock)
 {
 	int retval;
@@ -189,23 +189,7 @@ static int __pm_runtime_idle(struct device *dev, int rpmflags)
 }
 
 /**
- * pm_runtime_idle - Notify device bus type if the device can be suspended.
- * @dev: Device to notify the bus type about.
- */
-int pm_runtime_idle(struct device *dev)
-{
-	int retval;
-
-	spin_lock_irq(&dev->power.lock);
-	retval = __pm_runtime_idle(dev, 0);
-	spin_unlock_irq(&dev->power.lock);
-
-	return retval;
-}
-EXPORT_SYMBOL_GPL(pm_runtime_idle);
-
-/**
- * __pm_runtime_suspend - Carry out run-time suspend of given device.
+ * rpm_suspend - Carry out run-time suspend of given device.
  * @dev: Device to suspend.
  * @rpmflags: Flag bits.
  *
@@ -220,7 +204,7 @@ EXPORT_SYMBOL_GPL(pm_runtime_idle);
  *
  * This function must be called under dev->power.lock with interrupts disabled.
  */
-static int __pm_runtime_suspend(struct device *dev, int rpmflags)
+static int rpm_suspend(struct device *dev, int rpmflags)
 	__releases(&dev->power.lock) __acquires(&dev->power.lock)
 {
 	struct device *parent = NULL;
@@ -332,13 +316,13 @@ static int __pm_runtime_suspend(struct device *dev, int rpmflags)
 	wake_up_all(&dev->power.wait_queue);
 
 	if (dev->power.deferred_resume) {
-		__pm_runtime_resume(dev, 0);
+		rpm_resume(dev, 0);
 		retval = -EAGAIN;
 		goto out;
 	}
 
 	if (notify)
-		__pm_runtime_idle(dev, 0);
+		rpm_idle(dev, 0);
 
 	if (parent && !parent->power.ignore_children) {
 		spin_unlock_irq(&dev->power.lock);
@@ -355,23 +339,7 @@ static int __pm_runtime_suspend(struct device *dev, int rpmflags)
 }
 
 /**
- * pm_runtime_suspend - Carry out run-time suspend of given device.
- * @dev: Device to suspend.
- */
-int pm_runtime_suspend(struct device *dev)
-{
-	int retval;
-
-	spin_lock_irq(&dev->power.lock);
-	retval = __pm_runtime_suspend(dev, 0);
-	spin_unlock_irq(&dev->power.lock);
-
-	return retval;
-}
-EXPORT_SYMBOL_GPL(pm_runtime_suspend);
-
-/**
- * __pm_runtime_resume - Carry out run-time resume of given device.
+ * rpm_resume - Carry out run-time resume of given device.
  * @dev: Device to resume.
  * @rpmflags: Flag bits.
  *
@@ -387,7 +355,7 @@ EXPORT_SYMBOL_GPL(pm_runtime_suspend);
  *
  * This function must be called under dev->power.lock with interrupts disabled.
  */
-static int __pm_runtime_resume(struct device *dev, int rpmflags)
+static int rpm_resume(struct device *dev, int rpmflags)
 	__releases(&dev->power.lock) __acquires(&dev->power.lock)
 {
 	struct device *parent = NULL;
@@ -469,7 +437,7 @@ static int __pm_runtime_resume(struct device *dev, int rpmflags)
 		 */
 		if (!parent->power.disable_depth
 		    && !parent->power.ignore_children) {
-			__pm_runtime_resume(parent, 0);
+			rpm_resume(parent, 0);
 			if (parent->power.runtime_status != RPM_ACTIVE)
 				retval = -EBUSY;
 		}
@@ -521,7 +489,7 @@ static int __pm_runtime_resume(struct device *dev, int rpmflags)
 	wake_up_all(&dev->power.wait_queue);
 
 	if (!retval)
-		__pm_runtime_idle(dev, RPM_ASYNC);
+		rpm_idle(dev, RPM_ASYNC);
 
  out:
 	if (parent) {
@@ -537,22 +505,6 @@ static int __pm_runtime_resume(struct device *dev, int rpmflags)
 	return retval;
 }
 
-/**
- * pm_runtime_resume - Carry out run-time resume of given device.
- * @dev: Device to suspend.
- */
-int pm_runtime_resume(struct device *dev)
-{
-	int retval;
-
-	spin_lock_irq(&dev->power.lock);
-	retval = __pm_runtime_resume(dev, 0);
-	spin_unlock_irq(&dev->power.lock);
-
-	return retval;
-}
-EXPORT_SYMBOL_GPL(pm_runtime_resume);
-
 /**
  * pm_runtime_work - Universal run-time PM work function.
  * @work: Work structure used for scheduling the execution of this function.
@@ -578,13 +530,13 @@ static void pm_runtime_work(struct work_struct *work)
 	case RPM_REQ_NONE:
 		break;
 	case RPM_REQ_IDLE:
-		__pm_runtime_idle(dev, RPM_NOWAIT);
+		rpm_idle(dev, RPM_NOWAIT);
 		break;
 	case RPM_REQ_SUSPEND:
-		__pm_runtime_suspend(dev, RPM_NOWAIT);
+		rpm_suspend(dev, RPM_NOWAIT);
 		break;
 	case RPM_REQ_RESUME:
-		__pm_runtime_resume(dev, RPM_NOWAIT);
+		rpm_resume(dev, RPM_NOWAIT);
 		break;
 	}
 
@@ -592,23 +544,6 @@ static void pm_runtime_work(struct work_struct *work)
 	spin_unlock_irq(&dev->power.lock);
 }
 
-/**
- * pm_request_idle - Submit an idle notification request for given device.
- * @dev: Device to handle.
- */
-int pm_request_idle(struct device *dev)
-{
-	unsigned long flags;
-	int retval;
-
-	spin_lock_irqsave(&dev->power.lock, flags);
-	retval = __pm_runtime_idle(dev, RPM_ASYNC);
-	spin_unlock_irqrestore(&dev->power.lock, flags);
-
-	return retval;
-}
-EXPORT_SYMBOL_GPL(pm_request_idle);
-
 /**
  * pm_suspend_timer_fn - Timer function for pm_schedule_suspend().
  * @data: Device pointer passed by pm_schedule_suspend().
@@ -627,7 +562,7 @@ static void pm_suspend_timer_fn(unsigned long data)
 	/* If 'expire' is after 'jiffies' we've been called too early. */
 	if (expires > 0 && !time_after(expires, jiffies)) {
 		dev->power.timer_expires = 0;
-		__pm_runtime_suspend(dev, RPM_ASYNC);
+		rpm_suspend(dev, RPM_ASYNC);
 	}
 
 	spin_unlock_irqrestore(&dev->power.lock, flags);
@@ -646,7 +581,7 @@ int pm_schedule_suspend(struct device *dev, unsigned int delay)
 	spin_lock_irqsave(&dev->power.lock, flags);
 
 	if (!delay) {
-		retval = __pm_runtime_suspend(dev, RPM_ASYNC);
+		retval = rpm_suspend(dev, RPM_ASYNC);
 		goto out;
 	}
 
@@ -669,62 +604,81 @@ int pm_schedule_suspend(struct device *dev, unsigned int delay)
 EXPORT_SYMBOL_GPL(pm_schedule_suspend);
 
 /**
- * pm_request_resume - Submit a resume request for given device.
- * @dev: Device to resume.
+ * __pm_runtime_idle - Entry point for run-time idle operations.
+ * @dev: Device to send idle notification for.
+ * @rpmflags: Flag bits.
+ *
+ * If the RPM_GET_PUT flag is set, decrement the device's usage count and
+ * return immediately if it is larger than zero.  Then carry out an idle
+ * notification, either synchronous or asynchronous.
+ *
+ * This routine may be called in atomic context if the RPM_ASYNC flag is set.
  */
-int pm_request_resume(struct device *dev)
+int __pm_runtime_idle(struct device *dev, int rpmflags)
 {
 	unsigned long flags;
 	int retval;
 
+	if (rpmflags & RPM_GET_PUT) {
+		if (!atomic_dec_and_test(&dev->power.usage_count))
+			return 0;
+	}
+
 	spin_lock_irqsave(&dev->power.lock, flags);
-	retval = __pm_runtime_resume(dev, RPM_ASYNC);
+	retval = rpm_idle(dev, rpmflags);
 	spin_unlock_irqrestore(&dev->power.lock, flags);
 
 	return retval;
 }
-EXPORT_SYMBOL_GPL(pm_request_resume);
+EXPORT_SYMBOL_GPL(__pm_runtime_idle);
 
 /**
- * __pm_runtime_get - Reference count a device and wake it up, if necessary.
- * @dev: Device to handle.
+ * __pm_runtime_suspend - Entry point for run-time put/suspend operations.
+ * @dev: Device to suspend.
  * @rpmflags: Flag bits.
  *
- * Increment the usage count of the device and resume it or submit a resume
- * request for it, depending on the RPM_ASYNC flag bit.
+ * Carry out a suspend, either synchronous or asynchronous.
+ *
+ * This routine may be called in atomic context if the RPM_ASYNC flag is set.
  */
-int __pm_runtime_get(struct device *dev, int rpmflags)
+int __pm_runtime_suspend(struct device *dev, int rpmflags)
 {
+	unsigned long flags;
 	int retval;
 
-	atomic_inc(&dev->power.usage_count);
-	retval = (rpmflags & RPM_ASYNC) ?
-	    pm_request_resume(dev) : pm_runtime_resume(dev);
+	spin_lock_irqsave(&dev->power.lock, flags);
+	retval = rpm_suspend(dev, rpmflags);
+	spin_unlock_irqrestore(&dev->power.lock, flags);
 
 	return retval;
 }
-EXPORT_SYMBOL_GPL(__pm_runtime_get);
+EXPORT_SYMBOL_GPL(__pm_runtime_suspend);
 
 /**
- * __pm_runtime_put - Decrement the device's usage counter and notify its bus.
- * @dev: Device to handle.
+ * __pm_runtime_resume - Entry point for run-time resume operations.
+ * @dev: Device to resume.
  * @rpmflags: Flag bits.
  *
- * Decrement the usage count of the device and if it reaches zero, carry out a
- * synchronous idle notification or submit an idle notification request for it,
- * depending on the RPM_ASYNC flag bit.
+ * If the RPM_GET_PUT flag is set, increment the device's usage count.  Then
+ * carry out a resume, either synchronous or asynchronous.
+ *
+ * This routine may be called in atomic context if the RPM_ASYNC flag is set.
  */
-int __pm_runtime_put(struct device *dev, int rpmflags)
+int __pm_runtime_resume(struct device *dev, int rpmflags)
 {
-	int retval = 0;
+	unsigned long flags;
+	int retval;
 
-	if (atomic_dec_and_test(&dev->power.usage_count))
-		retval = (rpmflags & RPM_ASYNC) ?
-		    pm_request_idle(dev) : pm_runtime_idle(dev);
+	if (rpmflags & RPM_GET_PUT)
+		atomic_inc(&dev->power.usage_count);
+
+	spin_lock_irqsave(&dev->power.lock, flags);
+	retval = rpm_resume(dev, rpmflags);
+	spin_unlock_irqrestore(&dev->power.lock, flags);
 
 	return retval;
 }
-EXPORT_SYMBOL_GPL(__pm_runtime_put);
+EXPORT_SYMBOL_GPL(__pm_runtime_resume);
 
 /**
  * __pm_runtime_set_status - Set run-time PM status of a device.
@@ -875,7 +829,7 @@ int pm_runtime_barrier(struct device *dev)
 
 	if (dev->power.request_pending
 	    && dev->power.request == RPM_REQ_RESUME) {
-		__pm_runtime_resume(dev, 0);
+		rpm_resume(dev, 0);
 		retval = 1;
 	}
 
@@ -924,7 +878,7 @@ void __pm_runtime_disable(struct device *dev, bool check_resume)
 		 */
 		pm_runtime_get_noresume(dev);
 
-		__pm_runtime_resume(dev, 0);
+		rpm_resume(dev, 0);
 
 		pm_runtime_put_noidle(dev);
 	}
@@ -972,7 +926,7 @@ void pm_runtime_forbid(struct device *dev)
 
 	dev->power.runtime_auto = false;
 	atomic_inc(&dev->power.usage_count);
-	__pm_runtime_resume(dev, 0);
+	rpm_resume(dev, 0);
 
  out:
 	spin_unlock_irq(&dev->power.lock);
@@ -993,7 +947,7 @@ void pm_runtime_allow(struct device *dev)
 
 	dev->power.runtime_auto = true;
 	if (atomic_dec_and_test(&dev->power.usage_count))
-		__pm_runtime_idle(dev, 0);
+		rpm_idle(dev, 0);
 
  out:
 	spin_unlock_irq(&dev->power.lock);

commit 1bfee5bc86fdaecc912e06080583eddab7263df2
Author: Alan Stern <stern@rowland.harvard.edu>
Date:   Sat Sep 25 23:35:00 2010 +0200

    PM / Runtime: Merge synchronous and async runtime routines
    
    This patch (as1423) merges the asynchronous routines
    __pm_request_idle(), __pm_request_suspend(), and __pm_request_resume()
    with their synchronous counterparts.  The RPM_ASYNC bitflag argument
    serves to indicate what sort of operation to perform.
    
    In the course of performing this merger, it became apparent that the
    various functions don't all behave consistenly with regard to error
    reporting and cancellation of outstanding requests.  A new routine,
    rpm_check_suspend_allowed(), was written to centralize much of the
    testing, and the other functions were revised to follow a simple
    algorithm:
    
            If the operation is disallowed because of the device's
            settings or current state, return an error.
    
            Cancel pending or scheduled requests of lower priority.
    
            Schedule, queue, or perform the desired operation.
    
    A few special cases and exceptions are noted in comments.
    
    Signed-off-by: Alan Stern <stern@rowland.harvard.edu>
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 0c1db879544b..d7b5d84c235c 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -2,6 +2,7 @@
  * drivers/base/power/runtime.c - Helper functions for device run-time PM
  *
  * Copyright (c) 2009 Rafael J. Wysocki <rjw@sisk.pl>, Novell Inc.
+ * Copyright (C) 2010 Alan Stern <stern@rowland.harvard.edu>
  *
  * This file is released under the GPLv2.
  */
@@ -11,8 +12,6 @@
 #include <linux/jiffies.h>
 
 static int __pm_runtime_resume(struct device *dev, int rpmflags);
-static int __pm_request_idle(struct device *dev);
-static int __pm_request_resume(struct device *dev);
 
 /**
  * update_pm_runtime_accounting - Update the time accounting of power states
@@ -79,40 +78,84 @@ static void pm_runtime_cancel_pending(struct device *dev)
 }
 
 /**
- * __pm_runtime_idle - Notify device bus type if the device can be suspended.
- * @dev: Device to notify the bus type about.
- *
- * This function must be called under dev->power.lock with interrupts disabled.
+ * rpm_check_suspend_allowed - Test whether a device may be suspended.
+ * @dev: Device to test.
  */
-static int __pm_runtime_idle(struct device *dev)
-	__releases(&dev->power.lock) __acquires(&dev->power.lock)
+static int rpm_check_suspend_allowed(struct device *dev)
 {
 	int retval = 0;
 
 	if (dev->power.runtime_error)
 		retval = -EINVAL;
-	else if (dev->power.idle_notification)
-		retval = -EINPROGRESS;
 	else if (atomic_read(&dev->power.usage_count) > 0
-	    || dev->power.disable_depth > 0
-	    || dev->power.runtime_status != RPM_ACTIVE)
+	    || dev->power.disable_depth > 0)
 		retval = -EAGAIN;
 	else if (!pm_children_suspended(dev))
 		retval = -EBUSY;
+
+	/* Pending resume requests take precedence over suspends. */
+	else if ((dev->power.deferred_resume
+			&& dev->power.status == RPM_SUSPENDING)
+	    || (dev->power.request_pending
+			&& dev->power.request == RPM_REQ_RESUME))
+		retval = -EAGAIN;
+	else if (dev->power.runtime_status == RPM_SUSPENDED)
+		retval = 1;
+
+	return retval;
+}
+
+
+/**
+ * __pm_runtime_idle - Notify device bus type if the device can be suspended.
+ * @dev: Device to notify the bus type about.
+ * @rpmflags: Flag bits.
+ *
+ * Check if the device's run-time PM status allows it to be suspended.  If
+ * another idle notification has been started earlier, return immediately.  If
+ * the RPM_ASYNC flag is set then queue an idle-notification request; otherwise
+ * run the ->runtime_idle() callback directly.
+ *
+ * This function must be called under dev->power.lock with interrupts disabled.
+ */
+static int __pm_runtime_idle(struct device *dev, int rpmflags)
+	__releases(&dev->power.lock) __acquires(&dev->power.lock)
+{
+	int retval;
+
+	retval = rpm_check_suspend_allowed(dev);
+	if (retval < 0)
+		;	/* Conditions are wrong. */
+
+	/* Idle notifications are allowed only in the RPM_ACTIVE state. */
+	else if (dev->power.runtime_status != RPM_ACTIVE)
+		retval = -EAGAIN;
+
+	/*
+	 * Any pending request other than an idle notification takes
+	 * precedence over us, except that the timer may be running.
+	 */
+	else if (dev->power.request_pending &&
+	    dev->power.request > RPM_REQ_IDLE)
+		retval = -EAGAIN;
+
+	/* Act as though RPM_NOWAIT is always set. */
+	else if (dev->power.idle_notification)
+		retval = -EINPROGRESS;
 	if (retval)
 		goto out;
 
-	if (dev->power.request_pending) {
-		/*
-		 * If an idle notification request is pending, cancel it.  Any
-		 * other pending request takes precedence over us.
-		 */
-		if (dev->power.request == RPM_REQ_IDLE) {
-			dev->power.request = RPM_REQ_NONE;
-		} else if (dev->power.request != RPM_REQ_NONE) {
-			retval = -EAGAIN;
-			goto out;
+	/* Pending requests need to be canceled. */
+	dev->power.request = RPM_REQ_NONE;
+
+	/* Carry out an asynchronous or a synchronous idle notification. */
+	if (rpmflags & RPM_ASYNC) {
+		dev->power.request = RPM_REQ_IDLE;
+		if (!dev->power.request_pending) {
+			dev->power.request_pending = true;
+			queue_work(pm_wq, &dev->power.work);
 		}
+		goto out;
 	}
 
 	dev->power.idle_notification = true;
@@ -154,7 +197,7 @@ int pm_runtime_idle(struct device *dev)
 	int retval;
 
 	spin_lock_irq(&dev->power.lock);
-	retval = __pm_runtime_idle(dev);
+	retval = __pm_runtime_idle(dev, 0);
 	spin_unlock_irq(&dev->power.lock);
 
 	return retval;
@@ -166,11 +209,14 @@ EXPORT_SYMBOL_GPL(pm_runtime_idle);
  * @dev: Device to suspend.
  * @rpmflags: Flag bits.
  *
- * Check if the device can be suspended and run the ->runtime_suspend() callback
- * provided by its bus type.  If another suspend has been started earlier,
- * either return immediately or wait for it to finish, depending on the
- * RPM_NOWAIT flag.  If an idle notification or suspend request is pending or
- * scheduled, cancel it.
+ * Check if the device's run-time PM status allows it to be suspended.  If
+ * another suspend has been started earlier, either return immediately or wait
+ * for it to finish, depending on the RPM_NOWAIT and RPM_ASYNC flags.  Cancel a
+ * pending idle notification.  If the RPM_ASYNC flag is set then queue a
+ * suspend request; otherwise run the ->runtime_suspend() callback directly.
+ * If a deferred resume was requested while the callback was running then carry
+ * it out; otherwise send an idle notification for the device (if the suspend
+ * failed) or for its parent (if the suspend succeeded).
  *
  * This function must be called under dev->power.lock with interrupts disabled.
  */
@@ -179,41 +225,30 @@ static int __pm_runtime_suspend(struct device *dev, int rpmflags)
 {
 	struct device *parent = NULL;
 	bool notify = false;
-	int retval = 0;
+	int retval;
 
 	dev_dbg(dev, "%s flags 0x%x\n", __func__, rpmflags);
 
  repeat:
-	if (dev->power.runtime_error) {
-		retval = -EINVAL;
-		goto out;
-	}
+	retval = rpm_check_suspend_allowed(dev);
 
-	/* Pending resume requests take precedence over us. */
-	if (dev->power.request_pending
-	    && dev->power.request == RPM_REQ_RESUME) {
+	if (retval < 0)
+		;	/* Conditions are wrong. */
+
+	/* Synchronous suspends are not allowed in the RPM_RESUMING state. */
+	else if (dev->power.runtime_status == RPM_RESUMING &&
+	    !(rpmflags & RPM_ASYNC))
 		retval = -EAGAIN;
+	if (retval)
 		goto out;
-	}
 
 	/* Other scheduled or pending requests need to be canceled. */
 	pm_runtime_cancel_pending(dev);
 
-	if (dev->power.runtime_status == RPM_SUSPENDED)
-		retval = 1;
-	else if (dev->power.runtime_status == RPM_RESUMING
-	    || dev->power.disable_depth > 0
-	    || atomic_read(&dev->power.usage_count) > 0)
-		retval = -EAGAIN;
-	else if (!pm_children_suspended(dev))
-		retval = -EBUSY;
-	if (retval)
-		goto out;
-
 	if (dev->power.runtime_status == RPM_SUSPENDING) {
 		DEFINE_WAIT(wait);
 
-		if (rpmflags & RPM_NOWAIT) {
+		if (rpmflags & (RPM_ASYNC | RPM_NOWAIT)) {
 			retval = -EINPROGRESS;
 			goto out;
 		}
@@ -235,6 +270,16 @@ static int __pm_runtime_suspend(struct device *dev, int rpmflags)
 		goto repeat;
 	}
 
+	/* Carry out an asynchronous or a synchronous suspend. */
+	if (rpmflags & RPM_ASYNC) {
+		dev->power.request = RPM_REQ_SUSPEND;
+		if (!dev->power.request_pending) {
+			dev->power.request_pending = true;
+			queue_work(pm_wq, &dev->power.work);
+		}
+		goto out;
+	}
+
 	__update_runtime_status(dev, RPM_SUSPENDING);
 	dev->power.deferred_resume = false;
 
@@ -267,6 +312,7 @@ static int __pm_runtime_suspend(struct device *dev, int rpmflags)
 
 	if (retval) {
 		__update_runtime_status(dev, RPM_ACTIVE);
+		dev->power.deferred_resume = 0;
 		if (retval == -EAGAIN || retval == -EBUSY) {
 			if (dev->power.timer_expires == 0)
 				notify = true;
@@ -292,7 +338,7 @@ static int __pm_runtime_suspend(struct device *dev, int rpmflags)
 	}
 
 	if (notify)
-		__pm_runtime_idle(dev);
+		__pm_runtime_idle(dev, 0);
 
 	if (parent && !parent->power.ignore_children) {
 		spin_unlock_irq(&dev->power.lock);
@@ -329,13 +375,15 @@ EXPORT_SYMBOL_GPL(pm_runtime_suspend);
  * @dev: Device to resume.
  * @rpmflags: Flag bits.
  *
- * Check if the device can be woken up and run the ->runtime_resume() callback
- * provided by its bus type.  If another resume has been started earlier,
- * either return imediately or wait for it to finish, depending on the
- * RPM_NOWAIT flag.  If there's a suspend running in parallel with this
- * function, either tell the other process to resume after suspending
- * (deferred_resume) or wait for it to finish, depending on the RPM_NOWAIT
- * flag.  Cancel any scheduled or pending requests.
+ * Check if the device's run-time PM status allows it to be resumed.  Cancel
+ * any scheduled or pending requests.  If another resume has been started
+ * earlier, either return imediately or wait for it to finish, depending on the
+ * RPM_NOWAIT and RPM_ASYNC flags.  Similarly, if there's a suspend running in
+ * parallel with this function, either tell the other process to resume after
+ * suspending (deferred_resume) or wait for it to finish.  If the RPM_ASYNC
+ * flag is set then queue a resume request; otherwise run the
+ * ->runtime_resume() callback directly.  Queue an idle notification for the
+ * device if the resume succeeded.
  *
  * This function must be called under dev->power.lock with interrupts disabled.
  */
@@ -348,28 +396,30 @@ static int __pm_runtime_resume(struct device *dev, int rpmflags)
 	dev_dbg(dev, "%s flags 0x%x\n", __func__, rpmflags);
 
  repeat:
-	if (dev->power.runtime_error) {
+	if (dev->power.runtime_error)
 		retval = -EINVAL;
+	else if (dev->power.disable_depth > 0)
+		retval = -EAGAIN;
+	if (retval)
 		goto out;
-	}
 
+	/* Other scheduled or pending requests need to be canceled. */
 	pm_runtime_cancel_pending(dev);
 
-	if (dev->power.runtime_status == RPM_ACTIVE)
+	if (dev->power.runtime_status == RPM_ACTIVE) {
 		retval = 1;
-	else if (dev->power.disable_depth > 0)
-		retval = -EAGAIN;
-	if (retval)
 		goto out;
+	}
 
 	if (dev->power.runtime_status == RPM_RESUMING
 	    || dev->power.runtime_status == RPM_SUSPENDING) {
 		DEFINE_WAIT(wait);
 
-		if (rpmflags & RPM_NOWAIT) {
+		if (rpmflags & (RPM_ASYNC | RPM_NOWAIT)) {
 			if (dev->power.runtime_status == RPM_SUSPENDING)
 				dev->power.deferred_resume = true;
-			retval = -EINPROGRESS;
+			else
+				retval = -EINPROGRESS;
 			goto out;
 		}
 
@@ -391,6 +441,17 @@ static int __pm_runtime_resume(struct device *dev, int rpmflags)
 		goto repeat;
 	}
 
+	/* Carry out an asynchronous or a synchronous resume. */
+	if (rpmflags & RPM_ASYNC) {
+		dev->power.request = RPM_REQ_RESUME;
+		if (!dev->power.request_pending) {
+			dev->power.request_pending = true;
+			queue_work(pm_wq, &dev->power.work);
+		}
+		retval = 0;
+		goto out;
+	}
+
 	if (!parent && dev->parent) {
 		/*
 		 * Increment the parent's resume counter and resume it if
@@ -460,7 +521,7 @@ static int __pm_runtime_resume(struct device *dev, int rpmflags)
 	wake_up_all(&dev->power.wait_queue);
 
 	if (!retval)
-		__pm_request_idle(dev);
+		__pm_runtime_idle(dev, RPM_ASYNC);
 
  out:
 	if (parent) {
@@ -517,7 +578,7 @@ static void pm_runtime_work(struct work_struct *work)
 	case RPM_REQ_NONE:
 		break;
 	case RPM_REQ_IDLE:
-		__pm_runtime_idle(dev);
+		__pm_runtime_idle(dev, RPM_NOWAIT);
 		break;
 	case RPM_REQ_SUSPEND:
 		__pm_runtime_suspend(dev, RPM_NOWAIT);
@@ -531,47 +592,6 @@ static void pm_runtime_work(struct work_struct *work)
 	spin_unlock_irq(&dev->power.lock);
 }
 
-/**
- * __pm_request_idle - Submit an idle notification request for given device.
- * @dev: Device to handle.
- *
- * Check if the device's run-time PM status is correct for suspending the device
- * and queue up a request to run __pm_runtime_idle() for it.
- *
- * This function must be called under dev->power.lock with interrupts disabled.
- */
-static int __pm_request_idle(struct device *dev)
-{
-	int retval = 0;
-
-	if (dev->power.runtime_error)
-		retval = -EINVAL;
-	else if (atomic_read(&dev->power.usage_count) > 0
-	    || dev->power.disable_depth > 0
-	    || dev->power.runtime_status == RPM_SUSPENDED
-	    || dev->power.runtime_status == RPM_SUSPENDING)
-		retval = -EAGAIN;
-	else if (!pm_children_suspended(dev))
-		retval = -EBUSY;
-	if (retval)
-		return retval;
-
-	if (dev->power.request_pending) {
-		/* Any requests other then RPM_REQ_IDLE take precedence. */
-		if (dev->power.request == RPM_REQ_NONE)
-			dev->power.request = RPM_REQ_IDLE;
-		else if (dev->power.request != RPM_REQ_IDLE)
-			retval = -EAGAIN;
-		return retval;
-	}
-
-	dev->power.request = RPM_REQ_IDLE;
-	dev->power.request_pending = true;
-	queue_work(pm_wq, &dev->power.work);
-
-	return retval;
-}
-
 /**
  * pm_request_idle - Submit an idle notification request for given device.
  * @dev: Device to handle.
@@ -582,67 +602,18 @@ int pm_request_idle(struct device *dev)
 	int retval;
 
 	spin_lock_irqsave(&dev->power.lock, flags);
-	retval = __pm_request_idle(dev);
+	retval = __pm_runtime_idle(dev, RPM_ASYNC);
 	spin_unlock_irqrestore(&dev->power.lock, flags);
 
 	return retval;
 }
 EXPORT_SYMBOL_GPL(pm_request_idle);
 
-/**
- * __pm_request_suspend - Submit a suspend request for given device.
- * @dev: Device to suspend.
- *
- * This function must be called under dev->power.lock with interrupts disabled.
- */
-static int __pm_request_suspend(struct device *dev)
-{
-	int retval = 0;
-
-	if (dev->power.runtime_error)
-		return -EINVAL;
-
-	if (dev->power.runtime_status == RPM_SUSPENDED)
-		retval = 1;
-	else if (atomic_read(&dev->power.usage_count) > 0
-	    || dev->power.disable_depth > 0)
-		retval = -EAGAIN;
-	else if (dev->power.runtime_status == RPM_SUSPENDING)
-		retval = -EINPROGRESS;
-	else if (!pm_children_suspended(dev))
-		retval = -EBUSY;
-	if (retval < 0)
-		return retval;
-
-	pm_runtime_deactivate_timer(dev);
-
-	if (dev->power.request_pending) {
-		/*
-		 * Pending resume requests take precedence over us, but we can
-		 * overtake any other pending request.
-		 */
-		if (dev->power.request == RPM_REQ_RESUME)
-			retval = -EAGAIN;
-		else if (dev->power.request != RPM_REQ_SUSPEND)
-			dev->power.request = retval ?
-						RPM_REQ_NONE : RPM_REQ_SUSPEND;
-		return retval;
-	} else if (retval) {
-		return retval;
-	}
-
-	dev->power.request = RPM_REQ_SUSPEND;
-	dev->power.request_pending = true;
-	queue_work(pm_wq, &dev->power.work);
-
-	return 0;
-}
-
 /**
  * pm_suspend_timer_fn - Timer function for pm_schedule_suspend().
  * @data: Device pointer passed by pm_schedule_suspend().
  *
- * Check if the time is right and execute __pm_request_suspend() in that case.
+ * Check if the time is right and queue a suspend request.
  */
 static void pm_suspend_timer_fn(unsigned long data)
 {
@@ -656,7 +627,7 @@ static void pm_suspend_timer_fn(unsigned long data)
 	/* If 'expire' is after 'jiffies' we've been called too early. */
 	if (expires > 0 && !time_after(expires, jiffies)) {
 		dev->power.timer_expires = 0;
-		__pm_request_suspend(dev);
+		__pm_runtime_suspend(dev, RPM_ASYNC);
 	}
 
 	spin_unlock_irqrestore(&dev->power.lock, flags);
@@ -670,47 +641,24 @@ static void pm_suspend_timer_fn(unsigned long data)
 int pm_schedule_suspend(struct device *dev, unsigned int delay)
 {
 	unsigned long flags;
-	int retval = 0;
+	int retval;
 
 	spin_lock_irqsave(&dev->power.lock, flags);
 
-	if (dev->power.runtime_error) {
-		retval = -EINVAL;
-		goto out;
-	}
-
 	if (!delay) {
-		retval = __pm_request_suspend(dev);
+		retval = __pm_runtime_suspend(dev, RPM_ASYNC);
 		goto out;
 	}
 
-	pm_runtime_deactivate_timer(dev);
-
-	if (dev->power.request_pending) {
-		/*
-		 * Pending resume requests take precedence over us, but any
-		 * other pending requests have to be canceled.
-		 */
-		if (dev->power.request == RPM_REQ_RESUME) {
-			retval = -EAGAIN;
-			goto out;
-		}
-		dev->power.request = RPM_REQ_NONE;
-	}
-
-	if (dev->power.runtime_status == RPM_SUSPENDED)
-		retval = 1;
-	else if (atomic_read(&dev->power.usage_count) > 0
-	    || dev->power.disable_depth > 0)
-		retval = -EAGAIN;
-	else if (!pm_children_suspended(dev))
-		retval = -EBUSY;
+	retval = rpm_check_suspend_allowed(dev);
 	if (retval)
 		goto out;
 
+	/* Other scheduled or pending requests need to be canceled. */
+	pm_runtime_cancel_pending(dev);
+
 	dev->power.timer_expires = jiffies + msecs_to_jiffies(delay);
-	if (!dev->power.timer_expires)
-		dev->power.timer_expires = 1;
+	dev->power.timer_expires += !dev->power.timer_expires;
 	mod_timer(&dev->power.suspend_timer, dev->power.timer_expires);
 
  out:
@@ -720,49 +668,6 @@ int pm_schedule_suspend(struct device *dev, unsigned int delay)
 }
 EXPORT_SYMBOL_GPL(pm_schedule_suspend);
 
-/**
- * pm_request_resume - Submit a resume request for given device.
- * @dev: Device to resume.
- *
- * This function must be called under dev->power.lock with interrupts disabled.
- */
-static int __pm_request_resume(struct device *dev)
-{
-	int retval = 0;
-
-	if (dev->power.runtime_error)
-		return -EINVAL;
-
-	if (dev->power.runtime_status == RPM_ACTIVE)
-		retval = 1;
-	else if (dev->power.runtime_status == RPM_RESUMING)
-		retval = -EINPROGRESS;
-	else if (dev->power.disable_depth > 0)
-		retval = -EAGAIN;
-	if (retval < 0)
-		return retval;
-
-	pm_runtime_deactivate_timer(dev);
-
-	if (dev->power.runtime_status == RPM_SUSPENDING) {
-		dev->power.deferred_resume = true;
-		return retval;
-	}
-	if (dev->power.request_pending) {
-		/* If non-resume request is pending, we can overtake it. */
-		dev->power.request = retval ? RPM_REQ_NONE : RPM_REQ_RESUME;
-		return retval;
-	}
-	if (retval)
-		return retval;
-
-	dev->power.request = RPM_REQ_RESUME;
-	dev->power.request_pending = true;
-	queue_work(pm_wq, &dev->power.work);
-
-	return retval;
-}
-
 /**
  * pm_request_resume - Submit a resume request for given device.
  * @dev: Device to resume.
@@ -773,7 +678,7 @@ int pm_request_resume(struct device *dev)
 	int retval;
 
 	spin_lock_irqsave(&dev->power.lock, flags);
-	retval = __pm_request_resume(dev);
+	retval = __pm_runtime_resume(dev, RPM_ASYNC);
 	spin_unlock_irqrestore(&dev->power.lock, flags);
 
 	return retval;
@@ -1088,7 +993,7 @@ void pm_runtime_allow(struct device *dev)
 
 	dev->power.runtime_auto = true;
 	if (atomic_dec_and_test(&dev->power.usage_count))
-		__pm_runtime_idle(dev);
+		__pm_runtime_idle(dev, 0);
 
  out:
 	spin_unlock_irq(&dev->power.lock);

commit 3f9af0513ae5b1f185302c2d0ba656640926d970
Author: Alan Stern <stern@rowland.harvard.edu>
Date:   Sat Sep 25 23:34:54 2010 +0200

    PM / Runtime: Replace boolean arguments with bitflags
    
    The "from_wq" argument in __pm_runtime_suspend() and
    __pm_runtime_resume() supposedly indicates whether or not the function
    was called by the PM workqueue thread, but in fact it isn't always
    used this way.  It really indicates whether or not the function should
    return early if the requested operation is already in progress.
    
    Along with this badly-named boolean argument, later patches in this
    series will add several other boolean arguments to these functions and
    others.  Therefore this patch (as1422) begins the conversion process
    by replacing from_wq with a bitflag argument.  The same bitflags are
    also used in __pm_runtime_get() and __pm_runtime_put(), where they
    indicate whether or not the operation should be asynchronous.
    
    Signed-off-by: Alan Stern <stern@rowland.harvard.edu>
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index ec08f1ae63f1..0c1db879544b 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -10,7 +10,7 @@
 #include <linux/pm_runtime.h>
 #include <linux/jiffies.h>
 
-static int __pm_runtime_resume(struct device *dev, bool from_wq);
+static int __pm_runtime_resume(struct device *dev, int rpmflags);
 static int __pm_request_idle(struct device *dev);
 static int __pm_request_resume(struct device *dev);
 
@@ -164,24 +164,24 @@ EXPORT_SYMBOL_GPL(pm_runtime_idle);
 /**
  * __pm_runtime_suspend - Carry out run-time suspend of given device.
  * @dev: Device to suspend.
- * @from_wq: If set, the function has been called via pm_wq.
+ * @rpmflags: Flag bits.
  *
  * Check if the device can be suspended and run the ->runtime_suspend() callback
- * provided by its bus type.  If another suspend has been started earlier, wait
- * for it to finish.  If an idle notification or suspend request is pending or
+ * provided by its bus type.  If another suspend has been started earlier,
+ * either return immediately or wait for it to finish, depending on the
+ * RPM_NOWAIT flag.  If an idle notification or suspend request is pending or
  * scheduled, cancel it.
  *
  * This function must be called under dev->power.lock with interrupts disabled.
  */
-int __pm_runtime_suspend(struct device *dev, bool from_wq)
+static int __pm_runtime_suspend(struct device *dev, int rpmflags)
 	__releases(&dev->power.lock) __acquires(&dev->power.lock)
 {
 	struct device *parent = NULL;
 	bool notify = false;
 	int retval = 0;
 
-	dev_dbg(dev, "__pm_runtime_suspend()%s!\n",
-		from_wq ? " from workqueue" : "");
+	dev_dbg(dev, "%s flags 0x%x\n", __func__, rpmflags);
 
  repeat:
 	if (dev->power.runtime_error) {
@@ -213,7 +213,7 @@ int __pm_runtime_suspend(struct device *dev, bool from_wq)
 	if (dev->power.runtime_status == RPM_SUSPENDING) {
 		DEFINE_WAIT(wait);
 
-		if (from_wq) {
+		if (rpmflags & RPM_NOWAIT) {
 			retval = -EINPROGRESS;
 			goto out;
 		}
@@ -286,7 +286,7 @@ int __pm_runtime_suspend(struct device *dev, bool from_wq)
 	wake_up_all(&dev->power.wait_queue);
 
 	if (dev->power.deferred_resume) {
-		__pm_runtime_resume(dev, false);
+		__pm_runtime_resume(dev, 0);
 		retval = -EAGAIN;
 		goto out;
 	}
@@ -303,7 +303,7 @@ int __pm_runtime_suspend(struct device *dev, bool from_wq)
 	}
 
  out:
-	dev_dbg(dev, "__pm_runtime_suspend() returns %d!\n", retval);
+	dev_dbg(dev, "%s returns %d\n", __func__, retval);
 
 	return retval;
 }
@@ -317,7 +317,7 @@ int pm_runtime_suspend(struct device *dev)
 	int retval;
 
 	spin_lock_irq(&dev->power.lock);
-	retval = __pm_runtime_suspend(dev, false);
+	retval = __pm_runtime_suspend(dev, 0);
 	spin_unlock_irq(&dev->power.lock);
 
 	return retval;
@@ -327,24 +327,25 @@ EXPORT_SYMBOL_GPL(pm_runtime_suspend);
 /**
  * __pm_runtime_resume - Carry out run-time resume of given device.
  * @dev: Device to resume.
- * @from_wq: If set, the function has been called via pm_wq.
+ * @rpmflags: Flag bits.
  *
  * Check if the device can be woken up and run the ->runtime_resume() callback
- * provided by its bus type.  If another resume has been started earlier, wait
- * for it to finish.  If there's a suspend running in parallel with this
- * function, wait for it to finish and resume the device.  Cancel any scheduled
- * or pending requests.
+ * provided by its bus type.  If another resume has been started earlier,
+ * either return imediately or wait for it to finish, depending on the
+ * RPM_NOWAIT flag.  If there's a suspend running in parallel with this
+ * function, either tell the other process to resume after suspending
+ * (deferred_resume) or wait for it to finish, depending on the RPM_NOWAIT
+ * flag.  Cancel any scheduled or pending requests.
  *
  * This function must be called under dev->power.lock with interrupts disabled.
  */
-int __pm_runtime_resume(struct device *dev, bool from_wq)
+static int __pm_runtime_resume(struct device *dev, int rpmflags)
 	__releases(&dev->power.lock) __acquires(&dev->power.lock)
 {
 	struct device *parent = NULL;
 	int retval = 0;
 
-	dev_dbg(dev, "__pm_runtime_resume()%s!\n",
-		from_wq ? " from workqueue" : "");
+	dev_dbg(dev, "%s flags 0x%x\n", __func__, rpmflags);
 
  repeat:
 	if (dev->power.runtime_error) {
@@ -365,7 +366,7 @@ int __pm_runtime_resume(struct device *dev, bool from_wq)
 	    || dev->power.runtime_status == RPM_SUSPENDING) {
 		DEFINE_WAIT(wait);
 
-		if (from_wq) {
+		if (rpmflags & RPM_NOWAIT) {
 			if (dev->power.runtime_status == RPM_SUSPENDING)
 				dev->power.deferred_resume = true;
 			retval = -EINPROGRESS;
@@ -407,7 +408,7 @@ int __pm_runtime_resume(struct device *dev, bool from_wq)
 		 */
 		if (!parent->power.disable_depth
 		    && !parent->power.ignore_children) {
-			__pm_runtime_resume(parent, false);
+			__pm_runtime_resume(parent, 0);
 			if (parent->power.runtime_status != RPM_ACTIVE)
 				retval = -EBUSY;
 		}
@@ -470,7 +471,7 @@ int __pm_runtime_resume(struct device *dev, bool from_wq)
 		spin_lock_irq(&dev->power.lock);
 	}
 
-	dev_dbg(dev, "__pm_runtime_resume() returns %d!\n", retval);
+	dev_dbg(dev, "%s returns %d\n", __func__, retval);
 
 	return retval;
 }
@@ -484,7 +485,7 @@ int pm_runtime_resume(struct device *dev)
 	int retval;
 
 	spin_lock_irq(&dev->power.lock);
-	retval = __pm_runtime_resume(dev, false);
+	retval = __pm_runtime_resume(dev, 0);
 	spin_unlock_irq(&dev->power.lock);
 
 	return retval;
@@ -519,10 +520,10 @@ static void pm_runtime_work(struct work_struct *work)
 		__pm_runtime_idle(dev);
 		break;
 	case RPM_REQ_SUSPEND:
-		__pm_runtime_suspend(dev, true);
+		__pm_runtime_suspend(dev, RPM_NOWAIT);
 		break;
 	case RPM_REQ_RESUME:
-		__pm_runtime_resume(dev, true);
+		__pm_runtime_resume(dev, RPM_NOWAIT);
 		break;
 	}
 
@@ -782,17 +783,18 @@ EXPORT_SYMBOL_GPL(pm_request_resume);
 /**
  * __pm_runtime_get - Reference count a device and wake it up, if necessary.
  * @dev: Device to handle.
- * @sync: If set and the device is suspended, resume it synchronously.
+ * @rpmflags: Flag bits.
  *
  * Increment the usage count of the device and resume it or submit a resume
- * request for it, depending on the value of @sync.
+ * request for it, depending on the RPM_ASYNC flag bit.
  */
-int __pm_runtime_get(struct device *dev, bool sync)
+int __pm_runtime_get(struct device *dev, int rpmflags)
 {
 	int retval;
 
 	atomic_inc(&dev->power.usage_count);
-	retval = sync ? pm_runtime_resume(dev) : pm_request_resume(dev);
+	retval = (rpmflags & RPM_ASYNC) ?
+	    pm_request_resume(dev) : pm_runtime_resume(dev);
 
 	return retval;
 }
@@ -801,18 +803,19 @@ EXPORT_SYMBOL_GPL(__pm_runtime_get);
 /**
  * __pm_runtime_put - Decrement the device's usage counter and notify its bus.
  * @dev: Device to handle.
- * @sync: If the device's bus type is to be notified, do that synchronously.
+ * @rpmflags: Flag bits.
  *
  * Decrement the usage count of the device and if it reaches zero, carry out a
  * synchronous idle notification or submit an idle notification request for it,
- * depending on the value of @sync.
+ * depending on the RPM_ASYNC flag bit.
  */
-int __pm_runtime_put(struct device *dev, bool sync)
+int __pm_runtime_put(struct device *dev, int rpmflags)
 {
 	int retval = 0;
 
 	if (atomic_dec_and_test(&dev->power.usage_count))
-		retval = sync ? pm_runtime_idle(dev) : pm_request_idle(dev);
+		retval = (rpmflags & RPM_ASYNC) ?
+		    pm_request_idle(dev) : pm_runtime_idle(dev);
 
 	return retval;
 }
@@ -967,7 +970,7 @@ int pm_runtime_barrier(struct device *dev)
 
 	if (dev->power.request_pending
 	    && dev->power.request == RPM_REQ_RESUME) {
-		__pm_runtime_resume(dev, false);
+		__pm_runtime_resume(dev, 0);
 		retval = 1;
 	}
 
@@ -1016,7 +1019,7 @@ void __pm_runtime_disable(struct device *dev, bool check_resume)
 		 */
 		pm_runtime_get_noresume(dev);
 
-		__pm_runtime_resume(dev, false);
+		__pm_runtime_resume(dev, 0);
 
 		pm_runtime_put_noidle(dev);
 	}
@@ -1064,7 +1067,7 @@ void pm_runtime_forbid(struct device *dev)
 
 	dev->power.runtime_auto = false;
 	atomic_inc(&dev->power.usage_count);
-	__pm_runtime_resume(dev, false);
+	__pm_runtime_resume(dev, 0);
 
  out:
 	spin_unlock_irq(&dev->power.lock);

commit 4769373ca2c8d0b999749a070c48fd8648888831
Author: Alan Stern <stern@rowland.harvard.edu>
Date:   Sat Sep 25 23:34:46 2010 +0200

    PM / Runtime: Move code in drivers/base/power/runtime.c
    
    This patch (as1421) moves the PM runtime accounting subroutines up to
    the beginning of runtime.c, taking them out of the middle of the
    functions that do the actual work.  No operational changes.
    
    Signed-off-by: Alan Stern <stern@rowland.harvard.edu>
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index e9520ad2d716..ec08f1ae63f1 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -14,6 +14,44 @@ static int __pm_runtime_resume(struct device *dev, bool from_wq);
 static int __pm_request_idle(struct device *dev);
 static int __pm_request_resume(struct device *dev);
 
+/**
+ * update_pm_runtime_accounting - Update the time accounting of power states
+ * @dev: Device to update the accounting for
+ *
+ * In order to be able to have time accounting of the various power states
+ * (as used by programs such as PowerTOP to show the effectiveness of runtime
+ * PM), we need to track the time spent in each state.
+ * update_pm_runtime_accounting must be called each time before the
+ * runtime_status field is updated, to account the time in the old state
+ * correctly.
+ */
+void update_pm_runtime_accounting(struct device *dev)
+{
+	unsigned long now = jiffies;
+	int delta;
+
+	delta = now - dev->power.accounting_timestamp;
+
+	if (delta < 0)
+		delta = 0;
+
+	dev->power.accounting_timestamp = now;
+
+	if (dev->power.disable_depth > 0)
+		return;
+
+	if (dev->power.runtime_status == RPM_SUSPENDED)
+		dev->power.suspended_jiffies += delta;
+	else
+		dev->power.active_jiffies += delta;
+}
+
+static void __update_runtime_status(struct device *dev, enum rpm_status status)
+{
+	update_pm_runtime_accounting(dev);
+	dev->power.runtime_status = status;
+}
+
 /**
  * pm_runtime_deactivate_timer - Deactivate given device's suspend timer.
  * @dev: Device to handle.
@@ -123,45 +161,6 @@ int pm_runtime_idle(struct device *dev)
 }
 EXPORT_SYMBOL_GPL(pm_runtime_idle);
 
-
-/**
- * update_pm_runtime_accounting - Update the time accounting of power states
- * @dev: Device to update the accounting for
- *
- * In order to be able to have time accounting of the various power states
- * (as used by programs such as PowerTOP to show the effectiveness of runtime
- * PM), we need to track the time spent in each state.
- * update_pm_runtime_accounting must be called each time before the
- * runtime_status field is updated, to account the time in the old state
- * correctly.
- */
-void update_pm_runtime_accounting(struct device *dev)
-{
-	unsigned long now = jiffies;
-	int delta;
-
-	delta = now - dev->power.accounting_timestamp;
-
-	if (delta < 0)
-		delta = 0;
-
-	dev->power.accounting_timestamp = now;
-
-	if (dev->power.disable_depth > 0)
-		return;
-
-	if (dev->power.runtime_status == RPM_SUSPENDED)
-		dev->power.suspended_jiffies += delta;
-	else
-		dev->power.active_jiffies += delta;
-}
-
-static void __update_runtime_status(struct device *dev, enum rpm_status status)
-{
-	update_pm_runtime_accounting(dev);
-	dev->power.runtime_status = status;
-}
-
 /**
  * __pm_runtime_suspend - Carry out run-time suspend of given device.
  * @dev: Device to suspend.

commit 074037ec79bea73edf1b1ec72fef1010e83e3cc5
Author: Rafael J. Wysocki <rjw@sisk.pl>
Date:   Wed Sep 22 22:09:10 2010 +0200

    PM / Wakeup: Introduce wakeup source objects and event statistics (v3)
    
    Introduce struct wakeup_source for representing system wakeup sources
    within the kernel and for collecting statistics related to them.
    Make the recently introduced helper functions pm_wakeup_event(),
    pm_stay_awake() and pm_relax() use struct wakeup_source objects
    internally, so that wakeup statistics associated with wakeup devices
    can be collected and reported in a consistent way (the definition of
    pm_relax() is changed, which is harmless, because this function is
    not called directly by anyone yet).  Introduce new wakeup-related
    sysfs device attributes in /sys/devices/.../power for reporting the
    device wakeup statistics.
    
    Change the global wakeup events counters event_count and
    events_in_progress into atomic variables, so that it is not necessary
    to acquire a global spinlock in pm_wakeup_event(), pm_stay_awake()
    and pm_relax(), which should allow us to avoid lock contention in
    these functions on SMP systems with many wakeup devices.
    
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>
    Acked-by: Greg Kroah-Hartman <gregkh@suse.de>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index b78c401ffa73..e9520ad2d716 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -1099,8 +1099,6 @@ EXPORT_SYMBOL_GPL(pm_runtime_allow);
  */
 void pm_runtime_init(struct device *dev)
 {
-	spin_lock_init(&dev->power.lock);
-
 	dev->power.runtime_status = RPM_SUSPENDED;
 	dev->power.idle_notification = false;
 

commit 8d4b9d1bfef117862a2889dec4dac227068544c9
Author: Arjan van de Ven <arjan@linux.intel.com>
Date:   Mon Jul 19 02:01:06 2010 +0200

    PM / Runtime: Add runtime PM statistics (v3)
    
    In order for PowerTOP to be able to report how well the new runtime PM is
    working for the various drivers, the kernel needs to export some basic
    statistics in sysfs.
    
    This patch adds two sysfs files in the runtime PM domain that expose the
    total time a device has been active, and the time a device has been
    suspended.
    
    With this PowerTOP can compute the activity percentage
    
    Active %age = 100 * (delta active) / (delta active + delta suspended)
    
    and present the information to the user.
    
    I've written the PowerTOP code (slated for version 1.12) already, and the
    output looks like this:
    
    Runtime Device Power Management statistics
    Active  Device name
     10.0%  06:00.0 Ethernet controller: Realtek Semiconductor Co., Ltd. RTL8101E/RTL8102E PCI Express Fast Ethernet controller
    
    [version 2: fix stat update bugs noticed by Alan Stern]
    [version 3: rebase to -next and move the sysfs declaration]
    
    Signed-off-by: Arjan van de Ven <arjan@linux.intel.com>
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index b0ec0e9f27e9..b78c401ffa73 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -123,6 +123,45 @@ int pm_runtime_idle(struct device *dev)
 }
 EXPORT_SYMBOL_GPL(pm_runtime_idle);
 
+
+/**
+ * update_pm_runtime_accounting - Update the time accounting of power states
+ * @dev: Device to update the accounting for
+ *
+ * In order to be able to have time accounting of the various power states
+ * (as used by programs such as PowerTOP to show the effectiveness of runtime
+ * PM), we need to track the time spent in each state.
+ * update_pm_runtime_accounting must be called each time before the
+ * runtime_status field is updated, to account the time in the old state
+ * correctly.
+ */
+void update_pm_runtime_accounting(struct device *dev)
+{
+	unsigned long now = jiffies;
+	int delta;
+
+	delta = now - dev->power.accounting_timestamp;
+
+	if (delta < 0)
+		delta = 0;
+
+	dev->power.accounting_timestamp = now;
+
+	if (dev->power.disable_depth > 0)
+		return;
+
+	if (dev->power.runtime_status == RPM_SUSPENDED)
+		dev->power.suspended_jiffies += delta;
+	else
+		dev->power.active_jiffies += delta;
+}
+
+static void __update_runtime_status(struct device *dev, enum rpm_status status)
+{
+	update_pm_runtime_accounting(dev);
+	dev->power.runtime_status = status;
+}
+
 /**
  * __pm_runtime_suspend - Carry out run-time suspend of given device.
  * @dev: Device to suspend.
@@ -197,7 +236,7 @@ int __pm_runtime_suspend(struct device *dev, bool from_wq)
 		goto repeat;
 	}
 
-	dev->power.runtime_status = RPM_SUSPENDING;
+	__update_runtime_status(dev, RPM_SUSPENDING);
 	dev->power.deferred_resume = false;
 
 	if (dev->bus && dev->bus->pm && dev->bus->pm->runtime_suspend) {
@@ -228,7 +267,7 @@ int __pm_runtime_suspend(struct device *dev, bool from_wq)
 	}
 
 	if (retval) {
-		dev->power.runtime_status = RPM_ACTIVE;
+		__update_runtime_status(dev, RPM_ACTIVE);
 		if (retval == -EAGAIN || retval == -EBUSY) {
 			if (dev->power.timer_expires == 0)
 				notify = true;
@@ -237,7 +276,7 @@ int __pm_runtime_suspend(struct device *dev, bool from_wq)
 			pm_runtime_cancel_pending(dev);
 		}
 	} else {
-		dev->power.runtime_status = RPM_SUSPENDED;
+		__update_runtime_status(dev, RPM_SUSPENDED);
 		pm_runtime_deactivate_timer(dev);
 
 		if (dev->parent) {
@@ -381,7 +420,7 @@ int __pm_runtime_resume(struct device *dev, bool from_wq)
 		goto repeat;
 	}
 
-	dev->power.runtime_status = RPM_RESUMING;
+	__update_runtime_status(dev, RPM_RESUMING);
 
 	if (dev->bus && dev->bus->pm && dev->bus->pm->runtime_resume) {
 		spin_unlock_irq(&dev->power.lock);
@@ -411,10 +450,10 @@ int __pm_runtime_resume(struct device *dev, bool from_wq)
 	}
 
 	if (retval) {
-		dev->power.runtime_status = RPM_SUSPENDED;
+		__update_runtime_status(dev, RPM_SUSPENDED);
 		pm_runtime_cancel_pending(dev);
 	} else {
-		dev->power.runtime_status = RPM_ACTIVE;
+		__update_runtime_status(dev, RPM_ACTIVE);
 		if (parent)
 			atomic_inc(&parent->power.child_count);
 	}
@@ -848,7 +887,7 @@ int __pm_runtime_set_status(struct device *dev, unsigned int status)
 	}
 
  out_set:
-	dev->power.runtime_status = status;
+	__update_runtime_status(dev, status);
 	dev->power.runtime_error = 0;
  out:
 	spin_unlock_irqrestore(&dev->power.lock, flags);
@@ -1077,6 +1116,7 @@ void pm_runtime_init(struct device *dev)
 	dev->power.request_pending = false;
 	dev->power.request = RPM_REQ_NONE;
 	dev->power.deferred_resume = false;
+	dev->power.accounting_timestamp = jiffies;
 	INIT_WORK(&dev->power.work, pm_runtime_work);
 
 	dev->power.timer_expires = 0;

commit 240c7337a4cd3d91b196c5ef97ad461b3a22fa09
Author: Alan Stern <stern@rowland.harvard.edu>
Date:   Tue Mar 23 00:50:07 2010 +0100

    PM: Allow runtime_suspend methods to call pm_schedule_suspend()
    
    This patch (as1361) changes the runtime PM interface slightly; it
    allows suspend requests to be scheduled while the runtime_suspend
    method is running.  If the method succeeds then the scheduled request
    is cancelled, whereas if the method fails then an idle notification is
    sent only if no request was scheduled.
    
    Being able to schedule suspend requests from within a runtime_suspend
    method is useful for drivers that need to test for idleness and
    suspend the device all while holding a single spinlock, or for drivers
    that want to check for idleness by polling.
    
    Signed-off-by: Alan Stern <stern@rowland.harvard.edu>
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 626dd147b75f..b0ec0e9f27e9 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -229,14 +229,16 @@ int __pm_runtime_suspend(struct device *dev, bool from_wq)
 
 	if (retval) {
 		dev->power.runtime_status = RPM_ACTIVE;
-		pm_runtime_cancel_pending(dev);
-
 		if (retval == -EAGAIN || retval == -EBUSY) {
-			notify = true;
+			if (dev->power.timer_expires == 0)
+				notify = true;
 			dev->power.runtime_error = 0;
+		} else {
+			pm_runtime_cancel_pending(dev);
 		}
 	} else {
 		dev->power.runtime_status = RPM_SUSPENDED;
+		pm_runtime_deactivate_timer(dev);
 
 		if (dev->parent) {
 			parent = dev->parent;
@@ -659,8 +661,6 @@ int pm_schedule_suspend(struct device *dev, unsigned int delay)
 
 	if (dev->power.runtime_status == RPM_SUSPENDED)
 		retval = 1;
-	else if (dev->power.runtime_status == RPM_SUSPENDING)
-		retval = -EINPROGRESS;
 	else if (atomic_read(&dev->power.usage_count) > 0
 	    || dev->power.disable_depth > 0)
 		retval = -EAGAIN;

commit 53823639173cc9e9a261f68f4abefe62364b86c6
Author: Rafael J. Wysocki <rjw@sisk.pl>
Date:   Sat Jan 23 22:02:51 2010 +0100

    PM / Runtime: Add sysfs switch for disabling device run-time PM
    
    Add new device sysfs attribute, power/control, allowing the user
    space to block the run-time power management of the devices.  If this
    attribute is set to "on", the driver of the device won't be able to power
    manage it at run time (without breaking the rules) and the device will
    always be in the full power state (except when the entire system goes
    into a sleep state).
    
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>
    Acked-by: Alan Stern <stern@rowland.harvard.edu>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index f8b044e8aef7..626dd147b75f 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -1010,6 +1010,50 @@ void pm_runtime_enable(struct device *dev)
 }
 EXPORT_SYMBOL_GPL(pm_runtime_enable);
 
+/**
+ * pm_runtime_forbid - Block run-time PM of a device.
+ * @dev: Device to handle.
+ *
+ * Increase the device's usage count and clear its power.runtime_auto flag,
+ * so that it cannot be suspended at run time until pm_runtime_allow() is called
+ * for it.
+ */
+void pm_runtime_forbid(struct device *dev)
+{
+	spin_lock_irq(&dev->power.lock);
+	if (!dev->power.runtime_auto)
+		goto out;
+
+	dev->power.runtime_auto = false;
+	atomic_inc(&dev->power.usage_count);
+	__pm_runtime_resume(dev, false);
+
+ out:
+	spin_unlock_irq(&dev->power.lock);
+}
+EXPORT_SYMBOL_GPL(pm_runtime_forbid);
+
+/**
+ * pm_runtime_allow - Unblock run-time PM of a device.
+ * @dev: Device to handle.
+ *
+ * Decrease the device's usage count and set its power.runtime_auto flag.
+ */
+void pm_runtime_allow(struct device *dev)
+{
+	spin_lock_irq(&dev->power.lock);
+	if (dev->power.runtime_auto)
+		goto out;
+
+	dev->power.runtime_auto = true;
+	if (atomic_dec_and_test(&dev->power.usage_count))
+		__pm_runtime_idle(dev);
+
+ out:
+	spin_unlock_irq(&dev->power.lock);
+}
+EXPORT_SYMBOL_GPL(pm_runtime_allow);
+
 /**
  * pm_runtime_init - Initialize run-time PM fields in given device object.
  * @dev: Device object to initialize.
@@ -1028,6 +1072,7 @@ void pm_runtime_init(struct device *dev)
 
 	atomic_set(&dev->power.child_count, 0);
 	pm_suspend_ignore_children(dev, false);
+	dev->power.runtime_auto = true;
 
 	dev->power.request_pending = false;
 	dev->power.request = RPM_REQ_NONE;

commit a6ab7aa9f432f722808c6fea5a8b7f5f229de031
Author: Rafael J. Wysocki <rjw@sisk.pl>
Date:   Tue Dec 22 20:43:17 2009 +0100

    PM / Runtime: Use device type and device class callbacks
    
    The power management of some devices is handled through device types
    and device classes rather than through bus types.  Since these
    devices may also benefit from using the run-time power management
    core, extend it so that the device type and device class run-time PM
    callbacks can be taken into consideration by it if the bus type
    callback is not defined.
    
    Update the run-time PM core documentation to reflect this change.
    
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 40d7720a4b21..f8b044e8aef7 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -84,6 +84,19 @@ static int __pm_runtime_idle(struct device *dev)
 
 		dev->bus->pm->runtime_idle(dev);
 
+		spin_lock_irq(&dev->power.lock);
+	} else if (dev->type && dev->type->pm && dev->type->pm->runtime_idle) {
+		spin_unlock_irq(&dev->power.lock);
+
+		dev->type->pm->runtime_idle(dev);
+
+		spin_lock_irq(&dev->power.lock);
+	} else if (dev->class && dev->class->pm
+	    && dev->class->pm->runtime_idle) {
+		spin_unlock_irq(&dev->power.lock);
+
+		dev->class->pm->runtime_idle(dev);
+
 		spin_lock_irq(&dev->power.lock);
 	}
 
@@ -192,6 +205,22 @@ int __pm_runtime_suspend(struct device *dev, bool from_wq)
 
 		retval = dev->bus->pm->runtime_suspend(dev);
 
+		spin_lock_irq(&dev->power.lock);
+		dev->power.runtime_error = retval;
+	} else if (dev->type && dev->type->pm
+	    && dev->type->pm->runtime_suspend) {
+		spin_unlock_irq(&dev->power.lock);
+
+		retval = dev->type->pm->runtime_suspend(dev);
+
+		spin_lock_irq(&dev->power.lock);
+		dev->power.runtime_error = retval;
+	} else if (dev->class && dev->class->pm
+	    && dev->class->pm->runtime_suspend) {
+		spin_unlock_irq(&dev->power.lock);
+
+		retval = dev->class->pm->runtime_suspend(dev);
+
 		spin_lock_irq(&dev->power.lock);
 		dev->power.runtime_error = retval;
 	} else {
@@ -357,6 +386,22 @@ int __pm_runtime_resume(struct device *dev, bool from_wq)
 
 		retval = dev->bus->pm->runtime_resume(dev);
 
+		spin_lock_irq(&dev->power.lock);
+		dev->power.runtime_error = retval;
+	} else if (dev->type && dev->type->pm
+	    && dev->type->pm->runtime_resume) {
+		spin_unlock_irq(&dev->power.lock);
+
+		retval = dev->type->pm->runtime_resume(dev);
+
+		spin_lock_irq(&dev->power.lock);
+		dev->power.runtime_error = retval;
+	} else if (dev->class && dev->class->pm
+	    && dev->class->pm->runtime_resume) {
+		spin_unlock_irq(&dev->power.lock);
+
+		retval = dev->class->pm->runtime_resume(dev);
+
 		spin_lock_irq(&dev->power.lock);
 		dev->power.runtime_error = retval;
 	} else {

commit 1d531c14d2ed4b24472a4d773f00ed6d1cd34ee7
Author: Alan Stern <stern@rowland.harvard.edu>
Date:   Sun Dec 13 20:28:30 2009 +0100

    PM: allow for usage_count > 0 in pm_runtime_get()
    
    This patch (as1308c) fixes __pm_runtime_get().  Currently the routine
    will resume a device if the prior usage count was 0.  But this isn't
    right; thanks to pm_runtime_get_noresume() the usage count can be
    positive even while the device is suspended.
    
    Signed-off-by: Alan Stern <stern@rowland.harvard.edu>
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 5a01ecef4af3..40d7720a4b21 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -701,15 +701,15 @@ EXPORT_SYMBOL_GPL(pm_request_resume);
  * @dev: Device to handle.
  * @sync: If set and the device is suspended, resume it synchronously.
  *
- * Increment the usage count of the device and if it was zero previously,
- * resume it or submit a resume request for it, depending on the value of @sync.
+ * Increment the usage count of the device and resume it or submit a resume
+ * request for it, depending on the value of @sync.
  */
 int __pm_runtime_get(struct device *dev, bool sync)
 {
-	int retval = 1;
+	int retval;
 
-	if (atomic_add_return(1, &dev->power.usage_count) == 1)
-		retval = sync ? pm_runtime_resume(dev) : pm_request_resume(dev);
+	atomic_inc(&dev->power.usage_count);
+	retval = sync ? pm_runtime_resume(dev) : pm_request_resume(dev);
 
 	return retval;
 }

commit 965c4ac0613b071d6f035334c5d9d942013df4f9
Author: Rafael J. Wysocki <rjw@sisk.pl>
Date:   Thu Dec 3 21:04:41 2009 +0100

    PM / Runtime: Remove unnecessary braces in __pm_runtime_set_status()
    
    Some braces in __pm_runtime_set_status() are not necessary, so
    remove them.
    
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 637706951885..5a01ecef4af3 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -791,12 +791,10 @@ int __pm_runtime_set_status(struct device *dev, unsigned int status)
 		 */
 		if (!parent->power.disable_depth
 		    && !parent->power.ignore_children
-		    && parent->power.runtime_status != RPM_ACTIVE) {
+		    && parent->power.runtime_status != RPM_ACTIVE)
 			error = -EBUSY;
-		} else {
-			if (dev->power.runtime_status == RPM_SUSPENDED)
-				atomic_inc(&parent->power.child_count);
-		}
+		else if (dev->power.runtime_status == RPM_SUSPENDED)
+			atomic_inc(&parent->power.child_count);
 
 		spin_unlock(&parent->power.lock);
 

commit 0ddf0ed1d47e2d4170fa2989273886a1df66a862
Author: Rafael J. Wysocki <rjw@sisk.pl>
Date:   Thu Dec 3 21:03:57 2009 +0100

    PM / Runtime: Ensure timer_expires is nonzero in pm_schedule_suspend()
    
    The runtime PM core code assumes that dev->power.timer_expires is
    nonzero when the timer is scheduled, but it may become zero
    incidentally in pm_schedule_suspend().  Prevent this from happening
    by bumping dev->power.timer_expires up to 1 if it's 0 before calling
    mod_timer().
    
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>
    Reported-by: Alan Stern <stern@rowland.harvard.edu>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 6e8577d1f750..637706951885 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -625,6 +625,8 @@ int pm_schedule_suspend(struct device *dev, unsigned int delay)
 		goto out;
 
 	dev->power.timer_expires = jiffies + msecs_to_jiffies(delay);
+	if (!dev->power.timer_expires)
+		dev->power.timer_expires = 1;
 	mod_timer(&dev->power.suspend_timer, dev->power.timer_expires);
 
  out:

commit 63c94801701abfea21570d3302687ec027ed33e8
Author: Alan Stern <stern@rowland.harvard.edu>
Date:   Thu Dec 3 20:22:34 2009 +0100

    PM / Runtime: Use deferred_resume flag in pm_request_resume
    
    This patch (as1307) adds a small optimization to
    __pm_request_resume().  If the device is currently being suspended,
    there's no need to queue a work routine to resume it.  Setting the
    deferred_resume flag will suffice.  (There's also a minor improvement
    to the function's code layout: An unnecessary "else" is removed.)
    
    Also, the patch clarifies the usage of the deferred_resume flag.  It
    is meaningful only while a suspend is in progress, so it should be
    cleared just before a suspend starts, not just after one ends.
    
    Signed-off-by: Alan Stern <stern@rowland.harvard.edu>
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 0a4b75f834c0..6e8577d1f750 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -185,6 +185,7 @@ int __pm_runtime_suspend(struct device *dev, bool from_wq)
 	}
 
 	dev->power.runtime_status = RPM_SUSPENDING;
+	dev->power.deferred_resume = false;
 
 	if (dev->bus && dev->bus->pm && dev->bus->pm->runtime_suspend) {
 		spin_unlock_irq(&dev->power.lock);
@@ -200,7 +201,6 @@ int __pm_runtime_suspend(struct device *dev, bool from_wq)
 	if (retval) {
 		dev->power.runtime_status = RPM_ACTIVE;
 		pm_runtime_cancel_pending(dev);
-		dev->power.deferred_resume = false;
 
 		if (retval == -EAGAIN || retval == -EBUSY) {
 			notify = true;
@@ -217,7 +217,6 @@ int __pm_runtime_suspend(struct device *dev, bool from_wq)
 	wake_up_all(&dev->power.wait_queue);
 
 	if (dev->power.deferred_resume) {
-		dev->power.deferred_resume = false;
 		__pm_runtime_resume(dev, false);
 		retval = -EAGAIN;
 		goto out;
@@ -659,13 +658,17 @@ static int __pm_request_resume(struct device *dev)
 
 	pm_runtime_deactivate_timer(dev);
 
+	if (dev->power.runtime_status == RPM_SUSPENDING) {
+		dev->power.deferred_resume = true;
+		return retval;
+	}
 	if (dev->power.request_pending) {
 		/* If non-resume request is pending, we can overtake it. */
 		dev->power.request = retval ? RPM_REQ_NONE : RPM_REQ_RESUME;
 		return retval;
-	} else if (retval) {
-		return retval;
 	}
+	if (retval)
+		return retval;
 
 	dev->power.request = RPM_REQ_RESUME;
 	dev->power.request_pending = true;

commit bab636b921017f0db6e0c2979438f50b898a9808
Author: Rafael J. Wysocki <rjw@sisk.pl>
Date:   Thu Dec 3 20:21:21 2009 +0100

    PM / Runtime: Fix lockdep warning in __pm_runtime_set_status()
    
    Lockdep complains about taking the parent lock in
    __pm_runtime_set_status(), so mark it as nested.
    
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>
    Reported-by: Alan Stern <stern@rowland.harvard.edu>
    Cc: stable@kernel.org

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 846d89e3d122..0a4b75f834c0 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -777,7 +777,7 @@ int __pm_runtime_set_status(struct device *dev, unsigned int status)
 	}
 
 	if (parent) {
-		spin_lock(&parent->power.lock);
+		spin_lock_nested(&parent->power.lock, SINGLE_DEPTH_NESTING);
 
 		/*
 		 * It is invalid to put an active child under a parent that is

commit 862f89b3d4c6bf3caab7fc69661fc6e725edd00a
Author: Alan Stern <stern@rowland.harvard.edu>
Date:   Wed Nov 25 01:06:37 2009 +0100

    PM: fix irq enable/disable in runtime PM code
    
    This patch (as1305) fixes a bug in the irq-enable settings and removes
    some related overhead in the runtime PM code.
    
            In __pm_runtime_resume(), within the scope of the original
            spin_lock_irq(), we know that irqs are disabled.  There's no
            reason to go through a pair of enable/disable cycles when
            acquiring and releasing the parent's lock.
    
            In __pm_runtime_set_status(), irqs are already disabled when
            the parent's lock is acquired, and they must remain disabled
            when it is released.
    
    Signed-off-by: Alan Stern <stern@rowland.harvard.edu>
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index a770498a74ec..846d89e3d122 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -328,11 +328,11 @@ int __pm_runtime_resume(struct device *dev, bool from_wq)
 		 * necessary.
 		 */
 		parent = dev->parent;
-		spin_unlock_irq(&dev->power.lock);
+		spin_unlock(&dev->power.lock);
 
 		pm_runtime_get_noresume(parent);
 
-		spin_lock_irq(&parent->power.lock);
+		spin_lock(&parent->power.lock);
 		/*
 		 * We can resume if the parent's run-time PM is disabled or it
 		 * is set to ignore children.
@@ -343,9 +343,9 @@ int __pm_runtime_resume(struct device *dev, bool from_wq)
 			if (parent->power.runtime_status != RPM_ACTIVE)
 				retval = -EBUSY;
 		}
-		spin_unlock_irq(&parent->power.lock);
+		spin_unlock(&parent->power.lock);
 
-		spin_lock_irq(&dev->power.lock);
+		spin_lock(&dev->power.lock);
 		if (retval)
 			goto out;
 		goto repeat;
@@ -777,7 +777,7 @@ int __pm_runtime_set_status(struct device *dev, unsigned int status)
 	}
 
 	if (parent) {
-		spin_lock_irq(&parent->power.lock);
+		spin_lock(&parent->power.lock);
 
 		/*
 		 * It is invalid to put an active child under a parent that is
@@ -793,7 +793,7 @@ int __pm_runtime_set_status(struct device *dev, unsigned int status)
 				atomic_inc(&parent->power.child_count);
 		}
 
-		spin_unlock_irq(&parent->power.lock);
+		spin_unlock(&parent->power.lock);
 
 		if (error)
 			goto out;

commit 2ddac2a6a8f13e95664fe7ad1b728ac84fb1bd07
Author: Pavel Machek <pavel@ucw.cz>
Date:   Wed Oct 28 22:56:10 2009 +0100

    PM: Remove some debug messages producing too much noise
    
    pm_runtime_idle() is somewhat noisy. Remove debug prints.
    
    Signed-off-by: Pavel Machek <pavel@ucw.cz>
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 38556f6cc22d..a770498a74ec 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -51,8 +51,6 @@ static int __pm_runtime_idle(struct device *dev)
 {
 	int retval = 0;
 
-	dev_dbg(dev, "__pm_runtime_idle()!\n");
-
 	if (dev->power.runtime_error)
 		retval = -EINVAL;
 	else if (dev->power.idle_notification)
@@ -93,8 +91,6 @@ static int __pm_runtime_idle(struct device *dev)
 	wake_up_all(&dev->power.wait_queue);
 
  out:
-	dev_dbg(dev, "__pm_runtime_idle() returns %d!\n", retval);
-
 	return retval;
 }
 

commit 5e928f77a09a07f9dd595bb8a489965d69a83458
Author: Rafael J. Wysocki <rjw@sisk.pl>
Date:   Tue Aug 18 23:38:32 2009 +0200

    PM: Introduce core framework for run-time PM of I/O devices (rev. 17)
    
    Introduce a core framework for run-time power management of I/O
    devices.  Add device run-time PM fields to 'struct dev_pm_info'
    and device run-time PM callbacks to 'struct dev_pm_ops'.  Introduce
    a run-time PM workqueue and define some device run-time PM helper
    functions at the core level.  Document all these things.
    
    Special thanks to Alan Stern for his help with the design and
    multiple detailed reviews of the pereceding versions of this patch
    and to Magnus Damm for testing feedback.
    
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>
    Acked-by: Magnus Damm <damm@igel.co.jp>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
new file mode 100644
index 000000000000..38556f6cc22d
--- /dev/null
+++ b/drivers/base/power/runtime.c
@@ -0,0 +1,1011 @@
+/*
+ * drivers/base/power/runtime.c - Helper functions for device run-time PM
+ *
+ * Copyright (c) 2009 Rafael J. Wysocki <rjw@sisk.pl>, Novell Inc.
+ *
+ * This file is released under the GPLv2.
+ */
+
+#include <linux/sched.h>
+#include <linux/pm_runtime.h>
+#include <linux/jiffies.h>
+
+static int __pm_runtime_resume(struct device *dev, bool from_wq);
+static int __pm_request_idle(struct device *dev);
+static int __pm_request_resume(struct device *dev);
+
+/**
+ * pm_runtime_deactivate_timer - Deactivate given device's suspend timer.
+ * @dev: Device to handle.
+ */
+static void pm_runtime_deactivate_timer(struct device *dev)
+{
+	if (dev->power.timer_expires > 0) {
+		del_timer(&dev->power.suspend_timer);
+		dev->power.timer_expires = 0;
+	}
+}
+
+/**
+ * pm_runtime_cancel_pending - Deactivate suspend timer and cancel requests.
+ * @dev: Device to handle.
+ */
+static void pm_runtime_cancel_pending(struct device *dev)
+{
+	pm_runtime_deactivate_timer(dev);
+	/*
+	 * In case there's a request pending, make sure its work function will
+	 * return without doing anything.
+	 */
+	dev->power.request = RPM_REQ_NONE;
+}
+
+/**
+ * __pm_runtime_idle - Notify device bus type if the device can be suspended.
+ * @dev: Device to notify the bus type about.
+ *
+ * This function must be called under dev->power.lock with interrupts disabled.
+ */
+static int __pm_runtime_idle(struct device *dev)
+	__releases(&dev->power.lock) __acquires(&dev->power.lock)
+{
+	int retval = 0;
+
+	dev_dbg(dev, "__pm_runtime_idle()!\n");
+
+	if (dev->power.runtime_error)
+		retval = -EINVAL;
+	else if (dev->power.idle_notification)
+		retval = -EINPROGRESS;
+	else if (atomic_read(&dev->power.usage_count) > 0
+	    || dev->power.disable_depth > 0
+	    || dev->power.runtime_status != RPM_ACTIVE)
+		retval = -EAGAIN;
+	else if (!pm_children_suspended(dev))
+		retval = -EBUSY;
+	if (retval)
+		goto out;
+
+	if (dev->power.request_pending) {
+		/*
+		 * If an idle notification request is pending, cancel it.  Any
+		 * other pending request takes precedence over us.
+		 */
+		if (dev->power.request == RPM_REQ_IDLE) {
+			dev->power.request = RPM_REQ_NONE;
+		} else if (dev->power.request != RPM_REQ_NONE) {
+			retval = -EAGAIN;
+			goto out;
+		}
+	}
+
+	dev->power.idle_notification = true;
+
+	if (dev->bus && dev->bus->pm && dev->bus->pm->runtime_idle) {
+		spin_unlock_irq(&dev->power.lock);
+
+		dev->bus->pm->runtime_idle(dev);
+
+		spin_lock_irq(&dev->power.lock);
+	}
+
+	dev->power.idle_notification = false;
+	wake_up_all(&dev->power.wait_queue);
+
+ out:
+	dev_dbg(dev, "__pm_runtime_idle() returns %d!\n", retval);
+
+	return retval;
+}
+
+/**
+ * pm_runtime_idle - Notify device bus type if the device can be suspended.
+ * @dev: Device to notify the bus type about.
+ */
+int pm_runtime_idle(struct device *dev)
+{
+	int retval;
+
+	spin_lock_irq(&dev->power.lock);
+	retval = __pm_runtime_idle(dev);
+	spin_unlock_irq(&dev->power.lock);
+
+	return retval;
+}
+EXPORT_SYMBOL_GPL(pm_runtime_idle);
+
+/**
+ * __pm_runtime_suspend - Carry out run-time suspend of given device.
+ * @dev: Device to suspend.
+ * @from_wq: If set, the function has been called via pm_wq.
+ *
+ * Check if the device can be suspended and run the ->runtime_suspend() callback
+ * provided by its bus type.  If another suspend has been started earlier, wait
+ * for it to finish.  If an idle notification or suspend request is pending or
+ * scheduled, cancel it.
+ *
+ * This function must be called under dev->power.lock with interrupts disabled.
+ */
+int __pm_runtime_suspend(struct device *dev, bool from_wq)
+	__releases(&dev->power.lock) __acquires(&dev->power.lock)
+{
+	struct device *parent = NULL;
+	bool notify = false;
+	int retval = 0;
+
+	dev_dbg(dev, "__pm_runtime_suspend()%s!\n",
+		from_wq ? " from workqueue" : "");
+
+ repeat:
+	if (dev->power.runtime_error) {
+		retval = -EINVAL;
+		goto out;
+	}
+
+	/* Pending resume requests take precedence over us. */
+	if (dev->power.request_pending
+	    && dev->power.request == RPM_REQ_RESUME) {
+		retval = -EAGAIN;
+		goto out;
+	}
+
+	/* Other scheduled or pending requests need to be canceled. */
+	pm_runtime_cancel_pending(dev);
+
+	if (dev->power.runtime_status == RPM_SUSPENDED)
+		retval = 1;
+	else if (dev->power.runtime_status == RPM_RESUMING
+	    || dev->power.disable_depth > 0
+	    || atomic_read(&dev->power.usage_count) > 0)
+		retval = -EAGAIN;
+	else if (!pm_children_suspended(dev))
+		retval = -EBUSY;
+	if (retval)
+		goto out;
+
+	if (dev->power.runtime_status == RPM_SUSPENDING) {
+		DEFINE_WAIT(wait);
+
+		if (from_wq) {
+			retval = -EINPROGRESS;
+			goto out;
+		}
+
+		/* Wait for the other suspend running in parallel with us. */
+		for (;;) {
+			prepare_to_wait(&dev->power.wait_queue, &wait,
+					TASK_UNINTERRUPTIBLE);
+			if (dev->power.runtime_status != RPM_SUSPENDING)
+				break;
+
+			spin_unlock_irq(&dev->power.lock);
+
+			schedule();
+
+			spin_lock_irq(&dev->power.lock);
+		}
+		finish_wait(&dev->power.wait_queue, &wait);
+		goto repeat;
+	}
+
+	dev->power.runtime_status = RPM_SUSPENDING;
+
+	if (dev->bus && dev->bus->pm && dev->bus->pm->runtime_suspend) {
+		spin_unlock_irq(&dev->power.lock);
+
+		retval = dev->bus->pm->runtime_suspend(dev);
+
+		spin_lock_irq(&dev->power.lock);
+		dev->power.runtime_error = retval;
+	} else {
+		retval = -ENOSYS;
+	}
+
+	if (retval) {
+		dev->power.runtime_status = RPM_ACTIVE;
+		pm_runtime_cancel_pending(dev);
+		dev->power.deferred_resume = false;
+
+		if (retval == -EAGAIN || retval == -EBUSY) {
+			notify = true;
+			dev->power.runtime_error = 0;
+		}
+	} else {
+		dev->power.runtime_status = RPM_SUSPENDED;
+
+		if (dev->parent) {
+			parent = dev->parent;
+			atomic_add_unless(&parent->power.child_count, -1, 0);
+		}
+	}
+	wake_up_all(&dev->power.wait_queue);
+
+	if (dev->power.deferred_resume) {
+		dev->power.deferred_resume = false;
+		__pm_runtime_resume(dev, false);
+		retval = -EAGAIN;
+		goto out;
+	}
+
+	if (notify)
+		__pm_runtime_idle(dev);
+
+	if (parent && !parent->power.ignore_children) {
+		spin_unlock_irq(&dev->power.lock);
+
+		pm_request_idle(parent);
+
+		spin_lock_irq(&dev->power.lock);
+	}
+
+ out:
+	dev_dbg(dev, "__pm_runtime_suspend() returns %d!\n", retval);
+
+	return retval;
+}
+
+/**
+ * pm_runtime_suspend - Carry out run-time suspend of given device.
+ * @dev: Device to suspend.
+ */
+int pm_runtime_suspend(struct device *dev)
+{
+	int retval;
+
+	spin_lock_irq(&dev->power.lock);
+	retval = __pm_runtime_suspend(dev, false);
+	spin_unlock_irq(&dev->power.lock);
+
+	return retval;
+}
+EXPORT_SYMBOL_GPL(pm_runtime_suspend);
+
+/**
+ * __pm_runtime_resume - Carry out run-time resume of given device.
+ * @dev: Device to resume.
+ * @from_wq: If set, the function has been called via pm_wq.
+ *
+ * Check if the device can be woken up and run the ->runtime_resume() callback
+ * provided by its bus type.  If another resume has been started earlier, wait
+ * for it to finish.  If there's a suspend running in parallel with this
+ * function, wait for it to finish and resume the device.  Cancel any scheduled
+ * or pending requests.
+ *
+ * This function must be called under dev->power.lock with interrupts disabled.
+ */
+int __pm_runtime_resume(struct device *dev, bool from_wq)
+	__releases(&dev->power.lock) __acquires(&dev->power.lock)
+{
+	struct device *parent = NULL;
+	int retval = 0;
+
+	dev_dbg(dev, "__pm_runtime_resume()%s!\n",
+		from_wq ? " from workqueue" : "");
+
+ repeat:
+	if (dev->power.runtime_error) {
+		retval = -EINVAL;
+		goto out;
+	}
+
+	pm_runtime_cancel_pending(dev);
+
+	if (dev->power.runtime_status == RPM_ACTIVE)
+		retval = 1;
+	else if (dev->power.disable_depth > 0)
+		retval = -EAGAIN;
+	if (retval)
+		goto out;
+
+	if (dev->power.runtime_status == RPM_RESUMING
+	    || dev->power.runtime_status == RPM_SUSPENDING) {
+		DEFINE_WAIT(wait);
+
+		if (from_wq) {
+			if (dev->power.runtime_status == RPM_SUSPENDING)
+				dev->power.deferred_resume = true;
+			retval = -EINPROGRESS;
+			goto out;
+		}
+
+		/* Wait for the operation carried out in parallel with us. */
+		for (;;) {
+			prepare_to_wait(&dev->power.wait_queue, &wait,
+					TASK_UNINTERRUPTIBLE);
+			if (dev->power.runtime_status != RPM_RESUMING
+			    && dev->power.runtime_status != RPM_SUSPENDING)
+				break;
+
+			spin_unlock_irq(&dev->power.lock);
+
+			schedule();
+
+			spin_lock_irq(&dev->power.lock);
+		}
+		finish_wait(&dev->power.wait_queue, &wait);
+		goto repeat;
+	}
+
+	if (!parent && dev->parent) {
+		/*
+		 * Increment the parent's resume counter and resume it if
+		 * necessary.
+		 */
+		parent = dev->parent;
+		spin_unlock_irq(&dev->power.lock);
+
+		pm_runtime_get_noresume(parent);
+
+		spin_lock_irq(&parent->power.lock);
+		/*
+		 * We can resume if the parent's run-time PM is disabled or it
+		 * is set to ignore children.
+		 */
+		if (!parent->power.disable_depth
+		    && !parent->power.ignore_children) {
+			__pm_runtime_resume(parent, false);
+			if (parent->power.runtime_status != RPM_ACTIVE)
+				retval = -EBUSY;
+		}
+		spin_unlock_irq(&parent->power.lock);
+
+		spin_lock_irq(&dev->power.lock);
+		if (retval)
+			goto out;
+		goto repeat;
+	}
+
+	dev->power.runtime_status = RPM_RESUMING;
+
+	if (dev->bus && dev->bus->pm && dev->bus->pm->runtime_resume) {
+		spin_unlock_irq(&dev->power.lock);
+
+		retval = dev->bus->pm->runtime_resume(dev);
+
+		spin_lock_irq(&dev->power.lock);
+		dev->power.runtime_error = retval;
+	} else {
+		retval = -ENOSYS;
+	}
+
+	if (retval) {
+		dev->power.runtime_status = RPM_SUSPENDED;
+		pm_runtime_cancel_pending(dev);
+	} else {
+		dev->power.runtime_status = RPM_ACTIVE;
+		if (parent)
+			atomic_inc(&parent->power.child_count);
+	}
+	wake_up_all(&dev->power.wait_queue);
+
+	if (!retval)
+		__pm_request_idle(dev);
+
+ out:
+	if (parent) {
+		spin_unlock_irq(&dev->power.lock);
+
+		pm_runtime_put(parent);
+
+		spin_lock_irq(&dev->power.lock);
+	}
+
+	dev_dbg(dev, "__pm_runtime_resume() returns %d!\n", retval);
+
+	return retval;
+}
+
+/**
+ * pm_runtime_resume - Carry out run-time resume of given device.
+ * @dev: Device to suspend.
+ */
+int pm_runtime_resume(struct device *dev)
+{
+	int retval;
+
+	spin_lock_irq(&dev->power.lock);
+	retval = __pm_runtime_resume(dev, false);
+	spin_unlock_irq(&dev->power.lock);
+
+	return retval;
+}
+EXPORT_SYMBOL_GPL(pm_runtime_resume);
+
+/**
+ * pm_runtime_work - Universal run-time PM work function.
+ * @work: Work structure used for scheduling the execution of this function.
+ *
+ * Use @work to get the device object the work is to be done for, determine what
+ * is to be done and execute the appropriate run-time PM function.
+ */
+static void pm_runtime_work(struct work_struct *work)
+{
+	struct device *dev = container_of(work, struct device, power.work);
+	enum rpm_request req;
+
+	spin_lock_irq(&dev->power.lock);
+
+	if (!dev->power.request_pending)
+		goto out;
+
+	req = dev->power.request;
+	dev->power.request = RPM_REQ_NONE;
+	dev->power.request_pending = false;
+
+	switch (req) {
+	case RPM_REQ_NONE:
+		break;
+	case RPM_REQ_IDLE:
+		__pm_runtime_idle(dev);
+		break;
+	case RPM_REQ_SUSPEND:
+		__pm_runtime_suspend(dev, true);
+		break;
+	case RPM_REQ_RESUME:
+		__pm_runtime_resume(dev, true);
+		break;
+	}
+
+ out:
+	spin_unlock_irq(&dev->power.lock);
+}
+
+/**
+ * __pm_request_idle - Submit an idle notification request for given device.
+ * @dev: Device to handle.
+ *
+ * Check if the device's run-time PM status is correct for suspending the device
+ * and queue up a request to run __pm_runtime_idle() for it.
+ *
+ * This function must be called under dev->power.lock with interrupts disabled.
+ */
+static int __pm_request_idle(struct device *dev)
+{
+	int retval = 0;
+
+	if (dev->power.runtime_error)
+		retval = -EINVAL;
+	else if (atomic_read(&dev->power.usage_count) > 0
+	    || dev->power.disable_depth > 0
+	    || dev->power.runtime_status == RPM_SUSPENDED
+	    || dev->power.runtime_status == RPM_SUSPENDING)
+		retval = -EAGAIN;
+	else if (!pm_children_suspended(dev))
+		retval = -EBUSY;
+	if (retval)
+		return retval;
+
+	if (dev->power.request_pending) {
+		/* Any requests other then RPM_REQ_IDLE take precedence. */
+		if (dev->power.request == RPM_REQ_NONE)
+			dev->power.request = RPM_REQ_IDLE;
+		else if (dev->power.request != RPM_REQ_IDLE)
+			retval = -EAGAIN;
+		return retval;
+	}
+
+	dev->power.request = RPM_REQ_IDLE;
+	dev->power.request_pending = true;
+	queue_work(pm_wq, &dev->power.work);
+
+	return retval;
+}
+
+/**
+ * pm_request_idle - Submit an idle notification request for given device.
+ * @dev: Device to handle.
+ */
+int pm_request_idle(struct device *dev)
+{
+	unsigned long flags;
+	int retval;
+
+	spin_lock_irqsave(&dev->power.lock, flags);
+	retval = __pm_request_idle(dev);
+	spin_unlock_irqrestore(&dev->power.lock, flags);
+
+	return retval;
+}
+EXPORT_SYMBOL_GPL(pm_request_idle);
+
+/**
+ * __pm_request_suspend - Submit a suspend request for given device.
+ * @dev: Device to suspend.
+ *
+ * This function must be called under dev->power.lock with interrupts disabled.
+ */
+static int __pm_request_suspend(struct device *dev)
+{
+	int retval = 0;
+
+	if (dev->power.runtime_error)
+		return -EINVAL;
+
+	if (dev->power.runtime_status == RPM_SUSPENDED)
+		retval = 1;
+	else if (atomic_read(&dev->power.usage_count) > 0
+	    || dev->power.disable_depth > 0)
+		retval = -EAGAIN;
+	else if (dev->power.runtime_status == RPM_SUSPENDING)
+		retval = -EINPROGRESS;
+	else if (!pm_children_suspended(dev))
+		retval = -EBUSY;
+	if (retval < 0)
+		return retval;
+
+	pm_runtime_deactivate_timer(dev);
+
+	if (dev->power.request_pending) {
+		/*
+		 * Pending resume requests take precedence over us, but we can
+		 * overtake any other pending request.
+		 */
+		if (dev->power.request == RPM_REQ_RESUME)
+			retval = -EAGAIN;
+		else if (dev->power.request != RPM_REQ_SUSPEND)
+			dev->power.request = retval ?
+						RPM_REQ_NONE : RPM_REQ_SUSPEND;
+		return retval;
+	} else if (retval) {
+		return retval;
+	}
+
+	dev->power.request = RPM_REQ_SUSPEND;
+	dev->power.request_pending = true;
+	queue_work(pm_wq, &dev->power.work);
+
+	return 0;
+}
+
+/**
+ * pm_suspend_timer_fn - Timer function for pm_schedule_suspend().
+ * @data: Device pointer passed by pm_schedule_suspend().
+ *
+ * Check if the time is right and execute __pm_request_suspend() in that case.
+ */
+static void pm_suspend_timer_fn(unsigned long data)
+{
+	struct device *dev = (struct device *)data;
+	unsigned long flags;
+	unsigned long expires;
+
+	spin_lock_irqsave(&dev->power.lock, flags);
+
+	expires = dev->power.timer_expires;
+	/* If 'expire' is after 'jiffies' we've been called too early. */
+	if (expires > 0 && !time_after(expires, jiffies)) {
+		dev->power.timer_expires = 0;
+		__pm_request_suspend(dev);
+	}
+
+	spin_unlock_irqrestore(&dev->power.lock, flags);
+}
+
+/**
+ * pm_schedule_suspend - Set up a timer to submit a suspend request in future.
+ * @dev: Device to suspend.
+ * @delay: Time to wait before submitting a suspend request, in milliseconds.
+ */
+int pm_schedule_suspend(struct device *dev, unsigned int delay)
+{
+	unsigned long flags;
+	int retval = 0;
+
+	spin_lock_irqsave(&dev->power.lock, flags);
+
+	if (dev->power.runtime_error) {
+		retval = -EINVAL;
+		goto out;
+	}
+
+	if (!delay) {
+		retval = __pm_request_suspend(dev);
+		goto out;
+	}
+
+	pm_runtime_deactivate_timer(dev);
+
+	if (dev->power.request_pending) {
+		/*
+		 * Pending resume requests take precedence over us, but any
+		 * other pending requests have to be canceled.
+		 */
+		if (dev->power.request == RPM_REQ_RESUME) {
+			retval = -EAGAIN;
+			goto out;
+		}
+		dev->power.request = RPM_REQ_NONE;
+	}
+
+	if (dev->power.runtime_status == RPM_SUSPENDED)
+		retval = 1;
+	else if (dev->power.runtime_status == RPM_SUSPENDING)
+		retval = -EINPROGRESS;
+	else if (atomic_read(&dev->power.usage_count) > 0
+	    || dev->power.disable_depth > 0)
+		retval = -EAGAIN;
+	else if (!pm_children_suspended(dev))
+		retval = -EBUSY;
+	if (retval)
+		goto out;
+
+	dev->power.timer_expires = jiffies + msecs_to_jiffies(delay);
+	mod_timer(&dev->power.suspend_timer, dev->power.timer_expires);
+
+ out:
+	spin_unlock_irqrestore(&dev->power.lock, flags);
+
+	return retval;
+}
+EXPORT_SYMBOL_GPL(pm_schedule_suspend);
+
+/**
+ * pm_request_resume - Submit a resume request for given device.
+ * @dev: Device to resume.
+ *
+ * This function must be called under dev->power.lock with interrupts disabled.
+ */
+static int __pm_request_resume(struct device *dev)
+{
+	int retval = 0;
+
+	if (dev->power.runtime_error)
+		return -EINVAL;
+
+	if (dev->power.runtime_status == RPM_ACTIVE)
+		retval = 1;
+	else if (dev->power.runtime_status == RPM_RESUMING)
+		retval = -EINPROGRESS;
+	else if (dev->power.disable_depth > 0)
+		retval = -EAGAIN;
+	if (retval < 0)
+		return retval;
+
+	pm_runtime_deactivate_timer(dev);
+
+	if (dev->power.request_pending) {
+		/* If non-resume request is pending, we can overtake it. */
+		dev->power.request = retval ? RPM_REQ_NONE : RPM_REQ_RESUME;
+		return retval;
+	} else if (retval) {
+		return retval;
+	}
+
+	dev->power.request = RPM_REQ_RESUME;
+	dev->power.request_pending = true;
+	queue_work(pm_wq, &dev->power.work);
+
+	return retval;
+}
+
+/**
+ * pm_request_resume - Submit a resume request for given device.
+ * @dev: Device to resume.
+ */
+int pm_request_resume(struct device *dev)
+{
+	unsigned long flags;
+	int retval;
+
+	spin_lock_irqsave(&dev->power.lock, flags);
+	retval = __pm_request_resume(dev);
+	spin_unlock_irqrestore(&dev->power.lock, flags);
+
+	return retval;
+}
+EXPORT_SYMBOL_GPL(pm_request_resume);
+
+/**
+ * __pm_runtime_get - Reference count a device and wake it up, if necessary.
+ * @dev: Device to handle.
+ * @sync: If set and the device is suspended, resume it synchronously.
+ *
+ * Increment the usage count of the device and if it was zero previously,
+ * resume it or submit a resume request for it, depending on the value of @sync.
+ */
+int __pm_runtime_get(struct device *dev, bool sync)
+{
+	int retval = 1;
+
+	if (atomic_add_return(1, &dev->power.usage_count) == 1)
+		retval = sync ? pm_runtime_resume(dev) : pm_request_resume(dev);
+
+	return retval;
+}
+EXPORT_SYMBOL_GPL(__pm_runtime_get);
+
+/**
+ * __pm_runtime_put - Decrement the device's usage counter and notify its bus.
+ * @dev: Device to handle.
+ * @sync: If the device's bus type is to be notified, do that synchronously.
+ *
+ * Decrement the usage count of the device and if it reaches zero, carry out a
+ * synchronous idle notification or submit an idle notification request for it,
+ * depending on the value of @sync.
+ */
+int __pm_runtime_put(struct device *dev, bool sync)
+{
+	int retval = 0;
+
+	if (atomic_dec_and_test(&dev->power.usage_count))
+		retval = sync ? pm_runtime_idle(dev) : pm_request_idle(dev);
+
+	return retval;
+}
+EXPORT_SYMBOL_GPL(__pm_runtime_put);
+
+/**
+ * __pm_runtime_set_status - Set run-time PM status of a device.
+ * @dev: Device to handle.
+ * @status: New run-time PM status of the device.
+ *
+ * If run-time PM of the device is disabled or its power.runtime_error field is
+ * different from zero, the status may be changed either to RPM_ACTIVE, or to
+ * RPM_SUSPENDED, as long as that reflects the actual state of the device.
+ * However, if the device has a parent and the parent is not active, and the
+ * parent's power.ignore_children flag is unset, the device's status cannot be
+ * set to RPM_ACTIVE, so -EBUSY is returned in that case.
+ *
+ * If successful, __pm_runtime_set_status() clears the power.runtime_error field
+ * and the device parent's counter of unsuspended children is modified to
+ * reflect the new status.  If the new status is RPM_SUSPENDED, an idle
+ * notification request for the parent is submitted.
+ */
+int __pm_runtime_set_status(struct device *dev, unsigned int status)
+{
+	struct device *parent = dev->parent;
+	unsigned long flags;
+	bool notify_parent = false;
+	int error = 0;
+
+	if (status != RPM_ACTIVE && status != RPM_SUSPENDED)
+		return -EINVAL;
+
+	spin_lock_irqsave(&dev->power.lock, flags);
+
+	if (!dev->power.runtime_error && !dev->power.disable_depth) {
+		error = -EAGAIN;
+		goto out;
+	}
+
+	if (dev->power.runtime_status == status)
+		goto out_set;
+
+	if (status == RPM_SUSPENDED) {
+		/* It always is possible to set the status to 'suspended'. */
+		if (parent) {
+			atomic_add_unless(&parent->power.child_count, -1, 0);
+			notify_parent = !parent->power.ignore_children;
+		}
+		goto out_set;
+	}
+
+	if (parent) {
+		spin_lock_irq(&parent->power.lock);
+
+		/*
+		 * It is invalid to put an active child under a parent that is
+		 * not active, has run-time PM enabled and the
+		 * 'power.ignore_children' flag unset.
+		 */
+		if (!parent->power.disable_depth
+		    && !parent->power.ignore_children
+		    && parent->power.runtime_status != RPM_ACTIVE) {
+			error = -EBUSY;
+		} else {
+			if (dev->power.runtime_status == RPM_SUSPENDED)
+				atomic_inc(&parent->power.child_count);
+		}
+
+		spin_unlock_irq(&parent->power.lock);
+
+		if (error)
+			goto out;
+	}
+
+ out_set:
+	dev->power.runtime_status = status;
+	dev->power.runtime_error = 0;
+ out:
+	spin_unlock_irqrestore(&dev->power.lock, flags);
+
+	if (notify_parent)
+		pm_request_idle(parent);
+
+	return error;
+}
+EXPORT_SYMBOL_GPL(__pm_runtime_set_status);
+
+/**
+ * __pm_runtime_barrier - Cancel pending requests and wait for completions.
+ * @dev: Device to handle.
+ *
+ * Flush all pending requests for the device from pm_wq and wait for all
+ * run-time PM operations involving the device in progress to complete.
+ *
+ * Should be called under dev->power.lock with interrupts disabled.
+ */
+static void __pm_runtime_barrier(struct device *dev)
+{
+	pm_runtime_deactivate_timer(dev);
+
+	if (dev->power.request_pending) {
+		dev->power.request = RPM_REQ_NONE;
+		spin_unlock_irq(&dev->power.lock);
+
+		cancel_work_sync(&dev->power.work);
+
+		spin_lock_irq(&dev->power.lock);
+		dev->power.request_pending = false;
+	}
+
+	if (dev->power.runtime_status == RPM_SUSPENDING
+	    || dev->power.runtime_status == RPM_RESUMING
+	    || dev->power.idle_notification) {
+		DEFINE_WAIT(wait);
+
+		/* Suspend, wake-up or idle notification in progress. */
+		for (;;) {
+			prepare_to_wait(&dev->power.wait_queue, &wait,
+					TASK_UNINTERRUPTIBLE);
+			if (dev->power.runtime_status != RPM_SUSPENDING
+			    && dev->power.runtime_status != RPM_RESUMING
+			    && !dev->power.idle_notification)
+				break;
+			spin_unlock_irq(&dev->power.lock);
+
+			schedule();
+
+			spin_lock_irq(&dev->power.lock);
+		}
+		finish_wait(&dev->power.wait_queue, &wait);
+	}
+}
+
+/**
+ * pm_runtime_barrier - Flush pending requests and wait for completions.
+ * @dev: Device to handle.
+ *
+ * Prevent the device from being suspended by incrementing its usage counter and
+ * if there's a pending resume request for the device, wake the device up.
+ * Next, make sure that all pending requests for the device have been flushed
+ * from pm_wq and wait for all run-time PM operations involving the device in
+ * progress to complete.
+ *
+ * Return value:
+ * 1, if there was a resume request pending and the device had to be woken up,
+ * 0, otherwise
+ */
+int pm_runtime_barrier(struct device *dev)
+{
+	int retval = 0;
+
+	pm_runtime_get_noresume(dev);
+	spin_lock_irq(&dev->power.lock);
+
+	if (dev->power.request_pending
+	    && dev->power.request == RPM_REQ_RESUME) {
+		__pm_runtime_resume(dev, false);
+		retval = 1;
+	}
+
+	__pm_runtime_barrier(dev);
+
+	spin_unlock_irq(&dev->power.lock);
+	pm_runtime_put_noidle(dev);
+
+	return retval;
+}
+EXPORT_SYMBOL_GPL(pm_runtime_barrier);
+
+/**
+ * __pm_runtime_disable - Disable run-time PM of a device.
+ * @dev: Device to handle.
+ * @check_resume: If set, check if there's a resume request for the device.
+ *
+ * Increment power.disable_depth for the device and if was zero previously,
+ * cancel all pending run-time PM requests for the device and wait for all
+ * operations in progress to complete.  The device can be either active or
+ * suspended after its run-time PM has been disabled.
+ *
+ * If @check_resume is set and there's a resume request pending when
+ * __pm_runtime_disable() is called and power.disable_depth is zero, the
+ * function will wake up the device before disabling its run-time PM.
+ */
+void __pm_runtime_disable(struct device *dev, bool check_resume)
+{
+	spin_lock_irq(&dev->power.lock);
+
+	if (dev->power.disable_depth > 0) {
+		dev->power.disable_depth++;
+		goto out;
+	}
+
+	/*
+	 * Wake up the device if there's a resume request pending, because that
+	 * means there probably is some I/O to process and disabling run-time PM
+	 * shouldn't prevent the device from processing the I/O.
+	 */
+	if (check_resume && dev->power.request_pending
+	    && dev->power.request == RPM_REQ_RESUME) {
+		/*
+		 * Prevent suspends and idle notifications from being carried
+		 * out after we have woken up the device.
+		 */
+		pm_runtime_get_noresume(dev);
+
+		__pm_runtime_resume(dev, false);
+
+		pm_runtime_put_noidle(dev);
+	}
+
+	if (!dev->power.disable_depth++)
+		__pm_runtime_barrier(dev);
+
+ out:
+	spin_unlock_irq(&dev->power.lock);
+}
+EXPORT_SYMBOL_GPL(__pm_runtime_disable);
+
+/**
+ * pm_runtime_enable - Enable run-time PM of a device.
+ * @dev: Device to handle.
+ */
+void pm_runtime_enable(struct device *dev)
+{
+	unsigned long flags;
+
+	spin_lock_irqsave(&dev->power.lock, flags);
+
+	if (dev->power.disable_depth > 0)
+		dev->power.disable_depth--;
+	else
+		dev_warn(dev, "Unbalanced %s!\n", __func__);
+
+	spin_unlock_irqrestore(&dev->power.lock, flags);
+}
+EXPORT_SYMBOL_GPL(pm_runtime_enable);
+
+/**
+ * pm_runtime_init - Initialize run-time PM fields in given device object.
+ * @dev: Device object to initialize.
+ */
+void pm_runtime_init(struct device *dev)
+{
+	spin_lock_init(&dev->power.lock);
+
+	dev->power.runtime_status = RPM_SUSPENDED;
+	dev->power.idle_notification = false;
+
+	dev->power.disable_depth = 1;
+	atomic_set(&dev->power.usage_count, 0);
+
+	dev->power.runtime_error = 0;
+
+	atomic_set(&dev->power.child_count, 0);
+	pm_suspend_ignore_children(dev, false);
+
+	dev->power.request_pending = false;
+	dev->power.request = RPM_REQ_NONE;
+	dev->power.deferred_resume = false;
+	INIT_WORK(&dev->power.work, pm_runtime_work);
+
+	dev->power.timer_expires = 0;
+	setup_timer(&dev->power.suspend_timer, pm_suspend_timer_fn,
+			(unsigned long)dev);
+
+	init_waitqueue_head(&dev->power.wait_queue);
+}
+
+/**
+ * pm_runtime_remove - Prepare for removing a device from device hierarchy.
+ * @dev: Device object being removed from device hierarchy.
+ */
+void pm_runtime_remove(struct device *dev)
+{
+	__pm_runtime_disable(dev, false);
+
+	/* Change the status back to 'suspended' to match the initial status. */
+	if (dev->power.runtime_status == RPM_ACTIVE)
+		pm_runtime_set_suspended(dev);
+}

commit 3f8df781fc5f9ee5253a54ba669e1c8872844b86
Author: Alan Stern <stern@rowland.harvard.edu>
Date:   Thu Jul 12 16:57:22 2007 -0400

    PM: remove deprecated dpm_runtime_* routines
    
    This patch (as933) removes the deprecated dpm_runtime_suspend() and
    dpm_runtime_resume() routines from the PM core.  The only user of
    those routines is the PCMCIA ds driver; local replacements are added.
    
    Signed-off-by: Alan Stern <stern@rowland.harvard.edu>
    CC: Dominik Brodowski <linux@dominikbrodowski.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@suse.de>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
deleted file mode 100644
index df6174d85866..000000000000
--- a/drivers/base/power/runtime.c
+++ /dev/null
@@ -1,85 +0,0 @@
-/*
- * drivers/base/power/runtime.c - Handling dynamic device power management.
- *
- * Copyright (c) 2003 Patrick Mochel
- * Copyright (c) 2003 Open Source Development Lab
- *
- */
-
-#include <linux/device.h>
-#include "power.h"
-
-
-static void runtime_resume(struct device * dev)
-{
-	dev_dbg(dev, "resuming\n");
-	if (!dev->power.power_state.event)
-		return;
-	if (!resume_device(dev))
-		dev->power.power_state = PMSG_ON;
-}
-
-
-/**
- *	dpm_runtime_resume - Power one device back on.
- *	@dev:	Device.
- *
- *	Bring one device back to the on state by first powering it
- *	on, then restoring state. We only operate on devices that aren't
- *	already on.
- *	FIXME: We need to handle devices that are in an unknown state.
- */
-
-void dpm_runtime_resume(struct device * dev)
-{
-	mutex_lock(&dpm_mtx);
-	runtime_resume(dev);
-	mutex_unlock(&dpm_mtx);
-}
-EXPORT_SYMBOL(dpm_runtime_resume);
-
-
-/**
- *	dpm_runtime_suspend - Put one device in low-power state.
- *	@dev:	Device.
- *	@state:	State to enter.
- */
-
-int dpm_runtime_suspend(struct device * dev, pm_message_t state)
-{
-	int error = 0;
-
-	mutex_lock(&dpm_mtx);
-	if (dev->power.power_state.event == state.event)
-		goto Done;
-
-	if (dev->power.power_state.event)
-		runtime_resume(dev);
-
-	if (!(error = suspend_device(dev, state)))
-		dev->power.power_state = state;
- Done:
-	mutex_unlock(&dpm_mtx);
-	return error;
-}
-EXPORT_SYMBOL(dpm_runtime_suspend);
-
-
-#if 0
-/**
- *	dpm_set_power_state - Update power_state field.
- *	@dev:	Device.
- *	@state:	Power state device is in.
- *
- *	This is an update mechanism for drivers to notify the core
- *	what power state a device is in. Device probing code may not
- *	always be able to tell, but we need accurate information to
- *	work reliably.
- */
-void dpm_set_power_state(struct device * dev, pm_message_t state)
-{
-	mutex_lock(&dpm_mtx);
-	dev->power.power_state = state;
-	mutex_unlock(&dpm_mtx);
-}
-#endif  /*  0  */

commit 11048dcf333c414f237bb713c422e68f67b115a3
Author: Matthias Kaehlcke <matthias.kaehlcke@gmail.com>
Date:   Wed May 23 14:19:41 2007 -0700

    Power Management: use mutexes instead of semaphores
    
    The Power Management code uses semaphores as mutexes.  Use the mutex API
    instead of the (binary) semaphores.
    
    Signed-off-by: Matthias Kaehlcke <matthias.kaehlcke@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@suse.de>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 96370ec1d673..df6174d85866 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -32,9 +32,9 @@ static void runtime_resume(struct device * dev)
 
 void dpm_runtime_resume(struct device * dev)
 {
-	down(&dpm_sem);
+	mutex_lock(&dpm_mtx);
 	runtime_resume(dev);
-	up(&dpm_sem);
+	mutex_unlock(&dpm_mtx);
 }
 EXPORT_SYMBOL(dpm_runtime_resume);
 
@@ -49,7 +49,7 @@ int dpm_runtime_suspend(struct device * dev, pm_message_t state)
 {
 	int error = 0;
 
-	down(&dpm_sem);
+	mutex_lock(&dpm_mtx);
 	if (dev->power.power_state.event == state.event)
 		goto Done;
 
@@ -59,7 +59,7 @@ int dpm_runtime_suspend(struct device * dev, pm_message_t state)
 	if (!(error = suspend_device(dev, state)))
 		dev->power.power_state = state;
  Done:
-	up(&dpm_sem);
+	mutex_unlock(&dpm_mtx);
 	return error;
 }
 EXPORT_SYMBOL(dpm_runtime_suspend);
@@ -78,8 +78,8 @@ EXPORT_SYMBOL(dpm_runtime_suspend);
  */
 void dpm_set_power_state(struct device * dev, pm_message_t state)
 {
-	down(&dpm_sem);
+	mutex_lock(&dpm_mtx);
 	dev->power.power_state = state;
-	up(&dpm_sem);
+	mutex_unlock(&dpm_mtx);
 }
 #endif  /*  0  */

commit 8e9e793d68fcda6cc84c18cedf85ca0f91d801a8
Author: Dominik Brodowski <linux@dominikbrodowski.net>
Date:   Fri Jan 6 00:02:03 2006 +0100

    [PATCH] pcmcia: merge suspend into device model
    
    Merge the suspend and resume methods for 16-bit PCMCIA cards into the
    device model -- for both runtime power management and suspend to ram/disk.
    
    Bugfix in ds.c by Richard Purdie
    Signed-Off-By: Richard Purdie <rpurdie@rpsys.net>
    
    Signed-off-by: Dominik Brodowski <linux@dominikbrodowski.net>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 4bafef83e79f..96370ec1d673 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -62,6 +62,7 @@ int dpm_runtime_suspend(struct device * dev, pm_message_t state)
 	up(&dpm_sem);
 	return error;
 }
+EXPORT_SYMBOL(dpm_runtime_suspend);
 
 
 #if 0

commit 1f1bf132d81ed723bc5fefbcec7d0779ce683a4f
Author: Adrian Bunk <bunk@stusta.de>
Date:   Mon Dec 12 01:31:03 2005 -0800

    [PATCH] drivers/base/power/runtime.c: #if 0 dpm_set_power_state()
    
    This patch #if 0's an unused global function.
    
    Signed-off-by: Adrian Bunk <bunk@stusta.de>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@suse.de>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index adbc3148c039..4bafef83e79f 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -64,6 +64,7 @@ int dpm_runtime_suspend(struct device * dev, pm_message_t state)
 }
 
 
+#if 0
 /**
  *	dpm_set_power_state - Update power_state field.
  *	@dev:	Device.
@@ -80,3 +81,4 @@ void dpm_set_power_state(struct device * dev, pm_message_t state)
 	dev->power.power_state = state;
 	up(&dpm_sem);
 }
+#endif  /*  0  */

commit 979d5199fee9e80290ddeb532e5993bd15506712
Author: David Brownell <david-b@pacbell.net>
Date:   Thu Sep 22 22:32:24 2005 -0700

    [PATCH] root hub changes (lesser half)
    
    This patch collects various small updates related to root hubs, to shrink
    later patches which build on them.
    
      - For root hub suspend/resume support:
         * Make the existing usb_hcd_resume_root_hub() routine respect pmcore
           locking, exporting and using the dpm_runtime_resume() method.
         * Add a new usb_hcd_suspend_root_hub() to pair with that routine.
           (Essential to make OHCI autosuspend behave again...)
         * HC_SUSPENDED by itself only refers to the root hub's downstream ports.
           So let HCDs see root hub URBs unless the parent device is suspended.
    
      - Remove an assertion we no longer need (and now, also don't want).
    
      - Generic suspend/resume updates to work better with swsusp.
         * Ignore the FREEZE vs SUSPEND distinction for hardware; trying to
           use it breaks the swsusp snapshots it's supposed to help (sigh).
         * On resume, mark devices as resumed right away, but then
           do nothing else if the device is marked NOTATTACHED.
    
    These changes shouldn't be very noticable by themselves.
    
    Signed-off-by: David Brownell <dbrownell@users.sourceforge.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@suse.de>
    
     drivers/base/power/runtime.c |    1
     drivers/usb/core/hcd.c       |   64 ++++++++++++++++++++++++++++++++++++++-----
     drivers/usb/core/hcd.h       |    1
     drivers/usb/core/hub.c       |   45 ++++++++++++++++++++++++------
     drivers/usb/core/usb.c       |   20 +++++++++----
     drivers/usb/core/usb.h       |    1
     6 files changed, 111 insertions(+), 21 deletions(-)

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index e8f0519f5dfa..adbc3148c039 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -36,6 +36,7 @@ void dpm_runtime_resume(struct device * dev)
 	runtime_resume(dev);
 	up(&dpm_sem);
 }
+EXPORT_SYMBOL(dpm_runtime_resume);
 
 
 /**

commit ca078bae813dd46c0f9b102fdfb4a3384641ff48
Author: Pavel Machek <pavel@ucw.cz>
Date:   Sat Sep 3 15:56:57 2005 -0700

    [PATCH] swsusp: switch pm_message_t to struct
    
    This adds type-checking to pm_message_t, so that people can't confuse it
    with int or u32.  It also allows us to fix "disk yoyo" during suspend (disk
    spinning down/up/down).
    
    [We've tried that before; since that cpufreq problems were fixed and I've
    tried make allyes config and fixed resulting damage.]
    
    Signed-off-by: Pavel Machek <pavel@suse.cz>
    Signed-off-by: Alexander Nyberg <alexn@telia.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 325962d80191..e8f0519f5dfa 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -13,10 +13,10 @@
 static void runtime_resume(struct device * dev)
 {
 	dev_dbg(dev, "resuming\n");
-	if (!dev->power.power_state)
+	if (!dev->power.power_state.event)
 		return;
 	if (!resume_device(dev))
-		dev->power.power_state = 0;
+		dev->power.power_state = PMSG_ON;
 }
 
 
@@ -49,10 +49,10 @@ int dpm_runtime_suspend(struct device * dev, pm_message_t state)
 	int error = 0;
 
 	down(&dpm_sem);
-	if (dev->power.power_state == state)
+	if (dev->power.power_state.event == state.event)
 		goto Done;
 
-	if (dev->power.power_state)
+	if (dev->power.power_state.event)
 		runtime_resume(dev);
 
 	if (!(error = suspend_device(dev, state)))

commit 1da177e4c3f41524e886b7f1b8a0c1fc7321cac2
Author: Linus Torvalds <torvalds@ppc970.osdl.org>
Date:   Sat Apr 16 15:20:36 2005 -0700

    Linux-2.6.12-rc2
    
    Initial git repository build. I'm not bothering with the full history,
    even though we have it. We can create a separate "historical" git
    archive of that later if we want to, and in the meantime it's about
    3.2GB when imported into git - space that would just make the early
    git days unnecessarily complicated, when we don't have a lot of good
    infrastructure for it.
    
    Let it rip!

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
new file mode 100644
index 000000000000..325962d80191
--- /dev/null
+++ b/drivers/base/power/runtime.c
@@ -0,0 +1,81 @@
+/*
+ * drivers/base/power/runtime.c - Handling dynamic device power management.
+ *
+ * Copyright (c) 2003 Patrick Mochel
+ * Copyright (c) 2003 Open Source Development Lab
+ *
+ */
+
+#include <linux/device.h>
+#include "power.h"
+
+
+static void runtime_resume(struct device * dev)
+{
+	dev_dbg(dev, "resuming\n");
+	if (!dev->power.power_state)
+		return;
+	if (!resume_device(dev))
+		dev->power.power_state = 0;
+}
+
+
+/**
+ *	dpm_runtime_resume - Power one device back on.
+ *	@dev:	Device.
+ *
+ *	Bring one device back to the on state by first powering it
+ *	on, then restoring state. We only operate on devices that aren't
+ *	already on.
+ *	FIXME: We need to handle devices that are in an unknown state.
+ */
+
+void dpm_runtime_resume(struct device * dev)
+{
+	down(&dpm_sem);
+	runtime_resume(dev);
+	up(&dpm_sem);
+}
+
+
+/**
+ *	dpm_runtime_suspend - Put one device in low-power state.
+ *	@dev:	Device.
+ *	@state:	State to enter.
+ */
+
+int dpm_runtime_suspend(struct device * dev, pm_message_t state)
+{
+	int error = 0;
+
+	down(&dpm_sem);
+	if (dev->power.power_state == state)
+		goto Done;
+
+	if (dev->power.power_state)
+		runtime_resume(dev);
+
+	if (!(error = suspend_device(dev, state)))
+		dev->power.power_state = state;
+ Done:
+	up(&dpm_sem);
+	return error;
+}
+
+
+/**
+ *	dpm_set_power_state - Update power_state field.
+ *	@dev:	Device.
+ *	@state:	Power state device is in.
+ *
+ *	This is an update mechanism for drivers to notify the core
+ *	what power state a device is in. Device probing code may not
+ *	always be able to tell, but we need accurate information to
+ *	work reliably.
+ */
+void dpm_set_power_state(struct device * dev, pm_message_t state)
+{
+	down(&dpm_sem);
+	dev->power.power_state = state;
+	up(&dpm_sem);
+}
