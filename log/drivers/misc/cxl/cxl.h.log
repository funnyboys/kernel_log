commit 4a14abc4bbe58aa465f0f5599bf4c612cfeb367f
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Jun 12 17:54:18 2019 +0200

    cxl: no need to check return value of debugfs_create functions
    
    When calling debugfs functions, there is no need to ever check the
    return value.  The function can work or not, but the code logic should
    never do something different based on this.
    
    Because there's no need to check, also make the return value of the
    local debugfs_create_io_x64() call void, as no one ever did anything
    with the return value (as they did not need to.)
    
    And make the cxl_debugfs_* calls return void as no one was even checking
    their return value at all.
    
    Cc: linuxppc-dev@lists.ozlabs.org
    Acked-by: Andrew Donnellan <ajd@linux.ibm.com>
    Reviewed-by: Frederic Barrat <fbarrat@linux.ibm.com>
    Reviewed-by: Arnd Bergmann <arnd@arndb.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index a73c9e669d78..5dc0f6093f9d 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -908,11 +908,11 @@ void cxl_update_dedicated_ivtes_psl8(struct cxl_context *ctx);
 
 #ifdef CONFIG_DEBUG_FS
 
-int cxl_debugfs_init(void);
+void cxl_debugfs_init(void);
 void cxl_debugfs_exit(void);
-int cxl_debugfs_adapter_add(struct cxl *adapter);
+void cxl_debugfs_adapter_add(struct cxl *adapter);
 void cxl_debugfs_adapter_remove(struct cxl *adapter);
-int cxl_debugfs_afu_add(struct cxl_afu *afu);
+void cxl_debugfs_afu_add(struct cxl_afu *afu);
 void cxl_debugfs_afu_remove(struct cxl_afu *afu);
 void cxl_debugfs_add_adapter_regs_psl9(struct cxl *adapter, struct dentry *dir);
 void cxl_debugfs_add_adapter_regs_psl8(struct cxl *adapter, struct dentry *dir);
@@ -921,27 +921,24 @@ void cxl_debugfs_add_afu_regs_psl8(struct cxl_afu *afu, struct dentry *dir);
 
 #else /* CONFIG_DEBUG_FS */
 
-static inline int __init cxl_debugfs_init(void)
+static inline void __init cxl_debugfs_init(void)
 {
-	return 0;
 }
 
 static inline void cxl_debugfs_exit(void)
 {
 }
 
-static inline int cxl_debugfs_adapter_add(struct cxl *adapter)
+static inline void cxl_debugfs_adapter_add(struct cxl *adapter)
 {
-	return 0;
 }
 
 static inline void cxl_debugfs_adapter_remove(struct cxl *adapter)
 {
 }
 
-static inline int cxl_debugfs_afu_add(struct cxl_afu *afu)
+static inline void cxl_debugfs_afu_add(struct cxl_afu *afu)
 {
-	return 0;
 }
 
 static inline void cxl_debugfs_afu_remove(struct cxl_afu *afu)

commit 2874c5fd284268364ece81a7bd936f3c8168e567
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon May 27 08:55:01 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 152
    
    Based on 1 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license as published by
      the free software foundation either version 2 of the license or at
      your option any later version
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-or-later
    
    has been chosen to replace the boilerplate/reference in 3029 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190527070032.746973796@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index d1d927ccb589..a73c9e669d78 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -1,10 +1,6 @@
+/* SPDX-License-Identifier: GPL-2.0-or-later */
 /*
  * Copyright 2014 IBM Corp.
- *
- * This program is free software; you can redistribute it and/or
- * modify it under the terms of the GNU General Public License
- * as published by the Free Software Foundation; either version
- * 2 of the License, or (at your option) any later version.
  */
 
 #ifndef _CXL_H_

commit ce57c6610cc2d7cde61fc005a2d2090bce46fc73
Merge: 9c3250a12790 a68bd1267b72
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Thu Jul 19 14:37:57 2018 +1000

    Merge branch 'topic/ppc-kvm' into next
    
    Merge in some commits we're sharing with the KVM tree.
    
    I manually propagated the change from commit d3d4ffaae439
    ("powerpc/powernv/ioda2: Reduce upper limit for DMA window size") into
    pci-ioda-tce.c.
    
    Conflicts:
            arch/powerpc/include/asm/cputable.h
            arch/powerpc/platforms/powernv/pci-ioda.c
            arch/powerpc/platforms/powernv/pci.h

commit 2bf1071a8d50928a4ae366bb3108833166c2b70c
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Thu Jul 5 18:47:00 2018 +1000

    powerpc/64s: Remove POWER9 DD1 support
    
    POWER9 DD1 was never a product. It is no longer supported by upstream
    firmware, and it is not effectively supported in Linux due to lack of
    testing.
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Reviewed-by: Michael Ellerman <mpe@ellerman.id.au>
    [mpe: Remove arch_make_huge_pte() entirely]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index 918d4fb742d1..505f973e13f3 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -865,14 +865,6 @@ static inline bool cxl_is_power9(void)
 	return false;
 }
 
-static inline bool cxl_is_power9_dd1(void)
-{
-	if ((pvr_version_is(PVR_POWER9)) &&
-	    cpu_has_feature(CPU_FTR_POWER9_DD1))
-		return true;
-	return false;
-}
-
 ssize_t cxl_pci_afu_read_err_buffer(struct cxl_afu *afu, char *buf,
 				loff_t off, size_t count);
 

commit f3988ca4c74e136e49487b51231d324d0c923495
Author: Frederic Barrat <fbarrat@linux.ibm.com>
Date:   Thu Jun 28 12:05:09 2018 +0200

    cxl: Remove abandonned capi support for the Mellanox CX4, final cleanup
    
    Remove a few XSL/CX4 oddities which are no longer needed. A simple
    revert of the initial commits was not possible (or not worth it) due
    to the history of the code.
    
    Signed-off-by: Frederic Barrat <fbarrat@linux.ibm.com>
    Acked-by: Andrew Donnellan <andrew.donnellan@au1.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index aa453448201d..44bcfafbb579 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -93,11 +93,6 @@ static const cxl_p1_reg_t CXL_PSL_FIR_CNTL  = {0x0148};
 static const cxl_p1_reg_t CXL_PSL_DSNDCTL   = {0x0150};
 static const cxl_p1_reg_t CXL_PSL_SNWRALLOC = {0x0158};
 static const cxl_p1_reg_t CXL_PSL_TRACE     = {0x0170};
-/* XSL registers (Mellanox CX4) */
-static const cxl_p1_reg_t CXL_XSL_Timebase  = {0x0100};
-static const cxl_p1_reg_t CXL_XSL_TB_CTLSTAT = {0x0108};
-static const cxl_p1_reg_t CXL_XSL_FEC       = {0x0158};
-static const cxl_p1_reg_t CXL_XSL_DSNCTL    = {0x0168};
 /* PSL registers - CAIA 2 */
 static const cxl_p1_reg_t CXL_PSL9_CONTROL  = {0x0020};
 static const cxl_p1_reg_t CXL_XSL9_INV      = {0x0110};
@@ -695,7 +690,6 @@ struct cxl {
 	struct bin_attribute cxl_attr;
 	int adapter_num;
 	int user_irqs;
-	int min_pe;
 	u64 ps_size;
 	u16 psl_rev;
 	u16 base_image;
@@ -934,7 +928,6 @@ int cxl_debugfs_afu_add(struct cxl_afu *afu);
 void cxl_debugfs_afu_remove(struct cxl_afu *afu);
 void cxl_debugfs_add_adapter_regs_psl9(struct cxl *adapter, struct dentry *dir);
 void cxl_debugfs_add_adapter_regs_psl8(struct cxl *adapter, struct dentry *dir);
-void cxl_debugfs_add_adapter_regs_xsl(struct cxl *adapter, struct dentry *dir);
 void cxl_debugfs_add_afu_regs_psl9(struct cxl_afu *afu, struct dentry *dir);
 void cxl_debugfs_add_afu_regs_psl8(struct cxl_afu *afu, struct dentry *dir);
 
@@ -977,11 +970,6 @@ static inline void cxl_debugfs_add_adapter_regs_psl8(struct cxl *adapter,
 {
 }
 
-static inline void cxl_debugfs_add_adapter_regs_xsl(struct cxl *adapter,
-						    struct dentry *dir)
-{
-}
-
 static inline void cxl_debugfs_add_afu_regs_psl9(struct cxl_afu *afu, struct dentry *dir)
 {
 }

commit f18a4e1d973bc69a50419eb8918f458ea89c6c3f
Author: Frederic Barrat <fbarrat@linux.ibm.com>
Date:   Thu Jun 28 12:05:08 2018 +0200

    Revert "cxl: Allow a default context to be associated with an external pci_dev"
    
    Remove abandonned capi support for the Mellanox CX4.
    
    This reverts commit a19bd79e31769626d288cc016e21a31b6f47bf6f.
    
    Signed-off-by: Frederic Barrat <fbarrat@linux.ibm.com>
    Acked-by: Andrew Donnellan <andrew.donnellan@au1.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index d95c2c98f2ab..aa453448201d 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -867,15 +867,9 @@ static inline bool cxl_is_power9_dd1(void)
 ssize_t cxl_pci_afu_read_err_buffer(struct cxl_afu *afu, char *buf,
 				loff_t off, size_t count);
 
-/* Internal functions wrapped in cxl_base to allow PHB to call them */
-bool _cxl_pci_associate_default_context(struct pci_dev *dev, struct cxl_afu *afu);
-void _cxl_pci_disable_device(struct pci_dev *dev);
 
 struct cxl_calls {
 	void (*cxl_slbia)(struct mm_struct *mm);
-	bool (*cxl_pci_associate_default_context)(struct pci_dev *dev, struct cxl_afu *afu);
-	void (*cxl_pci_disable_device)(struct pci_dev *dev);
-
 	struct module *owner;
 };
 int register_cxl_calls(struct cxl_calls *calls);

commit 17d29039388807305ab02a4d6eae7cbe09f81f90
Author: Alastair D'Silva <alastair@d-silva.org>
Date:   Thu Jun 28 12:05:02 2018 +0200

    Revert "cxl: Add preliminary workaround for CX4 interrupt limitation"
    
    Remove abandonned capi support for the Mellanox CX4.
    
    This reverts commit cbce0917e2e47d4bf5aa3b5fd6b1247f33e1a126.
    
    Signed-off-by: Alastair D'Silva <alastair@d-silva.org>
    Acked-by: Andrew Donnellan <andrew.donnellan@au1.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index 9688fe8b4d80..d95c2c98f2ab 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -623,14 +623,6 @@ struct cxl_context {
 
 	struct rcu_head rcu;
 
-	/*
-	 * Only used when more interrupts are allocated via
-	 * pci_enable_msix_range than are supported in the default context, to
-	 * use additional contexts to overcome the limitation. i.e. Mellanox
-	 * CX4 only:
-	 */
-	struct list_head extra_irq_contexts;
-
 	struct mm_struct *mm;
 
 	u16 tidr;
@@ -878,13 +870,11 @@ ssize_t cxl_pci_afu_read_err_buffer(struct cxl_afu *afu, char *buf,
 /* Internal functions wrapped in cxl_base to allow PHB to call them */
 bool _cxl_pci_associate_default_context(struct pci_dev *dev, struct cxl_afu *afu);
 void _cxl_pci_disable_device(struct pci_dev *dev);
-int _cxl_next_msi_hwirq(struct pci_dev *pdev, struct cxl_context **ctx, int *afu_irq);
 
 struct cxl_calls {
 	void (*cxl_slbia)(struct mm_struct *mm);
 	bool (*cxl_pci_associate_default_context)(struct pci_dev *dev, struct cxl_afu *afu);
 	void (*cxl_pci_disable_device)(struct pci_dev *dev);
-	int (*cxl_next_msi_hwirq)(struct pci_dev *pdev, struct cxl_context **ctx, int *afu_irq);
 
 	struct module *owner;
 };

commit 0cfd7335d1ebea42cf113fd22452f6a10d3960fe
Author: Alastair D'Silva <alastair@d-silva.org>
Date:   Thu Jun 28 12:05:01 2018 +0200

    Revert "cxl: Add support for interrupts on the Mellanox CX4"
    
    Remove abandonned capi support for the Mellanox CX4.
    
    This reverts commit a2f67d5ee8d950caaa7a6144cf0bfb256500b73e.
    
    Signed-off-by: Alastair D'Silva <alastair@d-silva.org>
    Acked-by: Andrew Donnellan <andrew.donnellan@au1.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index af8794719956..9688fe8b4d80 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -879,16 +879,12 @@ ssize_t cxl_pci_afu_read_err_buffer(struct cxl_afu *afu, char *buf,
 bool _cxl_pci_associate_default_context(struct pci_dev *dev, struct cxl_afu *afu);
 void _cxl_pci_disable_device(struct pci_dev *dev);
 int _cxl_next_msi_hwirq(struct pci_dev *pdev, struct cxl_context **ctx, int *afu_irq);
-int _cxl_cx4_setup_msi_irqs(struct pci_dev *pdev, int nvec, int type);
-void _cxl_cx4_teardown_msi_irqs(struct pci_dev *pdev);
 
 struct cxl_calls {
 	void (*cxl_slbia)(struct mm_struct *mm);
 	bool (*cxl_pci_associate_default_context)(struct pci_dev *dev, struct cxl_afu *afu);
 	void (*cxl_pci_disable_device)(struct pci_dev *dev);
 	int (*cxl_next_msi_hwirq)(struct pci_dev *pdev, struct cxl_context **ctx, int *afu_irq);
-	int (*cxl_cx4_setup_msi_irqs)(struct pci_dev *pdev, int nvec, int type);
-	void (*cxl_cx4_teardown_msi_irqs)(struct pci_dev *pdev);
 
 	struct module *owner;
 };

commit c5828150067c47a97f30e690a472e0548d3ac97d
Author: Alastair D'Silva <alastair@d-silva.org>
Date:   Thu Jun 28 12:05:00 2018 +0200

    Revert "cxl: Add kernel API to allow a context to operate with relocate disabled"
    
    Remove abandonned capi support for the Mellanox CX4.
    The symbol 'cxl_set_translation_mode' is never called, so
    ctx->real_mode is always false.
    
    This reverts commit 7a0d85d313c2066712e530e668bc02bb741a685c.
    
    Signed-off-by: Alastair D'Silva <alastair@d-silva.org>
    Acked-by: Andrew Donnellan <andrew.donnellan@au1.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index 918d4fb742d1..af8794719956 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -613,7 +613,6 @@ struct cxl_context {
 	bool pe_inserted;
 	bool master;
 	bool kernel;
-	bool real_mode;
 	bool pending_irq;
 	bool pending_fault;
 	bool pending_afu_err;

commit 497a0790e2c604366b9e35dcb41310319e9bca13
Author: Philippe Bergheaud <felix@linux.ibm.com>
Date:   Mon May 14 10:27:36 2018 +0200

    cxl: Report the tunneled operations status
    
    Failure to synchronize the tunneled operations does not prevent
    the initialization of the cxl card. This patch reports the tunneled
    operations status via /sys.
    
    Signed-off-by: Philippe Bergheaud <felix@linux.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index a4c9c8297a6d..918d4fb742d1 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -717,6 +717,7 @@ struct cxl {
 	bool perst_select_user;
 	bool perst_same_image;
 	bool psl_timebase_synced;
+	bool tunneled_ops_supported;
 
 	/*
 	 * number of contexts mapped on to this card. Possible values are:

commit 9dbcbfa1fe0c3b556e889ea213a73eb80d74307b
Author: Philippe Bergheaud <felix@linux.vnet.ibm.com>
Date:   Fri Mar 2 10:56:12 2018 +0100

    cxl: read PHB indications from the device tree
    
    Configure the P9 XSL_DSNCTL register with PHB indications found
    in the device tree, or else use legacy hard-coded values.
    
    Signed-off-by: Philippe Bergheaud <felix@linux.vnet.ibm.com>
    Reviewed-by: Frederic Barrat <fbarrat@linux.vnet.ibm.com>
    Reviewed-by: Christophe Lombard <clombard@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index 4949b8d5a748..a4c9c8297a6d 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -1069,7 +1069,7 @@ int cxl_psl_purge(struct cxl_afu *afu);
 int cxl_calc_capp_routing(struct pci_dev *dev, u64 *chipid,
 			  u32 *phb_index, u64 *capp_unit_id);
 int cxl_slot_is_switched(struct pci_dev *dev);
-int cxl_get_xsl9_dsnctl(u64 capp_unit_id, u64 *reg);
+int cxl_get_xsl9_dsnctl(struct pci_dev *dev, u64 capp_unit_id, u64 *reg);
 u64 cxl_calculate_sr(bool master, bool kernel, bool real_mode, bool p9);
 
 void cxl_native_irq_dump_regs_psl9(struct cxl_context *ctx);

commit 94322ed8e857e3b2a33cf75118051af9baaa110f
Author: Vaibhav Jain <vaibhav@linux.vnet.ibm.com>
Date:   Thu Feb 15 21:19:24 2018 +0530

    cxl: Check if PSL data-cache is available before issue flush request
    
    PSL9D doesn't have a data-cache that needs to be flushed before
    resetting the card. However when cxl tries to flush data-cache on such
    a card, it times-out as PSL_Control register never indicates flush
    operation complete due to missing data-cache. This is usually
    indicated in the kernel logs with this message:
    
    "WARNING: cache flush timed out"
    
    To fix this the patch checks PSL_Debug register CDC-Field(BIT:27)
    which indicates the absence of a data-cache and sets a flag
    'no_data_cache' in 'struct cxl_native' to indicate this. When
    cxl_data_cache_flush() is called it checks the flag and if set bails
    out early without requesting a data-cache flush operation to the PSL.
    
    Signed-off-by: Vaibhav Jain <vaibhav@linux.vnet.ibm.com>
    Acked-by: Andrew Donnellan <andrew.donnellan@au1.ibm.com>
    Acked-by: Frederic Barrat <fbarrat@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index 4f015da78f28..4949b8d5a748 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -369,6 +369,9 @@ static const cxl_p2n_reg_t CXL_PSL_WED_An     = {0x0A0};
 #define CXL_PSL_TFC_An_AE (1ull << (63-30)) /* Restart PSL with address error */
 #define CXL_PSL_TFC_An_R  (1ull << (63-31)) /* Restart PSL transaction */
 
+/****** CXL_PSL_DEBUG *****************************************************/
+#define CXL_PSL_DEBUG_CDC  (1ull << (63-27)) /* Coherent Data cache support */
+
 /****** CXL_XSL9_IERAT_ERAT - CAIA 2 **********************************/
 #define CXL_XSL9_IERAT_MLPID    (1ull << (63-0))  /* Match LPID */
 #define CXL_XSL9_IERAT_MPID     (1ull << (63-1))  /* Match PID */
@@ -669,6 +672,7 @@ struct cxl_native {
 	irq_hw_number_t err_hwirq;
 	unsigned int err_virq;
 	u64 ps_off;
+	bool no_data_cache; /* set if no data cache on the card */
 	const struct cxl_service_layer_ops *sl_ops;
 };
 

commit 03f51d4efa2287cc628bb20b0c032036d2a9e66a
Merge: 367b0df173b0 015eb1b89e95
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Feb 2 10:01:04 2018 -0800

    Merge tag 'powerpc-4.16-1' of git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux
    
    Pull powerpc updates from Michael Ellerman:
     "Highlights:
    
       - Enable support for memory protection keys aka "pkeys" on Power7/8/9
         when using the hash table MMU.
    
       - Extend our interrupt soft masking to support masking PMU interrupts
         as well as "normal" interrupts, and then use that to implement
         local_t for a ~4x speedup vs the current atomics-based
         implementation.
    
       - A new driver "ocxl" for "Open Coherent Accelerator Processor
         Interface (OpenCAPI)" devices.
    
       - Support for new device tree properties on PowerVM to describe
         hotpluggable memory and devices.
    
       - Add support for CLOCK_{REALTIME/MONOTONIC}_COARSE to the 64-bit
         VDSO.
    
       - Freescale updates from Scott: fixes for CPM GPIO and an FSL PCI
         erratum workaround, plus a minor cleanup patch.
    
      As well as quite a lot of other changes all over the place, and small
      fixes and cleanups as always.
    
      Thanks to: Alan Modra, Alastair D'Silva, Alexey Kardashevskiy,
      Alistair Popple, Andreas Schwab, Andrew Donnellan, Aneesh Kumar K.V,
      Anju T Sudhakar, Anshuman Khandual, Anton Blanchard, Arnd Bergmann,
      Balbir Singh, Benjamin Herrenschmidt, Bhaktipriya Shridhar, Bryant G.
      Ly, Cédric Le Goater, Christophe Leroy, Christophe Lombard, Cyril Bur,
      David Gibson, Desnes A. Nunes do Rosario, Dmitry Torokhov, Frederic
      Barrat, Geert Uytterhoeven, Guilherme G. Piccoli, Gustavo A. R. Silva,
      Gustavo Romero, Ivan Mikhaylov, Joakim Tjernlund, Joe Perches, Josh
      Poimboeuf, Juan J. Alvarez, Julia Cartwright, Kamalesh Babulal,
      Madhavan Srinivasan, Mahesh Salgaonkar, Mathieu Malaterre, Michael
      Bringmann, Michael Hanselmann, Michael Neuling, Nathan Fontenot,
      Naveen N. Rao, Nicholas Piggin, Paul Mackerras, Philippe Bergheaud,
      Ram Pai, Russell Currey, Santosh Sivaraj, Scott Wood, Seth Forshee,
      Simon Guo, Stewart Smith, Sukadev Bhattiprolu, Thiago Jung Bauermann,
      Vaibhav Jain, Vasyl Gomonovych"
    
    * tag 'powerpc-4.16-1' of git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux: (199 commits)
      powerpc/mm/radix: Fix build error when RADIX_MMU=n
      macintosh/ams-input: Use true and false for boolean values
      macintosh: change some data types from int to bool
      powerpc/watchdog: Print the NIP in soft_nmi_interrupt()
      powerpc/watchdog: regs can't be null in soft_nmi_interrupt()
      powerpc/watchdog: Tweak watchdog printks
      powerpc/cell: Remove axonram driver
      rtc-opal: Fix handling of firmware error codes, prevent busy loops
      powerpc/mpc52xx_gpt: make use of raw_spinlock variants
      macintosh/adb: Properly mark continued kernel messages
      powerpc/pseries: Fix cpu hotplug crash with memoryless nodes
      powerpc/numa: Ensure nodes initialized for hotplug
      powerpc/numa: Use ibm,max-associativity-domains to discover possible nodes
      powerpc/kernel: Block interrupts when updating TIDR
      powerpc/powernv/idoa: Remove unnecessary pcidev from pci_dn
      powerpc/mm/nohash: do not flush the entire mm when range is a single page
      powerpc/pseries: Add Initialization of VF Bars
      powerpc/pseries/pci: Associate PEs to VFs in configure SR-IOV
      powerpc/eeh: Add EEH notify resume sysfs
      powerpc/eeh: Add EEH operations to notify resume
      ...

commit b1db551324f72fa14ad82ca31237a7ed418104df
Author: Christophe Lombard <clombard@linux.vnet.ibm.com>
Date:   Thu Jan 11 09:55:25 2018 +0100

    cxl: Add support for ASB_Notify on POWER9
    
    The POWER9 core supports a new feature: ASB_Notify which requires the
    support of the Special Purpose Register: TIDR.
    
    The ASB_Notify command, generated by the AFU, will attempt to
    wake-up the host thread identified by the particular LPID:PID:TID.
    
    This patch assign a unique TIDR (thread id) for the current thread which
    will be used in the process element entry.
    
    Signed-off-by: Christophe Lombard <clombard@linux.vnet.ibm.com>
    Reviewed-by: Philippe Bergheaud <felix@linux.vnet.ibm.com>
    Acked-by: Frederic Barrat <fbarrat@linux.vnet.ibm.com>
    Reviewed-by: Vaibhav Jain <vaibhav@linux.vnet.ibm.com>
    Acked-by: Andrew Donnellan <andrew.donnellan@au1.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index e46a4062904a..53149fbd780e 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -630,6 +630,9 @@ struct cxl_context {
 	struct list_head extra_irq_contexts;
 
 	struct mm_struct *mm;
+
+	u16 tidr;
+	bool assign_tidr;
 };
 
 struct cxl_irq_info;

commit afc9a42b7464f76e1388cad87d8543c69f6f74ed
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Mon Jul 3 06:39:46 2017 -0400

    the rest of drivers/*: annotate ->poll() instances
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index e46a4062904a..a798c2ccd67d 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -1081,7 +1081,7 @@ int afu_open(struct inode *inode, struct file *file);
 int afu_release(struct inode *inode, struct file *file);
 long afu_ioctl(struct file *file, unsigned int cmd, unsigned long arg);
 int afu_mmap(struct file *file, struct vm_area_struct *vm);
-unsigned int afu_poll(struct file *file, struct poll_table_struct *poll);
+__poll_t afu_poll(struct file *file, struct poll_table_struct *poll);
 ssize_t afu_read(struct file *file, char __user *buf, size_t count, loff_t *off);
 extern const struct file_operations afu_fops;
 

commit cbb55eeb49b116bb3880137661ad8ce1ed45d672
Author: Vaibhav Jain <vaibhav@linux.vnet.ibm.com>
Date:   Wed Oct 11 18:00:20 2017 +0530

    cxl: Rework the implementation of cxl_stop_trace_psl9()
    
    Presently the PSL9 specific cxl_stop_trace_psl9() only stops the RX0
    traces on the CXL adapter when a PSL error irq is triggered. The patch
    updates the function to stop all the traces arrays and move them to
    the FIN state. The implementation issues the mmio to TRACECFG register
    to stop the trace array iff it already not in FIN state. This prevents
    the issue of trace data being reset in case of multiple stop mmio
    issued for a single trace array.
    
    Also the patch does some refactoring of existing cxl_stop_trace_psl9()
    and cxl_stop_trace_psl8() functions by moving them to 'pci.c' from
    'debugfs.c' file and marking them as static.
    
    Signed-off-by: Vaibhav Jain <vaibhav@linux.vnet.ibm.com>
    Acked-by: Frederic Barrat <fbarrat@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index fc98f6ad1616..e46a4062904a 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -115,6 +115,7 @@ static const cxl_p1_reg_t CXL_PSL9_TRACECFG = {0x0368};
 static const cxl_p1_reg_t CXL_PSL9_APCDEDALLOC = {0x0378};
 static const cxl_p1_reg_t CXL_PSL9_APCDEDTYPE = {0x0380};
 static const cxl_p1_reg_t CXL_PSL9_TNR_ADDR = {0x0388};
+static const cxl_p1_reg_t CXL_PSL9_CTCCFG = {0x0390};
 static const cxl_p1_reg_t CXL_PSL9_GP_CT = {0x0398};
 static const cxl_p1_reg_t CXL_XSL9_IERAT = {0x0588};
 static const cxl_p1_reg_t CXL_XSL9_ILPP  = {0x0590};
@@ -417,6 +418,9 @@ static const cxl_p2n_reg_t CXL_PSL_WED_An     = {0x0A0};
 #define CXL_CARD_MINOR(adapter) (adapter->adapter_num * CXL_DEV_MINORS)
 #define CXL_DEVT_ADAPTER(dev) (MINOR(dev) / CXL_DEV_MINORS)
 
+#define CXL_PSL9_TRACEID_MAX 0xAU
+#define CXL_PSL9_TRACESTATE_FIN 0x3U
+
 enum cxl_context_status {
 	CLOSED,
 	OPENED,
@@ -941,8 +945,6 @@ int cxl_debugfs_adapter_add(struct cxl *adapter);
 void cxl_debugfs_adapter_remove(struct cxl *adapter);
 int cxl_debugfs_afu_add(struct cxl_afu *afu);
 void cxl_debugfs_afu_remove(struct cxl_afu *afu);
-void cxl_stop_trace_psl9(struct cxl *cxl);
-void cxl_stop_trace_psl8(struct cxl *cxl);
 void cxl_debugfs_add_adapter_regs_psl9(struct cxl *adapter, struct dentry *dir);
 void cxl_debugfs_add_adapter_regs_psl8(struct cxl *adapter, struct dentry *dir);
 void cxl_debugfs_add_adapter_regs_xsl(struct cxl *adapter, struct dentry *dir);
@@ -978,14 +980,6 @@ static inline void cxl_debugfs_afu_remove(struct cxl_afu *afu)
 {
 }
 
-static inline void cxl_stop_trace_psl9(struct cxl *cxl)
-{
-}
-
-static inline void cxl_stop_trace_psl8(struct cxl *cxl)
-{
-}
-
 static inline void cxl_debugfs_add_adapter_regs_psl9(struct cxl *adapter,
 						    struct dentry *dir)
 {

commit 1cafc629408d1883a00c9f656e3de5a677460a88
Author: Vaibhav Jain <vaibhav@linux.vnet.ibm.com>
Date:   Wed Sep 20 11:53:22 2017 +0530

    cxl: Provide debugfs access to PSL_DEBUG/XSL_DEBUG registers
    
    Access to PSL/XSL_DEBUG registers on the adapter provides easy access
    to the debug facilities provided by PSL/XSL. So this patch adds two
    new files (debug, xsl-debug) to the cxl-adapter specific debugfs
    folder located at /sys/kernel/debugfs/cxl/card<n>, which will provide
    direct r/w access to corrosponding debug registers in the adapter
    config-space.
    
    Signed-off-by: Vaibhav Jain <vaibhav@linux.vnet.ibm.com>
    Acked-by: Andrew Donnellan <andrew.donnellan@au1.ibm.com>
    Acked-by: Frederic Barrat <fbarrat@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index 111c689b1771..fc98f6ad1616 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -101,6 +101,7 @@ static const cxl_p1_reg_t CXL_XSL_DSNCTL    = {0x0168};
 /* PSL registers - CAIA 2 */
 static const cxl_p1_reg_t CXL_PSL9_CONTROL  = {0x0020};
 static const cxl_p1_reg_t CXL_XSL9_INV      = {0x0110};
+static const cxl_p1_reg_t CXL_XSL9_DBG      = {0x0130};
 static const cxl_p1_reg_t CXL_XSL9_DEF      = {0x0140};
 static const cxl_p1_reg_t CXL_XSL9_DSNCTL   = {0x0168};
 static const cxl_p1_reg_t CXL_PSL9_FIR1     = {0x0300};

commit 990f19ae6feefb4a6e718355719cde5f6ba18ff6
Author: Vaibhav Jain <vaibhav@linux.vnet.ibm.com>
Date:   Wed Oct 11 11:44:41 2017 +0530

    cxl: Dump PSL_FIR register on PSL9 error irq
    
    For PSL9 currently we aren't dumping the PSL FIR register when a
    PSL error interrupt is triggered. Contents of this register are useful
    in debugging AFU issues.
    
    This patch fixes issue by adding a new service_layer_ops callback
    cxl_native_err_irq_dump_regs_psl9() to dump the PSL_FIR registers on a
    PSL error interrupt thereby bringing the behavior in line with PSL on
    POWER-8. Also the existing service_layer_ops callback
    for PSL8 has been renamed to cxl_native_err_irq_dump_regs_psl8().
    
    Signed-off-by: Vaibhav Jain <vaibhav@linux.vnet.ibm.com>
    Acked-by: Frederic Barrat <fbarrat@linux.vnet.ibm.com>
    Acked-by: Andrew Donnellan <andrew.donnellan@au1.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index 252373c2b861..111c689b1771 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -1072,7 +1072,8 @@ u64 cxl_calculate_sr(bool master, bool kernel, bool real_mode, bool p9);
 
 void cxl_native_irq_dump_regs_psl9(struct cxl_context *ctx);
 void cxl_native_irq_dump_regs_psl8(struct cxl_context *ctx);
-void cxl_native_err_irq_dump_regs(struct cxl *adapter);
+void cxl_native_err_irq_dump_regs_psl8(struct cxl *adapter);
+void cxl_native_err_irq_dump_regs_psl9(struct cxl *adapter);
 int cxl_pci_vphb_add(struct cxl_afu *afu);
 void cxl_pci_vphb_remove(struct cxl_afu *afu);
 void cxl_release_mapping(struct cxl_context *ctx);

commit 8f6a90421c7637984fb352da079fb13172176bfd
Author: Vaibhav Jain <vaibhav@linux.vnet.ibm.com>
Date:   Mon Oct 9 23:26:27 2017 +0530

    cxl: Rename register PSL9_FIR2 to PSL9_FIR_MASK
    
    PSL9 doesn't have a FIR2 register as was the case with PSL8. However
    currently the register definitions in 'cxl.h' have a definition for
    PSL9_FIR2 that actually points to PSL9_FIR_MASK register in the P1
    area at offset 0x308.
    
    So this patch renames the def PSL9_FIR2 to PSL9_FIR_MASK and updates
    the references in the code to point to the new identifier. It also
    removes the code to dump contents of FIR2 (FIR_MASK actually) in
    cxl_native_irq_dump_regs_psl9().
    
    Fixes: f24be42aab37 ("cxl: Add psl9 specific code")
    Reported-by: Frederic Barrat <fbarrat@linux.vnet.ibm.com>
    Signed-off-by: Vaibhav Jain <vaibhav@linux.vnet.ibm.com>
    Acked-by: Frederic Barrat <fbarrat@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index 0167df81df62..252373c2b861 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -104,7 +104,7 @@ static const cxl_p1_reg_t CXL_XSL9_INV      = {0x0110};
 static const cxl_p1_reg_t CXL_XSL9_DEF      = {0x0140};
 static const cxl_p1_reg_t CXL_XSL9_DSNCTL   = {0x0168};
 static const cxl_p1_reg_t CXL_PSL9_FIR1     = {0x0300};
-static const cxl_p1_reg_t CXL_PSL9_FIR2     = {0x0308};
+static const cxl_p1_reg_t CXL_PSL9_FIR_MASK = {0x0308};
 static const cxl_p1_reg_t CXL_PSL9_Timebase = {0x0310};
 static const cxl_p1_reg_t CXL_PSL9_DEBUG    = {0x0320};
 static const cxl_p1_reg_t CXL_PSL9_FIR_CNTL = {0x0348};

commit 5632874311dbf432c698fcbe0cf7a49e01ebf324
Author: Christophe Lombard <clombard@linux.vnet.ibm.com>
Date:   Fri Sep 8 15:52:11 2017 +0200

    cxl: Add support for POWER9 DD2
    
    The PSL initialization sequence has been updated to DD2.
    This patch adapts to the changes, retaining compatibility with DD1.
    The patch includes some changes to DD1 fix-ups as well.
    
    Tests performed on some of the old/new hardware.
    
    The function is_page_fault(), for POWER9, lists the Translation Checkout
    Responses where the page fault will be handled by copro_handle_mm_fault().
    This list is too restrictive and not necessary.
    
    This patches removes this restriction and all page faults, whatever the
    reason, will be handled. In this case, the interruption is always
    acknowledged.
    
    The following features will be added soon:
    - phb reset when switching to capi mode.
    - cxllib update to support new functions.
    
    Signed-off-by: Christophe Lombard <clombard@linux.vnet.ibm.com>
    
    Acked-by: Frederic Barrat <fbarrat@linux.vnet.ibm.com>
    Reviewed-by: Vaibhav Jain <vaibhav@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index b1afeccbb97f..0167df81df62 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -100,6 +100,8 @@ static const cxl_p1_reg_t CXL_XSL_FEC       = {0x0158};
 static const cxl_p1_reg_t CXL_XSL_DSNCTL    = {0x0168};
 /* PSL registers - CAIA 2 */
 static const cxl_p1_reg_t CXL_PSL9_CONTROL  = {0x0020};
+static const cxl_p1_reg_t CXL_XSL9_INV      = {0x0110};
+static const cxl_p1_reg_t CXL_XSL9_DEF      = {0x0140};
 static const cxl_p1_reg_t CXL_XSL9_DSNCTL   = {0x0168};
 static const cxl_p1_reg_t CXL_PSL9_FIR1     = {0x0300};
 static const cxl_p1_reg_t CXL_PSL9_FIR2     = {0x0308};

commit 3ced8d73006321bd2a0412fa0ff4b065a02e7514
Author: Christophe Lombard <clombard@linux.vnet.ibm.com>
Date:   Thu Jun 22 15:07:27 2017 +0200

    cxl: Export library to support IBM XSL
    
    This patch exports a in-kernel 'library' API which can be called by
    other drivers to help interacting with an IBM XSL on a POWER9 system.
    
    The XSL (Translation Service Layer) is a stripped down version of the
    PSL (Power Service Layer) used in some cards such as the Mellanox CX5.
    Like the PSL, it implements the CAIA architecture, but has a number
    of differences, mostly in it's implementation dependent registers.
    
    The XSL also uses a special DMA cxl mode, which uses a slightly
    different init sequence for the CAPP and PHB.
    
    Signed-off-by: Andrew Donnellan <andrew.donnellan@au1.ibm.com>
    Signed-off-by: Christophe Lombard <clombard@linux.vnet.ibm.com>
    Acked-by: Frederic Barrat <fbarrat@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index a03f8e7535e5..b1afeccbb97f 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -1010,6 +1010,7 @@ static inline void cxl_debugfs_add_afu_regs_psl8(struct cxl_afu *afu, struct den
 
 void cxl_handle_fault(struct work_struct *work);
 void cxl_prefault(struct cxl_context *ctx, u64 wed);
+int cxl_handle_mm_fault(struct mm_struct *mm, u64 dsisr, u64 dar);
 
 struct cxl *get_cxl_adapter(int num);
 int cxl_alloc_sst(struct cxl_context *ctx);
@@ -1061,6 +1062,11 @@ int cxl_afu_slbia(struct cxl_afu *afu);
 int cxl_data_cache_flush(struct cxl *adapter);
 int cxl_afu_disable(struct cxl_afu *afu);
 int cxl_psl_purge(struct cxl_afu *afu);
+int cxl_calc_capp_routing(struct pci_dev *dev, u64 *chipid,
+			  u32 *phb_index, u64 *capp_unit_id);
+int cxl_slot_is_switched(struct pci_dev *dev);
+int cxl_get_xsl9_dsnctl(u64 capp_unit_id, u64 *reg);
+u64 cxl_calculate_sr(bool master, bool kernel, bool real_mode, bool p9);
 
 void cxl_native_irq_dump_regs_psl9(struct cxl_context *ctx);
 void cxl_native_irq_dump_regs_psl8(struct cxl_context *ctx);

commit 797625deaedd9a0621376817db2813244b3246e3
Author: Christophe Lombard <clombard@linux.vnet.ibm.com>
Date:   Tue Jun 13 17:41:05 2017 +0200

    cxl: Fixes for Coherent Accelerator Interface Architecture 2.0
    
    A previous set of patches "cxl: Add support for Coherent Accelerator
    Interface Architecture 2.0" has introduced a new support for the CAPI
    cards. These patches have been tested on Simulation environment and
    quite a bit of them have been tested on real hardware.
    
    This patch brings new fixes after a series of tests carried out on new
    equipment:
      - Add POWER9 definition.
      - Re-enable any masked interrupts when the AFU is not activated
        after resetting the AFU.
      - Remove the api cxl_is_psl8/9 which is no longer useful.
      - Do not dump CAPI1 registers.
      - Rewrite cxl_is_page_fault() function.
      - Do not register slb callack on P9.
    
    Fixes: f24be42aab37 ("cxl: Add psl9 specific code")
    Signed-off-by: Christophe Lombard <clombard@linux.vnet.ibm.com>
    Acked-by: Frederic Barrat <fbarrat@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index c8568ea7c518..a03f8e7535e5 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -357,6 +357,7 @@ static const cxl_p2n_reg_t CXL_PSL_WED_An     = {0x0A0};
 #define CXL_PSL9_DSISR_An_PF_RGP  0x0000000000000090ULL  /* PTE not found (Radix Guest (parent)) 0b10010000 */
 #define CXL_PSL9_DSISR_An_PF_HRH  0x0000000000000094ULL  /* PTE not found (HPT/Radix Host)       0b10010100 */
 #define CXL_PSL9_DSISR_An_PF_STEG 0x000000000000009CULL  /* PTE not found (STEG VA)              0b10011100 */
+#define CXL_PSL9_DSISR_An_URTCH   0x00000000000000B4ULL  /* Unsupported Radix Tree Configuration 0b10110100 */
 
 /****** CXL_PSL_TFC_An ******************************************************/
 #define CXL_PSL_TFC_An_A  (1ull << (63-28)) /* Acknowledge non-translation fault */
@@ -844,24 +845,15 @@ static inline bool cxl_is_power8(void)
 
 static inline bool cxl_is_power9(void)
 {
-	/* intermediate solution */
-	if (!cxl_is_power8() &&
-	   (cpu_has_feature(CPU_FTRS_POWER9) ||
-	    cpu_has_feature(CPU_FTR_POWER9_DD1)))
+	if (pvr_version_is(PVR_POWER9))
 		return true;
 	return false;
 }
 
-static inline bool cxl_is_psl8(struct cxl_afu *afu)
+static inline bool cxl_is_power9_dd1(void)
 {
-	if (afu->adapter->caia_major == 1)
-		return true;
-	return false;
-}
-
-static inline bool cxl_is_psl9(struct cxl_afu *afu)
-{
-	if (afu->adapter->caia_major == 2)
+	if ((pvr_version_is(PVR_POWER9)) &&
+	    cpu_has_feature(CPU_FTR_POWER9_DD1))
 		return true;
 	return false;
 }

commit a715626a8e904e7226915d1bc4885317ea9da141
Author: Alastair D'Silva <alastair@d-silva.org>
Date:   Mon May 1 10:53:31 2017 +1000

    cxl: Mask slice error interrupts after first occurrence
    
    In some situations, a faulty AFU slice may create an interrupt storm of
    slice errors, rendering the machine unusable. Since these interrupts are
    informational only, present the interrupt once, then mask it off to
    prevent it from being retriggered until the AFU is reset.
    
    Signed-off-by: Alastair D'Silva <alastair@d-silva.org>
    Reviewed-by: Andrew Donnellan <andrew.donnellan@au1.ibm.com>
    Reviewed-by: Vaibhav Jain <vaibhav@linux.vnet.ibm.com>
    Acked-by: Frederic Barrat <fbarrat@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index 452e209c5e67..c8568ea7c518 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -228,6 +228,24 @@ static const cxl_p2n_reg_t CXL_PSL_WED_An     = {0x0A0};
 #define CXL_PSL_SERR_An_llcmdto	(1ull << (63-6))
 #define CXL_PSL_SERR_An_afupar	(1ull << (63-7))
 #define CXL_PSL_SERR_An_afudup	(1ull << (63-8))
+#define CXL_PSL_SERR_An_IRQS	( \
+	CXL_PSL_SERR_An_afuto | CXL_PSL_SERR_An_afudis | CXL_PSL_SERR_An_afuov | \
+	CXL_PSL_SERR_An_badsrc | CXL_PSL_SERR_An_badctx | CXL_PSL_SERR_An_llcmdis | \
+	CXL_PSL_SERR_An_llcmdto | CXL_PSL_SERR_An_afupar | CXL_PSL_SERR_An_afudup)
+#define CXL_PSL_SERR_An_afuto_mask	(1ull << (63-32))
+#define CXL_PSL_SERR_An_afudis_mask	(1ull << (63-33))
+#define CXL_PSL_SERR_An_afuov_mask	(1ull << (63-34))
+#define CXL_PSL_SERR_An_badsrc_mask	(1ull << (63-35))
+#define CXL_PSL_SERR_An_badctx_mask	(1ull << (63-36))
+#define CXL_PSL_SERR_An_llcmdis_mask	(1ull << (63-37))
+#define CXL_PSL_SERR_An_llcmdto_mask	(1ull << (63-38))
+#define CXL_PSL_SERR_An_afupar_mask	(1ull << (63-39))
+#define CXL_PSL_SERR_An_afudup_mask	(1ull << (63-40))
+#define CXL_PSL_SERR_An_IRQ_MASKS	( \
+	CXL_PSL_SERR_An_afuto_mask | CXL_PSL_SERR_An_afudis_mask | CXL_PSL_SERR_An_afuov_mask | \
+	CXL_PSL_SERR_An_badsrc_mask | CXL_PSL_SERR_An_badctx_mask | CXL_PSL_SERR_An_llcmdis_mask | \
+	CXL_PSL_SERR_An_llcmdto_mask | CXL_PSL_SERR_An_afupar_mask | CXL_PSL_SERR_An_afudup_mask)
+
 #define CXL_PSL_SERR_An_AE	(1ull << (63-30))
 
 /****** CXL_PSL_SCNTL_An ****************************************************/

commit f24be42aab37c6d07c05126673138e06223a6399
Author: Christophe Lombard <clombard@linux.vnet.ibm.com>
Date:   Wed Apr 12 16:34:07 2017 +0200

    cxl: Add psl9 specific code
    
    The new Coherent Accelerator Interface Architecture, level 2, for the
    IBM POWER9 brings new content and features:
    - POWER9 Service Layer
    - Registers
    - Radix mode
    - Process element entry
    - Dedicated-Shared Process Programming Model
    - Translation Fault Handling
    - CAPP
    - Memory Context ID
        If a valid mm_struct is found the memory context id is used for each
        transaction associated with the process handle. The PSL uses the
        context ID to find the corresponding process element.
    
    Signed-off-by: Christophe Lombard <clombard@linux.vnet.ibm.com>
    Acked-by: Frederic Barrat <fbarrat@linux.vnet.ibm.com>
    [mpe: Fixup comment formatting, unsplit long strings]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index 82335c0f7ac9..452e209c5e67 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -63,7 +63,7 @@ typedef struct {
 /* Memory maps. Ref CXL Appendix A */
 
 /* PSL Privilege 1 Memory Map */
-/* Configuration and Control area */
+/* Configuration and Control area - CAIA 1&2 */
 static const cxl_p1_reg_t CXL_PSL_CtxTime = {0x0000};
 static const cxl_p1_reg_t CXL_PSL_ErrIVTE = {0x0008};
 static const cxl_p1_reg_t CXL_PSL_KEY1    = {0x0010};
@@ -98,11 +98,29 @@ static const cxl_p1_reg_t CXL_XSL_Timebase  = {0x0100};
 static const cxl_p1_reg_t CXL_XSL_TB_CTLSTAT = {0x0108};
 static const cxl_p1_reg_t CXL_XSL_FEC       = {0x0158};
 static const cxl_p1_reg_t CXL_XSL_DSNCTL    = {0x0168};
+/* PSL registers - CAIA 2 */
+static const cxl_p1_reg_t CXL_PSL9_CONTROL  = {0x0020};
+static const cxl_p1_reg_t CXL_XSL9_DSNCTL   = {0x0168};
+static const cxl_p1_reg_t CXL_PSL9_FIR1     = {0x0300};
+static const cxl_p1_reg_t CXL_PSL9_FIR2     = {0x0308};
+static const cxl_p1_reg_t CXL_PSL9_Timebase = {0x0310};
+static const cxl_p1_reg_t CXL_PSL9_DEBUG    = {0x0320};
+static const cxl_p1_reg_t CXL_PSL9_FIR_CNTL = {0x0348};
+static const cxl_p1_reg_t CXL_PSL9_DSNDCTL  = {0x0350};
+static const cxl_p1_reg_t CXL_PSL9_TB_CTLSTAT = {0x0340};
+static const cxl_p1_reg_t CXL_PSL9_TRACECFG = {0x0368};
+static const cxl_p1_reg_t CXL_PSL9_APCDEDALLOC = {0x0378};
+static const cxl_p1_reg_t CXL_PSL9_APCDEDTYPE = {0x0380};
+static const cxl_p1_reg_t CXL_PSL9_TNR_ADDR = {0x0388};
+static const cxl_p1_reg_t CXL_PSL9_GP_CT = {0x0398};
+static const cxl_p1_reg_t CXL_XSL9_IERAT = {0x0588};
+static const cxl_p1_reg_t CXL_XSL9_ILPP  = {0x0590};
+
 /* 0x7F00:7FFF Reserved PCIe MSI-X Pending Bit Array area */
 /* 0x8000:FFFF Reserved PCIe MSI-X Table Area */
 
 /* PSL Slice Privilege 1 Memory Map */
-/* Configuration Area */
+/* Configuration Area - CAIA 1&2 */
 static const cxl_p1n_reg_t CXL_PSL_SR_An          = {0x00};
 static const cxl_p1n_reg_t CXL_PSL_LPID_An        = {0x08};
 static const cxl_p1n_reg_t CXL_PSL_AMBAR_An       = {0x10};
@@ -111,17 +129,18 @@ static const cxl_p1n_reg_t CXL_PSL_ID_An          = {0x20};
 static const cxl_p1n_reg_t CXL_PSL_SERR_An        = {0x28};
 /* Memory Management and Lookaside Buffer Management - CAIA 1*/
 static const cxl_p1n_reg_t CXL_PSL_SDR_An         = {0x30};
+/* Memory Management and Lookaside Buffer Management - CAIA 1&2 */
 static const cxl_p1n_reg_t CXL_PSL_AMOR_An        = {0x38};
-/* Pointer Area */
+/* Pointer Area - CAIA 1&2 */
 static const cxl_p1n_reg_t CXL_HAURP_An           = {0x80};
 static const cxl_p1n_reg_t CXL_PSL_SPAP_An        = {0x88};
 static const cxl_p1n_reg_t CXL_PSL_LLCMD_An       = {0x90};
-/* Control Area */
+/* Control Area - CAIA 1&2 */
 static const cxl_p1n_reg_t CXL_PSL_SCNTL_An       = {0xA0};
 static const cxl_p1n_reg_t CXL_PSL_CtxTime_An     = {0xA8};
 static const cxl_p1n_reg_t CXL_PSL_IVTE_Offset_An = {0xB0};
 static const cxl_p1n_reg_t CXL_PSL_IVTE_Limit_An  = {0xB8};
-/* 0xC0:FF Implementation Dependent Area */
+/* 0xC0:FF Implementation Dependent Area - CAIA 1&2 */
 static const cxl_p1n_reg_t CXL_PSL_FIR_SLICE_An   = {0xC0};
 static const cxl_p1n_reg_t CXL_AFU_DEBUG_An       = {0xC8};
 /* 0xC0:FF Implementation Dependent Area - CAIA 1 */
@@ -131,7 +150,7 @@ static const cxl_p1n_reg_t CXL_PSL_RXCTL_A        = {0xE0};
 static const cxl_p1n_reg_t CXL_PSL_SLICE_TRACE    = {0xE8};
 
 /* PSL Slice Privilege 2 Memory Map */
-/* Configuration and Control Area */
+/* Configuration and Control Area - CAIA 1&2 */
 static const cxl_p2n_reg_t CXL_PSL_PID_TID_An = {0x000};
 static const cxl_p2n_reg_t CXL_CSRP_An        = {0x008};
 /* Configuration and Control Area - CAIA 1 */
@@ -145,17 +164,17 @@ static const cxl_p2n_reg_t CXL_PSL_AMR_An     = {0x030};
 static const cxl_p2n_reg_t CXL_SLBIE_An       = {0x040};
 static const cxl_p2n_reg_t CXL_SLBIA_An       = {0x048};
 static const cxl_p2n_reg_t CXL_SLBI_Select_An = {0x050};
-/* Interrupt Registers */
+/* Interrupt Registers - CAIA 1&2 */
 static const cxl_p2n_reg_t CXL_PSL_DSISR_An   = {0x060};
 static const cxl_p2n_reg_t CXL_PSL_DAR_An     = {0x068};
 static const cxl_p2n_reg_t CXL_PSL_DSR_An     = {0x070};
 static const cxl_p2n_reg_t CXL_PSL_TFC_An     = {0x078};
 static const cxl_p2n_reg_t CXL_PSL_PEHandle_An = {0x080};
 static const cxl_p2n_reg_t CXL_PSL_ErrStat_An = {0x088};
-/* AFU Registers */
+/* AFU Registers - CAIA 1&2 */
 static const cxl_p2n_reg_t CXL_AFU_Cntl_An    = {0x090};
 static const cxl_p2n_reg_t CXL_AFU_ERR_An     = {0x098};
-/* Work Element Descriptor */
+/* Work Element Descriptor - CAIA 1&2 */
 static const cxl_p2n_reg_t CXL_PSL_WED_An     = {0x0A0};
 /* 0x0C0:FFF Implementation Dependent Area */
 
@@ -182,6 +201,10 @@ static const cxl_p2n_reg_t CXL_PSL_WED_An     = {0x0A0};
 #define CXL_PSL_SR_An_SF  MSR_SF            /* 64bit */
 #define CXL_PSL_SR_An_TA  (1ull << (63-1))  /* Tags active,   GA1: 0 */
 #define CXL_PSL_SR_An_HV  MSR_HV            /* Hypervisor,    GA1: 0 */
+#define CXL_PSL_SR_An_XLAT_hpt (0ull << (63-6))/* Hashed page table (HPT) mode */
+#define CXL_PSL_SR_An_XLAT_roh (2ull << (63-6))/* Radix on HPT mode */
+#define CXL_PSL_SR_An_XLAT_ror (3ull << (63-6))/* Radix on Radix mode */
+#define CXL_PSL_SR_An_BOT (1ull << (63-10)) /* Use the in-memory segment table */
 #define CXL_PSL_SR_An_PR  MSR_PR            /* Problem state, GA1: 1 */
 #define CXL_PSL_SR_An_ISL (1ull << (63-53)) /* Ignore Segment Large Page */
 #define CXL_PSL_SR_An_TC  (1ull << (63-54)) /* Page Table secondary hash */
@@ -298,12 +321,39 @@ static const cxl_p2n_reg_t CXL_PSL_WED_An     = {0x0A0};
 #define CXL_PSL_DSISR_An_S  DSISR_ISSTORE     /* Access was afu_wr or afu_zero */
 #define CXL_PSL_DSISR_An_K  DSISR_KEYFAULT    /* Access not permitted by virtual page class key protection */
 
+/****** CXL_PSL_DSISR_An - CAIA 2 ****************************************************/
+#define CXL_PSL9_DSISR_An_TF (1ull << (63-3))  /* Translation fault */
+#define CXL_PSL9_DSISR_An_PE (1ull << (63-4))  /* PSL Error (implementation specific) */
+#define CXL_PSL9_DSISR_An_AE (1ull << (63-5))  /* AFU Error */
+#define CXL_PSL9_DSISR_An_OC (1ull << (63-6))  /* OS Context Warning */
+#define CXL_PSL9_DSISR_An_S (1ull << (63-38))  /* TF for a write operation */
+#define CXL_PSL9_DSISR_PENDING (CXL_PSL9_DSISR_An_TF | CXL_PSL9_DSISR_An_PE | CXL_PSL9_DSISR_An_AE | CXL_PSL9_DSISR_An_OC)
+/*
+ * NOTE: Bits 56:63 (Checkout Response Status) are valid when DSISR_An[TF] = 1
+ * Status (0:7) Encoding
+ */
+#define CXL_PSL9_DSISR_An_CO_MASK 0x00000000000000ffULL
+#define CXL_PSL9_DSISR_An_SF      0x0000000000000080ULL  /* Segment Fault                        0b10000000 */
+#define CXL_PSL9_DSISR_An_PF_SLR  0x0000000000000088ULL  /* PTE not found (Single Level Radix)   0b10001000 */
+#define CXL_PSL9_DSISR_An_PF_RGC  0x000000000000008CULL  /* PTE not found (Radix Guest (child))  0b10001100 */
+#define CXL_PSL9_DSISR_An_PF_RGP  0x0000000000000090ULL  /* PTE not found (Radix Guest (parent)) 0b10010000 */
+#define CXL_PSL9_DSISR_An_PF_HRH  0x0000000000000094ULL  /* PTE not found (HPT/Radix Host)       0b10010100 */
+#define CXL_PSL9_DSISR_An_PF_STEG 0x000000000000009CULL  /* PTE not found (STEG VA)              0b10011100 */
+
 /****** CXL_PSL_TFC_An ******************************************************/
 #define CXL_PSL_TFC_An_A  (1ull << (63-28)) /* Acknowledge non-translation fault */
 #define CXL_PSL_TFC_An_C  (1ull << (63-29)) /* Continue (abort transaction) */
 #define CXL_PSL_TFC_An_AE (1ull << (63-30)) /* Restart PSL with address error */
 #define CXL_PSL_TFC_An_R  (1ull << (63-31)) /* Restart PSL transaction */
 
+/****** CXL_XSL9_IERAT_ERAT - CAIA 2 **********************************/
+#define CXL_XSL9_IERAT_MLPID    (1ull << (63-0))  /* Match LPID */
+#define CXL_XSL9_IERAT_MPID     (1ull << (63-1))  /* Match PID */
+#define CXL_XSL9_IERAT_PRS      (1ull << (63-4))  /* PRS bit for Radix invalidations */
+#define CXL_XSL9_IERAT_INVR     (1ull << (63-3))  /* Invalidate Radix */
+#define CXL_XSL9_IERAT_IALL     (1ull << (63-8))  /* Invalidate All */
+#define CXL_XSL9_IERAT_IINPROG  (1ull << (63-63)) /* Invalidate in progress */
+
 /* cxl_process_element->software_status */
 #define CXL_PE_SOFTWARE_STATE_V (1ul << (31 -  0)) /* Valid */
 #define CXL_PE_SOFTWARE_STATE_C (1ul << (31 - 29)) /* Complete */
@@ -654,25 +704,38 @@ int cxl_pci_reset(struct cxl *adapter);
 void cxl_pci_release_afu(struct device *dev);
 ssize_t cxl_pci_read_adapter_vpd(struct cxl *adapter, void *buf, size_t len);
 
-/* common == phyp + powernv */
+/* common == phyp + powernv - CAIA 1&2 */
 struct cxl_process_element_common {
 	__be32 tid;
 	__be32 pid;
 	__be64 csrp;
-	__be64 aurp0;
-	__be64 aurp1;
-	__be64 sstp0;
-	__be64 sstp1;
+	union {
+		struct {
+			__be64 aurp0;
+			__be64 aurp1;
+			__be64 sstp0;
+			__be64 sstp1;
+		} psl8;  /* CAIA 1 */
+		struct {
+			u8     reserved2[8];
+			u8     reserved3[8];
+			u8     reserved4[8];
+			u8     reserved5[8];
+		} psl9;  /* CAIA 2 */
+	} u;
 	__be64 amr;
-	u8     reserved3[4];
+	u8     reserved6[4];
 	__be64 wed;
 } __packed;
 
-/* just powernv */
+/* just powernv - CAIA 1&2 */
 struct cxl_process_element {
 	__be64 sr;
 	__be64 SPOffset;
-	__be64 sdr;
+	union {
+		__be64 sdr;          /* CAIA 1 */
+		u8     reserved1[8]; /* CAIA 2 */
+	} u;
 	__be64 haurp;
 	__be32 ctxtime;
 	__be16 ivte_offsets[4];
@@ -761,6 +824,16 @@ static inline bool cxl_is_power8(void)
 	return false;
 }
 
+static inline bool cxl_is_power9(void)
+{
+	/* intermediate solution */
+	if (!cxl_is_power8() &&
+	   (cpu_has_feature(CPU_FTRS_POWER9) ||
+	    cpu_has_feature(CPU_FTR_POWER9_DD1)))
+		return true;
+	return false;
+}
+
 static inline bool cxl_is_psl8(struct cxl_afu *afu)
 {
 	if (afu->adapter->caia_major == 1)
@@ -768,6 +841,13 @@ static inline bool cxl_is_psl8(struct cxl_afu *afu)
 	return false;
 }
 
+static inline bool cxl_is_psl9(struct cxl_afu *afu)
+{
+	if (afu->adapter->caia_major == 2)
+		return true;
+	return false;
+}
+
 ssize_t cxl_pci_afu_read_err_buffer(struct cxl_afu *afu, char *buf,
 				loff_t off, size_t count);
 
@@ -794,7 +874,6 @@ int cxl_update_properties(struct device_node *dn, struct property *new_prop);
 
 void cxl_remove_adapter_nr(struct cxl *adapter);
 
-int cxl_alloc_spa(struct cxl_afu *afu);
 void cxl_release_spa(struct cxl_afu *afu);
 
 dev_t cxl_get_dev(void);
@@ -832,9 +911,13 @@ int afu_register_irqs(struct cxl_context *ctx, u32 count);
 void afu_release_irqs(struct cxl_context *ctx, void *cookie);
 void afu_irq_name_free(struct cxl_context *ctx);
 
+int cxl_attach_afu_directed_psl9(struct cxl_context *ctx, u64 wed, u64 amr);
 int cxl_attach_afu_directed_psl8(struct cxl_context *ctx, u64 wed, u64 amr);
+int cxl_activate_dedicated_process_psl9(struct cxl_afu *afu);
 int cxl_activate_dedicated_process_psl8(struct cxl_afu *afu);
+int cxl_attach_dedicated_process_psl9(struct cxl_context *ctx, u64 wed, u64 amr);
 int cxl_attach_dedicated_process_psl8(struct cxl_context *ctx, u64 wed, u64 amr);
+void cxl_update_dedicated_ivtes_psl9(struct cxl_context *ctx);
 void cxl_update_dedicated_ivtes_psl8(struct cxl_context *ctx);
 
 #ifdef CONFIG_DEBUG_FS
@@ -845,9 +928,12 @@ int cxl_debugfs_adapter_add(struct cxl *adapter);
 void cxl_debugfs_adapter_remove(struct cxl *adapter);
 int cxl_debugfs_afu_add(struct cxl_afu *afu);
 void cxl_debugfs_afu_remove(struct cxl_afu *afu);
+void cxl_stop_trace_psl9(struct cxl *cxl);
 void cxl_stop_trace_psl8(struct cxl *cxl);
+void cxl_debugfs_add_adapter_regs_psl9(struct cxl *adapter, struct dentry *dir);
 void cxl_debugfs_add_adapter_regs_psl8(struct cxl *adapter, struct dentry *dir);
 void cxl_debugfs_add_adapter_regs_xsl(struct cxl *adapter, struct dentry *dir);
+void cxl_debugfs_add_afu_regs_psl9(struct cxl_afu *afu, struct dentry *dir);
 void cxl_debugfs_add_afu_regs_psl8(struct cxl_afu *afu, struct dentry *dir);
 
 #else /* CONFIG_DEBUG_FS */
@@ -879,10 +965,19 @@ static inline void cxl_debugfs_afu_remove(struct cxl_afu *afu)
 {
 }
 
+static inline void cxl_stop_trace_psl9(struct cxl *cxl)
+{
+}
+
 static inline void cxl_stop_trace_psl8(struct cxl *cxl)
 {
 }
 
+static inline void cxl_debugfs_add_adapter_regs_psl9(struct cxl *adapter,
+						    struct dentry *dir)
+{
+}
+
 static inline void cxl_debugfs_add_adapter_regs_psl8(struct cxl *adapter,
 						    struct dentry *dir)
 {
@@ -893,6 +988,10 @@ static inline void cxl_debugfs_add_adapter_regs_xsl(struct cxl *adapter,
 {
 }
 
+static inline void cxl_debugfs_add_afu_regs_psl9(struct cxl_afu *afu, struct dentry *dir)
+{
+}
+
 static inline void cxl_debugfs_add_afu_regs_psl8(struct cxl_afu *afu, struct dentry *dir)
 {
 }
@@ -938,7 +1037,9 @@ struct cxl_irq_info {
 };
 
 void cxl_assign_psn_space(struct cxl_context *ctx);
+int cxl_invalidate_all_psl9(struct cxl *adapter);
 int cxl_invalidate_all_psl8(struct cxl *adapter);
+irqreturn_t cxl_irq_psl9(int irq, struct cxl_context *ctx, struct cxl_irq_info *irq_info);
 irqreturn_t cxl_irq_psl8(int irq, struct cxl_context *ctx, struct cxl_irq_info *irq_info);
 irqreturn_t cxl_fail_irq_psl(struct cxl_afu *afu, struct cxl_irq_info *irq_info);
 int cxl_register_one_irq(struct cxl *adapter, irq_handler_t handler,
@@ -951,6 +1052,7 @@ int cxl_data_cache_flush(struct cxl *adapter);
 int cxl_afu_disable(struct cxl_afu *afu);
 int cxl_psl_purge(struct cxl_afu *afu);
 
+void cxl_native_irq_dump_regs_psl9(struct cxl_context *ctx);
 void cxl_native_irq_dump_regs_psl8(struct cxl_context *ctx);
 void cxl_native_err_irq_dump_regs(struct cxl *adapter);
 int cxl_pci_vphb_add(struct cxl_afu *afu);

commit abd1d99bb3da42d6c7341c14986f5b8f4dcc6bd5
Author: Christophe Lombard <clombard@linux.vnet.ibm.com>
Date:   Fri Apr 7 16:11:58 2017 +0200

    cxl: Isolate few psl8 specific calls
    
    Point out the specific Coherent Accelerator Interface Architecture,
    level 1, registers.
    Code and functions specific to PSL8 (CAIA1) must be framed.
    
    Signed-off-by: Christophe Lombard <clombard@linux.vnet.ibm.com>
    Acked-by: Frederic Barrat <fbarrat@linux.vnet.ibm.com>
    [mpe: Don't split long strings, it makes them hard to grep for]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index a54c0030932c..82335c0f7ac9 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -73,7 +73,7 @@ static const cxl_p1_reg_t CXL_PSL_Control = {0x0020};
 static const cxl_p1_reg_t CXL_PSL_DLCNTL  = {0x0060};
 static const cxl_p1_reg_t CXL_PSL_DLADDR  = {0x0068};
 
-/* PSL Lookaside Buffer Management Area */
+/* PSL Lookaside Buffer Management Area - CAIA 1 */
 static const cxl_p1_reg_t CXL_PSL_LBISEL  = {0x0080};
 static const cxl_p1_reg_t CXL_PSL_SLBIE   = {0x0088};
 static const cxl_p1_reg_t CXL_PSL_SLBIA   = {0x0090};
@@ -82,7 +82,7 @@ static const cxl_p1_reg_t CXL_PSL_TLBIA   = {0x00A8};
 static const cxl_p1_reg_t CXL_PSL_AFUSEL  = {0x00B0};
 
 /* 0x00C0:7EFF Implementation dependent area */
-/* PSL registers */
+/* PSL registers - CAIA 1 */
 static const cxl_p1_reg_t CXL_PSL_FIR1      = {0x0100};
 static const cxl_p1_reg_t CXL_PSL_FIR2      = {0x0108};
 static const cxl_p1_reg_t CXL_PSL_Timebase  = {0x0110};
@@ -109,7 +109,7 @@ static const cxl_p1n_reg_t CXL_PSL_AMBAR_An       = {0x10};
 static const cxl_p1n_reg_t CXL_PSL_SPOffset_An    = {0x18};
 static const cxl_p1n_reg_t CXL_PSL_ID_An          = {0x20};
 static const cxl_p1n_reg_t CXL_PSL_SERR_An        = {0x28};
-/* Memory Management and Lookaside Buffer Management */
+/* Memory Management and Lookaside Buffer Management - CAIA 1*/
 static const cxl_p1n_reg_t CXL_PSL_SDR_An         = {0x30};
 static const cxl_p1n_reg_t CXL_PSL_AMOR_An        = {0x38};
 /* Pointer Area */
@@ -124,6 +124,7 @@ static const cxl_p1n_reg_t CXL_PSL_IVTE_Limit_An  = {0xB8};
 /* 0xC0:FF Implementation Dependent Area */
 static const cxl_p1n_reg_t CXL_PSL_FIR_SLICE_An   = {0xC0};
 static const cxl_p1n_reg_t CXL_AFU_DEBUG_An       = {0xC8};
+/* 0xC0:FF Implementation Dependent Area - CAIA 1 */
 static const cxl_p1n_reg_t CXL_PSL_APCALLOC_A     = {0xD0};
 static const cxl_p1n_reg_t CXL_PSL_COALLOC_A      = {0xD8};
 static const cxl_p1n_reg_t CXL_PSL_RXCTL_A        = {0xE0};
@@ -133,12 +134,14 @@ static const cxl_p1n_reg_t CXL_PSL_SLICE_TRACE    = {0xE8};
 /* Configuration and Control Area */
 static const cxl_p2n_reg_t CXL_PSL_PID_TID_An = {0x000};
 static const cxl_p2n_reg_t CXL_CSRP_An        = {0x008};
+/* Configuration and Control Area - CAIA 1 */
 static const cxl_p2n_reg_t CXL_AURP0_An       = {0x010};
 static const cxl_p2n_reg_t CXL_AURP1_An       = {0x018};
 static const cxl_p2n_reg_t CXL_SSTP0_An       = {0x020};
 static const cxl_p2n_reg_t CXL_SSTP1_An       = {0x028};
+/* Configuration and Control Area - CAIA 1 */
 static const cxl_p2n_reg_t CXL_PSL_AMR_An     = {0x030};
-/* Segment Lookaside Buffer Management */
+/* Segment Lookaside Buffer Management - CAIA 1 */
 static const cxl_p2n_reg_t CXL_SLBIE_An       = {0x040};
 static const cxl_p2n_reg_t CXL_SLBIA_An       = {0x048};
 static const cxl_p2n_reg_t CXL_SLBI_Select_An = {0x050};
@@ -257,7 +260,7 @@ static const cxl_p2n_reg_t CXL_PSL_WED_An     = {0x0A0};
 #define CXL_SSTP1_An_STVA_L_MASK (~((1ull << (63-55))-1))
 #define CXL_SSTP1_An_V              (1ull << (63-63))
 
-/****** CXL_PSL_SLBIE_[An] **************************************************/
+/****** CXL_PSL_SLBIE_[An] - CAIA 1 **************************************************/
 /* write: */
 #define CXL_SLBIE_C        PPC_BIT(36)         /* Class */
 #define CXL_SLBIE_SS       PPC_BITMASK(37, 38) /* Segment Size */
@@ -267,10 +270,10 @@ static const cxl_p2n_reg_t CXL_PSL_WED_An     = {0x0A0};
 #define CXL_SLBIE_MAX      PPC_BITMASK(24, 31)
 #define CXL_SLBIE_PENDING  PPC_BITMASK(56, 63)
 
-/****** Common to all CXL_TLBIA/SLBIA_[An] **********************************/
+/****** Common to all CXL_TLBIA/SLBIA_[An] - CAIA 1 **********************************/
 #define CXL_TLB_SLB_P          (1ull) /* Pending (read) */
 
-/****** Common to all CXL_TLB/SLB_IA/IE_[An] registers **********************/
+/****** Common to all CXL_TLB/SLB_IA/IE_[An] registers - CAIA 1 **********************/
 #define CXL_TLB_SLB_IQ_ALL     (0ull) /* Inv qualifier */
 #define CXL_TLB_SLB_IQ_LPID    (1ull) /* Inv qualifier */
 #define CXL_TLB_SLB_IQ_LPIDPID (3ull) /* Inv qualifier */
@@ -278,7 +281,7 @@ static const cxl_p2n_reg_t CXL_PSL_WED_An     = {0x0A0};
 /****** CXL_PSL_AFUSEL ******************************************************/
 #define CXL_PSL_AFUSEL_A (1ull << (63-55)) /* Adapter wide invalidates affect all AFUs */
 
-/****** CXL_PSL_DSISR_An ****************************************************/
+/****** CXL_PSL_DSISR_An - CAIA 1 ****************************************************/
 #define CXL_PSL_DSISR_An_DS (1ull << (63-0))  /* Segment not found */
 #define CXL_PSL_DSISR_An_DM (1ull << (63-1))  /* PTE not found (See also: M) or protection fault */
 #define CXL_PSL_DSISR_An_ST (1ull << (63-2))  /* Segment Table PTE not found */
@@ -749,6 +752,22 @@ static inline u64 cxl_p2n_read(struct cxl_afu *afu, cxl_p2n_reg_t reg)
 		return ~0ULL;
 }
 
+static inline bool cxl_is_power8(void)
+{
+	if ((pvr_version_is(PVR_POWER8E)) ||
+	    (pvr_version_is(PVR_POWER8NVL)) ||
+	    (pvr_version_is(PVR_POWER8)))
+		return true;
+	return false;
+}
+
+static inline bool cxl_is_psl8(struct cxl_afu *afu)
+{
+	if (afu->adapter->caia_major == 1)
+		return true;
+	return false;
+}
+
 ssize_t cxl_pci_afu_read_err_buffer(struct cxl_afu *afu, char *buf,
 				loff_t off, size_t count);
 

commit 64663f372c72cedeba1b1dc86df9cc159ae5a93d
Author: Christophe Lombard <clombard@linux.vnet.ibm.com>
Date:   Fri Apr 7 16:11:57 2017 +0200

    cxl: Rename some psl8 specific functions
    
    Rename a few functions, changing the '_psl' suffix to '_psl8', to make
    clear that the implementation is psl8 specific.
    Those functions will have an equivalent implementation for the psl9 in
    a later patch.
    
    Signed-off-by: Christophe Lombard <clombard@linux.vnet.ibm.com>
    Reviewed-by: Andrew Donnellan <andrew.donnellan@au1.ibm.com>
    Acked-by: Frederic Barrat <fbarrat@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index 626073d1786c..a54c0030932c 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -813,10 +813,10 @@ int afu_register_irqs(struct cxl_context *ctx, u32 count);
 void afu_release_irqs(struct cxl_context *ctx, void *cookie);
 void afu_irq_name_free(struct cxl_context *ctx);
 
-int cxl_attach_afu_directed_psl(struct cxl_context *ctx, u64 wed, u64 amr);
-int cxl_activate_dedicated_process_psl(struct cxl_afu *afu);
-int cxl_attach_dedicated_process_psl(struct cxl_context *ctx, u64 wed, u64 amr);
-void cxl_update_dedicated_ivtes_psl(struct cxl_context *ctx);
+int cxl_attach_afu_directed_psl8(struct cxl_context *ctx, u64 wed, u64 amr);
+int cxl_activate_dedicated_process_psl8(struct cxl_afu *afu);
+int cxl_attach_dedicated_process_psl8(struct cxl_context *ctx, u64 wed, u64 amr);
+void cxl_update_dedicated_ivtes_psl8(struct cxl_context *ctx);
 
 #ifdef CONFIG_DEBUG_FS
 
@@ -826,10 +826,10 @@ int cxl_debugfs_adapter_add(struct cxl *adapter);
 void cxl_debugfs_adapter_remove(struct cxl *adapter);
 int cxl_debugfs_afu_add(struct cxl_afu *afu);
 void cxl_debugfs_afu_remove(struct cxl_afu *afu);
-void cxl_stop_trace_psl(struct cxl *cxl);
-void cxl_debugfs_add_adapter_regs_psl(struct cxl *adapter, struct dentry *dir);
+void cxl_stop_trace_psl8(struct cxl *cxl);
+void cxl_debugfs_add_adapter_regs_psl8(struct cxl *adapter, struct dentry *dir);
 void cxl_debugfs_add_adapter_regs_xsl(struct cxl *adapter, struct dentry *dir);
-void cxl_debugfs_add_afu_regs_psl(struct cxl_afu *afu, struct dentry *dir);
+void cxl_debugfs_add_afu_regs_psl8(struct cxl_afu *afu, struct dentry *dir);
 
 #else /* CONFIG_DEBUG_FS */
 
@@ -860,11 +860,11 @@ static inline void cxl_debugfs_afu_remove(struct cxl_afu *afu)
 {
 }
 
-static inline void cxl_stop_trace(struct cxl *cxl)
+static inline void cxl_stop_trace_psl8(struct cxl *cxl)
 {
 }
 
-static inline void cxl_debugfs_add_adapter_regs_psl(struct cxl *adapter,
+static inline void cxl_debugfs_add_adapter_regs_psl8(struct cxl *adapter,
 						    struct dentry *dir)
 {
 }
@@ -874,7 +874,7 @@ static inline void cxl_debugfs_add_adapter_regs_xsl(struct cxl *adapter,
 {
 }
 
-static inline void cxl_debugfs_add_afu_regs_psl(struct cxl_afu *afu, struct dentry *dir)
+static inline void cxl_debugfs_add_afu_regs_psl8(struct cxl_afu *afu, struct dentry *dir)
 {
 }
 
@@ -919,8 +919,8 @@ struct cxl_irq_info {
 };
 
 void cxl_assign_psn_space(struct cxl_context *ctx);
-int cxl_invalidate_all_psl(struct cxl *adapter);
-irqreturn_t cxl_irq_psl(int irq, struct cxl_context *ctx, struct cxl_irq_info *irq_info);
+int cxl_invalidate_all_psl8(struct cxl *adapter);
+irqreturn_t cxl_irq_psl8(int irq, struct cxl_context *ctx, struct cxl_irq_info *irq_info);
 irqreturn_t cxl_fail_irq_psl(struct cxl_afu *afu, struct cxl_irq_info *irq_info);
 int cxl_register_one_irq(struct cxl *adapter, irq_handler_t handler,
 			void *cookie, irq_hw_number_t *dest_hwirq,
@@ -932,7 +932,7 @@ int cxl_data_cache_flush(struct cxl *adapter);
 int cxl_afu_disable(struct cxl_afu *afu);
 int cxl_psl_purge(struct cxl_afu *afu);
 
-void cxl_native_irq_dump_regs_psl(struct cxl_context *ctx);
+void cxl_native_irq_dump_regs_psl8(struct cxl_context *ctx);
 void cxl_native_err_irq_dump_regs(struct cxl *adapter);
 int cxl_pci_vphb_add(struct cxl_afu *afu);
 void cxl_pci_vphb_remove(struct cxl_afu *afu);

commit bdd2e7150644fee4de7167a3e08294ef32eeda11
Author: Christophe Lombard <clombard@linux.vnet.ibm.com>
Date:   Fri Apr 7 16:11:56 2017 +0200

    cxl: Update implementation service layer
    
    The service layer API (in cxl.h) lists some low-level functions whose
    implementation is different on PSL8, PSL9 and XSL:
    - Init implementation for the adapter and the afu.
    - Invalidate TLB/SLB.
    - Attach process for dedicated/directed models.
    - Handle psl interrupts.
    - Debug registers for the adapter and the afu.
    - Traces.
    Each environment implements its own functions, and the common code uses
    them through function pointers, defined in cxl_service_layer_ops.
    
    Signed-off-by: Christophe Lombard <clombard@linux.vnet.ibm.com>
    Reviewed-by: Andrew Donnellan <andrew.donnellan@au1.ibm.com>
    Acked-by: Frederic Barrat <fbarrat@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index 4bcbf7a9bba6..626073d1786c 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -553,13 +553,23 @@ struct cxl_context {
 	struct mm_struct *mm;
 };
 
+struct cxl_irq_info;
+
 struct cxl_service_layer_ops {
 	int (*adapter_regs_init)(struct cxl *adapter, struct pci_dev *dev);
+	int (*invalidate_all)(struct cxl *adapter);
 	int (*afu_regs_init)(struct cxl_afu *afu);
+	int (*sanitise_afu_regs)(struct cxl_afu *afu);
 	int (*register_serr_irq)(struct cxl_afu *afu);
 	void (*release_serr_irq)(struct cxl_afu *afu);
-	void (*debugfs_add_adapter_sl_regs)(struct cxl *adapter, struct dentry *dir);
-	void (*debugfs_add_afu_sl_regs)(struct cxl_afu *afu, struct dentry *dir);
+	irqreturn_t (*handle_interrupt)(int irq, struct cxl_context *ctx, struct cxl_irq_info *irq_info);
+	irqreturn_t (*fail_irq)(struct cxl_afu *afu, struct cxl_irq_info *irq_info);
+	int (*activate_dedicated_process)(struct cxl_afu *afu);
+	int (*attach_afu_directed)(struct cxl_context *ctx, u64 wed, u64 amr);
+	int (*attach_dedicated_process)(struct cxl_context *ctx, u64 wed, u64 amr);
+	void (*update_dedicated_ivtes)(struct cxl_context *ctx);
+	void (*debugfs_add_adapter_regs)(struct cxl *adapter, struct dentry *dir);
+	void (*debugfs_add_afu_regs)(struct cxl_afu *afu, struct dentry *dir);
 	void (*psl_irq_dump_registers)(struct cxl_context *ctx);
 	void (*err_irq_dump_registers)(struct cxl *adapter);
 	void (*debugfs_stop_trace)(struct cxl *adapter);
@@ -803,6 +813,11 @@ int afu_register_irqs(struct cxl_context *ctx, u32 count);
 void afu_release_irqs(struct cxl_context *ctx, void *cookie);
 void afu_irq_name_free(struct cxl_context *ctx);
 
+int cxl_attach_afu_directed_psl(struct cxl_context *ctx, u64 wed, u64 amr);
+int cxl_activate_dedicated_process_psl(struct cxl_afu *afu);
+int cxl_attach_dedicated_process_psl(struct cxl_context *ctx, u64 wed, u64 amr);
+void cxl_update_dedicated_ivtes_psl(struct cxl_context *ctx);
+
 #ifdef CONFIG_DEBUG_FS
 
 int cxl_debugfs_init(void);
@@ -811,10 +826,10 @@ int cxl_debugfs_adapter_add(struct cxl *adapter);
 void cxl_debugfs_adapter_remove(struct cxl *adapter);
 int cxl_debugfs_afu_add(struct cxl_afu *afu);
 void cxl_debugfs_afu_remove(struct cxl_afu *afu);
-void cxl_stop_trace(struct cxl *cxl);
-void cxl_debugfs_add_adapter_psl_regs(struct cxl *adapter, struct dentry *dir);
-void cxl_debugfs_add_adapter_xsl_regs(struct cxl *adapter, struct dentry *dir);
-void cxl_debugfs_add_afu_psl_regs(struct cxl_afu *afu, struct dentry *dir);
+void cxl_stop_trace_psl(struct cxl *cxl);
+void cxl_debugfs_add_adapter_regs_psl(struct cxl *adapter, struct dentry *dir);
+void cxl_debugfs_add_adapter_regs_xsl(struct cxl *adapter, struct dentry *dir);
+void cxl_debugfs_add_afu_regs_psl(struct cxl_afu *afu, struct dentry *dir);
 
 #else /* CONFIG_DEBUG_FS */
 
@@ -849,17 +864,17 @@ static inline void cxl_stop_trace(struct cxl *cxl)
 {
 }
 
-static inline void cxl_debugfs_add_adapter_psl_regs(struct cxl *adapter,
+static inline void cxl_debugfs_add_adapter_regs_psl(struct cxl *adapter,
 						    struct dentry *dir)
 {
 }
 
-static inline void cxl_debugfs_add_adapter_xsl_regs(struct cxl *adapter,
+static inline void cxl_debugfs_add_adapter_regs_xsl(struct cxl *adapter,
 						    struct dentry *dir)
 {
 }
 
-static inline void cxl_debugfs_add_afu_psl_regs(struct cxl_afu *afu, struct dentry *dir)
+static inline void cxl_debugfs_add_afu_regs_psl(struct cxl_afu *afu, struct dentry *dir)
 {
 }
 
@@ -904,19 +919,20 @@ struct cxl_irq_info {
 };
 
 void cxl_assign_psn_space(struct cxl_context *ctx);
-irqreturn_t cxl_irq(int irq, struct cxl_context *ctx, struct cxl_irq_info *irq_info);
+int cxl_invalidate_all_psl(struct cxl *adapter);
+irqreturn_t cxl_irq_psl(int irq, struct cxl_context *ctx, struct cxl_irq_info *irq_info);
+irqreturn_t cxl_fail_irq_psl(struct cxl_afu *afu, struct cxl_irq_info *irq_info);
 int cxl_register_one_irq(struct cxl *adapter, irq_handler_t handler,
 			void *cookie, irq_hw_number_t *dest_hwirq,
 			unsigned int *dest_virq, const char *name);
 
 int cxl_check_error(struct cxl_afu *afu);
 int cxl_afu_slbia(struct cxl_afu *afu);
-int cxl_tlb_slb_invalidate(struct cxl *adapter);
 int cxl_data_cache_flush(struct cxl *adapter);
 int cxl_afu_disable(struct cxl_afu *afu);
 int cxl_psl_purge(struct cxl_afu *afu);
 
-void cxl_native_psl_irq_dump_regs(struct cxl_context *ctx);
+void cxl_native_irq_dump_regs_psl(struct cxl_context *ctx);
 void cxl_native_err_irq_dump_regs(struct cxl *adapter);
 int cxl_pci_vphb_add(struct cxl_afu *afu);
 void cxl_pci_vphb_remove(struct cxl_afu *afu);

commit 6dd2d23403396d8e6d153a6c9db56e1a1012bad8
Author: Christophe Lombard <clombard@linux.vnet.ibm.com>
Date:   Fri Apr 7 16:11:55 2017 +0200

    cxl: Keep track of mm struct associated with a context
    
    The mm_struct corresponding to the current task is acquired each time
    an interrupt is raised. So to simplify the code, we only get the
    mm_struct when attaching an AFU context to the process.
    The mm_count reference is increased to ensure that the mm_struct can't
    be freed. The mm_struct will be released when the context is detached.
    A reference on mm_users is not kept to avoid a circular dependency if
    the process mmaps its cxl mmio and forget to unmap before exiting.
    The field glpid (pid of the group leader associated with the pid), of
    the structure cxl_context, is removed because it's no longer useful.
    
    Signed-off-by: Christophe Lombard <clombard@linux.vnet.ibm.com>
    Reviewed-by: Andrew Donnellan <andrew.donnellan@au1.ibm.com>
    Acked-by: Frederic Barrat <fbarrat@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index 36bc213629ad..4bcbf7a9bba6 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -482,8 +482,6 @@ struct cxl_context {
 	unsigned int sst_size, sst_lru;
 
 	wait_queue_head_t wq;
-	/* pid of the group leader associated with the pid */
-	struct pid *glpid;
 	/* use mm context associated with this pid for ds faults */
 	struct pid *pid;
 	spinlock_t lock; /* Protects pending_irq_mask, pending_fault and fault_addr */
@@ -551,6 +549,8 @@ struct cxl_context {
 	 * CX4 only:
 	 */
 	struct list_head extra_irq_contexts;
+
+	struct mm_struct *mm;
 };
 
 struct cxl_service_layer_ops {
@@ -1012,4 +1012,10 @@ int cxl_adapter_context_lock(struct cxl *adapter);
 /* Unlock the contexts-lock if taken. Warn and force unlock otherwise */
 void cxl_adapter_context_unlock(struct cxl *adapter);
 
+/* Increases the reference count to "struct mm_struct" */
+void cxl_context_mm_count_get(struct cxl_context *ctx);
+
+/* Decrements the reference count to "struct mm_struct" */
+void cxl_context_mm_count_put(struct cxl_context *ctx);
+
 #endif

commit 66ef20c7834b7df18168b12a57ef01c6ae0d1a81
Author: Christophe Lombard <clombard@linux.vnet.ibm.com>
Date:   Fri Apr 7 16:11:54 2017 +0200

    cxl: Remove unused values in bare-metal environment.
    
    The two previously fields pid and tid, located in the structure
    cxl_irq_info, are only used in the guest environment. To avoid confusion,
    it's not necessary to fill the fields in the bare-metal environment.
    Pid_tid is now renamed to 'reserved' to avoid undefined behavior on
    bare-metal. The PSL Process and Thread Identification Register
    (CXL_PSL_PID_TID_An) is only used when attaching a dedicated process
    for PSL8 only. This register goes away in CAIA2.
    
    Signed-off-by: Christophe Lombard <clombard@linux.vnet.ibm.com>
    Reviewed-by: Andrew Donnellan <andrew.donnellan@au1.ibm.com>
    Acked-by: Frederic Barrat <fbarrat@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index 79e60ec70bd3..36bc213629ad 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -888,27 +888,15 @@ int __detach_context(struct cxl_context *ctx);
 /*
  * This must match the layout of the H_COLLECT_CA_INT_INFO retbuf defined
  * in PAPR.
- * A word about endianness: a pointer to this structure is passed when
- * calling the hcall. However, it is not a block of memory filled up by
- * the hypervisor. The return values are found in registers, and copied
- * one by one when returning from the hcall. See the end of the call to
- * plpar_hcall9() in hvCall.S
- * As a consequence:
- * - we don't need to do any endianness conversion
- * - the pid and tid are an exception. They are 32-bit values returned in
- *   the same 64-bit register. So we do need to worry about byte ordering.
+ * Field pid_tid is now 'reserved' because it's no more used on bare-metal.
+ * On a guest environment, PSL_PID_An is located on the upper 32 bits and
+ * PSL_TID_An register in the lower 32 bits.
  */
 struct cxl_irq_info {
 	u64 dsisr;
 	u64 dar;
 	u64 dsr;
-#ifndef CONFIG_CPU_LITTLE_ENDIAN
-	u32 pid;
-	u32 tid;
-#else
-	u32 tid;
-	u32 pid;
-#endif
+	u64 reserved;
 	u64 afu_err;
 	u64 errstat;
 	u64 proc_handle;

commit 171ed0fcd8966d82c45376f1434678e7b9d4d9b1
Author: Andrew Donnellan <andrew.donnellan@au1.ibm.com>
Date:   Mon Feb 6 12:07:17 2017 +1100

    cxl: fix nested locking hang during EEH hotplug
    
    Commit 14a3ae34bfd0 ("cxl: Prevent read/write to AFU config space while AFU
    not configured") introduced a rwsem to fix an invalid memory access that
    occurred when someone attempts to access the config space of an AFU on a
    vPHB whilst the AFU is deconfigured, such as during EEH recovery.
    
    It turns out that it's possible to run into a nested locking issue when EEH
    recovery fails and a full device hotplug is required.
    cxl_pci_error_detected() deconfigures the AFU, taking a writer lock on
    configured_rwsem. When EEH recovery fails, the EEH code calls
    pci_hp_remove_devices() to remove the device, which in turn calls
    cxl_remove() -> cxl_pci_remove_afu() -> pci_deconfigure_afu(), which tries
    to grab the writer lock that's already held.
    
    Standard rwsem semantics don't express what we really want to do here and
    don't allow for nested locking. Fix this by replacing the rwsem with an
    atomic_t which we can control more finely. Allow the AFU to be locked
    multiple times so long as there are no readers.
    
    Fixes: 14a3ae34bfd0 ("cxl: Prevent read/write to AFU config space while AFU not configured")
    Cc: stable@vger.kernel.org # v4.9+
    Signed-off-by: Andrew Donnellan <andrew.donnellan@au1.ibm.com>
    Acked-by: Frederic Barrat <fbarrat@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index 6c722d96b775..79e60ec70bd3 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -418,8 +418,9 @@ struct cxl_afu {
 	struct dentry *debugfs;
 	struct mutex contexts_lock;
 	spinlock_t afu_cntl_lock;
-	/* Used to block access to AFU config space while deconfigured */
-	struct rw_semaphore configured_rwsem;
+
+	/* -1: AFU deconfigured/locked, >= 0: number of readers */
+	atomic_t configured_state;
 
 	/* AFU error buffer fields and bin attribute for sysfs */
 	u64 eb_len, eb_offset;

commit 39d40871526627fd0e2cfc1e2fb88500a5049c4c
Author: Andrew Donnellan <andrew.donnellan@au1.ibm.com>
Date:   Wed Feb 1 14:22:07 2017 +1100

    cxl: Fix build when CONFIG_DEBUG_FS=n
    
    Stub out the debugfs functions so that the build doesn't break when
    CONFIG_DEBUG_FS=n.
    
    Reported-by: Michael Ellerman <mpe@ellerman.id.au>
    Signed-off-by: Andrew Donnellan <andrew.donnellan@au1.ibm.com>
    Acked-by: Ian Munsie <imunsie@au1.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index b4a43fd14b99..6c722d96b775 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -802,12 +802,67 @@ int afu_register_irqs(struct cxl_context *ctx, u32 count);
 void afu_release_irqs(struct cxl_context *ctx, void *cookie);
 void afu_irq_name_free(struct cxl_context *ctx);
 
+#ifdef CONFIG_DEBUG_FS
+
 int cxl_debugfs_init(void);
 void cxl_debugfs_exit(void);
 int cxl_debugfs_adapter_add(struct cxl *adapter);
 void cxl_debugfs_adapter_remove(struct cxl *adapter);
 int cxl_debugfs_afu_add(struct cxl_afu *afu);
 void cxl_debugfs_afu_remove(struct cxl_afu *afu);
+void cxl_stop_trace(struct cxl *cxl);
+void cxl_debugfs_add_adapter_psl_regs(struct cxl *adapter, struct dentry *dir);
+void cxl_debugfs_add_adapter_xsl_regs(struct cxl *adapter, struct dentry *dir);
+void cxl_debugfs_add_afu_psl_regs(struct cxl_afu *afu, struct dentry *dir);
+
+#else /* CONFIG_DEBUG_FS */
+
+static inline int __init cxl_debugfs_init(void)
+{
+	return 0;
+}
+
+static inline void cxl_debugfs_exit(void)
+{
+}
+
+static inline int cxl_debugfs_adapter_add(struct cxl *adapter)
+{
+	return 0;
+}
+
+static inline void cxl_debugfs_adapter_remove(struct cxl *adapter)
+{
+}
+
+static inline int cxl_debugfs_afu_add(struct cxl_afu *afu)
+{
+	return 0;
+}
+
+static inline void cxl_debugfs_afu_remove(struct cxl_afu *afu)
+{
+}
+
+static inline void cxl_stop_trace(struct cxl *cxl)
+{
+}
+
+static inline void cxl_debugfs_add_adapter_psl_regs(struct cxl *adapter,
+						    struct dentry *dir)
+{
+}
+
+static inline void cxl_debugfs_add_adapter_xsl_regs(struct cxl *adapter,
+						    struct dentry *dir)
+{
+}
+
+static inline void cxl_debugfs_add_afu_psl_regs(struct cxl_afu *afu, struct dentry *dir)
+{
+}
+
+#endif /* CONFIG_DEBUG_FS */
 
 void cxl_handle_fault(struct work_struct *work);
 void cxl_prefault(struct cxl_context *ctx, u64 wed);
@@ -872,12 +927,8 @@ int cxl_data_cache_flush(struct cxl *adapter);
 int cxl_afu_disable(struct cxl_afu *afu);
 int cxl_psl_purge(struct cxl_afu *afu);
 
-void cxl_debugfs_add_adapter_psl_regs(struct cxl *adapter, struct dentry *dir);
-void cxl_debugfs_add_adapter_xsl_regs(struct cxl *adapter, struct dentry *dir);
-void cxl_debugfs_add_afu_psl_regs(struct cxl_afu *afu, struct dentry *dir);
 void cxl_native_psl_irq_dump_regs(struct cxl_context *ctx);
 void cxl_native_err_irq_dump_regs(struct cxl *adapter);
-void cxl_stop_trace(struct cxl *cxl);
 int cxl_pci_vphb_add(struct cxl_afu *afu);
 void cxl_pci_vphb_remove(struct cxl_afu *afu);
 void cxl_release_mapping(struct cxl_context *ctx);

commit 14a3ae34bfd0bcb1cc12d55b06a8584c11fac6fc
Author: Andrew Donnellan <andrew.donnellan@au1.ibm.com>
Date:   Fri Dec 9 17:18:50 2016 +1100

    cxl: Prevent read/write to AFU config space while AFU not configured
    
    During EEH recovery, we deconfigure all AFUs whilst leaving the
    corresponding vPHB and virtual PCI device in place.
    
    If something attempts to interact with the AFU's PCI config space (e.g.
    running lspci) after the AFU has been deconfigured and before it's
    reconfigured, cxl_pcie_{read,write}_config() will read invalid values from
    the deconfigured struct cxl_afu and proceed to Oops when they try to
    dereference pointers that have been set to NULL during deconfiguration.
    
    Add a rwsem to struct cxl_afu so we can prevent interaction with config
    space while the AFU is deconfigured.
    
    Reported-by: Pradipta Ghosh <pradghos@in.ibm.com>
    Suggested-by: Frederic Barrat <fbarrat@linux.vnet.ibm.com>
    Cc: stable@vger.kernel.org # v4.9+
    Signed-off-by: Andrew Donnellan <andrew.donnellan@au1.ibm.com>
    Signed-off-by: Vaibhav Jain <vaibhav@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index b24d76723fb0..b4a43fd14b99 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -418,6 +418,8 @@ struct cxl_afu {
 	struct dentry *debugfs;
 	struct mutex contexts_lock;
 	spinlock_t afu_cntl_lock;
+	/* Used to block access to AFU config space while deconfigured */
+	struct rw_semaphore configured_rwsem;
 
 	/* AFU error buffer fields and bin attribute for sysfs */
 	u64 eb_len, eb_offset;

commit bdecf76e319a29735d828575f4a9269f0e17c547
Author: Frederic Barrat <fbarrat@linux.vnet.ibm.com>
Date:   Fri Nov 18 23:00:31 2016 +1100

    cxl: Fix coredump generation when cxl_get_fd() is used
    
    If a process dumps core while owning a cxl file descriptor obtained
    from an AFU driver (e.g. cxlflash) through the cxl_get_fd() API, the
    following error occurs:
    
      [  868.027591] Unable to handle kernel paging request for data at address ...
      [  868.027778] Faulting instruction address: 0xc00000000035edb0
      cpu 0x8c: Vector: 300 (Data Access) at [c000003c688275e0]
          pc: c00000000035edb0: elf_core_dump+0xd60/0x1300
          lr: c00000000035ed80: elf_core_dump+0xd30/0x1300
          sp: c000003c68827860
         msr: 9000000100009033
         dar: c
      dsisr: 40000000
       current = 0xc000003c68780000
       paca    = 0xc000000001b73200   softe: 0        irq_happened: 0x01
          pid   = 46725, comm = hxesurelock
      enter ? for help
      [c000003c68827a60] c00000000036948c do_coredump+0xcec/0x11e0
      [c000003c68827c20] c0000000000ce9e0 get_signal+0x540/0x7b0
      [c000003c68827d10] c000000000017354 do_signal+0x54/0x2b0
      [c000003c68827e00] c00000000001777c do_notify_resume+0xbc/0xd0
      [c000003c68827e30] c000000000009838 ret_from_except_lite+0x64/0x68
      --- Exception: 300 (Data Access) at 00003fff98ad2918
    
    The root cause is that the address_space structure for the file
    doesn't define a 'host' member.
    
    When cxl allocates a file descriptor, it's using the anonymous inode
    to back the file, but allocates a private address_space for each
    context. The private address_space allows to track memory allocation
    for each context. cxl doesn't define the 'host' member of the address
    space, i.e. the inode. We don't want to define it as the anonymous
    inode, since there's no longer a 1-to-1 relation between address_space
    and inode.
    
    To fix it, instead of using the anonymous inode, we introduce a simple
    pseudo filesystem so that cxl can allocate its own inodes. So we now
    have one inode for each file and address_space. The pseudo filesystem
    is only mounted on the first allocation of a file descriptor by
    cxl_get_fd().
    
    Tested with cxlflash.
    
    Signed-off-by: Frederic Barrat <fbarrat@linux.vnet.ibm.com>
    Reviewed-by: Matthew R. Ochs <mrochs@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index a144073593fa..b24d76723fb0 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -817,8 +817,9 @@ void cxl_dump_debug_buffer(void *addr, size_t size);
 void init_cxl_native(void);
 
 struct cxl_context *cxl_context_alloc(void);
-int cxl_context_init(struct cxl_context *ctx, struct cxl_afu *afu, bool master,
-		     struct address_space *mapping);
+int cxl_context_init(struct cxl_context *ctx, struct cxl_afu *afu, bool master);
+void cxl_context_set_mapping(struct cxl_context *ctx,
+			struct address_space *mapping);
 void cxl_context_free(struct cxl_context *ctx);
 int cxl_context_iomap(struct cxl_context *ctx, struct vm_area_struct *vma);
 unsigned int cxl_map_irq(struct cxl *adapter, irq_hw_number_t hwirq,
@@ -877,6 +878,7 @@ void cxl_native_err_irq_dump_regs(struct cxl *adapter);
 void cxl_stop_trace(struct cxl *cxl);
 int cxl_pci_vphb_add(struct cxl_afu *afu);
 void cxl_pci_vphb_remove(struct cxl_afu *afu);
+void cxl_release_mapping(struct cxl_context *ctx);
 
 extern struct pci_driver cxl_pci_driver;
 extern struct platform_driver cxl_of_driver;

commit 70b565bbdb911023373e035225ab10077e4ab937
Author: Vaibhav Jain <vaibhav@linux.vnet.ibm.com>
Date:   Fri Oct 14 15:08:36 2016 +0530

    cxl: Prevent adapter reset if an active context exists
    
    This patch prevents resetting the cxl adapter via sysfs in presence of
    one or more active cxl_context on it. This protects against an
    unrecoverable error caused by PSL owning a dirty cache line even after
    reset and host tries to touch the same cache line. In case a force reset
    of the card is required irrespective of any active contexts, the int
    value -1 can be stored in the 'reset' sysfs attribute of the card.
    
    The patch introduces a new atomic_t member named contexts_num inside
    struct cxl that holds the number of active context attached to the card
    , which is checked against '0' before proceeding with the reset. To
    prevent against a race condition where a context is activated just after
    reset check is performed, the contexts_num is atomically set to '-1'
    after reset-check to indicate that no more contexts can be activated on
    the card anymore.
    
    Before activating a context we atomically test if contexts_num is
    non-negative and if so, increment its value by one. In case the value of
    contexts_num is negative then it indicates that the card is about to be
    reset and context activation is error-ed out at that point.
    
    Fixes: 62fa19d4b4fd ("cxl: Add ability to reset the card")
    Cc: stable@vger.kernel.org # v4.0+
    Acked-by: Frederic Barrat <fbarrat@linux.vnet.ibm.com>
    Reviewed-by: Andrew Donnellan <andrew.donnellan@au1.ibm.com>
    Signed-off-by: Vaibhav Jain <vaibhav@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index 01d372aba131..a144073593fa 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -618,6 +618,14 @@ struct cxl {
 	bool perst_select_user;
 	bool perst_same_image;
 	bool psl_timebase_synced;
+
+	/*
+	 * number of contexts mapped on to this card. Possible values are:
+	 * >0: Number of contexts mapped and new one can be mapped.
+	 *  0: No active contexts and new ones can be mapped.
+	 * -1: No contexts mapped and new ones cannot be mapped.
+	 */
+	atomic_t contexts_num;
 };
 
 int cxl_pci_alloc_one_irq(struct cxl *adapter);
@@ -944,4 +952,20 @@ bool cxl_pci_is_vphb_device(struct pci_dev *dev);
 
 /* decode AFU error bits in the PSL register PSL_SERR_An */
 void cxl_afu_decode_psl_serr(struct cxl_afu *afu, u64 serr);
+
+/*
+ * Increments the number of attached contexts on an adapter.
+ * In case an adapter_context_lock is taken the return -EBUSY.
+ */
+int cxl_adapter_context_get(struct cxl *adapter);
+
+/* Decrements the number of attached contexts on an adapter */
+void cxl_adapter_context_put(struct cxl *adapter);
+
+/* If no active contexts then prevents contexts from being attached */
+int cxl_adapter_context_lock(struct cxl *adapter);
+
+/* Unlock the contexts-lock if taken. Warn and force unlock otherwise */
+void cxl_adapter_context_unlock(struct cxl *adapter);
+
 #endif

commit aaa2245ed836824f21f8e42e0ab63b1637d1cb20
Author: Frederic Barrat <fbarrat@linux.vnet.ibm.com>
Date:   Mon Oct 3 21:36:02 2016 +0200

    cxl: Flush PSL cache before resetting the adapter
    
    If the capi link is going down while the PSL owns a dirty cache line,
    any access from the host for that data could lead to an Uncorrectable
    Error.
    
    So when resetting the capi adapter through sysfs, make sure the PSL
    cache is flushed. It won't help if there are any active Process
    Elements on the card, as the cache would likely get new dirty cache
    lines immediately, but if resetting an idle adapter, it should avoid
    any bad surprises from data left over from terminated Process Elements.
    
    Signed-off-by: Frederic Barrat <fbarrat@linux.vnet.ibm.com>
    Reviewed-by: Andrew Donnellan <andrew.donnellan@au1.ibm.com>
    Acked-by: Ian Munsie <imunsie@au1.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index 344a0ff8f8c7..01d372aba131 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -162,7 +162,10 @@ static const cxl_p2n_reg_t CXL_PSL_WED_An     = {0x0A0};
 #define CXL_PSL_SPAP_V    0x0000000000000001ULL
 
 /****** CXL_PSL_Control ****************************************************/
-#define CXL_PSL_Control_tb 0x0000000000000001ULL
+#define CXL_PSL_Control_tb              (0x1ull << (63-63))
+#define CXL_PSL_Control_Fr              (0x1ull << (63-31))
+#define CXL_PSL_Control_Fs_MASK         (0x3ull << (63-29))
+#define CXL_PSL_Control_Fs_Complete     (0x3ull << (63-29))
 
 /****** CXL_PSL_DLCNTL *****************************************************/
 #define CXL_PSL_DLCNTL_D (0x1ull << (63-28))
@@ -854,6 +857,7 @@ int cxl_register_one_irq(struct cxl *adapter, irq_handler_t handler,
 int cxl_check_error(struct cxl_afu *afu);
 int cxl_afu_slbia(struct cxl_afu *afu);
 int cxl_tlb_slb_invalidate(struct cxl *adapter);
+int cxl_data_cache_flush(struct cxl *adapter);
 int cxl_afu_disable(struct cxl_afu *afu);
 int cxl_psl_purge(struct cxl_afu *afu);
 

commit 164793379ad3b7ef5fc5a28260c111358892dff3
Author: Andrew Donnellan <andrew.donnellan@au1.ibm.com>
Date:   Thu Jul 28 15:39:41 2016 +1000

    cxl: Fix NULL dereference in cxl_context_init() on PowerVM guests
    
    Commit f67a6722d650 ("cxl: Workaround PE=0 hardware limitation in
    Mellanox CX4") added a "min_pe" field to struct cxl_service_layer_ops,
    to allow us to work around a Mellanox CX-4 hardware limitation.
    
    When allocating the PE number in cxl_context_init(), we read from
    ctx->afu->adapter->native->sl_ops->min_pe to get the minimum PE number.
    Unsurprisingly, in a PowerVM guest ctx->afu->adapter->native is NULL,
    and guests don't have a cxl_service_layer_ops struct anywhere.
    
    Move min_pe from struct cxl_service_layer_ops to struct cxl so it's
    accessible in both native and PowerVM environments. For the Mellanox
    CX-4, set the min_pe value in set_sl_ops().
    
    Fixes: f67a6722d650 ("cxl: Workaround PE=0 hardware limitation in Mellanox CX4")
    Reported-by: Frederic Barrat <fbarrat@linux.vnet.ibm.com>
    Signed-off-by: Andrew Donnellan <andrew.donnellan@au1.ibm.com>
    Acked-by: Ian Munsie <imunsie@au1.ibm.com>
    Reviewed-by: Frederic Barrat <fbarrat@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index de090533f18c..344a0ff8f8c7 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -561,7 +561,6 @@ struct cxl_service_layer_ops {
 	u64 (*timebase_read)(struct cxl *adapter);
 	int capi_mode;
 	bool needs_reset_before_disable;
-	int min_pe;
 };
 
 struct cxl_native {
@@ -603,6 +602,7 @@ struct cxl {
 	struct bin_attribute cxl_attr;
 	int adapter_num;
 	int user_irqs;
+	int min_pe;
 	u64 ps_size;
 	u16 psl_rev;
 	u16 base_image;

commit f67a6722d650b864b020b19b3926e7152b55f1ff
Author: Ian Munsie <imunsie@au1.ibm.com>
Date:   Thu Jul 14 07:17:11 2016 +1000

    cxl: Workaround PE=0 hardware limitation in Mellanox CX4
    
    The CX4 card cannot cope with a context with PE=0 due to a hardware
    limitation, resulting in:
    
    [   34.166577] command failed, status limits exceeded(0x8), syndrome 0x5a7939
    [   34.166580] mlx5_core 0000:01:00.1: Failed allocating uar, aborting
    
    Since the kernel API allocates a default context very early during
    device init that will almost certainly get Process Element ID 0 there is
    no easy way for us to extend the API to allow the Mellanox to inform us
    of this limitation ahead of time.
    
    Instead, work around the issue by extending the XSL structure to include
    a minimum PE to allocate. Although the bug is not in the XSL, it is the
    easiest place to work around this limitation given that the CX4 is
    currently the only card that uses an XSL.
    
    Signed-off-by: Ian Munsie <imunsie@au1.ibm.com>
    Reviewed-by: Andrew Donnellan <andrew.donnellan@au1.ibm.com>
    Reviewed-by: Frederic Barrat <fbarrat@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index d50cdb137c43..de090533f18c 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -561,6 +561,7 @@ struct cxl_service_layer_ops {
 	u64 (*timebase_read)(struct cxl *adapter);
 	int capi_mode;
 	bool needs_reset_before_disable;
+	int min_pe;
 };
 
 struct cxl_native {

commit a2f67d5ee8d950caaa7a6144cf0bfb256500b73e
Author: Ian Munsie <imunsie@au1.ibm.com>
Date:   Thu Jul 14 07:17:10 2016 +1000

    cxl: Add support for interrupts on the Mellanox CX4
    
    The Mellanox CX4 in cxl mode uses a hybrid interrupt model, where
    interrupts are routed from the networking hardware to the XSL using the
    MSIX table, and from there will be transformed back into an MSIX
    interrupt using the cxl style interrupts (i.e. using IVTE entries and
    ranges to map a PE and AFU interrupt number to an MSIX address).
    
    We want to hide the implementation details of cxl interrupts as much as
    possible. To this end, we use a special version of the MSI setup &
    teardown routines in the PHB while in cxl mode to allocate the cxl
    interrupts and configure the IVTE entries in the process element.
    
    This function does not configure the MSIX table - the CX4 card uses a
    custom format in that table and it would not be appropriate to fill that
    out in generic code. The rest of the functionality is similar to the
    "Full MSI-X mode" described in the CAIA, and this could be easily
    extended to support other adapters that use that mode in the future.
    
    The interrupts will be associated with the default context. If the
    maximum number of interrupts per context has been limited (e.g. by the
    mlx5 driver), it will automatically allocate additional kernel contexts
    to associate extra interrupts as required. These contexts will be
    started using the same WED that was used to start the default context.
    
    Signed-off-by: Ian Munsie <imunsie@au1.ibm.com>
    Reviewed-by: Andrew Donnellan <andrew.donnellan@au1.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index 73b9a55aa35b..d50cdb137c43 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -731,12 +731,16 @@ ssize_t cxl_pci_afu_read_err_buffer(struct cxl_afu *afu, char *buf,
 bool _cxl_pci_associate_default_context(struct pci_dev *dev, struct cxl_afu *afu);
 void _cxl_pci_disable_device(struct pci_dev *dev);
 int _cxl_next_msi_hwirq(struct pci_dev *pdev, struct cxl_context **ctx, int *afu_irq);
+int _cxl_cx4_setup_msi_irqs(struct pci_dev *pdev, int nvec, int type);
+void _cxl_cx4_teardown_msi_irqs(struct pci_dev *pdev);
 
 struct cxl_calls {
 	void (*cxl_slbia)(struct mm_struct *mm);
 	bool (*cxl_pci_associate_default_context)(struct pci_dev *dev, struct cxl_afu *afu);
 	void (*cxl_pci_disable_device)(struct pci_dev *dev);
 	int (*cxl_next_msi_hwirq)(struct pci_dev *pdev, struct cxl_context **ctx, int *afu_irq);
+	int (*cxl_cx4_setup_msi_irqs)(struct pci_dev *pdev, int nvec, int type);
+	void (*cxl_cx4_teardown_msi_irqs)(struct pci_dev *pdev);
 
 	struct module *owner;
 };

commit cbce0917e2e47d4bf5aa3b5fd6b1247f33e1a126
Author: Ian Munsie <imunsie@au1.ibm.com>
Date:   Thu Jul 14 07:17:09 2016 +1000

    cxl: Add preliminary workaround for CX4 interrupt limitation
    
    The Mellanox CX4 has a hardware limitation where only 4 bits of the
    AFU interrupt number can be passed to the XSL when sending an interrupt,
    limiting it to only 15 interrupts per context (AFU interrupt number 0 is
    invalid).
    
    In order to overcome this, we will allocate additional contexts linked
    to the default context as extra address space for the extra interrupts -
    this will be implemented in the next patch.
    
    This patch adds the preliminary support to allow this, by way of adding
    a linked list in the context structure that we use to keep track of the
    contexts dedicated to interrupts, and an API to simultaneously iterate
    over the related context structures, AFU interrupt numbers and hardware
    interrupt numbers. The point of using a single API to iterate these is
    to hide some of the details of the iteration from external code, and to
    reduce the number of APIs that need to be exported via base.c to allow
    built in code to call.
    
    Signed-off-by: Ian Munsie <imunsie@au1.ibm.com>
    Reviewed-by: Frederic Barrat <fbarrat@linux.vnet.ibm.com>
    Reviewed-by: Andrew Donnellan <andrew.donnellan@au1.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index b81f476a2b9f..73b9a55aa35b 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -537,6 +537,14 @@ struct cxl_context {
 	atomic_t afu_driver_events;
 
 	struct rcu_head rcu;
+
+	/*
+	 * Only used when more interrupts are allocated via
+	 * pci_enable_msix_range than are supported in the default context, to
+	 * use additional contexts to overcome the limitation. i.e. Mellanox
+	 * CX4 only:
+	 */
+	struct list_head extra_irq_contexts;
 };
 
 struct cxl_service_layer_ops {
@@ -722,11 +730,13 @@ ssize_t cxl_pci_afu_read_err_buffer(struct cxl_afu *afu, char *buf,
 /* Internal functions wrapped in cxl_base to allow PHB to call them */
 bool _cxl_pci_associate_default_context(struct pci_dev *dev, struct cxl_afu *afu);
 void _cxl_pci_disable_device(struct pci_dev *dev);
+int _cxl_next_msi_hwirq(struct pci_dev *pdev, struct cxl_context **ctx, int *afu_irq);
 
 struct cxl_calls {
 	void (*cxl_slbia)(struct mm_struct *mm);
 	bool (*cxl_pci_associate_default_context)(struct pci_dev *dev, struct cxl_afu *afu);
 	void (*cxl_pci_disable_device)(struct pci_dev *dev);
+	int (*cxl_next_msi_hwirq)(struct pci_dev *pdev, struct cxl_context **ctx, int *afu_irq);
 
 	struct module *owner;
 };

commit a19bd79e31769626d288cc016e21a31b6f47bf6f
Author: Ian Munsie <imunsie@au1.ibm.com>
Date:   Thu Jul 14 07:17:04 2016 +1000

    cxl: Allow a default context to be associated with an external pci_dev
    
    The cxl kernel API has a concept of a default context associated with
    each PCI device under the virtual PHB. The Mellanox CX4 will also use
    the cxl kernel API, but it does not use a virtual PHB - rather, the AFU
    appears as a physical function as a peer to the networking functions.
    
    In order to allow the kernel API to work with those networking
    functions, we will need to associate a default context with them as
    well. To this end, refactor the corresponding code to do this in vphb.c
    and export it so that it can be called from the PHB code.
    
    Signed-off-by: Ian Munsie <imunsie@au1.ibm.com>
    Reviewed-by: Frederic Barrat <fbarrat@linux.vnet.ibm.com>
    Reviewed-by: Andrew Donnellan <andrew.donnellan@au1.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index d4aae6f855a8..b81f476a2b9f 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -719,9 +719,15 @@ static inline u64 cxl_p2n_read(struct cxl_afu *afu, cxl_p2n_reg_t reg)
 ssize_t cxl_pci_afu_read_err_buffer(struct cxl_afu *afu, char *buf,
 				loff_t off, size_t count);
 
+/* Internal functions wrapped in cxl_base to allow PHB to call them */
+bool _cxl_pci_associate_default_context(struct pci_dev *dev, struct cxl_afu *afu);
+void _cxl_pci_disable_device(struct pci_dev *dev);
 
 struct cxl_calls {
 	void (*cxl_slbia)(struct mm_struct *mm);
+	bool (*cxl_pci_associate_default_context)(struct pci_dev *dev, struct cxl_afu *afu);
+	void (*cxl_pci_disable_device)(struct pci_dev *dev);
+
 	struct module *owner;
 };
 int register_cxl_calls(struct cxl_calls *calls);

commit 62ccf2d2efefa01d0eb92cd6ecbb45ea0499fb1c
Author: Ian Munsie <imunsie@au1.ibm.com>
Date:   Thu Jul 14 07:17:03 2016 +1000

    cxl: Move cxl_afu_get / cxl_afu_put to base
    
    The Mellanox CX4 uses a model where the AFU is one physical function of
    the device, and is used by other peer physical functions of the same
    device. This will require those other devices to grab a reference on the
    AFU when they are initialised to make sure that it does not go away
    during their lifetime.
    
    Move the AFU refcount functions to base.c so they can be called from
    the PHB code.
    
    Signed-off-by: Ian Munsie <imunsie@au1.ibm.com>
    Reviewed-by: Andrew Donnellan <andrew.donnellan@au1.ibm.com>
    Reviewed-by: Frederic Barrat <fbarrat@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index 36b3237fc2b1..d4aae6f855a8 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -440,18 +440,6 @@ struct cxl_afu {
 	bool enabled;
 };
 
-/* AFU refcount management */
-static inline struct cxl_afu *cxl_afu_get(struct cxl_afu *afu)
-{
-
-	return (get_device(&afu->dev) == NULL) ? NULL : afu;
-}
-
-static inline void  cxl_afu_put(struct cxl_afu *afu)
-{
-	put_device(&afu->dev);
-}
-
 
 struct cxl_irq_name {
 	struct list_head list;

commit 6e0c50f9e814220ada60497c522b60a8e1cc1e92
Author: Philippe Bergheaud <felix@linux.vnet.ibm.com>
Date:   Tue Jul 5 13:08:06 2016 +0200

    cxl: Refine slice error debug messages
    
    The PSL Slice Error Register (PSL_SERR_An) reports implementation
    dependent AFU errors, in the form of a bitmap. The PSL_SERR_An
    register content is printed in the form of hex dump debug message.
    
    This patch decodes the PSL_ERR_An register contents, and prints a
    specific error message for each possible error bit. It also dumps
    the secondary registers AFU_ERR_An and PSL_DSISR_An, that may
    contain extra debug information.
    
    This patch also removes the large WARN message that used to report
    the cxl slice error interrupt, and replaces it by a short informative
    message, that draws attention to AFU implementation errors.
    
    Signed-off-by: Philippe Bergheaud <felix@linux.vnet.ibm.com>
    Acked-by: Ian Munsie <imunsie@au1.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index aafffa8554e2..36b3237fc2b1 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -189,6 +189,18 @@ static const cxl_p2n_reg_t CXL_PSL_WED_An     = {0x0A0};
 #define CXL_PSL_ID_An_F	(1ull << (63-31))
 #define CXL_PSL_ID_An_L	(1ull << (63-30))
 
+/****** CXL_PSL_SERR_An ****************************************************/
+#define CXL_PSL_SERR_An_afuto	(1ull << (63-0))
+#define CXL_PSL_SERR_An_afudis	(1ull << (63-1))
+#define CXL_PSL_SERR_An_afuov	(1ull << (63-2))
+#define CXL_PSL_SERR_An_badsrc	(1ull << (63-3))
+#define CXL_PSL_SERR_An_badctx	(1ull << (63-4))
+#define CXL_PSL_SERR_An_llcmdis	(1ull << (63-5))
+#define CXL_PSL_SERR_An_llcmdto	(1ull << (63-6))
+#define CXL_PSL_SERR_An_afupar	(1ull << (63-7))
+#define CXL_PSL_SERR_An_afudup	(1ull << (63-8))
+#define CXL_PSL_SERR_An_AE	(1ull << (63-30))
+
 /****** CXL_PSL_SCNTL_An ****************************************************/
 #define CXL_PSL_SCNTL_An_CR          (0x1ull << (63-15))
 /* Programming Modes: */
@@ -916,4 +928,7 @@ extern const struct cxl_backend_ops *cxl_ops;
 
 /* check if the given pci_dev is on the the cxl vphb bus */
 bool cxl_pci_is_vphb_device(struct pci_dev *dev);
+
+/* decode AFU error bits in the PSL register PSL_SERR_An */
+void cxl_afu_decode_psl_serr(struct cxl_afu *afu, u64 serr);
 #endif

commit 5e7823c9bc44965c2e7d1d755b382109830c4916
Author: Ian Munsie <imunsie@au1.ibm.com>
Date:   Fri Jul 1 02:50:40 2016 +1000

    cxl: Fix bug where AFU disable operation had no effect
    
    The AFU disable operation has a bug where it will not clear the enable
    bit and therefore will have no effect. To date this has likely been
    masked by fact that we perform an AFU reset before the disable, which
    also has the effect of clearing the enable bit, making the following
    disable operation effectively a noop on most hardware. This patch
    modifies the afu_control function to take a parameter to clear from the
    AFU control register so that the disable operation can clear the
    appropriate bit.
    
    This bug was uncovered on the Mellanox CX4, which uses an XSL rather
    than a PSL. On the XSL the reset operation will not complete while the
    AFU is enabled, meaning the enable bit was still set at the start of the
    disable and as a result this bug was hit and the disable also timed out.
    
    Because of this difference in behaviour between the PSL and XSL, this
    patch now makes the reset dependent on the card using a PSL to avoid
    waiting for a timeout on the XSL. It is entirely possible that we may be
    able to drop the reset altogether if it turns out we only ever needed it
    due to this bug - however I am not willing to drop it without further
    regression testing and have added comments to the code explaining the
    background.
    
    This also fixes a small issue where the AFU_Cntl register was read
    outside of the lock that protects it.
    
    Signed-off-by: Ian Munsie <imunsie@au1.ibm.com>
    Reviewed-by: Frederic Barrat <fbarrat@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index 27578fceda8a..aafffa8554e2 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -552,6 +552,7 @@ struct cxl_service_layer_ops {
 	void (*write_timebase_ctrl)(struct cxl *adapter);
 	u64 (*timebase_read)(struct cxl *adapter);
 	int capi_mode;
+	bool needs_reset_before_disable;
 };
 
 struct cxl_native {

commit ad42de859ff14c079e966e61cbcba85265b982e1
Author: Michael Neuling <mikey@neuling.org>
Date:   Fri Jun 24 08:47:07 2016 +0200

    cxl: Add set and get private data to context struct
    
    This provides AFU drivers a means to associate private data with a cxl
    context. This is particularly intended for make the new callbacks for
    driver specific events easier for AFU drivers to use, as they can easily
    get back to any private data structures they may use.
    
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Ian Munsie <imunsie@au1.ibm.com>
    Signed-off-by: Philippe Bergheaud <felix@linux.vnet.ibm.com
    Reviewed-by: Matthew R. Ochs <mrochs@linux.vnet.ibm.com>
    Reviewed-by: Andrew Donnellan <andrew.donnellan@au1.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index 422ee53868a8..27578fceda8a 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -484,6 +484,9 @@ struct cxl_context {
 	/* Only used in PR mode */
 	u64 process_token;
 
+	/* driver private data */
+	void *priv;
+
 	unsigned long *irq_bitmap; /* Accessed from IRQ context */
 	struct cxl_irq_ranges irqs;
 	struct list_head irq_names;

commit b810253bd9342f863a86ec7dfff4a5a7a0394d2f
Author: Philippe Bergheaud <felix@linux.vnet.ibm.com>
Date:   Thu Jun 23 15:03:53 2016 +0200

    cxl: Add mechanism for delivering AFU driver specific events
    
    This adds an afu_driver_ops structure with fetch_event() and
    event_delivered() callbacks. An AFU driver such as cxlflash can fill
    this out and associate it with a context to enable passing custom AFU
    specific events to userspace.
    
    This also adds a new kernel API function cxl_context_pending_events(),
    that the AFU driver can use to notify the cxl driver that new specific
    events are ready to be delivered, and wake up anyone waiting on the
    context wait queue.
    
    The current count of AFU driver specific events is stored in the field
    afu_driver_events of the context structure.
    
    The cxl driver checks the afu_driver_events count during poll, select,
    read, etc. calls to check if an AFU driver specific event is pending,
    and calls fetch_event() to obtain and deliver that event. This way, the
    cxl driver takes care of all the usual locking semantics around these
    calls and handles all the generic cxl events, so that the AFU driver
    only needs to worry about it's own events.
    
    fetch_event() return a struct cxl_event_afu_driver_reserved, allocated
    by the AFU driver, and filled in with the specific event information and
    size. Total event size (header + data) should not be greater than
    CXL_READ_MIN_SIZE (4K).
    
    Th cxl driver prepends an appropriate cxl event header, copies the event
    to userspace, and finally calls event_delivered() to return the status of
    the operation to the AFU driver. The event is identified by the context
    and cxl_event_afu_driver_reserved pointers.
    
    Since AFU drivers provide their own means for userspace to obtain the
    AFU file descriptor (i.e. cxlflash uses an ioctl on their scsi file
    descriptor to obtain the AFU file descriptor) and the generic cxl driver
    will never use this event, the ABI of the event is up to each individual
    AFU driver.
    
    Signed-off-by: Philippe Bergheaud <felix@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index ce2b9d513069..422ee53868a8 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -24,6 +24,7 @@
 #include <asm/reg.h>
 #include <misc/cxl-base.h>
 
+#include <misc/cxl.h>
 #include <uapi/misc/cxl.h>
 
 extern uint cxl_verbose;
@@ -34,7 +35,7 @@ extern uint cxl_verbose;
  * Bump version each time a user API change is made, whether it is
  * backwards compatible ot not.
  */
-#define CXL_API_VERSION 2
+#define CXL_API_VERSION 3
 #define CXL_API_VERSION_COMPATIBLE 1
 
 /*
@@ -528,6 +529,10 @@ struct cxl_context {
 	bool pending_fault;
 	bool pending_afu_err;
 
+	/* Used by AFU drivers for driver specific event delivery */
+	struct cxl_afu_driver_ops *afu_driver_ops;
+	atomic_t afu_driver_events;
+
 	struct rcu_head rcu;
 };
 

commit b385c9e971468eb8816b26742449d6d1e49f55f1
Author: Ian Munsie <imunsie@au1.ibm.com>
Date:   Wed Jun 8 15:09:54 2016 +1000

    cxl: Add support for CAPP DMA mode
    
    This adds support for using CAPP DMA mode, which is required for XSL
    based cards such as the Mellanox CX4 to function.
    
    This is currently an RFC as it depends on the corresponding support to
    be merged into skiboot first, which was submitted here:
    http://patchwork.ozlabs.org/patch/625582/
    
    In the event that the skiboot on the system does not have the above
    support, it will indicate as such in the kernel log and abort the init
    process.
    
    Signed-off-by: Ian Munsie <imunsie@au1.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index 790faebf44dc..ce2b9d513069 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -543,6 +543,7 @@ struct cxl_service_layer_ops {
 	void (*debugfs_stop_trace)(struct cxl *adapter);
 	void (*write_timebase_ctrl)(struct cxl *adapter);
 	u64 (*timebase_read)(struct cxl *adapter);
+	int capi_mode;
 };
 
 struct cxl_native {

commit 6d382616ac2283ed65c7a6a52d05b064488aa8f8
Author: Frederic Barrat <fbarrat@linux.vnet.ibm.com>
Date:   Tue May 24 03:39:18 2016 +1000

    cxl: Abstract the differences between the PSL and XSL
    
    The XSL (Translation Service Layer) is a stripped down version of the
    PSL (Power Service Layer) used in some cards such as the Mellanox CX4.
    
    Like the PSL, it implements the CAIA architecture, but has a number of
    differences, mostly in it's implementation dependent registers. This
    adds an ops structure to abstract these differences to bring initial
    support for XSL CAPI devices.
    
    The XSL does not implement the optional architected SERR register,
    however while it treats it as a reserved register and should work with
    no special treatment, attempting to access it will cause the XSL_FEC
    (First Error Capture) register to be filled out, preventing it from
    capturing any subsequent errors. Therefore, this patch also prevents the
    kernel from trying to set up the SERR register so that the FEC register
    may still be useful, and to save one interrupt.
    
    The XSL also uses a special DMA cxl mode, which uses a slightly
    different init sequence for the CAPP and PHB. The kernel support for
    this will be in a future patch once the corresponding support has been
    merged into skiboot.
    
    Co-authored-by: Ian Munsie <imunsie@au1.ibm.com>
    Signed-off-by: Ian Munsie <imunsie@au1.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index fbec29bd6575..790faebf44dc 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -81,6 +81,7 @@ static const cxl_p1_reg_t CXL_PSL_TLBIA   = {0x00A8};
 static const cxl_p1_reg_t CXL_PSL_AFUSEL  = {0x00B0};
 
 /* 0x00C0:7EFF Implementation dependent area */
+/* PSL registers */
 static const cxl_p1_reg_t CXL_PSL_FIR1      = {0x0100};
 static const cxl_p1_reg_t CXL_PSL_FIR2      = {0x0108};
 static const cxl_p1_reg_t CXL_PSL_Timebase  = {0x0110};
@@ -91,6 +92,11 @@ static const cxl_p1_reg_t CXL_PSL_FIR_CNTL  = {0x0148};
 static const cxl_p1_reg_t CXL_PSL_DSNDCTL   = {0x0150};
 static const cxl_p1_reg_t CXL_PSL_SNWRALLOC = {0x0158};
 static const cxl_p1_reg_t CXL_PSL_TRACE     = {0x0170};
+/* XSL registers (Mellanox CX4) */
+static const cxl_p1_reg_t CXL_XSL_Timebase  = {0x0100};
+static const cxl_p1_reg_t CXL_XSL_TB_CTLSTAT = {0x0108};
+static const cxl_p1_reg_t CXL_XSL_FEC       = {0x0158};
+static const cxl_p1_reg_t CXL_XSL_DSNCTL    = {0x0168};
 /* 0x7F00:7FFF Reserved PCIe MSI-X Pending Bit Array area */
 /* 0x8000:FFFF Reserved PCIe MSI-X Table Area */
 
@@ -525,6 +531,20 @@ struct cxl_context {
 	struct rcu_head rcu;
 };
 
+struct cxl_service_layer_ops {
+	int (*adapter_regs_init)(struct cxl *adapter, struct pci_dev *dev);
+	int (*afu_regs_init)(struct cxl_afu *afu);
+	int (*register_serr_irq)(struct cxl_afu *afu);
+	void (*release_serr_irq)(struct cxl_afu *afu);
+	void (*debugfs_add_adapter_sl_regs)(struct cxl *adapter, struct dentry *dir);
+	void (*debugfs_add_afu_sl_regs)(struct cxl_afu *afu, struct dentry *dir);
+	void (*psl_irq_dump_registers)(struct cxl_context *ctx);
+	void (*err_irq_dump_registers)(struct cxl *adapter);
+	void (*debugfs_stop_trace)(struct cxl *adapter);
+	void (*write_timebase_ctrl)(struct cxl *adapter);
+	u64 (*timebase_read)(struct cxl *adapter);
+};
+
 struct cxl_native {
 	u64 afu_desc_off;
 	u64 afu_desc_size;
@@ -533,6 +553,7 @@ struct cxl_native {
 	irq_hw_number_t err_hwirq;
 	unsigned int err_virq;
 	u64 ps_off;
+	const struct cxl_service_layer_ops *sl_ops;
 };
 
 struct cxl_guest {
@@ -805,6 +826,11 @@ int cxl_tlb_slb_invalidate(struct cxl *adapter);
 int cxl_afu_disable(struct cxl_afu *afu);
 int cxl_psl_purge(struct cxl_afu *afu);
 
+void cxl_debugfs_add_adapter_psl_regs(struct cxl *adapter, struct dentry *dir);
+void cxl_debugfs_add_adapter_xsl_regs(struct cxl *adapter, struct dentry *dir);
+void cxl_debugfs_add_afu_psl_regs(struct cxl_afu *afu, struct dentry *dir);
+void cxl_native_psl_irq_dump_regs(struct cxl_context *ctx);
+void cxl_native_err_irq_dump_regs(struct cxl *adapter);
 void cxl_stop_trace(struct cxl *cxl);
 int cxl_pci_vphb_add(struct cxl_afu *afu);
 void cxl_pci_vphb_remove(struct cxl_afu *afu);

commit 292841b09648ce7aee5df16ab72581f3b6c2bd7a
Author: Ian Munsie <imunsie@au1.ibm.com>
Date:   Tue May 24 02:14:05 2016 +1000

    cxl: Update process element after allocating interrupts
    
    In the kernel API, it is possible to attempt to allocate AFU interrupts
    after already starting a context. Since the process element structure
    used by the hardware is only filled out at the time the context is
    started, it will not be updated with the interrupt numbers that have
    just been allocated and therefore AFU interrupts will not work unless
    they were allocated prior to starting the context.
    
    This can present some difficulties as each CAPI enabled PCI device in
    the kernel API has a default context, which may need to be started very
    early to enable translations, potentially before interrupts can easily
    be set up.
    
    This patch makes the API more flexible to allow interrupts to be
    allocated after a context has already been started and takes care of
    updating the PE structure used by the hardware and notifying it to
    discard any cached copy it may have.
    
    The update is currently performed via a terminate/remove/add sequence.
    This is necessary on some hardware such as the XSL that does not
    properly support the update LLCMD.
    
    Note that this is only supported on powernv at present - attempting to
    perform this ordering on PowerVM will raise a warning.
    
    Signed-off-by: Ian Munsie <imunsie@au1.ibm.com>
    Reviewed-by: Frederic Barrat <fbarrat@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index 4fe50788ff45..fbec29bd6575 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -855,6 +855,7 @@ struct cxl_backend_ops {
 	int (*attach_process)(struct cxl_context *ctx, bool kernel,
 			u64 wed, u64 amr);
 	int (*detach_process)(struct cxl_context *ctx);
+	void (*update_ivtes)(struct cxl_context *ctx);
 	bool (*support_attributes)(const char *attr_name, enum cxl_attrs type);
 	bool (*link_ok)(struct cxl *cxl, struct cxl_afu *afu);
 	void (*release_afu)(struct device *dev);

commit c04a5880299eab3da8c10547db96ea9cdffd44a6
Merge: a1c28b75a958 138a076496e6
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri May 20 10:12:41 2016 -0700

    Merge tag 'powerpc-4.7-1' of git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux
    
    Pull powerpc updates from Michael Ellerman:
     "Highlights:
       - Support for Power ISA 3.0 (Power9) Radix Tree MMU from Aneesh Kumar K.V
       - Live patching support for ppc64le (also merged via livepatching.git)
    
      Various cleanups & minor fixes from:
       - Aaro Koskinen, Alexey Kardashevskiy, Andrew Donnellan, Aneesh Kumar K.V,
         Chris Smart, Daniel Axtens, Frederic Barrat, Gavin Shan, Ian Munsie,
         Lennart Sorensen, Madhavan Srinivasan, Mahesh Salgaonkar, Markus Elfring,
         Michael Ellerman, Oliver O'Halloran, Paul Gortmaker, Paul Mackerras,
         Rashmica Gupta, Russell Currey, Suraj Jitindar Singh, Thiago Jung
         Bauermann, Valentin Rothberg, Vipin K Parashar.
    
      General:
       - Update LMB associativity index during DLPAR add/remove from Nathan
         Fontenot
       - Fix branching to OOL handlers in relocatable kernel from Hari Bathini
       - Add support for userspace Power9 copy/paste from Chris Smart
       - Always use STRICT_MM_TYPECHECKS from Michael Ellerman
       - Add mask of possible MMU features from Michael Ellerman
    
      PCI:
       - Enable pass through of NVLink to guests from Alexey Kardashevskiy
       - Cleanups in preparation for powernv PCI hotplug from Gavin Shan
       - Don't report error in eeh_pe_reset_and_recover() from Gavin Shan
       - Restore initial state in eeh_pe_reset_and_recover() from Gavin Shan
       - Revert "powerpc/eeh: Fix crash in eeh_add_device_early() on Cell"
         from Guilherme G Piccoli
       - Remove the dependency on EEH struct in DDW mechanism from Guilherme
         G Piccoli
    
      selftests:
       - Test cp_abort during context switch from Chris Smart
       - Add several tests for transactional memory support from Rashmica
         Gupta
    
      perf:
       - Add support for sampling interrupt register state from Anju T
       - Add support for unwinding perf-stackdump from Chandan Kumar
    
      cxl:
       - Configure the PSL for two CAPI ports on POWER8NVL from Philippe
         Bergheaud
       - Allow initialization on timebase sync failures from Frederic Barrat
       - Increase timeout for detection of AFU mmio hang from Frederic
         Barrat
       - Handle num_of_processes larger than can fit in the SPA from Ian
         Munsie
       - Ensure PSL interrupt is configured for contexts with no AFU IRQs
         from Ian Munsie
       - Add kernel API to allow a context to operate with relocate disabled
         from Ian Munsie
       - Check periodically the coherent platform function's state from
         Christophe Lombard
    
      Freescale:
       - Updates from Scott: "Contains 86xx fixes, minor device tree fixes,
         an erratum workaround, and a kconfig dependency fix."
    
    * tag 'powerpc-4.7-1' of git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux: (192 commits)
      powerpc/86xx: Fix PCI interrupt map definition
      powerpc/86xx: Move pci1 definition to the include file
      powerpc/fsl: Fix build of the dtb embedded kernel images
      powerpc/fsl: Fix rcpm compatible string
      powerpc/fsl: Remove FSL_SOC dependency from FSL_LBC
      powerpc/fsl-pci: Add a workaround for PCI 5 errata
      powerpc/fsl: Fix SPI compatible on t208xrdb and t1040rdb
      powerpc/powernv/npu: Add PE to PHB's list
      powerpc/powernv: Fix insufficient memory allocation
      powerpc/iommu: Remove the dependency on EEH struct in DDW mechanism
      Revert "powerpc/eeh: Fix crash in eeh_add_device_early() on Cell"
      powerpc/eeh: Drop unnecessary label in eeh_pe_change_owner()
      powerpc/eeh: Ignore handlers in eeh_pe_reset_and_recover()
      powerpc/eeh: Restore initial state in eeh_pe_reset_and_recover()
      powerpc/eeh: Don't report error in eeh_pe_reset_and_recover()
      Revert "powerpc/powernv: Exclude root bus in pnv_pci_reset_secondary_bus()"
      powerpc/powernv/npu: Enable NVLink pass through
      powerpc/powernv/npu: Rework TCE Kill handling
      powerpc/powernv/npu: Add set/unset window helpers
      powerpc/powernv/ioda2: Export debug helper pe_level_printk()
      ...

commit 266eab8f32cc43b688c2e9aaab63c2565a3998c2
Author: Christophe Lombard <clombard@linux.vnet.ibm.com>
Date:   Fri Apr 22 15:39:22 2016 +0200

    cxl: Check periodically the coherent platform function's state
    
    In the PowerVM environment, the PHYP CoherentAccel component manages
    the state of the Coherent Accelerator Processor Interface adapter and
    virtualizes CAPI resources, handles CAPP, PSL, PSL Slice errors - and
    interrupts - and provides a new set of hcalls for the OS APIs to utilize
    Accelerator Function Unit (AFU).
    
    During the course of operation, a coherent platform function can
    encounter errors. Some possible reason for errors are:
    • Hardware recoverable and unrecoverable errors
    • Transient and over-threshold correctable errors
    
    PHYP implements its own state model for the coherent platform function.
    The state of the AFU is available through a hcall.
    
    The current implementation of the cxl driver, for the PowerVM
    environment, checks this state of the AFU only when an action is
    requested - open a device, ioctl command, memory map, attach/detach a
    process - from an external driver - cxlflash, libcxl. If an error is
    detected the cxl driver handles the error according the content of the
    Power Architecture Platform Requirements document.
    
    But in case of low-level troubles (or error injection), the PHYP
    component may reset the card and change the AFU state. The PHYP
    interface doesn't provide any way to be notified when that happens thus
    implies that the cxl driver:
    • cannot handle immediatly the state change of the AFU.
    • cannot notify other drivers (cxlflash, ...)
    
    The purpose of this patch is to wake up the cpu periodically to check
    the current state of each AFU and to see if we need to enter an error
    recovery path.
    
    Signed-off-by: Christophe Lombard <clombard@linux.vnet.ibm.com>
    Acked-by: Ian Munsie <imunsie@au1.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index 9dd3a0e7917f..d23a3a59a712 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -366,11 +366,13 @@ struct cxl_afu_native {
 };
 
 struct cxl_afu_guest {
+	struct cxl_afu *parent;
 	u64 handle;
 	phys_addr_t p2n_phys;
 	u64 p2n_size;
 	int max_ints;
-	struct mutex recovery_lock;
+	bool handle_err;
+	struct delayed_work work_err;
 	int previous_state;
 };
 

commit 7a0d85d313c2066712e530e668bc02bb741a685c
Author: Ian Munsie <imunsie@au1.ibm.com>
Date:   Fri May 6 17:46:36 2016 +1000

    cxl: Add kernel API to allow a context to operate with relocate disabled
    
    cxl devices typically access memory using an MMU in much the same way as
    the CPU, and each context includes a state register much like the MSR in
    the CPU. Like the CPU, the state register includes a bit to enable
    relocation, which we currently always enable.
    
    In some cases, it may be desirable to allow a device to access memory
    using real addresses instead of effective addresses, so this adds a new
    API, cxl_set_translation_mode, that can be used to disable relocation
    on a given kernel context. This can allow for the creation of a special
    privileged context that the device can use if it needs relocation
    disabled, and can use regular contexts at times when it needs relocation
    enabled.
    
    This interface is only available to users of the kernel API for obvious
    reasons, and will never be supported in a virtualised environment.
    
    This will be used by the upcoming cxl support in the mlx5 driver.
    
    Signed-off-by: Ian Munsie <imunsie@au1.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index 2823fb32fcf6..9dd3a0e7917f 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -514,6 +514,7 @@ struct cxl_context {
 	bool pe_inserted;
 	bool master;
 	bool kernel;
+	bool real_mode;
 	bool pending_irq;
 	bool pending_fault;
 	bool pending_afu_err;

commit 0e5b5ba17ac33a05d9f4a48b5eb8b5e30f2274d7
Author: Ian Munsie <imunsie@au1.ibm.com>
Date:   Wed May 4 14:48:32 2016 +1000

    cxl: Remove duplicate #defines
    
    These defines are not used, but other equivalent definitions
    (CXL_SPA_SW_CMD_*) are used. Remove the unused defines.
    
    Signed-off-by: Ian Munsie <imunsie@au1.ibm.com>
    Reviewed-by: Andrew Donnellan <andrew.donnellan@au1.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index dfdbfb025089..2823fb32fcf6 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -178,15 +178,6 @@ static const cxl_p2n_reg_t CXL_PSL_WED_An     = {0x0A0};
 #define CXL_PSL_SR_An_MP  (1ull << (63-62)) /* Master Process */
 #define CXL_PSL_SR_An_LE  (1ull << (63-63)) /* Little Endian */
 
-/****** CXL_PSL_LLCMD_An ****************************************************/
-#define CXL_LLCMD_TERMINATE   0x0001000000000000ULL
-#define CXL_LLCMD_REMOVE      0x0002000000000000ULL
-#define CXL_LLCMD_SUSPEND     0x0003000000000000ULL
-#define CXL_LLCMD_RESUME      0x0004000000000000ULL
-#define CXL_LLCMD_ADD         0x0005000000000000ULL
-#define CXL_LLCMD_UPDATE      0x0006000000000000ULL
-#define CXL_LLCMD_HANDLE_MASK 0x000000000000ffffULL
-
 /****** CXL_PSL_ID_An ****************************************************/
 #define CXL_PSL_ID_An_F	(1ull << (63-31))
 #define CXL_PSL_ID_An_L	(1ull << (63-30))

commit 2bc79ffcbb817873cc43d63118008ab75181b73d
Author: Michael Neuling <mikey@neuling.org>
Date:   Fri Apr 22 14:57:49 2016 +1000

    cxl: Poll for outstanding IRQs when detaching a context
    
    When detaching contexts, we may still have interrupts in the system
    which are yet to be delivered to any CPU and be acked in the PSL.
    This can result in a subsequent unrelated process getting an spurious
    IRQ or an interrupt for a non-existent context.
    
    This polls the PSL to ensure that the PSL is clear of IRQs for the
    detached context, before removing the context from the idr.
    
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Tested-by: Andrew Donnellan <andrew.donnellan@au1.ibm.com>
    Acked-by: Ian Munsie <imunsie@au1.ibm.com>
    Tested-by: Vaibhav Jain <vaibhav@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index 38e21cf7806e..73dc2a33da74 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -274,6 +274,7 @@ static const cxl_p2n_reg_t CXL_PSL_WED_An     = {0x0A0};
 #define CXL_PSL_DSISR_An_PE (1ull << (63-4))  /* PSL Error (implementation specific) */
 #define CXL_PSL_DSISR_An_AE (1ull << (63-5))  /* AFU Error */
 #define CXL_PSL_DSISR_An_OC (1ull << (63-6))  /* OS Context Warning */
+#define CXL_PSL_DSISR_PENDING (CXL_PSL_DSISR_TRANS | CXL_PSL_DSISR_An_PE | CXL_PSL_DSISR_An_AE | CXL_PSL_DSISR_An_OC)
 /* NOTE: Bits 32:63 are undefined if DSISR[DS] = 1 */
 #define CXL_PSL_DSISR_An_M  DSISR_NOHPTE      /* PTE not found */
 #define CXL_PSL_DSISR_An_P  DSISR_PROTFAULT   /* Storage protection violation */
@@ -855,6 +856,7 @@ struct cxl_backend_ops {
 					u64 dsisr, u64 errstat);
 	irqreturn_t (*psl_interrupt)(int irq, void *data);
 	int (*ack_irq)(struct cxl_context *ctx, u64 tfc, u64 psl_reset_mask);
+	void (*irq_wait)(struct cxl_context *ctx);
 	int (*attach_process)(struct cxl_context *ctx, bool kernel,
 			u64 wed, u64 amr);
 	int (*detach_process)(struct cxl_context *ctx);

commit e009a7e858fed215cb4eed5174a31cadd42d8797
Author: Frederic Barrat <fbarrat@linux.vnet.ibm.com>
Date:   Mon Mar 21 14:32:48 2016 -0500

    cxl: Allow initialization on timebase sync failures
    
    Failure to synchronize the PSL timebase currently prevents the
    initialization of the cxl card, thus rendering the card useless. This
    is too extreme for a feature which is rarely used, if at all. No
    hardware AFUs or software is currently using PSL timebase.
    
    This patch still tries to synchronize the PSL timebase when the card
    is initialized, but ignores the error if it can't. Instead, it reports
    a status via /sys.
    
    Signed-off-by: Frederic Barrat <fbarrat@linux.vnet.ibm.com>
    Acked-by: Ian Munsie <imunsie@au1.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index 38e21cf7806e..dfdbfb025089 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -579,6 +579,7 @@ struct cxl {
 	bool perst_loads_image;
 	bool perst_select_user;
 	bool perst_same_image;
+	bool psl_timebase_synced;
 };
 
 int cxl_pci_alloc_one_irq(struct cxl *adapter);

commit 17eb3eef19f2c0541a7f04ad37c4a7fec89f0822
Author: Vaibhav Jain <vaibhav@linux.vnet.ibm.com>
Date:   Mon Feb 29 11:10:53 2016 +0530

    cxl: Ignore probes for virtual afu pci devices
    
    Add a check at the beginning of cxl_probe function to ignore virtual pci
    devices created for each afu registered. This fixes the the errors
    messages logged about missing CXL vsec, when cxl probe is unable to
    find necessary vsec entries in device pci config space. The error
    message logged are of the form :
    
    cxl-pci 0004:00:00.0: ABORTING: CXL VSEC not found!
    cxl-pci 0004:00:00.0: cxl_init_adapter failed: -19
    
    Cc: Ian Munsie <imunsie@au1.ibm.com>
    Cc: Frederic Barrat <fbarrat@linux.vnet.ibm.com>
    Signed-off-by: Vaibhav Jain <vaibhav@linux.vnet.ibm.com>
    Reviewed-by: fbarrat@linux.vnet.ibm.com
    Reviewed-by: Andrew Donnellan <andrew.donnellan@au1.ibm.com>
    Acked-by: Ian Munsie <imunsie@au1.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index e345860c25eb..38e21cf7806e 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -880,4 +880,6 @@ extern const struct cxl_backend_ops cxl_native_ops;
 extern const struct cxl_backend_ops cxl_guest_ops;
 extern const struct cxl_backend_ops *cxl_ops;
 
+/* check if the given pci_dev is on the the cxl vphb bus */
+bool cxl_pci_is_vphb_device(struct pci_dev *dev);
 #endif

commit 0d400f77c19e8d2606f8194846bcf18ebdc9df2a
Author: Christophe Lombard <clombard@linux.vnet.ibm.com>
Date:   Fri Mar 4 12:26:41 2016 +0100

    cxl: Adapter failure handling
    
    Check the AFU state whenever an API is called. The hypervisor may
    issue a reset of the adapter when it detects a fault. When it happens,
    it launches an error recovery which will either move the AFU to a
    permanent failure state, or in the disabled state.
    If the AFU is found to be disabled, detach all existing contexts from
    it before issuing a AFU reset to re-enable it.
    
    Before detaching contexts, notify any kernel driver through the EEH
    callbacks of the AFU pci device.
    
    Co-authored-by: Frederic Barrat <fbarrat@linux.vnet.ibm.com>
    Signed-off-by: Frederic Barrat <fbarrat@linux.vnet.ibm.com>
    Signed-off-by: Christophe Lombard <clombard@linux.vnet.ibm.com>
    Reviewed-by: Manoj Kumar <manoj@linux.vnet.ibm.com>
    Acked-by: Ian Munsie <imunsie@au1.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index b388c971810f..e345860c25eb 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -379,6 +379,8 @@ struct cxl_afu_guest {
 	phys_addr_t p2n_phys;
 	u64 p2n_size;
 	int max_ints;
+	struct mutex recovery_lock;
+	int previous_state;
 };
 
 struct cxl_afu {
@@ -617,7 +619,7 @@ struct cxl_process_element {
 	__be32 software_state;
 } __packed;
 
-static inline bool cxl_adapter_link_ok(struct cxl *cxl)
+static inline bool cxl_adapter_link_ok(struct cxl *cxl, struct cxl_afu *afu)
 {
 	struct pci_dev *pdev;
 
@@ -636,13 +638,13 @@ static inline void __iomem *_cxl_p1_addr(struct cxl *cxl, cxl_p1_reg_t reg)
 
 static inline void cxl_p1_write(struct cxl *cxl, cxl_p1_reg_t reg, u64 val)
 {
-	if (likely(cxl_adapter_link_ok(cxl)))
+	if (likely(cxl_adapter_link_ok(cxl, NULL)))
 		out_be64(_cxl_p1_addr(cxl, reg), val);
 }
 
 static inline u64 cxl_p1_read(struct cxl *cxl, cxl_p1_reg_t reg)
 {
-	if (likely(cxl_adapter_link_ok(cxl)))
+	if (likely(cxl_adapter_link_ok(cxl, NULL)))
 		return in_be64(_cxl_p1_addr(cxl, reg));
 	else
 		return ~0ULL;
@@ -656,13 +658,13 @@ static inline void __iomem *_cxl_p1n_addr(struct cxl_afu *afu, cxl_p1n_reg_t reg
 
 static inline void cxl_p1n_write(struct cxl_afu *afu, cxl_p1n_reg_t reg, u64 val)
 {
-	if (likely(cxl_adapter_link_ok(afu->adapter)))
+	if (likely(cxl_adapter_link_ok(afu->adapter, afu)))
 		out_be64(_cxl_p1n_addr(afu, reg), val);
 }
 
 static inline u64 cxl_p1n_read(struct cxl_afu *afu, cxl_p1n_reg_t reg)
 {
-	if (likely(cxl_adapter_link_ok(afu->adapter)))
+	if (likely(cxl_adapter_link_ok(afu->adapter, afu)))
 		return in_be64(_cxl_p1n_addr(afu, reg));
 	else
 		return ~0ULL;
@@ -675,13 +677,13 @@ static inline void __iomem *_cxl_p2n_addr(struct cxl_afu *afu, cxl_p2n_reg_t reg
 
 static inline void cxl_p2n_write(struct cxl_afu *afu, cxl_p2n_reg_t reg, u64 val)
 {
-	if (likely(cxl_adapter_link_ok(afu->adapter)))
+	if (likely(cxl_adapter_link_ok(afu->adapter, afu)))
 		out_be64(_cxl_p2n_addr(afu, reg), val);
 }
 
 static inline u64 cxl_p2n_read(struct cxl_afu *afu, cxl_p2n_reg_t reg)
 {
-	if (likely(cxl_adapter_link_ok(afu->adapter)))
+	if (likely(cxl_adapter_link_ok(afu->adapter, afu)))
 		return in_be64(_cxl_p2n_addr(afu, reg));
 	else
 		return ~0ULL;
@@ -857,7 +859,7 @@ struct cxl_backend_ops {
 			u64 wed, u64 amr);
 	int (*detach_process)(struct cxl_context *ctx);
 	bool (*support_attributes)(const char *attr_name, enum cxl_attrs type);
-	bool (*link_ok)(struct cxl *cxl);
+	bool (*link_ok)(struct cxl *cxl, struct cxl_afu *afu);
 	void (*release_afu)(struct device *dev);
 	ssize_t (*afu_read_err_buffer)(struct cxl_afu *afu, char *buf,
 				loff_t off, size_t count);

commit d601ea918b878582e60b773f2f943d8d292b2abf
Author: Frederic Barrat <fbarrat@linux.vnet.ibm.com>
Date:   Fri Mar 4 12:26:40 2016 +0100

    cxl: Support the cxl kernel API from a guest
    
    Like on bare-metal, the cxl driver creates a virtual PHB and a pci
    device for the AFU. The configuration space of the device is mapped to
    the configuration record of the AFU.
    
    Reuse the code defined in afu_cr_read8|16|32() when reading the
    configuration space of the AFU device.
    
    Even though the (virtual) AFU device is a pci device, the adapter is
    not. So a driver using the cxl kernel API cannot read the VPD of the
    adapter through the usual PCI interface. Therefore, we add a call to
    the cxl kernel API:
    ssize_t cxl_read_adapter_vpd(struct pci_dev *dev, void *buf, size_t count);
    
    Co-authored-by: Christophe Lombard <clombard@linux.vnet.ibm.com>
    Signed-off-by: Frederic Barrat <fbarrat@linux.vnet.ibm.com>
    Signed-off-by: Christophe Lombard <clombard@linux.vnet.ibm.com>
    Reviewed-by: Manoj Kumar <manoj@linux.vnet.ibm.com>
    Acked-by: Ian Munsie <imunsie@au1.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index 24bd4cab02c2..b388c971810f 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -587,6 +587,7 @@ int cxl_pci_setup_irq(struct cxl *adapter, unsigned int hwirq, unsigned int virq
 int cxl_update_image_control(struct cxl *adapter);
 int cxl_pci_reset(struct cxl *adapter);
 void cxl_pci_release_afu(struct device *dev);
+ssize_t cxl_pci_read_adapter_vpd(struct cxl *adapter, void *buf, size_t len);
 
 /* common == phyp + powernv */
 struct cxl_process_element_common {
@@ -808,7 +809,6 @@ int cxl_psl_purge(struct cxl_afu *afu);
 
 void cxl_stop_trace(struct cxl *cxl);
 int cxl_pci_vphb_add(struct cxl_afu *afu);
-void cxl_pci_vphb_reconfigure(struct cxl_afu *afu);
 void cxl_pci_vphb_remove(struct cxl_afu *afu);
 
 extern struct pci_driver cxl_pci_driver;
@@ -869,6 +869,10 @@ struct cxl_backend_ops {
 	int (*afu_cr_read16)(struct cxl_afu *afu, int cr_idx, u64 offset, u16 *val);
 	int (*afu_cr_read32)(struct cxl_afu *afu, int cr_idx, u64 offset, u32 *val);
 	int (*afu_cr_read64)(struct cxl_afu *afu, int cr_idx, u64 offset, u64 *val);
+	int (*afu_cr_write8)(struct cxl_afu *afu, int cr_idx, u64 offset, u8 val);
+	int (*afu_cr_write16)(struct cxl_afu *afu, int cr_idx, u64 offset, u16 val);
+	int (*afu_cr_write32)(struct cxl_afu *afu, int cr_idx, u64 offset, u32 val);
+	ssize_t (*read_adapter_vpd)(struct cxl *adapter, void *buf, size_t count);
 };
 extern const struct cxl_backend_ops cxl_native_ops;
 extern const struct cxl_backend_ops cxl_guest_ops;

commit 594ff7d067ca42676e27e2a7b5dcc0ff039d08ca
Author: Christophe Lombard <clombard@linux.vnet.ibm.com>
Date:   Fri Mar 4 12:26:38 2016 +0100

    cxl: Support to flash a new image on the adapter from a guest
    
    The new flash.c file contains the logic to flash a new image on the
    adapter, through a hcall. It is an iterative process, with chunks of
    data of 1M at a time. There are also 2 phases: write and verify. The
    flash operation itself is driven from a user-land tool.
    Once flashing is successful, an rtas call is made to update the device
    tree with the new properties values for the adapter and the AFU(s)
    
    Add a new char device for the adapter, so that the flash tool can
    access the card, even if there is no valid AFU on it.
    
    Co-authored-by: Frederic Barrat <fbarrat@linux.vnet.ibm.com>
    Signed-off-by: Frederic Barrat <fbarrat@linux.vnet.ibm.com>
    Signed-off-by: Christophe Lombard <clombard@linux.vnet.ibm.com>
    Reviewed-by: Manoj Kumar <manoj@linux.vnet.ibm.com>
    Acked-by: Ian Munsie <imunsie@au1.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index a7e75f1cc903..24bd4cab02c2 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -324,6 +324,10 @@ static const cxl_p2n_reg_t CXL_PSL_WED_An     = {0x0A0};
 #define CXL_MODE_TIME_SLICED 0x4
 #define CXL_SUPPORTED_MODES (CXL_MODE_DEDICATED | CXL_MODE_DIRECTED)
 
+#define CXL_DEV_MINORS 13   /* 1 control + 4 AFUs * 3 (dedicated/master/shared) */
+#define CXL_CARD_MINOR(adapter) (adapter->adapter_num * CXL_DEV_MINORS)
+#define CXL_DEVT_ADAPTER(dev) (MINOR(dev) / CXL_DEV_MINORS)
+
 enum cxl_context_status {
 	CLOSED,
 	OPENED,
@@ -692,12 +696,14 @@ struct cxl_calls {
 };
 int register_cxl_calls(struct cxl_calls *calls);
 void unregister_cxl_calls(struct cxl_calls *calls);
+int cxl_update_properties(struct device_node *dn, struct property *new_prop);
 
 void cxl_remove_adapter_nr(struct cxl *adapter);
 
 int cxl_alloc_spa(struct cxl_afu *afu);
 void cxl_release_spa(struct cxl_afu *afu);
 
+dev_t cxl_get_dev(void);
 int cxl_file_init(void);
 void cxl_file_exit(void);
 int cxl_register_adapter(struct cxl *adapter);

commit 4752876c71701b7663a5ded789058ab2c05f7d0f
Author: Christophe Lombard <clombard@linux.vnet.ibm.com>
Date:   Fri Mar 4 12:26:37 2016 +0100

    cxl: sysfs support for guests
    
    Filter out a few adapter parameters which don't make sense in a guest.
    Document the changes.
    
    Co-authored-by: Frederic Barrat <fbarrat@linux.vnet.ibm.com>
    Signed-off-by: Frederic Barrat <fbarrat@linux.vnet.ibm.com>
    Signed-off-by: Christophe Lombard <clombard@linux.vnet.ibm.com>
    Reviewed-by: Manoj Kumar <manoj@linux.vnet.ibm.com>
    Acked-by: Ian Munsie <imunsie@au1.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index 4372a87ff3aa..a7e75f1cc903 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -336,6 +336,12 @@ enum prefault_modes {
 	CXL_PREFAULT_ALL,
 };
 
+enum cxl_attrs {
+	CXL_ADAPTER_ATTRS,
+	CXL_AFU_MASTER_ATTRS,
+	CXL_AFU_ATTRS,
+};
+
 struct cxl_sste {
 	__be64 esid_data;
 	__be64 vsid_data;
@@ -844,6 +850,7 @@ struct cxl_backend_ops {
 	int (*attach_process)(struct cxl_context *ctx, bool kernel,
 			u64 wed, u64 amr);
 	int (*detach_process)(struct cxl_context *ctx);
+	bool (*support_attributes)(const char *attr_name, enum cxl_attrs type);
 	bool (*link_ok)(struct cxl *cxl);
 	void (*release_afu)(struct device *dev);
 	ssize_t (*afu_read_err_buffer)(struct cxl_afu *afu, char *buf,

commit 14baf4d9c739e6e69150512d2eb23c71fffcc192
Author: Christophe Lombard <clombard@linux.vnet.ibm.com>
Date:   Fri Mar 4 12:26:36 2016 +0100

    cxl: Add guest-specific code
    
    The new of.c file contains code to parse the device tree to find out
    about cxl adapters and AFUs.
    
    guest.c implements the guest-specific callbacks for the backend API.
    
    The process element ID is not known until the context is attached, so
    we have to separate the context ID assigned by the cxl driver from the
    process element ID visible to the user applications. In bare-metal,
    the 2 IDs match.
    
    Co-authored-by: Frederic Barrat <fbarrat@linux.vnet.ibm.com>
    Signed-off-by: Frederic Barrat <fbarrat@linux.vnet.ibm.com>
    Signed-off-by: Christophe Lombard <clombard@linux.vnet.ibm.com>
    Reviewed-by: Manoj Kumar <manoj@linux.vnet.ibm.com>
    Acked-by: Ian Munsie <imunsie@au1.ibm.com>
    [mpe: Fix SMP=n build, fix PSERIES=n build, minor whitespace fixes]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index 3a1fabd41072..4372a87ff3aa 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -433,6 +433,12 @@ struct cxl_irq_name {
 	char *name;
 };
 
+struct irq_avail {
+	irq_hw_number_t offset;
+	irq_hw_number_t range;
+	unsigned long   *bitmap;
+};
+
 /*
  * This is a cxl context.  If the PSL is in dedicated mode, there will be one
  * of these per AFU.  If in AFU directed there can be lots of these.
@@ -488,7 +494,19 @@ struct cxl_context {
 
 	struct cxl_process_element *elem;
 
-	int pe; /* process element handle */
+	/*
+	 * pe is the process element handle, assigned by this driver when the
+	 * context is initialized.
+	 *
+	 * external_pe is the PE shown outside of cxl.
+	 * On bare-metal, pe=external_pe, because we decide what the handle is.
+	 * In a guest, we only find out about the pe used by pHyp when the
+	 * context is attached, and that's the value we want to report outside
+	 * of cxl.
+	 */
+	int pe;
+	int external_pe;
+
 	u32 irq_count;
 	bool pe_inserted;
 	bool master;
@@ -782,6 +800,7 @@ void cxl_pci_vphb_reconfigure(struct cxl_afu *afu);
 void cxl_pci_vphb_remove(struct cxl_afu *afu);
 
 extern struct pci_driver cxl_pci_driver;
+extern struct platform_driver cxl_of_driver;
 int afu_allocate_irqs(struct cxl_context *ctx, u32 count);
 
 int afu_open(struct inode *inode, struct file *file);
@@ -792,6 +811,21 @@ unsigned int afu_poll(struct file *file, struct poll_table_struct *poll);
 ssize_t afu_read(struct file *file, char __user *buf, size_t count, loff_t *off);
 extern const struct file_operations afu_fops;
 
+struct cxl *cxl_guest_init_adapter(struct device_node *np, struct platform_device *dev);
+void cxl_guest_remove_adapter(struct cxl *adapter);
+int cxl_of_read_adapter_handle(struct cxl *adapter, struct device_node *np);
+int cxl_of_read_adapter_properties(struct cxl *adapter, struct device_node *np);
+ssize_t cxl_guest_read_adapter_vpd(struct cxl *adapter, void *buf, size_t len);
+ssize_t cxl_guest_read_afu_vpd(struct cxl_afu *afu, void *buf, size_t len);
+int cxl_guest_init_afu(struct cxl *adapter, int slice, struct device_node *afu_np);
+void cxl_guest_remove_afu(struct cxl_afu *afu);
+int cxl_of_read_afu_handle(struct cxl_afu *afu, struct device_node *afu_np);
+int cxl_of_read_afu_properties(struct cxl_afu *afu, struct device_node *afu_np);
+int cxl_guest_add_chardev(struct cxl *adapter);
+void cxl_guest_remove_chardev(struct cxl *adapter);
+void cxl_guest_reload_module(struct cxl *adapter);
+int cxl_of_probe(struct platform_device *pdev);
+
 struct cxl_backend_ops {
 	struct module *module;
 	int (*adapter_reset)(struct cxl *adapter);
@@ -824,6 +858,7 @@ struct cxl_backend_ops {
 	int (*afu_cr_read64)(struct cxl_afu *afu, int cr_idx, u64 offset, u64 *val);
 };
 extern const struct cxl_backend_ops cxl_native_ops;
+extern const struct cxl_backend_ops cxl_guest_ops;
 extern const struct cxl_backend_ops *cxl_ops;
 
 #endif

commit cbffa3a5146a90f46806cef3a98b8be5833727e8
Author: Christophe Lombard <clombard@linux.vnet.ibm.com>
Date:   Fri Mar 4 12:26:35 2016 +0100

    cxl: Separate bare-metal fields in adapter and AFU data structures
    
    Introduce sub-structures containing the bare-metal specific fields in
    the structures describing the adapter (struct cxl) and AFU (struct
    cxl_afu).
    Update all their references.
    
    Co-authored-by: Frederic Barrat <fbarrat@linux.vnet.ibm.com>
    Signed-off-by: Frederic Barrat <fbarrat@linux.vnet.ibm.com>
    Signed-off-by: Christophe Lombard <clombard@linux.vnet.ibm.com>
    Reviewed-by: Manoj Kumar <manoj@linux.vnet.ibm.com>
    Acked-by: Ian Munsie <imunsie@au1.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index ac655a698e41..3a1fabd41072 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -344,18 +344,44 @@ struct cxl_sste {
 #define to_cxl_adapter(d) container_of(d, struct cxl, dev)
 #define to_cxl_afu(d) container_of(d, struct cxl_afu, dev)
 
-struct cxl_afu {
+struct cxl_afu_native {
+	void __iomem *p1n_mmio;
+	void __iomem *afu_desc_mmio;
 	irq_hw_number_t psl_hwirq;
+	unsigned int psl_virq;
+	struct mutex spa_mutex;
+	/*
+	 * Only the first part of the SPA is used for the process element
+	 * linked list. The only other part that software needs to worry about
+	 * is sw_command_status, which we store a separate pointer to.
+	 * Everything else in the SPA is only used by hardware
+	 */
+	struct cxl_process_element *spa;
+	__be64 *sw_command_status;
+	unsigned int spa_size;
+	int spa_order;
+	int spa_max_procs;
+	u64 pp_offset;
+};
+
+struct cxl_afu_guest {
+	u64 handle;
+	phys_addr_t p2n_phys;
+	u64 p2n_size;
+	int max_ints;
+};
+
+struct cxl_afu {
+	struct cxl_afu_native *native;
+	struct cxl_afu_guest *guest;
 	irq_hw_number_t serr_hwirq;
-	char *err_irq_name;
-	char *psl_irq_name;
 	unsigned int serr_virq;
-	void __iomem *p1n_mmio;
+	char *psl_irq_name;
+	char *err_irq_name;
 	void __iomem *p2n_mmio;
 	phys_addr_t psn_phys;
-	u64 pp_offset;
 	u64 pp_size;
-	void __iomem *afu_desc_mmio;
+
 	struct cxl *adapter;
 	struct device dev;
 	struct cdev afu_cdev_s, afu_cdev_m, afu_cdev_d;
@@ -363,26 +389,12 @@ struct cxl_afu {
 	struct idr contexts_idr;
 	struct dentry *debugfs;
 	struct mutex contexts_lock;
-	struct mutex spa_mutex;
 	spinlock_t afu_cntl_lock;
 
 	/* AFU error buffer fields and bin attribute for sysfs */
 	u64 eb_len, eb_offset;
 	struct bin_attribute attr_eb;
 
-	/*
-	 * Only the first part of the SPA is used for the process element
-	 * linked list. The only other part that software needs to worry about
-	 * is sw_command_status, which we store a separate pointer to.
-	 * Everything else in the SPA is only used by hardware
-	 */
-	struct cxl_process_element *spa;
-	__be64 *sw_command_status;
-	unsigned int spa_size;
-	int spa_order;
-	int spa_max_procs;
-	unsigned int psl_virq;
-
 	/* pointer to the vphb */
 	struct pci_controller *phb;
 
@@ -488,11 +500,34 @@ struct cxl_context {
 	struct rcu_head rcu;
 };
 
-struct cxl {
+struct cxl_native {
+	u64 afu_desc_off;
+	u64 afu_desc_size;
 	void __iomem *p1_mmio;
 	void __iomem *p2_mmio;
 	irq_hw_number_t err_hwirq;
 	unsigned int err_virq;
+	u64 ps_off;
+};
+
+struct cxl_guest {
+	struct platform_device *pdev;
+	int irq_nranges;
+	struct cdev cdev;
+	irq_hw_number_t irq_base_offset;
+	struct irq_avail *irq_avail;
+	spinlock_t irq_alloc_lock;
+	u64 handle;
+	char *status;
+	u16 vendor;
+	u16 device;
+	u16 subsystem_vendor;
+	u16 subsystem;
+};
+
+struct cxl {
+	struct cxl_native *native;
+	struct cxl_guest *guest;
 	spinlock_t afu_list_lock;
 	struct cxl_afu *afu[CXL_MAX_SLICES];
 	struct device dev;
@@ -503,9 +538,6 @@ struct cxl {
 	struct bin_attribute cxl_attr;
 	int adapter_num;
 	int user_irqs;
-	u64 afu_desc_off;
-	u64 afu_desc_size;
-	u64 ps_off;
 	u64 ps_size;
 	u16 psl_rev;
 	u16 base_image;
@@ -570,7 +602,7 @@ static inline bool cxl_adapter_link_ok(struct cxl *cxl)
 static inline void __iomem *_cxl_p1_addr(struct cxl *cxl, cxl_p1_reg_t reg)
 {
 	WARN_ON(!cpu_has_feature(CPU_FTR_HVMODE));
-	return cxl->p1_mmio + cxl_reg_off(reg);
+	return cxl->native->p1_mmio + cxl_reg_off(reg);
 }
 
 static inline void cxl_p1_write(struct cxl *cxl, cxl_p1_reg_t reg, u64 val)
@@ -590,7 +622,7 @@ static inline u64 cxl_p1_read(struct cxl *cxl, cxl_p1_reg_t reg)
 static inline void __iomem *_cxl_p1n_addr(struct cxl_afu *afu, cxl_p1n_reg_t reg)
 {
 	WARN_ON(!cpu_has_feature(CPU_FTR_HVMODE));
-	return afu->p1n_mmio + cxl_reg_off(reg);
+	return afu->native->p1n_mmio + cxl_reg_off(reg);
 }
 
 static inline void cxl_p1n_write(struct cxl_afu *afu, cxl_p1n_reg_t reg, u64 val)

commit 444c4ba4616503baf68cffbf6748047d308b8cd2
Author: Christophe Lombard <clombard@linux.vnet.ibm.com>
Date:   Fri Mar 4 12:26:34 2016 +0100

    cxl: New hcalls to support cxl adapters
    
    The hypervisor calls provide an interface with a coherent platform
    facility and function. It matches version 0.16 of the 'PAPR changes'
    document.
    
    The following hcalls are supported:
    H_ATTACH_CA_PROCESS    Attach a process element to a coherent platform
                           function.
    H_DETACH_CA_PROCESS    Detach a process element from a coherent
                           platform function.
    H_CONTROL_CA_FUNCTION  Allow the partition to manipulate or query
                           certain coherent platform function behaviors.
    H_COLLECT_CA_INT_INFO  Collect interrupt info about a coherent.
                           platform function after an interrupt occurred
    H_CONTROL_CA_FAULTS    Control the operation of a coherent platform
                           function after a fault occurs.
    H_DOWNLOAD_CA_FACILITY Support for downloading a base adapter image to
                           the coherent platform facility, and for
                           validating the entire image after the download.
    H_CONTROL_CA_FACILITY  Allow the partition to manipulate or query
                           certain coherent platform facility behaviors.
    
    Co-authored-by: Frederic Barrat <fbarrat@linux.vnet.ibm.com>
    Signed-off-by: Frederic Barrat <fbarrat@linux.vnet.ibm.com>
    Signed-off-by: Christophe Lombard <clombard@linux.vnet.ibm.com>
    Reviewed-by: Manoj Kumar <manoj@linux.vnet.ibm.com>
    Acked-by: Ian Munsie <imunsie@au1.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index c7ed26549565..ac655a698e41 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -688,6 +688,7 @@ void cxl_prefault(struct cxl_context *ctx, u64 wed);
 
 struct cxl *get_cxl_adapter(int num);
 int cxl_alloc_sst(struct cxl_context *ctx);
+void cxl_dump_debug_buffer(void *addr, size_t size);
 
 void init_cxl_native(void);
 
@@ -701,16 +702,34 @@ unsigned int cxl_map_irq(struct cxl *adapter, irq_hw_number_t hwirq,
 void cxl_unmap_irq(unsigned int virq, void *cookie);
 int __detach_context(struct cxl_context *ctx);
 
-/* This matches the layout of the H_COLLECT_CA_INT_INFO retbuf */
+/*
+ * This must match the layout of the H_COLLECT_CA_INT_INFO retbuf defined
+ * in PAPR.
+ * A word about endianness: a pointer to this structure is passed when
+ * calling the hcall. However, it is not a block of memory filled up by
+ * the hypervisor. The return values are found in registers, and copied
+ * one by one when returning from the hcall. See the end of the call to
+ * plpar_hcall9() in hvCall.S
+ * As a consequence:
+ * - we don't need to do any endianness conversion
+ * - the pid and tid are an exception. They are 32-bit values returned in
+ *   the same 64-bit register. So we do need to worry about byte ordering.
+ */
 struct cxl_irq_info {
 	u64 dsisr;
 	u64 dar;
 	u64 dsr;
+#ifndef CONFIG_CPU_LITTLE_ENDIAN
 	u32 pid;
 	u32 tid;
+#else
+	u32 tid;
+	u32 pid;
+#endif
 	u64 afu_err;
 	u64 errstat;
-	u64 padding[3]; /* to match the expected retbuf size for plpar_hcall9 */
+	u64 proc_handle;
+	u64 padding[2]; /* to match the expected retbuf size for plpar_hcall9 */
 };
 
 void cxl_assign_psn_space(struct cxl_context *ctx);

commit 6d625ed9a7b04c5905dcaab564ec560be586822f
Author: Frederic Barrat <fbarrat@linux.vnet.ibm.com>
Date:   Fri Mar 4 12:26:31 2016 +0100

    cxl: Update cxl_irq() prototype
    
    The context parameter when calling cxl_irq() should be strongly typed.
    
    Co-authored-by: Christophe Lombard <clombard@linux.vnet.ibm.com>
    Signed-off-by: Frederic Barrat <fbarrat@linux.vnet.ibm.com>
    Signed-off-by: Christophe Lombard <clombard@linux.vnet.ibm.com>
    Reviewed-by: Manoj Kumar <manoj@linux.vnet.ibm.com>
    Acked-by: Ian Munsie <imunsie@au1.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index 40f67838dd6d..c7ed26549565 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -714,7 +714,7 @@ struct cxl_irq_info {
 };
 
 void cxl_assign_psn_space(struct cxl_context *ctx);
-irqreturn_t cxl_irq(int irq, void *ctx, struct cxl_irq_info *irq_info);
+irqreturn_t cxl_irq(int irq, struct cxl_context *ctx, struct cxl_irq_info *irq_info);
 int cxl_register_one_irq(struct cxl *adapter, irq_handler_t handler,
 			void *cookie, irq_hw_number_t *dest_hwirq,
 			unsigned int *dest_virq, const char *name);

commit ea2d1f95efd7c100617235918bac370414aec1ad
Author: Frederic Barrat <fbarrat@linux.vnet.ibm.com>
Date:   Fri Mar 4 12:26:30 2016 +0100

    cxl: Isolate a few bare-metal-specific calls
    
    A few functions are mostly common between bare-metal and guest and
    just need minor tuning. To avoid crowding the backend API, introduce a
    few 'if' based on the CPU being in HV mode.
    
    Co-authored-by: Christophe Lombard <clombard@linux.vnet.ibm.com>
    Signed-off-by: Frederic Barrat <fbarrat@linux.vnet.ibm.com>
    Signed-off-by: Christophe Lombard <clombard@linux.vnet.ibm.com>
    Reviewed-by: Manoj Kumar <manoj@linux.vnet.ibm.com>
    Acked-by: Ian Munsie <imunsie@au1.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index 02065b4defa2..40f67838dd6d 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -560,8 +560,11 @@ static inline bool cxl_adapter_link_ok(struct cxl *cxl)
 {
 	struct pci_dev *pdev;
 
-	pdev = to_pci_dev(cxl->dev.parent);
-	return !pci_channel_offline(pdev);
+	if (cpu_has_feature(CPU_FTR_HVMODE)) {
+		pdev = to_pci_dev(cxl->dev.parent);
+		return !pci_channel_offline(pdev);
+	}
+	return true;
 }
 
 static inline void __iomem *_cxl_p1_addr(struct cxl *cxl, cxl_p1_reg_t reg)

commit 2b04cf310ba8c123e9957cfab80274e7606bf53c
Author: Frederic Barrat <fbarrat@linux.vnet.ibm.com>
Date:   Fri Mar 4 12:26:29 2016 +0100

    cxl: Rename some bare-metal specific functions
    
    Rename a few functions, changing the 'cxl_' prefix to either
    'cxl_pci_' or 'cxl_native_', to make clear that the implementation is
    bare-metal specific.
    
    Those functions will have an equivalent implementation for a guest in
    a later patch.
    
    Co-authored-by: Christophe Lombard <clombard@linux.vnet.ibm.com>
    Signed-off-by: Frederic Barrat <fbarrat@linux.vnet.ibm.com>
    Signed-off-by: Christophe Lombard <clombard@linux.vnet.ibm.com>
    Reviewed-by: Manoj Kumar <manoj@linux.vnet.ibm.com>
    Acked-by: Ian Munsie <imunsie@au1.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index 8233af305f8d..02065b4defa2 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -519,14 +519,14 @@ struct cxl {
 	bool perst_same_image;
 };
 
-int cxl_alloc_one_irq(struct cxl *adapter);
-void cxl_release_one_irq(struct cxl *adapter, int hwirq);
-int cxl_alloc_irq_ranges(struct cxl_irq_ranges *irqs, struct cxl *adapter, unsigned int num);
-void cxl_release_irq_ranges(struct cxl_irq_ranges *irqs, struct cxl *adapter);
-int cxl_setup_irq(struct cxl *adapter, unsigned int hwirq, unsigned int virq);
+int cxl_pci_alloc_one_irq(struct cxl *adapter);
+void cxl_pci_release_one_irq(struct cxl *adapter, int hwirq);
+int cxl_pci_alloc_irq_ranges(struct cxl_irq_ranges *irqs, struct cxl *adapter, unsigned int num);
+void cxl_pci_release_irq_ranges(struct cxl_irq_ranges *irqs, struct cxl *adapter);
+int cxl_pci_setup_irq(struct cxl *adapter, unsigned int hwirq, unsigned int virq);
 int cxl_update_image_control(struct cxl *adapter);
-int cxl_reset(struct cxl *adapter);
-void cxl_release_afu(struct device *dev);
+int cxl_pci_reset(struct cxl *adapter);
+void cxl_pci_release_afu(struct device *dev);
 
 /* common == phyp + powernv */
 struct cxl_process_element_common {
@@ -623,7 +623,7 @@ static inline u64 cxl_p2n_read(struct cxl_afu *afu, cxl_p2n_reg_t reg)
 		return ~0ULL;
 }
 
-ssize_t cxl_afu_read_err_buffer(struct cxl_afu *afu, char *buf,
+ssize_t cxl_pci_afu_read_err_buffer(struct cxl_afu *afu, char *buf,
 				loff_t off, size_t count);
 
 
@@ -663,12 +663,12 @@ struct cxl *cxl_alloc_adapter(void);
 struct cxl_afu *cxl_alloc_afu(struct cxl *adapter, int slice);
 int cxl_afu_select_best_mode(struct cxl_afu *afu);
 
-int cxl_register_psl_irq(struct cxl_afu *afu);
-void cxl_release_psl_irq(struct cxl_afu *afu);
-int cxl_register_psl_err_irq(struct cxl *adapter);
-void cxl_release_psl_err_irq(struct cxl *adapter);
-int cxl_register_serr_irq(struct cxl_afu *afu);
-void cxl_release_serr_irq(struct cxl_afu *afu);
+int cxl_native_register_psl_irq(struct cxl_afu *afu);
+void cxl_native_release_psl_irq(struct cxl_afu *afu);
+int cxl_native_register_psl_err_irq(struct cxl *adapter);
+void cxl_native_release_psl_err_irq(struct cxl *adapter);
+int cxl_native_register_serr_irq(struct cxl_afu *afu);
+void cxl_native_release_serr_irq(struct cxl_afu *afu);
 int afu_register_irqs(struct cxl_context *ctx, u32 count);
 void afu_release_irqs(struct cxl_context *ctx, void *cookie);
 void afu_irq_name_free(struct cxl_context *ctx);

commit 5be587b1110132b4f05e0bc3515a145365e910fe
Author: Frederic Barrat <fbarrat@linux.vnet.ibm.com>
Date:   Fri Mar 4 12:26:28 2016 +0100

    cxl: Introduce implementation-specific API
    
    The backend API (in cxl.h) lists some low-level functions whose
    implementation is different on bare-metal and in a guest. Each
    environment implements its own functions, and the common code uses
    them through function pointers, defined in cxl_backend_ops
    
    Co-authored-by: Christophe Lombard <clombard@linux.vnet.ibm.com>
    Signed-off-by: Frederic Barrat <fbarrat@linux.vnet.ibm.com>
    Signed-off-by: Christophe Lombard <clombard@linux.vnet.ibm.com>
    Reviewed-by: Manoj Kumar <manoj@linux.vnet.ibm.com>
    Acked-by: Ian Munsie <imunsie@au1.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index 3b824e3d68d2..8233af305f8d 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -623,11 +623,6 @@ static inline u64 cxl_p2n_read(struct cxl_afu *afu, cxl_p2n_reg_t reg)
 		return ~0ULL;
 }
 
-u64 cxl_afu_cr_read64(struct cxl_afu *afu, int cr, u64 off);
-u32 cxl_afu_cr_read32(struct cxl_afu *afu, int cr, u64 off);
-u16 cxl_afu_cr_read16(struct cxl_afu *afu, int cr, u64 off);
-u8 cxl_afu_cr_read8(struct cxl_afu *afu, int cr, u64 off);
-
 ssize_t cxl_afu_read_err_buffer(struct cxl_afu *afu, char *buf,
 				loff_t off, size_t count);
 
@@ -666,10 +661,6 @@ void cxl_sysfs_afu_m_remove(struct cxl_afu *afu);
 
 struct cxl *cxl_alloc_adapter(void);
 struct cxl_afu *cxl_alloc_afu(struct cxl *adapter, int slice);
-
-int cxl_afu_activate_mode(struct cxl_afu *afu, int mode);
-int _cxl_afu_deactivate_mode(struct cxl_afu *afu, int mode);
-int cxl_afu_deactivate_mode(struct cxl_afu *afu);
 int cxl_afu_select_best_mode(struct cxl_afu *afu);
 
 int cxl_register_psl_irq(struct cxl_afu *afu);
@@ -681,8 +672,6 @@ void cxl_release_serr_irq(struct cxl_afu *afu);
 int afu_register_irqs(struct cxl_context *ctx, u32 count);
 void afu_release_irqs(struct cxl_context *ctx, void *cookie);
 void afu_irq_name_free(struct cxl_context *ctx);
-irqreturn_t handle_psl_slice_error(struct cxl_context *ctx, u64 dsisr,
-				u64 errstat);
 
 int cxl_debugfs_init(void);
 void cxl_debugfs_exit(void);
@@ -727,18 +716,10 @@ int cxl_register_one_irq(struct cxl *adapter, irq_handler_t handler,
 			void *cookie, irq_hw_number_t *dest_hwirq,
 			unsigned int *dest_virq, const char *name);
 
-int cxl_attach_process(struct cxl_context *ctx, bool kernel, u64 wed,
-			    u64 amr);
-int cxl_detach_process(struct cxl_context *ctx);
-
-int cxl_ack_irq(struct cxl_context *ctx, u64 tfc, u64 psl_reset_mask);
-
 int cxl_check_error(struct cxl_afu *afu);
 int cxl_afu_slbia(struct cxl_afu *afu);
 int cxl_tlb_slb_invalidate(struct cxl *adapter);
 int cxl_afu_disable(struct cxl_afu *afu);
-int __cxl_afu_reset(struct cxl_afu *afu);
-int cxl_afu_check_and_enable(struct cxl_afu *afu);
 int cxl_psl_purge(struct cxl_afu *afu);
 
 void cxl_stop_trace(struct cxl *cxl);
@@ -757,4 +738,38 @@ unsigned int afu_poll(struct file *file, struct poll_table_struct *poll);
 ssize_t afu_read(struct file *file, char __user *buf, size_t count, loff_t *off);
 extern const struct file_operations afu_fops;
 
+struct cxl_backend_ops {
+	struct module *module;
+	int (*adapter_reset)(struct cxl *adapter);
+	int (*alloc_one_irq)(struct cxl *adapter);
+	void (*release_one_irq)(struct cxl *adapter, int hwirq);
+	int (*alloc_irq_ranges)(struct cxl_irq_ranges *irqs,
+				struct cxl *adapter, unsigned int num);
+	void (*release_irq_ranges)(struct cxl_irq_ranges *irqs,
+				struct cxl *adapter);
+	int (*setup_irq)(struct cxl *adapter, unsigned int hwirq,
+			unsigned int virq);
+	irqreturn_t (*handle_psl_slice_error)(struct cxl_context *ctx,
+					u64 dsisr, u64 errstat);
+	irqreturn_t (*psl_interrupt)(int irq, void *data);
+	int (*ack_irq)(struct cxl_context *ctx, u64 tfc, u64 psl_reset_mask);
+	int (*attach_process)(struct cxl_context *ctx, bool kernel,
+			u64 wed, u64 amr);
+	int (*detach_process)(struct cxl_context *ctx);
+	bool (*link_ok)(struct cxl *cxl);
+	void (*release_afu)(struct device *dev);
+	ssize_t (*afu_read_err_buffer)(struct cxl_afu *afu, char *buf,
+				loff_t off, size_t count);
+	int (*afu_check_and_enable)(struct cxl_afu *afu);
+	int (*afu_activate_mode)(struct cxl_afu *afu, int mode);
+	int (*afu_deactivate_mode)(struct cxl_afu *afu, int mode);
+	int (*afu_reset)(struct cxl_afu *afu);
+	int (*afu_cr_read8)(struct cxl_afu *afu, int cr_idx, u64 offset, u8 *val);
+	int (*afu_cr_read16)(struct cxl_afu *afu, int cr_idx, u64 offset, u16 *val);
+	int (*afu_cr_read32)(struct cxl_afu *afu, int cr_idx, u64 offset, u32 *val);
+	int (*afu_cr_read64)(struct cxl_afu *afu, int cr_idx, u64 offset, u64 *val);
+};
+extern const struct cxl_backend_ops cxl_native_ops;
+extern const struct cxl_backend_ops *cxl_ops;
+
 #endif

commit d56d301b51746e71f7bdaaba10973f054c3c736e
Author: Frederic Barrat <fbarrat@linux.vnet.ibm.com>
Date:   Fri Mar 4 12:26:26 2016 +0100

    cxl: Move bare-metal specific code to specialized files
    
    Move a few functions around to better separate code specific to
    bare-metal environment from code which will be commonly used between
    guest and bare-metal.
    
    Code specific to bare-metal is meant to be in native.c or pci.c
    only. It's basically anything which touches the card p1 registers,
    some p2 registers not needed from a guest and the PCI interface.
    
    Co-authored-by: Christophe Lombard <clombard@linux.vnet.ibm.com>
    Signed-off-by: Frederic Barrat <fbarrat@linux.vnet.ibm.com>
    Signed-off-by: Christophe Lombard <clombard@linux.vnet.ibm.com>
    Reviewed-by: Manoj Kumar <manoj@linux.vnet.ibm.com>
    Acked-by: Ian Munsie <imunsie@au1.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index 3f881400f0fe..3b824e3d68d2 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -623,23 +623,8 @@ static inline u64 cxl_p2n_read(struct cxl_afu *afu, cxl_p2n_reg_t reg)
 		return ~0ULL;
 }
 
-static inline u64 cxl_afu_cr_read64(struct cxl_afu *afu, int cr, u64 off)
-{
-	if (likely(cxl_adapter_link_ok(afu->adapter)))
-		return in_le64((afu)->afu_desc_mmio + (afu)->crs_offset +
-			       ((cr) * (afu)->crs_len) + (off));
-	else
-		return ~0ULL;
-}
-
-static inline u32 cxl_afu_cr_read32(struct cxl_afu *afu, int cr, u64 off)
-{
-	if (likely(cxl_adapter_link_ok(afu->adapter)))
-		return in_le32((afu)->afu_desc_mmio + (afu)->crs_offset +
-			       ((cr) * (afu)->crs_len) + (off));
-	else
-		return 0xffffffff;
-}
+u64 cxl_afu_cr_read64(struct cxl_afu *afu, int cr, u64 off);
+u32 cxl_afu_cr_read32(struct cxl_afu *afu, int cr, u64 off);
 u16 cxl_afu_cr_read16(struct cxl_afu *afu, int cr, u64 off);
 u8 cxl_afu_cr_read8(struct cxl_afu *afu, int cr, u64 off);
 
@@ -654,7 +639,6 @@ struct cxl_calls {
 int register_cxl_calls(struct cxl_calls *calls);
 void unregister_cxl_calls(struct cxl_calls *calls);
 
-int cxl_alloc_adapter_nr(struct cxl *adapter);
 void cxl_remove_adapter_nr(struct cxl *adapter);
 
 int cxl_alloc_spa(struct cxl_afu *afu);
@@ -697,7 +681,8 @@ void cxl_release_serr_irq(struct cxl_afu *afu);
 int afu_register_irqs(struct cxl_context *ctx, u32 count);
 void afu_release_irqs(struct cxl_context *ctx, void *cookie);
 void afu_irq_name_free(struct cxl_context *ctx);
-irqreturn_t cxl_slice_irq_err(int irq, void *data);
+irqreturn_t handle_psl_slice_error(struct cxl_context *ctx, u64 dsisr,
+				u64 errstat);
 
 int cxl_debugfs_init(void);
 void cxl_debugfs_exit(void);
@@ -746,7 +731,6 @@ int cxl_attach_process(struct cxl_context *ctx, bool kernel, u64 wed,
 			    u64 amr);
 int cxl_detach_process(struct cxl_context *ctx);
 
-int cxl_get_irq(struct cxl_afu *afu, struct cxl_irq_info *info);
 int cxl_ack_irq(struct cxl_context *ctx, u64 tfc, u64 psl_reset_mask);
 
 int cxl_check_error(struct cxl_afu *afu);

commit 8633186209e35dfafc27c3d0f0d5e702ab47265f
Author: Christophe Lombard <clombard@linux.vnet.ibm.com>
Date:   Fri Mar 4 12:26:25 2016 +0100

    cxl: Move common code away from bare-metal-specific files
    
    Move around some functions which will be accessed from the bare-metal
    and guest environments.
    Code in native.c and pci.c is meant to be bare-metal specific.
    Other files contain code which may be shared with guests.
    
    Co-authored-by: Frederic Barrat <fbarrat@linux.vnet.ibm.com>
    Signed-off-by: Frederic Barrat <fbarrat@linux.vnet.ibm.com>
    Signed-off-by: Christophe Lombard <clombard@linux.vnet.ibm.com>
    Reviewed-by: Manoj Kumar <manoj@linux.vnet.ibm.com>
    Acked-by: Ian Munsie <imunsie@au1.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index a521bc72cec2..3f881400f0fe 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -526,6 +526,7 @@ void cxl_release_irq_ranges(struct cxl_irq_ranges *irqs, struct cxl *adapter);
 int cxl_setup_irq(struct cxl *adapter, unsigned int hwirq, unsigned int virq);
 int cxl_update_image_control(struct cxl *adapter);
 int cxl_reset(struct cxl *adapter);
+void cxl_release_afu(struct device *dev);
 
 /* common == phyp + powernv */
 struct cxl_process_element_common {
@@ -679,6 +680,9 @@ void cxl_sysfs_afu_remove(struct cxl_afu *afu);
 int cxl_sysfs_afu_m_add(struct cxl_afu *afu);
 void cxl_sysfs_afu_m_remove(struct cxl_afu *afu);
 
+struct cxl *cxl_alloc_adapter(void);
+struct cxl_afu *cxl_alloc_afu(struct cxl *adapter, int slice);
+
 int cxl_afu_activate_mode(struct cxl_afu *afu, int mode);
 int _cxl_afu_deactivate_mode(struct cxl_afu *afu, int mode);
 int cxl_afu_deactivate_mode(struct cxl_afu *afu);
@@ -733,6 +737,11 @@ struct cxl_irq_info {
 };
 
 void cxl_assign_psn_space(struct cxl_context *ctx);
+irqreturn_t cxl_irq(int irq, void *ctx, struct cxl_irq_info *irq_info);
+int cxl_register_one_irq(struct cxl *adapter, irq_handler_t handler,
+			void *cookie, irq_hw_number_t *dest_hwirq,
+			unsigned int *dest_virq, const char *name);
+
 int cxl_attach_process(struct cxl_context *ctx, bool kernel, u64 wed,
 			    u64 amr);
 int cxl_detach_process(struct cxl_context *ctx);

commit 7b8ad495d59280b634a7b546f4cdf58cf4d65f61
Author: Vaibhav Jain <vaibhav@linux.vnet.ibm.com>
Date:   Tue Nov 24 16:26:18 2015 +0530

    cxl: Fix DSI misses when the context owning task exits
    
    Presently when a user-space process issues CXL_IOCTL_START_WORK ioctl we
    store the pid of the current task_struct and use it to get pointer to
    the mm_struct of the process, while processing page or segment faults
    from the capi card. However this causes issues when the thread that had
    originally issued the start-work ioctl exits in which case the stored
    pid is no more valid and the cxl driver is unable to handle faults as
    the mm_struct corresponding to process is no more accessible.
    
    This patch fixes this issue by using the mm_struct of the next alive
    task in the thread group. This is done by iterating over all the tasks
    in the thread group starting from thread group leader and calling
    get_task_mm on each one of them. When a valid mm_struct is obtained the
    pid of the associated task is stored in the context replacing the
    exiting one for handling future faults.
    
    The patch introduces a new function named get_mem_context that checks if
    the current task pointed to by ctx->pid is dead? If yes it performs the
    steps described above. Also a new variable cxl_context.glpid is
    introduced which stores the pid of the thread group leader associated
    with the context owning task.
    
    Reported-by: Matthew R. Ochs <mrochs@linux.vnet.ibm.com>
    Reported-by: Frank Haverkamp <HAVERKAM@de.ibm.com>
    Suggested-by: Ian Munsie <imunsie@au1.ibm.com>
    Signed-off-by: Vaibhav Jain <vaibhav@linux.vnet.ibm.com>
    Acked-by: Ian Munsie <imunsie@au1.ibm.com>
    Reviewed-by: Frederic Barrat <fbarrat@linux.vnet.ibm.com>
    Reviewed-by: Matthew R. Ochs <mrochs@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index 25ae57fa79b0..a521bc72cec2 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -445,6 +445,9 @@ struct cxl_context {
 	unsigned int sst_size, sst_lru;
 
 	wait_queue_head_t wq;
+	/* pid of the group leader associated with the pid */
+	struct pid *glpid;
+	/* use mm context associated with this pid for ds faults */
 	struct pid *pid;
 	spinlock_t lock; /* Protects pending_irq_mask, pending_fault and fault_addr */
 	/* Only used in PR mode */

commit 1b5df59e50874b9034c0fa389cd52b65f1f93292
Author: Vaibhav Jain <vaibhav@linux.vnet.ibm.com>
Date:   Mon Nov 16 09:33:45 2015 +0530

    cxl: Fix possible idr warning when contexts are released
    
    An idr warning is reported when a context is release after the capi card
    is unbound from the cxl driver via sysfs. Below are the steps to
    reproduce:
    
    1. Create multiple afu contexts in an user-space application using libcxl.
    2. Unbind capi card from cxl using command of form
       echo <capi-card-pci-addr> > /sys/bus/pci/drivers/cxl-pci/unbind
    3. Exit/kill the application owning afu contexts.
    
    After above steps a warning message is usually seen in the kernel logs
    of the form "idr_remove called for id=<context-id> which is not
    allocated."
    
    This is caused by the function cxl_release_afu which destroys the
    contexts_idr table. So when a context is release no entry for context pe
    is found in the contexts_idr table and idr code prints this warning.
    
    This patch fixes this issue by increasing & decreasing the ref-count on
    the afu device when a context is initialized or when its freed
    respectively. This prevents the afu from being released until all the
    afu contexts have been released. The patch introduces two new functions
    namely cxl_afu_get/put that manage the ref-count on the afu device.
    
    Also the patch removes code inside cxl_dev_context_init that increases ref
    on the afu device as its guaranteed to be alive during this function.
    
    Reported-by: Ian Munsie <imunsie@au1.ibm.com>
    Signed-off-by: Vaibhav Jain <vaibhav@linux.vnet.ibm.com>
    Acked-by: Ian Munsie <imunsie@au1.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index 0cfb9c129f27..25ae57fa79b0 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -403,6 +403,18 @@ struct cxl_afu {
 	bool enabled;
 };
 
+/* AFU refcount management */
+static inline struct cxl_afu *cxl_afu_get(struct cxl_afu *afu)
+{
+
+	return (get_device(&afu->dev) == NULL) ? NULL : afu;
+}
+
+static inline void  cxl_afu_put(struct cxl_afu *afu)
+{
+	put_device(&afu->dev);
+}
+
 
 struct cxl_irq_name {
 	struct list_head list;

commit 8dde152ea34860403c839598bdef3f07239eb25a
Author: Andrew Donnellan <andrew.donnellan@au1.ibm.com>
Date:   Wed Sep 30 11:58:05 2015 +1000

    cxl: fix leak of IRQ names in cxl_free_afu_irqs()
    
    cxl_free_afu_irqs() doesn't free IRQ names when it releases an AFU's IRQ
    ranges. The userspace API equivalent in afu_release_irqs() calls
    afu_irq_name_free() to release the IRQ names.
    
    Call afu_irq_name_free() in cxl_free_afu_irqs() to release the IRQ names.
    Make afu_irq_name_free() non-static to allow this.
    
    Reported-by: Matthew R. Ochs <mrochs@linux.vnet.ibm.com>
    Fixes: 6f7f0b3df6d4 ("cxl: Add AFU virtual PHB and kernel API")
    Signed-off-by: Andrew Donnellan <andrew.donnellan@au1.ibm.com>
    Signed-off-by: Ian Munsie <imunsie@au1.ibm.com>
    Reviewed-by: Matthew R. Ochs <mrochs@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index 1c30ef77073d..0cfb9c129f27 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -677,6 +677,7 @@ int cxl_register_serr_irq(struct cxl_afu *afu);
 void cxl_release_serr_irq(struct cxl_afu *afu);
 int afu_register_irqs(struct cxl_context *ctx, u32 count);
 void afu_release_irqs(struct cxl_context *ctx, void *cookie);
+void afu_irq_name_free(struct cxl_context *ctx);
 irqreturn_t cxl_slice_irq_err(int irq, void *data);
 
 int cxl_debugfs_init(void);

commit 390fd5929f52bdfb9dfcc03820041ba556780f4a
Author: Philippe Bergheaud <felix@linux.vnet.ibm.com>
Date:   Fri Aug 28 09:37:36 2015 +0200

    cxl: Set up and enable PSL Timebase
    
    This patch configures the PSL Timebase function and enables it,
    after the CAPP has been initialized by OPAL.
    
    Acked-by: Ian Munsie <imunsie@au1.ibm.com>
    Signed-off-by: Philippe Bergheaud <felix@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index d6566c60bcb0..1c30ef77073d 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -83,8 +83,10 @@ static const cxl_p1_reg_t CXL_PSL_AFUSEL  = {0x00B0};
 /* 0x00C0:7EFF Implementation dependent area */
 static const cxl_p1_reg_t CXL_PSL_FIR1      = {0x0100};
 static const cxl_p1_reg_t CXL_PSL_FIR2      = {0x0108};
+static const cxl_p1_reg_t CXL_PSL_Timebase  = {0x0110};
 static const cxl_p1_reg_t CXL_PSL_VERSION   = {0x0118};
 static const cxl_p1_reg_t CXL_PSL_RESLCKTO  = {0x0128};
+static const cxl_p1_reg_t CXL_PSL_TB_CTLSTAT = {0x0140};
 static const cxl_p1_reg_t CXL_PSL_FIR_CNTL  = {0x0148};
 static const cxl_p1_reg_t CXL_PSL_DSNDCTL   = {0x0150};
 static const cxl_p1_reg_t CXL_PSL_SNWRALLOC = {0x0158};
@@ -152,6 +154,9 @@ static const cxl_p2n_reg_t CXL_PSL_WED_An     = {0x0A0};
 #define CXL_PSL_SPAP_Size_Shift 4
 #define CXL_PSL_SPAP_V    0x0000000000000001ULL
 
+/****** CXL_PSL_Control ****************************************************/
+#define CXL_PSL_Control_tb 0x0000000000000001ULL
+
 /****** CXL_PSL_DLCNTL *****************************************************/
 #define CXL_PSL_DLCNTL_D (0x1ull << (63-28))
 #define CXL_PSL_DLCNTL_C (0x1ull << (63-29))

commit 55e07668fbba9466e6a9ef7650718356cda38406
Author: Ian Munsie <imunsie@au1.ibm.com>
Date:   Thu Aug 27 19:50:19 2015 +1000

    cxl: Fix force unmapping mmaps of contexts allocated through the kernel api
    
    The cxl user api uses the address_space associated with the file when we
    need to force unmap all cxl mmap regions (e.g. on eeh, driver detach,
    etc). Currently, contexts allocated through the kernel api do not do
    this and instead skip the mmap invalidation, potentially allowing them
    to poke at the hardware after such an event, which may cause all sorts
    of trouble.
    
    This patch allocates an address_space for cxl contexts allocated through
    the kernel api so that the same invalidate path will for these contexts
    as well. We don't use the anonymous inode's address_space, as doing so
    could invalidate any mmaps of completely unrelated drivers using
    anonymous file descriptors.
    
    This patch also introduces a kernelapi flag, so we know when freeing the
    context if the address_space was allocated by us and needs to be freed.
    
    Signed-off-by: Ian Munsie <imunsie@au1.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index e7af256f60c5..d6566c60bcb0 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -420,6 +420,7 @@ struct cxl_context {
 	struct mutex mapping_lock;
 	struct page *ff_page;
 	bool mmio_err_ff;
+	bool kernelapi;
 
 	spinlock_t sste_lock; /* Protects segment table entries */
 	struct cxl_sste *sstp;

commit d9232a3da8683cd9c9854a858bcca968fe5f3bca
Author: Ian Munsie <imunsie@au1.ibm.com>
Date:   Thu Jul 23 16:43:56 2015 +1000

    cxl: Add alternate MMIO error handling
    
    userspace programs using cxl currently have to use two strategies for
    dealing with MMIO errors simultaneously. They have to check every read
    for a return of all Fs in case the adapter has gone away and the kernel
    has not yet noticed, and they have to deal with SIGBUS in case the
    kernel has already noticed, invalidated the mapping and marked the
    context as failed.
    
    In order to simplify things, this patch adds an alternative approach
    where the kernel will return a page filled with Fs instead of delivering
    a SIGBUS. This allows userspace to only need to deal with one of these
    two error paths, and is intended for use in libraries that use cxl
    transparently and may not be able to safely install a signal handler.
    
    This approach will only work if certain constraints are met. Namely, if
    the application is both reading and writing to an address in the problem
    state area it cannot assume that a non-FF read is OK, as it may just be
    reading out a value it has previously written. Further - since only one
    page is used per context a write to a given offset would be visible when
    reading the same offset from a different page in the mapping (this only
    applies within a single context, not between contexts).
    
    An application could deal with this by e.g. making sure it also reads
    from a read-only offset after any reads to a read/write offset.
    
    Due to these constraints, this functionality must be explicitly
    requested by userspace when starting the context by passing in the
    CXL_START_WORK_ERR_FF flag.
    
    Signed-off-by: Ian Munsie <imunsie@au1.ibm.com>
    Acked-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index 6f5386653dae..e7af256f60c5 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -34,7 +34,7 @@ extern uint cxl_verbose;
  * Bump version each time a user API change is made, whether it is
  * backwards compatible ot not.
  */
-#define CXL_API_VERSION 1
+#define CXL_API_VERSION 2
 #define CXL_API_VERSION_COMPATIBLE 1
 
 /*
@@ -418,6 +418,8 @@ struct cxl_context {
 	/* Used to unmap any mmaps when force detaching */
 	struct address_space *mapping;
 	struct mutex mapping_lock;
+	struct page *ff_page;
+	bool mmio_err_ff;
 
 	spinlock_t sste_lock; /* Protects segment table entries */
 	struct cxl_sste *sstp;

commit 9e8df8a219635c5af36a49d78c1f69009b780339
Author: Daniel Axtens <dja@axtens.net>
Date:   Fri Aug 14 17:41:26 2015 +1000

    cxl: EEH support
    
    EEH (Enhanced Error Handling) allows a driver to recover from the
    temporary failure of an attached PCI card. Enable basic CXL support
    for EEH.
    
    Signed-off-by: Daniel Axtens <dja@axtens.net>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index cda02412b01e..6f5386653dae 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -726,6 +726,7 @@ int cxl_psl_purge(struct cxl_afu *afu);
 
 void cxl_stop_trace(struct cxl *cxl);
 int cxl_pci_vphb_add(struct cxl_afu *afu);
+void cxl_pci_vphb_reconfigure(struct cxl_afu *afu);
 void cxl_pci_vphb_remove(struct cxl_afu *afu);
 
 extern struct pci_driver cxl_pci_driver;

commit 13e68d8bd05c998cae452a4f3400af1e8edd852e
Author: Daniel Axtens <dja@axtens.net>
Date:   Fri Aug 14 17:41:25 2015 +1000

    cxl: Allow the kernel to trust that an image won't change on PERST.
    
    Provide a kernel API and a sysfs entry which allow a user to specify
    that when a card is PERSTed, it's image will stay the same, allowing
    it to participate in EEH.
    
    cxl_reset is used to reflash the card. In that case, we cannot safely
    assert that the image will not change. Therefore, disallow cxl_reset
    if the flag is set.
    
    Signed-off-by: Daniel Axtens <dja@axtens.net>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index d540542f9931..cda02412b01e 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -493,6 +493,7 @@ struct cxl {
 	bool user_image_loaded;
 	bool perst_loads_image;
 	bool perst_select_user;
+	bool perst_same_image;
 };
 
 int cxl_alloc_one_irq(struct cxl *adapter);

commit 05155772f642a5b0e421adf2017f993759bf7f95
Author: Daniel Axtens <dja@axtens.net>
Date:   Fri Aug 14 17:41:19 2015 +1000

    cxl: Allocate and release the SPA with the AFU
    
    Previously the SPA was allocated and freed upon entering and leaving
    AFU-directed mode. This causes some issues for error recovery - contexts
    hold a pointer inside the SPA, and they may persist after the AFU has
    been detached.
    
    We would ideally like to allocate the SPA when the AFU is allocated, and
    release it until the AFU is released. However, we don't know how big the
    SPA needs to be until we read the AFU descriptor.
    
    Therefore, restructure the code:
    
     - Allocate the SPA only once, on the first attach.
    
     - Release the SPA only when the entire AFU is being released (not
       detached). Guard the release with a NULL check, so we don't free
       if it was never allocated (e.g. dedicated mode)
    
    Acked-by: Cyril Bur <cyrilbur@gmail.com>
    Signed-off-by: Daniel Axtens <dja@axtens.net>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index 9b9e89fd02cc..d540542f9931 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -632,6 +632,9 @@ void unregister_cxl_calls(struct cxl_calls *calls);
 int cxl_alloc_adapter_nr(struct cxl *adapter);
 void cxl_remove_adapter_nr(struct cxl *adapter);
 
+int cxl_alloc_spa(struct cxl_afu *afu);
+void cxl_release_spa(struct cxl_afu *afu);
+
 int cxl_file_init(void);
 void cxl_file_exit(void);
 int cxl_register_adapter(struct cxl *adapter);

commit 0b3f9c757cabad4b8101c5fcddddd029ed5506a6
Author: Daniel Axtens <dja@axtens.net>
Date:   Fri Aug 14 17:41:18 2015 +1000

    cxl: Drop commands if the PCI channel is not in normal state
    
    If the PCI channel has gone down, don't attempt to poke the hardware.
    
    We need to guard every time cxl_whatever_(read|write) is called. This
    is because a call to those functions will dereference an offset into an
    mmio register, and the mmio mappings get invalidated in the EEH
    teardown.
    
    Check in the read/write functions in the header.
    We give them the same semantics as usual PCI operations:
     - a write to a channel that is down is ignored.
     - a read from a channel that is down returns all fs.
    
    Also, we try to access the MMIO space of a vPHB device as part of the
    PCI disable path. Because that's a read that bypasses most of our usual
    checks, we handle it explicitly.
    
    As far as user visible warnings go:
     - Check link state in file ops, return -EIO if down.
     - Be reasonably quiet if there's an error in a teardown path,
       or when we already know the hardware is going down.
     - Throw a big WARN if someone tries to start a CXL operation
       while the card is down. This gives a useful stacktrace for
       debugging whatever is doing that.
    
    Signed-off-by: Daniel Axtens <dja@axtens.net>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index 6a93bfbcd826..9b9e89fd02cc 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -531,6 +531,14 @@ struct cxl_process_element {
 	__be32 software_state;
 } __packed;
 
+static inline bool cxl_adapter_link_ok(struct cxl *cxl)
+{
+	struct pci_dev *pdev;
+
+	pdev = to_pci_dev(cxl->dev.parent);
+	return !pci_channel_offline(pdev);
+}
+
 static inline void __iomem *_cxl_p1_addr(struct cxl *cxl, cxl_p1_reg_t reg)
 {
 	WARN_ON(!cpu_has_feature(CPU_FTR_HVMODE));
@@ -539,12 +547,16 @@ static inline void __iomem *_cxl_p1_addr(struct cxl *cxl, cxl_p1_reg_t reg)
 
 static inline void cxl_p1_write(struct cxl *cxl, cxl_p1_reg_t reg, u64 val)
 {
-	out_be64(_cxl_p1_addr(cxl, reg), val);
+	if (likely(cxl_adapter_link_ok(cxl)))
+		out_be64(_cxl_p1_addr(cxl, reg), val);
 }
 
 static inline u64 cxl_p1_read(struct cxl *cxl, cxl_p1_reg_t reg)
 {
-	return in_be64(_cxl_p1_addr(cxl, reg));
+	if (likely(cxl_adapter_link_ok(cxl)))
+		return in_be64(_cxl_p1_addr(cxl, reg));
+	else
+		return ~0ULL;
 }
 
 static inline void __iomem *_cxl_p1n_addr(struct cxl_afu *afu, cxl_p1n_reg_t reg)
@@ -555,12 +567,16 @@ static inline void __iomem *_cxl_p1n_addr(struct cxl_afu *afu, cxl_p1n_reg_t reg
 
 static inline void cxl_p1n_write(struct cxl_afu *afu, cxl_p1n_reg_t reg, u64 val)
 {
-	out_be64(_cxl_p1n_addr(afu, reg), val);
+	if (likely(cxl_adapter_link_ok(afu->adapter)))
+		out_be64(_cxl_p1n_addr(afu, reg), val);
 }
 
 static inline u64 cxl_p1n_read(struct cxl_afu *afu, cxl_p1n_reg_t reg)
 {
-	return in_be64(_cxl_p1n_addr(afu, reg));
+	if (likely(cxl_adapter_link_ok(afu->adapter)))
+		return in_be64(_cxl_p1n_addr(afu, reg));
+	else
+		return ~0ULL;
 }
 
 static inline void __iomem *_cxl_p2n_addr(struct cxl_afu *afu, cxl_p2n_reg_t reg)
@@ -570,22 +586,34 @@ static inline void __iomem *_cxl_p2n_addr(struct cxl_afu *afu, cxl_p2n_reg_t reg
 
 static inline void cxl_p2n_write(struct cxl_afu *afu, cxl_p2n_reg_t reg, u64 val)
 {
-	out_be64(_cxl_p2n_addr(afu, reg), val);
+	if (likely(cxl_adapter_link_ok(afu->adapter)))
+		out_be64(_cxl_p2n_addr(afu, reg), val);
 }
 
 static inline u64 cxl_p2n_read(struct cxl_afu *afu, cxl_p2n_reg_t reg)
 {
-	return in_be64(_cxl_p2n_addr(afu, reg));
+	if (likely(cxl_adapter_link_ok(afu->adapter)))
+		return in_be64(_cxl_p2n_addr(afu, reg));
+	else
+		return ~0ULL;
 }
 
 static inline u64 cxl_afu_cr_read64(struct cxl_afu *afu, int cr, u64 off)
 {
-	return in_le64((afu)->afu_desc_mmio + (afu)->crs_offset + ((cr) * (afu)->crs_len) + (off));
+	if (likely(cxl_adapter_link_ok(afu->adapter)))
+		return in_le64((afu)->afu_desc_mmio + (afu)->crs_offset +
+			       ((cr) * (afu)->crs_len) + (off));
+	else
+		return ~0ULL;
 }
 
 static inline u32 cxl_afu_cr_read32(struct cxl_afu *afu, int cr, u64 off)
 {
-	return in_le32((afu)->afu_desc_mmio + (afu)->crs_offset + ((cr) * (afu)->crs_len) + (off));
+	if (likely(cxl_adapter_link_ok(afu->adapter)))
+		return in_le32((afu)->afu_desc_mmio + (afu)->crs_offset +
+			       ((cr) * (afu)->crs_len) + (off));
+	else
+		return 0xffffffff;
 }
 u16 cxl_afu_cr_read16(struct cxl_afu *afu, int cr, u64 off);
 u8 cxl_afu_cr_read8(struct cxl_afu *afu, int cr, u64 off);

commit 588b34be20bc3dd7441c108c95039933699467ab
Author: Daniel Axtens <dja@axtens.net>
Date:   Fri Aug 14 17:41:17 2015 +1000

    cxl: Convert MMIO read/write macros to inline functions
    
    We're about to make these more complex, so make them functions
    first.
    
    Signed-off-by: Daniel Axtens <dja@axtens.net>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index 4fd66cabde1e..6a93bfbcd826 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -537,10 +537,15 @@ static inline void __iomem *_cxl_p1_addr(struct cxl *cxl, cxl_p1_reg_t reg)
 	return cxl->p1_mmio + cxl_reg_off(reg);
 }
 
-#define cxl_p1_write(cxl, reg, val) \
-	out_be64(_cxl_p1_addr(cxl, reg), val)
-#define cxl_p1_read(cxl, reg) \
-	in_be64(_cxl_p1_addr(cxl, reg))
+static inline void cxl_p1_write(struct cxl *cxl, cxl_p1_reg_t reg, u64 val)
+{
+	out_be64(_cxl_p1_addr(cxl, reg), val);
+}
+
+static inline u64 cxl_p1_read(struct cxl *cxl, cxl_p1_reg_t reg)
+{
+	return in_be64(_cxl_p1_addr(cxl, reg));
+}
 
 static inline void __iomem *_cxl_p1n_addr(struct cxl_afu *afu, cxl_p1n_reg_t reg)
 {
@@ -548,26 +553,40 @@ static inline void __iomem *_cxl_p1n_addr(struct cxl_afu *afu, cxl_p1n_reg_t reg
 	return afu->p1n_mmio + cxl_reg_off(reg);
 }
 
-#define cxl_p1n_write(afu, reg, val) \
-	out_be64(_cxl_p1n_addr(afu, reg), val)
-#define cxl_p1n_read(afu, reg) \
-	in_be64(_cxl_p1n_addr(afu, reg))
+static inline void cxl_p1n_write(struct cxl_afu *afu, cxl_p1n_reg_t reg, u64 val)
+{
+	out_be64(_cxl_p1n_addr(afu, reg), val);
+}
+
+static inline u64 cxl_p1n_read(struct cxl_afu *afu, cxl_p1n_reg_t reg)
+{
+	return in_be64(_cxl_p1n_addr(afu, reg));
+}
 
 static inline void __iomem *_cxl_p2n_addr(struct cxl_afu *afu, cxl_p2n_reg_t reg)
 {
 	return afu->p2n_mmio + cxl_reg_off(reg);
 }
 
-#define cxl_p2n_write(afu, reg, val) \
-	out_be64(_cxl_p2n_addr(afu, reg), val)
-#define cxl_p2n_read(afu, reg) \
-	in_be64(_cxl_p2n_addr(afu, reg))
+static inline void cxl_p2n_write(struct cxl_afu *afu, cxl_p2n_reg_t reg, u64 val)
+{
+	out_be64(_cxl_p2n_addr(afu, reg), val);
+}
 
+static inline u64 cxl_p2n_read(struct cxl_afu *afu, cxl_p2n_reg_t reg)
+{
+	return in_be64(_cxl_p2n_addr(afu, reg));
+}
 
-#define cxl_afu_cr_read64(afu, cr, off) \
-	in_le64((afu)->afu_desc_mmio + (afu)->crs_offset + ((cr) * (afu)->crs_len) + (off))
-#define cxl_afu_cr_read32(afu, cr, off) \
-	in_le32((afu)->afu_desc_mmio + (afu)->crs_offset + ((cr) * (afu)->crs_len) + (off))
+static inline u64 cxl_afu_cr_read64(struct cxl_afu *afu, int cr, u64 off)
+{
+	return in_le64((afu)->afu_desc_mmio + (afu)->crs_offset + ((cr) * (afu)->crs_len) + (off));
+}
+
+static inline u32 cxl_afu_cr_read32(struct cxl_afu *afu, int cr, u64 off)
+{
+	return in_le32((afu)->afu_desc_mmio + (afu)->crs_offset + ((cr) * (afu)->crs_len) + (off));
+}
 u16 cxl_afu_cr_read16(struct cxl_afu *afu, int cr, u64 off);
 u8 cxl_afu_cr_read8(struct cxl_afu *afu, int cr, u64 off);
 

commit 6f7f0b3df6d49316c6f27390bb5ec250255be548
Author: Michael Neuling <mikey@neuling.org>
Date:   Wed May 27 16:07:18 2015 +1000

    cxl: Add AFU virtual PHB and kernel API
    
    This patch does two things.
    
    Firstly it presents the Accelerator Function Unit (AFUs) behind the POWER
    Service Layer (PSL) as PCI devices on a virtual PCI Host Bridge (vPHB).  This
    in in addition to the PSL being a PCI device itself.
    
    As part of the Coherent Accelerator Interface Architecture (CAIA) AFUs can
    provide an AFU configuration.  This AFU configuration recored is architected to
    be the same as a PCI config space.
    
    This patch sets discovers the AFU configuration records, provides AFU config
    space read/write functions to these configuration records.  It then enumerates
    the PCI bus.  It also hooks in PCI ops where appropriate.  It also destroys the
    vPHB when the physical card is removed.
    
    Secondly, it add an in kernel API for AFU to use CXL.  AFUs must present a
    driver that firstly binds as a PCI device.  This PCI device can then be using
    to do CXL specific operations (that can't sit in the PCI ops) using this API.
    
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Acked-by: Ian Munsie <imunsie@au1.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index 2ec8e96e2de3..4fd66cabde1e 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -378,6 +378,9 @@ struct cxl_afu {
 	int spa_max_procs;
 	unsigned int psl_virq;
 
+	/* pointer to the vphb */
+	struct pci_controller *phb;
+
 	int pp_irqs;
 	int irqs_max;
 	int num_procs;
@@ -671,6 +674,8 @@ int cxl_afu_check_and_enable(struct cxl_afu *afu);
 int cxl_psl_purge(struct cxl_afu *afu);
 
 void cxl_stop_trace(struct cxl *cxl);
+int cxl_pci_vphb_add(struct cxl_afu *afu);
+void cxl_pci_vphb_remove(struct cxl_afu *afu);
 
 extern struct pci_driver cxl_pci_driver;
 int afu_allocate_irqs(struct cxl_context *ctx, u32 count);

commit 0520336afe5de76324c73f793bc40732e5c13359
Author: Michael Neuling <mikey@neuling.org>
Date:   Wed May 27 16:07:17 2015 +1000

    cxl: Export file ops for use by API
    
    The cxl kernel API will allow drivers other than cxl to export a file
    descriptor which has the same userspace API.  These file descriptors will be
    able to be used against libcxl.
    
    This exports those file ops for use by other drivers.
    
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Acked-by: Ian Munsie <imunsie@au1.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index 46d806e3b943..2ec8e96e2de3 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -18,6 +18,7 @@
 #include <linux/pid.h>
 #include <linux/io.h>
 #include <linux/pci.h>
+#include <linux/fs.h>
 #include <asm/cputable.h>
 #include <asm/mmu.h>
 #include <asm/reg.h>
@@ -674,4 +675,12 @@ void cxl_stop_trace(struct cxl *cxl);
 extern struct pci_driver cxl_pci_driver;
 int afu_allocate_irqs(struct cxl_context *ctx, u32 count);
 
+int afu_open(struct inode *inode, struct file *file);
+int afu_release(struct inode *inode, struct file *file);
+long afu_ioctl(struct file *file, unsigned int cmd, unsigned long arg);
+int afu_mmap(struct file *file, struct vm_area_struct *vm);
+unsigned int afu_poll(struct file *file, struct poll_table_struct *poll);
+ssize_t afu_read(struct file *file, char __user *buf, size_t count, loff_t *off);
+extern const struct file_operations afu_fops;
+
 #endif

commit ec249dd860ed88e15b3e2bd363cbfc76ba8c1884
Author: Michael Neuling <mikey@neuling.org>
Date:   Wed May 27 16:07:16 2015 +1000

    cxl: Move include file cxl.h -> cxl-base.h
    
    This moves the current include file from cxl.h -> cxl-base.h.  This current
    include file is used only to pass information between the base driver that
    needs to be built into the kernel and the cxl module.
    
    This is to make way for a new include/misc/cxl.h which will
    contain just the kernel API for other driver to use
    
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Acked-by: Ian Munsie <imunsie@au1.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index 778161afd0a3..46d806e3b943 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -21,7 +21,7 @@
 #include <asm/cputable.h>
 #include <asm/mmu.h>
 #include <asm/reg.h>
-#include <misc/cxl.h>
+#include <misc/cxl-base.h>
 
 #include <uapi/misc/cxl.h>
 

commit c358d84b4e57b060e0287d0c614f8f076d725612
Author: Michael Neuling <mikey@neuling.org>
Date:   Wed May 27 16:07:12 2015 +1000

    cxl: Split afu_register_irqs() function
    
    Split the afu_register_irqs() function so that different parts can
    be useful elsewhere.
    
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Acked-by: Ian Munsie <imunsie@au1.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index eccddfe5d5a3..778161afd0a3 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -672,5 +672,6 @@ int cxl_psl_purge(struct cxl_afu *afu);
 void cxl_stop_trace(struct cxl *cxl);
 
 extern struct pci_driver cxl_pci_driver;
+int afu_allocate_irqs(struct cxl_context *ctx, u32 count);
 
 #endif

commit 1a1a94b876b9159d2b10675d8f680f7bbedc163e
Author: Michael Neuling <mikey@neuling.org>
Date:   Wed May 27 16:07:10 2015 +1000

    cxl: Export some symbols
    
    Export some symbols which will soon be used elsewhere in this driver.
    
    Now they are global we rename them so to avoid collisions.
    
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Acked-by: Ian Munsie <imunsie@au1.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index d6570a7ee4ef..eccddfe5d5a3 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -636,6 +636,9 @@ int cxl_context_init(struct cxl_context *ctx, struct cxl_afu *afu, bool master,
 		     struct address_space *mapping);
 void cxl_context_free(struct cxl_context *ctx);
 int cxl_context_iomap(struct cxl_context *ctx, struct vm_area_struct *vma);
+unsigned int cxl_map_irq(struct cxl *adapter, irq_hw_number_t hwirq,
+			 irq_handler_t handler, void *cookie, const char *name);
+void cxl_unmap_irq(unsigned int virq, void *cookie);
 int __detach_context(struct cxl_context *ctx);
 
 /* This matches the layout of the H_COLLECT_CA_INT_INFO retbuf */
@@ -650,6 +653,7 @@ struct cxl_irq_info {
 	u64 padding[3]; /* to match the expected retbuf size for plpar_hcall9 */
 };
 
+void cxl_assign_psn_space(struct cxl_context *ctx);
 int cxl_attach_process(struct cxl_context *ctx, bool kernel, u64 wed,
 			    u64 amr);
 int cxl_detach_process(struct cxl_context *ctx);
@@ -662,6 +666,7 @@ int cxl_afu_slbia(struct cxl_afu *afu);
 int cxl_tlb_slb_invalidate(struct cxl *adapter);
 int cxl_afu_disable(struct cxl_afu *afu);
 int __cxl_afu_reset(struct cxl_afu *afu);
+int cxl_afu_check_and_enable(struct cxl_afu *afu);
 int cxl_psl_purge(struct cxl_afu *afu);
 
 void cxl_stop_trace(struct cxl *cxl);

commit b12994fbfe9362e3b5ed9f360d3cd6fb34d6645a
Author: Michael Neuling <mikey@neuling.org>
Date:   Wed May 27 16:07:09 2015 +1000

    cxl: cxl_afu_reset() -> __cxl_afu_reset()
    
    Rename cxl_afu_reset() to __cxl_afu_reset() to we can reuse this function name
    in the API.
    
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Acked-by: Ian Munsie <imunsie@au1.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index 7b7509c79e11..d6570a7ee4ef 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -661,7 +661,7 @@ int cxl_check_error(struct cxl_afu *afu);
 int cxl_afu_slbia(struct cxl_afu *afu);
 int cxl_tlb_slb_invalidate(struct cxl *adapter);
 int cxl_afu_disable(struct cxl_afu *afu);
-int cxl_afu_reset(struct cxl_afu *afu);
+int __cxl_afu_reset(struct cxl_afu *afu);
 int cxl_psl_purge(struct cxl_afu *afu);
 
 void cxl_stop_trace(struct cxl *cxl);

commit eda3693c842ed169af66af943554c648633769d0
Author: Michael Neuling <mikey@neuling.org>
Date:   Wed May 27 16:07:08 2015 +1000

    cxl: Rework detach context functions
    
    Rework __detach_context() and cxl_context_detach() so we can reuse them in the
    kernel API.
    
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Acked-by: Ian Munsie <imunsie@au1.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index a4dadc5b5dd7..7b7509c79e11 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -636,6 +636,7 @@ int cxl_context_init(struct cxl_context *ctx, struct cxl_afu *afu, bool master,
 		     struct address_space *mapping);
 void cxl_context_free(struct cxl_context *ctx);
 int cxl_context_iomap(struct cxl_context *ctx, struct vm_area_struct *vma);
+int __detach_context(struct cxl_context *ctx);
 
 /* This matches the layout of the H_COLLECT_CA_INT_INFO retbuf */
 struct cxl_irq_info {

commit 6428832a7bfae73345706d63a228a6ce60af0081
Author: Michael Neuling <mikey@neuling.org>
Date:   Wed May 27 16:07:07 2015 +1000

    cxl: Add cookie parameter to afu_release_irqs()
    
    Add cookie parameter to afu_release_irqs() so that we can pass in a different
    cookie than the context structure.  This will be useful for other kernel
    drivers that want to call this but get their own cookie back in the interrupt
    handler.
    
    Update all existing call sites.
    
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Acked-by: Ian Munsie <imunsie@au1.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index b361b48d1b01..a4dadc5b5dd7 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -613,7 +613,7 @@ void cxl_release_psl_err_irq(struct cxl *adapter);
 int cxl_register_serr_irq(struct cxl_afu *afu);
 void cxl_release_serr_irq(struct cxl_afu *afu);
 int afu_register_irqs(struct cxl_context *ctx, u32 count);
-void afu_release_irqs(struct cxl_context *ctx);
+void afu_release_irqs(struct cxl_context *ctx, void *cookie);
 irqreturn_t cxl_slice_irq_err(int irq, void *data);
 
 int cxl_debugfs_init(void);

commit 8ac75b96be71e20ec1785ca18170890c4dfffe87
Author: Ian Munsie <imunsie@au1.ibm.com>
Date:   Fri May 8 22:55:18 2015 +1000

    cxl: Use call_rcu to reduce latency when releasing the afu fd
    
    The afu fd release path was identified as a significant bottleneck in
    the overall performance of cxl. While an optimal AFU design would
    minimise the need to close & reopen the AFU fd, it is not always
    practical to avoid.
    
    The bottleneck seems to be down to the call to synchronize_rcu(), which
    will block until every other thread is guaranteed to be out of an RCU
    critical section. Replace it with call_rcu() to free the context
    structures later so we can return to the application sooner.
    
    This reduces the time spent in the fd release path from 13356 usec to
    13.3 usec - about a 100x speed up.
    
    Reported-by: Fei K Chen <uchen@cn.ibm.com>
    Signed-off-by: Ian Munsie <imunsie@au1.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index cfee819bf5d4..b361b48d1b01 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -457,6 +457,8 @@ struct cxl_context {
 	bool pending_irq;
 	bool pending_fault;
 	bool pending_afu_err;
+
+	struct rcu_head rcu;
 };
 
 struct cxl {

commit e36f6fe1f7aa4238478d4b253aac7d3fcfff6ee0
Author: Vaibhav Jain <vaibhav@linux.vnet.ibm.com>
Date:   Fri May 22 10:56:05 2015 +0530

    cxl: Export AFU error buffer via sysfs
    
    Export the "AFU Error Buffer" via sysfs attribute (afu_err_buf). AFU
    error buffer is used by the AFU to report application specific
    errors. The contents of this buffer are AFU specific and are intended to
    be interpreted by the application interacting with the afu.
    
    Suggested-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Vaibhav Jain <vaibhav@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index 9f280e3e742e..cfee819bf5d4 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -360,6 +360,10 @@ struct cxl_afu {
 	struct mutex spa_mutex;
 	spinlock_t afu_cntl_lock;
 
+	/* AFU error buffer fields and bin attribute for sysfs */
+	u64 eb_len, eb_offset;
+	struct bin_attribute attr_eb;
+
 	/*
 	 * Only the first part of the SPA is used for the process element
 	 * linked list. The only other part that software needs to worry about
@@ -561,6 +565,9 @@ static inline void __iomem *_cxl_p2n_addr(struct cxl_afu *afu, cxl_p2n_reg_t reg
 u16 cxl_afu_cr_read16(struct cxl_afu *afu, int cr, u64 off);
 u8 cxl_afu_cr_read8(struct cxl_afu *afu, int cr, u64 off);
 
+ssize_t cxl_afu_read_err_buffer(struct cxl_afu *afu, char *buf,
+				loff_t off, size_t count);
+
 
 struct cxl_calls {
 	void (*cxl_slbia)(struct mm_struct *mm);

commit 27d4dc7116eed98775902627ba61b70e9045e321
Author: Vaibhav Jain <vaibhav@linux.vnet.ibm.com>
Date:   Wed Apr 29 15:47:23 2015 +0530

    cxl: Implement an ioctl to fetch afu card-id, offset-id and mode
    
    Given a file descriptor on an afu device, libcxl currently uses the
    major/minor number obtained from fstat on the fd to construct path to
    the afu's sysfs directory. However it is possible that rather than using
    one of the device in /dev/cxl, a kernel driver creates its own device
    which export generic cxl interface to the userspace. This causes
    problems with libcxl as it tries to use a wrong major/minor number to
    construct the sysfs path and fail.
    
    So this patch introduces a new ioctl called CXL_IOCTL_GET_AFU_ID on the
    afu file descriptor to fetch the cxl_afu_id struct that holds the
    card/offset-id and mode information. These info is then used by libcxl to
    construct the correct path to the afu sysfs directory.
    
    Testing:
            - Build against pseries be/le configs
            - Testing with corresponding libcxl changes to verify that it constructs
              right sysfs path to the afu.
    
    Signed-off-by: Vaibhav Jain <vaibhav@linux.vnet.ibm.com>
    Acked-by: Ian Munsie <imunsie@au1.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index a1cee4767ec6..9f280e3e742e 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -315,8 +315,6 @@ static const cxl_p2n_reg_t CXL_PSL_WED_An     = {0x0A0};
 #define CXL_MAX_SLICES 4
 #define MAX_AFU_MMIO_REGS 3
 
-#define CXL_MODE_DEDICATED   0x1
-#define CXL_MODE_DIRECTED    0x2
 #define CXL_MODE_TIME_SLICED 0x4
 #define CXL_SUPPORTED_MODES (CXL_MODE_DEDICATED | CXL_MODE_DIRECTED)
 

commit b087e6190ddcd9ae4e8ff2c788d2b32f193e946b
Author: Ian Munsie <imunsie@au1.ibm.com>
Date:   Wed Feb 4 19:09:01 2015 +1100

    cxl: Export optional AFU configuration record in sysfs
    
    An AFU may optionally contain one or more PCIe like configuration
    records, which can be used to identify the AFU.
    
    This patch adds support for exposing the raw config space and the
    vendor, device and class code under sysfs. These will appear in a
    subdirectory of the AFU device corresponding with the configuration
    record number, e.g.
    
    cat /sys/class/cxl/afu0.0/cr0/vendor
    0x1014
    
    cat /sys/class/cxl/afu0.0/cr0/device
    0x4350
    
    cat /sys/class/cxl/afu0.0/cr0/class
    0x120000
    
    hexdump -C /sys/class/cxl/afu0.0/cr0/config
    00000000  14 10 50 43 00 00 00 00  06 00 00 12 00 00 00 00  |..PC............|
    00000010  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
    *
    00000100
    
    These files behave in much the same way as the equivalent files for PCI
    devices, with one exception being that the config file is currently
    read-only and restricted to the root user. It is not necessarily
    required to be this strict, but we currently do not have a compelling
    use-case to make it writable and/or world-readable, so I erred on the
    side of being restrictive.
    
    Signed-off-by: Ian Munsie <imunsie@au1.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index 6a6a487464c5..a1cee4767ec6 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -382,6 +382,10 @@ struct cxl_afu {
 	int slice;
 	int modes_supported;
 	int current_mode;
+	int crs_num;
+	u64 crs_len;
+	u64 crs_offset;
+	struct list_head crs;
 	enum prefault_modes prefault_mode;
 	bool psa;
 	bool pp_psa;
@@ -551,6 +555,15 @@ static inline void __iomem *_cxl_p2n_addr(struct cxl_afu *afu, cxl_p2n_reg_t reg
 #define cxl_p2n_read(afu, reg) \
 	in_be64(_cxl_p2n_addr(afu, reg))
 
+
+#define cxl_afu_cr_read64(afu, cr, off) \
+	in_le64((afu)->afu_desc_mmio + (afu)->crs_offset + ((cr) * (afu)->crs_len) + (off))
+#define cxl_afu_cr_read32(afu, cr, off) \
+	in_le32((afu)->afu_desc_mmio + (afu)->crs_offset + ((cr) * (afu)->crs_len) + (off))
+u16 cxl_afu_cr_read16(struct cxl_afu *afu, int cr, u64 off);
+u8 cxl_afu_cr_read8(struct cxl_afu *afu, int cr, u64 off);
+
+
 struct cxl_calls {
 	void (*cxl_slbia)(struct mm_struct *mm);
 	struct module *owner;

commit 62fa19d4b4fd781ad37c9155c6332f28a9e97a2c
Author: Ryan Grimm <grimm@linux.vnet.ibm.com>
Date:   Mon Jan 19 11:52:51 2015 -0600

    cxl: Add ability to reset the card
    
    Adds reset to sysfs which will PERST the card. If load_image_on_perst is set
    to "user" or "factory", the PERST will cause that image to be loaded.
    
    load_image_on_perst is set to "user" for production.
    
    "none" could be used for debugging. The PSL trace arrays are preserved which
    then can be read through debugfs.
    
    PERST also triggers CAPP recovery. An HMI comes in, which is handled by EEH.
    EEH unbinds the driver, calls into Sapphire to reinitialize the PHB, then
    rebinds the driver.
    
    Signed-off-by: Ryan Grimm <grimm@linux.vnet.ibm.com>
    Acked-by: Ian Munsie <imunsie@au1.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index 518c4c6e6151..6a6a487464c5 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -489,6 +489,7 @@ int cxl_alloc_irq_ranges(struct cxl_irq_ranges *irqs, struct cxl *adapter, unsig
 void cxl_release_irq_ranges(struct cxl_irq_ranges *irqs, struct cxl *adapter);
 int cxl_setup_irq(struct cxl *adapter, unsigned int hwirq, unsigned int virq);
 int cxl_update_image_control(struct cxl *adapter);
+int cxl_reset(struct cxl *adapter);
 
 /* common == phyp + powernv */
 struct cxl_process_element_common {

commit 4beb5421babee1204757b877622830c6aa31be6d
Author: Ryan Grimm <grimm@linux.vnet.ibm.com>
Date:   Mon Jan 19 11:52:48 2015 -0600

    cxl: Use image state defaults for reloading FPGA
    
    Select defaults such that a PERST causes flash image reload.  Select which
    image based on what the card is set up to load.
    
    CXL_VSEC_PERST_LOADS_IMAGE selects whether PERST assertion causes flash image
    load.
    
    CXL_VSEC_PERST_SELECT_USER selects which image is loaded on the next PERST.
    
    cxl_update_image_control writes these bits into the VSEC.
    
    Signed-off-by: Ryan Grimm <grimm@linux.vnet.ibm.com>
    Acked-by: Ian Munsie <imunsie@au1.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index 0df04380bfd6..518c4c6e6151 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -488,6 +488,7 @@ void cxl_release_one_irq(struct cxl *adapter, int hwirq);
 int cxl_alloc_irq_ranges(struct cxl_irq_ranges *irqs, struct cxl *adapter, unsigned int num);
 void cxl_release_irq_ranges(struct cxl_irq_ranges *irqs, struct cxl *adapter);
 int cxl_setup_irq(struct cxl *adapter, unsigned int hwirq, unsigned int virq);
+int cxl_update_image_control(struct cxl *adapter);
 
 /* common == phyp + powernv */
 struct cxl_process_element_common {

commit d6a6af2c181400aade59417e698c7cd9bec8804e
Author: Ian Munsie <imunsie@au1.ibm.com>
Date:   Mon Dec 8 19:17:59 2014 +1100

    cxl: Disable AFU debug flag
    
    Upon inspection of the implementation specific registers, it was
    discovered that the high bit of the implementation specific RXCTL
    register was enabled, which enables the DEADB00F debug feature.
    
    The debug feature causes MMIO reads to a disabled AFU to respond with
    0xDEADB00F instead of all Fs. In general this should not be visible as
    the kernel will only allow MMIO access to enabled AFUs, but there may be
    some circumstances where an AFU may become disabled while it is use.
    One such case would be an AFU designed to only be used in the dedicated
    process mode and to disable itself after it has completed it's work
    (however even in that case the effects of this debug flag would be
    limited as the userspace application must have completed any required
    MMIO accesses before the AFU disables itself with or without the flag).
    
    This patch removes the debug flag and replaces the magic value
    programmed into this register with a preprocessor define so it is
    clearer what the rest of this initialisation does.
    
    Signed-off-by: Ian Munsie <imunsie@au1.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index 28078f8894a5..0df04380bfd6 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -287,6 +287,13 @@ static const cxl_p2n_reg_t CXL_PSL_WED_An     = {0x0A0};
 #define CXL_PE_SOFTWARE_STATE_S (1ul << (31 - 30)) /* Suspend */
 #define CXL_PE_SOFTWARE_STATE_T (1ul << (31 - 31)) /* Terminate */
 
+/****** CXL_PSL_RXCTL_An (Implementation Specific) **************************
+ * Controls AFU Hang Pulse, which sets the timeout for the AFU to respond to
+ * the PSL for any response (except MMIO). Timeouts will occur between 1x to 2x
+ * of the hang pulse frequency.
+ */
+#define CXL_PSL_RXCTL_AFUHP_4S      0x7000000000000000ULL
+
 /* SPA->sw_command_status */
 #define CXL_SPA_SW_CMD_MASK         0xffff000000000000ULL
 #define CXL_SPA_SW_CMD_TERMINATE    0x0001000000000000ULL

commit b123429e6a9e8d03aacf888d23262835f0081448
Author: Ian Munsie <imunsie@au1.ibm.com>
Date:   Mon Dec 8 19:18:01 2014 +1100

    cxl: Unmap MMIO regions when detaching a context
    
    If we need to force detach a context (e.g. due to EEH or simply force
    unbinding the driver) we should prevent the userspace contexts from
    being able to access the Problem State Area MMIO region further, which
    they may have mapped with mmap().
    
    This patch unmaps any mapped MMIO regions when detaching a userspace
    context.
    
    Cc: stable@vger.kernel.org
    Signed-off-by: Ian Munsie <imunsie@au1.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index 7c05239359df..28078f8894a5 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -398,6 +398,10 @@ struct cxl_context {
 	phys_addr_t psn_phys;
 	u64 psn_size;
 
+	/* Used to unmap any mmaps when force detaching */
+	struct address_space *mapping;
+	struct mutex mapping_lock;
+
 	spinlock_t sste_lock; /* Protects segment table entries */
 	struct cxl_sste *sstp;
 	u64 sstp0, sstp1;
@@ -599,7 +603,8 @@ int cxl_alloc_sst(struct cxl_context *ctx);
 void init_cxl_native(void);
 
 struct cxl_context *cxl_context_alloc(void);
-int cxl_context_init(struct cxl_context *ctx, struct cxl_afu *afu, bool master);
+int cxl_context_init(struct cxl_context *ctx, struct cxl_afu *afu, bool master,
+		     struct address_space *mapping);
 void cxl_context_free(struct cxl_context *ctx);
 int cxl_context_iomap(struct cxl_context *ctx, struct vm_area_struct *vma);
 

commit ee41d11d53c8fc4968f0816504651541d606cf40
Author: Ian Munsie <imunsie@au1.ibm.com>
Date:   Mon Dec 8 19:17:55 2014 +1100

    cxl: Change contexts_lock to a mutex to fix sleep while atomic bug
    
    We had a known sleep while atomic bug if a CXL device was forcefully
    unbound while it was in use. This could occur as a result of EEH, or
    manually induced with something like this while the device was in use:
    
    echo 0000:01:00.0 > /sys/bus/pci/drivers/cxl-pci/unbind
    
    The issue was that in this code path we iterated over each context and
    forcefully detached it with the contexts_lock spin lock held, however
    the detach also needed to take the spu_mutex, and call schedule.
    
    This patch changes the contexts_lock to a mutex so that we are not in
    atomic context while doing the detach, thereby avoiding the sleep while
    atomic.
    
    Also delete the related TODO comment, which suggested an alternate
    solution which turned out to not be workable.
    
    Cc: stable@vger.kernel.org
    Signed-off-by: Ian Munsie <imunsie@au1.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index b5b6bda44a00..7c05239359df 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -351,7 +351,7 @@ struct cxl_afu {
 	struct device *chardev_s, *chardev_m, *chardev_d;
 	struct idr contexts_idr;
 	struct dentry *debugfs;
-	spinlock_t contexts_lock;
+	struct mutex contexts_lock;
 	struct mutex spa_mutex;
 	spinlock_t afu_cntl_lock;
 

commit 80fa93fce37d3490f4bb0da8a5b239a6745bc744
Author: Michael Neuling <mikey@neuling.org>
Date:   Fri Nov 14 18:09:28 2014 +1100

    cxl: Name interrupts in /proc/interrupt
    
    Currently all interrupts generated by cxl are named "cxl".  This is not very
    informative as we can't distinguish between cards, AFUs, error interrupts, user
    contexts and user interrupts numbers.  Being able to distinguish them is useful
    for setting affinity.
    
    This patch gives each of these names in /proc/interrupts.
    
    A two card CAPI system, with afu0.0 having 2 active contexts each with 4 user
    IRQs each, will now look like this:
    
        % grep cxl /proc/interrupts
        444:          0  OPAL ICS 141312 Level     cxl-card1-err
        445:          0  OPAL ICS 141313 Level     cxl-afu1.0-err
        446:          0  OPAL ICS 141314 Level     cxl-afu1.0
        462:          0  OPAL ICS 2052 Level     cxl-afu0.0-pe0-1
        463:      75517  OPAL ICS 2053 Level     cxl-afu0.0-pe0-2
        468:          0  OPAL ICS 2054 Level     cxl-afu0.0-pe0-3
        469:          0  OPAL ICS 2055 Level     cxl-afu0.0-pe0-4
        470:          0  OPAL ICS 2056 Level     cxl-afu0.0-pe1-1
        471:      75506  OPAL ICS 2057 Level     cxl-afu0.0-pe1-2
        472:          0  OPAL ICS 2058 Level     cxl-afu0.0-pe1-3
        473:          0  OPAL ICS 2059 Level     cxl-afu0.0-pe1-4
        502:       1066  OPAL ICS 2050 Level     cxl-afu0.0
        514:          0  OPAL ICS 2048 Level     cxl-card0-err
        515:          0  OPAL ICS 2049 Level     cxl-afu0.0-err
    
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Ian Munsie <imunsie@au1.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index 64a4aa3a5c5d..b5b6bda44a00 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -336,6 +336,8 @@ struct cxl_sste {
 struct cxl_afu {
 	irq_hw_number_t psl_hwirq;
 	irq_hw_number_t serr_hwirq;
+	char *err_irq_name;
+	char *psl_irq_name;
 	unsigned int serr_virq;
 	void __iomem *p1n_mmio;
 	void __iomem *p2n_mmio;
@@ -379,6 +381,12 @@ struct cxl_afu {
 	bool enabled;
 };
 
+
+struct cxl_irq_name {
+	struct list_head list;
+	char *name;
+};
+
 /*
  * This is a cxl context.  If the PSL is in dedicated mode, there will be one
  * of these per AFU.  If in AFU directed there can be lots of these.
@@ -403,6 +411,7 @@ struct cxl_context {
 
 	unsigned long *irq_bitmap; /* Accessed from IRQ context */
 	struct cxl_irq_ranges irqs;
+	struct list_head irq_names;
 	u64 fault_addr;
 	u64 fault_dsisr;
 	u64 afu_err;
@@ -444,6 +453,7 @@ struct cxl {
 	struct dentry *trace;
 	struct dentry *psl_err_chk;
 	struct dentry *debugfs;
+	char *irq_name;
 	struct bin_attribute cxl_attr;
 	int adapter_num;
 	int user_irqs;
@@ -563,9 +573,6 @@ int _cxl_afu_deactivate_mode(struct cxl_afu *afu, int mode);
 int cxl_afu_deactivate_mode(struct cxl_afu *afu);
 int cxl_afu_select_best_mode(struct cxl_afu *afu);
 
-unsigned int cxl_map_irq(struct cxl *adapter, irq_hw_number_t hwirq,
-		         irq_handler_t handler, void *cookie);
-void cxl_unmap_irq(unsigned int virq, void *cookie);
 int cxl_register_psl_irq(struct cxl_afu *afu);
 void cxl_release_psl_irq(struct cxl_afu *afu);
 int cxl_register_psl_err_irq(struct cxl *adapter);

commit bc78b05bb412fad135715551fc536ca511a3cff2
Author: Ian Munsie <imunsie@au1.ibm.com>
Date:   Fri Nov 14 17:37:50 2014 +1100

    cxl: Return error to PSL if IRQ demultiplexing fails & print clearer warning
    
    If an AFU has a hardware bug that causes it to acknowledge a context
    terminate or remove while that context has outstanding transactions, it
    is possible for the kernel to receive an interrupt for that context
    after we have removed it from the context list.
    
    The kernel will not be able to demultiplex the interrupt (or worse - if
    we have already reallocated the process handle we could mis-attribute it
    to the new context), and printed a big scary warning.
    
    It did not acknowledge the interrupt, which would effectively halt
    further translation fault processing on the PSL.
    
    This patch makes the warning clearer about the likely cause of the issue
    (i.e. hardware bug) to make it obvious to future AFU designers of what
    needs to be fixed. It also prints out the process handle which can then
    be matched up with hardware and software traces for debugging.
    
    It also acknowledges the interrupt to the PSL with either an address
    error or acknowledge, so that the PSL can continue with other
    translations.
    
    Signed-off-by: Ian Munsie <imunsie@au1.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
index 3d2b8677ec8a..64a4aa3a5c5d 100644
--- a/drivers/misc/cxl/cxl.h
+++ b/drivers/misc/cxl/cxl.h
@@ -612,7 +612,7 @@ int cxl_attach_process(struct cxl_context *ctx, bool kernel, u64 wed,
 			    u64 amr);
 int cxl_detach_process(struct cxl_context *ctx);
 
-int cxl_get_irq(struct cxl_context *ctx, struct cxl_irq_info *info);
+int cxl_get_irq(struct cxl_afu *afu, struct cxl_irq_info *info);
 int cxl_ack_irq(struct cxl_context *ctx, u64 tfc, u64 psl_reset_mask);
 
 int cxl_check_error(struct cxl_afu *afu);

commit f204e0b8cedd7da1dfcfd05ed6b7692737e24029
Author: Ian Munsie <imunsie@au1.ibm.com>
Date:   Wed Oct 8 19:55:02 2014 +1100

    cxl: Driver code for powernv PCIe based cards for userspace access
    
    This is the core of the cxl driver.
    
    It adds support for using cxl cards in the powernv environment only (ie POWER8
    bare metal). It allows access to cxl accelerators by userspace using the
    /dev/cxl/afuM.N char devices.
    
    The kernel driver has no knowledge of the function implemented by the
    accelerator. It provides services to userspace via the /dev/cxl/afuM.N
    devices. When a program opens this device and runs the start work IOCTL, the
    accelerator will have coherent access to that processes memory using the same
    virtual addresses. That process may mmap the device to access any MMIO space
    the accelerator provides.  Also, reads on the device will allow interrupts to
    be received. These services are further documented in a later patch in
    Documentation/powerpc/cxl.txt.
    
    Documentation of the cxl hardware architecture and userspace API is provided in
    subsequent patches.
    
    Signed-off-by: Ian Munsie <imunsie@au1.ibm.com>
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h
new file mode 100644
index 000000000000..3d2b8677ec8a
--- /dev/null
+++ b/drivers/misc/cxl/cxl.h
@@ -0,0 +1,629 @@
+/*
+ * Copyright 2014 IBM Corp.
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; either version
+ * 2 of the License, or (at your option) any later version.
+ */
+
+#ifndef _CXL_H_
+#define _CXL_H_
+
+#include <linux/interrupt.h>
+#include <linux/semaphore.h>
+#include <linux/device.h>
+#include <linux/types.h>
+#include <linux/cdev.h>
+#include <linux/pid.h>
+#include <linux/io.h>
+#include <linux/pci.h>
+#include <asm/cputable.h>
+#include <asm/mmu.h>
+#include <asm/reg.h>
+#include <misc/cxl.h>
+
+#include <uapi/misc/cxl.h>
+
+extern uint cxl_verbose;
+
+#define CXL_TIMEOUT 5
+
+/*
+ * Bump version each time a user API change is made, whether it is
+ * backwards compatible ot not.
+ */
+#define CXL_API_VERSION 1
+#define CXL_API_VERSION_COMPATIBLE 1
+
+/*
+ * Opaque types to avoid accidentally passing registers for the wrong MMIO
+ *
+ * At the end of the day, I'm not married to using typedef here, but it might
+ * (and has!) help avoid bugs like mixing up CXL_PSL_CtxTime and
+ * CXL_PSL_CtxTime_An, or calling cxl_p1n_write instead of cxl_p1_write.
+ *
+ * I'm quite happy if these are changed back to #defines before upstreaming, it
+ * should be little more than a regexp search+replace operation in this file.
+ */
+typedef struct {
+	const int x;
+} cxl_p1_reg_t;
+typedef struct {
+	const int x;
+} cxl_p1n_reg_t;
+typedef struct {
+	const int x;
+} cxl_p2n_reg_t;
+#define cxl_reg_off(reg) \
+	(reg.x)
+
+/* Memory maps. Ref CXL Appendix A */
+
+/* PSL Privilege 1 Memory Map */
+/* Configuration and Control area */
+static const cxl_p1_reg_t CXL_PSL_CtxTime = {0x0000};
+static const cxl_p1_reg_t CXL_PSL_ErrIVTE = {0x0008};
+static const cxl_p1_reg_t CXL_PSL_KEY1    = {0x0010};
+static const cxl_p1_reg_t CXL_PSL_KEY2    = {0x0018};
+static const cxl_p1_reg_t CXL_PSL_Control = {0x0020};
+/* Downloading */
+static const cxl_p1_reg_t CXL_PSL_DLCNTL  = {0x0060};
+static const cxl_p1_reg_t CXL_PSL_DLADDR  = {0x0068};
+
+/* PSL Lookaside Buffer Management Area */
+static const cxl_p1_reg_t CXL_PSL_LBISEL  = {0x0080};
+static const cxl_p1_reg_t CXL_PSL_SLBIE   = {0x0088};
+static const cxl_p1_reg_t CXL_PSL_SLBIA   = {0x0090};
+static const cxl_p1_reg_t CXL_PSL_TLBIE   = {0x00A0};
+static const cxl_p1_reg_t CXL_PSL_TLBIA   = {0x00A8};
+static const cxl_p1_reg_t CXL_PSL_AFUSEL  = {0x00B0};
+
+/* 0x00C0:7EFF Implementation dependent area */
+static const cxl_p1_reg_t CXL_PSL_FIR1      = {0x0100};
+static const cxl_p1_reg_t CXL_PSL_FIR2      = {0x0108};
+static const cxl_p1_reg_t CXL_PSL_VERSION   = {0x0118};
+static const cxl_p1_reg_t CXL_PSL_RESLCKTO  = {0x0128};
+static const cxl_p1_reg_t CXL_PSL_FIR_CNTL  = {0x0148};
+static const cxl_p1_reg_t CXL_PSL_DSNDCTL   = {0x0150};
+static const cxl_p1_reg_t CXL_PSL_SNWRALLOC = {0x0158};
+static const cxl_p1_reg_t CXL_PSL_TRACE     = {0x0170};
+/* 0x7F00:7FFF Reserved PCIe MSI-X Pending Bit Array area */
+/* 0x8000:FFFF Reserved PCIe MSI-X Table Area */
+
+/* PSL Slice Privilege 1 Memory Map */
+/* Configuration Area */
+static const cxl_p1n_reg_t CXL_PSL_SR_An          = {0x00};
+static const cxl_p1n_reg_t CXL_PSL_LPID_An        = {0x08};
+static const cxl_p1n_reg_t CXL_PSL_AMBAR_An       = {0x10};
+static const cxl_p1n_reg_t CXL_PSL_SPOffset_An    = {0x18};
+static const cxl_p1n_reg_t CXL_PSL_ID_An          = {0x20};
+static const cxl_p1n_reg_t CXL_PSL_SERR_An        = {0x28};
+/* Memory Management and Lookaside Buffer Management */
+static const cxl_p1n_reg_t CXL_PSL_SDR_An         = {0x30};
+static const cxl_p1n_reg_t CXL_PSL_AMOR_An        = {0x38};
+/* Pointer Area */
+static const cxl_p1n_reg_t CXL_HAURP_An           = {0x80};
+static const cxl_p1n_reg_t CXL_PSL_SPAP_An        = {0x88};
+static const cxl_p1n_reg_t CXL_PSL_LLCMD_An       = {0x90};
+/* Control Area */
+static const cxl_p1n_reg_t CXL_PSL_SCNTL_An       = {0xA0};
+static const cxl_p1n_reg_t CXL_PSL_CtxTime_An     = {0xA8};
+static const cxl_p1n_reg_t CXL_PSL_IVTE_Offset_An = {0xB0};
+static const cxl_p1n_reg_t CXL_PSL_IVTE_Limit_An  = {0xB8};
+/* 0xC0:FF Implementation Dependent Area */
+static const cxl_p1n_reg_t CXL_PSL_FIR_SLICE_An   = {0xC0};
+static const cxl_p1n_reg_t CXL_AFU_DEBUG_An       = {0xC8};
+static const cxl_p1n_reg_t CXL_PSL_APCALLOC_A     = {0xD0};
+static const cxl_p1n_reg_t CXL_PSL_COALLOC_A      = {0xD8};
+static const cxl_p1n_reg_t CXL_PSL_RXCTL_A        = {0xE0};
+static const cxl_p1n_reg_t CXL_PSL_SLICE_TRACE    = {0xE8};
+
+/* PSL Slice Privilege 2 Memory Map */
+/* Configuration and Control Area */
+static const cxl_p2n_reg_t CXL_PSL_PID_TID_An = {0x000};
+static const cxl_p2n_reg_t CXL_CSRP_An        = {0x008};
+static const cxl_p2n_reg_t CXL_AURP0_An       = {0x010};
+static const cxl_p2n_reg_t CXL_AURP1_An       = {0x018};
+static const cxl_p2n_reg_t CXL_SSTP0_An       = {0x020};
+static const cxl_p2n_reg_t CXL_SSTP1_An       = {0x028};
+static const cxl_p2n_reg_t CXL_PSL_AMR_An     = {0x030};
+/* Segment Lookaside Buffer Management */
+static const cxl_p2n_reg_t CXL_SLBIE_An       = {0x040};
+static const cxl_p2n_reg_t CXL_SLBIA_An       = {0x048};
+static const cxl_p2n_reg_t CXL_SLBI_Select_An = {0x050};
+/* Interrupt Registers */
+static const cxl_p2n_reg_t CXL_PSL_DSISR_An   = {0x060};
+static const cxl_p2n_reg_t CXL_PSL_DAR_An     = {0x068};
+static const cxl_p2n_reg_t CXL_PSL_DSR_An     = {0x070};
+static const cxl_p2n_reg_t CXL_PSL_TFC_An     = {0x078};
+static const cxl_p2n_reg_t CXL_PSL_PEHandle_An = {0x080};
+static const cxl_p2n_reg_t CXL_PSL_ErrStat_An = {0x088};
+/* AFU Registers */
+static const cxl_p2n_reg_t CXL_AFU_Cntl_An    = {0x090};
+static const cxl_p2n_reg_t CXL_AFU_ERR_An     = {0x098};
+/* Work Element Descriptor */
+static const cxl_p2n_reg_t CXL_PSL_WED_An     = {0x0A0};
+/* 0x0C0:FFF Implementation Dependent Area */
+
+#define CXL_PSL_SPAP_Addr 0x0ffffffffffff000ULL
+#define CXL_PSL_SPAP_Size 0x0000000000000ff0ULL
+#define CXL_PSL_SPAP_Size_Shift 4
+#define CXL_PSL_SPAP_V    0x0000000000000001ULL
+
+/****** CXL_PSL_DLCNTL *****************************************************/
+#define CXL_PSL_DLCNTL_D (0x1ull << (63-28))
+#define CXL_PSL_DLCNTL_C (0x1ull << (63-29))
+#define CXL_PSL_DLCNTL_E (0x1ull << (63-30))
+#define CXL_PSL_DLCNTL_S (0x1ull << (63-31))
+#define CXL_PSL_DLCNTL_CE (CXL_PSL_DLCNTL_C | CXL_PSL_DLCNTL_E)
+#define CXL_PSL_DLCNTL_DCES (CXL_PSL_DLCNTL_D | CXL_PSL_DLCNTL_CE | CXL_PSL_DLCNTL_S)
+
+/****** CXL_PSL_SR_An ******************************************************/
+#define CXL_PSL_SR_An_SF  MSR_SF            /* 64bit */
+#define CXL_PSL_SR_An_TA  (1ull << (63-1))  /* Tags active,   GA1: 0 */
+#define CXL_PSL_SR_An_HV  MSR_HV            /* Hypervisor,    GA1: 0 */
+#define CXL_PSL_SR_An_PR  MSR_PR            /* Problem state, GA1: 1 */
+#define CXL_PSL_SR_An_ISL (1ull << (63-53)) /* Ignore Segment Large Page */
+#define CXL_PSL_SR_An_TC  (1ull << (63-54)) /* Page Table secondary hash */
+#define CXL_PSL_SR_An_US  (1ull << (63-56)) /* User state,    GA1: X */
+#define CXL_PSL_SR_An_SC  (1ull << (63-58)) /* Segment Table secondary hash */
+#define CXL_PSL_SR_An_R   MSR_DR            /* Relocate,      GA1: 1 */
+#define CXL_PSL_SR_An_MP  (1ull << (63-62)) /* Master Process */
+#define CXL_PSL_SR_An_LE  (1ull << (63-63)) /* Little Endian */
+
+/****** CXL_PSL_LLCMD_An ****************************************************/
+#define CXL_LLCMD_TERMINATE   0x0001000000000000ULL
+#define CXL_LLCMD_REMOVE      0x0002000000000000ULL
+#define CXL_LLCMD_SUSPEND     0x0003000000000000ULL
+#define CXL_LLCMD_RESUME      0x0004000000000000ULL
+#define CXL_LLCMD_ADD         0x0005000000000000ULL
+#define CXL_LLCMD_UPDATE      0x0006000000000000ULL
+#define CXL_LLCMD_HANDLE_MASK 0x000000000000ffffULL
+
+/****** CXL_PSL_ID_An ****************************************************/
+#define CXL_PSL_ID_An_F	(1ull << (63-31))
+#define CXL_PSL_ID_An_L	(1ull << (63-30))
+
+/****** CXL_PSL_SCNTL_An ****************************************************/
+#define CXL_PSL_SCNTL_An_CR          (0x1ull << (63-15))
+/* Programming Modes: */
+#define CXL_PSL_SCNTL_An_PM_MASK     (0xffffull << (63-31))
+#define CXL_PSL_SCNTL_An_PM_Shared   (0x0000ull << (63-31))
+#define CXL_PSL_SCNTL_An_PM_OS       (0x0001ull << (63-31))
+#define CXL_PSL_SCNTL_An_PM_Process  (0x0002ull << (63-31))
+#define CXL_PSL_SCNTL_An_PM_AFU      (0x0004ull << (63-31))
+#define CXL_PSL_SCNTL_An_PM_AFU_PBT  (0x0104ull << (63-31))
+/* Purge Status (ro) */
+#define CXL_PSL_SCNTL_An_Ps_MASK     (0x3ull << (63-39))
+#define CXL_PSL_SCNTL_An_Ps_Pending  (0x1ull << (63-39))
+#define CXL_PSL_SCNTL_An_Ps_Complete (0x3ull << (63-39))
+/* Purge */
+#define CXL_PSL_SCNTL_An_Pc          (0x1ull << (63-48))
+/* Suspend Status (ro) */
+#define CXL_PSL_SCNTL_An_Ss_MASK     (0x3ull << (63-55))
+#define CXL_PSL_SCNTL_An_Ss_Pending  (0x1ull << (63-55))
+#define CXL_PSL_SCNTL_An_Ss_Complete (0x3ull << (63-55))
+/* Suspend Control */
+#define CXL_PSL_SCNTL_An_Sc          (0x1ull << (63-63))
+
+/* AFU Slice Enable Status (ro) */
+#define CXL_AFU_Cntl_An_ES_MASK     (0x7ull << (63-2))
+#define CXL_AFU_Cntl_An_ES_Disabled (0x0ull << (63-2))
+#define CXL_AFU_Cntl_An_ES_Enabled  (0x4ull << (63-2))
+/* AFU Slice Enable */
+#define CXL_AFU_Cntl_An_E           (0x1ull << (63-3))
+/* AFU Slice Reset status (ro) */
+#define CXL_AFU_Cntl_An_RS_MASK     (0x3ull << (63-5))
+#define CXL_AFU_Cntl_An_RS_Pending  (0x1ull << (63-5))
+#define CXL_AFU_Cntl_An_RS_Complete (0x2ull << (63-5))
+/* AFU Slice Reset */
+#define CXL_AFU_Cntl_An_RA          (0x1ull << (63-7))
+
+/****** CXL_SSTP0/1_An ******************************************************/
+/* These top bits are for the segment that CONTAINS the segment table */
+#define CXL_SSTP0_An_B_SHIFT    SLB_VSID_SSIZE_SHIFT
+#define CXL_SSTP0_An_KS             (1ull << (63-2))
+#define CXL_SSTP0_An_KP             (1ull << (63-3))
+#define CXL_SSTP0_An_N              (1ull << (63-4))
+#define CXL_SSTP0_An_L              (1ull << (63-5))
+#define CXL_SSTP0_An_C              (1ull << (63-6))
+#define CXL_SSTP0_An_TA             (1ull << (63-7))
+#define CXL_SSTP0_An_LP_SHIFT                (63-9)  /* 2 Bits */
+/* And finally, the virtual address & size of the segment table: */
+#define CXL_SSTP0_An_SegTableSize_SHIFT      (63-31) /* 12 Bits */
+#define CXL_SSTP0_An_SegTableSize_MASK \
+	(((1ull << 12) - 1) << CXL_SSTP0_An_SegTableSize_SHIFT)
+#define CXL_SSTP0_An_STVA_U_MASK   ((1ull << (63-49))-1)
+#define CXL_SSTP1_An_STVA_L_MASK (~((1ull << (63-55))-1))
+#define CXL_SSTP1_An_V              (1ull << (63-63))
+
+/****** CXL_PSL_SLBIE_[An] **************************************************/
+/* write: */
+#define CXL_SLBIE_C        PPC_BIT(36)         /* Class */
+#define CXL_SLBIE_SS       PPC_BITMASK(37, 38) /* Segment Size */
+#define CXL_SLBIE_SS_SHIFT PPC_BITLSHIFT(38)
+#define CXL_SLBIE_TA       PPC_BIT(38)         /* Tags Active */
+/* read: */
+#define CXL_SLBIE_MAX      PPC_BITMASK(24, 31)
+#define CXL_SLBIE_PENDING  PPC_BITMASK(56, 63)
+
+/****** Common to all CXL_TLBIA/SLBIA_[An] **********************************/
+#define CXL_TLB_SLB_P          (1ull) /* Pending (read) */
+
+/****** Common to all CXL_TLB/SLB_IA/IE_[An] registers **********************/
+#define CXL_TLB_SLB_IQ_ALL     (0ull) /* Inv qualifier */
+#define CXL_TLB_SLB_IQ_LPID    (1ull) /* Inv qualifier */
+#define CXL_TLB_SLB_IQ_LPIDPID (3ull) /* Inv qualifier */
+
+/****** CXL_PSL_AFUSEL ******************************************************/
+#define CXL_PSL_AFUSEL_A (1ull << (63-55)) /* Adapter wide invalidates affect all AFUs */
+
+/****** CXL_PSL_DSISR_An ****************************************************/
+#define CXL_PSL_DSISR_An_DS (1ull << (63-0))  /* Segment not found */
+#define CXL_PSL_DSISR_An_DM (1ull << (63-1))  /* PTE not found (See also: M) or protection fault */
+#define CXL_PSL_DSISR_An_ST (1ull << (63-2))  /* Segment Table PTE not found */
+#define CXL_PSL_DSISR_An_UR (1ull << (63-3))  /* AURP PTE not found */
+#define CXL_PSL_DSISR_TRANS (CXL_PSL_DSISR_An_DS | CXL_PSL_DSISR_An_DM | CXL_PSL_DSISR_An_ST | CXL_PSL_DSISR_An_UR)
+#define CXL_PSL_DSISR_An_PE (1ull << (63-4))  /* PSL Error (implementation specific) */
+#define CXL_PSL_DSISR_An_AE (1ull << (63-5))  /* AFU Error */
+#define CXL_PSL_DSISR_An_OC (1ull << (63-6))  /* OS Context Warning */
+/* NOTE: Bits 32:63 are undefined if DSISR[DS] = 1 */
+#define CXL_PSL_DSISR_An_M  DSISR_NOHPTE      /* PTE not found */
+#define CXL_PSL_DSISR_An_P  DSISR_PROTFAULT   /* Storage protection violation */
+#define CXL_PSL_DSISR_An_A  (1ull << (63-37)) /* AFU lock access to write through or cache inhibited storage */
+#define CXL_PSL_DSISR_An_S  DSISR_ISSTORE     /* Access was afu_wr or afu_zero */
+#define CXL_PSL_DSISR_An_K  DSISR_KEYFAULT    /* Access not permitted by virtual page class key protection */
+
+/****** CXL_PSL_TFC_An ******************************************************/
+#define CXL_PSL_TFC_An_A  (1ull << (63-28)) /* Acknowledge non-translation fault */
+#define CXL_PSL_TFC_An_C  (1ull << (63-29)) /* Continue (abort transaction) */
+#define CXL_PSL_TFC_An_AE (1ull << (63-30)) /* Restart PSL with address error */
+#define CXL_PSL_TFC_An_R  (1ull << (63-31)) /* Restart PSL transaction */
+
+/* cxl_process_element->software_status */
+#define CXL_PE_SOFTWARE_STATE_V (1ul << (31 -  0)) /* Valid */
+#define CXL_PE_SOFTWARE_STATE_C (1ul << (31 - 29)) /* Complete */
+#define CXL_PE_SOFTWARE_STATE_S (1ul << (31 - 30)) /* Suspend */
+#define CXL_PE_SOFTWARE_STATE_T (1ul << (31 - 31)) /* Terminate */
+
+/* SPA->sw_command_status */
+#define CXL_SPA_SW_CMD_MASK         0xffff000000000000ULL
+#define CXL_SPA_SW_CMD_TERMINATE    0x0001000000000000ULL
+#define CXL_SPA_SW_CMD_REMOVE       0x0002000000000000ULL
+#define CXL_SPA_SW_CMD_SUSPEND      0x0003000000000000ULL
+#define CXL_SPA_SW_CMD_RESUME       0x0004000000000000ULL
+#define CXL_SPA_SW_CMD_ADD          0x0005000000000000ULL
+#define CXL_SPA_SW_CMD_UPDATE       0x0006000000000000ULL
+#define CXL_SPA_SW_STATE_MASK       0x0000ffff00000000ULL
+#define CXL_SPA_SW_STATE_TERMINATED 0x0000000100000000ULL
+#define CXL_SPA_SW_STATE_REMOVED    0x0000000200000000ULL
+#define CXL_SPA_SW_STATE_SUSPENDED  0x0000000300000000ULL
+#define CXL_SPA_SW_STATE_RESUMED    0x0000000400000000ULL
+#define CXL_SPA_SW_STATE_ADDED      0x0000000500000000ULL
+#define CXL_SPA_SW_STATE_UPDATED    0x0000000600000000ULL
+#define CXL_SPA_SW_PSL_ID_MASK      0x00000000ffff0000ULL
+#define CXL_SPA_SW_LINK_MASK        0x000000000000ffffULL
+
+#define CXL_MAX_SLICES 4
+#define MAX_AFU_MMIO_REGS 3
+
+#define CXL_MODE_DEDICATED   0x1
+#define CXL_MODE_DIRECTED    0x2
+#define CXL_MODE_TIME_SLICED 0x4
+#define CXL_SUPPORTED_MODES (CXL_MODE_DEDICATED | CXL_MODE_DIRECTED)
+
+enum cxl_context_status {
+	CLOSED,
+	OPENED,
+	STARTED
+};
+
+enum prefault_modes {
+	CXL_PREFAULT_NONE,
+	CXL_PREFAULT_WED,
+	CXL_PREFAULT_ALL,
+};
+
+struct cxl_sste {
+	__be64 esid_data;
+	__be64 vsid_data;
+};
+
+#define to_cxl_adapter(d) container_of(d, struct cxl, dev)
+#define to_cxl_afu(d) container_of(d, struct cxl_afu, dev)
+
+struct cxl_afu {
+	irq_hw_number_t psl_hwirq;
+	irq_hw_number_t serr_hwirq;
+	unsigned int serr_virq;
+	void __iomem *p1n_mmio;
+	void __iomem *p2n_mmio;
+	phys_addr_t psn_phys;
+	u64 pp_offset;
+	u64 pp_size;
+	void __iomem *afu_desc_mmio;
+	struct cxl *adapter;
+	struct device dev;
+	struct cdev afu_cdev_s, afu_cdev_m, afu_cdev_d;
+	struct device *chardev_s, *chardev_m, *chardev_d;
+	struct idr contexts_idr;
+	struct dentry *debugfs;
+	spinlock_t contexts_lock;
+	struct mutex spa_mutex;
+	spinlock_t afu_cntl_lock;
+
+	/*
+	 * Only the first part of the SPA is used for the process element
+	 * linked list. The only other part that software needs to worry about
+	 * is sw_command_status, which we store a separate pointer to.
+	 * Everything else in the SPA is only used by hardware
+	 */
+	struct cxl_process_element *spa;
+	__be64 *sw_command_status;
+	unsigned int spa_size;
+	int spa_order;
+	int spa_max_procs;
+	unsigned int psl_virq;
+
+	int pp_irqs;
+	int irqs_max;
+	int num_procs;
+	int max_procs_virtualised;
+	int slice;
+	int modes_supported;
+	int current_mode;
+	enum prefault_modes prefault_mode;
+	bool psa;
+	bool pp_psa;
+	bool enabled;
+};
+
+/*
+ * This is a cxl context.  If the PSL is in dedicated mode, there will be one
+ * of these per AFU.  If in AFU directed there can be lots of these.
+ */
+struct cxl_context {
+	struct cxl_afu *afu;
+
+	/* Problem state MMIO */
+	phys_addr_t psn_phys;
+	u64 psn_size;
+
+	spinlock_t sste_lock; /* Protects segment table entries */
+	struct cxl_sste *sstp;
+	u64 sstp0, sstp1;
+	unsigned int sst_size, sst_lru;
+
+	wait_queue_head_t wq;
+	struct pid *pid;
+	spinlock_t lock; /* Protects pending_irq_mask, pending_fault and fault_addr */
+	/* Only used in PR mode */
+	u64 process_token;
+
+	unsigned long *irq_bitmap; /* Accessed from IRQ context */
+	struct cxl_irq_ranges irqs;
+	u64 fault_addr;
+	u64 fault_dsisr;
+	u64 afu_err;
+
+	/*
+	 * This status and it's lock pretects start and detach context
+	 * from racing.  It also prevents detach from racing with
+	 * itself
+	 */
+	enum cxl_context_status status;
+	struct mutex status_mutex;
+
+
+	/* XXX: Is it possible to need multiple work items at once? */
+	struct work_struct fault_work;
+	u64 dsisr;
+	u64 dar;
+
+	struct cxl_process_element *elem;
+
+	int pe; /* process element handle */
+	u32 irq_count;
+	bool pe_inserted;
+	bool master;
+	bool kernel;
+	bool pending_irq;
+	bool pending_fault;
+	bool pending_afu_err;
+};
+
+struct cxl {
+	void __iomem *p1_mmio;
+	void __iomem *p2_mmio;
+	irq_hw_number_t err_hwirq;
+	unsigned int err_virq;
+	spinlock_t afu_list_lock;
+	struct cxl_afu *afu[CXL_MAX_SLICES];
+	struct device dev;
+	struct dentry *trace;
+	struct dentry *psl_err_chk;
+	struct dentry *debugfs;
+	struct bin_attribute cxl_attr;
+	int adapter_num;
+	int user_irqs;
+	u64 afu_desc_off;
+	u64 afu_desc_size;
+	u64 ps_off;
+	u64 ps_size;
+	u16 psl_rev;
+	u16 base_image;
+	u8 vsec_status;
+	u8 caia_major;
+	u8 caia_minor;
+	u8 slices;
+	bool user_image_loaded;
+	bool perst_loads_image;
+	bool perst_select_user;
+};
+
+int cxl_alloc_one_irq(struct cxl *adapter);
+void cxl_release_one_irq(struct cxl *adapter, int hwirq);
+int cxl_alloc_irq_ranges(struct cxl_irq_ranges *irqs, struct cxl *adapter, unsigned int num);
+void cxl_release_irq_ranges(struct cxl_irq_ranges *irqs, struct cxl *adapter);
+int cxl_setup_irq(struct cxl *adapter, unsigned int hwirq, unsigned int virq);
+
+/* common == phyp + powernv */
+struct cxl_process_element_common {
+	__be32 tid;
+	__be32 pid;
+	__be64 csrp;
+	__be64 aurp0;
+	__be64 aurp1;
+	__be64 sstp0;
+	__be64 sstp1;
+	__be64 amr;
+	u8     reserved3[4];
+	__be64 wed;
+} __packed;
+
+/* just powernv */
+struct cxl_process_element {
+	__be64 sr;
+	__be64 SPOffset;
+	__be64 sdr;
+	__be64 haurp;
+	__be32 ctxtime;
+	__be16 ivte_offsets[4];
+	__be16 ivte_ranges[4];
+	__be32 lpid;
+	struct cxl_process_element_common common;
+	__be32 software_state;
+} __packed;
+
+static inline void __iomem *_cxl_p1_addr(struct cxl *cxl, cxl_p1_reg_t reg)
+{
+	WARN_ON(!cpu_has_feature(CPU_FTR_HVMODE));
+	return cxl->p1_mmio + cxl_reg_off(reg);
+}
+
+#define cxl_p1_write(cxl, reg, val) \
+	out_be64(_cxl_p1_addr(cxl, reg), val)
+#define cxl_p1_read(cxl, reg) \
+	in_be64(_cxl_p1_addr(cxl, reg))
+
+static inline void __iomem *_cxl_p1n_addr(struct cxl_afu *afu, cxl_p1n_reg_t reg)
+{
+	WARN_ON(!cpu_has_feature(CPU_FTR_HVMODE));
+	return afu->p1n_mmio + cxl_reg_off(reg);
+}
+
+#define cxl_p1n_write(afu, reg, val) \
+	out_be64(_cxl_p1n_addr(afu, reg), val)
+#define cxl_p1n_read(afu, reg) \
+	in_be64(_cxl_p1n_addr(afu, reg))
+
+static inline void __iomem *_cxl_p2n_addr(struct cxl_afu *afu, cxl_p2n_reg_t reg)
+{
+	return afu->p2n_mmio + cxl_reg_off(reg);
+}
+
+#define cxl_p2n_write(afu, reg, val) \
+	out_be64(_cxl_p2n_addr(afu, reg), val)
+#define cxl_p2n_read(afu, reg) \
+	in_be64(_cxl_p2n_addr(afu, reg))
+
+struct cxl_calls {
+	void (*cxl_slbia)(struct mm_struct *mm);
+	struct module *owner;
+};
+int register_cxl_calls(struct cxl_calls *calls);
+void unregister_cxl_calls(struct cxl_calls *calls);
+
+int cxl_alloc_adapter_nr(struct cxl *adapter);
+void cxl_remove_adapter_nr(struct cxl *adapter);
+
+int cxl_file_init(void);
+void cxl_file_exit(void);
+int cxl_register_adapter(struct cxl *adapter);
+int cxl_register_afu(struct cxl_afu *afu);
+int cxl_chardev_d_afu_add(struct cxl_afu *afu);
+int cxl_chardev_m_afu_add(struct cxl_afu *afu);
+int cxl_chardev_s_afu_add(struct cxl_afu *afu);
+void cxl_chardev_afu_remove(struct cxl_afu *afu);
+
+void cxl_context_detach_all(struct cxl_afu *afu);
+void cxl_context_free(struct cxl_context *ctx);
+void cxl_context_detach(struct cxl_context *ctx);
+
+int cxl_sysfs_adapter_add(struct cxl *adapter);
+void cxl_sysfs_adapter_remove(struct cxl *adapter);
+int cxl_sysfs_afu_add(struct cxl_afu *afu);
+void cxl_sysfs_afu_remove(struct cxl_afu *afu);
+int cxl_sysfs_afu_m_add(struct cxl_afu *afu);
+void cxl_sysfs_afu_m_remove(struct cxl_afu *afu);
+
+int cxl_afu_activate_mode(struct cxl_afu *afu, int mode);
+int _cxl_afu_deactivate_mode(struct cxl_afu *afu, int mode);
+int cxl_afu_deactivate_mode(struct cxl_afu *afu);
+int cxl_afu_select_best_mode(struct cxl_afu *afu);
+
+unsigned int cxl_map_irq(struct cxl *adapter, irq_hw_number_t hwirq,
+		         irq_handler_t handler, void *cookie);
+void cxl_unmap_irq(unsigned int virq, void *cookie);
+int cxl_register_psl_irq(struct cxl_afu *afu);
+void cxl_release_psl_irq(struct cxl_afu *afu);
+int cxl_register_psl_err_irq(struct cxl *adapter);
+void cxl_release_psl_err_irq(struct cxl *adapter);
+int cxl_register_serr_irq(struct cxl_afu *afu);
+void cxl_release_serr_irq(struct cxl_afu *afu);
+int afu_register_irqs(struct cxl_context *ctx, u32 count);
+void afu_release_irqs(struct cxl_context *ctx);
+irqreturn_t cxl_slice_irq_err(int irq, void *data);
+
+int cxl_debugfs_init(void);
+void cxl_debugfs_exit(void);
+int cxl_debugfs_adapter_add(struct cxl *adapter);
+void cxl_debugfs_adapter_remove(struct cxl *adapter);
+int cxl_debugfs_afu_add(struct cxl_afu *afu);
+void cxl_debugfs_afu_remove(struct cxl_afu *afu);
+
+void cxl_handle_fault(struct work_struct *work);
+void cxl_prefault(struct cxl_context *ctx, u64 wed);
+
+struct cxl *get_cxl_adapter(int num);
+int cxl_alloc_sst(struct cxl_context *ctx);
+
+void init_cxl_native(void);
+
+struct cxl_context *cxl_context_alloc(void);
+int cxl_context_init(struct cxl_context *ctx, struct cxl_afu *afu, bool master);
+void cxl_context_free(struct cxl_context *ctx);
+int cxl_context_iomap(struct cxl_context *ctx, struct vm_area_struct *vma);
+
+/* This matches the layout of the H_COLLECT_CA_INT_INFO retbuf */
+struct cxl_irq_info {
+	u64 dsisr;
+	u64 dar;
+	u64 dsr;
+	u32 pid;
+	u32 tid;
+	u64 afu_err;
+	u64 errstat;
+	u64 padding[3]; /* to match the expected retbuf size for plpar_hcall9 */
+};
+
+int cxl_attach_process(struct cxl_context *ctx, bool kernel, u64 wed,
+			    u64 amr);
+int cxl_detach_process(struct cxl_context *ctx);
+
+int cxl_get_irq(struct cxl_context *ctx, struct cxl_irq_info *info);
+int cxl_ack_irq(struct cxl_context *ctx, u64 tfc, u64 psl_reset_mask);
+
+int cxl_check_error(struct cxl_afu *afu);
+int cxl_afu_slbia(struct cxl_afu *afu);
+int cxl_tlb_slb_invalidate(struct cxl *adapter);
+int cxl_afu_disable(struct cxl_afu *afu);
+int cxl_afu_reset(struct cxl_afu *afu);
+int cxl_psl_purge(struct cxl_afu *afu);
+
+void cxl_stop_trace(struct cxl *cxl);
+
+extern struct pci_driver cxl_pci_driver;
+
+#endif
