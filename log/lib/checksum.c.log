commit 5904122c46581a5ccee54a51ef07e0d891fd7aef
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Tue Feb 18 14:26:32 2020 -0500

    take the dummy csum_and_copy_from_user() into net/checksum.h
    
    now that can be done conveniently - all non-trivial cases have
    _HAVE_ARCH_COPY_AND_CSUM_FROM_USER defined, so the fallback in
    net/checksum.h is used only for dummy (copy_from_user, then
    csum_partial) implementation.  Allowing us to get rid of all
    dummy instances, both of csum_and_copy_from_user() and
    csum_partial_copy_from_user().
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/lib/checksum.c b/lib/checksum.c
index de032ad96f4a..7ac65a0000ff 100644
--- a/lib/checksum.c
+++ b/lib/checksum.c
@@ -145,26 +145,6 @@ __sum16 ip_compute_csum(const void *buff, int len)
 }
 EXPORT_SYMBOL(ip_compute_csum);
 
-/*
- * copy from fs while checksumming, otherwise like csum_partial
- */
-__wsum
-csum_partial_copy_from_user(const void __user *src, void *dst, int len,
-						__wsum sum, int *csum_err)
-{
-	int missing;
-
-	missing = __copy_from_user(dst, src, len);
-	if (missing) {
-		memset(dst + len - missing, 0, missing);
-		*csum_err = -EFAULT;
-	} else
-		*csum_err = 0;
-
-	return csum_partial(dst, len, sum);
-}
-EXPORT_SYMBOL(csum_partial_copy_from_user);
-
 /*
  * copy from ds while checksumming, otherwise like csum_partial
  */

commit 2874c5fd284268364ece81a7bd936f3c8168e567
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon May 27 08:55:01 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 152
    
    Based on 1 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license as published by
      the free software foundation either version 2 of the license or at
      your option any later version
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-or-later
    
    has been chosen to replace the boilerplate/reference in 3029 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190527070032.746973796@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/lib/checksum.c b/lib/checksum.c
index d3ec93f9e5f3..de032ad96f4a 100644
--- a/lib/checksum.c
+++ b/lib/checksum.c
@@ -1,3 +1,4 @@
+// SPDX-License-Identifier: GPL-2.0-or-later
 /*
  *
  * INET		An implementation of the TCP/IP protocol suite for the LINUX
@@ -22,11 +23,6 @@
  *		data-registers to hold input values and one tries to
  *		specify d0 and d1 as scratch registers. Letting gcc
  *		choose these registers itself solves the problem.
- *
- *		This program is free software; you can redistribute it and/or
- *		modify it under the terms of the GNU General Public License
- *		as published by the Free Software Foundation; either version
- *		2 of the License, or (at your option) any later version.
  */
 
 /* Revised by Kenneth Albanowski for m68knommu. Basic problem: unaligned access

commit 01cfbad79a5e2b835abf6a8154a341d75a6fc8cd
Author: Alexander Duyck <aduyck@mirantis.com>
Date:   Fri Mar 11 14:05:34 2016 -0800

    ipv4: Update parameters for csum_tcpudp_magic to their original types
    
    This patch updates all instances of csum_tcpudp_magic and
    csum_tcpudp_nofold to reflect the types that are usually used as the source
    inputs.  For example the protocol field is populated based on nexthdr which
    is actually an unsigned 8 bit value.  The length is usually populated based
    on skb->len which is an unsigned integer.
    
    This addresses an issue in which the IPv6 function csum_ipv6_magic was
    generating a checksum using the full 32b of skb->len while
    csum_tcpudp_magic was only using the lower 16 bits.  As a result we could
    run into issues when attempting to adjust the checksum as there was no
    protocol agnostic way to update it.
    
    With this change the value is still truncated as many architectures use
    "(len + proto) << 8", however this truncation only occurs for values
    greater than 16776960 in length and as such is unlikely to occur as we stop
    the inner headers at ~64K in size.
    
    I did have to make a few minor changes in the arm, mn10300, nios2, and
    score versions of the function in order to support these changes as they
    were either using things such as an OR to combine the protocol and length,
    or were using ntohs to convert the length which would have truncated the
    value.
    
    I also updated a few spots in terms of whitespace and type differences for
    the addresses.  Most of this was just to make sure all of the definitions
    were in sync going forward.
    
    Signed-off-by: Alexander Duyck <aduyck@mirantis.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/lib/checksum.c b/lib/checksum.c
index 8b39e86dbab5..d3ec93f9e5f3 100644
--- a/lib/checksum.c
+++ b/lib/checksum.c
@@ -191,9 +191,7 @@ static inline u32 from64to32(u64 x)
 }
 
 __wsum csum_tcpudp_nofold(__be32 saddr, __be32 daddr,
-			unsigned short len,
-			unsigned short proto,
-			__wsum sum)
+			  __u32 len, __u8 proto, __wsum sum)
 {
 	unsigned long long s = (__force u32)sum;
 

commit 9ce357795ef208faa0d59894d9d119a7434e37f3
Author: karl beldan <karl.beldan@gmail.com>
Date:   Thu Jan 29 11:10:22 2015 +0100

    lib/checksum.c: fix build for generic csum_tcpudp_nofold
    
    Fixed commit added from64to32 under _#ifndef do_csum_ but used it
    under _#ifndef csum_tcpudp_nofold_, breaking some builds (Fengguang's
    robot reported TILEGX's). Move from64to32 under the latter.
    
    Fixes: 150ae0e94634 ("lib/checksum.c: fix carry in csum_tcpudp_nofold")
    Reported-by: kbuild test robot <fengguang.wu@intel.com>
    Signed-off-by: Karl Beldan <karl.beldan@rivierawaves.com>
    Cc: Eric Dumazet <edumazet@google.com>
    Cc: David S. Miller <davem@davemloft.net>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/lib/checksum.c b/lib/checksum.c
index fcf38943132c..8b39e86dbab5 100644
--- a/lib/checksum.c
+++ b/lib/checksum.c
@@ -47,15 +47,6 @@ static inline unsigned short from32to16(unsigned int x)
 	return x;
 }
 
-static inline u32 from64to32(u64 x)
-{
-	/* add up 32-bit and 32-bit for 32+c bit */
-	x = (x & 0xffffffff) + (x >> 32);
-	/* add up carry.. */
-	x = (x & 0xffffffff) + (x >> 32);
-	return (u32)x;
-}
-
 static unsigned int do_csum(const unsigned char *buff, int len)
 {
 	int odd;
@@ -190,6 +181,15 @@ csum_partial_copy(const void *src, void *dst, int len, __wsum sum)
 EXPORT_SYMBOL(csum_partial_copy);
 
 #ifndef csum_tcpudp_nofold
+static inline u32 from64to32(u64 x)
+{
+	/* add up 32-bit and 32-bit for 32+c bit */
+	x = (x & 0xffffffff) + (x >> 32);
+	/* add up carry.. */
+	x = (x & 0xffffffff) + (x >> 32);
+	return (u32)x;
+}
+
 __wsum csum_tcpudp_nofold(__be32 saddr, __be32 daddr,
 			unsigned short len,
 			unsigned short proto,

commit 150ae0e94634714b23919f0c333fee28a5b199d5
Author: karl beldan <karl.beldan@gmail.com>
Date:   Wed Jan 28 10:58:11 2015 +0100

    lib/checksum.c: fix carry in csum_tcpudp_nofold
    
    The carry from the 64->32bits folding was dropped, e.g with:
    saddr=0xFFFFFFFF daddr=0xFF0000FF len=0xFFFF proto=0 sum=1,
    csum_tcpudp_nofold returned 0 instead of 1.
    
    Signed-off-by: Karl Beldan <karl.beldan@rivierawaves.com>
    Cc: Al Viro <viro@ZenIV.linux.org.uk>
    Cc: Eric Dumazet <eric.dumazet@gmail.com>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Mike Frysinger <vapier@gentoo.org>
    Cc: netdev@vger.kernel.org
    Cc: linux-kernel@vger.kernel.org
    Cc: stable@vger.kernel.org
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/lib/checksum.c b/lib/checksum.c
index 129775eb6de6..fcf38943132c 100644
--- a/lib/checksum.c
+++ b/lib/checksum.c
@@ -47,6 +47,15 @@ static inline unsigned short from32to16(unsigned int x)
 	return x;
 }
 
+static inline u32 from64to32(u64 x)
+{
+	/* add up 32-bit and 32-bit for 32+c bit */
+	x = (x & 0xffffffff) + (x >> 32);
+	/* add up carry.. */
+	x = (x & 0xffffffff) + (x >> 32);
+	return (u32)x;
+}
+
 static unsigned int do_csum(const unsigned char *buff, int len)
 {
 	int odd;
@@ -195,8 +204,7 @@ __wsum csum_tcpudp_nofold(__be32 saddr, __be32 daddr,
 #else
 	s += (proto + len) << 8;
 #endif
-	s += (s >> 32);
-	return (__force __wsum)s;
+	return (__force __wsum)from64to32(s);
 }
 EXPORT_SYMBOL(csum_tcpudp_nofold);
 #endif

commit 64e69073c35439fa19c2ad2a4a18834e0314f071
Author: Vineet Gupta <vgupta@synopsys.com>
Date:   Fri Jan 18 15:12:16 2013 +0530

    asm-generic headers: Allow yet more arch overrides in checksum.h
    
    arches can have more efficient implementation of these routines
    
    Acked-by: Arnd Bergmann <arnd@arndb.de>
    Signed-off-by: Vineet Gupta <vgupta@synopsys.com>

diff --git a/lib/checksum.c b/lib/checksum.c
index 12dceb27ff20..129775eb6de6 100644
--- a/lib/checksum.c
+++ b/lib/checksum.c
@@ -102,6 +102,7 @@ static unsigned int do_csum(const unsigned char *buff, int len)
 }
 #endif
 
+#ifndef ip_fast_csum
 /*
  *	This is a version of ip_compute_csum() optimized for IP headers,
  *	which always checksum on 4 octet boundaries.
@@ -111,6 +112,7 @@ __sum16 ip_fast_csum(const void *iph, unsigned int ihl)
 	return (__force __sum16)~do_csum(iph, ihl*4);
 }
 EXPORT_SYMBOL(ip_fast_csum);
+#endif
 
 /*
  * computes the checksum of a memory block at buff, length len,

commit 8bc3bcc93a2b4e47d5d410146f6546bca6171663
Author: Paul Gortmaker <paul.gortmaker@windriver.com>
Date:   Wed Nov 16 21:29:17 2011 -0500

    lib: reduce the use of module.h wherever possible
    
    For files only using THIS_MODULE and/or EXPORT_SYMBOL, map
    them onto including export.h -- or if the file isn't even
    using those, then just delete the include.  Fix up any implicit
    include dependencies that were being masked by module.h along
    the way.
    
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>

diff --git a/lib/checksum.c b/lib/checksum.c
index 8df2f91e6d98..12dceb27ff20 100644
--- a/lib/checksum.c
+++ b/lib/checksum.c
@@ -32,7 +32,7 @@
 /* Revised by Kenneth Albanowski for m68knommu. Basic problem: unaligned access
  kills, so most of the assembly has to go. */
 
-#include <linux/module.h>
+#include <linux/export.h>
 #include <net/checksum.h>
 
 #include <asm/byteorder.h>

commit be0e1e788b0973147b6b83cc940676cc26009eb7
Author: Ian Abbott <abbotti@mev.co.uk>
Date:   Thu Jul 7 01:18:49 2011 +0000

    lib/checksum.c: optimize do_csum a bit
    
    Reduce the number of variables modified by the loop in do_csum() by 1,
    which seems like a good idea.  On Nios II (a RISC CPU with 3-operand
    instruction set) it reduces the loop from 7 to 6 instructions, including
    the conditional branch.
    
    Signed-off-by: Ian Abbott <abbotti@mev.co.uk>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/lib/checksum.c b/lib/checksum.c
index 097508732f34..8df2f91e6d98 100644
--- a/lib/checksum.c
+++ b/lib/checksum.c
@@ -49,7 +49,7 @@ static inline unsigned short from32to16(unsigned int x)
 
 static unsigned int do_csum(const unsigned char *buff, int len)
 {
-	int odd, count;
+	int odd;
 	unsigned int result = 0;
 
 	if (len <= 0)
@@ -64,25 +64,22 @@ static unsigned int do_csum(const unsigned char *buff, int len)
 		len--;
 		buff++;
 	}
-	count = len >> 1;		/* nr of 16-bit words.. */
-	if (count) {
+	if (len >= 2) {
 		if (2 & (unsigned long) buff) {
 			result += *(unsigned short *) buff;
-			count--;
 			len -= 2;
 			buff += 2;
 		}
-		count >>= 1;		/* nr of 32-bit words.. */
-		if (count) {
+		if (len >= 4) {
+			const unsigned char *end = buff + ((unsigned)len & ~3);
 			unsigned int carry = 0;
 			do {
 				unsigned int w = *(unsigned int *) buff;
-				count--;
 				buff += 4;
 				result += carry;
 				result += w;
 				carry = (w > result);
-			} while (count);
+			} while (buff < end);
 			result += carry;
 			result = (result & 0xffff) + (result >> 16);
 		}

commit 0a5549ed163520787f76b7515dfe9d9aa1c7ae37
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Tue Jun 23 22:52:51 2009 +0200

    lib/checksum: fix one more thinko
    
    When do_csum gets unaligned data, we really need to treat
    the first byte as an even byte, not an odd byte, because
    we swap the two halves later.
    
    Found by Mike's checksum-selftest module.
    
    Reported-by: Mike Frysinger <vapier.adi@gmail.com>
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>

diff --git a/lib/checksum.c b/lib/checksum.c
index b08c2d059024..097508732f34 100644
--- a/lib/checksum.c
+++ b/lib/checksum.c
@@ -57,9 +57,9 @@ static unsigned int do_csum(const unsigned char *buff, int len)
 	odd = 1 & (unsigned long) buff;
 	if (odd) {
 #ifdef __LITTLE_ENDIAN
-		result = *buff;
-#else
 		result += (*buff << 8);
+#else
+		result = *buff;
 #endif
 		len--;
 		buff++;

commit 20c1f641bb80fb272dec959a5caabed92e5a422e
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Tue Jun 23 21:37:26 2009 +0200

    lib/checksum.c: make do_csum optional
    
    Mike Frysinger suggested that do_csum should be optional
    so that an architecture can use the generic checksum code
    but still provide an optimized fast-path for the most
    critical function.
    
    This can mean an implementation using inline assembly,
    or in case of Alpha one using 64-bit arithmetic in C.
    
    Cc: Mike Frysinger <vapier@gentoo.org>
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>

diff --git a/lib/checksum.c b/lib/checksum.c
index 886b48db4f28..b08c2d059024 100644
--- a/lib/checksum.c
+++ b/lib/checksum.c
@@ -37,6 +37,7 @@
 
 #include <asm/byteorder.h>
 
+#ifndef do_csum
 static inline unsigned short from32to16(unsigned int x)
 {
 	/* add up 16-bit and 16-bit for 16+c bit */
@@ -102,6 +103,7 @@ static unsigned int do_csum(const unsigned char *buff, int len)
 out:
 	return result;
 }
+#endif
 
 /*
  *	This is a version of ip_compute_csum() optimized for IP headers,

commit c44ba9f6684946b156335da6a6d55f0b8cf7cb72
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Tue Jun 23 21:22:58 2009 +0200

    lib/checksum.c: use 32-bit arithmetic consistently
    
    The use of 'unsigned long' variables in the 32-bit part of do_csum()
    is confusing at best, and potentially broken for long input on 64-bit
    machines.
    
    This changes the code to use 'unsigned int' instead, which makes
    the code behave in the same (correct) way on both 32 and 64 bit
    machines.
    
    Reported-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>

diff --git a/lib/checksum.c b/lib/checksum.c
index b2e2fd468461..886b48db4f28 100644
--- a/lib/checksum.c
+++ b/lib/checksum.c
@@ -37,7 +37,7 @@
 
 #include <asm/byteorder.h>
 
-static inline unsigned short from32to16(unsigned long x)
+static inline unsigned short from32to16(unsigned int x)
 {
 	/* add up 16-bit and 16-bit for 16+c bit */
 	x = (x & 0xffff) + (x >> 16);
@@ -49,7 +49,7 @@ static inline unsigned short from32to16(unsigned long x)
 static unsigned int do_csum(const unsigned char *buff, int len)
 {
 	int odd, count;
-	unsigned long result = 0;
+	unsigned int result = 0;
 
 	if (len <= 0)
 		goto out;
@@ -73,9 +73,9 @@ static unsigned int do_csum(const unsigned char *buff, int len)
 		}
 		count >>= 1;		/* nr of 32-bit words.. */
 		if (count) {
-			unsigned long carry = 0;
+			unsigned int carry = 0;
 			do {
-				unsigned long w = *(unsigned int *) buff;
+				unsigned int w = *(unsigned int *) buff;
 				count--;
 				buff += 4;
 				result += carry;

commit 32a9ff9cc55b42543a84bca90b070df92af72671
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Fri Jun 19 10:41:19 2009 +0200

    lib/checksum.c: fix endianess bug
    
    The new generic checksum code has a small dependency on endianess and
    worked only on big-endian systems. I could not find a nice efficient
    way to express this, so I added an #ifdef. Using
    'result += le16_to_cpu(*buff);' would have worked as well, but
    would be slightly less efficient on big-endian systems and IMHO
    would not be clearer.
    
    Also fix a bug that prevents this from working on 64-bit machines.
    If you have a 64-bit CPU and want to use the generic checksum
    code, you should probably do some more optimizations anyway, but
    at least the code should not break.
    
    Reported-by: Mike Frysinger <vapier@gentoo.org>
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>

diff --git a/lib/checksum.c b/lib/checksum.c
index 12e5a1c91cda..b2e2fd468461 100644
--- a/lib/checksum.c
+++ b/lib/checksum.c
@@ -55,7 +55,11 @@ static unsigned int do_csum(const unsigned char *buff, int len)
 		goto out;
 	odd = 1 & (unsigned long) buff;
 	if (odd) {
+#ifdef __LITTLE_ENDIAN
 		result = *buff;
+#else
+		result += (*buff << 8);
+#endif
 		len--;
 		buff++;
 	}
@@ -71,7 +75,7 @@ static unsigned int do_csum(const unsigned char *buff, int len)
 		if (count) {
 			unsigned long carry = 0;
 			do {
-				unsigned long w = *(unsigned long *) buff;
+				unsigned long w = *(unsigned int *) buff;
 				count--;
 				buff += 4;
 				result += carry;
@@ -87,7 +91,11 @@ static unsigned int do_csum(const unsigned char *buff, int len)
 		}
 	}
 	if (len & 1)
+#ifdef __LITTLE_ENDIAN
+		result += *buff;
+#else
 		result += (*buff << 8);
+#endif
 	result = from32to16(result);
 	if (odd)
 		result = ((result >> 8) & 0xff) | ((result & 0xff) << 8);

commit 26a28fa4fea5b8c65713aa50c124f76a88c7924d
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Wed May 13 22:56:38 2009 +0000

    add generic lib/checksum.c
    
    Add a generic (unoptimized) implementation of checksum.c in pure C
    for use by all architectures that cannot be bother with implementing
    their own version.
    
    Based on microblaze code by Michal Simek <monstr@monstr.eu>
    
    Cc: Michal Simek <monstr@monstr.eu>
    Signed-off-by: Remis Lima Baima <remis.developer@googlemail.com>
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>

diff --git a/lib/checksum.c b/lib/checksum.c
new file mode 100644
index 000000000000..12e5a1c91cda
--- /dev/null
+++ b/lib/checksum.c
@@ -0,0 +1,193 @@
+/*
+ *
+ * INET		An implementation of the TCP/IP protocol suite for the LINUX
+ *		operating system.  INET is implemented using the  BSD Socket
+ *		interface as the means of communication with the user level.
+ *
+ *		IP/TCP/UDP checksumming routines
+ *
+ * Authors:	Jorge Cwik, <jorge@laser.satlink.net>
+ *		Arnt Gulbrandsen, <agulbra@nvg.unit.no>
+ *		Tom May, <ftom@netcom.com>
+ *		Andreas Schwab, <schwab@issan.informatik.uni-dortmund.de>
+ *		Lots of code moved from tcp.c and ip.c; see those files
+ *		for more names.
+ *
+ * 03/02/96	Jes Sorensen, Andreas Schwab, Roman Hodek:
+ *		Fixed some nasty bugs, causing some horrible crashes.
+ *		A: At some points, the sum (%0) was used as
+ *		length-counter instead of the length counter
+ *		(%1). Thanks to Roman Hodek for pointing this out.
+ *		B: GCC seems to mess up if one uses too many
+ *		data-registers to hold input values and one tries to
+ *		specify d0 and d1 as scratch registers. Letting gcc
+ *		choose these registers itself solves the problem.
+ *
+ *		This program is free software; you can redistribute it and/or
+ *		modify it under the terms of the GNU General Public License
+ *		as published by the Free Software Foundation; either version
+ *		2 of the License, or (at your option) any later version.
+ */
+
+/* Revised by Kenneth Albanowski for m68knommu. Basic problem: unaligned access
+ kills, so most of the assembly has to go. */
+
+#include <linux/module.h>
+#include <net/checksum.h>
+
+#include <asm/byteorder.h>
+
+static inline unsigned short from32to16(unsigned long x)
+{
+	/* add up 16-bit and 16-bit for 16+c bit */
+	x = (x & 0xffff) + (x >> 16);
+	/* add up carry.. */
+	x = (x & 0xffff) + (x >> 16);
+	return x;
+}
+
+static unsigned int do_csum(const unsigned char *buff, int len)
+{
+	int odd, count;
+	unsigned long result = 0;
+
+	if (len <= 0)
+		goto out;
+	odd = 1 & (unsigned long) buff;
+	if (odd) {
+		result = *buff;
+		len--;
+		buff++;
+	}
+	count = len >> 1;		/* nr of 16-bit words.. */
+	if (count) {
+		if (2 & (unsigned long) buff) {
+			result += *(unsigned short *) buff;
+			count--;
+			len -= 2;
+			buff += 2;
+		}
+		count >>= 1;		/* nr of 32-bit words.. */
+		if (count) {
+			unsigned long carry = 0;
+			do {
+				unsigned long w = *(unsigned long *) buff;
+				count--;
+				buff += 4;
+				result += carry;
+				result += w;
+				carry = (w > result);
+			} while (count);
+			result += carry;
+			result = (result & 0xffff) + (result >> 16);
+		}
+		if (len & 2) {
+			result += *(unsigned short *) buff;
+			buff += 2;
+		}
+	}
+	if (len & 1)
+		result += (*buff << 8);
+	result = from32to16(result);
+	if (odd)
+		result = ((result >> 8) & 0xff) | ((result & 0xff) << 8);
+out:
+	return result;
+}
+
+/*
+ *	This is a version of ip_compute_csum() optimized for IP headers,
+ *	which always checksum on 4 octet boundaries.
+ */
+__sum16 ip_fast_csum(const void *iph, unsigned int ihl)
+{
+	return (__force __sum16)~do_csum(iph, ihl*4);
+}
+EXPORT_SYMBOL(ip_fast_csum);
+
+/*
+ * computes the checksum of a memory block at buff, length len,
+ * and adds in "sum" (32-bit)
+ *
+ * returns a 32-bit number suitable for feeding into itself
+ * or csum_tcpudp_magic
+ *
+ * this function must be called with even lengths, except
+ * for the last fragment, which may be odd
+ *
+ * it's best to have buff aligned on a 32-bit boundary
+ */
+__wsum csum_partial(const void *buff, int len, __wsum wsum)
+{
+	unsigned int sum = (__force unsigned int)wsum;
+	unsigned int result = do_csum(buff, len);
+
+	/* add in old sum, and carry.. */
+	result += sum;
+	if (sum > result)
+		result += 1;
+	return (__force __wsum)result;
+}
+EXPORT_SYMBOL(csum_partial);
+
+/*
+ * this routine is used for miscellaneous IP-like checksums, mainly
+ * in icmp.c
+ */
+__sum16 ip_compute_csum(const void *buff, int len)
+{
+	return (__force __sum16)~do_csum(buff, len);
+}
+EXPORT_SYMBOL(ip_compute_csum);
+
+/*
+ * copy from fs while checksumming, otherwise like csum_partial
+ */
+__wsum
+csum_partial_copy_from_user(const void __user *src, void *dst, int len,
+						__wsum sum, int *csum_err)
+{
+	int missing;
+
+	missing = __copy_from_user(dst, src, len);
+	if (missing) {
+		memset(dst + len - missing, 0, missing);
+		*csum_err = -EFAULT;
+	} else
+		*csum_err = 0;
+
+	return csum_partial(dst, len, sum);
+}
+EXPORT_SYMBOL(csum_partial_copy_from_user);
+
+/*
+ * copy from ds while checksumming, otherwise like csum_partial
+ */
+__wsum
+csum_partial_copy(const void *src, void *dst, int len, __wsum sum)
+{
+	memcpy(dst, src, len);
+	return csum_partial(dst, len, sum);
+}
+EXPORT_SYMBOL(csum_partial_copy);
+
+#ifndef csum_tcpudp_nofold
+__wsum csum_tcpudp_nofold(__be32 saddr, __be32 daddr,
+			unsigned short len,
+			unsigned short proto,
+			__wsum sum)
+{
+	unsigned long long s = (__force u32)sum;
+
+	s += (__force u32)saddr;
+	s += (__force u32)daddr;
+#ifdef __BIG_ENDIAN
+	s += proto + len;
+#else
+	s += (proto + len) << 8;
+#endif
+	s += (s >> 32);
+	return (__force __wsum)s;
+}
+EXPORT_SYMBOL(csum_tcpudp_nofold);
+#endif
