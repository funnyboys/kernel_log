commit 7328c8f48d1895b3fec98b0b319cfb856b4c4fa1
Author: Bjorn Helgaas <bhelgaas@google.com>
Date:   Fri Jan 26 11:45:16 2018 -0600

    PCI: Add SPDX GPL-2.0 when no license was specified
    
    b24413180f56 ("License cleanup: add SPDX GPL-2.0 license identifier to
    files with no license") added SPDX GPL-2.0 to several PCI files that
    previously contained no license information.
    
    Add SPDX GPL-2.0 to all other PCI files that did not contain any license
    information and hence were under the default GPL version 2 license of the
    kernel.
    
    Signed-off-by: Bjorn Helgaas <bhelgaas@google.com>
    Reviewed-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/lib/pci_iomap.c b/lib/pci_iomap.c
index c10fba461454..2d3eb1cb73b8 100644
--- a/lib/pci_iomap.c
+++ b/lib/pci_iomap.c
@@ -1,3 +1,4 @@
+// SPDX-License-Identifier: GPL-2.0
 /*
  * Implement the default iomap interfaces
  *

commit 12f03ee606914317e7e6a0815e53a48205c31dae
Merge: d9241b22b58e 004f1afbe199
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Sep 8 14:35:59 2015 -0700

    Merge tag 'libnvdimm-for-4.3' of git://git.kernel.org/pub/scm/linux/kernel/git/nvdimm/nvdimm
    
    Pull libnvdimm updates from Dan Williams:
     "This update has successfully completed a 0day-kbuild run and has
      appeared in a linux-next release.  The changes outside of the typical
      drivers/nvdimm/ and drivers/acpi/nfit.[ch] paths are related to the
      removal of IORESOURCE_CACHEABLE, the introduction of memremap(), and
      the introduction of ZONE_DEVICE + devm_memremap_pages().
    
      Summary:
    
       - Introduce ZONE_DEVICE and devm_memremap_pages() as a generic
         mechanism for adding device-driver-discovered memory regions to the
         kernel's direct map.
    
         This facility is used by the pmem driver to enable pfn_to_page()
         operations on the page frames returned by DAX ('direct_access' in
         'struct block_device_operations').
    
         For now, the 'memmap' allocation for these "device" pages comes
         from "System RAM".  Support for allocating the memmap from device
         memory will arrive in a later kernel.
    
       - Introduce memremap() to replace usages of ioremap_cache() and
         ioremap_wt().  memremap() drops the __iomem annotation for these
         mappings to memory that do not have i/o side effects.  The
         replacement of ioremap_cache() with memremap() is limited to the
         pmem driver to ease merging the api change in v4.3.
    
         Completion of the conversion is targeted for v4.4.
    
       - Similar to the usage of memcpy_to_pmem() + wmb_pmem() in the pmem
         driver, update the VFS DAX implementation and PMEM api to provide
         persistence guarantees for kernel operations on a DAX mapping.
    
       - Convert the ACPI NFIT 'BLK' driver to map the block apertures as
         cacheable to improve performance.
    
       - Miscellaneous updates and fixes to libnvdimm including support for
         issuing "address range scrub" commands, clarifying the optimal
         'sector size' of pmem devices, a clarification of the usage of the
         ACPI '_STA' (status) property for DIMM devices, and other minor
         fixes"
    
    * tag 'libnvdimm-for-4.3' of git://git.kernel.org/pub/scm/linux/kernel/git/nvdimm/nvdimm: (34 commits)
      libnvdimm, pmem: direct map legacy pmem by default
      libnvdimm, pmem: 'struct page' for pmem
      libnvdimm, pfn: 'struct page' provider infrastructure
      x86, pmem: clarify that ARCH_HAS_PMEM_API implies PMEM mapped WB
      add devm_memremap_pages
      mm: ZONE_DEVICE for "device memory"
      mm: move __phys_to_pfn and __pfn_to_phys to asm/generic/memory_model.h
      dax: drop size parameter to ->direct_access()
      nd_blk: change aperture mapping from WC to WB
      nvdimm: change to use generic kvfree()
      pmem, dax: have direct_access use __pmem annotation
      dax: update I/O path to do proper PMEM flushing
      pmem: add copy_from_iter_pmem() and clear_pmem()
      pmem, x86: clean up conditional pmem includes
      pmem: remove layer when calling arch_has_wmb_pmem()
      pmem, x86: move x86 PMEM API to new pmem.h header
      libnvdimm, e820: make CONFIG_X86_PMEM_LEGACY a tristate option
      pmem: switch to devm_ allocations
      devres: add devm_memremap
      libnvdimm, btt: write and validate parent_uuid
      ...

commit 1b3d4200c1e00a3fb5e0aea428de5b07079a37e3
Author: Luis R. Rodriguez <mcgrof@suse.com>
Date:   Mon Aug 24 12:13:27 2015 -0700

    PCI: Add pci_iomap_wc() variants
    
    PCI BARs tell us whether prefetching is safe, but they don't say
    anything about write combining (WC). WC changes ordering rules
    and allows writes to be collapsed, so it's not safe in general
    to use it on a prefetchable region.
    
    Add pci_iomap_wc() and pci_iomap_wc_range() so drivers can take
    advantage of write combining when they know it's safe.
    
    On architectures that don't fully support WC, e.g., x86 without
    PAT, drivers for legacy framebuffers may get some of the benefit
    by using arch_phys_wc_add() in addition to pci_iomap_wc().  But
    arch_phys_wc_add() is unreliable and should be avoided in
    general.  On x86, it uses MTRRs, which are limited in number and
    size, so the results will vary based on driver loading order.
    
    The goals of adding pci_iomap_wc() are to:
    
    - Give drivers an architecture-independent way to use WC so they can stop
      using interfaces like mtrr_add() (on x86, pci_iomap_wc() uses
      PAT when available).
    
    - Move toward using _PAGE_CACHE_MODE_UC, not _PAGE_CACHE_MODE_UC_MINUS,
      on x86 on ioremap_nocache() (see de33c442ed2a ("x86 PAT: fix
      performance drop for glx, use UC minus for ioremap(), ioremap_nocache()
      and pci_mmap_page_range()").
    
    Signed-off-by: Luis R. Rodriguez <mcgrof@suse.com>
    [ Move IORESOURCE_IO check up, space out statements for better readability. ]
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Acked-by: Arnd Bergmann <arnd@arndb.de>
    Cc: <roger.pau@citrix.com>
    Cc: <syrjala@sci.fi>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Antonino Daplas <adaplas@gmail.com>
    Cc: Bjorn Helgaas <bhelgaas@google.com>
    Cc: Daniel Vetter <daniel.vetter@ffwll.ch>
    Cc: Dave Airlie <airlied@redhat.com>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Davidlohr Bueso <dbueso@suse.de>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Jean-Christophe Plagniol-Villard <plagnioj@jcrosoft.com>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mel Gorman <mgorman@suse.de>
    Cc: Michael S. Tsirkin <mst@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Roger Pau Monné <roger.pau@citrix.com>
    Cc: Rusty Russell <rusty@rustcorp.com.au>
    Cc: Stefan Bader <stefan.bader@canonical.com>
    Cc: Suresh Siddha <sbsiddha@gmail.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Tomi Valkeinen <tomi.valkeinen@ti.com>
    Cc: Toshi Kani <toshi.kani@hp.com>
    Cc: Ville Syrjälä <syrjala@sci.fi>
    Cc: Vlastimil Babka <vbabka@suse.cz>
    Cc: airlied@linux.ie
    Cc: benh@kernel.crashing.org
    Cc: dan.j.williams@intel.com
    Cc: david.vrabel@citrix.com
    Cc: jbeulich@suse.com
    Cc: konrad.wilk@oracle.com
    Cc: linux-arch@vger.kernel.org
    Cc: linux-fbdev@vger.kernel.org
    Cc: linux-pci@vger.kernel.org
    Cc: venkatesh.pallipadi@intel.com
    Cc: vinod.koul@intel.com
    Cc: xen-devel@lists.xensource.com
    Link: http://lkml.kernel.org/r/1440443613-13696-6-git-send-email-mcgrof@do-not-panic.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/lib/pci_iomap.c b/lib/pci_iomap.c
index bcce5f149310..5f5d24d1d53f 100644
--- a/lib/pci_iomap.c
+++ b/lib/pci_iomap.c
@@ -51,6 +51,51 @@ void __iomem *pci_iomap_range(struct pci_dev *dev,
 }
 EXPORT_SYMBOL(pci_iomap_range);
 
+/**
+ * pci_iomap_wc_range - create a virtual WC mapping cookie for a PCI BAR
+ * @dev: PCI device that owns the BAR
+ * @bar: BAR number
+ * @offset: map memory at the given offset in BAR
+ * @maxlen: max length of the memory to map
+ *
+ * Using this function you will get a __iomem address to your device BAR.
+ * You can access it using ioread*() and iowrite*(). These functions hide
+ * the details if this is a MMIO or PIO address space and will just do what
+ * you expect from them in the correct way. When possible write combining
+ * is used.
+ *
+ * @maxlen specifies the maximum length to map. If you want to get access to
+ * the complete BAR from offset to the end, pass %0 here.
+ * */
+void __iomem *pci_iomap_wc_range(struct pci_dev *dev,
+				 int bar,
+				 unsigned long offset,
+				 unsigned long maxlen)
+{
+	resource_size_t start = pci_resource_start(dev, bar);
+	resource_size_t len = pci_resource_len(dev, bar);
+	unsigned long flags = pci_resource_flags(dev, bar);
+
+
+	if (flags & IORESOURCE_IO)
+		return NULL;
+
+	if (len <= offset || !start)
+		return NULL;
+
+	len -= offset;
+	start += offset;
+	if (maxlen && len > maxlen)
+		len = maxlen;
+
+	if (flags & IORESOURCE_MEM)
+		return ioremap_wc(start, len);
+
+	/* What? */
+	return NULL;
+}
+EXPORT_SYMBOL_GPL(pci_iomap_wc_range);
+
 /**
  * pci_iomap - create a virtual mapping cookie for a PCI BAR
  * @dev: PCI device that owns the BAR
@@ -70,4 +115,25 @@ void __iomem *pci_iomap(struct pci_dev *dev, int bar, unsigned long maxlen)
 	return pci_iomap_range(dev, bar, 0, maxlen);
 }
 EXPORT_SYMBOL(pci_iomap);
+
+/**
+ * pci_iomap_wc - create a virtual WC mapping cookie for a PCI BAR
+ * @dev: PCI device that owns the BAR
+ * @bar: BAR number
+ * @maxlen: length of the memory to map
+ *
+ * Using this function you will get a __iomem address to your device BAR.
+ * You can access it using ioread*() and iowrite*(). These functions hide
+ * the details if this is a MMIO or PIO address space and will just do what
+ * you expect from them in the correct way. When possible write combining
+ * is used.
+ *
+ * @maxlen specifies the maximum length to map. If you want to get access to
+ * the complete BAR without checking for its length first, pass %0 here.
+ * */
+void __iomem *pci_iomap_wc(struct pci_dev *dev, int bar, unsigned long maxlen)
+{
+	return pci_iomap_wc_range(dev, bar, 0, maxlen);
+}
+EXPORT_SYMBOL_GPL(pci_iomap_wc);
 #endif /* CONFIG_PCI */

commit 92b19ff50e8f242392d78b2aacc5b5b672f1796b
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Mon Aug 10 23:07:06 2015 -0400

    cleanup IORESOURCE_CACHEABLE vs ioremap()
    
    Quoting Arnd:
        I was thinking the opposite approach and basically removing all uses
        of IORESOURCE_CACHEABLE from the kernel. There are only a handful of
        them.and we can probably replace them all with hardcoded
        ioremap_cached() calls in the cases they are actually useful.
    
    All existing usages of IORESOURCE_CACHEABLE call ioremap() instead of
    ioremap_nocache() if the resource is cacheable, however ioremap() is
    uncached by default. Clearly none of the existing usages care about the
    cacheability. Particularly devm_ioremap_resource() never worked as
    advertised since it always fell back to plain ioremap().
    
    Clean this up as the new direction we want is to convert
    ioremap_<type>() usages to memremap(..., flags).
    
    Suggested-by: Arnd Bergmann <arnd@arndb.de>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/lib/pci_iomap.c b/lib/pci_iomap.c
index bcce5f149310..e1930dbab2da 100644
--- a/lib/pci_iomap.c
+++ b/lib/pci_iomap.c
@@ -41,11 +41,8 @@ void __iomem *pci_iomap_range(struct pci_dev *dev,
 		len = maxlen;
 	if (flags & IORESOURCE_IO)
 		return __pci_ioport_map(dev, start, len);
-	if (flags & IORESOURCE_MEM) {
-		if (flags & IORESOURCE_CACHEABLE)
-			return ioremap(start, len);
-		return ioremap_nocache(start, len);
-	}
+	if (flags & IORESOURCE_MEM)
+		return ioremap(start, len);
 	/* What? */
 	return NULL;
 }

commit eb29d8d2aad70636ea23810b4868693673d630d5
Author: Michael S. Tsirkin <mst@redhat.com>
Date:   Wed May 29 11:52:21 2013 +0930

    pci: add pci_iomap_range
    
    Virtio drivers should map the part of the BAR they need, not necessarily
    all of it.
    
    Cc: Bjorn Helgaas <bhelgaas@google.com>
    Cc: linux-pci@vger.kernel.org
    Acked-by: Arnd Bergmann <arnd@arndb.de>
    Signed-off-by: Michael S. Tsirkin <mst@redhat.com>
    Signed-off-by: Rusty Russell <rusty@rustcorp.com.au>

diff --git a/lib/pci_iomap.c b/lib/pci_iomap.c
index 0d83ea8a9605..bcce5f149310 100644
--- a/lib/pci_iomap.c
+++ b/lib/pci_iomap.c
@@ -10,10 +10,11 @@
 
 #ifdef CONFIG_PCI
 /**
- * pci_iomap - create a virtual mapping cookie for a PCI BAR
+ * pci_iomap_range - create a virtual mapping cookie for a PCI BAR
  * @dev: PCI device that owns the BAR
  * @bar: BAR number
- * @maxlen: length of the memory to map
+ * @offset: map memory at the given offset in BAR
+ * @maxlen: max length of the memory to map
  *
  * Using this function you will get a __iomem address to your device BAR.
  * You can access it using ioread*() and iowrite*(). These functions hide
@@ -21,16 +22,21 @@
  * you expect from them in the correct way.
  *
  * @maxlen specifies the maximum length to map. If you want to get access to
- * the complete BAR without checking for its length first, pass %0 here.
+ * the complete BAR from offset to the end, pass %0 here.
  * */
-void __iomem *pci_iomap(struct pci_dev *dev, int bar, unsigned long maxlen)
+void __iomem *pci_iomap_range(struct pci_dev *dev,
+			      int bar,
+			      unsigned long offset,
+			      unsigned long maxlen)
 {
 	resource_size_t start = pci_resource_start(dev, bar);
 	resource_size_t len = pci_resource_len(dev, bar);
 	unsigned long flags = pci_resource_flags(dev, bar);
 
-	if (!len || !start)
+	if (len <= offset || !start)
 		return NULL;
+	len -= offset;
+	start += offset;
 	if (maxlen && len > maxlen)
 		len = maxlen;
 	if (flags & IORESOURCE_IO)
@@ -43,6 +49,25 @@ void __iomem *pci_iomap(struct pci_dev *dev, int bar, unsigned long maxlen)
 	/* What? */
 	return NULL;
 }
+EXPORT_SYMBOL(pci_iomap_range);
 
+/**
+ * pci_iomap - create a virtual mapping cookie for a PCI BAR
+ * @dev: PCI device that owns the BAR
+ * @bar: BAR number
+ * @maxlen: length of the memory to map
+ *
+ * Using this function you will get a __iomem address to your device BAR.
+ * You can access it using ioread*() and iowrite*(). These functions hide
+ * the details if this is a MMIO or PIO address space and will just do what
+ * you expect from them in the correct way.
+ *
+ * @maxlen specifies the maximum length to map. If you want to get access to
+ * the complete BAR without checking for its length first, pass %0 here.
+ * */
+void __iomem *pci_iomap(struct pci_dev *dev, int bar, unsigned long maxlen)
+{
+	return pci_iomap_range(dev, bar, 0, maxlen);
+}
 EXPORT_SYMBOL(pci_iomap);
 #endif /* CONFIG_PCI */

commit b923650b84068b74b6df838aa8f9b2a350171de6
Author: Michael S. Tsirkin <mst@redhat.com>
Date:   Mon Jan 30 00:20:48 2012 +0200

    lib: add NO_GENERIC_PCI_IOPORT_MAP
    
    Some architectures need to override the way
    IO port mapping is done on PCI devices.
    Supply a generic macro that calls
    ioport_map, and make it possible for architectures
    to override.
    
    Signed-off-by: Michael S. Tsirkin <mst@redhat.com>
    Acked-by: Arnd Bergmann <arnd@arndb.de>

diff --git a/lib/pci_iomap.c b/lib/pci_iomap.c
index 4b0fdc22e688..0d83ea8a9605 100644
--- a/lib/pci_iomap.c
+++ b/lib/pci_iomap.c
@@ -34,7 +34,7 @@ void __iomem *pci_iomap(struct pci_dev *dev, int bar, unsigned long maxlen)
 	if (maxlen && len > maxlen)
 		len = maxlen;
 	if (flags & IORESOURCE_IO)
-		return ioport_map(start, len);
+		return __pci_ioport_map(dev, start, len);
 	if (flags & IORESOURCE_MEM) {
 		if (flags & IORESOURCE_CACHEABLE)
 			return ioremap(start, len);

commit 66eab4df288aaee75938ae99877c4f759fc6d56c
Author: Michael S. Tsirkin <mst@redhat.com>
Date:   Thu Nov 24 20:45:20 2011 +0200

    lib: add GENERIC_PCI_IOMAP
    
    Many architectures want a generic pci_iomap but
    not the rest of iomap.c. Split that to a separate .c
    file and add a new config symbol. select automatically
    by GENERIC_IOMAP.
    
    Signed-off-by: Michael S. Tsirkin <mst@redhat.com>

diff --git a/lib/pci_iomap.c b/lib/pci_iomap.c
new file mode 100644
index 000000000000..4b0fdc22e688
--- /dev/null
+++ b/lib/pci_iomap.c
@@ -0,0 +1,48 @@
+/*
+ * Implement the default iomap interfaces
+ *
+ * (C) Copyright 2004 Linus Torvalds
+ */
+#include <linux/pci.h>
+#include <linux/io.h>
+
+#include <linux/export.h>
+
+#ifdef CONFIG_PCI
+/**
+ * pci_iomap - create a virtual mapping cookie for a PCI BAR
+ * @dev: PCI device that owns the BAR
+ * @bar: BAR number
+ * @maxlen: length of the memory to map
+ *
+ * Using this function you will get a __iomem address to your device BAR.
+ * You can access it using ioread*() and iowrite*(). These functions hide
+ * the details if this is a MMIO or PIO address space and will just do what
+ * you expect from them in the correct way.
+ *
+ * @maxlen specifies the maximum length to map. If you want to get access to
+ * the complete BAR without checking for its length first, pass %0 here.
+ * */
+void __iomem *pci_iomap(struct pci_dev *dev, int bar, unsigned long maxlen)
+{
+	resource_size_t start = pci_resource_start(dev, bar);
+	resource_size_t len = pci_resource_len(dev, bar);
+	unsigned long flags = pci_resource_flags(dev, bar);
+
+	if (!len || !start)
+		return NULL;
+	if (maxlen && len > maxlen)
+		len = maxlen;
+	if (flags & IORESOURCE_IO)
+		return ioport_map(start, len);
+	if (flags & IORESOURCE_MEM) {
+		if (flags & IORESOURCE_CACHEABLE)
+			return ioremap(start, len);
+		return ioremap_nocache(start, len);
+	}
+	/* What? */
+	return NULL;
+}
+
+EXPORT_SYMBOL(pci_iomap);
+#endif /* CONFIG_PCI */
