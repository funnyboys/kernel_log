commit 45ec975efb527625629d123f30597673889f52ca
Author: Dave Rodgman <dave.rodgman@arm.com>
Date:   Thu Mar 7 16:30:44 2019 -0800

    lib/lzo: separate lzo-rle from lzo
    
    To prevent any issues with persistent data, separate lzo-rle from lzo so
    that it is treated as a separate algorithm, and lzo is still available.
    
    Link: http://lkml.kernel.org/r/20190205155944.16007-3-dave.rodgman@arm.com
    Signed-off-by: Dave Rodgman <dave.rodgman@arm.com>
    Cc: David S. Miller <davem@davemloft.net>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Herbert Xu <herbert@gondor.apana.org.au>
    Cc: Markus F.X.J. Oberhumer <markus@oberhumer.com>
    Cc: Matt Sealey <matt.sealey@arm.com>
    Cc: Minchan Kim <minchan@kernel.org>
    Cc: Nitin Gupta <nitingupta910@gmail.com>
    Cc: Richard Purdie <rpurdie@openedhand.com>
    Cc: Sergey Senozhatsky <sergey.senozhatsky.work@gmail.com>
    Cc: Sonny Rao <sonnyrao@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/lib/lzo/lzodefs.h b/lib/lzo/lzodefs.h
index ac64159ee344..b60851fcf6ce 100644
--- a/lib/lzo/lzodefs.h
+++ b/lib/lzo/lzodefs.h
@@ -44,7 +44,8 @@
 #define M1_MAX_OFFSET	0x0400
 #define M2_MAX_OFFSET	0x0800
 #define M3_MAX_OFFSET	0x4000
-#define M4_MAX_OFFSET	0xbffe
+#define M4_MAX_OFFSET_V0	0xbfff
+#define M4_MAX_OFFSET_V1	0xbffe
 
 #define M1_MIN_LEN	2
 #define M1_MAX_LEN	2

commit 5ee4014af99f77dac89e01961b717d13ff1a8ea5
Author: Dave Rodgman <dave.rodgman@arm.com>
Date:   Thu Mar 7 16:30:40 2019 -0800

    lib/lzo: implement run-length encoding
    
    Patch series "lib/lzo: run-length encoding support", v5.
    
    Following on from the previous lzo-rle patchset:
    
      https://lkml.org/lkml/2018/11/30/972
    
    This patchset contains only the RLE patches, and should be applied on
    top of the non-RLE patches ( https://lkml.org/lkml/2019/2/5/366 ).
    
    Previously, some questions were raised around the RLE patches.  I've
    done some additional benchmarking to answer these questions.  In short:
    
     - RLE offers significant additional performance (data-dependent)
    
     - I didn't measure any regressions that were clearly outside the noise
    
    One concern with this patchset was around performance - specifically,
    measuring RLE impact separately from Matt Sealey's patches (CTZ & fast
    copy).  I have done some additional benchmarking which I hope clarifies
    the benefits of each part of the patchset.
    
    Firstly, I've captured some memory via /dev/fmem from a Chromebook with
    many tabs open which is starting to swap, and then split this into 4178
    4k pages.  I've excluded the all-zero pages (as zram does), and also the
    no-zero pages (which won't tell us anything about RLE performance).
    This should give a realistic test dataset for zram.  What I found was
    that the data is VERY bimodal: 44% of pages in this dataset contain 5%
    or fewer zeros, and 44% contain over 90% zeros (30% if you include the
    no-zero pages).  This supports the idea of special-casing zeros in zram.
    
    Next, I've benchmarked four variants of lzo on these pages (on 64-bit
    Arm at max frequency): baseline LZO; baseline + Matt Sealey's patches
    (aka MS); baseline + RLE only; baseline + MS + RLE.  Numbers are for
    weighted roundtrip throughput (the weighting reflects that zram does
    more compression than decompression).
    
      https://drive.google.com/file/d/1VLtLjRVxgUNuWFOxaGPwJYhl_hMQXpHe/view?usp=sharing
    
    Matt's patches help in all cases for Arm (and no effect on Intel), as
    expected.
    
    RLE also behaves as expected: with few zeros present, it makes no
    difference; above ~75%, it gives a good improvement (50 - 300 MB/s on
    top of the benefit from Matt's patches).
    
    Best performance is seen with both MS and RLE patches.
    
    Finally, I have benchmarked the same dataset on an x86-64 device.  Here,
    the MS patches make no difference (as expected); RLE helps, similarly as
    on Arm.  There were no definite regressions; allowing for observational
    error, 0.1% (3/4178) of cases had a regression > 1 standard deviation,
    of which the largest was 4.6% (1.2 standard deviations).  I think this
    is probably within the noise.
    
      https://drive.google.com/file/d/1xCUVwmiGD0heEMx5gcVEmLBI4eLaageV/view?usp=sharing
    
    One point to note is that the graphs show RLE appears to help very
    slightly with no zeros present! This is because the extra code causes
    the clang optimiser to change code layout in a way that happens to have
    a significant benefit.  Taking baseline LZO and adding a do-nothing line
    like "__builtin_prefetch(out_len);" immediately before the "goto next"
    has the same effect.  So this is a real, but basically spurious effect -
    it's small enough not to upset the overall findings.
    
    This patch (of 3):
    
    When using zram, we frequently encounter long runs of zero bytes.  This
    adds a special case which identifies runs of zeros and encodes them
    using run-length encoding.
    
    This is faster for both compression and decompresion.  For high-entropy
    data which doesn't hit this case, impact is minimal.
    
    Compression ratio is within a few percent in all cases.
    
    This modifies the bitstream in a way which is backwards compatible
    (i.e., we can decompress old bitstreams, but old versions of lzo cannot
    decompress new bitstreams).
    
    Link: http://lkml.kernel.org/r/20190205155944.16007-2-dave.rodgman@arm.com
    Signed-off-by: Dave Rodgman <dave.rodgman@arm.com>
    Cc: David S. Miller <davem@davemloft.net>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Herbert Xu <herbert@gondor.apana.org.au>
    Cc: Markus F.X.J. Oberhumer <markus@oberhumer.com>
    Cc: Matt Sealey <matt.sealey@arm.com>
    Cc: Minchan Kim <minchan@kernel.org>
    Cc: Nitin Gupta <nitingupta910@gmail.com>
    Cc: Richard Purdie <rpurdie@openedhand.com>
    Cc: Sergey Senozhatsky <sergey.senozhatsky.work@gmail.com>
    Cc: Sonny Rao <sonnyrao@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/lib/lzo/lzodefs.h b/lib/lzo/lzodefs.h
index fa0a45fed8c4..ac64159ee344 100644
--- a/lib/lzo/lzodefs.h
+++ b/lib/lzo/lzodefs.h
@@ -13,6 +13,12 @@
  */
 
 
+/* Version
+ * 0: original lzo version
+ * 1: lzo with support for RLE
+ */
+#define LZO_VERSION 1
+
 #define COPY4(dst, src)	\
 		put_unaligned(get_unaligned((const u32 *)(src)), (u32 *)(dst))
 #if defined(CONFIG_X86_64) || defined(CONFIG_ARM64)
@@ -28,6 +34,7 @@
 #elif defined(CONFIG_X86_64) || defined(CONFIG_ARM64)
 #define LZO_USE_CTZ64	1
 #define LZO_USE_CTZ32	1
+#define LZO_FAST_64BIT_MEMORY_ACCESS
 #elif defined(CONFIG_X86) || defined(CONFIG_PPC)
 #define LZO_USE_CTZ32	1
 #elif defined(CONFIG_ARM) && (__LINUX_ARM_ARCH__ >= 5)
@@ -37,7 +44,7 @@
 #define M1_MAX_OFFSET	0x0400
 #define M2_MAX_OFFSET	0x0800
 #define M3_MAX_OFFSET	0x4000
-#define M4_MAX_OFFSET	0xbfff
+#define M4_MAX_OFFSET	0xbffe
 
 #define M1_MIN_LEN	2
 #define M1_MAX_LEN	2
@@ -53,6 +60,9 @@
 #define M3_MARKER	32
 #define M4_MARKER	16
 
+#define MIN_ZERO_RUN_LENGTH	4
+#define MAX_ZERO_RUN_LENGTH	(2047 + MIN_ZERO_RUN_LENGTH)
+
 #define lzo_dict_t      unsigned short
 #define D_BITS		13
 #define D_SIZE		(1u << D_BITS)

commit 761b3238504858bbc630dc957eed1659dd7eaff1
Author: Matt Sealey <matt.sealey@arm.com>
Date:   Thu Mar 7 16:30:36 2019 -0800

    lib/lzo: fast 8-byte copy on arm64
    
    Enable faster 8-byte copies on arm64.
    
    Link: http://lkml.kernel.org/r/20181127161913.23863-6-dave.rodgman@arm.com
    Link: http://lkml.kernel.org/r/20190205141950.9058-4-dave.rodgman@arm.com
    Signed-off-by: Matt Sealey <matt.sealey@arm.com>
    Signed-off-by: Dave Rodgman <dave.rodgman@arm.com>
    Cc: David S. Miller <davem@davemloft.net>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Herbert Xu <herbert@gondor.apana.org.au>
    Cc: Markus F.X.J. Oberhumer <markus@oberhumer.com>
    Cc: Minchan Kim <minchan@kernel.org>
    Cc: Nitin Gupta <nitingupta910@gmail.com>
    Cc: Richard Purdie <rpurdie@openedhand.com>
    Cc: Sergey Senozhatsky <sergey.senozhatsky.work@gmail.com>
    Cc: Sonny Rao <sonnyrao@google.com>
    Cc: Stephen Rothwell <sfr@canb.auug.org.au>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/lib/lzo/lzodefs.h b/lib/lzo/lzodefs.h
index 00d1080155e4..fa0a45fed8c4 100644
--- a/lib/lzo/lzodefs.h
+++ b/lib/lzo/lzodefs.h
@@ -15,7 +15,7 @@
 
 #define COPY4(dst, src)	\
 		put_unaligned(get_unaligned((const u32 *)(src)), (u32 *)(dst))
-#if defined(CONFIG_X86_64)
+#if defined(CONFIG_X86_64) || defined(CONFIG_ARM64)
 #define COPY8(dst, src)	\
 		put_unaligned(get_unaligned((const u64 *)(src)), (u64 *)(dst))
 #else

commit 433b3b3d9f642e37b270cd29aef53cee75ef4a05
Author: Matt Sealey <matt.sealey@arm.com>
Date:   Thu Mar 7 16:30:33 2019 -0800

    lib/lzo: 64-bit CTZ on arm64
    
    LZO leaves some performance on the table by not realising that arm64 can
    optimize count-trailing-zeros bit operations.
    
    Add CONFIG_ARM64 to the checked definitions alongside CONFIG_X86_64 to
    enable the use of rbit/clz instructions on full 64-bit quantities.
    
    Link: http://lkml.kernel.org/r/20181127161913.23863-5-dave.rodgman@arm.com
    Link: http://lkml.kernel.org/r/20190205141950.9058-3-dave.rodgman@arm.com
    Signed-off-by: Matt Sealey <matt.sealey@arm.com>
    Signed-off-by: Dave Rodgman <dave.rodgman@arm.com>
    Cc: David S. Miller <davem@davemloft.net>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Herbert Xu <herbert@gondor.apana.org.au>
    Cc: Markus F.X.J. Oberhumer <markus@oberhumer.com>
    Cc: Minchan Kim <minchan@kernel.org>
    Cc: Nitin Gupta <nitingupta910@gmail.com>
    Cc: Richard Purdie <rpurdie@openedhand.com>
    Cc: Sergey Senozhatsky <sergey.senozhatsky.work@gmail.com>
    Cc: Sonny Rao <sonnyrao@google.com>
    Cc: Stephen Rothwell <sfr@canb.auug.org.au>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/lib/lzo/lzodefs.h b/lib/lzo/lzodefs.h
index 497f9c9f03a8..00d1080155e4 100644
--- a/lib/lzo/lzodefs.h
+++ b/lib/lzo/lzodefs.h
@@ -25,7 +25,7 @@
 
 #if defined(__BIG_ENDIAN) && defined(__LITTLE_ENDIAN)
 #error "conflicting endian definitions"
-#elif defined(CONFIG_X86_64)
+#elif defined(CONFIG_X86_64) || defined(CONFIG_ARM64)
 #define LZO_USE_CTZ64	1
 #define LZO_USE_CTZ32	1
 #elif defined(CONFIG_X86) || defined(CONFIG_PPC)

commit 95777591d07e08ebb95bb373237fcfbf54fcbf5c
Author: Dave Rodgman <dave.rodgman@arm.com>
Date:   Thu Mar 7 16:30:29 2019 -0800

    lib/lzo: tidy-up ifdefs
    
    Patch series "lib/lzo: performance improvements", v5.
    
    This patch (of 3):
    
    Modify the ifdefs in lzodefs.h to be more consistent with normal kernel
    macros (e.g., change __aarch64__ to CONFIG_ARM64).
    
    Link: http://lkml.kernel.org/r/20190205141950.9058-2-dave.rodgman@arm.com
    Signed-off-by: Dave Rodgman <dave.rodgman@arm.com>
    Cc: Herbert Xu <herbert@gondor.apana.org.au>
    Cc: David S. Miller <davem@davemloft.net>
    Cc: Nitin Gupta <nitingupta910@gmail.com>
    Cc: Richard Purdie <rpurdie@openedhand.com>
    Cc: Markus F.X.J. Oberhumer <markus@oberhumer.com>
    Cc: Minchan Kim <minchan@kernel.org>
    Cc: Sergey Senozhatsky <sergey.senozhatsky.work@gmail.com>
    Cc: Sonny Rao <sonnyrao@google.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Matt Sealey <matt.sealey@arm.com>
    Cc: Stephen Rothwell <sfr@canb.auug.org.au>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/lib/lzo/lzodefs.h b/lib/lzo/lzodefs.h
index 4edefd2f540c..497f9c9f03a8 100644
--- a/lib/lzo/lzodefs.h
+++ b/lib/lzo/lzodefs.h
@@ -15,7 +15,7 @@
 
 #define COPY4(dst, src)	\
 		put_unaligned(get_unaligned((const u32 *)(src)), (u32 *)(dst))
-#if defined(__x86_64__)
+#if defined(CONFIG_X86_64)
 #define COPY8(dst, src)	\
 		put_unaligned(get_unaligned((const u64 *)(src)), (u64 *)(dst))
 #else
@@ -25,12 +25,12 @@
 
 #if defined(__BIG_ENDIAN) && defined(__LITTLE_ENDIAN)
 #error "conflicting endian definitions"
-#elif defined(__x86_64__)
+#elif defined(CONFIG_X86_64)
 #define LZO_USE_CTZ64	1
 #define LZO_USE_CTZ32	1
-#elif defined(__i386__) || defined(__powerpc__)
+#elif defined(CONFIG_X86) || defined(CONFIG_PPC)
 #define LZO_USE_CTZ32	1
-#elif defined(__arm__) && (__LINUX_ARM_ARCH__ >= 5)
+#elif defined(CONFIG_ARM) && (__LINUX_ARM_ARCH__ >= 5)
 #define LZO_USE_CTZ32	1
 #endif
 

commit b24413180f5600bcb3bb70fbed5cf186b60864bd
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 1 15:07:57 2017 +0100

    License cleanup: add SPDX GPL-2.0 license identifier to files with no license
    
    Many source files in the tree are missing licensing information, which
    makes it harder for compliance tools to determine the correct license.
    
    By default all files without license information are under the default
    license of the kernel, which is GPL version 2.
    
    Update the files which contain no license information with the 'GPL-2.0'
    SPDX license identifier.  The SPDX identifier is a legally binding
    shorthand, which can be used instead of the full boiler plate text.
    
    This patch is based on work done by Thomas Gleixner and Kate Stewart and
    Philippe Ombredanne.
    
    How this work was done:
    
    Patches were generated and checked against linux-4.14-rc6 for a subset of
    the use cases:
     - file had no licensing information it it.
     - file was a */uapi/* one with no licensing information in it,
     - file was a */uapi/* one with existing licensing information,
    
    Further patches will be generated in subsequent months to fix up cases
    where non-standard license headers were used, and references to license
    had to be inferred by heuristics based on keywords.
    
    The analysis to determine which SPDX License Identifier to be applied to
    a file was done in a spreadsheet of side by side results from of the
    output of two independent scanners (ScanCode & Windriver) producing SPDX
    tag:value files created by Philippe Ombredanne.  Philippe prepared the
    base worksheet, and did an initial spot review of a few 1000 files.
    
    The 4.13 kernel was the starting point of the analysis with 60,537 files
    assessed.  Kate Stewart did a file by file comparison of the scanner
    results in the spreadsheet to determine which SPDX license identifier(s)
    to be applied to the file. She confirmed any determination that was not
    immediately clear with lawyers working with the Linux Foundation.
    
    Criteria used to select files for SPDX license identifier tagging was:
     - Files considered eligible had to be source code files.
     - Make and config files were included as candidates if they contained >5
       lines of source
     - File already had some variant of a license header in it (even if <5
       lines).
    
    All documentation files were explicitly excluded.
    
    The following heuristics were used to determine which SPDX license
    identifiers to apply.
    
     - when both scanners couldn't find any license traces, file was
       considered to have no license information in it, and the top level
       COPYING file license applied.
    
       For non */uapi/* files that summary was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0                                              11139
    
       and resulted in the first patch in this series.
    
       If that file was a */uapi/* path one, it was "GPL-2.0 WITH
       Linux-syscall-note" otherwise it was "GPL-2.0".  Results of that was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0 WITH Linux-syscall-note                        930
    
       and resulted in the second patch in this series.
    
     - if a file had some form of licensing information in it, and was one
       of the */uapi/* ones, it was denoted with the Linux-syscall-note if
       any GPL family license was found in the file or had no licensing in
       it (per prior point).  Results summary:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|------
       GPL-2.0 WITH Linux-syscall-note                       270
       GPL-2.0+ WITH Linux-syscall-note                      169
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-2-Clause)    21
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-3-Clause)    17
       LGPL-2.1+ WITH Linux-syscall-note                      15
       GPL-1.0+ WITH Linux-syscall-note                       14
       ((GPL-2.0+ WITH Linux-syscall-note) OR BSD-3-Clause)    5
       LGPL-2.0+ WITH Linux-syscall-note                       4
       LGPL-2.1 WITH Linux-syscall-note                        3
       ((GPL-2.0 WITH Linux-syscall-note) OR MIT)              3
       ((GPL-2.0 WITH Linux-syscall-note) AND MIT)             1
    
       and that resulted in the third patch in this series.
    
     - when the two scanners agreed on the detected license(s), that became
       the concluded license(s).
    
     - when there was disagreement between the two scanners (one detected a
       license but the other didn't, or they both detected different
       licenses) a manual inspection of the file occurred.
    
     - In most cases a manual inspection of the information in the file
       resulted in a clear resolution of the license that should apply (and
       which scanner probably needed to revisit its heuristics).
    
     - When it was not immediately clear, the license identifier was
       confirmed with lawyers working with the Linux Foundation.
    
     - If there was any question as to the appropriate license identifier,
       the file was flagged for further research and to be revisited later
       in time.
    
    In total, over 70 hours of logged manual review was done on the
    spreadsheet to determine the SPDX license identifiers to apply to the
    source files by Kate, Philippe, Thomas and, in some cases, confirmation
    by lawyers working with the Linux Foundation.
    
    Kate also obtained a third independent scan of the 4.13 code base from
    FOSSology, and compared selected files where the other two scanners
    disagreed against that SPDX file, to see if there was new insights.  The
    Windriver scanner is based on an older version of FOSSology in part, so
    they are related.
    
    Thomas did random spot checks in about 500 files from the spreadsheets
    for the uapi headers and agreed with SPDX license identifier in the
    files he inspected. For the non-uapi files Thomas did random spot checks
    in about 15000 files.
    
    In initial set of patches against 4.14-rc6, 3 files were found to have
    copy/paste license identifier errors, and have been fixed to reflect the
    correct identifier.
    
    Additionally Philippe spent 10 hours this week doing a detailed manual
    inspection and review of the 12,461 patched files from the initial patch
    version early this week with:
     - a full scancode scan run, collecting the matched texts, detected
       license ids and scores
     - reviewing anything where there was a license detected (about 500+
       files) to ensure that the applied SPDX license was correct
     - reviewing anything where there was no detection but the patch license
       was not GPL-2.0 WITH Linux-syscall-note to ensure that the applied
       SPDX license was correct
    
    This produced a worksheet with 20 files needing minor correction.  This
    worksheet was then exported into 3 different .csv files for the
    different types of files to be modified.
    
    These .csv files were then reviewed by Greg.  Thomas wrote a script to
    parse the csv files and add the proper SPDX tag to the file, in the
    format that the file expected.  This script was further refined by Greg
    based on the output to detect more types of files automatically and to
    distinguish between header and source .c files (which need different
    comment types.)  Finally Greg ran the script using the .csv files to
    generate the patches.
    
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Philippe Ombredanne <pombredanne@nexb.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/lib/lzo/lzodefs.h b/lib/lzo/lzodefs.h
index 6710b83ce72e..4edefd2f540c 100644
--- a/lib/lzo/lzodefs.h
+++ b/lib/lzo/lzodefs.h
@@ -1,3 +1,4 @@
+/* SPDX-License-Identifier: GPL-2.0 */
 /*
  *  lzodefs.h -- architecture, OS and compiler specific defines
  *

commit 8b975bd3f9089f8ee5d7bbfd798537b992bbc7e7
Author: Markus F.X.J. Oberhumer <markus@oberhumer.com>
Date:   Mon Aug 13 17:25:44 2012 +0200

    lib/lzo: Update LZO compression to current upstream version
    
    This commit updates the kernel LZO code to the current upsteam version
    which features a significant speed improvement - benchmarking the Calgary
    and Silesia test corpora typically shows a doubled performance in
    both compression and decompression on modern i386/x86_64/powerpc machines.
    
    Signed-off-by: Markus F.X.J. Oberhumer <markus@oberhumer.com>

diff --git a/lib/lzo/lzodefs.h b/lib/lzo/lzodefs.h
index b6d482c492ef..6710b83ce72e 100644
--- a/lib/lzo/lzodefs.h
+++ b/lib/lzo/lzodefs.h
@@ -1,19 +1,37 @@
 /*
  *  lzodefs.h -- architecture, OS and compiler specific defines
  *
- *  Copyright (C) 1996-2005 Markus F.X.J. Oberhumer <markus@oberhumer.com>
+ *  Copyright (C) 1996-2012 Markus F.X.J. Oberhumer <markus@oberhumer.com>
  *
  *  The full LZO package can be found at:
  *  http://www.oberhumer.com/opensource/lzo/
  *
- *  Changed for kernel use by:
+ *  Changed for Linux kernel use by:
  *  Nitin Gupta <nitingupta910@gmail.com>
  *  Richard Purdie <rpurdie@openedhand.com>
  */
 
-#define LZO_VERSION		0x2020
-#define LZO_VERSION_STRING	"2.02"
-#define LZO_VERSION_DATE	"Oct 17 2005"
+
+#define COPY4(dst, src)	\
+		put_unaligned(get_unaligned((const u32 *)(src)), (u32 *)(dst))
+#if defined(__x86_64__)
+#define COPY8(dst, src)	\
+		put_unaligned(get_unaligned((const u64 *)(src)), (u64 *)(dst))
+#else
+#define COPY8(dst, src)	\
+		COPY4(dst, src); COPY4((dst) + 4, (src) + 4)
+#endif
+
+#if defined(__BIG_ENDIAN) && defined(__LITTLE_ENDIAN)
+#error "conflicting endian definitions"
+#elif defined(__x86_64__)
+#define LZO_USE_CTZ64	1
+#define LZO_USE_CTZ32	1
+#elif defined(__i386__) || defined(__powerpc__)
+#define LZO_USE_CTZ32	1
+#elif defined(__arm__) && (__LINUX_ARM_ARCH__ >= 5)
+#define LZO_USE_CTZ32	1
+#endif
 
 #define M1_MAX_OFFSET	0x0400
 #define M2_MAX_OFFSET	0x0800
@@ -34,10 +52,8 @@
 #define M3_MARKER	32
 #define M4_MARKER	16
 
-#define D_BITS		14
-#define D_MASK		((1u << D_BITS) - 1)
+#define lzo_dict_t      unsigned short
+#define D_BITS		13
+#define D_SIZE		(1u << D_BITS)
+#define D_MASK		(D_SIZE - 1)
 #define D_HIGH		((D_MASK >> 1) + 1)
-
-#define DX2(p, s1, s2)	(((((size_t)((p)[2]) << (s2)) ^ (p)[1]) \
-							<< (s1)) ^ (p)[0])
-#define DX3(p, s1, s2, s3)	((DX2((p)+1, s2, s3) << (s1)) ^ (p)[0])

commit 64c70b1cf43de158282bc1675918d503e5b15cc1
Author: Richard Purdie <rpurdie@openedhand.com>
Date:   Tue Jul 10 17:22:24 2007 -0700

    Add LZO1X algorithm to the kernel
    
    This is a hybrid version of the patch to add the LZO1X compression
    algorithm to the kernel.  Nitin and myself have merged the best parts of
    the various patches to form this version which we're both happy with (and
    are jointly signing off).
    
    The performance of this version is equivalent to the original minilzo code
    it was based on.  Bytecode comparisons have also been made on ARM, i386 and
    x86_64 with favourable results.
    
    There are several users of LZO lined up including jffs2, crypto and reiser4
    since its much faster than zlib.
    
    Signed-off-by: Nitin Gupta <nitingupta910@gmail.com>
    Signed-off-by: Richard Purdie <rpurdie@openedhand.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/lib/lzo/lzodefs.h b/lib/lzo/lzodefs.h
new file mode 100644
index 000000000000..b6d482c492ef
--- /dev/null
+++ b/lib/lzo/lzodefs.h
@@ -0,0 +1,43 @@
+/*
+ *  lzodefs.h -- architecture, OS and compiler specific defines
+ *
+ *  Copyright (C) 1996-2005 Markus F.X.J. Oberhumer <markus@oberhumer.com>
+ *
+ *  The full LZO package can be found at:
+ *  http://www.oberhumer.com/opensource/lzo/
+ *
+ *  Changed for kernel use by:
+ *  Nitin Gupta <nitingupta910@gmail.com>
+ *  Richard Purdie <rpurdie@openedhand.com>
+ */
+
+#define LZO_VERSION		0x2020
+#define LZO_VERSION_STRING	"2.02"
+#define LZO_VERSION_DATE	"Oct 17 2005"
+
+#define M1_MAX_OFFSET	0x0400
+#define M2_MAX_OFFSET	0x0800
+#define M3_MAX_OFFSET	0x4000
+#define M4_MAX_OFFSET	0xbfff
+
+#define M1_MIN_LEN	2
+#define M1_MAX_LEN	2
+#define M2_MIN_LEN	3
+#define M2_MAX_LEN	8
+#define M3_MIN_LEN	3
+#define M3_MAX_LEN	33
+#define M4_MIN_LEN	3
+#define M4_MAX_LEN	9
+
+#define M1_MARKER	0
+#define M2_MARKER	64
+#define M3_MARKER	32
+#define M4_MARKER	16
+
+#define D_BITS		14
+#define D_MASK		((1u << D_BITS) - 1)
+#define D_HIGH		((D_MASK >> 1) + 1)
+
+#define DX2(p, s1, s2)	(((((size_t)((p)[2]) << (s2)) ^ (p)[1]) \
+							<< (s1)) ^ (p)[0])
+#define DX3(p, s1, s2, s3)	((DX2((p)+1, s2, s3) << (s1)) ^ (p)[0])
