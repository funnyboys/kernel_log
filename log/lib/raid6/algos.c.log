commit e6abef610c7363cbd25205674b962031ef3bc790
Author: Jason A. Donenfeld <Jason@zx2c4.com>
Date:   Thu Mar 26 14:26:00 2020 -0600

    x86: update AS_* macros to binutils >=2.23, supporting ADX and AVX2
    
    Now that the kernel specifies binutils 2.23 as the minimum version, we
    can remove ifdefs for AVX2 and ADX throughout.
    
    Signed-off-by: Jason A. Donenfeld <Jason@zx2c4.com>
    Acked-by: Ingo Molnar <mingo@kernel.org>
    Reviewed-by: Nick Desaulniers <ndesaulniers@google.com>
    Signed-off-by: Masahiro Yamada <masahiroy@kernel.org>

diff --git a/lib/raid6/algos.c b/lib/raid6/algos.c
index df08664d3432..6d5e5000fdd7 100644
--- a/lib/raid6/algos.c
+++ b/lib/raid6/algos.c
@@ -34,10 +34,8 @@ const struct raid6_calls * const raid6_algos[] = {
 	&raid6_avx512x2,
 	&raid6_avx512x1,
 #endif
-#ifdef CONFIG_AS_AVX2
 	&raid6_avx2x2,
 	&raid6_avx2x1,
-#endif
 	&raid6_sse2x2,
 	&raid6_sse2x1,
 	&raid6_sse1x2,
@@ -51,11 +49,9 @@ const struct raid6_calls * const raid6_algos[] = {
 	&raid6_avx512x2,
 	&raid6_avx512x1,
 #endif
-#ifdef CONFIG_AS_AVX2
 	&raid6_avx2x4,
 	&raid6_avx2x2,
 	&raid6_avx2x1,
-#endif
 	&raid6_sse2x4,
 	&raid6_sse2x2,
 	&raid6_sse2x1,
@@ -101,9 +97,7 @@ const struct raid6_recov_calls *const raid6_recov_algos[] = {
 #ifdef CONFIG_AS_AVX512
 	&raid6_recov_avx512,
 #endif
-#ifdef CONFIG_AS_AVX2
 	&raid6_recov_avx2,
-#endif
 	&raid6_recov_ssse3,
 #endif
 #ifdef CONFIG_S390

commit 92203b02805d99d8aca88b1c6b93c721237205fe
Author: Masahiro Yamada <masahiroy@kernel.org>
Date:   Thu Mar 26 17:00:54 2020 +0900

    x86: remove always-defined CONFIG_AS_SSSE3
    
    CONFIG_AS_SSSE3 was introduced by commit 75aaf4c3e6a4 ("x86/raid6:
    correctly check for assembler capabilities").
    
    We raise the minimal supported binutils version from time to time.
    The last bump was commit 1fb12b35e5ff ("kbuild: Raise the minimum
    required binutils version to 2.21").
    
    I confirmed the code in $(call as-instr,...) can be assembled by the
    binutils 2.21 assembler and also by LLVM integrated assembler.
    
    Remove CONFIG_AS_SSSE3, which is always defined.
    
    I added ifdef CONFIG_X86 to lib/raid6/algos.c to avoid link errors
    on non-x86 architectures.
    
    lib/raid6/algos.c is built not only for the kernel but also for
    testing the library code from userspace. I added -DCONFIG_X86 to
    lib/raid6/test/Makefile to cator to this usecase.
    
    Signed-off-by: Masahiro Yamada <masahiroy@kernel.org>
    Reviewed-by: Jason A. Donenfeld <Jason@zx2c4.com>
    Reviewed-by: Nick Desaulniers <ndesaulniers@google.com>
    Acked-by: Ingo Molnar <mingo@kernel.org>

diff --git a/lib/raid6/algos.c b/lib/raid6/algos.c
index bf1b4765c8f6..df08664d3432 100644
--- a/lib/raid6/algos.c
+++ b/lib/raid6/algos.c
@@ -97,13 +97,13 @@ void (*raid6_datap_recov)(int, size_t, int, void **);
 EXPORT_SYMBOL_GPL(raid6_datap_recov);
 
 const struct raid6_recov_calls *const raid6_recov_algos[] = {
+#ifdef CONFIG_X86
 #ifdef CONFIG_AS_AVX512
 	&raid6_recov_avx512,
 #endif
 #ifdef CONFIG_AS_AVX2
 	&raid6_recov_avx2,
 #endif
-#ifdef CONFIG_AS_SSSE3
 	&raid6_recov_ssse3,
 #endif
 #ifdef CONFIG_S390

commit f591df3cc6d60cadf8ceff5d44af73ea6ba0a39a
Author: Zhengyuan Liu <liuzhengyuan@kylinos.cn>
Date:   Fri Dec 20 10:21:28 2019 +0800

    md/raid6: fix algorithm choice under larger PAGE_SIZE
    
    There are several algorithms available for raid6 to generate xor and syndrome
    parity, including basic int1, int2 ... int32 and SIMD optimized implementation
    like sse and neon.  To test and choose the best algorithms at the initial
    stage, we need provide enough disk data to feed the algorithms. However, the
    disk number we provided depends on page size and gfmul table, seeing bellow:
    
        const int disks = (65536/PAGE_SIZE) + 2;
    
    So when come to 64K PAGE_SIZE, there is only one data disk plus 2 parity disk,
    as a result the chosed algorithm is not reliable. For example, on my arm64
    machine with 64K page enabled, it will choose intx32 as the best one, although
    the NEON implementation is better.
    
    This patch tries to fix the problem by defining a constant raid6 disk number to
    supporting arbitrary page size.
    
    Suggested-by: H. Peter Anvin <hpa@zytor.com>
    Signed-off-by: Zhengyuan Liu <liuzhengyuan@kylinos.cn>
    Signed-off-by: Song Liu <songliubraving@fb.com>

diff --git a/lib/raid6/algos.c b/lib/raid6/algos.c
index 17417eee0866..bf1b4765c8f6 100644
--- a/lib/raid6/algos.c
+++ b/lib/raid6/algos.c
@@ -124,6 +124,9 @@ const struct raid6_recov_calls *const raid6_recov_algos[] = {
 #define time_before(x, y) ((x) < (y))
 #endif
 
+#define RAID6_TEST_DISKS	8
+#define RAID6_TEST_DISKS_ORDER	3
+
 static inline const struct raid6_recov_calls *raid6_choose_recov(void)
 {
 	const struct raid6_recov_calls *const *algo;
@@ -146,7 +149,7 @@ static inline const struct raid6_recov_calls *raid6_choose_recov(void)
 }
 
 static inline const struct raid6_calls *raid6_choose_gen(
-	void *(*const dptrs)[(65536/PAGE_SIZE)+2], const int disks)
+	void *(*const dptrs)[RAID6_TEST_DISKS], const int disks)
 {
 	unsigned long perf, bestgenperf, bestxorperf, j0, j1;
 	int start = (disks>>1)-1, stop = disks-3;	/* work on the second half of the disks */
@@ -181,7 +184,8 @@ static inline const struct raid6_calls *raid6_choose_gen(
 				best = *algo;
 			}
 			pr_info("raid6: %-8s gen() %5ld MB/s\n", (*algo)->name,
-			       (perf*HZ) >> (20-16+RAID6_TIME_JIFFIES_LG2));
+				(perf * HZ * (disks-2)) >>
+				(20 - PAGE_SHIFT + RAID6_TIME_JIFFIES_LG2));
 
 			if (!(*algo)->xor_syndrome)
 				continue;
@@ -204,17 +208,24 @@ static inline const struct raid6_calls *raid6_choose_gen(
 				bestxorperf = perf;
 
 			pr_info("raid6: %-8s xor() %5ld MB/s\n", (*algo)->name,
-				(perf*HZ) >> (20-16+RAID6_TIME_JIFFIES_LG2+1));
+				(perf * HZ * (disks-2)) >>
+				(20 - PAGE_SHIFT + RAID6_TIME_JIFFIES_LG2 + 1));
 		}
 	}
 
 	if (best) {
-		pr_info("raid6: using algorithm %s gen() %ld MB/s\n",
-		       best->name,
-		       (bestgenperf*HZ) >> (20-16+RAID6_TIME_JIFFIES_LG2));
-		if (best->xor_syndrome)
-			pr_info("raid6: .... xor() %ld MB/s, rmw enabled\n",
-			       (bestxorperf*HZ) >> (20-16+RAID6_TIME_JIFFIES_LG2+1));
+		if (IS_ENABLED(CONFIG_RAID6_PQ_BENCHMARK)) {
+			pr_info("raid6: using algorithm %s gen() %ld MB/s\n",
+				best->name,
+				(bestgenperf * HZ * (disks-2)) >>
+				(20 - PAGE_SHIFT+RAID6_TIME_JIFFIES_LG2));
+			if (best->xor_syndrome)
+				pr_info("raid6: .... xor() %ld MB/s, rmw enabled\n",
+					(bestxorperf * HZ * (disks-2)) >>
+					(20 - PAGE_SHIFT + RAID6_TIME_JIFFIES_LG2 + 1));
+		} else
+			pr_info("raid6: skip pq benchmark and using algorithm %s\n",
+				best->name);
 		raid6_call = *best;
 	} else
 		pr_err("raid6: Yikes!  No algorithm found!\n");
@@ -228,27 +239,33 @@ static inline const struct raid6_calls *raid6_choose_gen(
 
 int __init raid6_select_algo(void)
 {
-	const int disks = (65536/PAGE_SIZE)+2;
+	const int disks = RAID6_TEST_DISKS;
 
 	const struct raid6_calls *gen_best;
 	const struct raid6_recov_calls *rec_best;
-	char *syndromes;
-	void *dptrs[(65536/PAGE_SIZE)+2];
-	int i;
-
-	for (i = 0; i < disks-2; i++)
-		dptrs[i] = ((char *)raid6_gfmul) + PAGE_SIZE*i;
-
-	/* Normal code - use a 2-page allocation to avoid D$ conflict */
-	syndromes = (void *) __get_free_pages(GFP_KERNEL, 1);
+	char *disk_ptr, *p;
+	void *dptrs[RAID6_TEST_DISKS];
+	int i, cycle;
 
-	if (!syndromes) {
+	/* prepare the buffer and fill it circularly with gfmul table */
+	disk_ptr = (char *)__get_free_pages(GFP_KERNEL, RAID6_TEST_DISKS_ORDER);
+	if (!disk_ptr) {
 		pr_err("raid6: Yikes!  No memory available.\n");
 		return -ENOMEM;
 	}
 
-	dptrs[disks-2] = syndromes;
-	dptrs[disks-1] = syndromes + PAGE_SIZE;
+	p = disk_ptr;
+	for (i = 0; i < disks; i++)
+		dptrs[i] = p + PAGE_SIZE * i;
+
+	cycle = ((disks - 2) * PAGE_SIZE) / 65536;
+	for (i = 0; i < cycle; i++) {
+		memcpy(p, raid6_gfmul, 65536);
+		p += 65536;
+	}
+
+	if ((disks - 2) * PAGE_SIZE % 65536)
+		memcpy(p, raid6_gfmul, (disks - 2) * PAGE_SIZE % 65536);
 
 	/* select raid gen_syndrome function */
 	gen_best = raid6_choose_gen(&dptrs, disks);
@@ -256,7 +273,7 @@ int __init raid6_select_algo(void)
 	/* select raid recover functions */
 	rec_best = raid6_choose_recov();
 
-	free_pages((unsigned long)syndromes, 1);
+	free_pages((unsigned long)disk_ptr, RAID6_TEST_DISKS_ORDER);
 
 	return gen_best && rec_best ? 0 : -EINVAL;
 }

commit dd165a658d9018cf31f87d2ea2f26293f215d91d
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon May 20 19:08:13 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 48
    
    Based on 1 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license as published by
      the free software foundation inc 53 temple place ste 330 boston ma
      02111 1307 usa either version 2 of the license or at your option any
      later version incorporated herein by reference
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-or-later
    
    has been chosen to replace the boilerplate/reference in 13 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190520170858.645641371@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/lib/raid6/algos.c b/lib/raid6/algos.c
index 7e4f7a8ffa8e..17417eee0866 100644
--- a/lib/raid6/algos.c
+++ b/lib/raid6/algos.c
@@ -1,13 +1,8 @@
+// SPDX-License-Identifier: GPL-2.0-or-later
 /* -*- linux-c -*- ------------------------------------------------------- *
  *
  *   Copyright 2002 H. Peter Anvin - All Rights Reserved
  *
- *   This program is free software; you can redistribute it and/or modify
- *   it under the terms of the GNU General Public License as published by
- *   the Free Software Foundation, Inc., 53 Temple Place Ste 330,
- *   Boston MA 02111-1307, USA; either version 2 of the License, or
- *   (at your option) any later version; incorporated herein by reference.
- *
  * ----------------------------------------------------------------------- */
 
 /*

commit be85f93ae2df32dea0b20908316f1d894c3e0f64
Author: Daniel Verkamp <dverkamp@chromium.org>
Date:   Mon Nov 12 15:26:52 2018 -0800

    lib/raid6: add option to skip algo benchmarking
    
    This is helpful for systems where fast startup time is important.
    It is especially nice to avoid benchmarking RAID functions that are
    never used (for example, BTRFS selects RAID6_PQ even if the parity RAID
    mode is not in use).
    
    This saves 250+ milliseconds of boot time on modern x86 and ARM systems
    with a dozen or more available implementations.
    
    The new option is defaulted to 'y' to match the previous behavior of
    always benchmarking on init.
    
    Signed-off-by: Daniel Verkamp <dverkamp@chromium.org>
    Signed-off-by: Shaohua Li <shli@fb.com>

diff --git a/lib/raid6/algos.c b/lib/raid6/algos.c
index a753ff56670f..7e4f7a8ffa8e 100644
--- a/lib/raid6/algos.c
+++ b/lib/raid6/algos.c
@@ -163,6 +163,11 @@ static inline const struct raid6_calls *raid6_choose_gen(
 			if ((*algo)->valid && !(*algo)->valid())
 				continue;
 
+			if (!IS_ENABLED(CONFIG_RAID6_PQ_BENCHMARK)) {
+				best = *algo;
+				break;
+			}
+
 			perf = 0;
 
 			preempt_disable();

commit 0437de4fa09fe59b57d12b785e4afb73b0f34c05
Author: Daniel Verkamp <dverkamp@chromium.org>
Date:   Mon Nov 12 15:26:51 2018 -0800

    lib/raid6: sort algos in rough performance order
    
    Sort the list of RAID6 algorithms in roughly decreasing order of
    expected performance: newer instruction sets first (within each
    architecture) and wider unrollings first.
    
    This doesn't make any difference right now, since all functions are
    benchmarked; a follow-up change will make use of this by optionally
    choosing the first valid function rather than testing all of them.
    
    The Itanium raid6_intx{16,32} entries are also moved down to be near the
    other raid6_intx entries for clarity.
    
    Signed-off-by: Daniel Verkamp <dverkamp@chromium.org>
    Signed-off-by: Shaohua Li <shli@fb.com>

diff --git a/lib/raid6/algos.c b/lib/raid6/algos.c
index 5065b1e7e327..a753ff56670f 100644
--- a/lib/raid6/algos.c
+++ b/lib/raid6/algos.c
@@ -34,64 +34,64 @@ struct raid6_calls raid6_call;
 EXPORT_SYMBOL_GPL(raid6_call);
 
 const struct raid6_calls * const raid6_algos[] = {
-#if defined(__ia64__)
-	&raid6_intx16,
-	&raid6_intx32,
-#endif
 #if defined(__i386__) && !defined(__arch_um__)
-	&raid6_mmxx1,
-	&raid6_mmxx2,
-	&raid6_sse1x1,
-	&raid6_sse1x2,
-	&raid6_sse2x1,
-	&raid6_sse2x2,
-#ifdef CONFIG_AS_AVX2
-	&raid6_avx2x1,
-	&raid6_avx2x2,
-#endif
 #ifdef CONFIG_AS_AVX512
-	&raid6_avx512x1,
 	&raid6_avx512x2,
+	&raid6_avx512x1,
 #endif
-#endif
-#if defined(__x86_64__) && !defined(__arch_um__)
-	&raid6_sse2x1,
-	&raid6_sse2x2,
-	&raid6_sse2x4,
 #ifdef CONFIG_AS_AVX2
-	&raid6_avx2x1,
 	&raid6_avx2x2,
-	&raid6_avx2x4,
+	&raid6_avx2x1,
 #endif
+	&raid6_sse2x2,
+	&raid6_sse2x1,
+	&raid6_sse1x2,
+	&raid6_sse1x1,
+	&raid6_mmxx2,
+	&raid6_mmxx1,
+#endif
+#if defined(__x86_64__) && !defined(__arch_um__)
 #ifdef CONFIG_AS_AVX512
-	&raid6_avx512x1,
-	&raid6_avx512x2,
 	&raid6_avx512x4,
+	&raid6_avx512x2,
+	&raid6_avx512x1,
+#endif
+#ifdef CONFIG_AS_AVX2
+	&raid6_avx2x4,
+	&raid6_avx2x2,
+	&raid6_avx2x1,
 #endif
+	&raid6_sse2x4,
+	&raid6_sse2x2,
+	&raid6_sse2x1,
 #endif
 #ifdef CONFIG_ALTIVEC
-	&raid6_altivec1,
-	&raid6_altivec2,
-	&raid6_altivec4,
-	&raid6_altivec8,
-	&raid6_vpermxor1,
-	&raid6_vpermxor2,
-	&raid6_vpermxor4,
 	&raid6_vpermxor8,
+	&raid6_vpermxor4,
+	&raid6_vpermxor2,
+	&raid6_vpermxor1,
+	&raid6_altivec8,
+	&raid6_altivec4,
+	&raid6_altivec2,
+	&raid6_altivec1,
 #endif
 #if defined(CONFIG_S390)
 	&raid6_s390vx8,
 #endif
-	&raid6_intx1,
-	&raid6_intx2,
-	&raid6_intx4,
-	&raid6_intx8,
 #ifdef CONFIG_KERNEL_MODE_NEON
-	&raid6_neonx1,
-	&raid6_neonx2,
-	&raid6_neonx4,
 	&raid6_neonx8,
+	&raid6_neonx4,
+	&raid6_neonx2,
+	&raid6_neonx1,
+#endif
+#if defined(__ia64__)
+	&raid6_intx32,
+	&raid6_intx16,
 #endif
+	&raid6_intx8,
+	&raid6_intx4,
+	&raid6_intx2,
+	&raid6_intx1,
 	NULL
 };
 

commit 49a695ba723224875df50e327bd7b0b65dd9a56b
Merge: 299f89d53e61 c1b25a17d249
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Apr 7 12:08:19 2018 -0700

    Merge tag 'powerpc-4.17-1' of git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux
    
    Pull powerpc updates from Michael Ellerman:
     "Notable changes:
    
       - Support for 4PB user address space on 64-bit, opt-in via mmap().
    
       - Removal of POWER4 support, which was accidentally broken in 2016
         and no one noticed, and blocked use of some modern instructions.
    
       - Workarounds so that the hypervisor can enable Transactional Memory
         on Power9.
    
       - A series to disable the DAWR (Data Address Watchpoint Register) on
         Power9.
    
       - More information displayed in the meltdown/spectre_v1/v2 sysfs
         files.
    
       - A vpermxor (Power8 Altivec) implementation for the raid6 Q
         Syndrome.
    
       - A big series to make the allocation of our pacas (per cpu area),
         kernel page tables, and per-cpu stacks NUMA aware when using the
         Radix MMU on Power9.
    
      And as usual many fixes, reworks and cleanups.
    
      Thanks to: Aaro Koskinen, Alexandre Belloni, Alexey Kardashevskiy,
      Alistair Popple, Andy Shevchenko, Aneesh Kumar K.V, Anshuman Khandual,
      Balbir Singh, Benjamin Herrenschmidt, Christophe Leroy, Christophe
      Lombard, Cyril Bur, Daniel Axtens, Dave Young, Finn Thain, Frederic
      Barrat, Gustavo Romero, Horia Geantă, Jonathan Neuschäfer, Kees Cook,
      Larry Finger, Laurent Dufour, Laurent Vivier, Logan Gunthorpe,
      Madhavan Srinivasan, Mark Greer, Mark Hairgrove, Markus Elfring,
      Mathieu Malaterre, Matt Brown, Matt Evans, Mauricio Faria de Oliveira,
      Michael Neuling, Naveen N. Rao, Nicholas Piggin, Paul Mackerras,
      Philippe Bergheaud, Ram Pai, Rob Herring, Sam Bobroff, Segher
      Boessenkool, Simon Guo, Simon Horman, Stewart Smith, Sukadev
      Bhattiprolu, Suraj Jitindar Singh, Thiago Jung Bauermann, Vaibhav
      Jain, Vaidyanathan Srinivasan, Vasant Hegde, Wei Yongjun"
    
    * tag 'powerpc-4.17-1' of git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux: (207 commits)
      powerpc/64s/idle: Fix restore of AMOR on POWER9 after deep sleep
      powerpc/64s: Fix POWER9 DD2.2 and above in cputable features
      powerpc/64s: Fix pkey support in dt_cpu_ftrs, add CPU_FTR_PKEY bit
      powerpc/64s: Fix dt_cpu_ftrs to have restore_cpu clear unwanted LPCR bits
      Revert "powerpc/64s/idle: POWER9 ESL=0 stop avoid save/restore overhead"
      powerpc: iomap.c: introduce io{read|write}64_{lo_hi|hi_lo}
      powerpc: io.h: move iomap.h include so that it can use readq/writeq defs
      cxl: Fix possible deadlock when processing page faults from cxllib
      powerpc/hw_breakpoint: Only disable hw breakpoint if cpu supports it
      powerpc/mm/radix: Update command line parsing for disable_radix
      powerpc/mm/radix: Parse disable_radix commandline correctly.
      powerpc/mm/hugetlb: initialize the pagetable cache correctly for hugetlb
      powerpc/mm/radix: Update pte fragment count from 16 to 256 on radix
      powerpc/mm/keys: Update documentation and remove unnecessary check
      powerpc/64s/idle: POWER9 ESL=0 stop avoid save/restore overhead
      powerpc/64s/idle: Consolidate power9_offline_stop()/power9_idle_stop()
      powerpc/powernv: Always stop secondaries before reboot/shutdown
      powerpc: hard disable irqs in smp_send_stop loop
      powerpc: use NMI IPI for smp_send_stop
      powerpc/powernv: Fix SMT4 forcing idle code
      ...

commit 889ce12b1650b3c388634451872638a08faf6d6b
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Fri Mar 9 16:05:23 2018 +0100

    raid: remove tile specific raid6 implementation
    
    The Tile architecture is getting removed, so we no longer need this either.
    
    Acked-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>

diff --git a/lib/raid6/algos.c b/lib/raid6/algos.c
index 476994723258..c65aa80d67ed 100644
--- a/lib/raid6/algos.c
+++ b/lib/raid6/algos.c
@@ -75,9 +75,6 @@ const struct raid6_calls * const raid6_algos[] = {
 	&raid6_altivec4,
 	&raid6_altivec8,
 #endif
-#if defined(CONFIG_TILEGX)
-	&raid6_tilegx8,
-#endif
 #if defined(CONFIG_S390)
 	&raid6_s390vx8,
 #endif

commit 751ba79cc552c146595cd439b21c4ff8998c3b69
Author: Matt Brown <matthew.brown.dev@gmail.com>
Date:   Fri Aug 4 13:42:32 2017 +1000

    lib/raid6/altivec: Add vpermxor implementation for raid6 Q syndrome
    
    This patch uses the vpermxor instruction to optimise the raid6 Q
    syndrome. This instruction was made available with POWER8, ISA version
    2.07. It allows for both vperm and vxor instructions to be done in a
    single instruction. This has been tested for correctness on a ppc64le
    vm with a basic RAID6 setup containing 5 drives.
    
    The performance benchmarks are from the raid6test in the
    /lib/raid6/test directory. These results are from an IBM Firestone
    machine with ppc64le architecture. The benchmark results show a 35%
    speed increase over the best existing algorithm for powerpc (altivec).
    The raid6test has also been run on a big-endian ppc64 vm to ensure it
    also works for big-endian architectures.
    
    Performance benchmarks:
      raid6: altivecx4 gen() 18773 MB/s
      raid6: altivecx8 gen() 19438 MB/s
    
      raid6: vpermxor4 gen() 25112 MB/s
      raid6: vpermxor8 gen() 26279 MB/s
    
    Signed-off-by: Matt Brown <matthew.brown.dev@gmail.com>
    Reviewed-by: Daniel Axtens <dja@axtens.net>
    [mpe: Add VPERMXOR macro so we can build with old binutils]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/lib/raid6/algos.c b/lib/raid6/algos.c
index 476994723258..b2e681018145 100644
--- a/lib/raid6/algos.c
+++ b/lib/raid6/algos.c
@@ -74,6 +74,10 @@ const struct raid6_calls * const raid6_algos[] = {
 	&raid6_altivec2,
 	&raid6_altivec4,
 	&raid6_altivec8,
+	&raid6_vpermxor1,
+	&raid6_vpermxor2,
+	&raid6_vpermxor4,
+	&raid6_vpermxor8,
 #endif
 #if defined(CONFIG_TILEGX)
 	&raid6_tilegx8,

commit 6ec4e2514decd6fb4782a9364fa71d6244d05af4
Author: Ard Biesheuvel <ard.biesheuvel@linaro.org>
Date:   Thu Jul 13 18:16:01 2017 +0100

    md/raid6: implement recovery using ARM NEON intrinsics
    
    Provide a NEON accelerated implementation of the recovery algorithm,
    which supersedes the default byte-by-byte one.
    
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/lib/raid6/algos.c b/lib/raid6/algos.c
index 7857049fd7d3..476994723258 100644
--- a/lib/raid6/algos.c
+++ b/lib/raid6/algos.c
@@ -112,6 +112,9 @@ const struct raid6_recov_calls *const raid6_recov_algos[] = {
 #endif
 #ifdef CONFIG_S390
 	&raid6_recov_s390xc,
+#endif
+#if defined(CONFIG_KERNEL_MODE_NEON)
+	&raid6_recov_neon,
 #endif
 	&raid6_recov_intx1,
 	NULL

commit c23112e0395a89c8a52cd955442240de7fba46aa
Merge: 4dfddf503670 bb086a89a406
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Oct 7 09:45:43 2016 -0700

    Merge tag 'md/4.9-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/shli/md
    
    Pull MD updates from Shaohua Li:
     "This update includes:
    
       - new AVX512 instruction based raid6 gen/recovery algorithm
    
       - a couple of md-cluster related bug fixes
    
       - fix a potential deadlock
    
       - set nonrotational bit for raid array with SSD
    
       - set correct max_hw_sectors for raid5/6, which hopefuly can improve
         performance a little bit
    
       - other minor fixes"
    
    * tag 'md/4.9-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/shli/md:
      md: set rotational bit
      raid6/test/test.c: bug fix: Specify aligned(alignment) attributes to the char arrays
      raid5: handle register_shrinker failure
      raid5: fix to detect failure of register_shrinker
      md: fix a potential deadlock
      md/bitmap: fix wrong cleanup
      raid5: allow arbitrary max_hw_sectors
      lib/raid6: Add AVX512 optimized xor_syndrome functions
      lib/raid6/test/Makefile: Add avx512 gen_syndrome and recovery functions
      lib/raid6: Add AVX512 optimized recovery functions
      lib/raid6: Add AVX512 optimized gen_syndrome functions
      md-cluster: make resync lock also could be interruptted
      md-cluster: introduce dlm_lock_sync_interruptible to fix tasks hang
      md-cluster: convert the completion to wait queue
      md-cluster: protect md_find_rdev_nr_rcu with rcu lock
      md-cluster: clean related infos of cluster
      md: changes for MD_STILL_CLOSED flag
      md-cluster: remove some unnecessary dlm_unlock_sync
      md-cluster: use FORCEUNLOCK in lockres_free
      md-cluster: call md_kick_rdev_from_array once ack failed

commit 13c520b2993c9faae6770264d33ff1e1ea4c2ceb
Author: Gayatri Kammela <gayatri.kammela@intel.com>
Date:   Fri Aug 12 18:03:20 2016 -0700

    lib/raid6: Add AVX512 optimized recovery functions
    
    Optimize RAID6 recovery functions to take advantage of
    the 512-bit ZMM integer instructions introduced in AVX512.
    
    AVX512 optimized recovery functions, which is simply based
    on recov_avx2.c written by Jim Kukunas
    
    This patch was tested and benchmarked before submission on
    a hardware that has AVX512 flags to support such instructions
    
    Cc: Jim Kukunas <james.t.kukunas@linux.intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Signed-off-by: Megha Dey <megha.dey@linux.intel.com>
    Signed-off-by: Gayatri Kammela <gayatri.kammela@intel.com>
    Reviewed-by: Fenghua Yu <fenghua.yu@intel.com>
    Signed-off-by: Shaohua Li <shli@fb.com>

diff --git a/lib/raid6/algos.c b/lib/raid6/algos.c
index f5f090c52dd9..149d947a4fec 100644
--- a/lib/raid6/algos.c
+++ b/lib/raid6/algos.c
@@ -98,6 +98,9 @@ void (*raid6_datap_recov)(int, size_t, int, void **);
 EXPORT_SYMBOL_GPL(raid6_datap_recov);
 
 const struct raid6_recov_calls *const raid6_recov_algos[] = {
+#ifdef CONFIG_AS_AVX512
+	&raid6_recov_avx512,
+#endif
 #ifdef CONFIG_AS_AVX2
 	&raid6_recov_avx2,
 #endif

commit e0a491c1296874a1aca51cc68452f12a4d950029
Author: Gayatri Kammela <gayatri.kammela@intel.com>
Date:   Fri Aug 12 18:03:19 2016 -0700

    lib/raid6: Add AVX512 optimized gen_syndrome functions
    
    Optimize RAID6 gen_syndrom functions to take advantage of
    the 512-bit ZMM integer instructions introduced in AVX512.
    
    AVX512 optimized gen_syndrom functions, which is simply based
    on avx2.c written by Yuanhan Liu and sse2.c written by hpa.
    
    The patch was tested and benchmarked before submission on
    a hardware that has AVX512 flags to support such instructions
    
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Jim Kukunas <james.t.kukunas@linux.intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Signed-off-by: Megha Dey <megha.dey@linux.intel.com>
    Signed-off-by: Gayatri Kammela <gayatri.kammela@intel.com>
    Reviewed-by: Fenghua Yu <fenghua.yu@intel.com>
    Signed-off-by: Shaohua Li <shli@fb.com>

diff --git a/lib/raid6/algos.c b/lib/raid6/algos.c
index 975c6e0434bd..f5f090c52dd9 100644
--- a/lib/raid6/algos.c
+++ b/lib/raid6/algos.c
@@ -49,6 +49,10 @@ const struct raid6_calls * const raid6_algos[] = {
 	&raid6_avx2x1,
 	&raid6_avx2x2,
 #endif
+#ifdef CONFIG_AS_AVX512
+	&raid6_avx512x1,
+	&raid6_avx512x2,
+#endif
 #endif
 #if defined(__x86_64__) && !defined(__arch_um__)
 	&raid6_sse2x1,
@@ -59,6 +63,11 @@ const struct raid6_calls * const raid6_algos[] = {
 	&raid6_avx2x2,
 	&raid6_avx2x4,
 #endif
+#ifdef CONFIG_AS_AVX512
+	&raid6_avx512x1,
+	&raid6_avx512x2,
+	&raid6_avx512x4,
+#endif
 #endif
 #ifdef CONFIG_ALTIVEC
 	&raid6_altivec1,

commit f5b55fa1f81d518925d68b50d2316850c525d1ad
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Wed Aug 31 09:27:35 2016 +0200

    RAID/s390: provide raid6 recovery optimization
    
    The XC instruction can be used to improve the speed of the raid6
    recovery. The loops now operate on blocks of 256 bytes.
    
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/lib/raid6/algos.c b/lib/raid6/algos.c
index e1923b602bbc..592ff49df47d 100644
--- a/lib/raid6/algos.c
+++ b/lib/raid6/algos.c
@@ -97,6 +97,9 @@ const struct raid6_recov_calls *const raid6_recov_algos[] = {
 #endif
 #ifdef CONFIG_AS_SSSE3
 	&raid6_recov_ssse3,
+#endif
+#ifdef CONFIG_S390
+	&raid6_recov_s390xc,
 #endif
 	&raid6_recov_intx1,
 	NULL

commit 474fd6e80fe529e9adeeb7ea9d4e5d6c4da0b7fe
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Tue Aug 23 13:30:24 2016 +0200

    RAID/s390: add SIMD implementation for raid6 gen/xor
    
    Using vector registers is slightly faster:
    
    raid6: vx128x8  gen() 19705 MB/s
    raid6: vx128x8  xor() 11886 MB/s
    raid6: using algorithm vx128x8 gen() 19705 MB/s
    raid6: .... xor() 11886 MB/s, rmw enabled
    
    vs the software algorithms:
    
    raid6: int64x1  gen()  3018 MB/s
    raid6: int64x1  xor()  1429 MB/s
    raid6: int64x2  gen()  4661 MB/s
    raid6: int64x2  xor()  3143 MB/s
    raid6: int64x4  gen()  5392 MB/s
    raid6: int64x4  xor()  3509 MB/s
    raid6: int64x8  gen()  4441 MB/s
    raid6: int64x8  xor()  3207 MB/s
    raid6: using algorithm int64x4 gen() 5392 MB/s
    raid6: .... xor() 3509 MB/s, rmw enabled
    
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/lib/raid6/algos.c b/lib/raid6/algos.c
index 975c6e0434bd..e1923b602bbc 100644
--- a/lib/raid6/algos.c
+++ b/lib/raid6/algos.c
@@ -68,6 +68,9 @@ const struct raid6_calls * const raid6_algos[] = {
 #endif
 #if defined(CONFIG_TILEGX)
 	&raid6_tilegx8,
+#endif
+#if defined(CONFIG_S390)
+	&raid6_s390vx8,
 #endif
 	&raid6_intx1,
 	&raid6_intx2,

commit fe5cbc6e06c7d8b3a86f6f5491d74766bb5c2827
Author: Markus Stockhausen <stockhausen@collogia.de>
Date:   Mon Dec 15 12:57:04 2014 +1100

    md/raid6 algorithms: delta syndrome functions
    
    v3: s-o-b comment, explanation of performance and descision for
    the start/stop implementation
    
    Implementing rmw functionality for RAID6 requires optimized syndrome
    calculation. Up to now we can only generate a complete syndrome. The
    target P/Q pages are always overwritten. With this patch we provide
    a framework for inplace P/Q modification. In the first place simply
    fill those functions with NULL values.
    
    xor_syndrome() has two additional parameters: start & stop. These
    will indicate the first and last page that are changing during a
    rmw run. That makes it possible to avoid several unneccessary loops
    and speed up calculation. The caller needs to implement the following
    logic to make the functions work.
    
    1) xor_syndrome(disks, start, stop, ...): "Remove" all data of source
    blocks inside P/Q between (and including) start and end.
    
    2) modify any block with start <= block <= stop
    
    3) xor_syndrome(disks, start, stop, ...): "Reinsert" all data of
    source blocks into P/Q between (and including) start and end.
    
    Pages between start and stop that won't be changed should be filled
    with a pointer to the kernel zero page. The reasons for not taking NULL
    pages are:
    
    1) Algorithms cross the whole source data line by line. Thus avoid
    additional branches.
    
    2) Having a NULL page avoids calculating the XOR P parity but still
    need calulation steps for the Q parity. Depending on the algorithm
    unrolling that might be only a difference of 2 instructions per loop.
    
    The benchmark numbers of the gen_syndrome() functions are displayed in
    the kernel log. Do the same for the xor_syndrome() functions. This
    will help to analyze performance problems and give an rough estimate
    how well the algorithm works. The choice of the fastest algorithm will
    still depend on the gen_syndrome() performance.
    
    With the start/stop page implementation the speed can vary a lot in real
    life. E.g. a change of page 0 & page 15 on a stripe will be harder to
    compute than the case where page 0 & page 1 are XOR candidates. To be not
    to enthusiatic about the expected speeds we will run a worse case test
    that simulates a change on the upper half of the stripe. So we do:
    
    1) calculation of P/Q for the upper pages
    
    2) continuation of Q for the lower (empty) pages
    
    Signed-off-by: Markus Stockhausen <stockhausen@collogia.de>
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/lib/raid6/algos.c b/lib/raid6/algos.c
index dbef2314901e..975c6e0434bd 100644
--- a/lib/raid6/algos.c
+++ b/lib/raid6/algos.c
@@ -131,11 +131,12 @@ static inline const struct raid6_recov_calls *raid6_choose_recov(void)
 static inline const struct raid6_calls *raid6_choose_gen(
 	void *(*const dptrs)[(65536/PAGE_SIZE)+2], const int disks)
 {
-	unsigned long perf, bestperf, j0, j1;
+	unsigned long perf, bestgenperf, bestxorperf, j0, j1;
+	int start = (disks>>1)-1, stop = disks-3;	/* work on the second half of the disks */
 	const struct raid6_calls *const *algo;
 	const struct raid6_calls *best;
 
-	for (bestperf = 0, best = NULL, algo = raid6_algos; *algo; algo++) {
+	for (bestgenperf = 0, bestxorperf = 0, best = NULL, algo = raid6_algos; *algo; algo++) {
 		if (!best || (*algo)->prefer >= best->prefer) {
 			if ((*algo)->valid && !(*algo)->valid())
 				continue;
@@ -153,19 +154,45 @@ static inline const struct raid6_calls *raid6_choose_gen(
 			}
 			preempt_enable();
 
-			if (perf > bestperf) {
-				bestperf = perf;
+			if (perf > bestgenperf) {
+				bestgenperf = perf;
 				best = *algo;
 			}
-			pr_info("raid6: %-8s %5ld MB/s\n", (*algo)->name,
+			pr_info("raid6: %-8s gen() %5ld MB/s\n", (*algo)->name,
 			       (perf*HZ) >> (20-16+RAID6_TIME_JIFFIES_LG2));
+
+			if (!(*algo)->xor_syndrome)
+				continue;
+
+			perf = 0;
+
+			preempt_disable();
+			j0 = jiffies;
+			while ((j1 = jiffies) == j0)
+				cpu_relax();
+			while (time_before(jiffies,
+					    j1 + (1<<RAID6_TIME_JIFFIES_LG2))) {
+				(*algo)->xor_syndrome(disks, start, stop,
+						      PAGE_SIZE, *dptrs);
+				perf++;
+			}
+			preempt_enable();
+
+			if (best == *algo)
+				bestxorperf = perf;
+
+			pr_info("raid6: %-8s xor() %5ld MB/s\n", (*algo)->name,
+				(perf*HZ) >> (20-16+RAID6_TIME_JIFFIES_LG2+1));
 		}
 	}
 
 	if (best) {
-		pr_info("raid6: using algorithm %s (%ld MB/s)\n",
+		pr_info("raid6: using algorithm %s gen() %ld MB/s\n",
 		       best->name,
-		       (bestperf*HZ) >> (20-16+RAID6_TIME_JIFFIES_LG2));
+		       (bestgenperf*HZ) >> (20-16+RAID6_TIME_JIFFIES_LG2));
+		if (best->xor_syndrome)
+			pr_info("raid6: .... xor() %ld MB/s, rmw enabled\n",
+			       (bestxorperf*HZ) >> (20-16+RAID6_TIME_JIFFIES_LG2+1));
 		raid6_call = *best;
 	} else
 		pr_err("raid6: Yikes!  No algorithm found!\n");

commit 75aaf4c3e6a4ed48207230cf133a02258ca5abd5
Author: Jan Beulich <JBeulich@suse.com>
Date:   Fri Jan 23 08:29:50 2015 +0000

    x86/raid6: correctly check for assembler capabilities
    
    Just like for AVX2 (which simply needs an #if -> #ifdef conversion),
    SSSE3 assembler support should be checked for before using it.
    
    Signed-off-by: Jan Beulich <jbeulich@suse.com>
    Cc: Jim Kukunas <james.t.kukunas@linux.intel.com>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/lib/raid6/algos.c b/lib/raid6/algos.c
index 7d0e5cd7b570..dbef2314901e 100644
--- a/lib/raid6/algos.c
+++ b/lib/raid6/algos.c
@@ -89,10 +89,10 @@ void (*raid6_datap_recov)(int, size_t, int, void **);
 EXPORT_SYMBOL_GPL(raid6_datap_recov);
 
 const struct raid6_recov_calls *const raid6_recov_algos[] = {
-#if (defined(__i386__) || defined(__x86_64__)) && !defined(__arch_um__)
 #ifdef CONFIG_AS_AVX2
 	&raid6_recov_avx2,
 #endif
+#ifdef CONFIG_AS_SSSE3
 	&raid6_recov_ssse3,
 #endif
 	&raid6_recov_intx1,

commit b395f75eabb3844c99244928293796ff42feaa3d
Author: Anton Blanchard <anton@samba.org>
Date:   Mon Oct 13 23:03:16 2014 +1100

    lib/raid6: Add log level to printks
    
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/lib/raid6/algos.c b/lib/raid6/algos.c
index f0b1aa3586d1..7d0e5cd7b570 100644
--- a/lib/raid6/algos.c
+++ b/lib/raid6/algos.c
@@ -121,9 +121,9 @@ static inline const struct raid6_recov_calls *raid6_choose_recov(void)
 		raid6_2data_recov = best->data2;
 		raid6_datap_recov = best->datap;
 
-		printk("raid6: using %s recovery algorithm\n", best->name);
+		pr_info("raid6: using %s recovery algorithm\n", best->name);
 	} else
-		printk("raid6: Yikes! No recovery algorithm found!\n");
+		pr_err("raid6: Yikes! No recovery algorithm found!\n");
 
 	return best;
 }
@@ -157,18 +157,18 @@ static inline const struct raid6_calls *raid6_choose_gen(
 				bestperf = perf;
 				best = *algo;
 			}
-			printk("raid6: %-8s %5ld MB/s\n", (*algo)->name,
+			pr_info("raid6: %-8s %5ld MB/s\n", (*algo)->name,
 			       (perf*HZ) >> (20-16+RAID6_TIME_JIFFIES_LG2));
 		}
 	}
 
 	if (best) {
-		printk("raid6: using algorithm %s (%ld MB/s)\n",
+		pr_info("raid6: using algorithm %s (%ld MB/s)\n",
 		       best->name,
 		       (bestperf*HZ) >> (20-16+RAID6_TIME_JIFFIES_LG2));
 		raid6_call = *best;
 	} else
-		printk("raid6: Yikes!  No algorithm found!\n");
+		pr_err("raid6: Yikes!  No algorithm found!\n");
 
 	return best;
 }
@@ -194,7 +194,7 @@ int __init raid6_select_algo(void)
 	syndromes = (void *) __get_free_pages(GFP_KERNEL, 1);
 
 	if (!syndromes) {
-		printk("raid6: Yikes!  No memory available.\n");
+		pr_err("raid6: Yikes!  No memory available.\n");
 		return -ENOMEM;
 	}
 

commit 4d7696f1b05f4aeb586c74868fe3da2731daca4b
Merge: b05430fc9341 bfc90cb0936f
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Sep 10 13:03:41 2013 -0700

    Merge tag 'md/3.12' of git://neil.brown.name/md
    
    Pull md update from Neil Brown:
     "Headline item is multithreading for RAID5 so that more IO/sec can be
      supported on fast (SSD) devices.  Also TILE-Gx SIMD suppor for RAID6
      calculations and an assortment of bug fixes"
    
    * tag 'md/3.12' of git://neil.brown.name/md:
      raid5: only wakeup necessary threads
      md/raid5: flush out all pending requests before proceeding with reshape.
      md/raid5: use seqcount to protect access to shape in make_request.
      raid5: sysfs entry to control worker thread number
      raid5: offload stripe handle to workqueue
      raid5: fix stripe release order
      raid5: make release_stripe lockless
      md: avoid deadlock when dirty buffers during md_stop.
      md: Don't test all of mddev->flags at once.
      md: Fix apparent cut-and-paste error in super_90_validate
      raid6/test: replace echo -e with printf
      RAID: add tilegx SIMD implementation of raid6
      md: fix safe_mode buglet.
      md: don't call md_allow_write in get_bitmap_file.

commit ae77cbc1e7b90473a2b0963bce0e1eb163873214
Author: Ken Steele <ken@tilera.com>
Date:   Wed Aug 7 12:39:56 2013 -0400

    RAID: add tilegx SIMD implementation of raid6
    
    This change adds TILE-Gx SIMD instructions to the software raid
    (md), modeling the Altivec implementation. This is only for Syndrome
    generation; there is more that could be done to improve recovery,
    as in the recent Intel SSE3 recovery implementation.
    
    The code unrolls 8 times; this turns out to be the best on tilegx
    hardware among the set 1, 2, 4, 8 or 16.  The code reads one
    cache-line of data from each disk, stores P and Q then goes to the
    next cache-line.
    
    The test code in sys/linux/lib/raid6/test reports 2008 MB/s data
    read rate for syndrome generation using 18 disks (16 data and 2
    parity). It was 1512 MB/s before this SIMD optimizations. This is
    running on 1 core with all the data in cache.
    
    This is based on the paper The Mathematics of RAID-6.
    (http://kernel.org/pub/linux/kernel/people/hpa/raid6.pdf).
    
    Signed-off-by: Ken Steele <ken@tilera.com>
    Signed-off-by: Chris Metcalf <cmetcalf@tilera.com>
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/lib/raid6/algos.c b/lib/raid6/algos.c
index 6d7316fe9f30..b9f340180a3b 100644
--- a/lib/raid6/algos.c
+++ b/lib/raid6/algos.c
@@ -65,6 +65,9 @@ const struct raid6_calls * const raid6_algos[] = {
 	&raid6_altivec2,
 	&raid6_altivec4,
 	&raid6_altivec8,
+#endif
+#if defined(CONFIG_TILEGX)
+	&raid6_tilegx8,
 #endif
 	&raid6_intx1,
 	&raid6_intx2,

commit 7d11965ddb9b9b1e0a5d13c58345ada1ccbc663b
Author: Ard Biesheuvel <ard.biesheuvel@linaro.org>
Date:   Thu May 16 17:20:32 2013 +0200

    lib/raid6: add ARM-NEON accelerated syndrome calculation
    
    Rebased/reworked a patch contributed by Rob Herring that uses
    NEON intrinsics to perform the RAID-6 syndrome calculations.
    It uses the existing unroll.awk code to generate several
    unrolled versions of which the best performing one is selected
    at boot time.
    
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Acked-by: Nicolas Pitre <nico@linaro.org>
    Cc: hpa@linux.intel.com

diff --git a/lib/raid6/algos.c b/lib/raid6/algos.c
index 6d7316fe9f30..74e6f5629dbc 100644
--- a/lib/raid6/algos.c
+++ b/lib/raid6/algos.c
@@ -70,6 +70,12 @@ const struct raid6_calls * const raid6_algos[] = {
 	&raid6_intx2,
 	&raid6_intx4,
 	&raid6_intx8,
+#ifdef CONFIG_KERNEL_MODE_NEON
+	&raid6_neonx1,
+	&raid6_neonx2,
+	&raid6_neonx4,
+	&raid6_neonx8,
+#endif
 	NULL
 };
 

commit 2c935842bdb46f5f557426feb4d2bdfdad1aa5f9
Author: Yuanhan Liu <yuanhan.liu@linux.intel.com>
Date:   Fri Nov 30 13:10:39 2012 -0800

    lib/raid6: Add AVX2 optimized gen_syndrome functions
    
    Add AVX2 optimized gen_syndrom functions, which is simply based on
    sse2.c written by hpa.
    
    Signed-off-by: Yuanhan Liu <yuanhan.liu@linux.intel.com>
    Reviewed-by: H. Peter Anvin <hpa@zytor.com>
    Signed-off-by: Jim Kukunas <james.t.kukunas@linux.intel.com>
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/lib/raid6/algos.c b/lib/raid6/algos.c
index 8b7f55cadb45..6d7316fe9f30 100644
--- a/lib/raid6/algos.c
+++ b/lib/raid6/algos.c
@@ -45,11 +45,20 @@ const struct raid6_calls * const raid6_algos[] = {
 	&raid6_sse1x2,
 	&raid6_sse2x1,
 	&raid6_sse2x2,
+#ifdef CONFIG_AS_AVX2
+	&raid6_avx2x1,
+	&raid6_avx2x2,
+#endif
 #endif
 #if defined(__x86_64__) && !defined(__arch_um__)
 	&raid6_sse2x1,
 	&raid6_sse2x2,
 	&raid6_sse2x4,
+#ifdef CONFIG_AS_AVX2
+	&raid6_avx2x1,
+	&raid6_avx2x2,
+	&raid6_avx2x4,
+#endif
 #endif
 #ifdef CONFIG_ALTIVEC
 	&raid6_altivec1,

commit 7056741fd9fc14a65608549a4657cf5178f05f63
Author: Jim Kukunas <james.t.kukunas@linux.intel.com>
Date:   Thu Nov 8 13:47:44 2012 -0800

    lib/raid6: Add AVX2 optimized recovery functions
    
    Optimize RAID6 recovery functions to take advantage of
    the 256-bit YMM integer instructions introduced in AVX2.
    
    The patch was tested and benchmarked before submission.
    However hardware is not yet released so benchmark numbers
    cannot be reported.
    
    Acked-by: "H. Peter Anvin" <hpa@zytor.com>
    Signed-off-by: Jim Kukunas <james.t.kukunas@linux.intel.com>
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/lib/raid6/algos.c b/lib/raid6/algos.c
index 589f5f50ad2e..8b7f55cadb45 100644
--- a/lib/raid6/algos.c
+++ b/lib/raid6/algos.c
@@ -72,6 +72,9 @@ EXPORT_SYMBOL_GPL(raid6_datap_recov);
 
 const struct raid6_recov_calls *const raid6_recov_algos[] = {
 #if (defined(__i386__) || defined(__x86_64__)) && !defined(__arch_um__)
+#ifdef CONFIG_AS_AVX2
+	&raid6_recov_avx2,
+#endif
 	&raid6_recov_ssse3,
 #endif
 	&raid6_recov_intx1,

commit 96e67703e71f4b3cc32b747dbb6158ec74d01e19
Author: Jim Kukunas <james.t.kukunas@linux.intel.com>
Date:   Tue May 22 13:54:24 2012 +1000

    lib/raid6: cleanup gen_syndrome function selection
    
    Reorders functions in raid6_algos as well as the preference check
    to reduce the number of functions tested on initialization.
    
    Also, creates symmetry between choosing the gen_syndrome functions
    and choosing the recovery functions.
    
    Signed-off-by: Jim Kukunas <james.t.kukunas@linux.intel.com>
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/lib/raid6/algos.c b/lib/raid6/algos.c
index 5a7f8022be13..589f5f50ad2e 100644
--- a/lib/raid6/algos.c
+++ b/lib/raid6/algos.c
@@ -34,10 +34,6 @@ struct raid6_calls raid6_call;
 EXPORT_SYMBOL_GPL(raid6_call);
 
 const struct raid6_calls * const raid6_algos[] = {
-	&raid6_intx1,
-	&raid6_intx2,
-	&raid6_intx4,
-	&raid6_intx8,
 #if defined(__ia64__)
 	&raid6_intx16,
 	&raid6_intx32,
@@ -61,6 +57,10 @@ const struct raid6_calls * const raid6_algos[] = {
 	&raid6_altivec4,
 	&raid6_altivec8,
 #endif
+	&raid6_intx1,
+	&raid6_intx2,
+	&raid6_intx4,
+	&raid6_intx8,
 	NULL
 };
 
@@ -86,7 +86,7 @@ const struct raid6_recov_calls *const raid6_recov_algos[] = {
 #define time_before(x, y) ((x) < (y))
 #endif
 
-static inline void raid6_choose_recov(void)
+static inline const struct raid6_recov_calls *raid6_choose_recov(void)
 {
 	const struct raid6_recov_calls *const *algo;
 	const struct raid6_recov_calls *best;
@@ -103,62 +103,38 @@ static inline void raid6_choose_recov(void)
 		printk("raid6: using %s recovery algorithm\n", best->name);
 	} else
 		printk("raid6: Yikes! No recovery algorithm found!\n");
-}
-
 
-/* Try to pick the best algorithm */
-/* This code uses the gfmul table as convenient data set to abuse */
+	return best;
+}
 
-int __init raid6_select_algo(void)
+static inline const struct raid6_calls *raid6_choose_gen(
+	void *(*const dptrs)[(65536/PAGE_SIZE)+2], const int disks)
 {
-	const struct raid6_calls * const * algo;
-	const struct raid6_calls * best;
-	char *syndromes;
-	void *dptrs[(65536/PAGE_SIZE)+2];
-	int i, disks;
-	unsigned long perf, bestperf;
-	int bestprefer;
-	unsigned long j0, j1;
-
-	disks = (65536/PAGE_SIZE)+2;
-	for ( i = 0 ; i < disks-2 ; i++ ) {
-		dptrs[i] = ((char *)raid6_gfmul) + PAGE_SIZE*i;
-	}
-
-	/* Normal code - use a 2-page allocation to avoid D$ conflict */
-	syndromes = (void *) __get_free_pages(GFP_KERNEL, 1);
-
-	if ( !syndromes ) {
-		printk("raid6: Yikes!  No memory available.\n");
-		return -ENOMEM;
-	}
-
-	dptrs[disks-2] = syndromes;
-	dptrs[disks-1] = syndromes + PAGE_SIZE;
+	unsigned long perf, bestperf, j0, j1;
+	const struct raid6_calls *const *algo;
+	const struct raid6_calls *best;
 
-	bestperf = 0;  bestprefer = 0;  best = NULL;
+	for (bestperf = 0, best = NULL, algo = raid6_algos; *algo; algo++) {
+		if (!best || (*algo)->prefer >= best->prefer) {
+			if ((*algo)->valid && !(*algo)->valid())
+				continue;
 
-	for ( algo = raid6_algos ; *algo ; algo++ ) {
-		if ( !(*algo)->valid || (*algo)->valid() ) {
 			perf = 0;
 
 			preempt_disable();
 			j0 = jiffies;
-			while ( (j1 = jiffies) == j0 )
+			while ((j1 = jiffies) == j0)
 				cpu_relax();
 			while (time_before(jiffies,
 					    j1 + (1<<RAID6_TIME_JIFFIES_LG2))) {
-				(*algo)->gen_syndrome(disks, PAGE_SIZE, dptrs);
+				(*algo)->gen_syndrome(disks, PAGE_SIZE, *dptrs);
 				perf++;
 			}
 			preempt_enable();
 
-			if ( (*algo)->prefer > bestprefer ||
-			     ((*algo)->prefer == bestprefer &&
-			      perf > bestperf) ) {
-				best = *algo;
-				bestprefer = best->prefer;
+			if (perf > bestperf) {
 				bestperf = perf;
+				best = *algo;
 			}
 			printk("raid6: %-8s %5ld MB/s\n", (*algo)->name,
 			       (perf*HZ) >> (20-16+RAID6_TIME_JIFFIES_LG2));
@@ -173,12 +149,46 @@ int __init raid6_select_algo(void)
 	} else
 		printk("raid6: Yikes!  No algorithm found!\n");
 
-	free_pages((unsigned long)syndromes, 1);
+	return best;
+}
+
+
+/* Try to pick the best algorithm */
+/* This code uses the gfmul table as convenient data set to abuse */
+
+int __init raid6_select_algo(void)
+{
+	const int disks = (65536/PAGE_SIZE)+2;
+
+	const struct raid6_calls *gen_best;
+	const struct raid6_recov_calls *rec_best;
+	char *syndromes;
+	void *dptrs[(65536/PAGE_SIZE)+2];
+	int i;
+
+	for (i = 0; i < disks-2; i++)
+		dptrs[i] = ((char *)raid6_gfmul) + PAGE_SIZE*i;
+
+	/* Normal code - use a 2-page allocation to avoid D$ conflict */
+	syndromes = (void *) __get_free_pages(GFP_KERNEL, 1);
+
+	if (!syndromes) {
+		printk("raid6: Yikes!  No memory available.\n");
+		return -ENOMEM;
+	}
+
+	dptrs[disks-2] = syndromes;
+	dptrs[disks-1] = syndromes + PAGE_SIZE;
+
+	/* select raid gen_syndrome function */
+	gen_best = raid6_choose_gen(&dptrs, disks);
 
 	/* select raid recover functions */
-	raid6_choose_recov();
+	rec_best = raid6_choose_recov();
+
+	free_pages((unsigned long)syndromes, 1);
 
-	return best ? 0 : -EINVAL;
+	return gen_best && rec_best ? 0 : -EINVAL;
 }
 
 static void raid6_exit(void)

commit 048a8b8c89dc427dd7a58527c8923224b1e66d83
Author: Jim Kukunas <james.t.kukunas@linux.intel.com>
Date:   Tue May 22 13:54:18 2012 +1000

    lib/raid6: Add SSSE3 optimized recovery functions
    
    Add SSSE3 optimized recovery functions, as well as a system
    for selecting the most appropriate recovery functions to use.
    
    Originally-by: H. Peter Anvin <hpa@zytor.com>
    Signed-off-by: Jim Kukunas <james.t.kukunas@linux.intel.com>
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/lib/raid6/algos.c b/lib/raid6/algos.c
index f6a0f7899163..5a7f8022be13 100644
--- a/lib/raid6/algos.c
+++ b/lib/raid6/algos.c
@@ -64,6 +64,20 @@ const struct raid6_calls * const raid6_algos[] = {
 	NULL
 };
 
+void (*raid6_2data_recov)(int, size_t, int, int, void **);
+EXPORT_SYMBOL_GPL(raid6_2data_recov);
+
+void (*raid6_datap_recov)(int, size_t, int, void **);
+EXPORT_SYMBOL_GPL(raid6_datap_recov);
+
+const struct raid6_recov_calls *const raid6_recov_algos[] = {
+#if (defined(__i386__) || defined(__x86_64__)) && !defined(__arch_um__)
+	&raid6_recov_ssse3,
+#endif
+	&raid6_recov_intx1,
+	NULL
+};
+
 #ifdef __KERNEL__
 #define RAID6_TIME_JIFFIES_LG2	4
 #else
@@ -72,6 +86,26 @@ const struct raid6_calls * const raid6_algos[] = {
 #define time_before(x, y) ((x) < (y))
 #endif
 
+static inline void raid6_choose_recov(void)
+{
+	const struct raid6_recov_calls *const *algo;
+	const struct raid6_recov_calls *best;
+
+	for (best = NULL, algo = raid6_recov_algos; *algo; algo++)
+		if (!best || (*algo)->priority > best->priority)
+			if (!(*algo)->valid || (*algo)->valid())
+				best = *algo;
+
+	if (best) {
+		raid6_2data_recov = best->data2;
+		raid6_datap_recov = best->datap;
+
+		printk("raid6: using %s recovery algorithm\n", best->name);
+	} else
+		printk("raid6: Yikes! No recovery algorithm found!\n");
+}
+
+
 /* Try to pick the best algorithm */
 /* This code uses the gfmul table as convenient data set to abuse */
 
@@ -141,6 +175,9 @@ int __init raid6_select_algo(void)
 
 	free_pages((unsigned long)syndromes, 1);
 
+	/* select raid recover functions */
+	raid6_choose_recov();
+
 	return best ? 0 : -EINVAL;
 }
 

commit f674ef7b43881b2ac11f98d6ba2dc5d9dd0dd118
Author: Jim Kukunas <james.t.kukunas@linux.intel.com>
Date:   Tue May 22 13:54:16 2012 +1000

    lib/raid6: fix test program build
    
    <linux/module.h> drags in headers which are not visible to userspace,
    thus breaking the build for the test program.
    
    Signed-off-by: Jim Kukunas <james.t.kukunas@linux.intel.com>
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/lib/raid6/algos.c b/lib/raid6/algos.c
index 8b02f60ffc86..f6a0f7899163 100644
--- a/lib/raid6/algos.c
+++ b/lib/raid6/algos.c
@@ -17,11 +17,11 @@
  */
 
 #include <linux/raid/pq.h>
-#include <linux/module.h>
 #ifndef __KERNEL__
 #include <sys/mman.h>
 #include <stdio.h>
 #else
+#include <linux/module.h>
 #include <linux/gfp.h>
 #if !RAID6_USE_EMPTY_ZERO_PAGE
 /* In .bss so it's zeroed */

commit 056075c76417b112b4924e7b6386fdc6dfc9ac03
Author: Paul Gortmaker <paul.gortmaker@windriver.com>
Date:   Sun Jul 3 13:58:33 2011 -0400

    md: Add module.h to all files using it implicitly
    
    A pending cleanup will mean that module.h won't be implicitly
    everywhere anymore.  Make sure the modular drivers in md dir
    are actually calling out for <module.h> explicitly in advance.
    
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>

diff --git a/lib/raid6/algos.c b/lib/raid6/algos.c
index b595f560bee7..8b02f60ffc86 100644
--- a/lib/raid6/algos.c
+++ b/lib/raid6/algos.c
@@ -17,6 +17,7 @@
  */
 
 #include <linux/raid/pq.h>
+#include <linux/module.h>
 #ifndef __KERNEL__
 #include <sys/mman.h>
 #include <stdio.h>

commit a8e026c785b3fecef0ef5c00c15223542c4db8f5
Author: NeilBrown <neilb@suse.de>
Date:   Thu Aug 12 06:44:54 2010 +1000

    Further tidyup of raid6 naming in lib/raid6
    
    Rename raid6/raid6x86.h to raid6/x86.h
    and modify some comments.
    
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/lib/raid6/algos.c b/lib/raid6/algos.c
index df7ff72777b8..b595f560bee7 100644
--- a/lib/raid6/algos.c
+++ b/lib/raid6/algos.c
@@ -11,7 +11,7 @@
  * ----------------------------------------------------------------------- */
 
 /*
- * raid6algos.c
+ * raid6/algos.c
  *
  * Algorithm list and algorithm selection for RAID-6
  */

commit d5302fe41ffb28d0a48be6a71becba36d3453ae0
Author: NeilBrown <neilb@suse.de>
Date:   Thu Aug 12 06:38:24 2010 +1000

    Make lib/raid6/test build correctly.
    
    Some bit-rot needs to be cleaned out.
    
    Signed-off-by: NeilBrown <neilb@suse.de>

diff --git a/lib/raid6/algos.c b/lib/raid6/algos.c
index 1f8784bfd44d..df7ff72777b8 100644
--- a/lib/raid6/algos.c
+++ b/lib/raid6/algos.c
@@ -17,11 +17,11 @@
  */
 
 #include <linux/raid/pq.h>
-#include <linux/gfp.h>
 #ifndef __KERNEL__
 #include <sys/mman.h>
 #include <stdio.h>
 #else
+#include <linux/gfp.h>
 #if !RAID6_USE_EMPTY_ZERO_PAGE
 /* In .bss so it's zeroed */
 const char raid6_empty_zero_page[PAGE_SIZE] __attribute__((aligned(256)));

commit cc4589ebfae6f8dbb5cf880a0a67eedab3416492
Author: David Woodhouse <David.Woodhouse@intel.com>
Date:   Wed Aug 11 00:19:05 2010 +0100

    Rename raid6 files now they're in a 'raid6' directory.
    
    Linus asks 'why "raid6" twice?'. No reason.
    
    Signed-off-by: David Woodhouse <David.Woodhouse@intel.com>

diff --git a/lib/raid6/algos.c b/lib/raid6/algos.c
new file mode 100644
index 000000000000..1f8784bfd44d
--- /dev/null
+++ b/lib/raid6/algos.c
@@ -0,0 +1,154 @@
+/* -*- linux-c -*- ------------------------------------------------------- *
+ *
+ *   Copyright 2002 H. Peter Anvin - All Rights Reserved
+ *
+ *   This program is free software; you can redistribute it and/or modify
+ *   it under the terms of the GNU General Public License as published by
+ *   the Free Software Foundation, Inc., 53 Temple Place Ste 330,
+ *   Boston MA 02111-1307, USA; either version 2 of the License, or
+ *   (at your option) any later version; incorporated herein by reference.
+ *
+ * ----------------------------------------------------------------------- */
+
+/*
+ * raid6algos.c
+ *
+ * Algorithm list and algorithm selection for RAID-6
+ */
+
+#include <linux/raid/pq.h>
+#include <linux/gfp.h>
+#ifndef __KERNEL__
+#include <sys/mman.h>
+#include <stdio.h>
+#else
+#if !RAID6_USE_EMPTY_ZERO_PAGE
+/* In .bss so it's zeroed */
+const char raid6_empty_zero_page[PAGE_SIZE] __attribute__((aligned(256)));
+EXPORT_SYMBOL(raid6_empty_zero_page);
+#endif
+#endif
+
+struct raid6_calls raid6_call;
+EXPORT_SYMBOL_GPL(raid6_call);
+
+const struct raid6_calls * const raid6_algos[] = {
+	&raid6_intx1,
+	&raid6_intx2,
+	&raid6_intx4,
+	&raid6_intx8,
+#if defined(__ia64__)
+	&raid6_intx16,
+	&raid6_intx32,
+#endif
+#if defined(__i386__) && !defined(__arch_um__)
+	&raid6_mmxx1,
+	&raid6_mmxx2,
+	&raid6_sse1x1,
+	&raid6_sse1x2,
+	&raid6_sse2x1,
+	&raid6_sse2x2,
+#endif
+#if defined(__x86_64__) && !defined(__arch_um__)
+	&raid6_sse2x1,
+	&raid6_sse2x2,
+	&raid6_sse2x4,
+#endif
+#ifdef CONFIG_ALTIVEC
+	&raid6_altivec1,
+	&raid6_altivec2,
+	&raid6_altivec4,
+	&raid6_altivec8,
+#endif
+	NULL
+};
+
+#ifdef __KERNEL__
+#define RAID6_TIME_JIFFIES_LG2	4
+#else
+/* Need more time to be stable in userspace */
+#define RAID6_TIME_JIFFIES_LG2	9
+#define time_before(x, y) ((x) < (y))
+#endif
+
+/* Try to pick the best algorithm */
+/* This code uses the gfmul table as convenient data set to abuse */
+
+int __init raid6_select_algo(void)
+{
+	const struct raid6_calls * const * algo;
+	const struct raid6_calls * best;
+	char *syndromes;
+	void *dptrs[(65536/PAGE_SIZE)+2];
+	int i, disks;
+	unsigned long perf, bestperf;
+	int bestprefer;
+	unsigned long j0, j1;
+
+	disks = (65536/PAGE_SIZE)+2;
+	for ( i = 0 ; i < disks-2 ; i++ ) {
+		dptrs[i] = ((char *)raid6_gfmul) + PAGE_SIZE*i;
+	}
+
+	/* Normal code - use a 2-page allocation to avoid D$ conflict */
+	syndromes = (void *) __get_free_pages(GFP_KERNEL, 1);
+
+	if ( !syndromes ) {
+		printk("raid6: Yikes!  No memory available.\n");
+		return -ENOMEM;
+	}
+
+	dptrs[disks-2] = syndromes;
+	dptrs[disks-1] = syndromes + PAGE_SIZE;
+
+	bestperf = 0;  bestprefer = 0;  best = NULL;
+
+	for ( algo = raid6_algos ; *algo ; algo++ ) {
+		if ( !(*algo)->valid || (*algo)->valid() ) {
+			perf = 0;
+
+			preempt_disable();
+			j0 = jiffies;
+			while ( (j1 = jiffies) == j0 )
+				cpu_relax();
+			while (time_before(jiffies,
+					    j1 + (1<<RAID6_TIME_JIFFIES_LG2))) {
+				(*algo)->gen_syndrome(disks, PAGE_SIZE, dptrs);
+				perf++;
+			}
+			preempt_enable();
+
+			if ( (*algo)->prefer > bestprefer ||
+			     ((*algo)->prefer == bestprefer &&
+			      perf > bestperf) ) {
+				best = *algo;
+				bestprefer = best->prefer;
+				bestperf = perf;
+			}
+			printk("raid6: %-8s %5ld MB/s\n", (*algo)->name,
+			       (perf*HZ) >> (20-16+RAID6_TIME_JIFFIES_LG2));
+		}
+	}
+
+	if (best) {
+		printk("raid6: using algorithm %s (%ld MB/s)\n",
+		       best->name,
+		       (bestperf*HZ) >> (20-16+RAID6_TIME_JIFFIES_LG2));
+		raid6_call = *best;
+	} else
+		printk("raid6: Yikes!  No algorithm found!\n");
+
+	free_pages((unsigned long)syndromes, 1);
+
+	return best ? 0 : -EINVAL;
+}
+
+static void raid6_exit(void)
+{
+	do { } while (0);
+}
+
+subsys_initcall(raid6_select_algo);
+module_exit(raid6_exit);
+MODULE_LICENSE("GPL");
+MODULE_DESCRIPTION("RAID6 Q-syndrome calculations");
