commit cf86a086a18095e33e0637cb78cda1fcf5280852
Author: Eric Dumazet <edumazet@google.com>
Date:   Thu May 7 18:58:10 2020 -0700

    net/dst: use a smaller percpu_counter batch for dst entries accounting
    
    percpu_counter_add() uses a default batch size which is quite big
    on platforms with 256 cpus. (2*256 -> 512)
    
    This means dst_entries_get_fast() can be off by +/- 2*(nr_cpus^2)
    (131072 on servers with 256 cpus)
    
    Reduce the batch size to something more reasonable, and
    add logic to ip6_dst_gc() to call dst_entries_get_slow()
    before calling the _very_ expensive fib6_run_gc() function.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: Jakub Kicinski <kuba@kernel.org>

diff --git a/net/core/dst.c b/net/core/dst.c
index 193af526e908..d6b6ced0d451 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -81,11 +81,11 @@ void *dst_alloc(struct dst_ops *ops, struct net_device *dev,
 {
 	struct dst_entry *dst;
 
-	if (ops->gc && dst_entries_get_fast(ops) > ops->gc_thresh) {
+	if (ops->gc &&
+	    !(flags & DST_NOCOUNT) &&
+	    dst_entries_get_fast(ops) > ops->gc_thresh) {
 		if (ops->gc(ops)) {
-			printk_ratelimited(KERN_NOTICE "Route cache is full: "
-					   "consider increasing sysctl "
-					   "net.ipv[4|6].route.max_size.\n");
+			pr_notice_ratelimited("Route cache is full: consider increasing sysctl net.ipv6.route.max_size.\n");
 			return NULL;
 		}
 	}

commit adecda5bee0a05c11f1a4a4b16b01d11a832fd43
Author: Jason A. Donenfeld <Jason@zx2c4.com>
Date:   Tue Sep 24 11:09:37 2019 +0200

    net: print proper warning on dst underflow
    
    Proper warnings with stack traces make it much easier to figure out
    what's doing the double free and create more meaningful bug reports from
    users.
    
    Signed-off-by: Jason A. Donenfeld <Jason@zx2c4.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index 1325316d9eab..193af526e908 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -172,7 +172,7 @@ void dst_release(struct dst_entry *dst)
 		int newrefcnt;
 
 		newrefcnt = atomic_dec_return(&dst->__refcnt);
-		if (unlikely(newrefcnt < 0))
+		if (WARN_ONCE(newrefcnt < 0, "dst_release underflow"))
 			net_warn_ratelimited("%s: dst:%p refcnt:%d\n",
 					     __func__, dst, newrefcnt);
 		if (!newrefcnt)
@@ -187,7 +187,7 @@ void dst_release_immediate(struct dst_entry *dst)
 		int newrefcnt;
 
 		newrefcnt = atomic_dec_return(&dst->__refcnt);
-		if (unlikely(newrefcnt < 0))
+		if (WARN_ONCE(newrefcnt < 0, "dst_release_immediate underflow"))
 			net_warn_ratelimited("%s: dst:%p refcnt:%d\n",
 					     __func__, dst, newrefcnt);
 		if (!newrefcnt)

commit 8d7017fd621d02ff0d47d19484350c2356828483
Author: Mahesh Bandewar <maheshb@google.com>
Date:   Mon Jul 1 14:38:57 2019 -0700

    blackhole_netdev: use blackhole_netdev to invalidate dst entries
    
    Use blackhole_netdev instead of 'lo' device with lower MTU when marking
    dst "dead".
    
    Signed-off-by: Mahesh Bandewar <maheshb@google.com>
    Tested-by: Michael Chan <michael.chan@broadcom.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index e46366228eaf..1325316d9eab 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -160,7 +160,7 @@ void dst_dev_put(struct dst_entry *dst)
 		dst->ops->ifdown(dst, dev, true);
 	dst->input = dst_discard;
 	dst->output = dst_discard_out;
-	dst->dev = dev_net(dst->dev)->loopback_dev;
+	dst->dev = blackhole_netdev;
 	dev_hold(dst->dev);
 	dev_put(dev);
 }

commit 457c89965399115e5cd8bf38f9c597293405703d
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sun May 19 13:08:55 2019 +0100

    treewide: Add SPDX license identifier for missed files
    
    Add SPDX license identifiers to all files which:
    
     - Have no license information of any form
    
     - Have EXPORT_.*_SYMBOL_GPL inside which was used in the
       initial scan/conversion to ignore the file
    
    These files fall under the project license, GPL v2 only. The resulting SPDX
    license identifier is:
    
      GPL-2.0-only
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/net/core/dst.c b/net/core/dst.c
index 1f13d90cd0e4..e46366228eaf 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -1,3 +1,4 @@
+// SPDX-License-Identifier: GPL-2.0-only
 /*
  * net/core/dst.c	Protocol independent destination cache.
  *

commit 02afc7ad45bd6cfc9fd51fdbc132455371b63469
Author: Julian Wiedmann <jwi@linux.ibm.com>
Date:   Wed Mar 20 20:02:56 2019 +0100

    net: dst: remove gc leftovers
    
    Get rid of some obsolete gc-related documentation and macros that were
    missed in commit 5b7c9a8ff828 ("net: remove dst gc related code").
    
    CC: Wei Wang <weiwan@google.com>
    Signed-off-by: Julian Wiedmann <jwi@linux.ibm.com>
    Acked-by: Wei Wang <weiwan@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index a263309df115..1f13d90cd0e4 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -26,23 +26,6 @@
 #include <net/dst.h>
 #include <net/dst_metadata.h>
 
-/*
- * Theory of operations:
- * 1) We use a list, protected by a spinlock, to add
- *    new entries from both BH and non-BH context.
- * 2) In order to keep spinlock held for a small delay,
- *    we use a second list where are stored long lived
- *    entries, that are handled by the garbage collect thread
- *    fired by a workqueue.
- * 3) This list is guarded by a mutex,
- *    so that the gc_task and dst_dev_event() can be synchronized.
- */
-
-/*
- * We want to keep lock & list close together
- * to dirty as few cache lines as possible in __dst_free().
- * As this is not a very strong hint, we dont force an alignment on SMP.
- */
 int dst_discard_out(struct net *net, struct sock *sk, struct sk_buff *skb)
 {
 	kfree_skb(skb);

commit 22c2ad616b74f3de2256b242572ab449d031d941
Author: Peter Oskolkov <posk@google.com>
Date:   Wed Jan 16 08:50:28 2019 -0800

    net: add a route cache full diagnostic message
    
    In some testing scenarios, dst/route cache can fill up so quickly
    that even an explicit GC call occasionally fails to clean it up. This leads
    to sporadically failing calls to dst_alloc and "network unreachable" errors
    to the user, which is confusing.
    
    This patch adds a diagnostic message to make the cause of the failure
    easier to determine.
    
    Signed-off-by: Peter Oskolkov <posk@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index 81ccf20e2826..a263309df115 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -98,8 +98,12 @@ void *dst_alloc(struct dst_ops *ops, struct net_device *dev,
 	struct dst_entry *dst;
 
 	if (ops->gc && dst_entries_get_fast(ops) > ops->gc_thresh) {
-		if (ops->gc(ops))
+		if (ops->gc(ops)) {
+			printk_ratelimited(KERN_NOTICE "Route cache is full: "
+					   "consider increasing sysctl "
+					   "net.ipv[4|6].route.max_size.\n");
 			return NULL;
+		}
 	}
 
 	dst = kmem_cache_alloc(ops->kmem_cachep, GFP_ATOMIC);

commit af308b94a2a4a5a27bec9028354c4df444a7c8ba
Author: Pablo Neira Ayuso <pablo@netfilter.org>
Date:   Thu Aug 2 20:51:39 2018 +0200

    netfilter: nf_tables: add tunnel support
    
    This patch implements the tunnel object type that can be used to
    configure tunnels via metadata template through the existing lightweight
    API from the ingress path.
    
    Signed-off-by: Pablo Neira Ayuso <pablo@netfilter.org>

diff --git a/net/core/dst.c b/net/core/dst.c
index 2d9b37f8944a..81ccf20e2826 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -307,6 +307,7 @@ void metadata_dst_free(struct metadata_dst *md_dst)
 #endif
 	kfree(md_dst);
 }
+EXPORT_SYMBOL_GPL(metadata_dst_free);
 
 struct metadata_dst __percpu *
 metadata_dst_alloc_percpu(u8 optslen, enum metadata_type type, gfp_t flags)

commit d4ead6b34b67fd711639324b6465a050bcb197d4
Author: David Ahern <dsahern@gmail.com>
Date:   Tue Apr 17 17:33:16 2018 -0700

    net/ipv6: move metrics from dst to rt6_info
    
    Similar to IPv4, add fib metrics to the fib struct, which at the moment
    is rt6_info. Will be moved to fib6_info in a later patch. Copy metrics
    into dst by reference using refcount.
    
    To make the transition:
    - add dst_metrics to rt6_info. Default to dst_default_metrics if no
      metrics are passed during route add. No need for a separate pmtu
      entry; it can reference the MTU slot in fib6_metrics
    
    - ip6_convert_metrics allocates memory in the FIB entry and uses
      ip_metrics_convert to copy from netlink attribute to metrics entry
    
    - the convert metrics call is done in ip6_route_info_create simplifying
      the route add path
      + fib6_commit_metrics and fib6_copy_metrics and the temporary
        mx6_config are no longer needed
    
    - add fib6_metric_set helper to change the value of a metric in the
      fib entry since dst_metric_set can no longer be used
    
    - cow_metrics for IPv6 can drop to dst_cow_metrics_generic
    
    - rt6_dst_from_metrics_check is no longer needed
    
    - rt6_fill_node needs the FIB entry and dst as separate arguments to
      keep compatibility with existing output. Current dst address is
      renamed to dest.
      (to be consistent with IPv4 rt6_fill_node really should be split
      into 2 functions similar to fib_dump_info and rt_fill_info)
    
    - rt6_fill_node no longer needs the temporary metrics variable
    
    Signed-off-by: David Ahern <dsahern@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index 007aa0b08291..2d9b37f8944a 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -58,6 +58,7 @@ const struct dst_metrics dst_default_metrics = {
 	 */
 	.refcnt = REFCOUNT_INIT(1),
 };
+EXPORT_SYMBOL(dst_default_metrics);
 
 void dst_init(struct dst_entry *dst, struct dst_ops *ops,
 	      struct net_device *dev, int initial_ref, int initial_obsolete,

commit 7149f813d12d92ba9abcf49026f7cebc3d55c426
Author: David Miller <davem@davemloft.net>
Date:   Tue Nov 28 15:41:07 2017 -0500

    net: Remove dst->next
    
    There are no more users.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Reviewed-by: Eric Dumazet <edumazet@google.com>

diff --git a/net/core/dst.c b/net/core/dst.c
index 9bc3bb6e94ef..007aa0b08291 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -86,7 +86,6 @@ void dst_init(struct dst_entry *dst, struct dst_ops *ops,
 	dst->__use = 0;
 	dst->lastuse = jiffies;
 	dst->flags = flags;
-	dst->next = NULL;
 	if (!(flags & DST_NOCOUNT))
 		dst_entries_add(ops, 1);
 }

commit 0f6c480f23f49b53644b383c5554e579498347f3
Author: David Miller <davem@davemloft.net>
Date:   Tue Nov 28 15:40:46 2017 -0500

    xfrm: Move dst->path into struct xfrm_dst
    
    The first member of an IPSEC route bundle chain sets it's dst->path to
    the underlying ipv4/ipv6 route that carries the bundle.
    
    Stated another way, if one were to follow the xfrm_dst->child chain of
    the bundle, the final non-NULL pointer would be the path and point to
    either an ipv4 or an ipv6 route.
    
    This is largely used to make sure that PMTU events propagate down to
    the correct ipv4 or ipv6 route.
    
    When we don't have the top of an IPSEC bundle 'dst->path == dst'.
    
    Move it down into xfrm_dst and key off of dst->xfrm.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Reviewed-by: Eric Dumazet <edumazet@google.com>

diff --git a/net/core/dst.c b/net/core/dst.c
index cf2076c0eb22..9bc3bb6e94ef 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -69,7 +69,6 @@ void dst_init(struct dst_entry *dst, struct dst_ops *ops,
 	dst->ops = ops;
 	dst_init_metrics(dst, dst_default_metrics.metrics, true);
 	dst->expires = 0UL;
-	dst->path = dst;
 #ifdef CONFIG_XFRM
 	dst->xfrm = NULL;
 #endif

commit 3a2232e92e87166a8a5113e918b8c7b7bdce4d83
Author: David Miller <davem@davemloft.net>
Date:   Tue Nov 28 15:40:40 2017 -0500

    ipv6: Move dst->from into struct rt6_info.
    
    The dst->from value is only used by ipv6 routes to track where
    a route "came from".
    
    Any time we clone or copy a core ipv6 route in the ipv6 routing
    tables, we have the copy/clone's ->from point to the base route.
    
    This is used to handle route expiration properly.
    
    Only ipv6 uses this mechanism, and only ipv6 code references
    it.  So it is safe to move it into rt6_info.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Reviewed-by: Eric Dumazet <edumazet@google.com>

diff --git a/net/core/dst.c b/net/core/dst.c
index 5cf96179e8e0..cf2076c0eb22 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -70,7 +70,6 @@ void dst_init(struct dst_entry *dst, struct dst_ops *ops,
 	dst_init_metrics(dst, dst_default_metrics.metrics, true);
 	dst->expires = 0UL;
 	dst->path = dst;
-	dst->from = NULL;
 #ifdef CONFIG_XFRM
 	dst->xfrm = NULL;
 #endif

commit b6ca8bd5a9198c70c48297390723e4e56bd6e879
Author: David Miller <davem@davemloft.net>
Date:   Tue Nov 28 15:45:44 2017 -0500

    xfrm: Move child route linkage into xfrm_dst.
    
    XFRM bundle child chains look like this:
    
            xdst1 --> xdst2 --> xdst3 --> path_dst
    
    All of xdstN are xfrm_dst objects and xdst->u.dst.xfrm is non-NULL.
    The final child pointer in the chain, here called 'path_dst', is some
    other kind of route such as an ipv4 or ipv6 one.
    
    The xfrm output path pops routes, one at a time, via the child
    pointer, until we hit one which has a dst->xfrm pointer which
    is NULL.
    
    We can easily preserve the above mechanisms with child sitting
    only in the xfrm_dst structure.  All children in the chain
    before we break out of the xfrm_output() loop have dst->xfrm
    non-NULL and are therefore xfrm_dst objects.
    
    Since we break out of the loop when we find dst->xfrm NULL, we
    will not try to dereference 'dst' as if it were an xfrm_dst.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index 6a3c21b8fc8d..5cf96179e8e0 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -21,6 +21,7 @@
 #include <linux/sched.h>
 #include <linux/prefetch.h>
 #include <net/lwtunnel.h>
+#include <net/xfrm.h>
 
 #include <net/dst.h>
 #include <net/dst_metadata.h>
@@ -62,7 +63,6 @@ void dst_init(struct dst_entry *dst, struct dst_ops *ops,
 	      struct net_device *dev, int initial_ref, int initial_obsolete,
 	      unsigned short flags)
 {
-	dst->child = NULL;
 	dst->dev = dev;
 	if (dev)
 		dev_hold(dev);
@@ -121,8 +121,11 @@ struct dst_entry *dst_destroy(struct dst_entry * dst)
 	smp_rmb();
 
 #ifdef CONFIG_XFRM
-	if (dst->xfrm)
-		child = dst->child;
+	if (dst->xfrm) {
+		struct xfrm_dst *xdst = (struct xfrm_dst *) dst;
+
+		child = xdst->child;
+	}
 #endif
 	if (!(dst->flags & DST_NOCOUNT))
 		dst_entries_add(dst->ops, -1);

commit b92cf4aab8e688b1bd501ac2ac4f1b5c99601e3b
Author: David Miller <davem@davemloft.net>
Date:   Tue Nov 28 15:40:22 2017 -0500

    net: Create and use new helper xfrm_dst_child().
    
    Only IPSEC routes have a non-NULL dst->child pointer.  And IPSEC
    routes are identified by a non-NULL dst->xfrm pointer.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index 662a2d4a3d19..6a3c21b8fc8d 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -116,12 +116,14 @@ EXPORT_SYMBOL(dst_alloc);
 
 struct dst_entry *dst_destroy(struct dst_entry * dst)
 {
-	struct dst_entry *child;
+	struct dst_entry *child = NULL;
 
 	smp_rmb();
 
-	child = dst->child;
-
+#ifdef CONFIG_XFRM
+	if (dst->xfrm)
+		child = dst->child;
+#endif
 	if (!(dst->flags & DST_NOCOUNT))
 		dst_entries_add(dst->ops, -1);
 

commit 833e0e2f24fd0525090878f71e129a8a4cb8bf78
Author: Jakub Kicinski <jakub.kicinski@netronome.com>
Date:   Tue Oct 10 15:05:39 2017 -0700

    net: dst: move cpu inside ifdef to avoid compilation warning
    
    If CONFIG_DST_CACHE is not selected cpu variable
    will be unused and we will see a compilation warning.
    Move it under the ifdef.
    
    Reported-by: kbuild test robot <fengguang.wu@intel.com>
    Fixes: d66f2b91f95b ("bpf: don't rely on the verifier lock for metadata_dst allocation")
    Signed-off-by: Jakub Kicinski <jakub.kicinski@netronome.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index 8b2eafac984d..662a2d4a3d19 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -325,9 +325,9 @@ EXPORT_SYMBOL_GPL(metadata_dst_alloc_percpu);
 
 void metadata_dst_free_percpu(struct metadata_dst __percpu *md_dst)
 {
+#ifdef CONFIG_DST_CACHE
 	int cpu;
 
-#ifdef CONFIG_DST_CACHE
 	for_each_possible_cpu(cpu) {
 		struct metadata_dst *one_md_dst = per_cpu_ptr(md_dst, cpu);
 

commit d66f2b91f95b56e31772b9faa0d036cd2e53cb02
Author: Jakub Kicinski <jakub.kicinski@netronome.com>
Date:   Mon Oct 9 10:30:14 2017 -0700

    bpf: don't rely on the verifier lock for metadata_dst allocation
    
    bpf_skb_set_tunnel_*() functions require allocation of per-cpu
    metadata_dst.  The allocation happens upon verification of the
    first program using those helpers.  In preparation for removing
    the verifier lock, use cmpxchg() to make sure we only allocate
    the metadata_dsts once.
    
    Signed-off-by: Jakub Kicinski <jakub.kicinski@netronome.com>
    Reviewed-by: Simon Horman <simon.horman@netronome.com>
    Acked-by: Alexei Starovoitov <ast@kernel.org>
    Acked-by: Daniel Borkmann <daniel@iogearbox.net>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index a6c47da7d0f8..8b2eafac984d 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -322,3 +322,19 @@ metadata_dst_alloc_percpu(u8 optslen, enum metadata_type type, gfp_t flags)
 	return md_dst;
 }
 EXPORT_SYMBOL_GPL(metadata_dst_alloc_percpu);
+
+void metadata_dst_free_percpu(struct metadata_dst __percpu *md_dst)
+{
+	int cpu;
+
+#ifdef CONFIG_DST_CACHE
+	for_each_possible_cpu(cpu) {
+		struct metadata_dst *one_md_dst = per_cpu_ptr(md_dst, cpu);
+
+		if (one_md_dst->type == METADATA_IP_TUNNEL)
+			dst_cache_destroy(&one_md_dst->u.tun_info.dst_cache);
+	}
+#endif
+	free_percpu(md_dst);
+}
+EXPORT_SYMBOL_GPL(metadata_dst_free_percpu);

commit e65a4955b0bb70ab66e2fbfd5509747fe51d8bf9
Author: David Lamparter <equinox@diac24.net>
Date:   Fri Aug 18 14:31:35 2017 +0200

    net: check type when freeing metadata dst
    
    Commit 3fcece12bc1b ("net: store port/representator id in metadata_dst")
    added a new type field to metadata_dst, but metadata_dst_free() wasn't
    updated to check it before freeing the METADATA_IP_TUNNEL specific dst
    cache entry.
    
    This is not currently causing problems since it's far enough back in the
    struct to be zeroed for the only other type currently in existance
    (METADATA_HW_PORT_MUX), but nevertheless it's not correct.
    
    Fixes: 3fcece12bc1b ("net: store port/representator id in metadata_dst")
    Signed-off-by: David Lamparter <equinox@diac24.net>
    Cc: Jakub Kicinski <jakub.kicinski@netronome.com>
    Cc: Sridhar Samudrala <sridhar.samudrala@intel.com>
    Cc: Simon Horman <horms@verge.net.au>
    Cc: David S. Miller <davem@davemloft.net>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index d6ead757c258..a6c47da7d0f8 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -299,7 +299,8 @@ EXPORT_SYMBOL_GPL(metadata_dst_alloc);
 void metadata_dst_free(struct metadata_dst *md_dst)
 {
 #ifdef CONFIG_DST_CACHE
-	dst_cache_destroy(&md_dst->u.tun_info.dst_cache);
+	if (md_dst->type == METADATA_IP_TUNNEL)
+		dst_cache_destroy(&md_dst->u.tun_info.dst_cache);
 #endif
 	kfree(md_dst);
 }

commit 9620fef27ed2cdb37bf6fd028f32bea2ef5119a8
Author: Eric Dumazet <edumazet@google.com>
Date:   Fri Aug 18 12:08:07 2017 -0700

    ipv4: convert dst_metrics.refcnt from atomic_t to refcount_t
    
    refcount_t type and corresponding API should be
    used instead of atomic_t when the variable is used as
    a reference counter. This allows to avoid accidental
    refcounter overflows that might lead to use-after-free
    situations.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index 00aa972ad1a1..d6ead757c258 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -55,7 +55,7 @@ const struct dst_metrics dst_default_metrics = {
 	 * We really want to avoid false sharing on this variable, and catch
 	 * any writes on it.
 	 */
-	.refcnt = ATOMIC_INIT(1),
+	.refcnt = REFCOUNT_INIT(1),
 };
 
 void dst_init(struct dst_entry *dst, struct dst_ops *ops,
@@ -213,7 +213,7 @@ u32 *dst_cow_metrics_generic(struct dst_entry *dst, unsigned long old)
 		struct dst_metrics *old_p = (struct dst_metrics *)__DST_METRICS_PTR(old);
 		unsigned long prev, new;
 
-		atomic_set(&p->refcnt, 1);
+		refcount_set(&p->refcnt, 1);
 		memcpy(p->metrics, old_p->metrics, sizeof(p->metrics));
 
 		new = (unsigned long) p;
@@ -225,7 +225,7 @@ u32 *dst_cow_metrics_generic(struct dst_entry *dst, unsigned long old)
 			if (prev & DST_METRICS_READ_ONLY)
 				p = NULL;
 		} else if (prev & DST_METRICS_REFCOUNTED) {
-			if (atomic_dec_and_test(&old_p->refcnt))
+			if (refcount_dec_and_test(&old_p->refcnt))
 				kfree(old_p);
 		}
 	}

commit 3fcece12bc1b6dcdf0986f2cd9e8f63b1f9b6aa0
Author: Jakub Kicinski <jakub.kicinski@netronome.com>
Date:   Fri Jun 23 22:11:58 2017 +0200

    net: store port/representator id in metadata_dst
    
    Switches and modern SR-IOV enabled NICs may multiplex traffic from Port
    representators and control messages over single set of hardware queues.
    Control messages and muxed traffic may need ordered delivery.
    
    Those requirements make it hard to comfortably use TC infrastructure today
    unless we have a way of attaching metadata to skbs at the upper device.
    Because single set of queues is used for many netdevs stopping TC/sched
    queues of all of them reliably is impossible and lower device has to
    retreat to returning NETDEV_TX_BUSY and usually has to take extra locks on
    the fastpath.
    
    This patch attempts to enable port/representative devs to attach metadata
    to skbs which carry port id.  This way representatives can be queueless and
    all queuing can be performed at the lower netdev in the usual way.
    
    Traffic arriving on the port/representative interfaces will be have
    metadata attached and will subsequently be queued to the lower device for
    transmission.  The lower device should recognize the metadata and translate
    it to HW specific format which is most likely either a special header
    inserted before the network headers or descriptor/metadata fields.
    
    Metadata is associated with the lower device by storing the netdev pointer
    along with port id so that if TC decides to redirect or mirror the new
    netdev will not try to interpret it.
    
    This is mostly for SR-IOV devices since switches don't have lower netdevs
    today.
    
    Signed-off-by: Jakub Kicinski <jakub.kicinski@netronome.com>
    Signed-off-by: Sridhar Samudrala <sridhar.samudrala@intel.com>
    Signed-off-by: Simon Horman <horms@verge.net.au>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index f851adb9ec9b..00aa972ad1a1 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -264,7 +264,9 @@ static int dst_md_discard(struct sk_buff *skb)
 	return 0;
 }
 
-static void __metadata_dst_init(struct metadata_dst *md_dst, u8 optslen)
+static void __metadata_dst_init(struct metadata_dst *md_dst,
+				enum metadata_type type, u8 optslen)
+
 {
 	struct dst_entry *dst;
 
@@ -276,9 +278,11 @@ static void __metadata_dst_init(struct metadata_dst *md_dst, u8 optslen)
 	dst->output = dst_md_discard_out;
 
 	memset(dst + 1, 0, sizeof(*md_dst) + optslen - sizeof(*dst));
+	md_dst->type = type;
 }
 
-struct metadata_dst *metadata_dst_alloc(u8 optslen, gfp_t flags)
+struct metadata_dst *metadata_dst_alloc(u8 optslen, enum metadata_type type,
+					gfp_t flags)
 {
 	struct metadata_dst *md_dst;
 
@@ -286,7 +290,7 @@ struct metadata_dst *metadata_dst_alloc(u8 optslen, gfp_t flags)
 	if (!md_dst)
 		return NULL;
 
-	__metadata_dst_init(md_dst, optslen);
+	__metadata_dst_init(md_dst, type, optslen);
 
 	return md_dst;
 }
@@ -300,7 +304,8 @@ void metadata_dst_free(struct metadata_dst *md_dst)
 	kfree(md_dst);
 }
 
-struct metadata_dst __percpu *metadata_dst_alloc_percpu(u8 optslen, gfp_t flags)
+struct metadata_dst __percpu *
+metadata_dst_alloc_percpu(u8 optslen, enum metadata_type type, gfp_t flags)
 {
 	int cpu;
 	struct metadata_dst __percpu *md_dst;
@@ -311,7 +316,7 @@ struct metadata_dst __percpu *metadata_dst_alloc_percpu(u8 optslen, gfp_t flags)
 		return NULL;
 
 	for_each_possible_cpu(cpu)
-		__metadata_dst_init(per_cpu_ptr(md_dst, cpu), optslen);
+		__metadata_dst_init(per_cpu_ptr(md_dst, cpu), type, optslen);
 
 	return md_dst;
 }

commit a4c2fd7f78915a0d7c5275e7612e7793157a01f2
Author: Wei Wang <weiwan@google.com>
Date:   Sat Jun 17 10:42:42 2017 -0700

    net: remove DST_NOCACHE flag
    
    DST_NOCACHE flag check has been removed from dst_release() and
    dst_hold_safe() in a previous patch because all the dst are now ref
    counted properly and can be released based on refcnt only.
    Looking at the rest of the DST_NOCACHE use, all of them can now be
    removed or replaced with other checks.
    So this patch gets rid of all the DST_NOCACHE usage and remove this flag
    completely.
    
    Signed-off-by: Wei Wang <weiwan@google.com>
    Acked-by: Martin KaFai Lau <kafai@fb.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index 70543dabb797..f851adb9ec9b 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -270,7 +270,7 @@ static void __metadata_dst_init(struct metadata_dst *md_dst, u8 optslen)
 
 	dst = &md_dst->dst;
 	dst_init(dst, &md_dst_ops, NULL, 1, DST_OBSOLETE_NONE,
-		 DST_METADATA | DST_NOCACHE | DST_NOCOUNT);
+		 DST_METADATA | DST_NOCOUNT);
 
 	dst->input = dst_md_discard;
 	dst->output = dst_md_discard_out;

commit b2a9c0ed75a32e788d034a58a18f2fc46396e412
Author: Wei Wang <weiwan@google.com>
Date:   Sat Jun 17 10:42:41 2017 -0700

    net: remove DST_NOGC flag
    
    Now that all the components have been changed to release dst based on
    refcnt only and not depend on dst gc anymore, we can remove the
    temporary flag DST_NOGC.
    
    Note that we also need to remove the DST_NOCACHE check in dst_release()
    and dst_hold_safe() because now all the dst are released based on refcnt
    and behaves as DST_NOCACHE.
    
    Signed-off-by: Wei Wang <weiwan@google.com>
    Acked-by: Martin KaFai Lau <kafai@fb.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index 30bea01d2262..70543dabb797 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -179,14 +179,12 @@ void dst_release(struct dst_entry *dst)
 {
 	if (dst) {
 		int newrefcnt;
-		unsigned short destroy_after_rcu = dst->flags &
-						   (DST_NOCACHE | DST_NOGC);
 
 		newrefcnt = atomic_dec_return(&dst->__refcnt);
 		if (unlikely(newrefcnt < 0))
 			net_warn_ratelimited("%s: dst:%p refcnt:%d\n",
 					     __func__, dst, newrefcnt);
-		if (!newrefcnt && unlikely(destroy_after_rcu))
+		if (!newrefcnt)
 			call_rcu(&dst->rcu_head, dst_destroy_rcu);
 	}
 }

commit 5b7c9a8ff828287af5aebe93e707271bf1a82cc3
Author: Wei Wang <weiwan@google.com>
Date:   Sat Jun 17 10:42:40 2017 -0700

    net: remove dst gc related code
    
    This patch removes all dst gc related code and all the dst free
    functions
    
    Signed-off-by: Wei Wang <weiwan@google.com>
    Acked-by: Martin KaFai Lau <kafai@fb.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index 64056ecca5b8..30bea01d2262 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -42,108 +42,6 @@
  * to dirty as few cache lines as possible in __dst_free().
  * As this is not a very strong hint, we dont force an alignment on SMP.
  */
-static struct {
-	spinlock_t		lock;
-	struct dst_entry	*list;
-	unsigned long		timer_inc;
-	unsigned long		timer_expires;
-} dst_garbage = {
-	.lock = __SPIN_LOCK_UNLOCKED(dst_garbage.lock),
-	.timer_inc = DST_GC_MAX,
-};
-static void dst_gc_task(struct work_struct *work);
-static void ___dst_free(struct dst_entry *dst);
-
-static DECLARE_DELAYED_WORK(dst_gc_work, dst_gc_task);
-
-static DEFINE_MUTEX(dst_gc_mutex);
-/*
- * long lived entries are maintained in this list, guarded by dst_gc_mutex
- */
-static struct dst_entry         *dst_busy_list;
-
-static void dst_gc_task(struct work_struct *work)
-{
-	int    delayed = 0;
-	int    work_performed = 0;
-	unsigned long expires = ~0L;
-	struct dst_entry *dst, *next, head;
-	struct dst_entry *last = &head;
-
-	mutex_lock(&dst_gc_mutex);
-	next = dst_busy_list;
-
-loop:
-	while ((dst = next) != NULL) {
-		next = dst->next;
-		prefetch(&next->next);
-		cond_resched();
-		if (likely(atomic_read(&dst->__refcnt))) {
-			last->next = dst;
-			last = dst;
-			delayed++;
-			continue;
-		}
-		work_performed++;
-
-		dst = dst_destroy(dst);
-		if (dst) {
-			/* NOHASH and still referenced. Unless it is already
-			 * on gc list, invalidate it and add to gc list.
-			 *
-			 * Note: this is temporary. Actually, NOHASH dst's
-			 * must be obsoleted when parent is obsoleted.
-			 * But we do not have state "obsoleted, but
-			 * referenced by parent", so it is right.
-			 */
-			if (dst->obsolete > 0)
-				continue;
-
-			___dst_free(dst);
-			dst->next = next;
-			next = dst;
-		}
-	}
-
-	spin_lock_bh(&dst_garbage.lock);
-	next = dst_garbage.list;
-	if (next) {
-		dst_garbage.list = NULL;
-		spin_unlock_bh(&dst_garbage.lock);
-		goto loop;
-	}
-	last->next = NULL;
-	dst_busy_list = head.next;
-	if (!dst_busy_list)
-		dst_garbage.timer_inc = DST_GC_MAX;
-	else {
-		/*
-		 * if we freed less than 1/10 of delayed entries,
-		 * we can sleep longer.
-		 */
-		if (work_performed <= delayed/10) {
-			dst_garbage.timer_expires += dst_garbage.timer_inc;
-			if (dst_garbage.timer_expires > DST_GC_MAX)
-				dst_garbage.timer_expires = DST_GC_MAX;
-			dst_garbage.timer_inc += DST_GC_INC;
-		} else {
-			dst_garbage.timer_inc = DST_GC_INC;
-			dst_garbage.timer_expires = DST_GC_MIN;
-		}
-		expires = dst_garbage.timer_expires;
-		/*
-		 * if the next desired timer is more than 4 seconds in the
-		 * future then round the timer to whole seconds
-		 */
-		if (expires > 4*HZ)
-			expires = round_jiffies_relative(expires);
-		schedule_delayed_work(&dst_gc_work, expires);
-	}
-
-	spin_unlock_bh(&dst_garbage.lock);
-	mutex_unlock(&dst_gc_mutex);
-}
-
 int dst_discard_out(struct net *net, struct sock *sk, struct sk_buff *skb)
 {
 	kfree_skb(skb);
@@ -216,34 +114,6 @@ void *dst_alloc(struct dst_ops *ops, struct net_device *dev,
 }
 EXPORT_SYMBOL(dst_alloc);
 
-static void ___dst_free(struct dst_entry *dst)
-{
-	/* The first case (dev==NULL) is required, when
-	   protocol module is unloaded.
-	 */
-	if (dst->dev == NULL || !(dst->dev->flags&IFF_UP)) {
-		dst->input = dst_discard;
-		dst->output = dst_discard_out;
-	}
-	dst->obsolete = DST_OBSOLETE_DEAD;
-}
-
-void __dst_free(struct dst_entry *dst)
-{
-	spin_lock_bh(&dst_garbage.lock);
-	___dst_free(dst);
-	dst->next = dst_garbage.list;
-	dst_garbage.list = dst;
-	if (dst_garbage.timer_inc > DST_GC_INC) {
-		dst_garbage.timer_inc = DST_GC_INC;
-		dst_garbage.timer_expires = DST_GC_MIN;
-		mod_delayed_work(system_wq, &dst_gc_work,
-				 dst_garbage.timer_expires);
-	}
-	spin_unlock_bh(&dst_garbage.lock);
-}
-EXPORT_SYMBOL(__dst_free);
-
 struct dst_entry *dst_destroy(struct dst_entry * dst)
 {
 	struct dst_entry *child;
@@ -448,86 +318,3 @@ struct metadata_dst __percpu *metadata_dst_alloc_percpu(u8 optslen, gfp_t flags)
 	return md_dst;
 }
 EXPORT_SYMBOL_GPL(metadata_dst_alloc_percpu);
-
-/* Dirty hack. We did it in 2.2 (in __dst_free),
- * we have _very_ good reasons not to repeat
- * this mistake in 2.3, but we have no choice
- * now. _It_ _is_ _explicit_ _deliberate_
- * _race_ _condition_.
- *
- * Commented and originally written by Alexey.
- */
-static void dst_ifdown(struct dst_entry *dst, struct net_device *dev,
-		       int unregister)
-{
-	if (dst->ops->ifdown)
-		dst->ops->ifdown(dst, dev, unregister);
-
-	if (dev != dst->dev)
-		return;
-
-	if (!unregister) {
-		dst->input = dst_discard;
-		dst->output = dst_discard_out;
-	} else {
-		dst->dev = dev_net(dst->dev)->loopback_dev;
-		dev_hold(dst->dev);
-		dev_put(dev);
-	}
-}
-
-static int dst_dev_event(struct notifier_block *this, unsigned long event,
-			 void *ptr)
-{
-	struct net_device *dev = netdev_notifier_info_to_dev(ptr);
-	struct dst_entry *dst, *last = NULL;
-
-	switch (event) {
-	case NETDEV_UNREGISTER_FINAL:
-	case NETDEV_DOWN:
-		mutex_lock(&dst_gc_mutex);
-		for (dst = dst_busy_list; dst; dst = dst->next) {
-			last = dst;
-			dst_ifdown(dst, dev, event != NETDEV_DOWN);
-		}
-
-		spin_lock_bh(&dst_garbage.lock);
-		dst = dst_garbage.list;
-		dst_garbage.list = NULL;
-		/* The code in dst_ifdown places a hold on the loopback device.
-		 * If the gc entry processing is set to expire after a lengthy
-		 * interval, this hold can cause netdev_wait_allrefs() to hang
-		 * out and wait for a long time -- until the the loopback
-		 * interface is released.  If we're really unlucky, it'll emit
-		 * pr_emerg messages to console too.  Reset the interval here,
-		 * so dst cleanups occur in a more timely fashion.
-		 */
-		if (dst_garbage.timer_inc > DST_GC_INC) {
-			dst_garbage.timer_inc = DST_GC_INC;
-			dst_garbage.timer_expires = DST_GC_MIN;
-			mod_delayed_work(system_wq, &dst_gc_work,
-					 dst_garbage.timer_expires);
-		}
-		spin_unlock_bh(&dst_garbage.lock);
-
-		if (last)
-			last->next = dst;
-		else
-			dst_busy_list = dst;
-		for (; dst; dst = dst->next)
-			dst_ifdown(dst, dev, event != NETDEV_DOWN);
-		mutex_unlock(&dst_gc_mutex);
-		break;
-	}
-	return NOTIFY_DONE;
-}
-
-static struct notifier_block dst_dev_notifier = {
-	.notifier_call	= dst_dev_event,
-	.priority = -10, /* must be called after other network notifiers */
-};
-
-void __init dst_subsys_init(void)
-{
-	register_netdevice_notifier(&dst_dev_notifier);
-}

commit 52df157f17e564ec22afc3e4a89b21828220f576
Author: Wei Wang <weiwan@google.com>
Date:   Sat Jun 17 10:42:38 2017 -0700

    xfrm: take refcnt of dst when creating struct xfrm_dst bundle
    
    During the creation of xfrm_dst bundle, always take ref count when
    allocating the dst. This way, xfrm_bundle_create() will form a linked
    list of dst with dst->child pointing to a ref counted dst child. And
    the returned dst pointer is also ref counted. This makes the link from
    the flow cache to this dst now ref counted properly.
    As the dst is always ref counted properly, we can safely mark
    DST_NOGC flag so dst_release() will release dst based on refcnt only.
    And dst gc is no longer needed and all dst_free() and its related
    function calls should be replaced with dst_release() or
    dst_release_immediate().
    
    The special handling logic for dst->child in dst_destroy() can be
    replaced with a simple dst_release_immediate() call on the child to
    release the whole list linked by dst->child pointer.
    Previously used DST_NOHASH flag is not needed anymore as well. The
    reason that DST_NOHASH is used in the existing code is mainly to prevent
    the dst inserted in the fib tree to be wrongly destroyed during the
    deletion of the xfrm_dst bundle. So in the existing code, DST_NOHASH
    flag is marked in all the dst children except the one which is in the
    fib tree.
    However, with this patch series to remove dst gc logic and release dst
    only based on ref count, it is safe to release all the children from a
    xfrm_dst bundle as long as the dst children are all ref counted
    properly which is already the case in the existing code.
    So, this patch removes the use of DST_NOHASH flag.
    
    Signed-off-by: Wei Wang <weiwan@google.com>
    Acked-by: Martin KaFai Lau <kafai@fb.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index 56998f69b84e..64056ecca5b8 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -250,7 +250,6 @@ struct dst_entry *dst_destroy(struct dst_entry * dst)
 
 	smp_rmb();
 
-again:
 	child = dst->child;
 
 	if (!(dst->flags & DST_NOCOUNT))
@@ -269,20 +268,8 @@ struct dst_entry *dst_destroy(struct dst_entry * dst)
 		kmem_cache_free(dst->ops->kmem_cachep, dst);
 
 	dst = child;
-	if (dst) {
-		int nohash = dst->flags & DST_NOHASH;
-
-		if (atomic_dec_and_test(&dst->__refcnt)) {
-			/* We were real parent of this dst, so kill child. */
-			if (nohash)
-				goto again;
-		} else {
-			/* Child is still referenced, return it for freeing. */
-			if (nohash)
-				return dst;
-			/* Child is still in his hash table */
-		}
-	}
+	if (dst)
+		dst_release_immediate(dst);
 	return NULL;
 }
 EXPORT_SYMBOL(dst_destroy);
@@ -292,8 +279,6 @@ static void dst_destroy_rcu(struct rcu_head *head)
 	struct dst_entry *dst = container_of(head, struct dst_entry, rcu_head);
 
 	dst = dst_destroy(dst);
-	if (dst)
-		__dst_free(dst);
 }
 
 /* Operations to mark dst as DEAD and clean up the net device referenced

commit 4a6ce2b6f2ecabbddcfe47e7cf61dd0f00b10e36
Author: Wei Wang <weiwan@google.com>
Date:   Sat Jun 17 10:42:28 2017 -0700

    net: introduce a new function dst_dev_put()
    
    This function should be called when removing routes from fib tree after
    the dst gc is no longer in use.
    We first mark DST_OBSOLETE_DEAD on this dst to make sure next
    dst_ops->check() fails and returns NULL.
    Secondly, as we no longer keep the gc_list, we need to properly
    release dst->dev right at the moment when the dst is removed from
    the fib/fib6 tree.
    It does the following:
    1. change dst->input and output pointers to dst_discard/dst_dscard_out to
       discard all packets
    2. replace dst->dev with loopback interface
    
    Signed-off-by: Wei Wang <weiwan@google.com>
    Acked-by: Martin KaFai Lau <kafai@fb.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index 551834c3363f..56998f69b84e 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -296,6 +296,30 @@ static void dst_destroy_rcu(struct rcu_head *head)
 		__dst_free(dst);
 }
 
+/* Operations to mark dst as DEAD and clean up the net device referenced
+ * by dst:
+ * 1. put the dst under loopback interface and discard all tx/rx packets
+ *    on this route.
+ * 2. release the net_device
+ * This function should be called when removing routes from the fib tree
+ * in preparation for a NETDEV_DOWN/NETDEV_UNREGISTER event and also to
+ * make the next dst_ops->check() fail.
+ */
+void dst_dev_put(struct dst_entry *dst)
+{
+	struct net_device *dev = dst->dev;
+
+	dst->obsolete = DST_OBSOLETE_DEAD;
+	if (dst->ops->ifdown)
+		dst->ops->ifdown(dst, dev, true);
+	dst->input = dst_discard;
+	dst->output = dst_discard_out;
+	dst->dev = dev_net(dst->dev)->loopback_dev;
+	dev_hold(dst->dev);
+	dev_put(dev);
+}
+EXPORT_SYMBOL(dst_dev_put);
+
 void dst_release(struct dst_entry *dst)
 {
 	if (dst) {

commit 5f56f409b5142bb4e88e1f64dedeb4a76c678177
Author: Wei Wang <weiwan@google.com>
Date:   Sat Jun 17 10:42:27 2017 -0700

    net: introduce DST_NOGC in dst_release() to destroy dst based on refcnt
    
    The current mechanism of freeing dst is a bit complicated. dst has its
    ref count and when user grabs the reference to the dst, the ref count is
    properly taken in most cases except in IPv4/IPv6/decnet/xfrm routing
    code due to some historic reasons.
    
    If the reference to dst is always taken properly, we should be able to
    simplify the logic in dst_release() to destroy dst when dst->__refcnt
    drops from 1 to 0. And this should be the only condition to determine
    if we can call dst_destroy().
    And as dst is always ref counted, there is no need for a dst garbage
    list to hold the dst entries that already get removed by the routing
    code but are still held by other users. And the task to periodically
    check the list to free dst if ref count become 0 is also not needed
    anymore.
    
    This patch introduces a temporary flag DST_NOGC(no garbage collector).
    If it is set in the dst, dst_release() will call dst_destroy() when
    dst->__refcnt drops to 0. dst_hold_safe() will also check for this flag
    and do atomic_inc_not_zero() similar as DST_NOCACHE to avoid double free
    issue.
    This temporary flag is mainly used so that we can make the transition
    component by component without breaking other parts.
    This flag will be removed after all components are properly transitioned.
    
    This patch also introduces a new function dst_release_immediate() which
    destroys dst without waiting on the rcu when refcnt drops to 0. It will
    be used in later patches.
    
    Follow-up patches will correct all the places to properly take ref count
    on dst and mark DST_NOGC. dst_release() or dst_release_immediate() will
    be used to release the dst instead of dst_free() and its related
    functions.
    And final clean-up patch will remove the DST_NOGC flag.
    
    Signed-off-by: Wei Wang <weiwan@google.com>
    Acked-by: Martin KaFai Lau <kafai@fb.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index 13ba4a090c41..551834c3363f 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -300,18 +300,34 @@ void dst_release(struct dst_entry *dst)
 {
 	if (dst) {
 		int newrefcnt;
-		unsigned short nocache = dst->flags & DST_NOCACHE;
+		unsigned short destroy_after_rcu = dst->flags &
+						   (DST_NOCACHE | DST_NOGC);
 
 		newrefcnt = atomic_dec_return(&dst->__refcnt);
 		if (unlikely(newrefcnt < 0))
 			net_warn_ratelimited("%s: dst:%p refcnt:%d\n",
 					     __func__, dst, newrefcnt);
-		if (!newrefcnt && unlikely(nocache))
+		if (!newrefcnt && unlikely(destroy_after_rcu))
 			call_rcu(&dst->rcu_head, dst_destroy_rcu);
 	}
 }
 EXPORT_SYMBOL(dst_release);
 
+void dst_release_immediate(struct dst_entry *dst)
+{
+	if (dst) {
+		int newrefcnt;
+
+		newrefcnt = atomic_dec_return(&dst->__refcnt);
+		if (unlikely(newrefcnt < 0))
+			net_warn_ratelimited("%s: dst:%p refcnt:%d\n",
+					     __func__, dst, newrefcnt);
+		if (!newrefcnt)
+			dst_destroy(dst);
+	}
+}
+EXPORT_SYMBOL(dst_release_immediate);
+
 u32 *dst_cow_metrics_generic(struct dst_entry *dst, unsigned long old)
 {
 	struct dst_metrics *p = kmalloc(sizeof(*p), GFP_ATOMIC);

commit f186ce61bb8235d80068c390dc2aad7ca427a4c2
Author: Krister Johansen <kjlx@templeofstupid.com>
Date:   Thu Jun 8 13:12:38 2017 -0700

    Fix an intermittent pr_emerg warning about lo becoming free.
    
    It looks like this:
    
    Message from syslogd@flamingo at Apr 26 00:45:00 ...
     kernel:unregister_netdevice: waiting for lo to become free. Usage count = 4
    
    They seem to coincide with net namespace teardown.
    
    The message is emitted by netdev_wait_allrefs().
    
    Forced a kdump in netdev_run_todo, but found that the refcount on the lo
    device was already 0 at the time we got to the panic.
    
    Used bcc to check the blocking in netdev_run_todo.  The only places
    where we're off cpu there are in the rcu_barrier() and msleep() calls.
    That behavior is expected.  The msleep time coincides with the amount of
    time we spend waiting for the refcount to reach zero; the rcu_barrier()
    wait times are not excessive.
    
    After looking through the list of callbacks that the netdevice notifiers
    invoke in this path, it appears that the dst_dev_event is the most
    interesting.  The dst_ifdown path places a hold on the loopback_dev as
    part of releasing the dev associated with the original dst cache entry.
    Most of our notifier callbacks are straight-forward, but this one a)
    looks complex, and b) places a hold on the network interface in
    question.
    
    I constructed a new bcc script that watches various events in the
    liftime of a dst cache entry.  Note that dst_ifdown will take a hold on
    the loopback device until the invalidated dst entry gets freed.
    
    [      __dst_free] on DST: ffff883ccabb7900 IF tap1008300eth0 invoked at 1282115677036183
        __dst_free
        rcu_nocb_kthread
        kthread
        ret_from_fork
    Acked-by: Eric Dumazet <edumazet@google.com>
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index 6192f11beec9..13ba4a090c41 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -469,6 +469,20 @@ static int dst_dev_event(struct notifier_block *this, unsigned long event,
 		spin_lock_bh(&dst_garbage.lock);
 		dst = dst_garbage.list;
 		dst_garbage.list = NULL;
+		/* The code in dst_ifdown places a hold on the loopback device.
+		 * If the gc entry processing is set to expire after a lengthy
+		 * interval, this hold can cause netdev_wait_allrefs() to hang
+		 * out and wait for a long time -- until the the loopback
+		 * interface is released.  If we're really unlucky, it'll emit
+		 * pr_emerg messages to console too.  Reset the interval here,
+		 * so dst cleanups occur in a more timely fashion.
+		 */
+		if (dst_garbage.timer_inc > DST_GC_INC) {
+			dst_garbage.timer_inc = DST_GC_INC;
+			dst_garbage.timer_expires = DST_GC_MIN;
+			mod_delayed_work(system_wq, &dst_gc_work,
+					 dst_garbage.timer_expires);
+		}
 		spin_unlock_bh(&dst_garbage.lock);
 
 		if (last)

commit 3fb07daff8e99243366a081e5129560734de4ada
Author: Eric Dumazet <edumazet@google.com>
Date:   Thu May 25 14:27:35 2017 -0700

    ipv4: add reference counting to metrics
    
    Andrey Konovalov reported crashes in ipv4_mtu()
    
    I could reproduce the issue with KASAN kernels, between
    10.246.7.151 and 10.246.7.152 :
    
    1) 20 concurrent netperf -t TCP_RR -H 10.246.7.152 -l 1000 &
    
    2) At the same time run following loop :
    while :
    do
     ip ro add 10.246.7.152 dev eth0 src 10.246.7.151 mtu 1500
     ip ro del 10.246.7.152 dev eth0 src 10.246.7.151 mtu 1500
    done
    
    Cong Wang attempted to add back rt->fi in commit
    82486aa6f1b9 ("ipv4: restore rt->fi for reference counting")
    but this proved to add some issues that were complex to solve.
    
    Instead, I suggested to add a refcount to the metrics themselves,
    being a standalone object (in particular, no reference to other objects)
    
    I tried to make this patch as small as possible to ease its backport,
    instead of being super clean. Note that we believe that only ipv4 dst
    need to take care of the metric refcount. But if this is wrong,
    this patch adds the basic infrastructure to extend this to other
    families.
    
    Many thanks to Julian Anastasov for reviewing this patch, and Cong Wang
    for his efforts on this problem.
    
    Fixes: 2860583fe840 ("ipv4: Kill rt->fi")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: Andrey Konovalov <andreyknvl@google.com>
    Reviewed-by: Julian Anastasov <ja@ssi.bg>
    Acked-by: Cong Wang <xiyou.wangcong@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index 960e503b5a52..6192f11beec9 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -151,13 +151,13 @@ int dst_discard_out(struct net *net, struct sock *sk, struct sk_buff *skb)
 }
 EXPORT_SYMBOL(dst_discard_out);
 
-const u32 dst_default_metrics[RTAX_MAX + 1] = {
+const struct dst_metrics dst_default_metrics = {
 	/* This initializer is needed to force linker to place this variable
 	 * into const section. Otherwise it might end into bss section.
 	 * We really want to avoid false sharing on this variable, and catch
 	 * any writes on it.
 	 */
-	[RTAX_MAX] = 0xdeadbeef,
+	.refcnt = ATOMIC_INIT(1),
 };
 
 void dst_init(struct dst_entry *dst, struct dst_ops *ops,
@@ -169,7 +169,7 @@ void dst_init(struct dst_entry *dst, struct dst_ops *ops,
 	if (dev)
 		dev_hold(dev);
 	dst->ops = ops;
-	dst_init_metrics(dst, dst_default_metrics, true);
+	dst_init_metrics(dst, dst_default_metrics.metrics, true);
 	dst->expires = 0UL;
 	dst->path = dst;
 	dst->from = NULL;
@@ -314,25 +314,30 @@ EXPORT_SYMBOL(dst_release);
 
 u32 *dst_cow_metrics_generic(struct dst_entry *dst, unsigned long old)
 {
-	u32 *p = kmalloc(sizeof(u32) * RTAX_MAX, GFP_ATOMIC);
+	struct dst_metrics *p = kmalloc(sizeof(*p), GFP_ATOMIC);
 
 	if (p) {
-		u32 *old_p = __DST_METRICS_PTR(old);
+		struct dst_metrics *old_p = (struct dst_metrics *)__DST_METRICS_PTR(old);
 		unsigned long prev, new;
 
-		memcpy(p, old_p, sizeof(u32) * RTAX_MAX);
+		atomic_set(&p->refcnt, 1);
+		memcpy(p->metrics, old_p->metrics, sizeof(p->metrics));
 
 		new = (unsigned long) p;
 		prev = cmpxchg(&dst->_metrics, old, new);
 
 		if (prev != old) {
 			kfree(p);
-			p = __DST_METRICS_PTR(prev);
+			p = (struct dst_metrics *)__DST_METRICS_PTR(prev);
 			if (prev & DST_METRICS_READ_ONLY)
 				p = NULL;
+		} else if (prev & DST_METRICS_REFCOUNTED) {
+			if (atomic_dec_and_test(&old_p->refcnt))
+				kfree(old_p);
 		}
 	}
-	return p;
+	BUILD_BUG_ON(offsetof(struct dst_metrics, metrics) != 0);
+	return (u32 *)p;
 }
 EXPORT_SYMBOL(dst_cow_metrics_generic);
 
@@ -341,7 +346,7 @@ void __dst_destroy_metrics_generic(struct dst_entry *dst, unsigned long old)
 {
 	unsigned long prev, new;
 
-	new = ((unsigned long) dst_default_metrics) | DST_METRICS_READ_ONLY;
+	new = ((unsigned long) &dst_default_metrics) | DST_METRICS_READ_ONLY;
 	prev = cmpxchg(&dst->_metrics, old, new);
 	if (prev == old)
 		kfree(__DST_METRICS_PTR(old));

commit 51ce8bd4d17a761e1a90a34a1b5c9b762cce7553
Author: Julian Anastasov <ja@ssi.bg>
Date:   Mon Feb 6 23:14:17 2017 +0200

    net: pending_confirm is not used anymore
    
    When same struct dst_entry can be used for many different
    neighbours we can not use it for pending confirmations.
    As last step, we can remove the pending_confirm flag.
    
    Reported-by: YueHaibing <yuehaibing@huawei.com>
    Fixes: 5110effee8fd ("net: Do delayed neigh confirmation.")
    Fixes: f2bb4bedf35d ("ipv4: Cache output routes in fib_info nexthops.")
    Signed-off-by: Julian Anastasov <ja@ssi.bg>
    Acked-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index b5cbbe07f786..960e503b5a52 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -190,7 +190,6 @@ void dst_init(struct dst_entry *dst, struct dst_ops *ops,
 	dst->__use = 0;
 	dst->lastuse = jiffies;
 	dst->flags = flags;
-	dst->pending_confirm = 0;
 	dst->next = NULL;
 	if (!(flags & DST_NOCOUNT))
 		dst_entries_add(ops, 1);

commit d71785ffc7e7cae3fbdc4ea8a9d05b7a1c59f7b8
Author: Paolo Abeni <pabeni@redhat.com>
Date:   Fri Feb 12 15:43:57 2016 +0100

    net: add dst_cache to ovs vxlan lwtunnel
    
    In case of UDP traffic with datagram length
    below MTU this give about 2% performance increase
    when tunneling over ipv4 and about 60% when tunneling
    over ipv6
    
    Signed-off-by: Paolo Abeni <pabeni@redhat.com>
    Suggested-and-acked-by: Hannes Frederic Sowa <hannes@stressinduktion.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index a1656e3b8d72..b5cbbe07f786 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -265,7 +265,7 @@ struct dst_entry *dst_destroy(struct dst_entry * dst)
 	lwtstate_put(dst->lwtstate);
 
 	if (dst->flags & DST_METADATA)
-		kfree(dst);
+		metadata_dst_free((struct metadata_dst *)dst);
 	else
 		kmem_cache_free(dst->ops->kmem_cachep, dst);
 
@@ -395,6 +395,14 @@ struct metadata_dst *metadata_dst_alloc(u8 optslen, gfp_t flags)
 }
 EXPORT_SYMBOL_GPL(metadata_dst_alloc);
 
+void metadata_dst_free(struct metadata_dst *md_dst)
+{
+#ifdef CONFIG_DST_CACHE
+	dst_cache_destroy(&md_dst->u.tun_info.dst_cache);
+#endif
+	kfree(md_dst);
+}
+
 struct metadata_dst __percpu *metadata_dst_alloc_percpu(u8 optslen, gfp_t flags)
 {
 	int cpu;

commit 07a5d38453599052aff0877b16bb9c1585f08609
Author: Francesco Ruggeri <fruggeri@aristanetworks.com>
Date:   Wed Jan 6 00:18:48 2016 -0800

    net: possible use after free in dst_release
    
    dst_release should not access dst->flags after decrementing
    __refcnt to 0. The dst_entry may be in dst_busy_list and
    dst_gc_task may dst_destroy it before dst_release gets a chance
    to access dst->flags.
    
    Fixes: d69bbf88c8d0 ("net: fix a race in dst_release()")
    Fixes: 27b75c95f10d ("net: avoid RCU for NOCACHE dst")
    Signed-off-by: Francesco Ruggeri <fruggeri@arista.com>
    Acked-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index e6dc77252fe9..a1656e3b8d72 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -301,12 +301,13 @@ void dst_release(struct dst_entry *dst)
 {
 	if (dst) {
 		int newrefcnt;
+		unsigned short nocache = dst->flags & DST_NOCACHE;
 
 		newrefcnt = atomic_dec_return(&dst->__refcnt);
 		if (unlikely(newrefcnt < 0))
 			net_warn_ratelimited("%s: dst:%p refcnt:%d\n",
 					     __func__, dst, newrefcnt);
-		if (!newrefcnt && unlikely(dst->flags & DST_NOCACHE))
+		if (!newrefcnt && unlikely(nocache))
 			call_rcu(&dst->rcu_head, dst_destroy_rcu);
 	}
 }

commit d69bbf88c8d0b367cf3e3a052f6daadf630ee566
Author: Eric Dumazet <edumazet@google.com>
Date:   Mon Nov 9 17:51:23 2015 -0800

    net: fix a race in dst_release()
    
    Only cpu seeing dst refcount going to 0 can safely
    dereference dst->flags.
    
    Otherwise an other cpu might already have freed the dst.
    
    Fixes: 27b75c95f10d ("net: avoid RCU for NOCACHE dst")
    Reported-by: Greg Thelen <gthelen@google.com>
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index 2a1818065e12..e6dc77252fe9 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -306,7 +306,7 @@ void dst_release(struct dst_entry *dst)
 		if (unlikely(newrefcnt < 0))
 			net_warn_ratelimited("%s: dst:%p refcnt:%d\n",
 					     __func__, dst, newrefcnt);
-		if (unlikely(dst->flags & DST_NOCACHE) && !newrefcnt)
+		if (!newrefcnt && unlikely(dst->flags & DST_NOCACHE))
 			call_rcu(&dst->rcu_head, dst_destroy_rcu);
 	}
 }

commit ede2059dbaf9c6557a49d466c8c7778343b208ff
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Wed Oct 7 16:48:47 2015 -0500

    dst: Pass net into dst->output
    
    The network namespace is already passed into dst_output pass it into
    dst->output lwt->output and friends.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index 0771c8cb9307..2a1818065e12 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -144,12 +144,12 @@ static void dst_gc_task(struct work_struct *work)
 	mutex_unlock(&dst_gc_mutex);
 }
 
-int dst_discard_sk(struct sock *sk, struct sk_buff *skb)
+int dst_discard_out(struct net *net, struct sock *sk, struct sk_buff *skb)
 {
 	kfree_skb(skb);
 	return 0;
 }
-EXPORT_SYMBOL(dst_discard_sk);
+EXPORT_SYMBOL(dst_discard_out);
 
 const u32 dst_default_metrics[RTAX_MAX + 1] = {
 	/* This initializer is needed to force linker to place this variable
@@ -177,7 +177,7 @@ void dst_init(struct dst_entry *dst, struct dst_ops *ops,
 	dst->xfrm = NULL;
 #endif
 	dst->input = dst_discard;
-	dst->output = dst_discard_sk;
+	dst->output = dst_discard_out;
 	dst->error = 0;
 	dst->obsolete = initial_obsolete;
 	dst->header_len = 0;
@@ -224,7 +224,7 @@ static void ___dst_free(struct dst_entry *dst)
 	 */
 	if (dst->dev == NULL || !(dst->dev->flags&IFF_UP)) {
 		dst->input = dst_discard;
-		dst->output = dst_discard_sk;
+		dst->output = dst_discard_out;
 	}
 	dst->obsolete = DST_OBSOLETE_DEAD;
 }
@@ -352,7 +352,7 @@ static struct dst_ops md_dst_ops = {
 	.family =		AF_UNSPEC,
 };
 
-static int dst_md_discard_sk(struct sock *sk, struct sk_buff *skb)
+static int dst_md_discard_out(struct net *net, struct sock *sk, struct sk_buff *skb)
 {
 	WARN_ONCE(1, "Attempting to call output on metadata dst\n");
 	kfree_skb(skb);
@@ -375,7 +375,7 @@ static void __metadata_dst_init(struct metadata_dst *md_dst, u8 optslen)
 		 DST_METADATA | DST_NOCACHE | DST_NOCOUNT);
 
 	dst->input = dst_md_discard;
-	dst->output = dst_md_discard_sk;
+	dst->output = dst_md_discard_out;
 
 	memset(dst + 1, 0, sizeof(*md_dst) + optslen - sizeof(*dst));
 }
@@ -430,7 +430,7 @@ static void dst_ifdown(struct dst_entry *dst, struct net_device *dev,
 
 	if (!unregister) {
 		dst->input = dst_discard;
-		dst->output = dst_discard_sk;
+		dst->output = dst_discard_out;
 	} else {
 		dst->dev = dev_net(dst->dev)->loopback_dev;
 		dev_hold(dst->dev);

commit 63b6c13dbb7d3e36f031629f7e4e86dacfcab8cf
Author: Pravin B Shelar <pshelar@nicira.com>
Date:   Mon Aug 31 20:05:57 2015 -0700

    tun_dst: Remove opts_size
    
    opts_size is only written and never read. Following patch
    removes this unused variable.
    
    Signed-off-by: Pravin B Shelar <pshelar@nicira.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index 477035ed7903..0771c8cb9307 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -378,7 +378,6 @@ static void __metadata_dst_init(struct metadata_dst *md_dst, u8 optslen)
 	dst->output = dst_md_discard_sk;
 
 	memset(dst + 1, 0, sizeof(*md_dst) + optslen - sizeof(*dst));
-	md_dst->opts_len = optslen;
 }
 
 struct metadata_dst *metadata_dst_alloc(u8 optslen, gfp_t flags)

commit e252b3d1a1744af1431aca30e091420734c2b012
Author: WANG Cong <xiyou.wangcong@gmail.com>
Date:   Tue Aug 25 10:38:53 2015 -0700

    route: fix a use-after-free
    
    This patch fixes the following crash:
    
     general protection fault: 0000 [#1] SMP DEBUG_PAGEALLOC
     CPU: 1 PID: 0 Comm: swapper/1 Not tainted 4.2.0-rc7+ #166
     Hardware name: Bochs Bochs, BIOS Bochs 01/01/2011
     task: ffff88010656d280 ti: ffff880106570000 task.ti: ffff880106570000
     RIP: 0010:[<ffffffff8182f91b>]  [<ffffffff8182f91b>] dst_destroy+0xa6/0xef
     RSP: 0018:ffff880107603e38  EFLAGS: 00010202
     RAX: 0000000000000001 RBX: ffff8800d225a000 RCX: ffffffff82250fd0
     RDX: 0000000000000001 RSI: ffffffff82250fd0 RDI: 6b6b6b6b6b6b6b6b
     RBP: ffff880107603e58 R08: 0000000000000001 R09: 0000000000000001
     R10: 000000000000b530 R11: ffff880107609000 R12: 0000000000000000
     R13: ffffffff82343c40 R14: 0000000000000000 R15: ffffffff8182fb4f
     FS:  0000000000000000(0000) GS:ffff880107600000(0000) knlGS:0000000000000000
     CS:  0010 DS: 0000 ES: 0000 CR0: 000000008005003b
     CR2: 00007fcabd9d3000 CR3: 00000000d7279000 CR4: 00000000000006e0
     Stack:
      ffffffff82250fd0 ffff8801077d6f00 ffffffff82253c40 ffff8800d225a000
      ffff880107603e68 ffffffff8182fb5d ffff880107603f08 ffffffff810d795e
      ffffffff810d7648 ffff880106574000 ffff88010656d280 ffff88010656d280
     Call Trace:
      <IRQ>
      [<ffffffff8182fb5d>] dst_destroy_rcu+0xe/0x1d
      [<ffffffff810d795e>] rcu_process_callbacks+0x618/0x7eb
      [<ffffffff810d7648>] ? rcu_process_callbacks+0x302/0x7eb
      [<ffffffff8182fb4f>] ? dst_gc_task+0x1eb/0x1eb
      [<ffffffff8107e11b>] __do_softirq+0x178/0x39f
      [<ffffffff8107e52e>] irq_exit+0x41/0x95
      [<ffffffff81a4f215>] smp_apic_timer_interrupt+0x34/0x40
      [<ffffffff81a4d5cd>] apic_timer_interrupt+0x6d/0x80
      <EOI>
      [<ffffffff8100b968>] ? default_idle+0x21/0x32
      [<ffffffff8100b966>] ? default_idle+0x1f/0x32
      [<ffffffff8100bf19>] arch_cpu_idle+0xf/0x11
      [<ffffffff810b0bc7>] default_idle_call+0x1f/0x21
      [<ffffffff810b0dce>] cpu_startup_entry+0x1ad/0x273
      [<ffffffff8102fe67>] start_secondary+0x135/0x156
    
    dst is freed right before lwtstate_put(), this is not correct...
    
    Fixes: 61adedf3e3f1 ("route: move lwtunnel state to dst_entry")
    Acked-by: Jiri Benc <jbenc@redhat.com>
    Signed-off-by: Cong Wang <xiyou.wangcong@gmail.com>
    Signed-off-by: Cong Wang <cwang@twopensource.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index 50dcdbb0ee46..477035ed7903 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -262,11 +262,12 @@ struct dst_entry *dst_destroy(struct dst_entry * dst)
 	if (dst->dev)
 		dev_put(dst->dev);
 
+	lwtstate_put(dst->lwtstate);
+
 	if (dst->flags & DST_METADATA)
 		kfree(dst);
 	else
 		kmem_cache_free(dst->ops->kmem_cachep, dst);
-	lwtstate_put(dst->lwtstate);
 
 	dst = child;
 	if (dst) {

commit 61adedf3e3f1d3f032c5a6a299978d91eff6d555
Author: Jiri Benc <jbenc@redhat.com>
Date:   Thu Aug 20 13:56:25 2015 +0200

    route: move lwtunnel state to dst_entry
    
    Currently, the lwtunnel state resides in per-protocol data. This is
    a problem if we encapsulate ipv6 traffic in an ipv4 tunnel (or vice versa).
    The xmit function of the tunnel does not know whether the packet has been
    routed to it by ipv4 or ipv6, yet it needs the lwtstate data. Moving the
    lwtstate data to dst_entry makes such inter-protocol tunneling possible.
    
    As a bonus, this brings a nice diffstat.
    
    Signed-off-by: Jiri Benc <jbenc@redhat.com>
    Acked-by: Roopa Prabhu <roopa@cumulusnetworks.com>
    Acked-by: Thomas Graf <tgraf@suug.ch>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index f8694d1b8702..50dcdbb0ee46 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -20,6 +20,7 @@
 #include <net/net_namespace.h>
 #include <linux/sched.h>
 #include <linux/prefetch.h>
+#include <net/lwtunnel.h>
 
 #include <net/dst.h>
 #include <net/dst_metadata.h>
@@ -184,6 +185,7 @@ void dst_init(struct dst_entry *dst, struct dst_ops *ops,
 #ifdef CONFIG_IP_ROUTE_CLASSID
 	dst->tclassid = 0;
 #endif
+	dst->lwtstate = NULL;
 	atomic_set(&dst->__refcnt, initial_ref);
 	dst->__use = 0;
 	dst->lastuse = jiffies;
@@ -264,6 +266,7 @@ struct dst_entry *dst_destroy(struct dst_entry * dst)
 		kfree(dst);
 	else
 		kmem_cache_free(dst->ops->kmem_cachep, dst);
+	lwtstate_put(dst->lwtstate);
 
 	dst = child;
 	if (dst) {

commit d3aa45ce6b94c65b83971257317867db13e5f492
Author: Alexei Starovoitov <ast@plumgrid.com>
Date:   Thu Jul 30 15:36:57 2015 -0700

    bpf: add helpers to access tunnel metadata
    
    Introduce helpers to let eBPF programs attached to TC manipulate tunnel metadata:
    bpf_skb_[gs]et_tunnel_key(skb, key, size, flags)
    skb: pointer to skb
    key: pointer to 'struct bpf_tunnel_key'
    size: size of 'struct bpf_tunnel_key'
    flags: room for future extensions
    
    First eBPF program that uses these helpers will allocate per_cpu
    metadata_dst structures that will be used on TX.
    On RX metadata_dst is allocated by tunnel driver.
    
    Typical usage for TX:
    struct bpf_tunnel_key tkey;
    ... populate tkey ...
    bpf_skb_set_tunnel_key(skb, &tkey, sizeof(tkey), 0);
    bpf_clone_redirect(skb, vxlan_dev_ifindex, 0);
    
    RX:
    struct bpf_tunnel_key tkey = {};
    bpf_skb_get_tunnel_key(skb, &tkey, sizeof(tkey), 0);
    ... lookup or redirect based on tkey ...
    
    'struct bpf_tunnel_key' will be extended in the future by adding
    elements to the end and the 'size' argument will indicate which fields
    are populated, thereby keeping backwards compatibility.
    The 'flags' argument may be used as well when the 'size' is not enough or
    to indicate completely different layout of bpf_tunnel_key.
    
    Signed-off-by: Alexei Starovoitov <ast@plumgrid.com>
    Acked-by: Thomas Graf <tgraf@suug.ch>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index 76a617f6d60a..f8694d1b8702 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -362,15 +362,10 @@ static int dst_md_discard(struct sk_buff *skb)
 	return 0;
 }
 
-struct metadata_dst *metadata_dst_alloc(u8 optslen, gfp_t flags)
+static void __metadata_dst_init(struct metadata_dst *md_dst, u8 optslen)
 {
-	struct metadata_dst *md_dst;
 	struct dst_entry *dst;
 
-	md_dst = kmalloc(sizeof(*md_dst) + optslen, flags);
-	if (!md_dst)
-		return ERR_PTR(-ENOMEM);
-
 	dst = &md_dst->dst;
 	dst_init(dst, &md_dst_ops, NULL, 1, DST_OBSOLETE_NONE,
 		 DST_METADATA | DST_NOCACHE | DST_NOCOUNT);
@@ -380,11 +375,39 @@ struct metadata_dst *metadata_dst_alloc(u8 optslen, gfp_t flags)
 
 	memset(dst + 1, 0, sizeof(*md_dst) + optslen - sizeof(*dst));
 	md_dst->opts_len = optslen;
+}
+
+struct metadata_dst *metadata_dst_alloc(u8 optslen, gfp_t flags)
+{
+	struct metadata_dst *md_dst;
+
+	md_dst = kmalloc(sizeof(*md_dst) + optslen, flags);
+	if (!md_dst)
+		return NULL;
+
+	__metadata_dst_init(md_dst, optslen);
 
 	return md_dst;
 }
 EXPORT_SYMBOL_GPL(metadata_dst_alloc);
 
+struct metadata_dst __percpu *metadata_dst_alloc_percpu(u8 optslen, gfp_t flags)
+{
+	int cpu;
+	struct metadata_dst __percpu *md_dst;
+
+	md_dst = __alloc_percpu_gfp(sizeof(struct metadata_dst) + optslen,
+				    __alignof__(struct metadata_dst), flags);
+	if (!md_dst)
+		return NULL;
+
+	for_each_possible_cpu(cpu)
+		__metadata_dst_init(per_cpu_ptr(md_dst, cpu), optslen);
+
+	return md_dst;
+}
+EXPORT_SYMBOL_GPL(metadata_dst_alloc_percpu);
+
 /* Dirty hack. We did it in 2.2 (in __dst_free),
  * we have _very_ good reasons not to repeat
  * this mistake in 2.3, but we have no choice

commit c5e40ee287db61a79af1746954ee03ebbf1ff8a3
Merge: 052831879945 c5dfd654d0ec
Author: David S. Miller <davem@davemloft.net>
Date:   Thu Jul 23 00:41:16 2015 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/davem/net
    
    Conflicts:
            net/bridge/br_mdb.c
    
    br_mdb.c conflict was a function call being removed to fix a bug in
    'net' but whose signature was changed in 'net-next'.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit f38a9eb1f77b296ff07e000823884a0f64d67b2a
Author: Thomas Graf <tgraf@suug.ch>
Date:   Tue Jul 21 10:43:56 2015 +0200

    dst: Metadata destinations
    
    Introduces a new dst_metadata which enables to carry per packet metadata
    between forwarding and processing elements via the skb->dst pointer.
    
    The structure is set up to be a union. Thus, each separate type of
    metadata requires its own dst instance. If demand arises to carry
    multiple types of metadata concurrently, metadata dst entries can be
    made stackable.
    
    The metadata dst entry is refcnt'ed as expected for now but a non
    reference counted use is possible if the reference is forced before
    queueing the skb.
    
    In order to allow allocating dsts with variable length, the existing
    dst_alloc() is split into a dst_alloc() and dst_init() function. The
    existing dst_init() function to initialize the subsystem is being
    renamed to dst_subsys_init() to make it clear what is what.
    
    The check before ip_route_input() is changed to ignore metadata dsts
    and drop the dst inside the routing function thus allowing to interpret
    metadata in a later commit.
    
    Signed-off-by: Thomas Graf <tgraf@suug.ch>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index e956ce6d1378..917364f0d0be 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -22,6 +22,7 @@
 #include <linux/prefetch.h>
 
 #include <net/dst.h>
+#include <net/dst_metadata.h>
 
 /*
  * Theory of operations:
@@ -158,19 +159,10 @@ const u32 dst_default_metrics[RTAX_MAX + 1] = {
 	[RTAX_MAX] = 0xdeadbeef,
 };
 
-
-void *dst_alloc(struct dst_ops *ops, struct net_device *dev,
-		int initial_ref, int initial_obsolete, unsigned short flags)
+void dst_init(struct dst_entry *dst, struct dst_ops *ops,
+	      struct net_device *dev, int initial_ref, int initial_obsolete,
+	      unsigned short flags)
 {
-	struct dst_entry *dst;
-
-	if (ops->gc && dst_entries_get_fast(ops) > ops->gc_thresh) {
-		if (ops->gc(ops))
-			return NULL;
-	}
-	dst = kmem_cache_alloc(ops->kmem_cachep, GFP_ATOMIC);
-	if (!dst)
-		return NULL;
 	dst->child = NULL;
 	dst->dev = dev;
 	if (dev)
@@ -200,6 +192,25 @@ void *dst_alloc(struct dst_ops *ops, struct net_device *dev,
 	dst->next = NULL;
 	if (!(flags & DST_NOCOUNT))
 		dst_entries_add(ops, 1);
+}
+EXPORT_SYMBOL(dst_init);
+
+void *dst_alloc(struct dst_ops *ops, struct net_device *dev,
+		int initial_ref, int initial_obsolete, unsigned short flags)
+{
+	struct dst_entry *dst;
+
+	if (ops->gc && dst_entries_get_fast(ops) > ops->gc_thresh) {
+		if (ops->gc(ops))
+			return NULL;
+	}
+
+	dst = kmem_cache_alloc(ops->kmem_cachep, GFP_ATOMIC);
+	if (!dst)
+		return NULL;
+
+	dst_init(dst, ops, dev, initial_ref, initial_obsolete, flags);
+
 	return dst;
 }
 EXPORT_SYMBOL(dst_alloc);
@@ -248,7 +259,11 @@ struct dst_entry *dst_destroy(struct dst_entry * dst)
 		dst->ops->destroy(dst);
 	if (dst->dev)
 		dev_put(dst->dev);
-	kmem_cache_free(dst->ops->kmem_cachep, dst);
+
+	if (dst->flags & DST_METADATA)
+		kfree(dst);
+	else
+		kmem_cache_free(dst->ops->kmem_cachep, dst);
 
 	dst = child;
 	if (dst) {
@@ -327,6 +342,47 @@ void __dst_destroy_metrics_generic(struct dst_entry *dst, unsigned long old)
 }
 EXPORT_SYMBOL(__dst_destroy_metrics_generic);
 
+static struct dst_ops md_dst_ops = {
+	.family =		AF_UNSPEC,
+};
+
+static int dst_md_discard_sk(struct sock *sk, struct sk_buff *skb)
+{
+	WARN_ONCE(1, "Attempting to call output on metadata dst\n");
+	kfree_skb(skb);
+	return 0;
+}
+
+static int dst_md_discard(struct sk_buff *skb)
+{
+	WARN_ONCE(1, "Attempting to call input on metadata dst\n");
+	kfree_skb(skb);
+	return 0;
+}
+
+struct metadata_dst *metadata_dst_alloc(u8 optslen, gfp_t flags)
+{
+	struct metadata_dst *md_dst;
+	struct dst_entry *dst;
+
+	md_dst = kmalloc(sizeof(*md_dst) + optslen, flags);
+	if (!md_dst)
+		return ERR_PTR(-ENOMEM);
+
+	dst = &md_dst->dst;
+	dst_init(dst, &md_dst_ops, NULL, 1, DST_OBSOLETE_NONE,
+		 DST_METADATA | DST_NOCACHE | DST_NOCOUNT);
+
+	dst->input = dst_md_discard;
+	dst->output = dst_md_discard_sk;
+
+	memset(dst + 1, 0, sizeof(*md_dst) + optslen - sizeof(*dst));
+	md_dst->opts_len = optslen;
+
+	return md_dst;
+}
+EXPORT_SYMBOL_GPL(metadata_dst_alloc);
+
 /* Dirty hack. We did it in 2.2 (in __dst_free),
  * we have _very_ good reasons not to repeat
  * this mistake in 2.3, but we have no choice
@@ -391,7 +447,7 @@ static struct notifier_block dst_dev_notifier = {
 	.priority = -10, /* must be called after other network notifiers */
 };
 
-void __init dst_init(void)
+void __init dst_subsys_init(void)
 {
 	register_netdevice_notifier(&dst_dev_notifier);
 }

commit 8bf4ada2e21378816b28205427ee6b0e1ca4c5f1
Author: Konstantin Khlebnikov <khlebnikov@yandex-team.ru>
Date:   Fri Jul 17 14:01:11 2015 +0300

    net: ratelimit warnings about dst entry refcount underflow or overflow
    
    Kernel generates a lot of warnings when dst entry reference counter
    overflows and becomes negative. That bug was seen several times at
    machines with outdated 3.10.y kernels. Most like it's already fixed
    in upstream. Anyway that flood completely kills machine and makes
    further debugging impossible.
    
    Signed-off-by: Konstantin Khlebnikov <khlebnikov@yandex-team.ru>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index e956ce6d1378..002144bea935 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -284,7 +284,9 @@ void dst_release(struct dst_entry *dst)
 		int newrefcnt;
 
 		newrefcnt = atomic_dec_return(&dst->__refcnt);
-		WARN_ON(newrefcnt < 0);
+		if (unlikely(newrefcnt < 0))
+			net_warn_ratelimited("%s: dst:%p refcnt:%d\n",
+					     __func__, dst, newrefcnt);
 		if (unlikely(dst->flags & DST_NOCACHE) && !newrefcnt)
 			call_rcu(&dst->rcu_head, dst_destroy_rcu);
 	}

commit dbfc4fb7d578d4f224faa6b60deb40804dfdc1b1
Author: Hannes Frederic Sowa <hannes@stressinduktion.org>
Date:   Sat Dec 6 19:19:42 2014 +0100

    dst: no need to take reference on DST_NOCACHE dsts
    
    Since commit f8864972126899 ("ipv4: fix dst race in sk_dst_get()")
    DST_NOCACHE dst_entries get freed by RCU. So there is no need to get a
    reference on them when we are in rcu protected sections.
    
    Cc: Eric Dumazet <edumazet@google.com>
    Cc: Julian Anastasov <ja@ssi.bg>
    Signed-off-by: Hannes Frederic Sowa <hannes@stressinduktion.org>
    Reviewed-by: Julian Anastasov <ja@ssi.bg>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index a028409ee438..e956ce6d1378 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -327,30 +327,6 @@ void __dst_destroy_metrics_generic(struct dst_entry *dst, unsigned long old)
 }
 EXPORT_SYMBOL(__dst_destroy_metrics_generic);
 
-/**
- * __skb_dst_set_noref - sets skb dst, without a reference
- * @skb: buffer
- * @dst: dst entry
- * @force: if force is set, use noref version even for DST_NOCACHE entries
- *
- * Sets skb dst, assuming a reference was not taken on dst
- * skb_dst_drop() should not dst_release() this dst
- */
-void __skb_dst_set_noref(struct sk_buff *skb, struct dst_entry *dst, bool force)
-{
-	WARN_ON(!rcu_read_lock_held() && !rcu_read_lock_bh_held());
-	/* If dst not in cache, we must take a reference, because
-	 * dst_release() will destroy dst as soon as its refcount becomes zero
-	 */
-	if (unlikely((dst->flags & DST_NOCACHE) && !force)) {
-		dst_hold(dst);
-		skb_dst_set(skb, dst);
-	} else {
-		skb->_skb_refdst = (unsigned long)dst | SKB_DST_NOREF;
-	}
-}
-EXPORT_SYMBOL(__skb_dst_set_noref);
-
 /* Dirty hack. We did it in 2.2 (in __dst_free),
  * we have _very_ good reasons not to repeat
  * this mistake in 2.3, but we have no choice

commit f88649721268999bdff09777847080a52004f691
Author: Eric Dumazet <edumazet@google.com>
Date:   Tue Jun 24 10:05:11 2014 -0700

    ipv4: fix dst race in sk_dst_get()
    
    When IP route cache had been removed in linux-3.6, we broke assumption
    that dst entries were all freed after rcu grace period. DST_NOCACHE
    dst were supposed to be freed from dst_release(). But it appears
    we want to keep such dst around, either in UDP sockets or tunnels.
    
    In sk_dst_get() we need to make sure dst refcount is not 0
    before incrementing it, or else we might end up freeing a dst
    twice.
    
    DST_NOCACHE set on a dst does not mean this dst can not be attached
    to a socket or a tunnel.
    
    Then, before actual freeing, we need to observe a rcu grace period
    to make sure all other cpus can catch the fact the dst is no longer
    usable.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: Dormando <dormando@rydia.net>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index 80d6286c8b62..a028409ee438 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -269,6 +269,15 @@ struct dst_entry *dst_destroy(struct dst_entry * dst)
 }
 EXPORT_SYMBOL(dst_destroy);
 
+static void dst_destroy_rcu(struct rcu_head *head)
+{
+	struct dst_entry *dst = container_of(head, struct dst_entry, rcu_head);
+
+	dst = dst_destroy(dst);
+	if (dst)
+		__dst_free(dst);
+}
+
 void dst_release(struct dst_entry *dst)
 {
 	if (dst) {
@@ -276,11 +285,8 @@ void dst_release(struct dst_entry *dst)
 
 		newrefcnt = atomic_dec_return(&dst->__refcnt);
 		WARN_ON(newrefcnt < 0);
-		if (unlikely(dst->flags & DST_NOCACHE) && !newrefcnt) {
-			dst = dst_destroy(dst);
-			if (dst)
-				__dst_free(dst);
-		}
+		if (unlikely(dst->flags & DST_NOCACHE) && !newrefcnt)
+			call_rcu(&dst->rcu_head, dst_destroy_rcu);
 	}
 }
 EXPORT_SYMBOL(dst_release);

commit aad88724c9d54acb1a9737cb6069d8470fa85f74
Author: Eric Dumazet <edumazet@google.com>
Date:   Tue Apr 15 13:47:15 2014 -0400

    ipv4: add a sock pointer to dst->output() path.
    
    In the dst->output() path for ipv4, the code assumes the skb it has to
    transmit is attached to an inet socket, specifically via
    ip_mc_output() : The sk_mc_loop() test triggers a WARN_ON() when the
    provider of the packet is an AF_PACKET socket.
    
    The dst->output() method gets an additional 'struct sock *sk'
    parameter. This needs a cascade of changes so that this parameter can
    be propagated from vxlan to final consumer.
    
    Fixes: 8f646c922d55 ("vxlan: keep original skb ownership")
    Reported-by: lucien xin <lucien.xin@gmail.com>
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index ca4231ec7347..80d6286c8b62 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -142,12 +142,12 @@ static void dst_gc_task(struct work_struct *work)
 	mutex_unlock(&dst_gc_mutex);
 }
 
-int dst_discard(struct sk_buff *skb)
+int dst_discard_sk(struct sock *sk, struct sk_buff *skb)
 {
 	kfree_skb(skb);
 	return 0;
 }
-EXPORT_SYMBOL(dst_discard);
+EXPORT_SYMBOL(dst_discard_sk);
 
 const u32 dst_default_metrics[RTAX_MAX + 1] = {
 	/* This initializer is needed to force linker to place this variable
@@ -184,7 +184,7 @@ void *dst_alloc(struct dst_ops *ops, struct net_device *dev,
 	dst->xfrm = NULL;
 #endif
 	dst->input = dst_discard;
-	dst->output = dst_discard;
+	dst->output = dst_discard_sk;
 	dst->error = 0;
 	dst->obsolete = initial_obsolete;
 	dst->header_len = 0;
@@ -209,8 +209,10 @@ static void ___dst_free(struct dst_entry *dst)
 	/* The first case (dev==NULL) is required, when
 	   protocol module is unloaded.
 	 */
-	if (dst->dev == NULL || !(dst->dev->flags&IFF_UP))
-		dst->input = dst->output = dst_discard;
+	if (dst->dev == NULL || !(dst->dev->flags&IFF_UP)) {
+		dst->input = dst_discard;
+		dst->output = dst_discard_sk;
+	}
 	dst->obsolete = DST_OBSOLETE_DEAD;
 }
 
@@ -361,7 +363,8 @@ static void dst_ifdown(struct dst_entry *dst, struct net_device *dev,
 		return;
 
 	if (!unregister) {
-		dst->input = dst->output = dst_discard;
+		dst->input = dst_discard;
+		dst->output = dst_discard_sk;
 	} else {
 		dst->dev = dev_net(dst->dev)->loopback_dev;
 		dev_hold(dst->dev);

commit 351638e7deeed2ec8ce451b53d33921b3da68f83
Author: Jiri Pirko <jiri@resnulli.us>
Date:   Tue May 28 01:30:21 2013 +0000

    net: pass info struct via netdevice notifier
    
    So far, only net_device * could be passed along with netdevice notifier
    event. This patch provides a possibility to pass custom structure
    able to provide info that event listener needs to know.
    
    Signed-off-by: Jiri Pirko <jiri@resnulli.us>
    
    v2->v3: fix typo on simeth
            shortened dev_getter
            shortened notifier_info struct name
    v1->v2: fix notifier_call parameter in call_netdevice_notifier()
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index df9cc810ec8e..ca4231ec7347 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -372,7 +372,7 @@ static void dst_ifdown(struct dst_entry *dst, struct net_device *dev,
 static int dst_dev_event(struct notifier_block *this, unsigned long event,
 			 void *ptr)
 {
-	struct net_device *dev = ptr;
+	struct net_device *dev = netdev_notifier_info_to_dev(ptr);
 	struct dst_entry *dst, *last = NULL;
 
 	switch (event) {

commit 932bc4d7a53ba418de67fdab533248df5b36c752
Author: Julian Anastasov <ja@ssi.bg>
Date:   Thu Mar 21 11:57:58 2013 +0200

    net: add skb_dst_set_noref_force
    
    Rename skb_dst_set_noref to __skb_dst_set_noref and
    add force flag as suggested by David Miller. The new wrapper
    skb_dst_set_noref_force will force dst entries that are not
    cached to be attached as skb dst without taking reference
    as long as provided dst is reclaimed after RCU grace period.
    
    Signed-off-by: Julian Anastasov <ja@ssi.bg>
    Signed-off by: Hans Schillstrom <hans@schillstrom.com>
    Acked-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Simon Horman <horms@verge.net.au>

diff --git a/net/core/dst.c b/net/core/dst.c
index 35fd12f1a69c..df9cc810ec8e 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -320,27 +320,28 @@ void __dst_destroy_metrics_generic(struct dst_entry *dst, unsigned long old)
 EXPORT_SYMBOL(__dst_destroy_metrics_generic);
 
 /**
- * skb_dst_set_noref - sets skb dst, without a reference
+ * __skb_dst_set_noref - sets skb dst, without a reference
  * @skb: buffer
  * @dst: dst entry
+ * @force: if force is set, use noref version even for DST_NOCACHE entries
  *
  * Sets skb dst, assuming a reference was not taken on dst
  * skb_dst_drop() should not dst_release() this dst
  */
-void skb_dst_set_noref(struct sk_buff *skb, struct dst_entry *dst)
+void __skb_dst_set_noref(struct sk_buff *skb, struct dst_entry *dst, bool force)
 {
 	WARN_ON(!rcu_read_lock_held() && !rcu_read_lock_bh_held());
 	/* If dst not in cache, we must take a reference, because
 	 * dst_release() will destroy dst as soon as its refcount becomes zero
 	 */
-	if (unlikely(dst->flags & DST_NOCACHE)) {
+	if (unlikely((dst->flags & DST_NOCACHE) && !force)) {
 		dst_hold(dst);
 		skb_dst_set(skb, dst);
 	} else {
 		skb->_skb_refdst = (unsigned long)dst | SKB_DST_NOREF;
 	}
 }
-EXPORT_SYMBOL(skb_dst_set_noref);
+EXPORT_SYMBOL(__skb_dst_set_noref);
 
 /* Dirty hack. We did it in 2.2 (in __dst_free),
  * we have _very_ good reasons not to repeat

commit ecd9883724b78cc72ed92c98bcb1a46c764fff21
Author: YOSHIFUJI Hideaki /  <yoshfuji@linux-ipv6.org>
Date:   Wed Feb 20 00:29:08 2013 +0000

    ipv6: fix race condition regarding dst->expires and dst->from.
    
    Eric Dumazet wrote:
    | Some strange crashes happen in rt6_check_expired(), with access
    | to random addresses.
    |
    | At first glance, it looks like the RTF_EXPIRES and
    | stuff added in commit 1716a96101c49186b
    | (ipv6: fix problem with expired dst cache)
    | are racy : same dst could be manipulated at the same time
    | on different cpus.
    |
    | At some point, our stack believes rt->dst.from contains a dst pointer,
    | while its really a jiffie value (as rt->dst.expires shares the same area
    | of memory)
    |
    | rt6_update_expires() should be fixed, or am I missing something ?
    |
    | CC Neil because of https://bugzilla.redhat.com/show_bug.cgi?id=892060
    
    Because we do not have any locks for dst_entry, we cannot change
    essential structure in the entry; e.g., we cannot change reference
    to other entity.
    
    To fix this issue, split 'from' and 'expires' field in dst_entry
    out of union.  Once it is 'from' is assigned in the constructor,
    keep the reference until the very last stage of the life time of
    the object.
    
    Of course, it is unsafe to change 'from', so make rt6_set_from simple
    just for fresh entries.
    
    Reported-by: Eric Dumazet <eric.dumazet@gmail.com>
    Reported-by: Neil Horman <nhorman@tuxdriver.com>
    CC: Gao Feng <gaofeng@cn.fujitsu.com>
    Signed-off-by: YOSHIFUJI Hideaki <yoshfuji@linux-ipv6.org>
    Reviewed-by: Eric Dumazet <edumazet@google.com>
    Reported-by: Steinar H. Gunderson <sesse@google.com>
    Reviewed-by: Neil Horman <nhorman@tuxdriver.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index ee6153e2cf43..35fd12f1a69c 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -179,6 +179,7 @@ void *dst_alloc(struct dst_ops *ops, struct net_device *dev,
 	dst_init_metrics(dst, dst_default_metrics, true);
 	dst->expires = 0UL;
 	dst->path = dst;
+	dst->from = NULL;
 #ifdef CONFIG_XFRM
 	dst->xfrm = NULL;
 #endif

commit aecdc33e111b2c447b622e287c6003726daa1426
Merge: a20acf99f75e a3a6cab5ea10
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Oct 2 13:38:27 2012 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/davem/net-next
    
    Pull networking changes from David Miller:
    
     1) GRE now works over ipv6, from Dmitry Kozlov.
    
     2) Make SCTP more network namespace aware, from Eric Biederman.
    
     3) TEAM driver now works with non-ethernet devices, from Jiri Pirko.
    
     4) Make openvswitch network namespace aware, from Pravin B Shelar.
    
     5) IPV6 NAT implementation, from Patrick McHardy.
    
     6) Server side support for TCP Fast Open, from Jerry Chu and others.
    
     7) Packet BPF filter supports MOD and XOR, from Eric Dumazet and Daniel
        Borkmann.
    
     8) Increate the loopback default MTU to 64K, from Eric Dumazet.
    
     9) Use a per-task rather than per-socket page fragment allocator for
        outgoing networking traffic.  This benefits processes that have very
        many mostly idle sockets, which is quite common.
    
        From Eric Dumazet.
    
    10) Use up to 32K for page fragment allocations, with fallbacks to
        smaller sizes when higher order page allocations fail.  Benefits are
        a) less segments for driver to process b) less calls to page
        allocator c) less waste of space.
    
        From Eric Dumazet.
    
    11) Allow GRO to be used on GRE tunnels, from Eric Dumazet.
    
    12) VXLAN device driver, one way to handle VLAN issues such as the
        limitation of 4096 VLAN IDs yet still have some level of isolation.
        From Stephen Hemminger.
    
    13) As usual there is a large boatload of driver changes, with the scale
        perhaps tilted towards the wireless side this time around.
    
    Fix up various fairly trivial conflicts, mostly caused by the user
    namespace changes.
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/davem/net-next: (1012 commits)
      hyperv: Add buffer for extended info after the RNDIS response message.
      hyperv: Report actual status in receive completion packet
      hyperv: Remove extra allocated space for recv_pkt_list elements
      hyperv: Fix page buffer handling in rndis_filter_send_request()
      hyperv: Fix the missing return value in rndis_filter_set_packet_filter()
      hyperv: Fix the max_xfer_size in RNDIS initialization
      vxlan: put UDP socket in correct namespace
      vxlan: Depend on CONFIG_INET
      sfc: Fix the reported priorities of different filter types
      sfc: Remove EFX_FILTER_FLAG_RX_OVERRIDE_IP
      sfc: Fix loopback self-test with separate_tx_channels=1
      sfc: Fix MCDI structure field lookup
      sfc: Add parentheses around use of bitfield macro arguments
      sfc: Fix null function pointer in efx_sriov_channel_type
      vxlan: virtual extensible lan
      igmp: export symbol ip_mc_leave_group
      netlink: add attributes to fdb interface
      tg3: unconditionally select HWMON support when tg3 is enabled.
      Revert "net: ti cpsw ethernet: allow reading phy interface mode from DT"
      gre: fix sparse warning
      ...

commit 033d9959ed2dc1029217d4165f80a71702dc578e
Merge: 974a847e00cf 7c6e72e46c9e
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Oct 2 09:54:49 2012 -0700

    Merge branch 'for-3.7' of git://git.kernel.org/pub/scm/linux/kernel/git/tj/wq
    
    Pull workqueue changes from Tejun Heo:
     "This is workqueue updates for v3.7-rc1.  A lot of activities this
      round including considerable API and behavior cleanups.
    
       * delayed_work combines a timer and a work item.  The handling of the
         timer part has always been a bit clunky leading to confusing
         cancelation API with weird corner-case behaviors.  delayed_work is
         updated to use new IRQ safe timer and cancelation now works as
         expected.
    
       * Another deficiency of delayed_work was lack of the counterpart of
         mod_timer() which led to cancel+queue combinations or open-coded
         timer+work usages.  mod_delayed_work[_on]() are added.
    
         These two delayed_work changes make delayed_work provide interface
         and behave like timer which is executed with process context.
    
       * A work item could be executed concurrently on multiple CPUs, which
         is rather unintuitive and made flush_work() behavior confusing and
         half-broken under certain circumstances.  This problem doesn't
         exist for non-reentrant workqueues.  While non-reentrancy check
         isn't free, the overhead is incurred only when a work item bounces
         across different CPUs and even in simulated pathological scenario
         the overhead isn't too high.
    
         All workqueues are made non-reentrant.  This removes the
         distinction between flush_[delayed_]work() and
         flush_[delayed_]_work_sync().  The former is now as strong as the
         latter and the specified work item is guaranteed to have finished
         execution of any previous queueing on return.
    
       * In addition to the various bug fixes, Lai redid and simplified CPU
         hotplug handling significantly.
    
       * Joonsoo introduced system_highpri_wq and used it during CPU
         hotplug.
    
      There are two merge commits - one to pull in IRQ safe timer from
      tip/timers/core and the other to pull in CPU hotplug fixes from
      wq/for-3.6-fixes as Lai's hotplug restructuring depended on them."
    
    Fixed a number of trivial conflicts, but the more interesting conflicts
    were silent ones where the deprecated interfaces had been used by new
    code in the merge window, and thus didn't cause any real data conflicts.
    
    Tejun pointed out a few of them, I fixed a couple more.
    
    * 'for-3.7' of git://git.kernel.org/pub/scm/linux/kernel/git/tj/wq: (46 commits)
      workqueue: remove spurious WARN_ON_ONCE(in_irq()) from try_to_grab_pending()
      workqueue: use cwq_set_max_active() helper for workqueue_set_max_active()
      workqueue: introduce cwq_set_max_active() helper for thaw_workqueues()
      workqueue: remove @delayed from cwq_dec_nr_in_flight()
      workqueue: fix possible stall on try_to_grab_pending() of a delayed work item
      workqueue: use hotcpu_notifier() for workqueue_cpu_down_callback()
      workqueue: use __cpuinit instead of __devinit for cpu callbacks
      workqueue: rename manager_mutex to assoc_mutex
      workqueue: WORKER_REBIND is no longer necessary for idle rebinding
      workqueue: WORKER_REBIND is no longer necessary for busy rebinding
      workqueue: reimplement idle worker rebinding
      workqueue: deprecate __cancel_delayed_work()
      workqueue: reimplement cancel_delayed_work() using try_to_grab_pending()
      workqueue: use mod_delayed_work() instead of __cancel + queue
      workqueue: use irqsafe timer for delayed_work
      workqueue: clean up delayed_work initializers and add missing one
      workqueue: make deferrable delayed_work initializer names consistent
      workqueue: cosmetic whitespace updates for macro definitions
      workqueue: deprecate system_nrt[_freezable]_wq
      workqueue: deprecate flush[_delayed]_work_sync()
      ...

commit 0115e8e30d6fcdd4b8faa30d3ffd90859a591f51
Author: Eric Dumazet <edumazet@google.com>
Date:   Wed Aug 22 17:19:46 2012 +0000

    net: remove delay at device dismantle
    
    I noticed extra one second delay in device dismantle, tracked down to
    a call to dst_dev_event() while some call_rcu() are still in RCU queues.
    
    These call_rcu() were posted by rt_free(struct rtable *rt) calls.
    
    We then wait a little (but one second) in netdev_wait_allrefs() before
    kicking again NETDEV_UNREGISTER.
    
    As the call_rcu() are now completed, dst_dev_event() can do the needed
    device swap on busy dst.
    
    To solve this problem, add a new NETDEV_UNREGISTER_FINAL, called
    after a rcu_barrier(), but outside of RTNL lock.
    
    Use NETDEV_UNREGISTER_FINAL with care !
    
    Change dst_dev_event() handler to react to NETDEV_UNREGISTER_FINAL
    
    Also remove NETDEV_UNREGISTER_BATCH, as its not used anymore after
    IP cache removal.
    
    With help from Gao feng
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Cc: Tom Herbert <therbert@google.com>
    Cc: Mahesh Bandewar <maheshb@google.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Gao feng <gaofeng@cn.fujitsu.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index 56d63612e1e4..f6593d238e9a 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -374,7 +374,7 @@ static int dst_dev_event(struct notifier_block *this, unsigned long event,
 	struct dst_entry *dst, *last = NULL;
 
 	switch (event) {
-	case NETDEV_UNREGISTER:
+	case NETDEV_UNREGISTER_FINAL:
 	case NETDEV_DOWN:
 		mutex_lock(&dst_gc_mutex);
 		for (dst = dst_busy_list; dst; dst = dst->next) {

commit 41f63c5359d14ca995172b8f6eaffd93f60fec54
Author: Tejun Heo <tj@kernel.org>
Date:   Fri Aug 3 10:30:47 2012 -0700

    workqueue: use mod_delayed_work() instead of cancel + queue
    
    Convert delayed_work users doing cancel_delayed_work() followed by
    queue_delayed_work() to mod_delayed_work().
    
    Most conversions are straight-forward.  Ones worth mentioning are,
    
    * drivers/edac/edac_mc.c: edac_mc_workq_setup() converted to always
      use mod_delayed_work() and cancel loop in
      edac_mc_reset_delay_period() is dropped.
    
    * drivers/platform/x86/thinkpad_acpi.c: No need to remember whether
      watchdog is active or not.  @fan_watchdog_active and related code
      dropped.
    
    * drivers/power/charger-manager.c: Seemingly a lot of
      delayed_work_pending() abuse going on here.
      [delayed_]work_pending() are unsynchronized and racy when used like
      this.  I converted one instance in fullbatt_handler().  Please
      conver the rest so that it invokes workqueue APIs for the intended
      target state rather than trying to game work item pending state
      transitions.  e.g. if timer should be modified - call
      mod_delayed_work(), canceled - call cancel_delayed_work[_sync]().
    
    * drivers/thermal/thermal_sys.c: thermal_zone_device_set_polling()
      simplified.  Note that round_jiffies() calls in this function are
      meaningless.  round_jiffies() work on absolute jiffies not delta
      delay used by delayed_work.
    
    v2: Tomi pointed out that __cancel_delayed_work() users can't be
        safely converted to mod_delayed_work().  They could be calling it
        from irq context and if that happens while delayed_work_timer_fn()
        is running, it could deadlock.  __cancel_delayed_work() users are
        dropped.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Henrique de Moraes Holschuh <hmh@hmh.eng.br>
    Acked-by: Dmitry Torokhov <dmitry.torokhov@gmail.com>
    Acked-by: Anton Vorontsov <cbouatmailru@gmail.com>
    Acked-by: David Howells <dhowells@redhat.com>
    Cc: Tomi Valkeinen <tomi.valkeinen@ti.com>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Jiri Kosina <jkosina@suse.cz>
    Cc: Doug Thompson <dougthompson@xmission.com>
    Cc: David Airlie <airlied@linux.ie>
    Cc: Roland Dreier <roland@kernel.org>
    Cc: "John W. Linville" <linville@tuxdriver.com>
    Cc: Zhang Rui <rui.zhang@intel.com>
    Cc: Len Brown <len.brown@intel.com>
    Cc: "J. Bruce Fields" <bfields@fieldses.org>
    Cc: Johannes Berg <johannes@sipsolutions.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index 069d51d29414..ed5a0b409aa3 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -214,8 +214,8 @@ void __dst_free(struct dst_entry *dst)
 	if (dst_garbage.timer_inc > DST_GC_INC) {
 		dst_garbage.timer_inc = DST_GC_INC;
 		dst_garbage.timer_expires = DST_GC_MIN;
-		cancel_delayed_work(&dst_gc_work);
-		schedule_delayed_work(&dst_gc_work, dst_garbage.timer_expires);
+		mod_delayed_work(system_wq, &dst_gc_work,
+				 dst_garbage.timer_expires);
 	}
 	spin_unlock_bh(&dst_garbage.lock);
 }

commit a37e6e344910a43b9ebc2bbf29a029f5ea942598
Author: Eric Dumazet <edumazet@google.com>
Date:   Tue Aug 7 10:55:45 2012 +0000

    net: force dst_default_metrics to const section
    
    While investigating on network performance problems, I found this little
    gem :
    
    $ nm -v vmlinux | grep -1 dst_default_metrics
    ffffffff82736540 b busy.46605
    ffffffff82736560 B dst_default_metrics
    ffffffff82736598 b dst_busy_list
    
    Apparently, declaring a const array without initializer put it in
    (writeable) bss section, in middle of possibly often dirtied cache
    lines.
    
    Since we really want dst_default_metrics be const to avoid any possible
    false sharing and catch any buggy writes, I force a null initializer.
    
    ffffffff818a4c20 R dst_default_metrics
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Cc: Ben Hutchings <bhutchings@solarflare.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index 069d51d29414..56d63612e1e4 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -149,7 +149,15 @@ int dst_discard(struct sk_buff *skb)
 }
 EXPORT_SYMBOL(dst_discard);
 
-const u32 dst_default_metrics[RTAX_MAX];
+const u32 dst_default_metrics[RTAX_MAX + 1] = {
+	/* This initializer is needed to force linker to place this variable
+	 * into const section. Otherwise it might end into bss section.
+	 * We really want to avoid false sharing on this variable, and catch
+	 * any writes on it.
+	 */
+	[RTAX_MAX] = 0xdeadbeef,
+};
+
 
 void *dst_alloc(struct dst_ops *ops, struct net_device *dev,
 		int initial_ref, int initial_obsolete, unsigned short flags)

commit f5b0a8743601a4477419171f5046bd07d1c080a0
Author: David S. Miller <davem@davemloft.net>
Date:   Thu Jul 19 12:31:33 2012 -0700

    net: Document dst->obsolete better.
    
    Add a big comment explaining how the field works, and use defines
    instead of magic constants for the values assigned to it.
    
    Suggested by Joe Perches.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index 07bacff84aa4..069d51d29414 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -94,7 +94,7 @@ static void dst_gc_task(struct work_struct *work)
 			 * But we do not have state "obsoleted, but
 			 * referenced by parent", so it is right.
 			 */
-			if (dst->obsolete > 1)
+			if (dst->obsolete > 0)
 				continue;
 
 			___dst_free(dst);
@@ -202,7 +202,7 @@ static void ___dst_free(struct dst_entry *dst)
 	 */
 	if (dst->dev == NULL || !(dst->dev->flags&IFF_UP))
 		dst->input = dst->output = dst_discard;
-	dst->obsolete = 2;
+	dst->obsolete = DST_OBSOLETE_DEAD;
 }
 
 void __dst_free(struct dst_entry *dst)

commit 36bdbcae2fa2a6dfa99344d4190fcea0aa7b7c25
Author: David S. Miller <davem@davemloft.net>
Date:   Mon Jul 2 22:58:02 2012 -0700

    net: Kill dst->_neighbour, accessors, and final uses.
    
    No longer used.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index a6e19a23a745..07bacff84aa4 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -171,7 +171,6 @@ void *dst_alloc(struct dst_ops *ops, struct net_device *dev,
 	dst_init_metrics(dst, dst_default_metrics, true);
 	dst->expires = 0UL;
 	dst->path = dst;
-	RCU_INIT_POINTER(dst->_neighbour, NULL);
 #ifdef CONFIG_XFRM
 	dst->xfrm = NULL;
 #endif
@@ -225,19 +224,12 @@ EXPORT_SYMBOL(__dst_free);
 struct dst_entry *dst_destroy(struct dst_entry * dst)
 {
 	struct dst_entry *child;
-	struct neighbour *neigh;
 
 	smp_rmb();
 
 again:
-	neigh = rcu_dereference_protected(dst->_neighbour, 1);
 	child = dst->child;
 
-	if (neigh) {
-		RCU_INIT_POINTER(dst->_neighbour, NULL);
-		neigh_release(neigh);
-	}
-
 	if (!(dst->flags & DST_NOCOUNT))
 		dst_entries_add(dst->ops, -1);
 
@@ -361,19 +353,9 @@ static void dst_ifdown(struct dst_entry *dst, struct net_device *dev,
 	if (!unregister) {
 		dst->input = dst->output = dst_discard;
 	} else {
-		struct neighbour *neigh;
-
 		dst->dev = dev_net(dst->dev)->loopback_dev;
 		dev_hold(dst->dev);
 		dev_put(dev);
-		rcu_read_lock();
-		neigh = dst_get_neighbour_noref(dst);
-		if (neigh && neigh->dev == dev) {
-			neigh->dev = dst->dev;
-			dev_hold(dst->dev);
-			dev_put(dev);
-		}
-		rcu_read_unlock();
 	}
 }
 

commit 5110effee8fde2edfacac9cd12a9960ab2dc39ea
Author: David S. Miller <davem@davemloft.net>
Date:   Mon Jul 2 02:21:03 2012 -0700

    net: Do delayed neigh confirmation.
    
    When a dst_confirm() happens, mark the confirmation as pending in the
    dst.  Then on the next packet out, when we have the neigh in-hand, do
    the update.
    
    This removes the dependency in dst_confirm() of dst's having an
    attached neigh.
    
    While we're here, remove the explicit 'dst' NULL check, all except 2
    or 3 call sites ensure it's not NULL.  So just fix those cases up.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index 43d94cedbf7c..a6e19a23a745 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -152,7 +152,7 @@ EXPORT_SYMBOL(dst_discard);
 const u32 dst_default_metrics[RTAX_MAX];
 
 void *dst_alloc(struct dst_ops *ops, struct net_device *dev,
-		int initial_ref, int initial_obsolete, int flags)
+		int initial_ref, int initial_obsolete, unsigned short flags)
 {
 	struct dst_entry *dst;
 
@@ -188,6 +188,7 @@ void *dst_alloc(struct dst_ops *ops, struct net_device *dev,
 	dst->__use = 0;
 	dst->lastuse = jiffies;
 	dst->flags = flags;
+	dst->pending_confirm = 0;
 	dst->next = NULL;
 	if (!(flags & DST_NOCOUNT))
 		dst_entries_add(ops, 1);

commit 2721745501a26d0dc3b88c0d2f3aa11471891388
Author: David Miller <davem@davemloft.net>
Date:   Fri Dec 2 16:52:08 2011 +0000

    net: Rename dst_get_neighbour{, _raw} to dst_get_neighbour_noref{, _raw}.
    
    To reflect the fact that a refrence is not obtained to the
    resulting neighbour entry.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Acked-by: Roland Dreier <roland@purestorage.com>

diff --git a/net/core/dst.c b/net/core/dst.c
index d5e2c4c09107..43d94cedbf7c 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -366,7 +366,7 @@ static void dst_ifdown(struct dst_entry *dst, struct net_device *dev,
 		dev_hold(dst->dev);
 		dev_put(dev);
 		rcu_read_lock();
-		neigh = dst_get_neighbour(dst);
+		neigh = dst_get_neighbour_noref(dst);
 		if (neigh && neigh->dev == dev) {
 			neigh->dev = dst->dev;
 			dev_hold(dst->dev);

commit 9de79c127cccecb11ae6a21ab1499e87aa222880
Author: Eric Dumazet <eric.dumazet@gmail.com>
Date:   Mon Aug 8 20:56:14 2011 +0000

    net: fix potential neighbour race in dst_ifdown()
    
    Followup of commit f2c31e32b378a (fix NULL dereferences in
    check_peer_redir()).
    
    We need to make sure dst neighbour doesnt change in dst_ifdown().
    
    Fix some sparse errors.
    
    Signed-off-by: Eric Dumazet <eric.dumazet@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index 14b33baf0733..d5e2c4c09107 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -171,7 +171,7 @@ void *dst_alloc(struct dst_ops *ops, struct net_device *dev,
 	dst_init_metrics(dst, dst_default_metrics, true);
 	dst->expires = 0UL;
 	dst->path = dst;
-	dst->_neighbour = NULL;
+	RCU_INIT_POINTER(dst->_neighbour, NULL);
 #ifdef CONFIG_XFRM
 	dst->xfrm = NULL;
 #endif
@@ -229,11 +229,11 @@ struct dst_entry *dst_destroy(struct dst_entry * dst)
 	smp_rmb();
 
 again:
-	neigh = dst->_neighbour;
+	neigh = rcu_dereference_protected(dst->_neighbour, 1);
 	child = dst->child;
 
 	if (neigh) {
-		dst->_neighbour = NULL;
+		RCU_INIT_POINTER(dst->_neighbour, NULL);
 		neigh_release(neigh);
 	}
 
@@ -360,14 +360,19 @@ static void dst_ifdown(struct dst_entry *dst, struct net_device *dev,
 	if (!unregister) {
 		dst->input = dst->output = dst_discard;
 	} else {
+		struct neighbour *neigh;
+
 		dst->dev = dev_net(dst->dev)->loopback_dev;
 		dev_hold(dst->dev);
 		dev_put(dev);
-		if (dst->_neighbour && dst->_neighbour->dev == dev) {
-			dst->_neighbour->dev = dst->dev;
+		rcu_read_lock();
+		neigh = dst_get_neighbour(dst);
+		if (neigh && neigh->dev == dev) {
+			neigh->dev = dst->dev;
 			dev_hold(dst->dev);
 			dev_put(dev);
 		}
+		rcu_read_unlock();
 	}
 }
 

commit 69cce1d1404968f78b177a0314f5822d5afdbbfb
Author: David S. Miller <davem@davemloft.net>
Date:   Sun Jul 17 23:09:49 2011 -0700

    net: Abstract dst->neighbour accesses behind helpers.
    
    dst_{get,set}_neighbour()
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index 4aacc14936a0..14b33baf0733 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -171,7 +171,7 @@ void *dst_alloc(struct dst_ops *ops, struct net_device *dev,
 	dst_init_metrics(dst, dst_default_metrics, true);
 	dst->expires = 0UL;
 	dst->path = dst;
-	dst->neighbour = NULL;
+	dst->_neighbour = NULL;
 #ifdef CONFIG_XFRM
 	dst->xfrm = NULL;
 #endif
@@ -229,11 +229,11 @@ struct dst_entry *dst_destroy(struct dst_entry * dst)
 	smp_rmb();
 
 again:
-	neigh = dst->neighbour;
+	neigh = dst->_neighbour;
 	child = dst->child;
 
 	if (neigh) {
-		dst->neighbour = NULL;
+		dst->_neighbour = NULL;
 		neigh_release(neigh);
 	}
 
@@ -363,8 +363,8 @@ static void dst_ifdown(struct dst_entry *dst, struct net_device *dev,
 		dst->dev = dev_net(dst->dev)->loopback_dev;
 		dev_hold(dst->dev);
 		dev_put(dev);
-		if (dst->neighbour && dst->neighbour->dev == dev) {
-			dst->neighbour->dev = dst->dev;
+		if (dst->_neighbour && dst->_neighbour->dev == dev) {
+			dst->_neighbour->dev = dst->dev;
 			dev_hold(dst->dev);
 			dev_put(dev);
 		}

commit f6b72b6217f8c24f2a54988e58af858b4e66024d
Author: David S. Miller <davem@davemloft.net>
Date:   Thu Jul 14 07:53:20 2011 -0700

    net: Embed hh_cache inside of struct neighbour.
    
    Now that there is a one-to-one correspondance between neighbour
    and hh_cache entries, we no longer need:
    
    1) dynamic allocation
    2) attachment to dst->hh
    3) refcounting
    
    Initialization of the hh_cache entry is indicated by hh_len
    being non-zero, and such initialization is always done with
    the neighbour's lock held as a writer.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index 6135f3671692..4aacc14936a0 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -172,7 +172,6 @@ void *dst_alloc(struct dst_ops *ops, struct net_device *dev,
 	dst->expires = 0UL;
 	dst->path = dst;
 	dst->neighbour = NULL;
-	dst->hh = NULL;
 #ifdef CONFIG_XFRM
 	dst->xfrm = NULL;
 #endif
@@ -226,19 +225,13 @@ struct dst_entry *dst_destroy(struct dst_entry * dst)
 {
 	struct dst_entry *child;
 	struct neighbour *neigh;
-	struct hh_cache *hh;
 
 	smp_rmb();
 
 again:
 	neigh = dst->neighbour;
-	hh = dst->hh;
 	child = dst->child;
 
-	dst->hh = NULL;
-	if (hh)
-		hh_cache_put(hh);
-
 	if (neigh) {
 		dst->neighbour = NULL;
 		neigh_release(neigh);

commit 957c665f37007de93ccbe45902a23143724170d0
Author: David S. Miller <davem@davemloft.net>
Date:   Fri Jun 24 15:25:00 2011 -0700

    ipv6: Don't put artificial limit on routing table size.
    
    IPV6, unlike IPV4, doesn't have a routing cache.
    
    Routing table entries, as well as clones made in response
    to route lookup requests, all live in the same table.  And
    all of these things are together collected in the destination
    cache table for ipv6.
    
    This means that routing table entries count against the garbage
    collection limits, even though such entries cannot ever be reclaimed
    and are added explicitly by the administrator (rather than being
    created in response to lookups).
    
    Therefore it makes no sense to count ipv6 routing table entries
    against the GC limits.
    
    Add a DST_NOCOUNT destination cache entry flag, and skip the counting
    if it is set.  Use this flag bit in ipv6 when adding routing table
    entries.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index 9ccca038444f..6135f3671692 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -190,7 +190,8 @@ void *dst_alloc(struct dst_ops *ops, struct net_device *dev,
 	dst->lastuse = jiffies;
 	dst->flags = flags;
 	dst->next = NULL;
-	dst_entries_add(ops, 1);
+	if (!(flags & DST_NOCOUNT))
+		dst_entries_add(ops, 1);
 	return dst;
 }
 EXPORT_SYMBOL(dst_alloc);
@@ -243,7 +244,8 @@ struct dst_entry *dst_destroy(struct dst_entry * dst)
 		neigh_release(neigh);
 	}
 
-	dst_entries_add(dst->ops, -1);
+	if (!(dst->flags & DST_NOCOUNT))
+		dst_entries_add(dst->ops, -1);
 
 	if (dst->ops->destroy)
 		dst->ops->destroy(dst);

commit b30c516f875004f025f4d10147bde28c5e98466b
Author: Eric Dumazet <eric.dumazet@gmail.com>
Date:   Tue May 24 13:29:50 2011 -0400

    net: fix __dst_destroy_metrics_generic()
    
    dst_default_metrics is readonly, we dont want to kfree() it later.
    
    Signed-off-by: Eric Dumazet <eric.dumazet@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index 81a4fa1c95ed..9ccca038444f 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -315,7 +315,7 @@ void __dst_destroy_metrics_generic(struct dst_entry *dst, unsigned long old)
 {
 	unsigned long prev, new;
 
-	new = (unsigned long) dst_default_metrics;
+	new = ((unsigned long) dst_default_metrics) | DST_METRICS_READ_ONLY;
 	prev = cmpxchg(&dst->_metrics, old, new);
 	if (prev == old)
 		kfree(__DST_METRICS_PTR(old));

commit 06f4e926d256d902dd9a53dcb400fd74974ce087
Merge: 8e7bfcbab382 d93515611bbc
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri May 20 13:43:21 2011 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/davem/net-next-2.6
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/davem/net-next-2.6: (1446 commits)
      macvlan: fix panic if lowerdev in a bond
      tg3: Add braces around 5906 workaround.
      tg3: Fix NETIF_F_LOOPBACK error
      macvlan: remove one synchronize_rcu() call
      networking: NET_CLS_ROUTE4 depends on INET
      irda: Fix error propagation in ircomm_lmp_connect_response()
      irda: Kill set but unused variable 'bytes' in irlan_check_command_param()
      irda: Kill set but unused variable 'clen' in ircomm_connect_indication()
      rxrpc: Fix set but unused variable 'usage' in rxrpc_get_transport()
      be2net: Kill set but unused variable 'req' in lancer_fw_download()
      irda: Kill set but unused vars 'saddr' and 'daddr' in irlan_provider_connect_indication()
      atl1c: atl1c_resume() is only used when CONFIG_PM_SLEEP is defined.
      rxrpc: Fix set but unused variable 'usage' in rxrpc_get_peer().
      rxrpc: Kill set but unused variable 'local' in rxrpc_UDP_error_handler()
      rxrpc: Kill set but unused variable 'sp' in rxrpc_process_connection()
      rxrpc: Kill set but unused variable 'sp' in rxrpc_rotate_tx_window()
      pkt_sched: Kill set but unused variable 'protocol' in tc_classify()
      isdn: capi: Use pr_debug() instead of ifdefs.
      tg3: Update version to 3.119
      tg3: Apply rx_discards fix to 5719/5720
      ...
    
    Fix up trivial conflicts in arch/x86/Kconfig and net/mac80211/agg-tx.c
    as per Davem.

commit 268bb0ce3e87872cb9290c322b0d35bce230d88f
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri May 20 12:50:29 2011 -0700

    sanitize <linux/prefetch.h> usage
    
    Commit e66eed651fd1 ("list: remove prefetching from regular list
    iterators") removed the include of prefetch.h from list.h, which
    uncovered several cases that had apparently relied on that rather
    obscure header file dependency.
    
    So this fixes things up a bit, using
    
       grep -L linux/prefetch.h $(git grep -l '[^a-z_]prefetchw*(' -- '*.[ch]')
       grep -L 'prefetchw*(' $(git grep -l 'linux/prefetch.h' -- '*.[ch]')
    
    to guide us in finding files that either need <linux/prefetch.h>
    inclusion, or have it despite not needing it.
    
    There are more of them around (mostly network drivers), but this gets
    many core ones.
    
    Reported-by: Stephen Rothwell <sfr@canb.auug.org.au>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/net/core/dst.c b/net/core/dst.c
index 91104d35de7d..0a3920bf3613 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -19,6 +19,7 @@
 #include <linux/types.h>
 #include <net/net_namespace.h>
 #include <linux/sched.h>
+#include <linux/prefetch.h>
 
 #include <net/dst.h>
 

commit 6882f933ccee5c3a86443ffc7621ce888b93ab6b
Author: David S. Miller <davem@davemloft.net>
Date:   Wed May 18 18:23:21 2011 -0400

    ipv4: Kill RT_CACHE_DEBUG
    
    It's way past it's usefulness.  And this gets rid of a bunch
    of stray ->rt_{dst,src} references.
    
    Even the comment documenting the macro was inaccurate (stated
    default was 1 when it's 0).
    
    If reintroduced, it should be done properly, with dynamic debug
    facilities.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index 30f009327b62..da47a299618a 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -33,9 +33,6 @@
  * 3) This list is guarded by a mutex,
  *    so that the gc_task and dst_dev_event() can be synchronized.
  */
-#if RT_CACHE_DEBUG >= 2
-static atomic_t			 dst_total = ATOMIC_INIT(0);
-#endif
 
 /*
  * We want to keep lock & list close together
@@ -69,10 +66,6 @@ static void dst_gc_task(struct work_struct *work)
 	unsigned long expires = ~0L;
 	struct dst_entry *dst, *next, head;
 	struct dst_entry *last = &head;
-#if RT_CACHE_DEBUG >= 2
-	ktime_t time_start = ktime_get();
-	struct timespec elapsed;
-#endif
 
 	mutex_lock(&dst_gc_mutex);
 	next = dst_busy_list;
@@ -146,15 +139,6 @@ static void dst_gc_task(struct work_struct *work)
 
 	spin_unlock_bh(&dst_garbage.lock);
 	mutex_unlock(&dst_gc_mutex);
-#if RT_CACHE_DEBUG >= 2
-	elapsed = ktime_to_timespec(ktime_sub(ktime_get(), time_start));
-	printk(KERN_DEBUG "dst_total: %d delayed: %d work_perf: %d"
-		" expires: %lu elapsed: %lu us\n",
-		atomic_read(&dst_total), delayed, work_performed,
-		expires,
-		elapsed.tv_sec * USEC_PER_SEC +
-		  elapsed.tv_nsec / NSEC_PER_USEC);
-#endif
 }
 
 int dst_discard(struct sk_buff *skb)
@@ -205,9 +189,6 @@ void *dst_alloc(struct dst_ops *ops, struct net_device *dev,
 	dst->lastuse = jiffies;
 	dst->flags = flags;
 	dst->next = NULL;
-#if RT_CACHE_DEBUG >= 2
-	atomic_inc(&dst_total);
-#endif
 	dst_entries_add(ops, 1);
 	return dst;
 }
@@ -267,9 +248,6 @@ struct dst_entry *dst_destroy(struct dst_entry * dst)
 		dst->ops->destroy(dst);
 	if (dst->dev)
 		dev_put(dst->dev);
-#if RT_CACHE_DEBUG >= 2
-	atomic_dec(&dst_total);
-#endif
 	kmem_cache_free(dst->ops->kmem_cachep, dst);
 
 	dst = child;

commit cf91166223772ef4a2ed98b9874958bf6a2470df
Author: David S. Miller <davem@davemloft.net>
Date:   Thu Apr 28 14:31:47 2011 -0700

    net: Use non-zero allocations in dst_alloc().
    
    Make dst_alloc() and it's users explicitly initialize the entire
    entry.
    
    The zero'ing done by kmem_cache_zalloc() was almost entirely
    redundant.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index 9505778ec800..30f009327b62 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -175,22 +175,36 @@ void *dst_alloc(struct dst_ops *ops, struct net_device *dev,
 		if (ops->gc(ops))
 			return NULL;
 	}
-	dst = kmem_cache_zalloc(ops->kmem_cachep, GFP_ATOMIC);
+	dst = kmem_cache_alloc(ops->kmem_cachep, GFP_ATOMIC);
 	if (!dst)
 		return NULL;
-	dst->ops = ops;
+	dst->child = NULL;
 	dst->dev = dev;
 	if (dev)
 		dev_hold(dev);
+	dst->ops = ops;
 	dst_init_metrics(dst, dst_default_metrics, true);
+	dst->expires = 0UL;
 	dst->path = dst;
+	dst->neighbour = NULL;
+	dst->hh = NULL;
+#ifdef CONFIG_XFRM
+	dst->xfrm = NULL;
+#endif
 	dst->input = dst_discard;
 	dst->output = dst_discard;
-
+	dst->error = 0;
 	dst->obsolete = initial_obsolete;
+	dst->header_len = 0;
+	dst->trailer_len = 0;
+#ifdef CONFIG_IP_ROUTE_CLASSID
+	dst->tclassid = 0;
+#endif
 	atomic_set(&dst->__refcnt, initial_ref);
+	dst->__use = 0;
 	dst->lastuse = jiffies;
 	dst->flags = flags;
+	dst->next = NULL;
 #if RT_CACHE_DEBUG >= 2
 	atomic_inc(&dst_total);
 #endif

commit 5c1e6aa300a7a669dc469d2dcb20172c6bd8fed9
Author: David S. Miller <davem@davemloft.net>
Date:   Thu Apr 28 14:13:38 2011 -0700

    net: Make dst_alloc() take more explicit initializations.
    
    Now the dst->dev, dev->obsolete, and dst->flags values can
    be specified as well.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index 91104d35de7d..9505778ec800 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -166,7 +166,8 @@ EXPORT_SYMBOL(dst_discard);
 
 const u32 dst_default_metrics[RTAX_MAX];
 
-void *dst_alloc(struct dst_ops *ops, int initial_ref)
+void *dst_alloc(struct dst_ops *ops, struct net_device *dev,
+		int initial_ref, int initial_obsolete, int flags)
 {
 	struct dst_entry *dst;
 
@@ -177,12 +178,19 @@ void *dst_alloc(struct dst_ops *ops, int initial_ref)
 	dst = kmem_cache_zalloc(ops->kmem_cachep, GFP_ATOMIC);
 	if (!dst)
 		return NULL;
-	atomic_set(&dst->__refcnt, initial_ref);
 	dst->ops = ops;
-	dst->lastuse = jiffies;
-	dst->path = dst;
-	dst->input = dst->output = dst_discard;
+	dst->dev = dev;
+	if (dev)
+		dev_hold(dev);
 	dst_init_metrics(dst, dst_default_metrics, true);
+	dst->path = dst;
+	dst->input = dst_discard;
+	dst->output = dst_discard;
+
+	dst->obsolete = initial_obsolete;
+	atomic_set(&dst->__refcnt, initial_ref);
+	dst->lastuse = jiffies;
+	dst->flags = flags;
 #if RT_CACHE_DEBUG >= 2
 	atomic_inc(&dst_total);
 #endif

commit 3c7bd1a14071b99d6535b710bc998ae5d3abbb66
Author: David S. Miller <davem@davemloft.net>
Date:   Wed Feb 16 14:08:44 2011 -0800

    net: Add initial_ref arg to dst_alloc().
    
    This allows avoiding multiple writes to the initial __refcnt.
    
    The most simplest cases of wanting an initial reference of "1"
    in ipv4 and ipv6 have been converted, the rest have been left
    along and kept at the existing "0".
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index c1674fde827d..91104d35de7d 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -166,7 +166,7 @@ EXPORT_SYMBOL(dst_discard);
 
 const u32 dst_default_metrics[RTAX_MAX];
 
-void *dst_alloc(struct dst_ops *ops)
+void *dst_alloc(struct dst_ops *ops, int initial_ref)
 {
 	struct dst_entry *dst;
 
@@ -177,7 +177,7 @@ void *dst_alloc(struct dst_ops *ops)
 	dst = kmem_cache_zalloc(ops->kmem_cachep, GFP_ATOMIC);
 	if (!dst)
 		return NULL;
-	atomic_set(&dst->__refcnt, 0);
+	atomic_set(&dst->__refcnt, initial_ref);
 	dst->ops = ops;
 	dst->lastuse = jiffies;
 	dst->path = dst;

commit 725d1e1b457dc2bbebb337677e73efe7c6d14da5
Author: David S. Miller <davem@davemloft.net>
Date:   Fri Jan 28 14:05:05 2011 -0800

    ipv4: Attach FIB info to dst_default_metrics when possible
    
    If there are no explicit metrics attached to a route, hook
    fi->fib_info up to dst_default_metrics.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index 578893505702..c1674fde827d 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -164,7 +164,7 @@ int dst_discard(struct sk_buff *skb)
 }
 EXPORT_SYMBOL(dst_discard);
 
-static const u32 dst_default_metrics[RTAX_MAX];
+const u32 dst_default_metrics[RTAX_MAX];
 
 void *dst_alloc(struct dst_ops *ops)
 {

commit 62fa8a846d7de4b299232e330c74b7783539df76
Author: David S. Miller <davem@davemloft.net>
Date:   Wed Jan 26 20:51:05 2011 -0800

    net: Implement read-only protection and COW'ing of metrics.
    
    Routing metrics are now copy-on-write.
    
    Initially a route entry points it's metrics at a read-only location.
    If a routing table entry exists, it will point there.  Else it will
    point at the all zero metric place-holder called 'dst_default_metrics'.
    
    The writeability state of the metrics is stored in the low bits of the
    metrics pointer, we have two bits left to spare if we want to store
    more states.
    
    For the initial implementation, COW is implemented simply via kmalloc.
    However future enhancements will change this to place the writable
    metrics somewhere else, in order to increase sharing.  Very likely
    this "somewhere else" will be the inetpeer cache.
    
    Note also that this means that metrics updates may transiently fail
    if we cannot COW the metrics successfully.
    
    But even by itself, this patch should decrease memory usage and
    increase cache locality especially for routing workloads.  In those
    cases the read-only metric copies stay in place and never get written
    to.
    
    TCP workloads where metrics get updated, and those rare cases where
    PMTU triggers occur, will take a very slight performance hit.  But
    that hit will be alleviated when the long-term writable metrics
    move to a more sharable location.
    
    Since the metrics storage went from a u32 array of RTAX_MAX entries to
    what is essentially a pointer, some retooling of the dst_entry layout
    was necessary.
    
    Most importantly, we need to preserve the alignment of the reference
    count so that it doesn't share cache lines with the read-mostly state,
    as per Eric Dumazet's alignment assertion checks.
    
    The only non-trivial bit here is the move of the 'flags' member into
    the writeable cacheline.  This is OK since we are always accessing the
    flags around the same moment when we made a modification to the
    reference count.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index b99c7c7ffce2..578893505702 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -164,6 +164,8 @@ int dst_discard(struct sk_buff *skb)
 }
 EXPORT_SYMBOL(dst_discard);
 
+static const u32 dst_default_metrics[RTAX_MAX];
+
 void *dst_alloc(struct dst_ops *ops)
 {
 	struct dst_entry *dst;
@@ -180,6 +182,7 @@ void *dst_alloc(struct dst_ops *ops)
 	dst->lastuse = jiffies;
 	dst->path = dst;
 	dst->input = dst->output = dst_discard;
+	dst_init_metrics(dst, dst_default_metrics, true);
 #if RT_CACHE_DEBUG >= 2
 	atomic_inc(&dst_total);
 #endif
@@ -282,6 +285,42 @@ void dst_release(struct dst_entry *dst)
 }
 EXPORT_SYMBOL(dst_release);
 
+u32 *dst_cow_metrics_generic(struct dst_entry *dst, unsigned long old)
+{
+	u32 *p = kmalloc(sizeof(u32) * RTAX_MAX, GFP_ATOMIC);
+
+	if (p) {
+		u32 *old_p = __DST_METRICS_PTR(old);
+		unsigned long prev, new;
+
+		memcpy(p, old_p, sizeof(u32) * RTAX_MAX);
+
+		new = (unsigned long) p;
+		prev = cmpxchg(&dst->_metrics, old, new);
+
+		if (prev != old) {
+			kfree(p);
+			p = __DST_METRICS_PTR(prev);
+			if (prev & DST_METRICS_READ_ONLY)
+				p = NULL;
+		}
+	}
+	return p;
+}
+EXPORT_SYMBOL(dst_cow_metrics_generic);
+
+/* Caller asserts that dst_metrics_read_only(dst) is false.  */
+void __dst_destroy_metrics_generic(struct dst_entry *dst, unsigned long old)
+{
+	unsigned long prev, new;
+
+	new = (unsigned long) dst_default_metrics;
+	prev = cmpxchg(&dst->_metrics, old, new);
+	if (prev == old)
+		kfree(__DST_METRICS_PTR(old));
+}
+EXPORT_SYMBOL(__dst_destroy_metrics_generic);
+
 /**
  * skb_dst_set_noref - sets skb dst, without a reference
  * @skb: buffer

commit 332dd96f7ac15e937088fe11f15cfe0210e8edd1
Author: Eric Dumazet <eric.dumazet@gmail.com>
Date:   Tue Nov 9 11:46:33 2010 -0800

    net/dst: dst_dev_event() called after other notifiers
    
    Followup of commit ef885afbf8a37689 (net: use rcu_barrier() in
    rollback_registered_many)
    
    dst_dev_event() scans a garbage dst list that might be feeded by various
    network notifiers at device dismantle time.
    
    Its important to call dst_dev_event() after other notifiers, or we might
    enter the infamous msleep(250) in netdev_wait_allrefs(), and wait one
    second before calling again call_netdevice_notifiers(NETDEV_UNREGISTER,
    dev) to properly remove last device references.
    
    Use priority -10 to let dst_dev_notifier be called after other network
    notifiers (they have the default 0 priority)
    
    Reported-by: Ben Greear <greearb@candelatech.com>
    Reported-by: Nicolas Dichtel <nicolas.dichtel@6wind.com>
    Reported-by: Octavian Purdila <opurdila@ixiacom.com>
    Reported-by: Benjamin LaHaise <bcrl@kvack.org>
    Tested-by: Ben Greear <greearb@candelatech.com>
    Signed-off-by: Eric Dumazet <eric.dumazet@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index 8abe628b79f1..b99c7c7ffce2 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -370,6 +370,7 @@ static int dst_dev_event(struct notifier_block *this, unsigned long event,
 
 static struct notifier_block dst_dev_notifier = {
 	.notifier_call	= dst_dev_event,
+	.priority = -10, /* must be called after other network notifiers */
 };
 
 void __init dst_init(void)

commit 27b75c95f10d249574d9c4cb9dab878107faede8
Author: Eric Dumazet <eric.dumazet@gmail.com>
Date:   Fri Oct 15 05:44:11 2010 +0000

    net: avoid RCU for NOCACHE dst
    
    There is no point using RCU for dst we allocate for a very short time
    (used once).
    
    Change dst_release() to take DST_NOCACHE into account, but also change
    skb_dst_set_noref() to force a refcount increment for such dst.
    
    This is a _huge_ gain, because we dont waste memory to store xx thousand
    of dsts. Instead of queueing them to RCU, we can free them instantly.
    
    CPU caches can stay hot, re-using same memory blocks to hold temporary
    dsts.
    
    Note : remove unneeded smp_mb__before_atomic_dec(); in dst_release(),
    since atomic_dec_return() implies a full memory barrier.
    
    Stress test, 160.000.000 udp frames sent, IP route cache disabled
    (DDOS).
    
    Before:
    
    real    0m38.091s
    user    0m13.189s
    sys     7m53.018s
    
    After:
    
    real    0m29.946s
    user    0m12.157s
    sys     7m40.605s
    
    For reference, if IP route cache was enabled :
    
    real    0m32.030s
    user    0m10.521s
    sys     8m15.243s
    
    Signed-off-by: Eric Dumazet <eric.dumazet@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index 32e542d7f472..8abe628b79f1 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -271,13 +271,40 @@ void dst_release(struct dst_entry *dst)
 	if (dst) {
 		int newrefcnt;
 
-		smp_mb__before_atomic_dec();
 		newrefcnt = atomic_dec_return(&dst->__refcnt);
 		WARN_ON(newrefcnt < 0);
+		if (unlikely(dst->flags & DST_NOCACHE) && !newrefcnt) {
+			dst = dst_destroy(dst);
+			if (dst)
+				__dst_free(dst);
+		}
 	}
 }
 EXPORT_SYMBOL(dst_release);
 
+/**
+ * skb_dst_set_noref - sets skb dst, without a reference
+ * @skb: buffer
+ * @dst: dst entry
+ *
+ * Sets skb dst, assuming a reference was not taken on dst
+ * skb_dst_drop() should not dst_release() this dst
+ */
+void skb_dst_set_noref(struct sk_buff *skb, struct dst_entry *dst)
+{
+	WARN_ON(!rcu_read_lock_held() && !rcu_read_lock_bh_held());
+	/* If dst not in cache, we must take a reference, because
+	 * dst_release() will destroy dst as soon as its refcount becomes zero
+	 */
+	if (unlikely(dst->flags & DST_NOCACHE)) {
+		dst_hold(dst);
+		skb_dst_set(skb, dst);
+	} else {
+		skb->_skb_refdst = (unsigned long)dst | SKB_DST_NOREF;
+	}
+}
+EXPORT_SYMBOL(skb_dst_set_noref);
+
 /* Dirty hack. We did it in 2.2 (in __dst_free),
  * we have _very_ good reasons not to repeat
  * this mistake in 2.3, but we have no choice

commit fc66f95c68b6d4535a0ea2ea15d5cf626e310956
Author: Eric Dumazet <eric.dumazet@gmail.com>
Date:   Fri Oct 8 06:37:34 2010 +0000

    net dst: use a percpu_counter to track entries
    
    struct dst_ops tracks number of allocated dst in an atomic_t field,
    subject to high cache line contention in stress workload.
    
    Switch to a percpu_counter, to reduce number of time we need to dirty a
    central location. Place it on a separate cache line to avoid dirtying
    read only fields.
    
    Stress test :
    
    (Sending 160.000.000 UDP frames,
    IP route cache disabled, dual E5540 @2.53GHz,
    32bit kernel, FIB_TRIE, SLUB/NUMA)
    
    Before:
    
    real    0m51.179s
    user    0m15.329s
    sys     10m15.942s
    
    After:
    
    real    0m45.570s
    user    0m15.525s
    sys     9m56.669s
    
    With a small reordering of struct neighbour fields, subject of a
    following patch, (to separate refcnt from other read mostly fields)
    
    real    0m41.841s
    user    0m15.261s
    sys     8m45.949s
    
    Signed-off-by: Eric Dumazet <eric.dumazet@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index 978a1ee1f7d0..32e542d7f472 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -168,7 +168,7 @@ void *dst_alloc(struct dst_ops *ops)
 {
 	struct dst_entry *dst;
 
-	if (ops->gc && atomic_read(&ops->entries) > ops->gc_thresh) {
+	if (ops->gc && dst_entries_get_fast(ops) > ops->gc_thresh) {
 		if (ops->gc(ops))
 			return NULL;
 	}
@@ -183,7 +183,7 @@ void *dst_alloc(struct dst_ops *ops)
 #if RT_CACHE_DEBUG >= 2
 	atomic_inc(&dst_total);
 #endif
-	atomic_inc(&ops->entries);
+	dst_entries_add(ops, 1);
 	return dst;
 }
 EXPORT_SYMBOL(dst_alloc);
@@ -236,7 +236,7 @@ struct dst_entry *dst_destroy(struct dst_entry * dst)
 		neigh_release(neigh);
 	}
 
-	atomic_dec(&dst->ops->entries);
+	dst_entries_add(dst->ops, -1);
 
 	if (dst->ops->destroy)
 		dst->ops->destroy(dst);

commit 34d101dd6204bd100fc2e6f7b5f9a10f959ce2c9
Author: Eric Dumazet <eric.dumazet@gmail.com>
Date:   Mon Oct 11 09:16:57 2010 -0700

    neigh: speedup neigh_hh_init()
    
    When a new dst is used to send a frame, neigh_resolve_output() tries to
    associate an struct hh_cache to this dst, calling neigh_hh_init() with
    the neigh rwlock write locked.
    
    Most of the time, hh_cache is already known and linked into neighbour,
    so we find it and increment its refcount.
    
    This patch changes the logic so that we call neigh_hh_init() with
    neighbour lock read locked only, so that fast path can be run in
    parallel by concurrent cpus.
    
    This brings part of the speedup we got with commit c7d4426a98a5f
    (introduce DST_NOCACHE flag) for non cached dsts, even for cached ones,
    removing one of the contention point that routers hit on multiqueue
    enabled machines.
    
    Further improvements would need to use a seqlock instead of an rwlock to
    protect neigh->ha[], to not dirty neigh too often and remove two atomic
    ops.
    
    Signed-off-by: Eric Dumazet <eric.dumazet@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index 6c41b1fac3db..978a1ee1f7d0 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -228,8 +228,8 @@ struct dst_entry *dst_destroy(struct dst_entry * dst)
 	child = dst->child;
 
 	dst->hh = NULL;
-	if (hh && atomic_dec_and_test(&hh->hh_refcnt))
-		kfree(hh);
+	if (hh)
+		hh_cache_put(hh);
 
 	if (neigh) {
 		dst->neighbour = NULL;

commit d79d991379af35d43f003f162e8650e72965b8ca
Author: Nicolas Dichtel <nicolas.dichtel@6wind.com>
Date:   Mon Jul 19 23:51:38 2010 +0000

    __dst_free(): put EXPORT_SYMBOLS after the fct
    
    Signed-off-by: Nicolas Dichtel <nicolas.dichtel@6wind.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index 9920722cc82b..6c41b1fac3db 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -197,7 +197,6 @@ static void ___dst_free(struct dst_entry *dst)
 		dst->input = dst->output = dst_discard;
 	dst->obsolete = 2;
 }
-EXPORT_SYMBOL(__dst_free);
 
 void __dst_free(struct dst_entry *dst)
 {
@@ -213,6 +212,7 @@ void __dst_free(struct dst_entry *dst)
 	}
 	spin_unlock_bh(&dst_garbage.lock);
 }
+EXPORT_SYMBOL(__dst_free);
 
 struct dst_entry *dst_destroy(struct dst_entry * dst)
 {

commit 561155110307ad304226a23272244398fa46cbae
Author: stephen hemminger <shemminger@vyatta.com>
Date:   Mon Apr 12 07:38:05 2010 +0000

    dst: don't inline dst_ifdown
    
    The function dst_ifdown is called only two places but in a non-
    performance critical code path, there is no reason to inline it.
    
    Signed-off-by: Stephen Hemminger <shemminger@vyatta.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index b8c22f0f9373..9920722cc82b 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -286,8 +286,8 @@ EXPORT_SYMBOL(dst_release);
  *
  * Commented and originally written by Alexey.
  */
-static inline void dst_ifdown(struct dst_entry *dst, struct net_device *dev,
-			      int unregister)
+static void dst_ifdown(struct dst_entry *dst, struct net_device *dev,
+		       int unregister)
 {
 	if (dst->ops->ifdown)
 		dst->ops->ifdown(dst, dev, unregister);

commit 871039f02f8ec4ab2e5e9010718caa8e085786f1
Merge: e4077e018b5e 4a1032faac94
Author: David S. Miller <davem@davemloft.net>
Date:   Sun Apr 11 14:53:53 2010 -0700

    Merge branch 'master' of master.kernel.org:/pub/scm/linux/kernel/git/davem/net-2.6
    
    Conflicts:
            drivers/net/stmmac/stmmac_main.c
            drivers/net/wireless/wl12xx/wl1271_cmd.c
            drivers/net/wireless/wl12xx/wl1271_main.c
            drivers/net/wireless/wl12xx/wl1271_spi.c
            net/core/ethtool.c
            net/mac80211/scan.c

commit 598ed9367a36ee1fd4ae3271a54a3547a33975a5
Author: laurent chavey <chavey@google.com>
Date:   Mon Mar 29 10:41:36 2010 +0000

    fix net/core/dst.c coding style error and warnings
    
    Fix coding style errors and warnings output while running checkpatch.pl
    on the file net/core/dst.c.
    
    Signed-off-by: chavey <chavey@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index cb1b3488b739..2076d84203d1 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -43,7 +43,7 @@ static atomic_t			 dst_total = ATOMIC_INIT(0);
  */
 static struct {
 	spinlock_t		lock;
-	struct dst_entry 	*list;
+	struct dst_entry	*list;
 	unsigned long		timer_inc;
 	unsigned long		timer_expires;
 } dst_garbage = {
@@ -51,7 +51,7 @@ static struct {
 	.timer_inc = DST_GC_MAX,
 };
 static void dst_gc_task(struct work_struct *work);
-static void ___dst_free(struct dst_entry * dst);
+static void ___dst_free(struct dst_entry *dst);
 
 static DECLARE_DELAYED_WORK(dst_gc_work, dst_gc_task);
 
@@ -135,8 +135,8 @@ static void dst_gc_task(struct work_struct *work)
 		}
 		expires = dst_garbage.timer_expires;
 		/*
-		 * if the next desired timer is more than 4 seconds in the future
-		 * then round the timer to whole seconds
+		 * if the next desired timer is more than 4 seconds in the
+		 * future then round the timer to whole seconds
 		 */
 		if (expires > 4*HZ)
 			expires = round_jiffies_relative(expires);
@@ -151,7 +151,8 @@ static void dst_gc_task(struct work_struct *work)
 		" expires: %lu elapsed: %lu us\n",
 		atomic_read(&dst_total), delayed, work_performed,
 		expires,
-		elapsed.tv_sec * USEC_PER_SEC + elapsed.tv_nsec / NSEC_PER_USEC);
+		elapsed.tv_sec * USEC_PER_SEC +
+		  elapsed.tv_nsec / NSEC_PER_USEC);
 #endif
 }
 
@@ -162,9 +163,9 @@ int dst_discard(struct sk_buff *skb)
 }
 EXPORT_SYMBOL(dst_discard);
 
-void * dst_alloc(struct dst_ops * ops)
+void *dst_alloc(struct dst_ops *ops)
 {
-	struct dst_entry * dst;
+	struct dst_entry *dst;
 
 	if (ops->gc && atomic_read(&ops->entries) > ops->gc_thresh) {
 		if (ops->gc(ops))
@@ -184,19 +185,20 @@ void * dst_alloc(struct dst_ops * ops)
 	atomic_inc(&ops->entries);
 	return dst;
 }
+EXPORT_SYMBOL(dst_alloc);
 
-static void ___dst_free(struct dst_entry * dst)
+static void ___dst_free(struct dst_entry *dst)
 {
 	/* The first case (dev==NULL) is required, when
 	   protocol module is unloaded.
 	 */
-	if (dst->dev == NULL || !(dst->dev->flags&IFF_UP)) {
+	if (dst->dev == NULL || !(dst->dev->flags&IFF_UP))
 		dst->input = dst->output = dst_discard;
-	}
 	dst->obsolete = 2;
 }
+EXPORT_SYMBOL(__dst_free);
 
-void __dst_free(struct dst_entry * dst)
+void __dst_free(struct dst_entry *dst)
 {
 	spin_lock_bh(&dst_garbage.lock);
 	___dst_free(dst);
@@ -261,15 +263,16 @@ struct dst_entry *dst_destroy(struct dst_entry * dst)
 	}
 	return NULL;
 }
+EXPORT_SYMBOL(dst_destroy);
 
 void dst_release(struct dst_entry *dst)
 {
 	if (dst) {
-               int newrefcnt;
+		int newrefcnt;
 
 		smp_mb__before_atomic_dec();
-               newrefcnt = atomic_dec_return(&dst->__refcnt);
-               WARN_ON(newrefcnt < 0);
+		newrefcnt = atomic_dec_return(&dst->__refcnt);
+		WARN_ON(newrefcnt < 0);
 	}
 }
 EXPORT_SYMBOL(dst_release);
@@ -305,7 +308,8 @@ static inline void dst_ifdown(struct dst_entry *dst, struct net_device *dev,
 	}
 }
 
-static int dst_dev_event(struct notifier_block *this, unsigned long event, void *ptr)
+static int dst_dev_event(struct notifier_block *this, unsigned long event,
+			 void *ptr)
 {
 	struct net_device *dev = ptr;
 	struct dst_entry *dst, *last = NULL;
@@ -328,9 +332,8 @@ static int dst_dev_event(struct notifier_block *this, unsigned long event, void
 			last->next = dst;
 		else
 			dst_busy_list = dst;
-		for (; dst; dst = dst->next) {
+		for (; dst; dst = dst->next)
 			dst_ifdown(dst, dev, event != NETDEV_DOWN);
-		}
 		mutex_unlock(&dst_gc_mutex);
 		break;
 	}
@@ -345,7 +348,3 @@ void __init dst_init(void)
 {
 	register_netdevice_notifier(&dst_dev_notifier);
 }
-
-EXPORT_SYMBOL(__dst_free);
-EXPORT_SYMBOL(dst_alloc);
-EXPORT_SYMBOL(dst_destroy);

commit 5a0e3ad6af8660be21ca98a971cd00f331318c05
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Mar 24 17:04:11 2010 +0900

    include cleanup: Update gfp.h and slab.h includes to prepare for breaking implicit slab.h inclusion from percpu.h
    
    percpu.h is included by sched.h and module.h and thus ends up being
    included when building most .c files.  percpu.h includes slab.h which
    in turn includes gfp.h making everything defined by the two files
    universally available and complicating inclusion dependencies.
    
    percpu.h -> slab.h dependency is about to be removed.  Prepare for
    this change by updating users of gfp and slab facilities include those
    headers directly instead of assuming availability.  As this conversion
    needs to touch large number of source files, the following script is
    used as the basis of conversion.
    
      http://userweb.kernel.org/~tj/misc/slabh-sweep.py
    
    The script does the followings.
    
    * Scan files for gfp and slab usages and update includes such that
      only the necessary includes are there.  ie. if only gfp is used,
      gfp.h, if slab is used, slab.h.
    
    * When the script inserts a new include, it looks at the include
      blocks and try to put the new include such that its order conforms
      to its surrounding.  It's put in the include block which contains
      core kernel includes, in the same order that the rest are ordered -
      alphabetical, Christmas tree, rev-Xmas-tree or at the end if there
      doesn't seem to be any matching order.
    
    * If the script can't find a place to put a new include (mostly
      because the file doesn't have fitting include block), it prints out
      an error message indicating which .h file needs to be added to the
      file.
    
    The conversion was done in the following steps.
    
    1. The initial automatic conversion of all .c files updated slightly
       over 4000 files, deleting around 700 includes and adding ~480 gfp.h
       and ~3000 slab.h inclusions.  The script emitted errors for ~400
       files.
    
    2. Each error was manually checked.  Some didn't need the inclusion,
       some needed manual addition while adding it to implementation .h or
       embedding .c file was more appropriate for others.  This step added
       inclusions to around 150 files.
    
    3. The script was run again and the output was compared to the edits
       from #2 to make sure no file was left behind.
    
    4. Several build tests were done and a couple of problems were fixed.
       e.g. lib/decompress_*.c used malloc/free() wrappers around slab
       APIs requiring slab.h to be added manually.
    
    5. The script was run on all .h files but without automatically
       editing them as sprinkling gfp.h and slab.h inclusions around .h
       files could easily lead to inclusion dependency hell.  Most gfp.h
       inclusion directives were ignored as stuff from gfp.h was usually
       wildly available and often used in preprocessor macros.  Each
       slab.h inclusion directive was examined and added manually as
       necessary.
    
    6. percpu.h was updated not to include slab.h.
    
    7. Build test were done on the following configurations and failures
       were fixed.  CONFIG_GCOV_KERNEL was turned off for all tests (as my
       distributed build env didn't work with gcov compiles) and a few
       more options had to be turned off depending on archs to make things
       build (like ipr on powerpc/64 which failed due to missing writeq).
    
       * x86 and x86_64 UP and SMP allmodconfig and a custom test config.
       * powerpc and powerpc64 SMP allmodconfig
       * sparc and sparc64 SMP allmodconfig
       * ia64 SMP allmodconfig
       * s390 SMP allmodconfig
       * alpha SMP allmodconfig
       * um on x86_64 SMP allmodconfig
    
    8. percpu.h modifications were reverted so that it could be applied as
       a separate patch and serve as bisection point.
    
    Given the fact that I had only a couple of failures from tests on step
    6, I'm fairly confident about the coverage of this conversion patch.
    If there is a breakage, it's likely to be something in one of the arch
    headers which should be easily discoverable easily on most builds of
    the specific arch.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Guess-its-ok-by: Christoph Lameter <cl@linux-foundation.org>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Lee Schermerhorn <Lee.Schermerhorn@hp.com>

diff --git a/net/core/dst.c b/net/core/dst.c
index cb1b3488b739..f307bc18f6a0 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -12,6 +12,7 @@
 #include <linux/workqueue.h>
 #include <linux/mm.h>
 #include <linux/module.h>
+#include <linux/slab.h>
 #include <linux/netdevice.h>
 #include <linux/skbuff.h>
 #include <linux/string.h>

commit 2fc1b5dd99f66d93ffc23fd8df82d384c1a354c8
Author: Eric Dumazet <eric.dumazet@gmail.com>
Date:   Mon Feb 8 15:00:39 2010 -0800

    dst: call cond_resched() in dst_gc_task()
    
    Kernel bugzilla #15239
    
    On some workloads, it is quite possible to get a huge dst list to
    process in dst_gc_task(), and trigger soft lockup detection.
    
    Fix is to call cond_resched(), as we run in process context.
    
    Reported-by: Pawel Staszewski <pstaszewski@itcare.pl>
    Tested-by: Pawel Staszewski <pstaszewski@itcare.pl>
    Signed-off-by: Eric Dumazet <eric.dumazet@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index 57bc4d5b8d08..cb1b3488b739 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -17,6 +17,7 @@
 #include <linux/string.h>
 #include <linux/types.h>
 #include <net/net_namespace.h>
+#include <linux/sched.h>
 
 #include <net/dst.h>
 
@@ -79,6 +80,7 @@ static void dst_gc_task(struct work_struct *work)
 	while ((dst = next) != NULL) {
 		next = dst->next;
 		prefetch(&next->next);
+		cond_resched();
 		if (likely(atomic_read(&dst->__refcnt))) {
 			last->next = dst;
 			last = dst;

commit ef711cf1d156428d4c2911b8c86c6ce90519dc45
Author: Eric Dumazet <dada1@cosmosbay.com>
Date:   Fri Nov 14 00:53:54 2008 -0800

    net: speedup dst_release()
    
    During tbench/oprofile sessions, I found that dst_release() was in third position.
    
    CPU: Core 2, speed 2999.68 MHz (estimated)
    Counted CPU_CLK_UNHALTED events (Clock cycles when not halted) with a unit mask of 0x00 (Unhalted core cycles) count 100000
    samples  %        symbol name
    483726    9.0185  __copy_user_zeroing_intel
    191466    3.5697  __copy_user_intel
    185475    3.4580  dst_release
    175114    3.2648  ip_queue_xmit
    153447    2.8608  tcp_sendmsg
    108775    2.0280  tcp_recvmsg
    102659    1.9140  sysenter_past_esp
    101450    1.8914  tcp_current_mss
    95067     1.7724  __copy_from_user_ll
    86531     1.6133  tcp_transmit_skb
    
    Of course, all CPUS fight on the dst_entry associated with 127.0.0.1
    
    Instead of first checking the refcount value, then decrement it,
    we use atomic_dec_return() to help CPU to make the right memory transaction
    (ie getting the cache line in exclusive mode)
    
    dst_release() is now at the fifth position, and tbench a litle bit faster ;)
    
    CPU: Core 2, speed 3000.1 MHz (estimated)
    Counted CPU_CLK_UNHALTED events (Clock cycles when not halted) with a unit mask of 0x00 (Unhalted core cycles) count 100000
    samples  %        symbol name
    647107    8.8072  __copy_user_zeroing_intel
    258840    3.5229  ip_queue_xmit
    258302    3.5155  __copy_user_intel
    209629    2.8531  tcp_sendmsg
    165632    2.2543  dst_release
    149232    2.0311  tcp_current_mss
    147821    2.0119  tcp_recvmsg
    137893    1.8767  sysenter_past_esp
    127473    1.7349  __copy_from_user_ll
    121308    1.6510  ip_finish_output
    118510    1.6129  tcp_transmit_skb
    109295    1.4875  tcp_v4_rcv
    
    Signed-off-by: Eric Dumazet <dada1@cosmosbay.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index 09c1530f4681..57bc4d5b8d08 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -263,9 +263,11 @@ struct dst_entry *dst_destroy(struct dst_entry * dst)
 void dst_release(struct dst_entry *dst)
 {
 	if (dst) {
-		WARN_ON(atomic_read(&dst->__refcnt) < 1);
+               int newrefcnt;
+
 		smp_mb__before_atomic_dec();
-		atomic_dec(&dst->__refcnt);
+               newrefcnt = atomic_dec_return(&dst->__refcnt);
+               WARN_ON(newrefcnt < 0);
 	}
 }
 EXPORT_SYMBOL(dst_release);

commit f262b59becc3f557da6460232abac13706402849
Author: Benjamin Thery <benjamin.thery@bull.net>
Date:   Fri Sep 12 16:16:37 2008 -0700

    net: fix scheduling of dst_gc_task by __dst_free
    
    The dst garbage collector dst_gc_task() may not be scheduled as we
    expect it to be in __dst_free().
    
    Indeed, when the dst_gc_timer was replaced by the delayed_work
    dst_gc_work, the mod_timer() call used to schedule the garbage
    collector at an earlier date was replaced by a schedule_delayed_work()
    (see commit 86bba269d08f0c545ae76c90b56727f65d62d57f).
    
    But, the behaviour of mod_timer() and schedule_delayed_work() is
    different in the way they handle the delay.
    
    mod_timer() stops the timer and re-arm it with the new given delay,
    whereas schedule_delayed_work() only check if the work is already
    queued in the workqueue (and queue it (with delay) if it is not)
    BUT it does NOT take into account the new delay (even if the new delay
    is earlier in time).
    schedule_delayed_work() returns 0 if it didn't queue the work,
    but we don't check the return code in __dst_free().
    
    If I understand the code in __dst_free() correctly, we want dst_gc_task
    to be queued after DST_GC_INC jiffies if we pass the test (and not in
    some undetermined time in the future), so I think we should add a call
    to cancel_delayed_work() before schedule_delayed_work(). Patch below.
    
    Or we should at least test the return code of schedule_delayed_work(),
    and reset the values of dst_garbage.timer_inc and dst_garbage.timer_expires
    back to their former values if schedule_delayed_work() failed.
    Otherwise the subsequent calls to __dst_free will test the wrong values
    and assume wrong thing about when the garbage collector is supposed to
    be scheduled.
    
    dst_gc_task() also calls schedule_delayed_work() without checking
    its return code (or calling cancel_scheduled_work() first), but it
    should fine there: dst_gc_task is the routine of the delayed_work, so
    no dst_gc_work should be pending in the queue when it's running.
    
    Signed-off-by: Benjamin Thery <benjamin.thery@bull.net>
    Acked-by: Eric Dumazet <dada1@cosmosbay.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index fe03266130b6..09c1530f4681 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -203,6 +203,7 @@ void __dst_free(struct dst_entry * dst)
 	if (dst_garbage.timer_inc > DST_GC_INC) {
 		dst_garbage.timer_inc = DST_GC_INC;
 		dst_garbage.timer_expires = DST_GC_MIN;
+		cancel_delayed_work(&dst_gc_work);
 		schedule_delayed_work(&dst_gc_work, dst_garbage.timer_expires);
 	}
 	spin_unlock_bh(&dst_garbage.lock);

commit 8d3308687f7f1eaa1bb5d202d14752d5f90068eb
Author: Ilpo Jrvinen <ilpo.jarvinen@helsinki.fi>
Date:   Thu Mar 27 17:53:31 2008 -0700

    [NET]: uninline dst_release
    
    Codiff stats (allyesconfig, v2.6.24-mm1):
    -16420  187 funcs, 103 +, 16523 -, diff: -16420 --- dst_release
    
    Without number of debug related CONFIGs (v2.6.25-rc2-mm1):
    -7257  186 funcs, 70 +, 7327 -, diff: -7257 --- dst_release
    dst_release                   |  +40
    
    Signed-off-by: Ilpo Jrvinen <ilpo.jarvinen@helsinki.fi>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index 694cd2a3f6d2..fe03266130b6 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -259,6 +259,16 @@ struct dst_entry *dst_destroy(struct dst_entry * dst)
 	return NULL;
 }
 
+void dst_release(struct dst_entry *dst)
+{
+	if (dst) {
+		WARN_ON(atomic_read(&dst->__refcnt) < 1);
+		smp_mb__before_atomic_dec();
+		atomic_dec(&dst->__refcnt);
+	}
+}
+EXPORT_SYMBOL(dst_release);
+
 /* Dirty hack. We did it in 2.2 (in __dst_free),
  * we have _very_ good reasons not to repeat
  * this mistake in 2.3, but we have no choice

commit c346dca10840a874240c78efe3f39acf4312a1f2
Author: YOSHIFUJI Hideaki <yoshfuji@linux-ipv6.org>
Date:   Tue Mar 25 21:47:49 2008 +0900

    [NET] NETNS: Omit net_device->nd_net without CONFIG_NET_NS.
    
    Introduce per-net_device inlines: dev_net(), dev_net_set().
    Without CONFIG_NET_NS, no namespace other than &init_net exists.
    Let's explicitly define them to help compiler optimizations.
    
    Signed-off-by: YOSHIFUJI Hideaki <yoshfuji@linux-ipv6.org>

diff --git a/net/core/dst.c b/net/core/dst.c
index 3a01a819ba47..694cd2a3f6d2 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -279,7 +279,7 @@ static inline void dst_ifdown(struct dst_entry *dst, struct net_device *dev,
 	if (!unregister) {
 		dst->input = dst->output = dst_discard;
 	} else {
-		dst->dev = dst->dev->nd_net->loopback_dev;
+		dst->dev = dev_net(dst->dev)->loopback_dev;
 		dev_hold(dst->dev);
 		dev_put(dev);
 		if (dst->neighbour && dst->neighbour->dev == dev) {

commit 9de8f76d200342f1e9495861c2c9ce87a6bc26d0
Author: Denis V. Lunev <den@openvz.org>
Date:   Thu Feb 28 20:49:44 2008 -0800

    [NETNS]: DST cleanup routines should be called inside namespace.
    
    Device inside the namespace can be started and downed. So, active routing
    cache should be cleaned up on device stop.
    
    Signed-off-by: Denis V. Lunev <den@openvz.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index 7deef483c79f..3a01a819ba47 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -295,9 +295,6 @@ static int dst_dev_event(struct notifier_block *this, unsigned long event, void
 	struct net_device *dev = ptr;
 	struct dst_entry *dst, *last = NULL;
 
-	if (dev->nd_net != &init_net)
-		return NOTIFY_DONE;
-
 	switch (event) {
 	case NETDEV_UNREGISTER:
 	case NETDEV_DOWN:

commit 569d36452ee26c08523cc9f658901c5188640853
Author: Daniel Lezcano <dlezcano@fr.ibm.com>
Date:   Fri Jan 18 03:56:57 2008 -0800

    [NETNS][DST] dst: pass the dst_ops as parameter to the gc functions
    
    The garbage collection function receive the dst_ops structure as
    parameter. This is useful for the next incoming patchset because it
    will need the dst_ops (there will be several instances) and the
    network namespace pointer (contained in the dst_ops).
    
    The protocols which do not take care of the namespaces will not be
    impacted by this change (expect for the function signature), they do
    just ignore the parameter.
    
    Signed-off-by: Daniel Lezcano <dlezcano@fr.ibm.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index 7eceebaabaaa..7deef483c79f 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -165,7 +165,7 @@ void * dst_alloc(struct dst_ops * ops)
 	struct dst_entry * dst;
 
 	if (ops->gc && atomic_read(&ops->entries) > ops->gc_thresh) {
-		if (ops->gc())
+		if (ops->gc(ops))
 			return NULL;
 	}
 	dst = kmem_cache_zalloc(ops->kmem_cachep, GFP_ATOMIC);

commit 64b7d96167977850f4a24e52dd0a76b03c6542cf
Author: Eric Dumazet <dada1@cosmosbay.com>
Date:   Tue Dec 11 02:00:30 2007 -0800

    [NET]: dst_ifdown() cleanup
    
    This cleanup shrinks size of net/core/dst.o on i386 from 1299 to 1289 bytes.
    (This is because dev_hold()/dev_put() are doing atomic_inc()/atomic_dec() and
    force compiler to re-evaluate memory contents.)
    
    Signed-off-by: Eric Dumazet <dada1@cosmosbay.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index 5c6cfc4e7fdb..7eceebaabaaa 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -284,8 +284,8 @@ static inline void dst_ifdown(struct dst_entry *dst, struct net_device *dev,
 		dev_put(dev);
 		if (dst->neighbour && dst->neighbour->dev == dev) {
 			dst->neighbour->dev = dst->dev;
+			dev_hold(dst->dev);
 			dev_put(dev);
-			dev_hold(dst->neighbour->dev);
 		}
 	}
 }

commit 5a3e55d68ec5baac578bf32ba67607088c763657
Author: Denis V. Lunev <den@openvz.org>
Date:   Fri Dec 7 00:38:10 2007 -0800

    [NET]: Multiple namespaces in the all dst_ifdown routines.
    
    Move dst entries to a namespace loopback to catch refcounting leaks.
    
    Signed-off-by: Denis V. Lunev <den@openvz.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index f538061f4b93..5c6cfc4e7fdb 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -279,11 +279,11 @@ static inline void dst_ifdown(struct dst_entry *dst, struct net_device *dev,
 	if (!unregister) {
 		dst->input = dst->output = dst_discard;
 	} else {
-		dst->dev = init_net.loopback_dev;
+		dst->dev = dst->dev->nd_net->loopback_dev;
 		dev_hold(dst->dev);
 		dev_put(dev);
 		if (dst->neighbour && dst->neighbour->dev == dev) {
-			dst->neighbour->dev = init_net.loopback_dev;
+			dst->neighbour->dev = dst->dev;
 			dev_put(dev);
 			dev_hold(dst->neighbour->dev);
 		}

commit 352e512c32b634768303a43768245a0363cebbe7
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Tue Nov 13 21:34:06 2007 -0800

    [NET]: Eliminate duplicate copies of dst_discard
    
    We have a number of copies of dst_discard scattered around the place
    which all do the same thing, namely free a packet on the input or
    output paths.
    
    This patch deletes all of them except dst_discard and points all the
    users to it.
    
    The only non-trivial bit is decnet where it returns an error.
    However, conceptually this is identical to the blackhole functions
    used in IPv4 and IPv6 which do not return errors.  So they should
    either all return errors or all return zero.  For now I've stuck with
    the majority and picked zero as the return value.
    
    It doesn't really matter in practice since few if any driver would
    react differently depending on a zero return value or NET_RX_DROP.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index 03daead3592a..f538061f4b93 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -153,11 +153,12 @@ static void dst_gc_task(struct work_struct *work)
 #endif
 }
 
-static int dst_discard(struct sk_buff *skb)
+int dst_discard(struct sk_buff *skb)
 {
 	kfree_skb(skb);
 	return 0;
 }
+EXPORT_SYMBOL(dst_discard);
 
 void * dst_alloc(struct dst_ops * ops)
 {

commit 40208d71e0c6b5f912b185e637272b6481fcef3f
Author: Jiri Olsa <olsajiri@gmail.com>
Date:   Wed Nov 7 00:49:04 2007 -0800

    [NET]: Removing duplicit #includes
    
    Removing duplicit #includes for net/
    
    Signed-off-by: Jiri Olsa <olsajiri@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index 16958e64e577..03daead3592a 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -18,7 +18,6 @@
 #include <linux/types.h>
 #include <net/net_namespace.h>
 
-#include <net/net_namespace.h>
 #include <net/dst.h>
 
 /*

commit 2774c7aba6c97a2535be3309a2209770953780b3
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Wed Sep 26 22:10:56 2007 -0700

    [NET]: Make the loopback device per network namespace.
    
    This patch makes loopback_dev per network namespace.  Adding
    code to create a different loopback device for each network
    namespace and adding the code to free a loopback device
    when a network namespace exits.
    
    This patch modifies all users the loopback_dev so they
    access it as init_net.loopback_dev, keeping all of the
    code compiling and working.  A later pass will be needed to
    update the users to use something other than the initial network
    namespace.
    
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index ad5ffa19d809..16958e64e577 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -18,6 +18,7 @@
 #include <linux/types.h>
 #include <net/net_namespace.h>
 
+#include <net/net_namespace.h>
 #include <net/dst.h>
 
 /*
@@ -278,11 +279,11 @@ static inline void dst_ifdown(struct dst_entry *dst, struct net_device *dev,
 	if (!unregister) {
 		dst->input = dst->output = dst_discard;
 	} else {
-		dst->dev = loopback_dev;
+		dst->dev = init_net.loopback_dev;
 		dev_hold(dst->dev);
 		dev_put(dev);
 		if (dst->neighbour && dst->neighbour->dev == dev) {
-			dst->neighbour->dev = loopback_dev;
+			dst->neighbour->dev = init_net.loopback_dev;
 			dev_put(dev);
 			dev_hold(dst->neighbour->dev);
 		}

commit de3cb747ffac5f2a4a6bb156e7e2fd5229e688e5
Author: Daniel Lezcano <dlezcano@fr.ibm.com>
Date:   Tue Sep 25 19:16:28 2007 -0700

    [NET]: Dynamically allocate the loopback device, part 1.
    
    This patch replaces all occurences to the static variable
    loopback_dev to a pointer loopback_dev. That provides the
    mindless, trivial, uninteressting change part for the dynamic
    allocation for the loopback.
    
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>
    Signed-off-by: Daniel Lezcano <dlezcano@fr.ibm.com>
    Acked-By: Kirill Korotaev <dev@sw.ru>
    Acked-by: Benjamin Thery <benjamin.thery@bull.net>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index 38c741ac5d08..ad5ffa19d809 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -278,13 +278,13 @@ static inline void dst_ifdown(struct dst_entry *dst, struct net_device *dev,
 	if (!unregister) {
 		dst->input = dst->output = dst_discard;
 	} else {
-		dst->dev = &loopback_dev;
-		dev_hold(&loopback_dev);
+		dst->dev = loopback_dev;
+		dev_hold(dst->dev);
 		dev_put(dev);
 		if (dst->neighbour && dst->neighbour->dev == dev) {
-			dst->neighbour->dev = &loopback_dev;
+			dst->neighbour->dev = loopback_dev;
 			dev_put(dev);
-			dev_hold(&loopback_dev);
+			dev_hold(dst->neighbour->dev);
 		}
 	}
 }

commit 86bba269d08f0c545ae76c90b56727f65d62d57f
Author: Eric Dumazet <dada1@cosmosbay.com>
Date:   Wed Sep 12 14:29:01 2007 +0200

    [PATCH] NET : convert IP route cache garbage collection from softirq processing to a workqueue
    
    When the periodic IP route cache flush is done (every 600 seconds on
    default configuration), some hosts suffer a lot and eventually trigger
    the "soft lockup" message.
    
    dst_run_gc() is doing a scan of a possibly huge list of dst_entries,
    eventually freeing some (less than 1%) of them, while holding the
    dst_lock spinlock for the whole scan.
    
    Then it rearms a timer to redo the full thing 1/10 s later...
    The slowdown can last one minute or so, depending on how active are
    the tcp sessions.
    
    This second version of the patch converts the processing from a softirq
    based one to a workqueue.
    
    Even if the list of entries in garbage_list is huge, host is still
    responsive to softirqs and can make progress.
    
    Instead of resetting gc timer to 0.1 second if one entry was freed in a
    gc run, we do this if more than 10% of entries were freed.
    
    Before patch :
    
    Aug 16 06:21:37 SRV1 kernel: BUG: soft lockup detected on CPU#0!
    Aug 16 06:21:37 SRV1 kernel:
    Aug 16 06:21:37 SRV1 kernel: Call Trace:
    Aug 16 06:21:37 SRV1 kernel:  <IRQ>  [<ffffffff802286f0>] wake_up_process+0x10/0x20
    Aug 16 06:21:37 SRV1 kernel:  [<ffffffff80251e09>] softlockup_tick+0xe9/0x110
    Aug 16 06:21:37 SRV1 kernel:  [<ffffffff803cd380>] dst_run_gc+0x0/0x140
    Aug 16 06:21:37 SRV1 kernel:  [<ffffffff802376f3>] run_local_timers+0x13/0x20
    Aug 16 06:21:37 SRV1 kernel:  [<ffffffff802379c7>] update_process_times+0x57/0x90
    Aug 16 06:21:37 SRV1 kernel:  [<ffffffff80216034>] smp_local_timer_interrupt+0x34/0x60
    Aug 16 06:21:37 SRV1 kernel:  [<ffffffff802165cc>] smp_apic_timer_interrupt+0x5c/0x80
    Aug 16 06:21:37 SRV1 kernel:  [<ffffffff8020a816>] apic_timer_interrupt+0x66/0x70
    Aug 16 06:21:37 SRV1 kernel:  [<ffffffff803cd3d3>] dst_run_gc+0x53/0x140
    Aug 16 06:21:37 SRV1 kernel:  [<ffffffff803cd3c6>] dst_run_gc+0x46/0x140
    Aug 16 06:21:37 SRV1 kernel:  [<ffffffff80237148>] run_timer_softirq+0x148/0x1c0
    Aug 16 06:21:37 SRV1 kernel:  [<ffffffff8023340c>] __do_softirq+0x6c/0xe0
    Aug 16 06:21:37 SRV1 kernel:  [<ffffffff8020ad6c>] call_softirq+0x1c/0x30
    Aug 16 06:21:37 SRV1 kernel:  <EOI>  [<ffffffff8020cb34>] do_softirq+0x34/0x90
    Aug 16 06:21:37 SRV1 kernel:  [<ffffffff802331cf>] local_bh_enable_ip+0x3f/0x60
    Aug 16 06:21:37 SRV1 kernel:  [<ffffffff80422913>] _spin_unlock_bh+0x13/0x20
    Aug 16 06:21:37 SRV1 kernel:  [<ffffffff803dfde8>] rt_garbage_collect+0x1d8/0x320
    Aug 16 06:21:37 SRV1 kernel:  [<ffffffff803cd4dd>] dst_alloc+0x1d/0xa0
    Aug 16 06:21:37 SRV1 kernel:  [<ffffffff803e1433>] __ip_route_output_key+0x573/0x800
    Aug 16 06:21:37 SRV1 kernel:  [<ffffffff803c02e2>] sock_common_recvmsg+0x32/0x50
    Aug 16 06:21:37 SRV1 kernel:  [<ffffffff803e16dc>] ip_route_output_flow+0x1c/0x60
    Aug 16 06:21:37 SRV1 kernel:  [<ffffffff80400160>] tcp_v4_connect+0x150/0x610
    Aug 16 06:21:37 SRV1 kernel:  [<ffffffff803ebf07>] inet_bind_bucket_create+0x17/0x60
    Aug 16 06:21:37 SRV1 kernel:  [<ffffffff8040cd16>] inet_stream_connect+0xa6/0x2c0
    Aug 16 06:21:37 SRV1 kernel:  [<ffffffff80422981>] _spin_lock_bh+0x11/0x30
    Aug 16 06:21:37 SRV1 kernel:  [<ffffffff803c0bdf>] lock_sock_nested+0xcf/0xe0
    Aug 16 06:21:37 SRV1 kernel:  [<ffffffff80422981>] _spin_lock_bh+0x11/0x30
    Aug 16 06:21:37 SRV1 kernel:  [<ffffffff803be551>] sys_connect+0x71/0xa0
    Aug 16 06:21:37 SRV1 kernel:  [<ffffffff803eee3f>] tcp_setsockopt+0x1f/0x30
    Aug 16 06:21:37 SRV1 kernel:  [<ffffffff803c030f>] sock_common_setsockopt+0xf/0x20
    Aug 16 06:21:37 SRV1 kernel:  [<ffffffff803be4bd>] sys_setsockopt+0x9d/0xc0
    Aug 16 06:21:37 SRV1 kernel:  [<ffffffff8028881e>] sys_ioctl+0x5e/0x80
    Aug 16 06:21:37 SRV1 kernel:  [<ffffffff80209c4e>] system_call+0x7e/0x83
    
    After patch : (RT_CACHE_DEBUG set to 2 to get following traces)
    
    dst_total: 75469 delayed: 74109 work_perf: 141 expires: 150 elapsed: 8092 us
    dst_total: 78725 delayed: 73366 work_perf: 743 expires: 400 elapsed: 8542 us
    dst_total: 86126 delayed: 71844 work_perf: 1522 expires: 775 elapsed: 8849 us
    dst_total: 100173 delayed: 68791 work_perf: 3053 expires: 1256 elapsed: 9748 us
    dst_total: 121798 delayed: 64711 work_perf: 4080 expires: 1997 elapsed: 10146 us
    dst_total: 154522 delayed: 58316 work_perf: 6395 expires: 25 elapsed: 11402 us
    dst_total: 154957 delayed: 58252 work_perf: 64 expires: 150 elapsed: 6148 us
    dst_total: 157377 delayed: 57843 work_perf: 409 expires: 400 elapsed: 6350 us
    dst_total: 163745 delayed: 56679 work_perf: 1164 expires: 775 elapsed: 7051 us
    dst_total: 176577 delayed: 53965 work_perf: 2714 expires: 1389 elapsed: 8120 us
    dst_total: 198993 delayed: 49627 work_perf: 4338 expires: 1997 elapsed: 8909 us
    dst_total: 226638 delayed: 46865 work_perf: 2762 expires: 2748 elapsed: 7351 us
    
    I successfully reduced the IP route cache of many hosts by a four factor
    thanks to this patch. Previously, I had to disable "ip route flush cache"
    to avoid crashes.
    
    Signed-off-by: Eric Dumazet <dada1@cosmosbay.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index 32267a16e01e..38c741ac5d08 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -9,6 +9,7 @@
 #include <linux/errno.h>
 #include <linux/init.h>
 #include <linux/kernel.h>
+#include <linux/workqueue.h>
 #include <linux/mm.h>
 #include <linux/module.h>
 #include <linux/netdevice.h>
@@ -19,50 +20,72 @@
 
 #include <net/dst.h>
 
-/* Locking strategy:
- * 1) Garbage collection state of dead destination cache
- *    entries is protected by dst_lock.
- * 2) GC is run only from BH context, and is the only remover
- *    of entries.
- * 3) Entries are added to the garbage list from both BH
- *    and non-BH context, so local BH disabling is needed.
- * 4) All operations modify state, so a spinlock is used.
+/*
+ * Theory of operations:
+ * 1) We use a list, protected by a spinlock, to add
+ *    new entries from both BH and non-BH context.
+ * 2) In order to keep spinlock held for a small delay,
+ *    we use a second list where are stored long lived
+ *    entries, that are handled by the garbage collect thread
+ *    fired by a workqueue.
+ * 3) This list is guarded by a mutex,
+ *    so that the gc_task and dst_dev_event() can be synchronized.
  */
-static struct dst_entry 	*dst_garbage_list;
 #if RT_CACHE_DEBUG >= 2
 static atomic_t			 dst_total = ATOMIC_INIT(0);
 #endif
-static DEFINE_SPINLOCK(dst_lock);
 
-static unsigned long dst_gc_timer_expires;
-static unsigned long dst_gc_timer_inc = DST_GC_MAX;
-static void dst_run_gc(unsigned long);
+/*
+ * We want to keep lock & list close together
+ * to dirty as few cache lines as possible in __dst_free().
+ * As this is not a very strong hint, we dont force an alignment on SMP.
+ */
+static struct {
+	spinlock_t		lock;
+	struct dst_entry 	*list;
+	unsigned long		timer_inc;
+	unsigned long		timer_expires;
+} dst_garbage = {
+	.lock = __SPIN_LOCK_UNLOCKED(dst_garbage.lock),
+	.timer_inc = DST_GC_MAX,
+};
+static void dst_gc_task(struct work_struct *work);
 static void ___dst_free(struct dst_entry * dst);
 
-static DEFINE_TIMER(dst_gc_timer, dst_run_gc, DST_GC_MIN, 0);
+static DECLARE_DELAYED_WORK(dst_gc_work, dst_gc_task);
 
-static void dst_run_gc(unsigned long dummy)
+static DEFINE_MUTEX(dst_gc_mutex);
+/*
+ * long lived entries are maintained in this list, guarded by dst_gc_mutex
+ */
+static struct dst_entry         *dst_busy_list;
+
+static void dst_gc_task(struct work_struct *work)
 {
 	int    delayed = 0;
-	int    work_performed;
-	struct dst_entry * dst, **dstp;
+	int    work_performed = 0;
+	unsigned long expires = ~0L;
+	struct dst_entry *dst, *next, head;
+	struct dst_entry *last = &head;
+#if RT_CACHE_DEBUG >= 2
+	ktime_t time_start = ktime_get();
+	struct timespec elapsed;
+#endif
 
-	if (!spin_trylock(&dst_lock)) {
-		mod_timer(&dst_gc_timer, jiffies + HZ/10);
-		return;
-	}
+	mutex_lock(&dst_gc_mutex);
+	next = dst_busy_list;
 
-	del_timer(&dst_gc_timer);
-	dstp = &dst_garbage_list;
-	work_performed = 0;
-	while ((dst = *dstp) != NULL) {
-		if (atomic_read(&dst->__refcnt)) {
-			dstp = &dst->next;
+loop:
+	while ((dst = next) != NULL) {
+		next = dst->next;
+		prefetch(&next->next);
+		if (likely(atomic_read(&dst->__refcnt))) {
+			last->next = dst;
+			last = dst;
 			delayed++;
 			continue;
 		}
-		*dstp = dst->next;
-		work_performed = 1;
+		work_performed++;
 
 		dst = dst_destroy(dst);
 		if (dst) {
@@ -78,38 +101,56 @@ static void dst_run_gc(unsigned long dummy)
 				continue;
 
 			___dst_free(dst);
-			dst->next = *dstp;
-			*dstp = dst;
-			dstp = &dst->next;
+			dst->next = next;
+			next = dst;
 		}
 	}
-	if (!dst_garbage_list) {
-		dst_gc_timer_inc = DST_GC_MAX;
-		goto out;
+
+	spin_lock_bh(&dst_garbage.lock);
+	next = dst_garbage.list;
+	if (next) {
+		dst_garbage.list = NULL;
+		spin_unlock_bh(&dst_garbage.lock);
+		goto loop;
 	}
-	if (!work_performed) {
-		if ((dst_gc_timer_expires += dst_gc_timer_inc) > DST_GC_MAX)
-			dst_gc_timer_expires = DST_GC_MAX;
-		dst_gc_timer_inc += DST_GC_INC;
-	} else {
-		dst_gc_timer_inc = DST_GC_INC;
-		dst_gc_timer_expires = DST_GC_MIN;
+	last->next = NULL;
+	dst_busy_list = head.next;
+	if (!dst_busy_list)
+		dst_garbage.timer_inc = DST_GC_MAX;
+	else {
+		/*
+		 * if we freed less than 1/10 of delayed entries,
+		 * we can sleep longer.
+		 */
+		if (work_performed <= delayed/10) {
+			dst_garbage.timer_expires += dst_garbage.timer_inc;
+			if (dst_garbage.timer_expires > DST_GC_MAX)
+				dst_garbage.timer_expires = DST_GC_MAX;
+			dst_garbage.timer_inc += DST_GC_INC;
+		} else {
+			dst_garbage.timer_inc = DST_GC_INC;
+			dst_garbage.timer_expires = DST_GC_MIN;
+		}
+		expires = dst_garbage.timer_expires;
+		/*
+		 * if the next desired timer is more than 4 seconds in the future
+		 * then round the timer to whole seconds
+		 */
+		if (expires > 4*HZ)
+			expires = round_jiffies_relative(expires);
+		schedule_delayed_work(&dst_gc_work, expires);
 	}
+
+	spin_unlock_bh(&dst_garbage.lock);
+	mutex_unlock(&dst_gc_mutex);
 #if RT_CACHE_DEBUG >= 2
-	printk("dst_total: %d/%d %ld\n",
-	       atomic_read(&dst_total), delayed,  dst_gc_timer_expires);
+	elapsed = ktime_to_timespec(ktime_sub(ktime_get(), time_start));
+	printk(KERN_DEBUG "dst_total: %d delayed: %d work_perf: %d"
+		" expires: %lu elapsed: %lu us\n",
+		atomic_read(&dst_total), delayed, work_performed,
+		expires,
+		elapsed.tv_sec * USEC_PER_SEC + elapsed.tv_nsec / NSEC_PER_USEC);
 #endif
-	/* if the next desired timer is more than 4 seconds in the future
-	 * then round the timer to whole seconds
-	 */
-	if (dst_gc_timer_expires > 4*HZ)
-		mod_timer(&dst_gc_timer,
-			round_jiffies(jiffies + dst_gc_timer_expires));
-	else
-		mod_timer(&dst_gc_timer, jiffies + dst_gc_timer_expires);
-
-out:
-	spin_unlock(&dst_lock);
 }
 
 static int dst_discard(struct sk_buff *skb)
@@ -154,16 +195,16 @@ static void ___dst_free(struct dst_entry * dst)
 
 void __dst_free(struct dst_entry * dst)
 {
-	spin_lock_bh(&dst_lock);
+	spin_lock_bh(&dst_garbage.lock);
 	___dst_free(dst);
-	dst->next = dst_garbage_list;
-	dst_garbage_list = dst;
-	if (dst_gc_timer_inc > DST_GC_INC) {
-		dst_gc_timer_inc = DST_GC_INC;
-		dst_gc_timer_expires = DST_GC_MIN;
-		mod_timer(&dst_gc_timer, jiffies + dst_gc_timer_expires);
+	dst->next = dst_garbage.list;
+	dst_garbage.list = dst;
+	if (dst_garbage.timer_inc > DST_GC_INC) {
+		dst_garbage.timer_inc = DST_GC_INC;
+		dst_garbage.timer_expires = DST_GC_MIN;
+		schedule_delayed_work(&dst_gc_work, dst_garbage.timer_expires);
 	}
-	spin_unlock_bh(&dst_lock);
+	spin_unlock_bh(&dst_garbage.lock);
 }
 
 struct dst_entry *dst_destroy(struct dst_entry * dst)
@@ -251,7 +292,7 @@ static inline void dst_ifdown(struct dst_entry *dst, struct net_device *dev,
 static int dst_dev_event(struct notifier_block *this, unsigned long event, void *ptr)
 {
 	struct net_device *dev = ptr;
-	struct dst_entry *dst;
+	struct dst_entry *dst, *last = NULL;
 
 	if (dev->nd_net != &init_net)
 		return NOTIFY_DONE;
@@ -259,11 +300,25 @@ static int dst_dev_event(struct notifier_block *this, unsigned long event, void
 	switch (event) {
 	case NETDEV_UNREGISTER:
 	case NETDEV_DOWN:
-		spin_lock_bh(&dst_lock);
-		for (dst = dst_garbage_list; dst; dst = dst->next) {
+		mutex_lock(&dst_gc_mutex);
+		for (dst = dst_busy_list; dst; dst = dst->next) {
+			last = dst;
+			dst_ifdown(dst, dev, event != NETDEV_DOWN);
+		}
+
+		spin_lock_bh(&dst_garbage.lock);
+		dst = dst_garbage.list;
+		dst_garbage.list = NULL;
+		spin_unlock_bh(&dst_garbage.lock);
+
+		if (last)
+			last->next = dst;
+		else
+			dst_busy_list = dst;
+		for (; dst; dst = dst->next) {
 			dst_ifdown(dst, dev, event != NETDEV_DOWN);
 		}
-		spin_unlock_bh(&dst_lock);
+		mutex_unlock(&dst_gc_mutex);
 		break;
 	}
 	return NOTIFY_DONE;

commit e9dc86534051b78e41e5b746cccc291b57a3a311
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Wed Sep 12 13:02:17 2007 +0200

    [NET]: Make device event notification network namespace safe
    
    Every user of the network device notifiers is either a protocol
    stack or a pseudo device.  If a protocol stack that does not have
    support for multiple network namespaces receives an event for a
    device that is not in the initial network namespace it quite possibly
    can get confused and do the wrong thing.
    
    To avoid problems until all of the protocol stacks are converted
    this patch modifies all netdev event handlers to ignore events on
    devices that are not in the initial network namespace.
    
    As the rest of the code is made network namespace aware these
    checks can be removed.
    
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index c6a05879d58c..32267a16e01e 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -15,6 +15,7 @@
 #include <linux/skbuff.h>
 #include <linux/string.h>
 #include <linux/types.h>
+#include <net/net_namespace.h>
 
 #include <net/dst.h>
 
@@ -252,6 +253,9 @@ static int dst_dev_event(struct notifier_block *this, unsigned long event, void
 	struct net_device *dev = ptr;
 	struct dst_entry *dst;
 
+	if (dev->nd_net != &init_net)
+		return NOTIFY_DONE;
+
 	switch (event) {
 	case NETDEV_UNREGISTER:
 	case NETDEV_DOWN:

commit c4b1010f406d7c3f819c22a6323c46776d5b148c
Author: Denis Cheng <crquan@gmail.com>
Date:   Tue Jun 5 00:06:57 2007 -0700

    [NET]: Merge dst_discard_in and dst_discard_out.
    
    Signed-off-by: Denis Cheng <crquan@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index 764bccb3d992..c6a05879d58c 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -111,13 +111,7 @@ static void dst_run_gc(unsigned long dummy)
 	spin_unlock(&dst_lock);
 }
 
-static int dst_discard_in(struct sk_buff *skb)
-{
-	kfree_skb(skb);
-	return 0;
-}
-
-static int dst_discard_out(struct sk_buff *skb)
+static int dst_discard(struct sk_buff *skb)
 {
 	kfree_skb(skb);
 	return 0;
@@ -138,8 +132,7 @@ void * dst_alloc(struct dst_ops * ops)
 	dst->ops = ops;
 	dst->lastuse = jiffies;
 	dst->path = dst;
-	dst->input = dst_discard_in;
-	dst->output = dst_discard_out;
+	dst->input = dst->output = dst_discard;
 #if RT_CACHE_DEBUG >= 2
 	atomic_inc(&dst_total);
 #endif
@@ -153,8 +146,7 @@ static void ___dst_free(struct dst_entry * dst)
 	   protocol module is unloaded.
 	 */
 	if (dst->dev == NULL || !(dst->dev->flags&IFF_UP)) {
-		dst->input = dst_discard_in;
-		dst->output = dst_discard_out;
+		dst->input = dst->output = dst_discard;
 	}
 	dst->obsolete = 2;
 }
@@ -242,8 +234,7 @@ static inline void dst_ifdown(struct dst_entry *dst, struct net_device *dev,
 		return;
 
 	if (!unregister) {
-		dst->input = dst_discard_in;
-		dst->output = dst_discard_out;
+		dst->input = dst->output = dst_discard;
 	} else {
 		dst->dev = &loopback_dev;
 		dev_hold(&loopback_dev);

commit cd354f1ae75e6466a7e31b727faede57a1f89ca5
Author: Tim Schmielau <tim@physik3.uni-rostock.de>
Date:   Wed Feb 14 00:33:14 2007 -0800

    [PATCH] remove many unneeded #includes of sched.h
    
    After Al Viro (finally) succeeded in removing the sched.h #include in module.h
    recently, it makes sense again to remove other superfluous sched.h includes.
    There are quite a lot of files which include it but don't actually need
    anything defined in there.  Presumably these includes were once needed for
    macros that used to live in sched.h, but moved to other header files in the
    course of cleaning it up.
    
    To ease the pain, this time I did not fiddle with any header files and only
    removed #includes from .c-files, which tend to cause less trouble.
    
    Compile tested against 2.6.20-rc2 and 2.6.20-rc2-mm2 (with offsets) on alpha,
    arm, i386, ia64, mips, powerpc, and x86_64 with allnoconfig, defconfig,
    allmodconfig, and allyesconfig as well as a few randconfigs on x86_64 and all
    configs in arch/arm/configs on arm.  I also checked that no new warnings were
    introduced by the patch (actually, some warnings are removed that were emitted
    by unnecessarily included header files).
    
    Signed-off-by: Tim Schmielau <tim@physik3.uni-rostock.de>
    Acked-by: Russell King <rmk+kernel@arm.linux.org.uk>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/net/core/dst.c b/net/core/dst.c
index 61dd9d3951f1..764bccb3d992 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -12,7 +12,6 @@
 #include <linux/mm.h>
 #include <linux/module.h>
 #include <linux/netdevice.h>
-#include <linux/sched.h>
 #include <linux/skbuff.h>
 #include <linux/string.h>
 #include <linux/types.h>

commit cb18eccff48ef3986d1072964590bce6fec705fb
Merge: c827ba4cb49a 5ef213f68422
Author: Linus Torvalds <torvalds@woody.linux-foundation.org>
Date:   Sun Feb 11 11:38:13 2007 -0800

    Merge master.kernel.org:/pub/scm/linux/kernel/git/davem/net-2.6
    
    * master.kernel.org:/pub/scm/linux/kernel/git/davem/net-2.6: (45 commits)
      [IPV4]: Restore multipath routing after rt_next changes.
      [XFRM] IPV6: Fix outbound RO transformation which is broken by IPsec tunnel patch.
      [NET]: Reorder fields of struct dst_entry
      [DECNET]: Convert decnet route to use the new dst_entry 'next' pointer
      [IPV6]: Convert ipv6 route to use the new dst_entry 'next' pointer
      [IPV4]: Convert ipv4 route to use the new dst_entry 'next' pointer
      [NET]: Introduce union in struct dst_entry to hold 'next' pointer
      [DECNET]: fix misannotation of linkinfo_dn
      [DECNET]: FRA_{DST,SRC} are le16 for decnet
      [UDP]: UDP can use sk_hash to speedup lookups
      [NET]: Fix whitespace errors.
      [NET] XFRM: Fix whitespace errors.
      [NET] X25: Fix whitespace errors.
      [NET] WANROUTER: Fix whitespace errors.
      [NET] UNIX: Fix whitespace errors.
      [NET] TIPC: Fix whitespace errors.
      [NET] SUNRPC: Fix whitespace errors.
      [NET] SCTP: Fix whitespace errors.
      [NET] SCHED: Fix whitespace errors.
      [NET] RXRPC: Fix whitespace errors.
      ...

commit c376222960ae91d5ffb9197ee36771aaed1d9f90
Author: Robert P. J. Day <rpjday@mindspring.com>
Date:   Sat Feb 10 01:45:03 2007 -0800

    [PATCH] Transform kmem_cache_alloc()+memset(0) -> kmem_cache_zalloc().
    
    Replace appropriate pairs of "kmem_cache_alloc()" + "memset(0)" with the
    corresponding "kmem_cache_zalloc()" call.
    
    Signed-off-by: Robert P. J. Day <rpjday@mindspring.com>
    Cc: "Luck, Tony" <tony.luck@intel.com>
    Cc: Andi Kleen <ak@muc.de>
    Cc: Roland McGrath <roland@redhat.com>
    Cc: James Bottomley <James.Bottomley@steeleye.com>
    Cc: Greg KH <greg@kroah.com>
    Acked-by: Joel Becker <Joel.Becker@oracle.com>
    Cc: Steven Whitehouse <swhiteho@redhat.com>
    Cc: Jan Kara <jack@ucw.cz>
    Cc: Michael Halcrow <mhalcrow@us.ibm.com>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Stephen Smalley <sds@tycho.nsa.gov>
    Cc: James Morris <jmorris@namei.org>
    Cc: Chris Wright <chrisw@sous-sol.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/net/core/dst.c b/net/core/dst.c
index 1a53fb39b7e0..f9eace78d354 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -132,10 +132,9 @@ void * dst_alloc(struct dst_ops * ops)
 		if (ops->gc())
 			return NULL;
 	}
-	dst = kmem_cache_alloc(ops->kmem_cachep, GFP_ATOMIC);
+	dst = kmem_cache_zalloc(ops->kmem_cachep, GFP_ATOMIC);
 	if (!dst)
 		return NULL;
-	memset(dst, 0, ops->entry_size);
 	atomic_set(&dst->__refcnt, 0);
 	dst->ops = ops;
 	dst->lastuse = jiffies;

commit 4ec93edb14fe5fdee9fae6335f2cbba204627eac
Author: YOSHIFUJI Hideaki <yoshfuji@linux-ipv6.org>
Date:   Fri Feb 9 23:24:36 2007 +0900

    [NET] CORE: Fix whitespace errors.
    
    Signed-off-by: YOSHIFUJI Hideaki <yoshfuji@linux-ipv6.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index 1a53fb39b7e0..0ab9a981fc6d 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -29,7 +29,7 @@
  * 4) All operations modify state, so a spinlock is used.
  */
 static struct dst_entry 	*dst_garbage_list;
-#if RT_CACHE_DEBUG >= 2 
+#if RT_CACHE_DEBUG >= 2
 static atomic_t			 dst_total = ATOMIC_INIT(0);
 #endif
 static DEFINE_SPINLOCK(dst_lock);
@@ -142,7 +142,7 @@ void * dst_alloc(struct dst_ops * ops)
 	dst->path = dst;
 	dst->input = dst_discard_in;
 	dst->output = dst_discard_out;
-#if RT_CACHE_DEBUG >= 2 
+#if RT_CACHE_DEBUG >= 2
 	atomic_inc(&dst_total);
 #endif
 	atomic_inc(&ops->entries);
@@ -203,7 +203,7 @@ struct dst_entry *dst_destroy(struct dst_entry * dst)
 		dst->ops->destroy(dst);
 	if (dst->dev)
 		dev_put(dst->dev);
-#if RT_CACHE_DEBUG >= 2 
+#if RT_CACHE_DEBUG >= 2
 	atomic_dec(&dst_total);
 #endif
 	kmem_cache_free(dst->ops->kmem_cachep, dst);

commit f5a6e01c093ca60c0cab15c47c8e7e199fbbc9e6
Author: Arjan van de Ven <arjan@linux.intel.com>
Date:   Mon Feb 5 17:59:51 2007 -0800

    [NET]: user of the jiffies rounding code: Networking
    
    This patch introduces users of the round_jiffies() function in the
    networking code.
    
    These timers all were of the "about once a second" or "about once
    every X seconds" variety and several showed up in the "what wakes the
    cpu up" profiles that the tickless patches provide.  Some timers are
    highly dynamic based on network load; but even on low activity systems
    they still show up so the rounding is done only in cases of low
    activity, allowing higher frequency timers in the high activity case.
    
    The various hardware watchdogs are an obvious case; they run every 2
    seconds but aren't otherwise specific of exactly when they need to
    run.
    
    Signed-off-by: Arjan van de Ven <arjan@linux.intel.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index 836ec6606925..1a53fb39b7e0 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -99,7 +99,14 @@ static void dst_run_gc(unsigned long dummy)
 	printk("dst_total: %d/%d %ld\n",
 	       atomic_read(&dst_total), delayed,  dst_gc_timer_expires);
 #endif
-	mod_timer(&dst_gc_timer, jiffies + dst_gc_timer_expires);
+	/* if the next desired timer is more than 4 seconds in the future
+	 * then round the timer to whole seconds
+	 */
+	if (dst_gc_timer_expires > 4*HZ)
+		mod_timer(&dst_gc_timer,
+			round_jiffies(jiffies + dst_gc_timer_expires));
+	else
+		mod_timer(&dst_gc_timer, jiffies + dst_gc_timer_expires);
 
 out:
 	spin_unlock(&dst_lock);

commit 54e6ecb23951b195d02433a741c7f7cb0b796c78
Author: Christoph Lameter <clameter@sgi.com>
Date:   Wed Dec 6 20:33:16 2006 -0800

    [PATCH] slab: remove SLAB_ATOMIC
    
    SLAB_ATOMIC is an alias of GFP_ATOMIC
    
    Signed-off-by: Christoph Lameter <clameter@sgi.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/net/core/dst.c b/net/core/dst.c
index 1a5e49da0e77..836ec6606925 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -125,7 +125,7 @@ void * dst_alloc(struct dst_ops * ops)
 		if (ops->gc())
 			return NULL;
 	}
-	dst = kmem_cache_alloc(ops->kmem_cachep, SLAB_ATOMIC);
+	dst = kmem_cache_alloc(ops->kmem_cachep, GFP_ATOMIC);
 	if (!dst)
 		return NULL;
 	memset(dst, 0, ops->entry_size);

commit 7c91767a6b701543c93ebcd611dab61deff3dad1
Author: Dmitry Mishin <dim@openvz.org>
Date:   Wed Aug 9 02:25:54 2006 -0700

    [NET]: add_timer -> mod_timer() in dst_run_gc()
    
    Patch from Dmitry Mishin <dim@openvz.org>:
    
    Replace add_timer() by mod_timer() in dst_run_gc
    in order to avoid BUG message.
    
           CPU1                            CPU2
    dst_run_gc()  entered           dst_run_gc() entered
    spin_lock(&dst_lock)                   .....
    del_timer(&dst_gc_timer)         fail to get lock
           ....                         mod_timer() <--- puts
                                                     timer back
                                                     to the list
    add_timer(&dst_gc_timer) <--- BUG because timer is in list already.
    
    Found during OpenVZ internal testing.
    
    At first we thought that it is OpenVZ specific as we
    added dst_run_gc(0) call in dst_dev_event(),
    but as Alexey pointed to me it is possible to trigger
    this condition in mainstream kernel.
    
    F.e. timer has fired on CPU2, but the handler was preeempted
    by an irq before dst_lock is tried.
    Meanwhile, someone on CPU1 adds an entry to gc list and
    starts the timer.
    If CPU2 was preempted long enough, this timer can expire
    simultaneously with resuming timer handler on CPU1, arriving
    exactly to the situation described.
    
    Signed-off-by: Dmitry Mishin <dim@openvz.org>
    Signed-off-by: Kirill Korotaev <dev@openvz.org>
    Signed-off-by: Alexey Kuznetsov <kuznet@ms2.inr.ac.ru>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index 470c05bc4cb2..1a5e49da0e77 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -95,12 +95,11 @@ static void dst_run_gc(unsigned long dummy)
 		dst_gc_timer_inc = DST_GC_INC;
 		dst_gc_timer_expires = DST_GC_MIN;
 	}
-	dst_gc_timer.expires = jiffies + dst_gc_timer_expires;
 #if RT_CACHE_DEBUG >= 2
 	printk("dst_total: %d/%d %ld\n",
 	       atomic_read(&dst_total), delayed,  dst_gc_timer_expires);
 #endif
-	add_timer(&dst_gc_timer);
+	mod_timer(&dst_gc_timer, jiffies + dst_gc_timer_expires);
 
 out:
 	spin_unlock(&dst_lock);

commit 8d06afab73a75f40ae2864e6c296356bab1ab473
Author: Ingo Molnar <mingo@elte.hu>
Date:   Fri Sep 9 13:10:40 2005 -0700

    [PATCH] timer initialization cleanup: DEFINE_TIMER
    
    Clean up timer initialization by introducing DEFINE_TIMER a'la
    DEFINE_SPINLOCK.  Build and boot-tested on x86.  A similar patch has been
    been in the -RT tree for some time.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/net/core/dst.c b/net/core/dst.c
index 334790da9f16..470c05bc4cb2 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -39,8 +39,7 @@ static unsigned long dst_gc_timer_inc = DST_GC_MAX;
 static void dst_run_gc(unsigned long);
 static void ___dst_free(struct dst_entry * dst);
 
-static struct timer_list dst_gc_timer =
-	TIMER_INITIALIZER(dst_run_gc, DST_GC_MIN, 0);
+static DEFINE_TIMER(dst_gc_timer, dst_run_gc, DST_GC_MIN, 0);
 
 static void dst_run_gc(unsigned long dummy)
 {

commit f0098f7863f814a5adc0b9cb271605d063cad7fa
Author: Denis Lunev <den@sw.ru>
Date:   Sat Jul 30 17:47:25 2005 -0700

    [NET] Fix too aggressive backoff in dst garbage collection
    
    The bug is evident when it is seen once. dst gc timer was backed off,
    when gc queue is not empty. But this means that timer quickly backs off,
    if at least one destination remains in use. Normally, the bug is invisible,
    because adding new dst entry to queue cancels the backoff. But it shots
    deadly with destination cache overflow when new destinations are not released
    for long time f.e. after an interface goes down.
    
    The fix is to cancel backoff when something was released.
    
    Signed-off-by: Denis Lunev <den@sw.ru>
    Signed-off-by: Alexey Kuznetsov <kuznet@ms2.inr.ac.ru>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/core/dst.c b/net/core/dst.c
index fc434ade5270..334790da9f16 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -45,6 +45,7 @@ static struct timer_list dst_gc_timer =
 static void dst_run_gc(unsigned long dummy)
 {
 	int    delayed = 0;
+	int    work_performed;
 	struct dst_entry * dst, **dstp;
 
 	if (!spin_trylock(&dst_lock)) {
@@ -52,9 +53,9 @@ static void dst_run_gc(unsigned long dummy)
 		return;
 	}
 
-
 	del_timer(&dst_gc_timer);
 	dstp = &dst_garbage_list;
+	work_performed = 0;
 	while ((dst = *dstp) != NULL) {
 		if (atomic_read(&dst->__refcnt)) {
 			dstp = &dst->next;
@@ -62,6 +63,7 @@ static void dst_run_gc(unsigned long dummy)
 			continue;
 		}
 		*dstp = dst->next;
+		work_performed = 1;
 
 		dst = dst_destroy(dst);
 		if (dst) {
@@ -86,9 +88,14 @@ static void dst_run_gc(unsigned long dummy)
 		dst_gc_timer_inc = DST_GC_MAX;
 		goto out;
 	}
-	if ((dst_gc_timer_expires += dst_gc_timer_inc) > DST_GC_MAX)
-		dst_gc_timer_expires = DST_GC_MAX;
-	dst_gc_timer_inc += DST_GC_INC;
+	if (!work_performed) {
+		if ((dst_gc_timer_expires += dst_gc_timer_inc) > DST_GC_MAX)
+			dst_gc_timer_expires = DST_GC_MAX;
+		dst_gc_timer_inc += DST_GC_INC;
+	} else {
+		dst_gc_timer_inc = DST_GC_INC;
+		dst_gc_timer_expires = DST_GC_MIN;
+	}
 	dst_gc_timer.expires = jiffies + dst_gc_timer_expires;
 #if RT_CACHE_DEBUG >= 2
 	printk("dst_total: %d/%d %ld\n",

commit 6775cab98b89b2caa10dce4b07e2c81999e45517
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Sat Apr 16 15:24:10 2005 -0700

    [PATCH] Fix dst_destroy() race
    
    When we are not the real parent of the dst (e.g., when we're xfrm_dst and
    the child is an rtentry), it may already be on the GC list.
    
    In fact the current code is buggy to, we need to check dst->flags before
    the dec as dst may no longer be valid afterwards.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/net/core/dst.c b/net/core/dst.c
index 3bf6cc434814..fc434ade5270 100644
--- a/net/core/dst.c
+++ b/net/core/dst.c
@@ -198,13 +198,15 @@ struct dst_entry *dst_destroy(struct dst_entry * dst)
 
 	dst = child;
 	if (dst) {
+		int nohash = dst->flags & DST_NOHASH;
+
 		if (atomic_dec_and_test(&dst->__refcnt)) {
 			/* We were real parent of this dst, so kill child. */
-			if (dst->flags&DST_NOHASH)
+			if (nohash)
 				goto again;
 		} else {
 			/* Child is still referenced, return it for freeing. */
-			if (dst->flags&DST_NOHASH)
+			if (nohash)
 				return dst;
 			/* Child is still in his hash table */
 		}

commit 1da177e4c3f41524e886b7f1b8a0c1fc7321cac2
Author: Linus Torvalds <torvalds@ppc970.osdl.org>
Date:   Sat Apr 16 15:20:36 2005 -0700

    Linux-2.6.12-rc2
    
    Initial git repository build. I'm not bothering with the full history,
    even though we have it. We can create a separate "historical" git
    archive of that later if we want to, and in the meantime it's about
    3.2GB when imported into git - space that would just make the early
    git days unnecessarily complicated, when we don't have a lot of good
    infrastructure for it.
    
    Let it rip!

diff --git a/net/core/dst.c b/net/core/dst.c
new file mode 100644
index 000000000000..3bf6cc434814
--- /dev/null
+++ b/net/core/dst.c
@@ -0,0 +1,276 @@
+/*
+ * net/core/dst.c	Protocol independent destination cache.
+ *
+ * Authors:		Alexey Kuznetsov, <kuznet@ms2.inr.ac.ru>
+ *
+ */
+
+#include <linux/bitops.h>
+#include <linux/errno.h>
+#include <linux/init.h>
+#include <linux/kernel.h>
+#include <linux/mm.h>
+#include <linux/module.h>
+#include <linux/netdevice.h>
+#include <linux/sched.h>
+#include <linux/skbuff.h>
+#include <linux/string.h>
+#include <linux/types.h>
+
+#include <net/dst.h>
+
+/* Locking strategy:
+ * 1) Garbage collection state of dead destination cache
+ *    entries is protected by dst_lock.
+ * 2) GC is run only from BH context, and is the only remover
+ *    of entries.
+ * 3) Entries are added to the garbage list from both BH
+ *    and non-BH context, so local BH disabling is needed.
+ * 4) All operations modify state, so a spinlock is used.
+ */
+static struct dst_entry 	*dst_garbage_list;
+#if RT_CACHE_DEBUG >= 2 
+static atomic_t			 dst_total = ATOMIC_INIT(0);
+#endif
+static DEFINE_SPINLOCK(dst_lock);
+
+static unsigned long dst_gc_timer_expires;
+static unsigned long dst_gc_timer_inc = DST_GC_MAX;
+static void dst_run_gc(unsigned long);
+static void ___dst_free(struct dst_entry * dst);
+
+static struct timer_list dst_gc_timer =
+	TIMER_INITIALIZER(dst_run_gc, DST_GC_MIN, 0);
+
+static void dst_run_gc(unsigned long dummy)
+{
+	int    delayed = 0;
+	struct dst_entry * dst, **dstp;
+
+	if (!spin_trylock(&dst_lock)) {
+		mod_timer(&dst_gc_timer, jiffies + HZ/10);
+		return;
+	}
+
+
+	del_timer(&dst_gc_timer);
+	dstp = &dst_garbage_list;
+	while ((dst = *dstp) != NULL) {
+		if (atomic_read(&dst->__refcnt)) {
+			dstp = &dst->next;
+			delayed++;
+			continue;
+		}
+		*dstp = dst->next;
+
+		dst = dst_destroy(dst);
+		if (dst) {
+			/* NOHASH and still referenced. Unless it is already
+			 * on gc list, invalidate it and add to gc list.
+			 *
+			 * Note: this is temporary. Actually, NOHASH dst's
+			 * must be obsoleted when parent is obsoleted.
+			 * But we do not have state "obsoleted, but
+			 * referenced by parent", so it is right.
+			 */
+			if (dst->obsolete > 1)
+				continue;
+
+			___dst_free(dst);
+			dst->next = *dstp;
+			*dstp = dst;
+			dstp = &dst->next;
+		}
+	}
+	if (!dst_garbage_list) {
+		dst_gc_timer_inc = DST_GC_MAX;
+		goto out;
+	}
+	if ((dst_gc_timer_expires += dst_gc_timer_inc) > DST_GC_MAX)
+		dst_gc_timer_expires = DST_GC_MAX;
+	dst_gc_timer_inc += DST_GC_INC;
+	dst_gc_timer.expires = jiffies + dst_gc_timer_expires;
+#if RT_CACHE_DEBUG >= 2
+	printk("dst_total: %d/%d %ld\n",
+	       atomic_read(&dst_total), delayed,  dst_gc_timer_expires);
+#endif
+	add_timer(&dst_gc_timer);
+
+out:
+	spin_unlock(&dst_lock);
+}
+
+static int dst_discard_in(struct sk_buff *skb)
+{
+	kfree_skb(skb);
+	return 0;
+}
+
+static int dst_discard_out(struct sk_buff *skb)
+{
+	kfree_skb(skb);
+	return 0;
+}
+
+void * dst_alloc(struct dst_ops * ops)
+{
+	struct dst_entry * dst;
+
+	if (ops->gc && atomic_read(&ops->entries) > ops->gc_thresh) {
+		if (ops->gc())
+			return NULL;
+	}
+	dst = kmem_cache_alloc(ops->kmem_cachep, SLAB_ATOMIC);
+	if (!dst)
+		return NULL;
+	memset(dst, 0, ops->entry_size);
+	atomic_set(&dst->__refcnt, 0);
+	dst->ops = ops;
+	dst->lastuse = jiffies;
+	dst->path = dst;
+	dst->input = dst_discard_in;
+	dst->output = dst_discard_out;
+#if RT_CACHE_DEBUG >= 2 
+	atomic_inc(&dst_total);
+#endif
+	atomic_inc(&ops->entries);
+	return dst;
+}
+
+static void ___dst_free(struct dst_entry * dst)
+{
+	/* The first case (dev==NULL) is required, when
+	   protocol module is unloaded.
+	 */
+	if (dst->dev == NULL || !(dst->dev->flags&IFF_UP)) {
+		dst->input = dst_discard_in;
+		dst->output = dst_discard_out;
+	}
+	dst->obsolete = 2;
+}
+
+void __dst_free(struct dst_entry * dst)
+{
+	spin_lock_bh(&dst_lock);
+	___dst_free(dst);
+	dst->next = dst_garbage_list;
+	dst_garbage_list = dst;
+	if (dst_gc_timer_inc > DST_GC_INC) {
+		dst_gc_timer_inc = DST_GC_INC;
+		dst_gc_timer_expires = DST_GC_MIN;
+		mod_timer(&dst_gc_timer, jiffies + dst_gc_timer_expires);
+	}
+	spin_unlock_bh(&dst_lock);
+}
+
+struct dst_entry *dst_destroy(struct dst_entry * dst)
+{
+	struct dst_entry *child;
+	struct neighbour *neigh;
+	struct hh_cache *hh;
+
+	smp_rmb();
+
+again:
+	neigh = dst->neighbour;
+	hh = dst->hh;
+	child = dst->child;
+
+	dst->hh = NULL;
+	if (hh && atomic_dec_and_test(&hh->hh_refcnt))
+		kfree(hh);
+
+	if (neigh) {
+		dst->neighbour = NULL;
+		neigh_release(neigh);
+	}
+
+	atomic_dec(&dst->ops->entries);
+
+	if (dst->ops->destroy)
+		dst->ops->destroy(dst);
+	if (dst->dev)
+		dev_put(dst->dev);
+#if RT_CACHE_DEBUG >= 2 
+	atomic_dec(&dst_total);
+#endif
+	kmem_cache_free(dst->ops->kmem_cachep, dst);
+
+	dst = child;
+	if (dst) {
+		if (atomic_dec_and_test(&dst->__refcnt)) {
+			/* We were real parent of this dst, so kill child. */
+			if (dst->flags&DST_NOHASH)
+				goto again;
+		} else {
+			/* Child is still referenced, return it for freeing. */
+			if (dst->flags&DST_NOHASH)
+				return dst;
+			/* Child is still in his hash table */
+		}
+	}
+	return NULL;
+}
+
+/* Dirty hack. We did it in 2.2 (in __dst_free),
+ * we have _very_ good reasons not to repeat
+ * this mistake in 2.3, but we have no choice
+ * now. _It_ _is_ _explicit_ _deliberate_
+ * _race_ _condition_.
+ *
+ * Commented and originally written by Alexey.
+ */
+static inline void dst_ifdown(struct dst_entry *dst, struct net_device *dev,
+			      int unregister)
+{
+	if (dst->ops->ifdown)
+		dst->ops->ifdown(dst, dev, unregister);
+
+	if (dev != dst->dev)
+		return;
+
+	if (!unregister) {
+		dst->input = dst_discard_in;
+		dst->output = dst_discard_out;
+	} else {
+		dst->dev = &loopback_dev;
+		dev_hold(&loopback_dev);
+		dev_put(dev);
+		if (dst->neighbour && dst->neighbour->dev == dev) {
+			dst->neighbour->dev = &loopback_dev;
+			dev_put(dev);
+			dev_hold(&loopback_dev);
+		}
+	}
+}
+
+static int dst_dev_event(struct notifier_block *this, unsigned long event, void *ptr)
+{
+	struct net_device *dev = ptr;
+	struct dst_entry *dst;
+
+	switch (event) {
+	case NETDEV_UNREGISTER:
+	case NETDEV_DOWN:
+		spin_lock_bh(&dst_lock);
+		for (dst = dst_garbage_list; dst; dst = dst->next) {
+			dst_ifdown(dst, dev, event != NETDEV_DOWN);
+		}
+		spin_unlock_bh(&dst_lock);
+		break;
+	}
+	return NOTIFY_DONE;
+}
+
+static struct notifier_block dst_dev_notifier = {
+	.notifier_call	= dst_dev_event,
+};
+
+void __init dst_init(void)
+{
+	register_netdevice_notifier(&dst_dev_notifier);
+}
+
+EXPORT_SYMBOL(__dst_free);
+EXPORT_SYMBOL(dst_alloc);
+EXPORT_SYMBOL(dst_destroy);
