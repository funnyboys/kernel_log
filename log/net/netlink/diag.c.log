commit 09c434b8a0047c69e48499de0107de312901e798
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sun May 19 13:08:20 2019 +0100

    treewide: Add SPDX license identifier for more missed files
    
    Add SPDX license identifiers to all files which:
    
     - Have no license information of any form
    
     - Have MODULE_LICENCE("GPL*") inside which was used in the initial
       scan/conversion to ignore the file
    
    These files fall under the project license, GPL v2 only. The resulting SPDX
    license identifier is:
    
      GPL-2.0-only
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/net/netlink/diag.c b/net/netlink/diag.c
index 7dda33b9b784..c6255eac305c 100644
--- a/net/netlink/diag.c
+++ b/net/netlink/diag.c
@@ -1,3 +1,4 @@
+// SPDX-License-Identifier: GPL-2.0-only
 #include <linux/module.h>
 
 #include <net/sock.h>

commit 97a6ec4ac021f7fbec05c15a3aa0c4aaf0461af5
Author: Tom Herbert <tom@quantonium.net>
Date:   Mon Dec 4 10:31:41 2017 -0800

    rhashtable: Change rhashtable_walk_start to return void
    
    Most callers of rhashtable_walk_start don't care about a resize event
    which is indicated by a return value of -EAGAIN. So calls to
    rhashtable_walk_start are wrapped wih code to ignore -EAGAIN. Something
    like this is common:
    
           ret = rhashtable_walk_start(rhiter);
           if (ret && ret != -EAGAIN)
                   goto out;
    
    Since zero and -EAGAIN are the only possible return values from the
    function this check is pointless. The condition never evaluates to true.
    
    This patch changes rhashtable_walk_start to return void. This simplifies
    code for the callers that ignore -EAGAIN. For the few cases where the
    caller cares about the resize event, particularly where the table can be
    walked in mulitple parts for netlink or seq file dump, the function
    rhashtable_walk_start_check has been added that returns -EAGAIN on a
    resize event.
    
    Signed-off-by: Tom Herbert <tom@quantonium.net>
    Acked-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/netlink/diag.c b/net/netlink/diag.c
index 8faa20b4d457..7dda33b9b784 100644
--- a/net/netlink/diag.c
+++ b/net/netlink/diag.c
@@ -115,11 +115,7 @@ static int __netlink_diag_dump(struct sk_buff *skb, struct netlink_callback *cb,
 	if (!s_num)
 		rhashtable_walk_enter(&tbl->hash, hti);
 
-	ret = rhashtable_walk_start(hti);
-	if (ret == -EAGAIN)
-		ret = 0;
-	if (ret)
-		goto stop;
+	rhashtable_walk_start(hti);
 
 	while ((nlsk = rhashtable_walk_next(hti))) {
 		if (IS_ERR(nlsk)) {
@@ -146,8 +142,8 @@ static int __netlink_diag_dump(struct sk_buff *skb, struct netlink_callback *cb,
 		}
 	}
 
-stop:
 	rhashtable_walk_stop(hti);
+
 	if (ret)
 		goto done;
 

commit 457c79e54487b076cafa0e1ec5f177e751c54087
Author: Andrey Vagin <avagin@openvz.org>
Date:   Mon Apr 3 18:13:32 2017 -0700

    netlink/diag: report flags for netlink sockets
    
    cb_running is reported in /proc/self/net/netlink and it is reported by
    the ss tool, when it gets information from the proc files.
    
    sock_diag is a new interface which is used instead of proc files, so it
    looks reasonable that this interface has to report no less information
    about sockets than proc files.
    
    We use these flags to dump and restore netlink sockets.
    
    Signed-off-by: Andrei Vagin <avagin@openvz.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/netlink/diag.c b/net/netlink/diag.c
index a5546249fb10..8faa20b4d457 100644
--- a/net/netlink/diag.c
+++ b/net/netlink/diag.c
@@ -19,6 +19,27 @@ static int sk_diag_dump_groups(struct sock *sk, struct sk_buff *nlskb)
 		       nlk->groups);
 }
 
+static int sk_diag_put_flags(struct sock *sk, struct sk_buff *skb)
+{
+	struct netlink_sock *nlk = nlk_sk(sk);
+	u32 flags = 0;
+
+	if (nlk->cb_running)
+		flags |= NDIAG_FLAG_CB_RUNNING;
+	if (nlk->flags & NETLINK_F_RECV_PKTINFO)
+		flags |= NDIAG_FLAG_PKTINFO;
+	if (nlk->flags & NETLINK_F_BROADCAST_SEND_ERROR)
+		flags |= NDIAG_FLAG_BROADCAST_ERROR;
+	if (nlk->flags & NETLINK_F_RECV_NO_ENOBUFS)
+		flags |= NDIAG_FLAG_NO_ENOBUFS;
+	if (nlk->flags & NETLINK_F_LISTEN_ALL_NSID)
+		flags |= NDIAG_FLAG_LISTEN_ALL_NSID;
+	if (nlk->flags & NETLINK_F_CAP_ACK)
+		flags |= NDIAG_FLAG_CAP_ACK;
+
+	return nla_put_u32(skb, NETLINK_DIAG_FLAGS, flags);
+}
+
 static int sk_diag_fill(struct sock *sk, struct sk_buff *skb,
 			struct netlink_diag_req *req,
 			u32 portid, u32 seq, u32 flags, int sk_ino)
@@ -52,6 +73,10 @@ static int sk_diag_fill(struct sock *sk, struct sk_buff *skb,
 	    sock_diag_put_meminfo(sk, skb, NETLINK_DIAG_MEMINFO))
 		goto out_nlmsg_trim;
 
+	if ((req->ndiag_show & NDIAG_SHOW_FLAGS) &&
+	    sk_diag_put_flags(sk, skb))
+		goto out_nlmsg_trim;
+
 	nlmsg_end(skb, nlh);
 	return 0;
 

commit 93636d1f1f162ae89ae4f2a22a83bf4fd960724e
Author: Eric Dumazet <edumazet@google.com>
Date:   Wed Nov 2 20:21:20 2016 -0700

    netlink: netlink_diag_dump() runs without locks
    
    A recent commit removed locking from netlink_diag_dump() but forgot
    one error case.
    
    =====================================
    [ BUG: bad unlock balance detected! ]
    4.9.0-rc3+ #336 Not tainted
    -------------------------------------
    syz-executor/4018 is trying to release lock ([   36.220068] nl_table_lock
    ) at:
    [<ffffffff82dc8683>] netlink_diag_dump+0x1a3/0x250 net/netlink/diag.c:182
    but there are no more locks to release!
    
    other info that might help us debug this:
    3 locks held by syz-executor/4018:
     #0: [   36.220068]  (
    sock_diag_mutex[   36.220068] ){+.+.+.}
    , at: [   36.220068] [<ffffffff82c3873b>] sock_diag_rcv+0x1b/0x40
     #1: [   36.220068]  (
    sock_diag_table_mutex[   36.220068] ){+.+.+.}
    , at: [   36.220068] [<ffffffff82c38e00>] sock_diag_rcv_msg+0x140/0x3a0
     #2: [   36.220068]  (
    nlk->cb_mutex[   36.220068] ){+.+.+.}
    , at: [   36.220068] [<ffffffff82db6600>] netlink_dump+0x50/0xac0
    
    stack backtrace:
    CPU: 1 PID: 4018 Comm: syz-executor Not tainted 4.9.0-rc3+ #336
    Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS Bochs 01/01/2011
     ffff8800645df688 ffffffff81b46934 ffffffff84eb3e78 ffff88006ad85800
     ffffffff82dc8683 ffffffff84eb3e78 ffff8800645df6b8 ffffffff812043ca
     dffffc0000000000 ffff88006ad85ff8 ffff88006ad85fd0 00000000ffffffff
    Call Trace:
     [<     inline     >] __dump_stack lib/dump_stack.c:15
     [<ffffffff81b46934>] dump_stack+0xb3/0x10f lib/dump_stack.c:51
     [<ffffffff812043ca>] print_unlock_imbalance_bug+0x17a/0x1a0
    kernel/locking/lockdep.c:3388
     [<     inline     >] __lock_release kernel/locking/lockdep.c:3512
     [<ffffffff8120cfd8>] lock_release+0x8e8/0xc60 kernel/locking/lockdep.c:3765
     [<     inline     >] __raw_read_unlock ./include/linux/rwlock_api_smp.h:225
     [<ffffffff83fc001a>] _raw_read_unlock+0x1a/0x30 kernel/locking/spinlock.c:255
     [<ffffffff82dc8683>] netlink_diag_dump+0x1a3/0x250 net/netlink/diag.c:182
     [<ffffffff82db6947>] netlink_dump+0x397/0xac0 net/netlink/af_netlink.c:2110
    
    Fixes: ad202074320c ("netlink: Use rhashtable walk interface in diag dump")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: Andrey Konovalov <andreyknvl@google.com>
    Tested-by: Andrey Konovalov <andreyknvl@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/netlink/diag.c b/net/netlink/diag.c
index b2f0e986a6f4..a5546249fb10 100644
--- a/net/netlink/diag.c
+++ b/net/netlink/diag.c
@@ -178,11 +178,8 @@ static int netlink_diag_dump(struct sk_buff *skb, struct netlink_callback *cb)
 		}
 		cb->args[1] = i;
 	} else {
-		if (req->sdiag_protocol >= MAX_LINKS) {
-			read_unlock(&nl_table_lock);
-			rcu_read_unlock();
+		if (req->sdiag_protocol >= MAX_LINKS)
 			return -ENOENT;
-		}
 
 		err = __netlink_diag_dump(skb, cb, req->sdiag_protocol, s_num);
 	}

commit 733ade23de1b72c1f11c5e4a1a9020a6f48decd2
Author: Andrey Vagin <avagin@openvz.org>
Date:   Tue Sep 6 21:31:17 2016 -0700

    netlink: don't forget to release a rhashtable_iter structure
    
    This bug was detected by kmemleak:
    unreferenced object 0xffff8804269cc3c0 (size 64):
      comm "criu", pid 1042, jiffies 4294907360 (age 13.713s)
      hex dump (first 32 bytes):
        a0 32 cc 2c 04 88 ff ff 00 00 00 00 00 00 00 00  .2.,............
        00 01 00 00 00 00 ad de 00 02 00 00 00 00 ad de  ................
      backtrace:
        [<ffffffff8184dffa>] kmemleak_alloc+0x4a/0xa0
        [<ffffffff8124720f>] kmem_cache_alloc_trace+0x10f/0x280
        [<ffffffffa02864cc>] __netlink_diag_dump+0x26c/0x290 [netlink_diag]
    
    v2: don't remove a reference on a rhashtable_iter structure to
        release it from netlink_diag_dump_done
    
    Cc: Herbert Xu <herbert@gondor.apana.org.au>
    Fixes: ad202074320c ("netlink: Use rhashtable walk interface in diag dump")
    Signed-off-by: Andrei Vagin <avagin@openvz.org>
    Acked-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/netlink/diag.c b/net/netlink/diag.c
index 3e3e2534478a..b2f0e986a6f4 100644
--- a/net/netlink/diag.c
+++ b/net/netlink/diag.c
@@ -127,7 +127,6 @@ static int __netlink_diag_dump(struct sk_buff *skb, struct netlink_callback *cb,
 		goto done;
 
 	rhashtable_walk_exit(hti);
-	cb->args[2] = 0;
 	num++;
 
 mc_list:

commit ad202074320cd75b31b8cdb58cca0d4ef6aaea8a
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Fri Aug 19 16:21:37 2016 +0800

    netlink: Use rhashtable walk interface in diag dump
    
    This patch converts the diag dumping code to use the rhashtable
    walk code instead of going through rhashtable by hand.  The lock
    nl_table_lock is now only taken while we process the multicast
    list as it's not needed for the rhashtable walk.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/netlink/diag.c b/net/netlink/diag.c
index 8dd836a8dd60..3e3e2534478a 100644
--- a/net/netlink/diag.c
+++ b/net/netlink/diag.c
@@ -63,43 +63,75 @@ static int sk_diag_fill(struct sock *sk, struct sk_buff *skb,
 static int __netlink_diag_dump(struct sk_buff *skb, struct netlink_callback *cb,
 				int protocol, int s_num)
 {
+	struct rhashtable_iter *hti = (void *)cb->args[2];
 	struct netlink_table *tbl = &nl_table[protocol];
-	struct rhashtable *ht = &tbl->hash;
-	const struct bucket_table *htbl = rht_dereference_rcu(ht->tbl, ht);
 	struct net *net = sock_net(skb->sk);
 	struct netlink_diag_req *req;
 	struct netlink_sock *nlsk;
 	struct sock *sk;
-	int ret = 0, num = 0, i;
+	int num = 2;
+	int ret = 0;
 
 	req = nlmsg_data(cb->nlh);
 
-	for (i = 0; i < htbl->size; i++) {
-		struct rhash_head *pos;
+	if (s_num > 1)
+		goto mc_list;
 
-		rht_for_each_entry_rcu(nlsk, pos, htbl, i, node) {
-			sk = (struct sock *)nlsk;
+	num--;
 
-			if (!net_eq(sock_net(sk), net))
-				continue;
-			if (num < s_num) {
-				num++;
+	if (!hti) {
+		hti = kmalloc(sizeof(*hti), GFP_KERNEL);
+		if (!hti)
+			return -ENOMEM;
+
+		cb->args[2] = (long)hti;
+	}
+
+	if (!s_num)
+		rhashtable_walk_enter(&tbl->hash, hti);
+
+	ret = rhashtable_walk_start(hti);
+	if (ret == -EAGAIN)
+		ret = 0;
+	if (ret)
+		goto stop;
+
+	while ((nlsk = rhashtable_walk_next(hti))) {
+		if (IS_ERR(nlsk)) {
+			ret = PTR_ERR(nlsk);
+			if (ret == -EAGAIN) {
+				ret = 0;
 				continue;
 			}
+			break;
+		}
 
-			if (sk_diag_fill(sk, skb, req,
-					 NETLINK_CB(cb->skb).portid,
-					 cb->nlh->nlmsg_seq,
-					 NLM_F_MULTI,
-					 sock_i_ino(sk)) < 0) {
-				ret = 1;
-				goto done;
-			}
+		sk = (struct sock *)nlsk;
 
-			num++;
+		if (!net_eq(sock_net(sk), net))
+			continue;
+
+		if (sk_diag_fill(sk, skb, req,
+				 NETLINK_CB(cb->skb).portid,
+				 cb->nlh->nlmsg_seq,
+				 NLM_F_MULTI,
+				 sock_i_ino(sk)) < 0) {
+			ret = 1;
+			break;
 		}
 	}
 
+stop:
+	rhashtable_walk_stop(hti);
+	if (ret)
+		goto done;
+
+	rhashtable_walk_exit(hti);
+	cb->args[2] = 0;
+	num++;
+
+mc_list:
+	read_lock(&nl_table_lock);
 	sk_for_each_bound(sk, &tbl->mc_list) {
 		if (sk_hashed(sk))
 			continue;
@@ -116,13 +148,14 @@ static int __netlink_diag_dump(struct sk_buff *skb, struct netlink_callback *cb,
 				 NLM_F_MULTI,
 				 sock_i_ino(sk)) < 0) {
 			ret = 1;
-			goto done;
+			break;
 		}
 		num++;
 	}
+	read_unlock(&nl_table_lock);
+
 done:
 	cb->args[0] = num;
-	cb->args[1] = protocol;
 
 	return ret;
 }
@@ -131,20 +164,20 @@ static int netlink_diag_dump(struct sk_buff *skb, struct netlink_callback *cb)
 {
 	struct netlink_diag_req *req;
 	int s_num = cb->args[0];
+	int err = 0;
 
 	req = nlmsg_data(cb->nlh);
 
-	rcu_read_lock();
-	read_lock(&nl_table_lock);
-
 	if (req->sdiag_protocol == NDIAG_PROTO_ALL) {
 		int i;
 
 		for (i = cb->args[1]; i < MAX_LINKS; i++) {
-			if (__netlink_diag_dump(skb, cb, i, s_num))
+			err = __netlink_diag_dump(skb, cb, i, s_num);
+			if (err)
 				break;
 			s_num = 0;
 		}
+		cb->args[1] = i;
 	} else {
 		if (req->sdiag_protocol >= MAX_LINKS) {
 			read_unlock(&nl_table_lock);
@@ -152,13 +185,22 @@ static int netlink_diag_dump(struct sk_buff *skb, struct netlink_callback *cb)
 			return -ENOENT;
 		}
 
-		__netlink_diag_dump(skb, cb, req->sdiag_protocol, s_num);
+		err = __netlink_diag_dump(skb, cb, req->sdiag_protocol, s_num);
 	}
 
-	read_unlock(&nl_table_lock);
-	rcu_read_unlock();
+	return err < 0 ? err : skb->len;
+}
+
+static int netlink_diag_dump_done(struct netlink_callback *cb)
+{
+	struct rhashtable_iter *hti = (void *)cb->args[2];
+
+	if (cb->args[0] == 1)
+		rhashtable_walk_exit(hti);
 
-	return skb->len;
+	kfree(hti);
+
+	return 0;
 }
 
 static int netlink_diag_handler_dump(struct sk_buff *skb, struct nlmsghdr *h)
@@ -172,6 +214,7 @@ static int netlink_diag_handler_dump(struct sk_buff *skb, struct nlmsghdr *h)
 	if (h->nlmsg_flags & NLM_F_DUMP) {
 		struct netlink_dump_control c = {
 			.dump = netlink_diag_dump,
+			.done = netlink_diag_dump_done,
 		};
 		return netlink_dump_start(net->diag_nlsk, skb, h, &c);
 	} else

commit d1b4c689d4130bcfd3532680b64db562300716b6
Author: Florian Westphal <fw@strlen.de>
Date:   Thu Feb 18 15:03:24 2016 +0100

    netlink: remove mmapped netlink support
    
    mmapped netlink has a number of unresolved issues:
    
    - TX zerocopy support had to be disabled more than a year ago via
      commit 4682a0358639b29cf ("netlink: Always copy on mmap TX.")
      because the content of the mmapped area can change after netlink
      attribute validation but before message processing.
    
    - RX support was implemented mainly to speed up nfqueue dumping packet
      payload to userspace.  However, since commit ae08ce0021087a5d812d2
      ("netfilter: nfnetlink_queue: zero copy support") we avoid one copy
      with the socket-based interface too (via the skb_zerocopy helper).
    
    The other problem is that skbs attached to mmaped netlink socket
    behave different from normal skbs:
    
    - they don't have a shinfo area, so all functions that use skb_shinfo()
    (e.g. skb_clone) cannot be used.
    
    - reserving headroom prevents userspace from seeing the content as
    it expects message to start at skb->head.
    See for instance
    commit aa3a022094fa ("netlink: not trim skb for mmaped socket when dump").
    
    - skbs handed e.g. to netlink_ack must have non-NULL skb->sk, else we
    crash because it needs the sk to check if a tx ring is attached.
    
    Also not obvious, leads to non-intuitive bug fixes such as 7c7bdf359
    ("netfilter: nfnetlink: use original skbuff when acking batches").
    
    mmaped netlink also didn't play nicely with the skb_zerocopy helper
    used by nfqueue and openvswitch.  Daniel Borkmann fixed this via
    commit 6bb0fef489f6 ("netlink, mmap: fix edge-case leakages in nf queue
    zero-copy")' but at the cost of also needing to provide remaining
    length to the allocation function.
    
    nfqueue also has problems when used with mmaped rx netlink:
    - mmaped netlink doesn't allow use of nfqueue batch verdict messages.
      Problem is that in the mmap case, the allocation time also determines
      the ordering in which the frame will be seen by userspace (A
      allocating before B means that A is located in earlier ring slot,
      but this also means that B might get a lower sequence number then A
      since seqno is decided later.  To fix this we would need to extend the
      spinlocked region to also cover the allocation and message setup which
      isn't desirable.
    - nfqueue can now be configured to queue large (GSO) skbs to userspace.
      Queing GSO packets is faster than having to force a software segmentation
      in the kernel, so this is a desirable option.  However, with a mmap based
      ring one has to use 64kb per ring slot element, else mmap has to fall back
      to the socket path (NL_MMAP_STATUS_COPY) for all large packets.
    
    To use the mmap interface, userspace not only has to probe for mmap netlink
    support, it also has to implement a recv/socket receive path in order to
    handle messages that exceed the size of an rx ring element.
    
    Cc: Daniel Borkmann <daniel@iogearbox.net>
    Cc: Ken-ichirou MATSUZAWA <chamaken@gmail.com>
    Cc: Pablo Neira Ayuso <pablo@netfilter.org>
    Cc: Patrick McHardy <kaber@trash.net>
    Cc: Thomas Graf <tgraf@suug.ch>
    Signed-off-by: Florian Westphal <fw@strlen.de>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/netlink/diag.c b/net/netlink/diag.c
index 3ee63a3cff30..8dd836a8dd60 100644
--- a/net/netlink/diag.c
+++ b/net/netlink/diag.c
@@ -8,41 +8,6 @@
 
 #include "af_netlink.h"
 
-#ifdef CONFIG_NETLINK_MMAP
-static int sk_diag_put_ring(struct netlink_ring *ring, int nl_type,
-			    struct sk_buff *nlskb)
-{
-	struct netlink_diag_ring ndr;
-
-	ndr.ndr_block_size = ring->pg_vec_pages << PAGE_SHIFT;
-	ndr.ndr_block_nr   = ring->pg_vec_len;
-	ndr.ndr_frame_size = ring->frame_size;
-	ndr.ndr_frame_nr   = ring->frame_max + 1;
-
-	return nla_put(nlskb, nl_type, sizeof(ndr), &ndr);
-}
-
-static int sk_diag_put_rings_cfg(struct sock *sk, struct sk_buff *nlskb)
-{
-	struct netlink_sock *nlk = nlk_sk(sk);
-	int ret;
-
-	mutex_lock(&nlk->pg_vec_lock);
-	ret = sk_diag_put_ring(&nlk->rx_ring, NETLINK_DIAG_RX_RING, nlskb);
-	if (!ret)
-		ret = sk_diag_put_ring(&nlk->tx_ring, NETLINK_DIAG_TX_RING,
-				       nlskb);
-	mutex_unlock(&nlk->pg_vec_lock);
-
-	return ret;
-}
-#else
-static int sk_diag_put_rings_cfg(struct sock *sk, struct sk_buff *nlskb)
-{
-	return 0;
-}
-#endif
-
 static int sk_diag_dump_groups(struct sock *sk, struct sk_buff *nlskb)
 {
 	struct netlink_sock *nlk = nlk_sk(sk);
@@ -87,10 +52,6 @@ static int sk_diag_fill(struct sock *sk, struct sk_buff *skb,
 	    sock_diag_put_meminfo(sk, skb, NETLINK_DIAG_MEMINFO))
 		goto out_nlmsg_trim;
 
-	if ((req->ndiag_show & NDIAG_SHOW_RING_CFG) &&
-	    sk_diag_put_rings_cfg(sk, skb))
-		goto out_nlmsg_trim;
-
 	nlmsg_end(skb, nlh);
 	return 0;
 

commit 053c095a82cf773075e83d7233b5cc19a1f73ece
Author: Johannes Berg <johannes.berg@intel.com>
Date:   Fri Jan 16 22:09:00 2015 +0100

    netlink: make nlmsg_end() and genlmsg_end() void
    
    Contrary to common expectations for an "int" return, these functions
    return only a positive value -- if used correctly they cannot even
    return 0 because the message header will necessarily be in the skb.
    
    This makes the very common pattern of
    
      if (genlmsg_end(...) < 0) { ... }
    
    be a whole bunch of dead code. Many places also simply do
    
      return nlmsg_end(...);
    
    and the caller is expected to deal with it.
    
    This also commonly (at least for me) causes errors, because it is very
    common to write
    
      if (my_function(...))
        /* error condition */
    
    and if my_function() does "return nlmsg_end()" this is of course wrong.
    
    Additionally, there's not a single place in the kernel that actually
    needs the message length returned, and if anyone needs it later then
    it'll be very easy to just use skb->len there.
    
    Remove this, and make the functions void. This removes a bunch of dead
    code as described above. The patch adds lines because I did
    
    -       return nlmsg_end(...);
    +       nlmsg_end(...);
    +       return 0;
    
    I could have preserved all the function's return values by returning
    skb->len, but instead I've audited all the places calling the affected
    functions and found that none cared. A few places actually compared
    the return value with <= 0 in dump functionality, but that could just
    be changed to < 0 with no change in behaviour, so I opted for the more
    efficient version.
    
    One instance of the error I've made numerous times now is also present
    in net/phonet/pn_netlink.c in the route_dumpit() function - it didn't
    check for <0 or <=0 and thus broke out of the loop every single time.
    I've preserved this since it will (I think) have caused the messages to
    userspace to be formatted differently with just a single message for
    every SKB returned to userspace. It's possible that this isn't needed
    for the tools that actually use this, but I don't even know what they
    are so couldn't test that changing this behaviour would be acceptable.
    
    Signed-off-by: Johannes Berg <johannes.berg@intel.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/netlink/diag.c b/net/netlink/diag.c
index bb59a7ed0859..3ee63a3cff30 100644
--- a/net/netlink/diag.c
+++ b/net/netlink/diag.c
@@ -91,7 +91,8 @@ static int sk_diag_fill(struct sock *sk, struct sk_buff *skb,
 	    sk_diag_put_rings_cfg(sk, skb))
 		goto out_nlmsg_trim;
 
-	return nlmsg_end(skb, nlh);
+	nlmsg_end(skb, nlh);
+	return 0;
 
 out_nlmsg_trim:
 	nlmsg_cancel(skb, nlh);

commit c5adde9468b0714a051eac7f9666f23eb10b61f7
Author: Ying Xue <ying.xue@windriver.com>
Date:   Mon Jan 12 14:52:23 2015 +0800

    netlink: eliminate nl_sk_hash_lock
    
    As rhashtable_lookup_compare_insert() can guarantee the process
    of search and insertion is atomic, it's safe to eliminate the
    nl_sk_hash_lock. After this, object insertion or removal will
    be protected with per bucket lock on write side while object
    lookup is guarded with rcu read lock on read side.
    
    Signed-off-by: Ying Xue <ying.xue@windriver.com>
    Cc: Thomas Graf <tgraf@suug.ch>
    Acked-by: Thomas Graf <tgraf@suug.ch>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/netlink/diag.c b/net/netlink/diag.c
index fcca36d81a62..bb59a7ed0859 100644
--- a/net/netlink/diag.c
+++ b/net/netlink/diag.c
@@ -103,7 +103,7 @@ static int __netlink_diag_dump(struct sk_buff *skb, struct netlink_callback *cb,
 {
 	struct netlink_table *tbl = &nl_table[protocol];
 	struct rhashtable *ht = &tbl->hash;
-	const struct bucket_table *htbl = rht_dereference(ht->tbl, ht);
+	const struct bucket_table *htbl = rht_dereference_rcu(ht->tbl, ht);
 	struct net *net = sock_net(skb->sk);
 	struct netlink_diag_req *req;
 	struct netlink_sock *nlsk;
@@ -115,7 +115,7 @@ static int __netlink_diag_dump(struct sk_buff *skb, struct netlink_callback *cb,
 	for (i = 0; i < htbl->size; i++) {
 		struct rhash_head *pos;
 
-		rht_for_each_entry(nlsk, pos, htbl, i, node) {
+		rht_for_each_entry_rcu(nlsk, pos, htbl, i, node) {
 			sk = (struct sock *)nlsk;
 
 			if (!net_eq(sock_net(sk), net))
@@ -172,7 +172,7 @@ static int netlink_diag_dump(struct sk_buff *skb, struct netlink_callback *cb)
 
 	req = nlmsg_data(cb->nlh);
 
-	mutex_lock(&nl_sk_hash_lock);
+	rcu_read_lock();
 	read_lock(&nl_table_lock);
 
 	if (req->sdiag_protocol == NDIAG_PROTO_ALL) {
@@ -186,7 +186,7 @@ static int netlink_diag_dump(struct sk_buff *skb, struct netlink_callback *cb)
 	} else {
 		if (req->sdiag_protocol >= MAX_LINKS) {
 			read_unlock(&nl_table_lock);
-			mutex_unlock(&nl_sk_hash_lock);
+			rcu_read_unlock();
 			return -ENOENT;
 		}
 
@@ -194,7 +194,7 @@ static int netlink_diag_dump(struct sk_buff *skb, struct netlink_callback *cb)
 	}
 
 	read_unlock(&nl_table_lock);
-	mutex_unlock(&nl_sk_hash_lock);
+	rcu_read_unlock();
 
 	return skb->len;
 }

commit 88d6ed15acff1cb44b1d1f3c0a393b7f7744957a
Author: Thomas Graf <tgraf@suug.ch>
Date:   Fri Jan 2 23:00:16 2015 +0100

    rhashtable: Convert bucket iterators to take table and index
    
    This patch is in preparation to introduce per bucket spinlocks. It
    extends all iterator macros to take the bucket table and bucket
    index. It also introduces a new rht_dereference_bucket() to
    handle protected accesses to buckets.
    
    It introduces a barrier() to the RCU iterators to the prevent
    the compiler from caching the first element.
    
    The lockdep verifier is introduced as stub which always succeeds
    and properly implement in the next patch when the locks are
    introduced.
    
    Signed-off-by: Thomas Graf <tgraf@suug.ch>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/netlink/diag.c b/net/netlink/diag.c
index de8c74a3c061..fcca36d81a62 100644
--- a/net/netlink/diag.c
+++ b/net/netlink/diag.c
@@ -113,7 +113,9 @@ static int __netlink_diag_dump(struct sk_buff *skb, struct netlink_callback *cb,
 	req = nlmsg_data(cb->nlh);
 
 	for (i = 0; i < htbl->size; i++) {
-		rht_for_each_entry(nlsk, htbl->buckets[i], ht, node) {
+		struct rhash_head *pos;
+
+		rht_for_each_entry(nlsk, pos, htbl, i, node) {
 			sk = (struct sock *)nlsk;
 
 			if (!net_eq(sock_net(sk), net))

commit 6c8f7e70837468da4e658080d4448930fb597e1b
Author: Thomas Graf <tgraf@suug.ch>
Date:   Thu Aug 7 00:18:47 2014 +0100

    netlink: hold nl_sock_hash_lock during diag dump
    
    Although RCU protection would be possible during diag dump, doing
    so allows for concurrent table mutations which can render the
    in-table offset between individual Netlink messages invalid and
    thus cause legitimate sockets to be skipped in the dump.
    
    Since the diag dump is relatively low volume and consistency is
    more important than performance, the table mutex is held during
    dump.
    
    Reported-by: Andrey Wagin <avagin@gmail.com>
    Signed-off-by: Thomas Graf <tgraf@suug.ch>
    Fixes: e341694e3eb57fc ("netlink: Convert netlink_lookup() to use RCU protected hash table")
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/netlink/diag.c b/net/netlink/diag.c
index 7301850eb56f..de8c74a3c061 100644
--- a/net/netlink/diag.c
+++ b/net/netlink/diag.c
@@ -170,6 +170,7 @@ static int netlink_diag_dump(struct sk_buff *skb, struct netlink_callback *cb)
 
 	req = nlmsg_data(cb->nlh);
 
+	mutex_lock(&nl_sk_hash_lock);
 	read_lock(&nl_table_lock);
 
 	if (req->sdiag_protocol == NDIAG_PROTO_ALL) {
@@ -183,6 +184,7 @@ static int netlink_diag_dump(struct sk_buff *skb, struct netlink_callback *cb)
 	} else {
 		if (req->sdiag_protocol >= MAX_LINKS) {
 			read_unlock(&nl_table_lock);
+			mutex_unlock(&nl_sk_hash_lock);
 			return -ENOENT;
 		}
 
@@ -190,6 +192,7 @@ static int netlink_diag_dump(struct sk_buff *skb, struct netlink_callback *cb)
 	}
 
 	read_unlock(&nl_table_lock);
+	mutex_unlock(&nl_sk_hash_lock);
 
 	return skb->len;
 }

commit e341694e3eb57fcda9f1adc7bfea42fe080d8d7a
Author: Thomas Graf <tgraf@suug.ch>
Date:   Sat Aug 2 11:47:45 2014 +0200

    netlink: Convert netlink_lookup() to use RCU protected hash table
    
    Heavy Netlink users such as Open vSwitch spend a considerable amount of
    time in netlink_lookup() due to the read-lock on nl_table_lock. Use of
    RCU relieves the lock contention.
    
    Makes use of the new resizable hash table to avoid locking on the
    lookup.
    
    The hash table will grow if entries exceeds 75% of table size up to a
    total table size of 64K. It will automatically shrink if usage falls
    below 30%.
    
    Also splits nl_table_lock into a separate mutex to protect hash table
    mutations and allow synchronize_rcu() to sleep while waiting for readers
    during expansion and shrinking.
    
    Before:
       9.16%  kpktgend_0  [openvswitch]      [k] masked_flow_lookup
       6.42%  kpktgend_0  [pktgen]           [k] mod_cur_headers
       6.26%  kpktgend_0  [pktgen]           [k] pktgen_thread_worker
       6.23%  kpktgend_0  [kernel.kallsyms]  [k] memset
       4.79%  kpktgend_0  [kernel.kallsyms]  [k] netlink_lookup
       4.37%  kpktgend_0  [kernel.kallsyms]  [k] memcpy
       3.60%  kpktgend_0  [openvswitch]      [k] ovs_flow_extract
       2.69%  kpktgend_0  [kernel.kallsyms]  [k] jhash2
    
    After:
      15.26%  kpktgend_0  [openvswitch]      [k] masked_flow_lookup
       8.12%  kpktgend_0  [pktgen]           [k] pktgen_thread_worker
       7.92%  kpktgend_0  [pktgen]           [k] mod_cur_headers
       5.11%  kpktgend_0  [kernel.kallsyms]  [k] memset
       4.11%  kpktgend_0  [openvswitch]      [k] ovs_flow_extract
       4.06%  kpktgend_0  [kernel.kallsyms]  [k] _raw_spin_lock
       3.90%  kpktgend_0  [kernel.kallsyms]  [k] jhash2
       [...]
       0.67%  kpktgend_0  [kernel.kallsyms]  [k] netlink_lookup
    
    Signed-off-by: Thomas Graf <tgraf@suug.ch>
    Reviewed-by: Nikolay Aleksandrov <nikolay@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/netlink/diag.c b/net/netlink/diag.c
index 1af29624b92f..7301850eb56f 100644
--- a/net/netlink/diag.c
+++ b/net/netlink/diag.c
@@ -4,6 +4,7 @@
 #include <linux/netlink.h>
 #include <linux/sock_diag.h>
 #include <linux/netlink_diag.h>
+#include <linux/rhashtable.h>
 
 #include "af_netlink.h"
 
@@ -101,16 +102,20 @@ static int __netlink_diag_dump(struct sk_buff *skb, struct netlink_callback *cb,
 				int protocol, int s_num)
 {
 	struct netlink_table *tbl = &nl_table[protocol];
-	struct nl_portid_hash *hash = &tbl->hash;
+	struct rhashtable *ht = &tbl->hash;
+	const struct bucket_table *htbl = rht_dereference(ht->tbl, ht);
 	struct net *net = sock_net(skb->sk);
 	struct netlink_diag_req *req;
+	struct netlink_sock *nlsk;
 	struct sock *sk;
 	int ret = 0, num = 0, i;
 
 	req = nlmsg_data(cb->nlh);
 
-	for (i = 0; i <= hash->mask; i++) {
-		sk_for_each(sk, &hash->table[i]) {
+	for (i = 0; i < htbl->size; i++) {
+		rht_for_each_entry(nlsk, htbl->buckets[i], ht, node) {
+			sk = (struct sock *)nlsk;
+
 			if (!net_eq(sock_net(sk), net))
 				continue;
 			if (num < s_num) {

commit 3dec2246c2ff11beb24ca1950f074b2bcbc85953
Author: David S. Miller <davem@davemloft.net>
Date:   Tue Apr 23 15:39:03 2013 -0400

    netlink: Fix build with mmap disabled.
    
    net/netlink/diag.c: In function 'sk_diag_put_rings_cfg':
    net/netlink/diag.c:28:17: error: 'struct netlink_sock' has no member named 'pg_vec_lock'
    net/netlink/diag.c:29:29: error: 'struct netlink_sock' has no member named 'rx_ring'
    net/netlink/diag.c:31:30: error: 'struct netlink_sock' has no member named 'tx_ring'
    net/netlink/diag.c:33:19: error: 'struct netlink_sock' has no member named 'pg_vec_lock'
    
    Reported-by: Randy Dunlap <rdunlap@infradead.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/netlink/diag.c b/net/netlink/diag.c
index 4e4aa471cd05..1af29624b92f 100644
--- a/net/netlink/diag.c
+++ b/net/netlink/diag.c
@@ -7,6 +7,7 @@
 
 #include "af_netlink.h"
 
+#ifdef CONFIG_NETLINK_MMAP
 static int sk_diag_put_ring(struct netlink_ring *ring, int nl_type,
 			    struct sk_buff *nlskb)
 {
@@ -34,6 +35,12 @@ static int sk_diag_put_rings_cfg(struct sock *sk, struct sk_buff *nlskb)
 
 	return ret;
 }
+#else
+static int sk_diag_put_rings_cfg(struct sock *sk, struct sk_buff *nlskb)
+{
+	return 0;
+}
+#endif
 
 static int sk_diag_dump_groups(struct sock *sk, struct sk_buff *nlskb)
 {

commit 4ae9fbee1690848a6aace1e0193ab27e981e35a5
Author: Patrick McHardy <kaber@trash.net>
Date:   Wed Apr 17 06:47:06 2013 +0000

    netlink: add RX/TX-ring support to netlink diag
    
    Based on AF_PACKET.
    
    Signed-off-by: Patrick McHardy <kaber@trash.net>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/netlink/diag.c b/net/netlink/diag.c
index 5ffb1d1cf402..4e4aa471cd05 100644
--- a/net/netlink/diag.c
+++ b/net/netlink/diag.c
@@ -7,6 +7,34 @@
 
 #include "af_netlink.h"
 
+static int sk_diag_put_ring(struct netlink_ring *ring, int nl_type,
+			    struct sk_buff *nlskb)
+{
+	struct netlink_diag_ring ndr;
+
+	ndr.ndr_block_size = ring->pg_vec_pages << PAGE_SHIFT;
+	ndr.ndr_block_nr   = ring->pg_vec_len;
+	ndr.ndr_frame_size = ring->frame_size;
+	ndr.ndr_frame_nr   = ring->frame_max + 1;
+
+	return nla_put(nlskb, nl_type, sizeof(ndr), &ndr);
+}
+
+static int sk_diag_put_rings_cfg(struct sock *sk, struct sk_buff *nlskb)
+{
+	struct netlink_sock *nlk = nlk_sk(sk);
+	int ret;
+
+	mutex_lock(&nlk->pg_vec_lock);
+	ret = sk_diag_put_ring(&nlk->rx_ring, NETLINK_DIAG_RX_RING, nlskb);
+	if (!ret)
+		ret = sk_diag_put_ring(&nlk->tx_ring, NETLINK_DIAG_TX_RING,
+				       nlskb);
+	mutex_unlock(&nlk->pg_vec_lock);
+
+	return ret;
+}
+
 static int sk_diag_dump_groups(struct sock *sk, struct sk_buff *nlskb)
 {
 	struct netlink_sock *nlk = nlk_sk(sk);
@@ -51,6 +79,10 @@ static int sk_diag_fill(struct sock *sk, struct sk_buff *skb,
 	    sock_diag_put_meminfo(sk, skb, NETLINK_DIAG_MEMINFO))
 		goto out_nlmsg_trim;
 
+	if ((req->ndiag_show & NDIAG_SHOW_RING_CFG) &&
+	    sk_diag_put_rings_cfg(sk, skb))
+		goto out_nlmsg_trim;
+
 	return nlmsg_end(skb, nlh);
 
 out_nlmsg_trim:

commit eaaa31392690c7609f7afeec5ba38a79d009842d
Author: Andrey Vagin <avagin@openvz.org>
Date:   Thu Mar 21 20:33:48 2013 +0400

    netlink: Diag core and basic socket info dumping (v2)
    
    The netlink_diag can be built as a module, just like it's done in
    unix sockets.
    
    The core dumping message carries the basic info about netlink sockets:
    family, type and protocol, portis, dst_group, dst_portid, state.
    
    Groups can be received as an optional parameter NETLINK_DIAG_GROUPS.
    
    Netlink sockets cab be filtered by protocols.
    
    The socket inode number and cookie is reserved for future per-socket info
    retrieving. The per-protocol filtering is also reserved for future by
    requiring the sdiag_protocol to be zero.
    
    The file /proc/net/netlink doesn't provide enough information for
    dumping netlink sockets. It doesn't provide dst_group, dst_portid,
    groups above 32.
    
    v2: fix NETLINK_DIAG_MAX. Now it's equal to the last constant.
    
    Acked-by: Pavel Emelyanov <xemul@parallels.com>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Eric Dumazet <edumazet@google.com>
    Cc: Pablo Neira Ayuso <pablo@netfilter.org>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Gao feng <gaofeng@cn.fujitsu.com>
    Cc: Thomas Graf <tgraf@suug.ch>
    Signed-off-by: Andrey Vagin <avagin@openvz.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/netlink/diag.c b/net/netlink/diag.c
new file mode 100644
index 000000000000..5ffb1d1cf402
--- /dev/null
+++ b/net/netlink/diag.c
@@ -0,0 +1,188 @@
+#include <linux/module.h>
+
+#include <net/sock.h>
+#include <linux/netlink.h>
+#include <linux/sock_diag.h>
+#include <linux/netlink_diag.h>
+
+#include "af_netlink.h"
+
+static int sk_diag_dump_groups(struct sock *sk, struct sk_buff *nlskb)
+{
+	struct netlink_sock *nlk = nlk_sk(sk);
+
+	if (nlk->groups == NULL)
+		return 0;
+
+	return nla_put(nlskb, NETLINK_DIAG_GROUPS, NLGRPSZ(nlk->ngroups),
+		       nlk->groups);
+}
+
+static int sk_diag_fill(struct sock *sk, struct sk_buff *skb,
+			struct netlink_diag_req *req,
+			u32 portid, u32 seq, u32 flags, int sk_ino)
+{
+	struct nlmsghdr *nlh;
+	struct netlink_diag_msg *rep;
+	struct netlink_sock *nlk = nlk_sk(sk);
+
+	nlh = nlmsg_put(skb, portid, seq, SOCK_DIAG_BY_FAMILY, sizeof(*rep),
+			flags);
+	if (!nlh)
+		return -EMSGSIZE;
+
+	rep = nlmsg_data(nlh);
+	rep->ndiag_family	= AF_NETLINK;
+	rep->ndiag_type		= sk->sk_type;
+	rep->ndiag_protocol	= sk->sk_protocol;
+	rep->ndiag_state	= sk->sk_state;
+
+	rep->ndiag_ino		= sk_ino;
+	rep->ndiag_portid	= nlk->portid;
+	rep->ndiag_dst_portid	= nlk->dst_portid;
+	rep->ndiag_dst_group	= nlk->dst_group;
+	sock_diag_save_cookie(sk, rep->ndiag_cookie);
+
+	if ((req->ndiag_show & NDIAG_SHOW_GROUPS) &&
+	    sk_diag_dump_groups(sk, skb))
+		goto out_nlmsg_trim;
+
+	if ((req->ndiag_show & NDIAG_SHOW_MEMINFO) &&
+	    sock_diag_put_meminfo(sk, skb, NETLINK_DIAG_MEMINFO))
+		goto out_nlmsg_trim;
+
+	return nlmsg_end(skb, nlh);
+
+out_nlmsg_trim:
+	nlmsg_cancel(skb, nlh);
+	return -EMSGSIZE;
+}
+
+static int __netlink_diag_dump(struct sk_buff *skb, struct netlink_callback *cb,
+				int protocol, int s_num)
+{
+	struct netlink_table *tbl = &nl_table[protocol];
+	struct nl_portid_hash *hash = &tbl->hash;
+	struct net *net = sock_net(skb->sk);
+	struct netlink_diag_req *req;
+	struct sock *sk;
+	int ret = 0, num = 0, i;
+
+	req = nlmsg_data(cb->nlh);
+
+	for (i = 0; i <= hash->mask; i++) {
+		sk_for_each(sk, &hash->table[i]) {
+			if (!net_eq(sock_net(sk), net))
+				continue;
+			if (num < s_num) {
+				num++;
+				continue;
+			}
+
+			if (sk_diag_fill(sk, skb, req,
+					 NETLINK_CB(cb->skb).portid,
+					 cb->nlh->nlmsg_seq,
+					 NLM_F_MULTI,
+					 sock_i_ino(sk)) < 0) {
+				ret = 1;
+				goto done;
+			}
+
+			num++;
+		}
+	}
+
+	sk_for_each_bound(sk, &tbl->mc_list) {
+		if (sk_hashed(sk))
+			continue;
+		if (!net_eq(sock_net(sk), net))
+			continue;
+		if (num < s_num) {
+			num++;
+			continue;
+		}
+
+		if (sk_diag_fill(sk, skb, req,
+				 NETLINK_CB(cb->skb).portid,
+				 cb->nlh->nlmsg_seq,
+				 NLM_F_MULTI,
+				 sock_i_ino(sk)) < 0) {
+			ret = 1;
+			goto done;
+		}
+		num++;
+	}
+done:
+	cb->args[0] = num;
+	cb->args[1] = protocol;
+
+	return ret;
+}
+
+static int netlink_diag_dump(struct sk_buff *skb, struct netlink_callback *cb)
+{
+	struct netlink_diag_req *req;
+	int s_num = cb->args[0];
+
+	req = nlmsg_data(cb->nlh);
+
+	read_lock(&nl_table_lock);
+
+	if (req->sdiag_protocol == NDIAG_PROTO_ALL) {
+		int i;
+
+		for (i = cb->args[1]; i < MAX_LINKS; i++) {
+			if (__netlink_diag_dump(skb, cb, i, s_num))
+				break;
+			s_num = 0;
+		}
+	} else {
+		if (req->sdiag_protocol >= MAX_LINKS) {
+			read_unlock(&nl_table_lock);
+			return -ENOENT;
+		}
+
+		__netlink_diag_dump(skb, cb, req->sdiag_protocol, s_num);
+	}
+
+	read_unlock(&nl_table_lock);
+
+	return skb->len;
+}
+
+static int netlink_diag_handler_dump(struct sk_buff *skb, struct nlmsghdr *h)
+{
+	int hdrlen = sizeof(struct netlink_diag_req);
+	struct net *net = sock_net(skb->sk);
+
+	if (nlmsg_len(h) < hdrlen)
+		return -EINVAL;
+
+	if (h->nlmsg_flags & NLM_F_DUMP) {
+		struct netlink_dump_control c = {
+			.dump = netlink_diag_dump,
+		};
+		return netlink_dump_start(net->diag_nlsk, skb, h, &c);
+	} else
+		return -EOPNOTSUPP;
+}
+
+static const struct sock_diag_handler netlink_diag_handler = {
+	.family = AF_NETLINK,
+	.dump = netlink_diag_handler_dump,
+};
+
+static int __init netlink_diag_init(void)
+{
+	return sock_diag_register(&netlink_diag_handler);
+}
+
+static void __exit netlink_diag_exit(void)
+{
+	sock_diag_unregister(&netlink_diag_handler);
+}
+
+module_init(netlink_diag_init);
+module_exit(netlink_diag_exit);
+MODULE_LICENSE("GPL");
+MODULE_ALIAS_NET_PF_PROTO_TYPE(PF_NETLINK, NETLINK_SOCK_DIAG, 16 /* AF_NETLINK */);
