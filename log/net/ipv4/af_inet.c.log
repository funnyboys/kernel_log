commit a152b85984a03e7f83b9d8bcf908c29597d898fc
Merge: 1e6a70526640 a5dfaa2ab940
Author: David S. Miller <davem@davemloft.net>
Date:   Fri May 22 18:30:34 2020 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf-next
    
    Daniel Borkmann says:
    
    ====================
    pull-request: bpf-next 2020-05-23
    
    The following pull-request contains BPF updates for your *net-next* tree.
    
    We've added 50 non-merge commits during the last 8 day(s) which contain
    a total of 109 files changed, 2776 insertions(+), 2887 deletions(-).
    
    The main changes are:
    
    1) Add a new AF_XDP buffer allocation API to the core in order to help
       lowering the bar for drivers adopting AF_XDP support. i40e, ice, ixgbe
       as well as mlx5 have been moved over to the new API and also gained a
       small improvement in performance, from Björn Töpel and Magnus Karlsson.
    
    2) Add getpeername()/getsockname() attach types for BPF sock_addr programs
       in order to allow for e.g. reverse translation of load-balancer backend
       to service address/port tuple from a connected peer, from Daniel Borkmann.
    
    3) Improve the BPF verifier is_branch_taken() logic to evaluate pointers
       being non-NULL, e.g. if after an initial test another non-NULL test on
       that pointer follows in a given path, then it can be pruned right away,
       from John Fastabend.
    
    4) Larger rework of BPF sockmap selftests to make output easier to understand
       and to reduce overall runtime as well as adding new BPF kTLS selftests
       that run in combination with sockmap, also from John Fastabend.
    
    5) Batch of misc updates to BPF selftests including fixing up test_align
       to match verifier output again and moving it under test_progs, allowing
       bpf_iter selftest to compile on machines with older vmlinux.h, and
       updating config options for lirc and v6 segment routing helpers, from
       Stanislav Fomichev, Andrii Nakryiko and Alan Maguire.
    
    6) Conversion of BPF tracing samples outdated internal BPF loader to use
       libbpf API instead, from Daniel T. Lee.
    
    7) Follow-up to BPF kernel test infrastructure in order to fix a flake in
       the XDP selftests, from Jesper Dangaard Brouer.
    
    8) Minor improvements to libbpf's internal hashmap implementation, from
       Ian Rogers.
    ====================
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 1b66d253610c7f8f257103808a9460223a087469
Author: Daniel Borkmann <daniel@iogearbox.net>
Date:   Tue May 19 00:45:45 2020 +0200

    bpf: Add get{peer, sock}name attach types for sock_addr
    
    As stated in 983695fa6765 ("bpf: fix unconnected udp hooks"), the objective
    for the existing cgroup connect/sendmsg/recvmsg/bind BPF hooks is to be
    transparent to applications. In Cilium we make use of these hooks [0] in
    order to enable E-W load balancing for existing Kubernetes service types
    for all Cilium managed nodes in the cluster. Those backends can be local
    or remote. The main advantage of this approach is that it operates as close
    as possible to the socket, and therefore allows to avoid packet-based NAT
    given in connect/sendmsg/recvmsg hooks we only need to xlate sock addresses.
    
    This also allows to expose NodePort services on loopback addresses in the
    host namespace, for example. As another advantage, this also efficiently
    blocks bind requests for applications in the host namespace for exposed
    ports. However, one missing item is that we also need to perform reverse
    xlation for inet{,6}_getname() hooks such that we can return the service
    IP/port tuple back to the application instead of the remote peer address.
    
    The vast majority of applications does not bother about getpeername(), but
    in a few occasions we've seen breakage when validating the peer's address
    since it returns unexpectedly the backend tuple instead of the service one.
    Therefore, this trivial patch allows to customise and adds a getpeername()
    as well as getsockname() BPF cgroup hook for both IPv4 and IPv6 in order
    to address this situation.
    
    Simple example:
    
      # ./cilium/cilium service list
      ID   Frontend     Service Type   Backend
      1    1.2.3.4:80   ClusterIP      1 => 10.0.0.10:80
    
    Before; curl's verbose output example, no getpeername() reverse xlation:
    
      # curl --verbose 1.2.3.4
      * Rebuilt URL to: 1.2.3.4/
      *   Trying 1.2.3.4...
      * TCP_NODELAY set
      * Connected to 1.2.3.4 (10.0.0.10) port 80 (#0)
      > GET / HTTP/1.1
      > Host: 1.2.3.4
      > User-Agent: curl/7.58.0
      > Accept: */*
      [...]
    
    After; with getpeername() reverse xlation:
    
      # curl --verbose 1.2.3.4
      * Rebuilt URL to: 1.2.3.4/
      *   Trying 1.2.3.4...
      * TCP_NODELAY set
      * Connected to 1.2.3.4 (1.2.3.4) port 80 (#0)
      > GET / HTTP/1.1
      >  Host: 1.2.3.4
      > User-Agent: curl/7.58.0
      > Accept: */*
      [...]
    
    Originally, I had both under a BPF_CGROUP_INET{4,6}_GETNAME type and exposed
    peer to the context similar as in inet{,6}_getname() fashion, but API-wise
    this is suboptimal as it always enforces programs having to test for ctx->peer
    which can easily be missed, hence BPF_CGROUP_INET{4,6}_GET{PEER,SOCK}NAME split.
    Similarly, the checked return code is on tnum_range(1, 1), but if a use case
    comes up in future, it can easily be changed to return an error code instead.
    Helper and ctx member access is the same as with connect/sendmsg/etc hooks.
    
      [0] https://github.com/cilium/cilium/blob/master/bpf/bpf_sock.c
    
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>
    Acked-by: Andrii Nakryiko <andriin@fb.com>
    Acked-by: Andrey Ignatov <rdna@fb.com>
    Link: https://lore.kernel.org/bpf/61a479d759b2482ae3efb45546490bacd796a220.1589841594.git.daniel@iogearbox.net

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index fcf0d12a407a..8f5c8c9409d3 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -755,12 +755,11 @@ int inet_accept(struct socket *sock, struct socket *newsock, int flags,
 }
 EXPORT_SYMBOL(inet_accept);
 
-
 /*
  *	This does both peername and sockname.
  */
 int inet_getname(struct socket *sock, struct sockaddr *uaddr,
-			int peer)
+		 int peer)
 {
 	struct sock *sk		= sock->sk;
 	struct inet_sock *inet	= inet_sk(sk);
@@ -781,6 +780,11 @@ int inet_getname(struct socket *sock, struct sockaddr *uaddr,
 		sin->sin_port = inet->inet_sport;
 		sin->sin_addr.s_addr = addr;
 	}
+	if (cgroup_bpf_enabled)
+		BPF_CGROUP_RUN_SA_PROG_LOCK(sk, (struct sockaddr *)sin,
+					    peer ? BPF_CGROUP_INET4_GETPEERNAME :
+						   BPF_CGROUP_INET4_GETSOCKNAME,
+					    NULL);
 	memset(sin->sin_zero, 0, sizeof(sin->sin_zero));
 	return sizeof(*sin);
 }

commit dc13c8761c91c06acd3d98cd107f371cba9811b9
Author: Christoph Hellwig <hch@lst.de>
Date:   Mon May 18 08:28:08 2020 +0200

    ipv4,appletalk: move SIOCADDRT and SIOCDELRT handling into ->compat_ioctl
    
    To prepare removing the global routing_ioctl hack start lifting the code
    into the ipv4 and appletalk ->compat_ioctl handlers.  Unlike the existing
    handler we don't bother copying in the name - there are no compat issues for
    char arrays.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index fcf0d12a407a..c35a8b2e0499 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -116,6 +116,7 @@
 #include <linux/mroute.h>
 #endif
 #include <net/l3mdev.h>
+#include <net/compat.h>
 
 #include <trace/events/sock.h>
 
@@ -970,17 +971,42 @@ int inet_ioctl(struct socket *sock, unsigned int cmd, unsigned long arg)
 EXPORT_SYMBOL(inet_ioctl);
 
 #ifdef CONFIG_COMPAT
+static int inet_compat_routing_ioctl(struct sock *sk, unsigned int cmd,
+		struct compat_rtentry __user *ur)
+{
+	compat_uptr_t rtdev;
+	struct rtentry rt;
+
+	if (copy_from_user(&rt.rt_dst, &ur->rt_dst,
+			3 * sizeof(struct sockaddr)) ||
+	    get_user(rt.rt_flags, &ur->rt_flags) ||
+	    get_user(rt.rt_metric, &ur->rt_metric) ||
+	    get_user(rt.rt_mtu, &ur->rt_mtu) ||
+	    get_user(rt.rt_window, &ur->rt_window) ||
+	    get_user(rt.rt_irtt, &ur->rt_irtt) ||
+	    get_user(rtdev, &ur->rt_dev))
+		return -EFAULT;
+
+	rt.rt_dev = compat_ptr(rtdev);
+	return ip_rt_ioctl(sock_net(sk), cmd, &rt);
+}
+
 static int inet_compat_ioctl(struct socket *sock, unsigned int cmd, unsigned long arg)
 {
+	void __user *argp = compat_ptr(arg);
 	struct sock *sk = sock->sk;
-	int err = -ENOIOCTLCMD;
-
-	if (sk->sk_prot->compat_ioctl)
-		err = sk->sk_prot->compat_ioctl(sk, cmd, arg);
 
-	return err;
+	switch (cmd) {
+	case SIOCADDRT:
+	case SIOCDELRT:
+		return inet_compat_routing_ioctl(sk, cmd, argp);
+	default:
+		if (!sk->sk_prot->compat_ioctl)
+			return -ENOIOCTLCMD;
+		return sk->sk_prot->compat_ioctl(sk, cmd, arg);
+	}
 }
-#endif
+#endif /* CONFIG_COMPAT */
 
 const struct proto_ops inet_stream_ops = {
 	.family		   = PF_INET,

commit 8086fbaf49345f988deec539ec8e182b02914401
Author: Stanislav Fomichev <sdf@google.com>
Date:   Fri May 8 10:46:11 2020 -0700

    bpf: Allow any port in bpf_bind helper
    
    We want to have a tighter control on what ports we bind to in
    the BPF_CGROUP_INET{4,6}_CONNECT hooks even if it means
    connect() becomes slightly more expensive. The expensive part
    comes from the fact that we now need to call inet_csk_get_port()
    that verifies that the port is not used and allocates an entry
    in the hash table for it.
    
    Since we can't rely on "snum || !bind_address_no_port" to prevent
    us from calling POST_BIND hook anymore, let's add another bind flag
    to indicate that the call site is BPF program.
    
    v5:
    * fix wrong AF_INET (should be AF_INET6) in the bpf program for v6
    
    v3:
    * More bpf_bind documentation refinements (Martin KaFai Lau)
    * Add UDP tests as well (Martin KaFai Lau)
    * Don't start the thread, just do socket+bind+listen (Martin KaFai Lau)
    
    v2:
    * Update documentation (Andrey Ignatov)
    * Pass BIND_FORCE_ADDRESS_NO_PORT conditionally (Andrey Ignatov)
    
    Signed-off-by: Stanislav Fomichev <sdf@google.com>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Acked-by: Andrey Ignatov <rdna@fb.com>
    Acked-by: Martin KaFai Lau <kafai@fb.com>
    Link: https://lore.kernel.org/bpf/20200508174611.228805-5-sdf@google.com

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 68e74b1b0f26..fcf0d12a407a 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -526,10 +526,12 @@ int __inet_bind(struct sock *sk, struct sockaddr *uaddr, int addr_len,
 			err = -EADDRINUSE;
 			goto out_release_sock;
 		}
-		err = BPF_CGROUP_RUN_PROG_INET4_POST_BIND(sk);
-		if (err) {
-			inet->inet_saddr = inet->inet_rcv_saddr = 0;
-			goto out_release_sock;
+		if (!(flags & BIND_FROM_BPF)) {
+			err = BPF_CGROUP_RUN_PROG_INET4_POST_BIND(sk);
+			if (err) {
+				inet->inet_saddr = inet->inet_rcv_saddr = 0;
+				goto out_release_sock;
+			}
 		}
 	}
 

commit cb0721c7e200750907bb8ef59b12646a5cb2dadf
Author: Stanislav Fomichev <sdf@google.com>
Date:   Fri May 8 10:46:10 2020 -0700

    net: Refactor arguments of inet{,6}_bind
    
    The intent is to add an additional bind parameter in the next commit.
    Instead of adding another argument, let's convert all existing
    flag arguments into an extendable bit field.
    
    No functional changes.
    
    Signed-off-by: Stanislav Fomichev <sdf@google.com>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Acked-by: Andrey Ignatov <rdna@fb.com>
    Acked-by: Martin KaFai Lau <kafai@fb.com>
    Link: https://lore.kernel.org/bpf/20200508174611.228805-4-sdf@google.com

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 6177c4ba0037..68e74b1b0f26 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -450,12 +450,12 @@ int inet_bind(struct socket *sock, struct sockaddr *uaddr, int addr_len)
 	if (err)
 		return err;
 
-	return __inet_bind(sk, uaddr, addr_len, false, true);
+	return __inet_bind(sk, uaddr, addr_len, BIND_WITH_LOCK);
 }
 EXPORT_SYMBOL(inet_bind);
 
 int __inet_bind(struct sock *sk, struct sockaddr *uaddr, int addr_len,
-		bool force_bind_address_no_port, bool with_lock)
+		u32 flags)
 {
 	struct sockaddr_in *addr = (struct sockaddr_in *)uaddr;
 	struct inet_sock *inet = inet_sk(sk);
@@ -506,7 +506,7 @@ int __inet_bind(struct sock *sk, struct sockaddr *uaddr, int addr_len,
 	 *      would be illegal to use them (multicast/broadcast) in
 	 *      which case the sending device address is used.
 	 */
-	if (with_lock)
+	if (flags & BIND_WITH_LOCK)
 		lock_sock(sk);
 
 	/* Check these errors (active socket, double bind). */
@@ -520,7 +520,7 @@ int __inet_bind(struct sock *sk, struct sockaddr *uaddr, int addr_len,
 
 	/* Make sure we are allowed to bind here. */
 	if (snum || !(inet->bind_address_no_port ||
-		      force_bind_address_no_port)) {
+		      (flags & BIND_FORCE_ADDRESS_NO_PORT))) {
 		if (sk->sk_prot->get_port(sk, snum)) {
 			inet->inet_saddr = inet->inet_rcv_saddr = 0;
 			err = -EADDRINUSE;
@@ -543,7 +543,7 @@ int __inet_bind(struct sock *sk, struct sockaddr *uaddr, int addr_len,
 	sk_dst_reset(sk);
 	err = 0;
 out_release_sock:
-	if (with_lock)
+	if (flags & BIND_WITH_LOCK)
 		release_sock(sk);
 out:
 	return err;

commit 4f80116d3df3b23ee4b83ea8557629e1799bc230
Author: Roopa Prabhu <roopa@cumulusnetworks.com>
Date:   Mon Apr 27 13:56:46 2020 -0700

    net: ipv4: add sysctl for nexthop api compatibility mode
    
    Current route nexthop API maintains user space compatibility
    with old route API by default. Dumps and netlink notifications
    support both new and old API format. In systems which have
    moved to the new API, this compatibility mode cancels some
    of the performance benefits provided by the new nexthop API.
    
    This patch adds new sysctl nexthop_compat_mode which is on
    by default but provides the ability to turn off compatibility
    mode allowing systems to run entirely with the new routing
    API. Old route API behaviour and support is not modified by this
    sysctl.
    
    Uses a single sysctl to cover both ipv4 and ipv6 following
    other sysctls. Covers dumps and delete notifications as
    suggested by David Ahern.
    
    Signed-off-by: Roopa Prabhu <roopa@cumulusnetworks.com>
    Reviewed-by: David Ahern <dsahern@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index c618e242490f..6177c4ba0037 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1835,6 +1835,7 @@ static __net_init int inet_init_net(struct net *net)
 	net->ipv4.sysctl_ip_early_demux = 1;
 	net->ipv4.sysctl_udp_early_demux = 1;
 	net->ipv4.sysctl_tcp_early_demux = 1;
+	net->ipv4.sysctl_nexthop_compat_mode = 1;
 #ifdef CONFIG_SYSCTL
 	net->ipv4.sysctl_ip_prot_sock = PROT_SOCK;
 #endif

commit b6246f4d8d0778fd045b84dbd7fc5aadd8f3136e
Author: Colin Ian King <colin.king@canonical.com>
Date:   Mon Apr 20 22:51:49 2020 +0100

    net: ipv4: remove redundant assignment to variable rc
    
    The variable rc is being assigned with a value that is never read
    and it is being updated later with a new value. The initialization is
    redundant and can be removed.
    
    Addresses-Coverity: ("Unused value")
    Signed-off-by: Colin Ian King <colin.king@canonical.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index cf58e29cf746..c618e242490f 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1914,7 +1914,7 @@ static int __init inet_init(void)
 {
 	struct inet_protosw *q;
 	struct list_head *r;
-	int rc = -EINVAL;
+	int rc;
 
 	sock_skb_cb_check_size(sizeof(struct inet_skb_parm));
 

commit fc518953bc9c8d7d33c6ab261995f5038f3c87f9
Author: Florian Westphal <fw@strlen.de>
Date:   Fri Mar 27 14:48:50 2020 -0700

    mptcp: add and use MIB counter infrastructure
    
    Exported via same /proc file as the Linux TCP MIB counters, so "netstat -s"
    or "nstat" will show them automatically.
    
    The MPTCP MIB counters are allocated in a distinct pcpu area in order to
    avoid bloating/wasting TCP pcpu memory.
    
    Counters are allocated once the first MPTCP socket is created in a
    network namespace and free'd on exit.
    
    If no sockets have been allocated, all-zero mptcp counters are shown.
    
    The MIB counter list is taken from the multipath-tcp.org kernel, but
    only a few counters have been picked up so far.  The counter list can
    be increased at any time later on.
    
    v2 -> v3:
     - remove 'inline' in foo.c files (David S. Miller)
    
    Co-developed-by: Paolo Abeni <pabeni@redhat.com>
    Signed-off-by: Paolo Abeni <pabeni@redhat.com>
    Signed-off-by: Florian Westphal <fw@strlen.de>
    Signed-off-by: Mat Martineau <mathew.j.martineau@linux.intel.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index bd7b4e92e07f..cf58e29cf746 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1793,6 +1793,10 @@ static __net_exit void ipv4_mib_exit_net(struct net *net)
 	free_percpu(net->mib.net_statistics);
 	free_percpu(net->mib.ip_statistics);
 	free_percpu(net->mib.tcp_statistics);
+#ifdef CONFIG_MPTCP
+	/* allocated on demand, see mptcp_init_sock() */
+	free_percpu(net->mib.mptcp_statistics);
+#endif
 }
 
 static __net_initdata struct pernet_operations ipv4_mib_ops = {

commit a8eceea84a3a3504e42f6495cf462027c5d19cb0
Author: Joe Perches <joe@perches.com>
Date:   Thu Mar 12 15:50:22 2020 -0700

    inet: Use fallthrough;
    
    Convert the various uses of fallthrough comments to fallthrough;
    
    Done via script
    Link: https://lore.kernel.org/lkml/b56602fcf79f849e733e7b521bb0e17895d390fa.1582230379.git.joe@perches.com/
    
    And by hand:
    
    net/ipv6/ip6_fib.c has a fallthrough comment outside of an #ifdef block
    that causes gcc to emit a warning if converted in-place.
    
    So move the new fallthrough; inside the containing #ifdef/#endif too.
    
    Signed-off-by: Joe Perches <joe@perches.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 2fe295432c24..bd7b4e92e07f 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -872,7 +872,7 @@ int inet_shutdown(struct socket *sock, int how)
 		err = -ENOTCONN;
 		/* Hack to wake up other listeners, who can poll for
 		   EPOLLHUP, even on eg. unconnected UDP sockets -- RR */
-		/* fall through */
+		fallthrough;
 	default:
 		sk->sk_shutdown |= how;
 		if (sk->sk_prot->shutdown)
@@ -886,7 +886,7 @@ int inet_shutdown(struct socket *sock, int how)
 	case TCP_LISTEN:
 		if (!(how & RCV_SHUTDOWN))
 			break;
-		/* fall through */
+		fallthrough;
 	case TCP_SYN_SENT:
 		err = sk->sk_prot->disconnect(sk, O_NONBLOCK);
 		sock->state = err ? SS_DISCONNECTING : SS_UNCONNECTED;

commit 82f31ebf61bed3077c9935308e0a4b6c44842c5a
Author: Maciej Żenczykowski <maze@google.com>
Date:   Mon Nov 25 15:37:04 2019 -0800

    net: port < inet_prot_sock(net) --> inet_port_requires_bind_service(net, port)
    
    Note that the sysctl write accessor functions guarantee that:
      net->ipv4.sysctl_ip_prot_sock <= net->ipv4.ip_local_ports.range[0]
    invariant is maintained, and as such the max() in selinux hooks is actually spurious.
    
    ie. even though
      if (snum < max(inet_prot_sock(sock_net(sk)), low) || snum > high) {
    per logic is the same as
      if ((snum < inet_prot_sock(sock_net(sk)) && snum < low) || snum > high) {
    it is actually functionally equivalent to:
      if (snum < low || snum > high) {
    which is equivalent to:
      if (snum < inet_prot_sock(sock_net(sk)) || snum < low || snum > high) {
    even though the first clause is spurious.
    
    But we want to hold on to it in case we ever want to change what what
    inet_port_requires_bind_service() means (for example by changing
    it from a, by default, [0..1024) range to some sort of set).
    
    Test: builds, git 'grep inet_prot_sock' finds no other references
    Cc: Eric Dumazet <edumazet@google.com>
    Signed-off-by: Maciej Żenczykowski <maze@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 53de8e00990e..2fe295432c24 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -495,7 +495,7 @@ int __inet_bind(struct sock *sk, struct sockaddr *uaddr, int addr_len,
 
 	snum = ntohs(addr->sin_port);
 	err = -EACCES;
-	if (snum && snum < inet_prot_sock(net) &&
+	if (snum && inet_port_requires_bind_service(net, snum) &&
 	    !ns_capable(net->user_ns, CAP_NET_BIND_SERVICE))
 		goto out;
 

commit 099ecf59f05b5f30f42ebac0ab8cb94f9b18c90c
Author: Eric Dumazet <edumazet@google.com>
Date:   Tue Nov 5 14:11:54 2019 -0800

    net: annotate lockless accesses to sk->sk_max_ack_backlog
    
    sk->sk_max_ack_backlog can be read without any lock being held
    at least in TCP/DCCP cases.
    
    We need to use READ_ONCE()/WRITE_ONCE() to avoid load/store tearing
    and/or potential KCSAN warnings.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 70f92aaca411..53de8e00990e 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -208,7 +208,7 @@ int inet_listen(struct socket *sock, int backlog)
 	if (!((1 << old_state) & (TCPF_CLOSE | TCPF_LISTEN)))
 		goto out;
 
-	sk->sk_max_ack_backlog = backlog;
+	WRITE_ONCE(sk->sk_max_ack_backlog, backlog);
 	/* Really, if the socket is already in listen state
 	 * we can only allow the backlog to be adjusted.
 	 */

commit af809709e9df2a44137429ba3694c339a11b710d
Author: Li RongQing <lirongqing@baidu.com>
Date:   Mon Aug 19 20:05:15 2019 +0800

    net: remove empty inet_exit_net
    
    Pointer members of an object with static storage duration, if not
    explicitly initialized, will be initialized to a NULL pointer. The
    net namespace API checks if this pointer is not NULL before using it,
    it are safe to remove the function.
    
    Signed-off-by: Li RongQing <lirongqing@baidu.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index ed2301ef872e..70f92aaca411 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1845,13 +1845,8 @@ static __net_init int inet_init_net(struct net *net)
 	return 0;
 }
 
-static __net_exit void inet_exit_net(struct net *net)
-{
-}
-
 static __net_initdata struct pernet_operations af_inet_ops = {
 	.init = inet_init_net,
-	.exit = inet_exit_net,
 };
 
 static int __init init_inet_pernet_ops(void)

commit 6f24080e8a1e5572045067507c7905cbe6bc64cc
Author: Paolo Abeni <pabeni@redhat.com>
Date:   Wed Jul 3 16:06:56 2019 +0200

    ipv4: use indirect call wrappers for {tcp, udp}_{recv, send}msg()
    
    This avoids an indirect call per syscall for common ipv4 transports
    
    v1 -> v2:
     - avoid unneeded reclaration for udp_sendmsg, as suggested by Willem
    
    Signed-off-by: Paolo Abeni <pabeni@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 8421e2f5bbb3..ed2301ef872e 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -804,7 +804,8 @@ int inet_sendmsg(struct socket *sock, struct msghdr *msg, size_t size)
 	if (unlikely(inet_send_prepare(sk)))
 		return -EAGAIN;
 
-	return sk->sk_prot->sendmsg(sk, msg, size);
+	return INDIRECT_CALL_2(sk->sk_prot->sendmsg, tcp_sendmsg, udp_sendmsg,
+			       sk, msg, size);
 }
 EXPORT_SYMBOL(inet_sendmsg);
 
@@ -822,6 +823,8 @@ ssize_t inet_sendpage(struct socket *sock, struct page *page, int offset,
 }
 EXPORT_SYMBOL(inet_sendpage);
 
+INDIRECT_CALLABLE_DECLARE(int udp_recvmsg(struct sock *, struct msghdr *,
+					  size_t, int, int, int *));
 int inet_recvmsg(struct socket *sock, struct msghdr *msg, size_t size,
 		 int flags)
 {
@@ -832,8 +835,9 @@ int inet_recvmsg(struct socket *sock, struct msghdr *msg, size_t size,
 	if (likely(!(flags & MSG_ERRQUEUE)))
 		sock_rps_record_flow(sk);
 
-	err = sk->sk_prot->recvmsg(sk, msg, size, flags & MSG_DONTWAIT,
-				   flags & ~MSG_DONTWAIT, &addr_len);
+	err = INDIRECT_CALL_2(sk->sk_prot->recvmsg, tcp_recvmsg, udp_recvmsg,
+			      sk, msg, size, flags & MSG_DONTWAIT,
+			      flags & ~MSG_DONTWAIT, &addr_len);
 	if (err >= 0)
 		msg->msg_namelen = addr_len;
 	return err;

commit e473093639945cb0a07ad4d51d5fd3fc3c3708cf
Author: Paolo Abeni <pabeni@redhat.com>
Date:   Wed Jul 3 16:06:52 2019 +0200

    inet: factor out inet_send_prepare()
    
    The same code is replicated verbatim in multiple places, and the next
    patches will introduce an additional user for it. Factor out a
    helper and use it where appropriate. No functional change intended.
    
    Signed-off-by: Paolo Abeni <pabeni@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 52bdb881a506..8421e2f5bbb3 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -784,10 +784,8 @@ int inet_getname(struct socket *sock, struct sockaddr *uaddr,
 }
 EXPORT_SYMBOL(inet_getname);
 
-int inet_sendmsg(struct socket *sock, struct msghdr *msg, size_t size)
+int inet_send_prepare(struct sock *sk)
 {
-	struct sock *sk = sock->sk;
-
 	sock_rps_record_flow(sk);
 
 	/* We may need to bind the socket. */
@@ -795,6 +793,17 @@ int inet_sendmsg(struct socket *sock, struct msghdr *msg, size_t size)
 	    inet_autobind(sk))
 		return -EAGAIN;
 
+	return 0;
+}
+EXPORT_SYMBOL_GPL(inet_send_prepare);
+
+int inet_sendmsg(struct socket *sock, struct msghdr *msg, size_t size)
+{
+	struct sock *sk = sock->sk;
+
+	if (unlikely(inet_send_prepare(sk)))
+		return -EAGAIN;
+
 	return sk->sk_prot->sendmsg(sk, msg, size);
 }
 EXPORT_SYMBOL(inet_sendmsg);
@@ -804,11 +813,7 @@ ssize_t inet_sendpage(struct socket *sock, struct page *page, int offset,
 {
 	struct sock *sk = sock->sk;
 
-	sock_rps_record_flow(sk);
-
-	/* We may need to bind the socket. */
-	if (!inet_sk(sk)->inet_num && !sk->sk_prot->no_autobind &&
-	    inet_autobind(sk))
+	if (unlikely(inet_send_prepare(sk)))
 		return -EAGAIN;
 
 	if (sk->sk_prot->sendpage)

commit 2f4c53349961c8ca480193e47da4d44fdb8335a8
Merge: 2209a3055d6f 96ac6d435100
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri May 31 08:34:32 2019 -0700

    Merge tag 'spdx-5.2-rc3-1' of git://git.kernel.org/pub/scm/linux/kernel/git/gregkh/driver-core
    
    Pull yet more SPDX updates from Greg KH:
     "Here is another set of reviewed patches that adds SPDX tags to
      different kernel files, based on a set of rules that are being used to
      parse the comments to try to determine that the license of the file is
      "GPL-2.0-or-later" or "GPL-2.0-only". Only the "obvious" versions of
      these matches are included here, a number of "non-obvious" variants of
      text have been found but those have been postponed for later review
      and analysis.
    
      There is also a patch in here to add the proper SPDX header to a bunch
      of Kbuild files that we have missed in the past due to new files being
      added and forgetting that Kbuild uses two different file names for
      Makefiles. This issue was reported by the Kbuild maintainer.
    
      These patches have been out for review on the linux-spdx@vger mailing
      list, and while they were created by automatic tools, they were
      hand-verified by a bunch of different people, all whom names are on
      the patches are reviewers"
    
    * tag 'spdx-5.2-rc3-1' of git://git.kernel.org/pub/scm/linux/kernel/git/gregkh/driver-core: (82 commits)
      treewide: Add SPDX license identifier - Kbuild
      treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 225
      treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 224
      treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 223
      treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 222
      treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 221
      treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 220
      treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 218
      treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 217
      treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 216
      treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 215
      treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 214
      treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 213
      treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 211
      treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 210
      treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 209
      treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 207
      treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 206
      treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 203
      treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 201
      ...

commit 2b81f8161dfeda4017cef4f2498ccb64b13f0d61
Author: Jakub Kicinski <jakub.kicinski@netronome.com>
Date:   Wed May 29 16:33:23 2019 -0700

    net: don't clear sock->sk early to avoid trouble in strparser
    
    af_inet sets sock->sk to NULL which trips strparser over:
    
    BUG: kernel NULL pointer dereference, address: 0000000000000012
    PGD 0 P4D 0
    Oops: 0000 [#1] SMP PTI
    CPU: 7 PID: 0 Comm: swapper/7 Not tainted 5.2.0-rc1-00139-g14629453a6d3 #21
    RIP: 0010:tcp_peek_len+0x10/0x60
    RSP: 0018:ffffc02e41c54b98 EFLAGS: 00010246
    RAX: 0000000000000000 RBX: ffff9cf924c4e030 RCX: 0000000000000051
    RDX: 0000000000000000 RSI: 000000000000000c RDI: ffff9cf97128f480
    RBP: ffff9cf9365e0300 R08: ffff9cf94fe7d2c0 R09: 0000000000000000
    R10: 000000000000036b R11: ffff9cf939735e00 R12: ffff9cf91ad9ae40
    R13: ffff9cf924c4e000 R14: ffff9cf9a8fcbaae R15: 0000000000000020
    FS: 0000000000000000(0000) GS:ffff9cf9af7c0000(0000) knlGS:0000000000000000
    CS: 0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    CR2: 0000000000000012 CR3: 000000013920a003 CR4: 00000000003606e0
    DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
    DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
     Call Trace:
     <IRQ>
     strp_data_ready+0x48/0x90
     tls_data_ready+0x22/0xd0 [tls]
     tcp_rcv_established+0x569/0x620
     tcp_v4_do_rcv+0x127/0x1e0
     tcp_v4_rcv+0xad7/0xbf0
     ip_protocol_deliver_rcu+0x2c/0x1c0
     ip_local_deliver_finish+0x41/0x50
     ip_local_deliver+0x6b/0xe0
     ? ip_protocol_deliver_rcu+0x1c0/0x1c0
     ip_rcv+0x52/0xd0
     ? ip_rcv_finish_core.isra.20+0x380/0x380
     __netif_receive_skb_one_core+0x7e/0x90
     netif_receive_skb_internal+0x42/0xf0
     napi_gro_receive+0xed/0x150
     nfp_net_poll+0x7a2/0xd30 [nfp]
     ? kmem_cache_free_bulk+0x286/0x310
     net_rx_action+0x149/0x3b0
     __do_softirq+0xe3/0x30a
     ? handle_irq_event_percpu+0x6a/0x80
     irq_exit+0xe8/0xf0
     do_IRQ+0x85/0xd0
     common_interrupt+0xf/0xf
     </IRQ>
    RIP: 0010:cpuidle_enter_state+0xbc/0x450
    
    To avoid this issue set sock->sk after sk_prot->close.
    My grepping and testing did not discover any code which
    would depend on the current behaviour.
    
    Fixes: c46234ebb4d1 ("tls: RX path for ktls")
    Reported-by: David Beckett <david.beckett@netronome.com>
    Signed-off-by: Jakub Kicinski <jakub.kicinski@netronome.com>
    Reviewed-by: Dirk van der Merwe <dirk.vandermerwe@netronome.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 5183a2daba64..aff93e7cdb31 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -428,8 +428,8 @@ int inet_release(struct socket *sock)
 		if (sock_flag(sk, SOCK_LINGER) &&
 		    !(current->flags & PF_EXITING))
 			timeout = sk->sk_lingertime;
-		sock->sk = NULL;
 		sk->sk_prot->close(sk, timeout);
+		sock->sk = NULL;
 	}
 	return 0;
 }

commit 2874c5fd284268364ece81a7bd936f3c8168e567
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon May 27 08:55:01 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 152
    
    Based on 1 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license as published by
      the free software foundation either version 2 of the license or at
      your option any later version
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-or-later
    
    has been chosen to replace the boilerplate/reference in 3029 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190527070032.746973796@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 5183a2daba64..fb0c3d9869da 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1,3 +1,4 @@
+// SPDX-License-Identifier: GPL-2.0-or-later
 /*
  * INET		An implementation of the TCP/IP protocol suite for the LINUX
  *		operating system.  INET is implemented using the  BSD Socket
@@ -58,11 +59,6 @@
  *					Some other random speedups.
  *		Cyrus Durgin	:	Cleaned up file for kmod hacks.
  *		Andi Kleen	:	Fix inet_stream_connect TCP race.
- *
- *		This program is free software; you can redistribute it and/or
- *		modify it under the terms of the GNU General Public License
- *		as published by the Free Software Foundation; either version
- *		2 of the License, or (at your option) any later version.
  */
 
 #define pr_fmt(fmt) "IPv4: " fmt

commit c7cbdbf29f488a19982cd9f4a109887f18028bbb
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Wed Apr 17 22:51:48 2019 +0200

    net: rework SIOCGSTAMP ioctl handling
    
    The SIOCGSTAMP/SIOCGSTAMPNS ioctl commands are implemented by many
    socket protocol handlers, and all of those end up calling the same
    sock_get_timestamp()/sock_get_timestampns() helper functions, which
    results in a lot of duplicate code.
    
    With the introduction of 64-bit time_t on 32-bit architectures, this
    gets worse, as we then need four different ioctl commands in each
    socket protocol implementation.
    
    To simplify that, let's add a new .gettstamp() operation in
    struct proto_ops, and move ioctl implementation into the common
    sock_ioctl()/compat_sock_ioctl_trans() functions that these all go
    through.
    
    We can reuse the sock_get_timestamp() implementation, but generalize
    it so it can deal with both native and compat mode, as well as
    timeval and timespec structures.
    
    Acked-by: Stefan Schmidt <stefan@datenfreihafen.org>
    Acked-by: Neil Horman <nhorman@tuxdriver.com>
    Acked-by: Marc Kleine-Budde <mkl@pengutronix.de>
    Link: https://lore.kernel.org/lkml/CAK8P3a038aDQQotzua_QtKGhq8O9n+rdiz2=WDCp82ys8eUT+A@mail.gmail.com/
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>
    Acked-by: Willem de Bruijn <willemb@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 08a8430f5647..5183a2daba64 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -915,12 +915,6 @@ int inet_ioctl(struct socket *sock, unsigned int cmd, unsigned long arg)
 	struct rtentry rt;
 
 	switch (cmd) {
-	case SIOCGSTAMP:
-		err = sock_get_timestamp(sk, (struct timeval __user *)arg);
-		break;
-	case SIOCGSTAMPNS:
-		err = sock_get_timestampns(sk, (struct timespec __user *)arg);
-		break;
 	case SIOCADDRT:
 	case SIOCDELRT:
 		if (copy_from_user(&rt, p, sizeof(struct rtentry)))
@@ -992,6 +986,7 @@ const struct proto_ops inet_stream_ops = {
 	.getname	   = inet_getname,
 	.poll		   = tcp_poll,
 	.ioctl		   = inet_ioctl,
+	.gettstamp	   = sock_gettstamp,
 	.listen		   = inet_listen,
 	.shutdown	   = inet_shutdown,
 	.setsockopt	   = sock_common_setsockopt,
@@ -1027,6 +1022,7 @@ const struct proto_ops inet_dgram_ops = {
 	.getname	   = inet_getname,
 	.poll		   = udp_poll,
 	.ioctl		   = inet_ioctl,
+	.gettstamp	   = sock_gettstamp,
 	.listen		   = sock_no_listen,
 	.shutdown	   = inet_shutdown,
 	.setsockopt	   = sock_common_setsockopt,
@@ -1059,6 +1055,7 @@ static const struct proto_ops inet_sockraw_ops = {
 	.getname	   = inet_getname,
 	.poll		   = datagram_poll,
 	.ioctl		   = inet_ioctl,
+	.gettstamp	   = sock_gettstamp,
 	.listen		   = sock_no_listen,
 	.shutdown	   = inet_shutdown,
 	.setsockopt	   = sock_common_setsockopt,

commit 5869b8fadad0be948e310c456f111c4103f5fbfb
Author: Xin Long <lucien.xin@gmail.com>
Date:   Sun Mar 31 17:03:02 2019 +0800

    net: use rcu_dereference_protected to fetch sk_dst_cache in sk_destruct
    
    As Eric noticed, in .sk_destruct, sk->sk_dst_cache update is prevented, and
    no barrier is needed for this. So change to use rcu_dereference_protected()
    instead of rcu_dereference_check() to fetch sk_dst_cache in there.
    
    v1->v2:
      - no change, repost after net-next is open.
    
    Reported-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: Xin Long <lucien.xin@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 7f3a984ad618..08a8430f5647 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -160,7 +160,7 @@ void inet_sock_destruct(struct sock *sk)
 	WARN_ON(sk->sk_forward_alloc);
 
 	kfree(rcu_dereference_protected(inet->inet_opt, 1));
-	dst_release(rcu_dereference_check(sk->sk_dst_cache, 1));
+	dst_release(rcu_dereference_protected(sk->sk_dst_cache, 1));
 	dst_release(sk->sk_rx_dst);
 	sk_refcnt_debug_dec(sk);
 }

commit 8b27dae5a2e89a61c46c6dbc76c040c0e6d0ed4c
Author: Eric Dumazet <edumazet@google.com>
Date:   Fri Mar 22 08:56:40 2019 -0700

    tcp: add one skb cache for rx
    
    Often times, recvmsg() system calls and BH handling for a particular
    TCP socket are done on different cpus.
    
    This means the incoming skb had to be allocated on a cpu,
    but freed on another.
    
    This incurs a high spinlock contention in slab layer for small rpc,
    but also a high number of cache line ping pongs for larger packets.
    
    A full size GRO packet might use 45 page fragments, meaning
    that up to 45 put_page() can be involved.
    
    More over performing the __kfree_skb() in the recvmsg() context
    adds a latency for user applications, and increase probability
    of trapping them in backlog processing, since the BH handler
    might found the socket owned by the user.
    
    This patch, combined with the prior one increases the rpc
    performance by about 10 % on servers with large number of cores.
    
    (tcp_rr workload with 10,000 flows and 112 threads reach 9 Mpps
     instead of 8 Mpps)
    
    This also increases single bulk flow performance on 40Gbit+ links,
    since in this case there are often two cpus working in tandem :
    
     - CPU handling the NIC rx interrupts, feeding the receive queue,
      and (after this patch) freeing the skbs that were consumed.
    
     - CPU in recvmsg() system call, essentially 100 % busy copying out
      data to user space.
    
    Having at most one skb in a per-socket cache has very little risk
    of memory exhaustion, and since it is protected by socket lock,
    its management is essentially free.
    
    Note that if rps/rfs is used, we do not enable this feature, because
    there is high chance that the same cpu is handling both the recvmsg()
    system call and the TCP rx path, but that another cpu did the skb
    allocations in the device driver right before the RPS/RFS logic.
    
    To properly handle this case, it seems we would need to record
    on which cpu skb was allocated, and use a different channel
    to give skbs back to this cpu.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Acked-by: Soheil Hassas Yeganeh <soheil@google.com>
    Acked-by: Willem de Bruijn <willemb@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index eab3ebde981e..7f3a984ad618 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -136,6 +136,10 @@ void inet_sock_destruct(struct sock *sk)
 	struct inet_sock *inet = inet_sk(sk);
 
 	__skb_queue_purge(&sk->sk_receive_queue);
+	if (sk->sk_rx_skb_cache) {
+		__kfree_skb(sk->sk_rx_skb_cache);
+		sk->sk_rx_skb_cache = NULL;
+	}
 	__skb_queue_purge(&sk->sk_error_queue);
 
 	sk_mem_reclaim(sk);

commit 418e897e0716b238ea4252ed22a73ca37d3cbbc1
Author: Willem de Bruijn <willemb@google.com>
Date:   Wed Feb 20 10:52:12 2019 -0500

    gso: validate gso_type on ipip style tunnels
    
    Commit 121d57af308d ("gso: validate gso_type in GSO handlers") added
    gso_type validation to existing gso_segment callback functions, to
    filter out illegal and potentially dangerous SKB_GSO_DODGY packets.
    
    Convert tunnels that now call inet_gso_segment and ipv6_gso_segment
    directly to have their own callbacks and extend validation to these.
    
    Signed-off-by: Willem de Bruijn <willemb@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 0dfb72c46671..eab3ebde981e 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1385,6 +1385,15 @@ struct sk_buff *inet_gso_segment(struct sk_buff *skb,
 }
 EXPORT_SYMBOL(inet_gso_segment);
 
+static struct sk_buff *ipip_gso_segment(struct sk_buff *skb,
+					netdev_features_t features)
+{
+	if (!(skb_shinfo(skb)->gso_type & SKB_GSO_IPXIP4))
+		return ERR_PTR(-EINVAL);
+
+	return inet_gso_segment(skb, features);
+}
+
 INDIRECT_CALLABLE_DECLARE(struct sk_buff *tcp4_gro_receive(struct list_head *,
 							   struct sk_buff *));
 INDIRECT_CALLABLE_DECLARE(struct sk_buff *udp4_gro_receive(struct list_head *,
@@ -1861,7 +1870,7 @@ static struct packet_offload ip_packet_offload __read_mostly = {
 
 static const struct net_offload ipip_offload = {
 	.callbacks = {
-		.gso_segment	= inet_gso_segment,
+		.gso_segment	= ipip_gso_segment,
 		.gro_receive	= ipip_gro_receive,
 		.gro_complete	= ipip_gro_complete,
 	},

commit 028e0a4766844e7eeb31b93479ea6dd40cfc2895
Author: Paolo Abeni <pabeni@redhat.com>
Date:   Fri Dec 14 11:51:59 2018 +0100

    net: use indirect call wrappers at GRO transport layer
    
    This avoids an indirect call in the receive path for TCP and UDP
    packets. TCP takes precedence on UDP, so that we have a single
    additional conditional in the common case.
    
    When IPV6 is build as module, all gro symbols except UDPv6 are
    builtin, while the latter belong to the ipv6 module, so we
    need some special care.
    
    v1 -> v2:
     - adapted to INDIRECT_CALL_ changes
    v2 -> v3:
     - fix build issue with CONFIG_IPV6=m
    
    Signed-off-by: Paolo Abeni <pabeni@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 326c422c22f8..0dfb72c46671 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1385,6 +1385,10 @@ struct sk_buff *inet_gso_segment(struct sk_buff *skb,
 }
 EXPORT_SYMBOL(inet_gso_segment);
 
+INDIRECT_CALLABLE_DECLARE(struct sk_buff *tcp4_gro_receive(struct list_head *,
+							   struct sk_buff *));
+INDIRECT_CALLABLE_DECLARE(struct sk_buff *udp4_gro_receive(struct list_head *,
+							   struct sk_buff *));
 struct sk_buff *inet_gro_receive(struct list_head *head, struct sk_buff *skb)
 {
 	const struct net_offload *ops;
@@ -1494,7 +1498,8 @@ struct sk_buff *inet_gro_receive(struct list_head *head, struct sk_buff *skb)
 	skb_gro_pull(skb, sizeof(*iph));
 	skb_set_transport_header(skb, skb_gro_offset(skb));
 
-	pp = call_gro_receive(ops->callbacks.gro_receive, head, skb);
+	pp = indirect_call_gro_receive(tcp4_gro_receive, udp4_gro_receive,
+				       ops->callbacks.gro_receive, head, skb);
 
 out_unlock:
 	rcu_read_unlock();
@@ -1556,6 +1561,8 @@ int inet_recv_error(struct sock *sk, struct msghdr *msg, int len, int *addr_len)
 	return -EINVAL;
 }
 
+INDIRECT_CALLABLE_DECLARE(int tcp4_gro_complete(struct sk_buff *, int));
+INDIRECT_CALLABLE_DECLARE(int udp4_gro_complete(struct sk_buff *, int));
 int inet_gro_complete(struct sk_buff *skb, int nhoff)
 {
 	__be16 newlen = htons(skb->len - nhoff);
@@ -1581,7 +1588,9 @@ int inet_gro_complete(struct sk_buff *skb, int nhoff)
 	 * because any hdr with option will have been flushed in
 	 * inet_gro_receive().
 	 */
-	err = ops->callbacks.gro_complete(skb, nhoff + sizeof(*iph));
+	err = INDIRECT_CALL_2(ops->callbacks.gro_complete,
+			      tcp4_gro_complete, udp4_gro_complete,
+			      skb, nhoff + sizeof(*iph));
 
 out_unlock:
 	rcu_read_unlock();

commit 1295e2cf3065a55f35d112e4dfeb2c7322823249
Author: Yafang Shao <laoar.shao@gmail.com>
Date:   Wed Nov 7 19:20:16 2018 +0800

    inet: minor optimization for backlog setting in listen(2)
    
    Set the backlog earlier in inet_dccp_listen() and inet_listen(),
    then we can avoid the redundant setting.
    
    Signed-off-by: Yafang Shao <laoar.shao@gmail.com>
    Reviewed-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 07749c5b0a50..326c422c22f8 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -208,6 +208,7 @@ int inet_listen(struct socket *sock, int backlog)
 	if (!((1 << old_state) & (TCPF_CLOSE | TCPF_LISTEN)))
 		goto out;
 
+	sk->sk_max_ack_backlog = backlog;
 	/* Really, if the socket is already in listen state
 	 * we can only allow the backlog to be adjusted.
 	 */
@@ -231,7 +232,6 @@ int inet_listen(struct socket *sock, int backlog)
 			goto out;
 		tcp_call_bpf(sk, BPF_SOCK_OPS_TCP_LISTEN_CB, 0, NULL);
 	}
-	sk->sk_max_ack_backlog = backlog;
 	err = 0;
 
 out:

commit 6897445fb194c8ad046df4a13e1ee9f080a5a21e
Author: Mike Manning <mmanning@vyatta.att-mail.com>
Date:   Wed Nov 7 15:36:05 2018 +0000

    net: provide a sysctl raw_l3mdev_accept for raw socket lookup with VRFs
    
    Add a sysctl raw_l3mdev_accept to control raw socket lookup in a manner
    similar to use of tcp_l3mdev_accept for stream and of udp_l3mdev_accept
    for datagram sockets. Have this default to enabled for reasons of
    backwards compatibility. This is so as to specify the output device
    with cmsg and IP_PKTINFO, but using a socket not bound to the
    corresponding VRF. This allows e.g. older ping implementations to be
    run with specifying the device but without executing it in the VRF.
    If the option is disabled, packets received in a VRF context are only
    handled by a raw socket bound to the VRF, and correspondingly packets
    in the default VRF are only handled by a socket not bound to any VRF.
    
    Signed-off-by: Mike Manning <mmanning@vyatta.att-mail.com>
    Reviewed-by: David Ahern <dsahern@gmail.com>
    Tested-by: David Ahern <dsahern@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 1fbe2f815474..07749c5b0a50 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1964,6 +1964,8 @@ static int __init inet_init(void)
 	/* Add UDP-Lite (RFC 3828) */
 	udplite4_register();
 
+	raw_init();
+
 	ping_init();
 
 	/*

commit c56cae23c6b167acc68043c683c4573b80cbcc2c
Author: Toke Høiland-Jørgensen <toke@toke.dk>
Date:   Thu Sep 13 16:43:07 2018 +0200

    gso_segment: Reset skb->mac_len after modifying network header
    
    When splitting a GSO segment that consists of encapsulated packets, the
    skb->mac_len of the segments can end up being set wrong, causing packet
    drops in particular when using act_mirred and ifb interfaces in
    combination with a qdisc that splits GSO packets.
    
    This happens because at the time skb_segment() is called, network_header
    will point to the inner header, throwing off the calculation in
    skb_reset_mac_len(). The network_header is subsequently adjust by the
    outer IP gso_segment handlers, but they don't set the mac_len.
    
    Fix this by adding skb_reset_mac_len() calls to both the IPv4 and IPv6
    gso_segment handlers, after they modify the network_header.
    
    Many thanks to Eric Dumazet for his help in identifying the cause of
    the bug.
    
    Acked-by: Dave Taht <dave.taht@gmail.com>
    Reviewed-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: Toke Høiland-Jørgensen <toke@toke.dk>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 20fda8fb8ffd..1fbe2f815474 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1377,6 +1377,7 @@ struct sk_buff *inet_gso_segment(struct sk_buff *skb,
 		if (encap)
 			skb_reset_inner_headers(skb);
 		skb->network_header = (u8 *)iph - skb->head;
+		skb_reset_mac_len(skb);
 	} while ((skb = skb->next));
 
 out:

commit 432e05d328921c68c35bfdeff7d7b7400b8e3d1a
Author: Petr Machata <petrm@mellanox.com>
Date:   Wed Aug 1 00:36:03 2018 +0200

    net: ipv4: Control SKB reprioritization after forwarding
    
    After IPv4 packets are forwarded, the priority of the corresponding SKB
    is updated according to the TOS field of IPv4 header. This overrides any
    prioritization done earlier by e.g. an skbedit action or ingress-qos-map
    defined at a vlan device.
    
    Such overriding may not always be desirable. Even if the packet ends up
    being routed, which implies this is an L3 network node, an administrator
    may wish to preserve whatever prioritization was done earlier on in the
    pipeline.
    
    Therefore introduce a sysctl that controls this behavior. Keep the
    default value at 1 to maintain backward-compatible behavior.
    
    Signed-off-by: Petr Machata <petrm@mellanox.com>
    Reviewed-by: Ido Schimmel <idosch@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index ee707b91d1a7..20fda8fb8ffd 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1801,6 +1801,7 @@ static __net_init int inet_init_net(struct net *net)
 	 * We set them here, in case sysctl is not compiled.
 	 */
 	net->ipv4.sysctl_ip_default_ttl = IPDEFTTL;
+	net->ipv4.sysctl_ip_fwd_update_priority = 1;
 	net->ipv4.sysctl_ip_dynaddr = 0;
 	net->ipv4.sysctl_ip_early_demux = 1;
 	net->ipv4.sysctl_udp_early_demux = 1;

commit 83ba4645152d1177c161750e1064e3a8e7cee19b
Author: Vincent Bernat <vincent@bernat.im>
Date:   Tue Jul 31 21:18:11 2018 +0200

    net: add helpers checking if socket can be bound to nonlocal address
    
    The construction "net->ipv4.sysctl_ip_nonlocal_bind || inet->freebind
    || inet->transparent" is present three times and its IPv6 counterpart
    is also present three times. We introduce two small helpers to
    characterize these tests uniformly.
    
    Signed-off-by: Vincent Bernat <vincent@bernat.im>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index f2a0a3bab6b5..ee707b91d1a7 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -486,8 +486,7 @@ int __inet_bind(struct sock *sk, struct sockaddr *uaddr, int addr_len,
 	 *  is temporarily down)
 	 */
 	err = -EADDRNOTAVAIL;
-	if (!net->ipv4.sysctl_ip_nonlocal_bind &&
-	    !(inet->freebind || inet->transparent) &&
+	if (!inet_can_nonlocal_bind(net, inet) &&
 	    addr->sin_addr.s_addr != htonl(INADDR_ANY) &&
 	    chk_addr_ret != RTN_LOCAL &&
 	    chk_addr_ret != RTN_MULTICAST &&

commit f333ee0cdb27ba201e6cc0c99c76b1364aa29b86
Author: Andrey Ignatov <rdna@fb.com>
Date:   Wed Jul 11 17:33:32 2018 -0700

    bpf: Add BPF_SOCK_OPS_TCP_LISTEN_CB
    
    Add new TCP-BPF callback that is called on listen(2) right after socket
    transition to TCP_LISTEN state.
    
    It fills the gap for listening sockets in TCP-BPF. For example BPF
    program can set BPF_SOCK_OPS_STATE_CB_FLAG when socket becomes listening
    and track later transition from TCP_LISTEN to TCP_CLOSE with
    BPF_SOCK_OPS_STATE_CB callback.
    
    Before there was no way to do it with TCP-BPF and other options were
    much harder to work with. E.g. socket state tracking can be done with
    tracepoints (either raw or regular) but they can't be attached to cgroup
    and their lifetime has to be managed separately.
    
    Signed-off-by: Andrey Ignatov <rdna@fb.com>
    Acked-by: Alexei Starovoitov <ast@kernel.org>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index c716be13d58c..f2a0a3bab6b5 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -229,6 +229,7 @@ int inet_listen(struct socket *sock, int backlog)
 		err = inet_csk_listen_start(sk, backlog);
 		if (err)
 			goto out;
+		tcp_call_bpf(sk, BPF_SOCK_OPS_TCP_LISTEN_CB, 0, NULL);
 	}
 	sk->sk_max_ack_backlog = backlog;
 	err = 0;

commit 17266ee939849cb095ed7dd9edbec4162172226b
Author: Edward Cree <ecree@solarflare.com>
Date:   Mon Jul 2 16:14:12 2018 +0100

    net: ipv4: listified version of ip_rcv
    
    Also involved adding a way to run a netfilter hook over a list of packets.
     Rather than attempting to make netfilter know about lists (which would be
     a major project in itself) we just let it call the regular okfn (in this
     case ip_rcv_finish()) for any packets it steals, and have it give us back
     a list of packets it's synchronously accepted (which normally NF_HOOK
     would automatically call okfn() on, but we want to be able to potentially
     pass the list to a listified version of okfn().)
    The netfilter hooks themselves are indirect calls that still happen per-
     packet (see nf_hook_entry_hookfn()), but again, changing that can be left
     for future work.
    
    There is potential for out-of-order receives if the netfilter hook ends up
     synchronously stealing packets, as they will be processed before any
     accepts earlier in the list.  However, it was already possible for an
     asynchronous accept to cause out-of-order receives, so presumably this is
     considered OK.
    
    Signed-off-by: Edward Cree <ecree@solarflare.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 9263a2c114e0..c716be13d58c 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1882,6 +1882,7 @@ fs_initcall(ipv4_offload_init);
 static struct packet_type ip_packet_type __read_mostly = {
 	.type = cpu_to_be16(ETH_P_IP),
 	.func = ip_rcv,
+	.list_func = ip_list_rcv,
 };
 
 static int __init inet_init(void)

commit 5cd3da4ba2397ef07226ca2aa5094ed21ff8198f
Merge: f6779e4e53b6 d0fbad0aec1d
Author: David S. Miller <davem@davemloft.net>
Date:   Tue Jul 3 10:26:50 2018 +0900

    Merge ra.kernel.org:/pub/scm/linux/kernel/git/davem/net
    
    Simple overlapping changes in stmmac driver.
    
    Adjust skb_gro_flush_final_remcsum function signature to make GRO list
    changes in net-next, as per Stephen Rothwell's example merge
    resolution.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit a11e1d432b51f63ba698d044441284a661f01144
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jun 28 09:43:44 2018 -0700

    Revert changes to convert to ->poll_mask() and aio IOCB_CMD_POLL
    
    The poll() changes were not well thought out, and completely
    unexplained.  They also caused a huge performance regression, because
    "->poll()" was no longer a trivial file operation that just called down
    to the underlying file operations, but instead did at least two indirect
    calls.
    
    Indirect calls are sadly slow now with the Spectre mitigation, but the
    performance problem could at least be largely mitigated by changing the
    "->get_poll_head()" operation to just have a per-file-descriptor pointer
    to the poll head instead.  That gets rid of one of the new indirections.
    
    But that doesn't fix the new complexity that is completely unwarranted
    for the regular case.  The (undocumented) reason for the poll() changes
    was some alleged AIO poll race fixing, but we don't make the common case
    slower and more complex for some uncommon special case, so this all
    really needs way more explanations and most likely a fundamental
    redesign.
    
    [ This revert is a revert of about 30 different commits, not reverted
      individually because that would just be unnecessarily messy  - Linus ]
    
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 15e125558c76..b403499fdabe 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -986,7 +986,7 @@ const struct proto_ops inet_stream_ops = {
 	.socketpair	   = sock_no_socketpair,
 	.accept		   = inet_accept,
 	.getname	   = inet_getname,
-	.poll_mask	   = tcp_poll_mask,
+	.poll		   = tcp_poll,
 	.ioctl		   = inet_ioctl,
 	.listen		   = inet_listen,
 	.shutdown	   = inet_shutdown,
@@ -1021,7 +1021,7 @@ const struct proto_ops inet_dgram_ops = {
 	.socketpair	   = sock_no_socketpair,
 	.accept		   = sock_no_accept,
 	.getname	   = inet_getname,
-	.poll_mask	   = udp_poll_mask,
+	.poll		   = udp_poll,
 	.ioctl		   = inet_ioctl,
 	.listen		   = sock_no_listen,
 	.shutdown	   = inet_shutdown,
@@ -1042,7 +1042,7 @@ EXPORT_SYMBOL(inet_dgram_ops);
 
 /*
  * For SOCK_RAW sockets; should be the same as inet_dgram_ops but without
- * udp_poll_mask
+ * udp_poll
  */
 static const struct proto_ops inet_sockraw_ops = {
 	.family		   = PF_INET,
@@ -1053,7 +1053,7 @@ static const struct proto_ops inet_sockraw_ops = {
 	.socketpair	   = sock_no_socketpair,
 	.accept		   = sock_no_accept,
 	.getname	   = inet_getname,
-	.poll_mask	   = datagram_poll_mask,
+	.poll		   = datagram_poll,
 	.ioctl		   = inet_ioctl,
 	.listen		   = sock_no_listen,
 	.shutdown	   = inet_shutdown,

commit d4546c2509b1e9cd082e3682dcec98472e37ee5a
Author: David Miller <davem@davemloft.net>
Date:   Sun Jun 24 14:13:49 2018 +0900

    net: Convert GRO SKB handling to list_head.
    
    Manage pending per-NAPI GRO packets via list_head.
    
    Return an SKB pointer from the GRO receive handlers.  When GRO receive
    handlers return non-NULL, it means that this SKB needs to be completed
    at this time and removed from the NAPI queue.
    
    Several operations are greatly simplified by this transformation,
    especially timing out the oldest SKB in the list when gro_count
    exceeds MAX_GRO_SKBS, and napi_gro_flush() which walks the queue
    in reverse order.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 15e125558c76..06b218a2870f 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1384,12 +1384,12 @@ struct sk_buff *inet_gso_segment(struct sk_buff *skb,
 }
 EXPORT_SYMBOL(inet_gso_segment);
 
-struct sk_buff **inet_gro_receive(struct sk_buff **head, struct sk_buff *skb)
+struct sk_buff *inet_gro_receive(struct list_head *head, struct sk_buff *skb)
 {
 	const struct net_offload *ops;
-	struct sk_buff **pp = NULL;
-	struct sk_buff *p;
+	struct sk_buff *pp = NULL;
 	const struct iphdr *iph;
+	struct sk_buff *p;
 	unsigned int hlen;
 	unsigned int off;
 	unsigned int id;
@@ -1425,7 +1425,7 @@ struct sk_buff **inet_gro_receive(struct sk_buff **head, struct sk_buff *skb)
 	flush = (u16)((ntohl(*(__be32 *)iph) ^ skb_gro_len(skb)) | (id & ~IP_DF));
 	id >>= 16;
 
-	for (p = *head; p; p = p->next) {
+	list_for_each_entry(p, head, list) {
 		struct iphdr *iph2;
 		u16 flush_id;
 
@@ -1505,8 +1505,8 @@ struct sk_buff **inet_gro_receive(struct sk_buff **head, struct sk_buff *skb)
 }
 EXPORT_SYMBOL(inet_gro_receive);
 
-static struct sk_buff **ipip_gro_receive(struct sk_buff **head,
-					 struct sk_buff *skb)
+static struct sk_buff *ipip_gro_receive(struct list_head *head,
+					struct sk_buff *skb)
 {
 	if (NAPI_GRO_CB(skb)->encap_mark) {
 		NAPI_GRO_CB(skb)->flush = 1;

commit 1c8c5a9d38f607c0b6fd12c91cbe1a4418762a21
Merge: 285767604576 7170e6045a6a
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Jun 6 18:39:49 2018 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/davem/net-next
    
    Pull networking updates from David Miller:
    
     1) Add Maglev hashing scheduler to IPVS, from Inju Song.
    
     2) Lots of new TC subsystem tests from Roman Mashak.
    
     3) Add TCP zero copy receive and fix delayed acks and autotuning with
        SO_RCVLOWAT, from Eric Dumazet.
    
     4) Add XDP_REDIRECT support to mlx5 driver, from Jesper Dangaard
        Brouer.
    
     5) Add ttl inherit support to vxlan, from Hangbin Liu.
    
     6) Properly separate ipv6 routes into their logically independant
        components. fib6_info for the routing table, and fib6_nh for sets of
        nexthops, which thus can be shared. From David Ahern.
    
     7) Add bpf_xdp_adjust_tail helper, which can be used to generate ICMP
        messages from XDP programs. From Nikita V. Shirokov.
    
     8) Lots of long overdue cleanups to the r8169 driver, from Heiner
        Kallweit.
    
     9) Add BTF ("BPF Type Format"), from Martin KaFai Lau.
    
    10) Add traffic condition monitoring to iwlwifi, from Luca Coelho.
    
    11) Plumb extack down into fib_rules, from Roopa Prabhu.
    
    12) Add Flower classifier offload support to igb, from Vinicius Costa
        Gomes.
    
    13) Add UDP GSO support, from Willem de Bruijn.
    
    14) Add documentation for eBPF helpers, from Quentin Monnet.
    
    15) Add TLS tx offload to mlx5, from Ilya Lesokhin.
    
    16) Allow applications to be given the number of bytes available to read
        on a socket via a control message returned from recvmsg(), from
        Soheil Hassas Yeganeh.
    
    17) Add x86_32 eBPF JIT compiler, from Wang YanQing.
    
    18) Add AF_XDP sockets, with zerocopy support infrastructure as well.
        From Björn Töpel.
    
    19) Remove indirect load support from all of the BPF JITs and handle
        these operations in the verifier by translating them into native BPF
        instead. From Daniel Borkmann.
    
    20) Add GRO support to ipv6 gre tunnels, from Eran Ben Elisha.
    
    21) Allow XDP programs to do lookups in the main kernel routing tables
        for forwarding. From David Ahern.
    
    22) Allow drivers to store hardware state into an ELF section of kernel
        dump vmcore files, and use it in cxgb4. From Rahul Lakkireddy.
    
    23) Various RACK and loss detection improvements in TCP, from Yuchung
        Cheng.
    
    24) Add TCP SACK compression, from Eric Dumazet.
    
    25) Add User Mode Helper support and basic bpfilter infrastructure, from
        Alexei Starovoitov.
    
    26) Support ports and protocol values in RTM_GETROUTE, from Roopa
        Prabhu.
    
    27) Support bulking in ->ndo_xdp_xmit() API, from Jesper Dangaard
        Brouer.
    
    28) Add lots of forwarding selftests, from Petr Machata.
    
    29) Add generic network device failover driver, from Sridhar Samudrala.
    
    * ra.kernel.org:/pub/scm/linux/kernel/git/davem/net-next: (1959 commits)
      strparser: Add __strp_unpause and use it in ktls.
      rxrpc: Fix terminal retransmission connection ID to include the channel
      net: hns3: Optimize PF CMDQ interrupt switching process
      net: hns3: Fix for VF mailbox receiving unknown message
      net: hns3: Fix for VF mailbox cannot receiving PF response
      bnx2x: use the right constant
      Revert "net: sched: cls: Fix offloading when ingress dev is vxlan"
      net: dsa: b53: Fix for brcm tag issue in Cygnus SoC
      enic: fix UDP rss bits
      netdev-FAQ: clarify DaveM's position for stable backports
      rtnetlink: validate attributes in do_setlink()
      mlxsw: Add extack messages for port_{un, }split failures
      netdevsim: Add extack error message for devlink reload
      devlink: Add extack to reload and port_{un, }split operations
      net: metrics: add proper netlink validation
      ipmr: fix error path when ipmr_new_table fails
      ip6mr: only set ip6mr_table from setsockopt when ip6mr_new_table succeeds
      net: hns3: remove unused hclgevf_cfg_func_mta_filter
      netfilter: provide udp*_lib_lookup for nf_tproxy
      qed*: Utilize FW 8.37.2.0
      ...

commit db5051ead64a987e863f71a770351a75be542b15
Author: Christoph Hellwig <hch@lst.de>
Date:   Mon Apr 9 15:27:37 2018 +0200

    net: convert datagram_poll users tp ->poll_mask
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 116e3cd11515..8a59428e63ab 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1018,7 +1018,7 @@ const struct proto_ops inet_dgram_ops = {
 	.socketpair	   = sock_no_socketpair,
 	.accept		   = sock_no_accept,
 	.getname	   = inet_getname,
-	.poll		   = udp_poll,
+	.poll_mask	   = udp_poll_mask,
 	.ioctl		   = inet_ioctl,
 	.listen		   = sock_no_listen,
 	.shutdown	   = inet_shutdown,
@@ -1039,7 +1039,7 @@ EXPORT_SYMBOL(inet_dgram_ops);
 
 /*
  * For SOCK_RAW sockets; should be the same as inet_dgram_ops but without
- * udp_poll
+ * udp_poll_mask
  */
 static const struct proto_ops inet_sockraw_ops = {
 	.family		   = PF_INET,
@@ -1050,7 +1050,7 @@ static const struct proto_ops inet_sockraw_ops = {
 	.socketpair	   = sock_no_socketpair,
 	.accept		   = sock_no_accept,
 	.getname	   = inet_getname,
-	.poll		   = datagram_poll,
+	.poll_mask	   = datagram_poll_mask,
 	.ioctl		   = inet_ioctl,
 	.listen		   = sock_no_listen,
 	.shutdown	   = inet_shutdown,

commit 2c7d3dacebd4b432acc5011bf69a986f366d851d
Author: Christoph Hellwig <hch@lst.de>
Date:   Mon Apr 9 15:27:02 2018 +0200

    net/tcp: convert to ->poll_mask
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index eaed0367e669..116e3cd11515 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -986,7 +986,7 @@ const struct proto_ops inet_stream_ops = {
 	.socketpair	   = sock_no_socketpair,
 	.accept		   = inet_accept,
 	.getname	   = inet_getname,
-	.poll		   = tcp_poll,
+	.poll_mask	   = tcp_poll_mask,
 	.ioctl		   = inet_ioctl,
 	.listen		   = inet_listen,
 	.shutdown	   = inet_shutdown,

commit 05255b823a6173525587f29c4e8f1ca33fd7677d
Author: Eric Dumazet <edumazet@google.com>
Date:   Fri Apr 27 08:58:08 2018 -0700

    tcp: add TCP_ZEROCOPY_RECEIVE support for zerocopy receive
    
    When adding tcp mmap() implementation, I forgot that socket lock
    had to be taken before current->mm->mmap_sem. syzbot eventually caught
    the bug.
    
    Since we can not lock the socket in tcp mmap() handler we have to
    split the operation in two phases.
    
    1) mmap() on a tcp socket simply reserves VMA space, and nothing else.
      This operation does not involve any TCP locking.
    
    2) getsockopt(fd, IPPROTO_TCP, TCP_ZEROCOPY_RECEIVE, ...) implements
     the transfert of pages from skbs to one VMA.
      This operation only uses down_read(&current->mm->mmap_sem) after
      holding TCP lock, thus solving the lockdep issue.
    
    This new implementation was suggested by Andy Lutomirski with great details.
    
    Benefits are :
    
    - Better scalability, in case multiple threads reuse VMAS
       (without mmap()/munmap() calls) since mmap_sem wont be write locked.
    
    - Better error recovery.
       The previous mmap() model had to provide the expected size of the
       mapping. If for some reason one part could not be mapped (partial MSS),
       the whole operation had to be aborted.
       With the tcp_zerocopy_receive struct, kernel can report how
       many bytes were successfuly mapped, and how many bytes should
       be read to skip the problematic sequence.
    
    - No more memory allocation to hold an array of page pointers.
      16 MB mappings needed 32 KB for this array, potentially using vmalloc() :/
    
    - skbs are freed while mmap_sem has been released
    
    Following patch makes the change in tcp_mmap tool to demonstrate
    one possible use of mmap() and setsockopt(... TCP_ZEROCOPY_RECEIVE ...)
    
    Note that memcg might require additional changes.
    
    Fixes: 93ab6cc69162 ("tcp: implement mmap() for zero copy receive")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: syzbot <syzkaller@googlegroups.com>
    Suggested-by: Andy Lutomirski <luto@kernel.org>
    Cc: linux-mm@kvack.org
    Acked-by: Soheil Hassas Yeganeh <soheil@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 3ebf599cebae..b403499fdabe 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -994,7 +994,9 @@ const struct proto_ops inet_stream_ops = {
 	.getsockopt	   = sock_common_getsockopt,
 	.sendmsg	   = inet_sendmsg,
 	.recvmsg	   = inet_recvmsg,
+#ifdef CONFIG_MMU
 	.mmap		   = tcp_mmap,
+#endif
 	.sendpage	   = inet_sendpage,
 	.splice_read	   = tcp_splice_read,
 	.read_sock	   = tcp_read_sock,

commit 93ab6cc69162775201587cc9da00d5016dc890e2
Author: Eric Dumazet <edumazet@google.com>
Date:   Mon Apr 16 10:33:38 2018 -0700

    tcp: implement mmap() for zero copy receive
    
    Some networks can make sure TCP payload can exactly fit 4KB pages,
    with well chosen MSS/MTU and architectures.
    
    Implement mmap() system call so that applications can avoid
    copying data without complex splice() games.
    
    Note that a successful mmap( X bytes) on TCP socket is consuming
    bytes, as if recvmsg() has been done. (tp->copied += X)
    
    Only PROT_READ mappings are accepted, as skb page frags
    are fundamentally shared and read only.
    
    If tcp_mmap() finds data that is not a full page, or a patch of
    urgent data, -EINVAL is returned, no bytes are consumed.
    
    Application must fallback to recvmsg() to read the problematic sequence.
    
    mmap() wont block,  regardless of socket being in blocking or
    non-blocking mode. If not enough bytes are in receive queue,
    mmap() would return -EAGAIN, or -EIO if socket is in a state
    where no other bytes can be added into receive queue.
    
    An application might use SO_RCVLOWAT, poll() and/or ioctl( FIONREAD)
    to efficiently use mmap()
    
    On the sender side, MSG_EOR might help to clearly separate unaligned
    headers and 4K-aligned chunks if necessary.
    
    Tested:
    
    mlx4 (cx-3) 40Gbit NIC, with tcp_mmap program provided in following patch.
    MTU set to 4168  (4096 TCP payload, 40 bytes IPv6 header, 32 bytes TCP header)
    
    Without mmap() (tcp_mmap -s)
    
    received 32768 MB (0 % mmap'ed) in 8.13342 s, 33.7961 Gbit,
      cpu usage user:0.034 sys:3.778, 116.333 usec per MB, 63062 c-switches
    received 32768 MB (0 % mmap'ed) in 8.14501 s, 33.748 Gbit,
      cpu usage user:0.029 sys:3.997, 122.864 usec per MB, 61903 c-switches
    received 32768 MB (0 % mmap'ed) in 8.11723 s, 33.8635 Gbit,
      cpu usage user:0.048 sys:3.964, 122.437 usec per MB, 62983 c-switches
    received 32768 MB (0 % mmap'ed) in 8.39189 s, 32.7552 Gbit,
      cpu usage user:0.038 sys:4.181, 128.754 usec per MB, 55834 c-switches
    
    With mmap() on receiver (tcp_mmap -s -z)
    
    received 32768 MB (100 % mmap'ed) in 8.03083 s, 34.2278 Gbit,
      cpu usage user:0.024 sys:1.466, 45.4712 usec per MB, 65479 c-switches
    received 32768 MB (100 % mmap'ed) in 7.98805 s, 34.4111 Gbit,
      cpu usage user:0.026 sys:1.401, 43.5486 usec per MB, 65447 c-switches
    received 32768 MB (100 % mmap'ed) in 7.98377 s, 34.4296 Gbit,
      cpu usage user:0.028 sys:1.452, 45.166 usec per MB, 65496 c-switches
    received 32768 MB (99.9969 % mmap'ed) in 8.01838 s, 34.281 Gbit,
      cpu usage user:0.02 sys:1.446, 44.7388 usec per MB, 65505 c-switches
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index f5c562aaef35..3ebf599cebae 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -994,7 +994,7 @@ const struct proto_ops inet_stream_ops = {
 	.getsockopt	   = sock_common_getsockopt,
 	.sendmsg	   = inet_sendmsg,
 	.recvmsg	   = inet_recvmsg,
-	.mmap		   = sock_no_mmap,
+	.mmap		   = tcp_mmap,
 	.sendpage	   = inet_sendpage,
 	.splice_read	   = tcp_splice_read,
 	.read_sock	   = tcp_read_sock,

commit d1361840f8c519eaee9a78ffe09e4f0a1b586846
Author: Eric Dumazet <edumazet@google.com>
Date:   Mon Apr 16 10:33:35 2018 -0700

    tcp: fix SO_RCVLOWAT and RCVBUF autotuning
    
    Applications might use SO_RCVLOWAT on TCP socket hoping to receive
    one [E]POLLIN event only when a given amount of bytes are ready in socket
    receive queue.
    
    Problem is that receive autotuning is not aware of this constraint,
    meaning sk_rcvbuf might be too small to allow all bytes to be stored.
    
    Add a new (struct proto_ops)->set_rcvlowat method so that a protocol
    can override the default setsockopt(SO_RCVLOWAT) behavior.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index eaed0367e669..f5c562aaef35 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1006,6 +1006,7 @@ const struct proto_ops inet_stream_ops = {
 	.compat_getsockopt = compat_sock_common_getsockopt,
 	.compat_ioctl	   = inet_compat_ioctl,
 #endif
+	.set_rcvlowat	   = tcp_set_rcvlowat,
 };
 EXPORT_SYMBOL(inet_stream_ops);
 

commit d4069fe6fc91d496e4d1fe38b1a8b71aeb181c50
Merge: 70ae7222c61d 7828f20e3779
Author: David S. Miller <davem@davemloft.net>
Date:   Sat Mar 31 23:33:04 2018 -0400

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf-next
    
    Daniel Borkmann says:
    
    ====================
    pull-request: bpf-next 2018-03-31
    
    The following pull-request contains BPF updates for your *net-next* tree.
    
    The main changes are:
    
    1) Add raw BPF tracepoint API in order to have a BPF program type that
       can access kernel internal arguments of the tracepoints in their
       raw form similar to kprobes based BPF programs. This infrastructure
       also adds a new BPF_RAW_TRACEPOINT_OPEN command to BPF syscall which
       returns an anon-inode backed fd for the tracepoint object that allows
       for automatic detach of the BPF program resp. unregistering of the
       tracepoint probe on fd release, from Alexei.
    
    2) Add new BPF cgroup hooks at bind() and connect() entry in order to
       allow BPF programs to reject, inspect or modify user space passed
       struct sockaddr, and as well a hook at post bind time once the port
       has been allocated. They are used in FB's container management engine
       for implementing policy, replacing fragile LD_PRELOAD wrapper
       intercepting bind() and connect() calls that only works in limited
       scenarios like glibc based apps but not for other runtimes in
       containerized applications, from Andrey.
    
    3) BPF_F_INGRESS flag support has been added to sockmap programs for
       their redirect helper call bringing it in line with cls_bpf based
       programs. Support is added for both variants of sockmap programs,
       meaning for tx ULP hooks as well as recv skb hooks, from John.
    
    4) Various improvements on BPF side for the nfp driver, besides others
       this work adds BPF map update and delete helper call support from
       the datapath, JITing of 32 and 64 bit XADD instructions as well as
       offload support of bpf_get_prandom_u32() call. Initial implementation
       of nfp packet cache has been tackled that optimizes memory access
       (see merge commit for further details), from Jakub and Jiong.
    
    5) Removal of struct bpf_verifier_env argument from the print_bpf_insn()
       API has been done in order to prepare to use print_bpf_insn() soon
       out of perf tool directly. This makes the print_bpf_insn() API more
       generic and pushes the env into private data. bpftool is adjusted
       as well with the print_bpf_insn() argument removal, from Jiri.
    
    6) Couple of cleanups and prep work for the upcoming BTF (BPF Type
       Format). The latter will reuse the current BPF verifier log as
       well, thus bpf_verifier_log() is further generalized, from Martin.
    
    7) For bpf_getsockopt() and bpf_setsockopt() helpers, IPv4 IP_TOS read
       and write support has been added in similar fashion to existing
       IPv6 IPV6_TCLASS socket option we already have, from Nikita.
    
    8) Fixes in recent sockmap scatterlist API usage, which did not use
       sg_init_table() for initialization thus triggering a BUG_ON() in
       scatterlist API when CONFIG_DEBUG_SG was enabled. This adds and
       uses a small helper sg_init_marker() to properly handle the affected
       cases, from Prashant.
    
    9) Let the BPF core follow IDR code convention and therefore use the
       idr_preload() and idr_preload_end() helpers, which would also help
       idr_alloc_cyclic() under GFP_ATOMIC to better succeed under memory
       pressure, from Shaohua.
    
    10) Last but not least, a spelling fix in an error message for the
        BPF cookie UID helper under BPF sample code, from Colin.
    ====================
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit aac3fc320d9404f2665a8b1249dc3170d5fa3caf
Author: Andrey Ignatov <rdna@fb.com>
Date:   Fri Mar 30 15:08:07 2018 -0700

    bpf: Post-hooks for sys_bind
    
    "Post-hooks" are hooks that are called right before returning from
    sys_bind. At this time IP and port are already allocated and no further
    changes to `struct sock` can happen before returning from sys_bind but
    BPF program has a chance to inspect the socket and change sys_bind
    result.
    
    Specifically it can e.g. inspect what port was allocated and if it
    doesn't satisfy some policy, BPF program can force sys_bind to fail and
    return EPERM to user.
    
    Another example of usage is recording the IP:port pair to some map to
    use it in later calls to sys_connect. E.g. if some TCP server inside
    cgroup was bound to some IP:port_n, it can be recorded to a map. And
    later when some TCP client inside same cgroup is trying to connect to
    127.0.0.1:port_n, BPF hook for sys_connect can override the destination
    and connect application to IP:port_n instead of 127.0.0.1:port_n. That
    helps forcing all applications inside a cgroup to use desired IP and not
    break those applications if they e.g. use localhost to communicate
    between each other.
    
    == Implementation details ==
    
    Post-hooks are implemented as two new attach types
    `BPF_CGROUP_INET4_POST_BIND` and `BPF_CGROUP_INET6_POST_BIND` for
    existing prog type `BPF_PROG_TYPE_CGROUP_SOCK`.
    
    Separate attach types for IPv4 and IPv6 are introduced to avoid access
    to IPv6 field in `struct sock` from `inet_bind()` and to IPv4 field from
    `inet6_bind()` since those fields might not make sense in such cases.
    
    Signed-off-by: Andrey Ignatov <rdna@fb.com>
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 488fe26ac8e5..142d4c35b493 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -519,12 +519,18 @@ int __inet_bind(struct sock *sk, struct sockaddr *uaddr, int addr_len,
 		inet->inet_saddr = 0;  /* Use device */
 
 	/* Make sure we are allowed to bind here. */
-	if ((snum || !(inet->bind_address_no_port ||
-		       force_bind_address_no_port)) &&
-	    sk->sk_prot->get_port(sk, snum)) {
-		inet->inet_saddr = inet->inet_rcv_saddr = 0;
-		err = -EADDRINUSE;
-		goto out_release_sock;
+	if (snum || !(inet->bind_address_no_port ||
+		      force_bind_address_no_port)) {
+		if (sk->sk_prot->get_port(sk, snum)) {
+			inet->inet_saddr = inet->inet_rcv_saddr = 0;
+			err = -EADDRINUSE;
+			goto out_release_sock;
+		}
+		err = BPF_CGROUP_RUN_PROG_INET4_POST_BIND(sk);
+		if (err) {
+			inet->inet_saddr = inet->inet_rcv_saddr = 0;
+			goto out_release_sock;
+		}
 	}
 
 	if (inet->inet_rcv_saddr)

commit d74bad4e74ee373787a9ae24197c17b7cdc428d5
Author: Andrey Ignatov <rdna@fb.com>
Date:   Fri Mar 30 15:08:05 2018 -0700

    bpf: Hooks for sys_connect
    
    == The problem ==
    
    See description of the problem in the initial patch of this patch set.
    
    == The solution ==
    
    The patch provides much more reliable in-kernel solution for the 2nd
    part of the problem: making outgoing connecttion from desired IP.
    
    It adds new attach types `BPF_CGROUP_INET4_CONNECT` and
    `BPF_CGROUP_INET6_CONNECT` for program type
    `BPF_PROG_TYPE_CGROUP_SOCK_ADDR` that can be used to override both
    source and destination of a connection at connect(2) time.
    
    Local end of connection can be bound to desired IP using newly
    introduced BPF-helper `bpf_bind()`. It allows to bind to only IP though,
    and doesn't support binding to port, i.e. leverages
    `IP_BIND_ADDRESS_NO_PORT` socket option. There are two reasons for this:
    * looking for a free port is expensive and can affect performance
      significantly;
    * there is no use-case for port.
    
    As for remote end (`struct sockaddr *` passed by user), both parts of it
    can be overridden, remote IP and remote port. It's useful if an
    application inside cgroup wants to connect to another application inside
    same cgroup or to itself, but knows nothing about IP assigned to the
    cgroup.
    
    Support is added for IPv4 and IPv6, for TCP and UDP.
    
    IPv4 and IPv6 have separate attach types for same reason as sys_bind
    hooks, i.e. to prevent reading from / writing to e.g. user_ip6 fields
    when user passes sockaddr_in since it'd be out-of-bound.
    
    == Implementation notes ==
    
    The patch introduces new field in `struct proto`: `pre_connect` that is
    a pointer to a function with same signature as `connect` but is called
    before it. The reason is in some cases BPF hooks should be called way
    before control is passed to `sk->sk_prot->connect`. Specifically
    `inet_dgram_connect` autobinds socket before calling
    `sk->sk_prot->connect` and there is no way to call `bpf_bind()` from
    hooks from e.g. `ip4_datagram_connect` or `ip6_datagram_connect` since
    it'd cause double-bind. On the other hand `proto.pre_connect` provides a
    flexible way to add BPF hooks for connect only for necessary `proto` and
    call them at desired time before `connect`. Since `bpf_bind()` is
    allowed to bind only to IP and autobind in `inet_dgram_connect` binds
    only port there is no chance of double-bind.
    
    bpf_bind() sets `force_bind_address_no_port` to bind to only IP despite
    of value of `bind_address_no_port` socket field.
    
    bpf_bind() sets `with_lock` to `false` when calling to __inet_bind()
    and __inet6_bind() since all call-sites, where bpf_bind() is called,
    already hold socket lock.
    
    Signed-off-by: Andrey Ignatov <rdna@fb.com>
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index e203a39d6988..488fe26ac8e5 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -547,12 +547,19 @@ int inet_dgram_connect(struct socket *sock, struct sockaddr *uaddr,
 		       int addr_len, int flags)
 {
 	struct sock *sk = sock->sk;
+	int err;
 
 	if (addr_len < sizeof(uaddr->sa_family))
 		return -EINVAL;
 	if (uaddr->sa_family == AF_UNSPEC)
 		return sk->sk_prot->disconnect(sk, flags);
 
+	if (BPF_CGROUP_PRE_CONNECT_ENABLED(sk)) {
+		err = sk->sk_prot->pre_connect(sk, uaddr, addr_len);
+		if (err)
+			return err;
+	}
+
 	if (!inet_sk(sk)->inet_num && inet_autobind(sk))
 		return -EAGAIN;
 	return sk->sk_prot->connect(sk, uaddr, addr_len);
@@ -633,6 +640,12 @@ int __inet_stream_connect(struct socket *sock, struct sockaddr *uaddr,
 		if (sk->sk_state != TCP_CLOSE)
 			goto out;
 
+		if (BPF_CGROUP_PRE_CONNECT_ENABLED(sk)) {
+			err = sk->sk_prot->pre_connect(sk, uaddr, addr_len);
+			if (err)
+				goto out;
+		}
+
 		err = sk->sk_prot->connect(sk, uaddr, addr_len);
 		if (err < 0)
 			goto out;

commit 3679d585bbc07a1ac4448d5b478b492cad3587ce
Author: Andrey Ignatov <rdna@fb.com>
Date:   Fri Mar 30 15:08:04 2018 -0700

    net: Introduce __inet_bind() and __inet6_bind
    
    Refactor `bind()` code to make it ready to be called from BPF helper
    function `bpf_bind()` (will be added soon). Implementation of
    `inet_bind()` and `inet6_bind()` is separated into `__inet_bind()` and
    `__inet6_bind()` correspondingly. These function can be used from both
    `sk_prot->bind` and `bpf_bind()` contexts.
    
    New functions have two additional arguments.
    
    `force_bind_address_no_port` forces binding to IP only w/o checking
    `inet_sock.bind_address_no_port` field. It'll allow to bind local end of
    a connection to desired IP in `bpf_bind()` w/o changing
    `bind_address_no_port` field of a socket. It's useful since `bpf_bind()`
    can return an error and we'd need to restore original value of
    `bind_address_no_port` in that case if we changed this before calling to
    the helper.
    
    `with_lock` specifies whether to lock socket when working with `struct
    sk` or not. The argument is set to `true` for `sk_prot->bind`, i.e. old
    behavior is preserved. But it will be set to `false` for `bpf_bind()`
    use-case. The reason is all call-sites, where `bpf_bind()` will be
    called, already hold that socket lock.
    
    Signed-off-by: Andrey Ignatov <rdna@fb.com>
    Acked-by: Alexei Starovoitov <ast@kernel.org>
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 2dec266507dc..e203a39d6988 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -432,30 +432,37 @@ EXPORT_SYMBOL(inet_release);
 
 int inet_bind(struct socket *sock, struct sockaddr *uaddr, int addr_len)
 {
-	struct sockaddr_in *addr = (struct sockaddr_in *)uaddr;
 	struct sock *sk = sock->sk;
-	struct inet_sock *inet = inet_sk(sk);
-	struct net *net = sock_net(sk);
-	unsigned short snum;
-	int chk_addr_ret;
-	u32 tb_id = RT_TABLE_LOCAL;
 	int err;
 
 	/* If the socket has its own bind function then use it. (RAW) */
 	if (sk->sk_prot->bind) {
-		err = sk->sk_prot->bind(sk, uaddr, addr_len);
-		goto out;
+		return sk->sk_prot->bind(sk, uaddr, addr_len);
 	}
-	err = -EINVAL;
 	if (addr_len < sizeof(struct sockaddr_in))
-		goto out;
+		return -EINVAL;
 
 	/* BPF prog is run before any checks are done so that if the prog
 	 * changes context in a wrong way it will be caught.
 	 */
 	err = BPF_CGROUP_RUN_PROG_INET4_BIND(sk, uaddr);
 	if (err)
-		goto out;
+		return err;
+
+	return __inet_bind(sk, uaddr, addr_len, false, true);
+}
+EXPORT_SYMBOL(inet_bind);
+
+int __inet_bind(struct sock *sk, struct sockaddr *uaddr, int addr_len,
+		bool force_bind_address_no_port, bool with_lock)
+{
+	struct sockaddr_in *addr = (struct sockaddr_in *)uaddr;
+	struct inet_sock *inet = inet_sk(sk);
+	struct net *net = sock_net(sk);
+	unsigned short snum;
+	int chk_addr_ret;
+	u32 tb_id = RT_TABLE_LOCAL;
+	int err;
 
 	if (addr->sin_family != AF_INET) {
 		/* Compatibility games : accept AF_UNSPEC (mapped to AF_INET)
@@ -499,7 +506,8 @@ int inet_bind(struct socket *sock, struct sockaddr *uaddr, int addr_len)
 	 *      would be illegal to use them (multicast/broadcast) in
 	 *      which case the sending device address is used.
 	 */
-	lock_sock(sk);
+	if (with_lock)
+		lock_sock(sk);
 
 	/* Check these errors (active socket, double bind). */
 	err = -EINVAL;
@@ -511,7 +519,8 @@ int inet_bind(struct socket *sock, struct sockaddr *uaddr, int addr_len)
 		inet->inet_saddr = 0;  /* Use device */
 
 	/* Make sure we are allowed to bind here. */
-	if ((snum || !inet->bind_address_no_port) &&
+	if ((snum || !(inet->bind_address_no_port ||
+		       force_bind_address_no_port)) &&
 	    sk->sk_prot->get_port(sk, snum)) {
 		inet->inet_saddr = inet->inet_rcv_saddr = 0;
 		err = -EADDRINUSE;
@@ -528,11 +537,11 @@ int inet_bind(struct socket *sock, struct sockaddr *uaddr, int addr_len)
 	sk_dst_reset(sk);
 	err = 0;
 out_release_sock:
-	release_sock(sk);
+	if (with_lock)
+		release_sock(sk);
 out:
 	return err;
 }
-EXPORT_SYMBOL(inet_bind);
 
 int inet_dgram_connect(struct socket *sock, struct sockaddr *uaddr,
 		       int addr_len, int flags)

commit 4fbac77d2d092b475dda9eea66da674369665427
Author: Andrey Ignatov <rdna@fb.com>
Date:   Fri Mar 30 15:08:02 2018 -0700

    bpf: Hooks for sys_bind
    
    == The problem ==
    
    There is a use-case when all processes inside a cgroup should use one
    single IP address on a host that has multiple IP configured.  Those
    processes should use the IP for both ingress and egress, for TCP and UDP
    traffic. So TCP/UDP servers should be bound to that IP to accept
    incoming connections on it, and TCP/UDP clients should make outgoing
    connections from that IP. It should not require changing application
    code since it's often not possible.
    
    Currently it's solved by intercepting glibc wrappers around syscalls
    such as `bind(2)` and `connect(2)`. It's done by a shared library that
    is preloaded for every process in a cgroup so that whenever TCP/UDP
    server calls `bind(2)`, the library replaces IP in sockaddr before
    passing arguments to syscall. When application calls `connect(2)` the
    library transparently binds the local end of connection to that IP
    (`bind(2)` with `IP_BIND_ADDRESS_NO_PORT` to avoid performance penalty).
    
    Shared library approach is fragile though, e.g.:
    * some applications clear env vars (incl. `LD_PRELOAD`);
    * `/etc/ld.so.preload` doesn't help since some applications are linked
      with option `-z nodefaultlib`;
    * other applications don't use glibc and there is nothing to intercept.
    
    == The solution ==
    
    The patch provides much more reliable in-kernel solution for the 1st
    part of the problem: binding TCP/UDP servers on desired IP. It does not
    depend on application environment and implementation details (whether
    glibc is used or not).
    
    It adds new eBPF program type `BPF_PROG_TYPE_CGROUP_SOCK_ADDR` and
    attach types `BPF_CGROUP_INET4_BIND` and `BPF_CGROUP_INET6_BIND`
    (similar to already existing `BPF_CGROUP_INET_SOCK_CREATE`).
    
    The new program type is intended to be used with sockets (`struct sock`)
    in a cgroup and provided by user `struct sockaddr`. Pointers to both of
    them are parts of the context passed to programs of newly added types.
    
    The new attach types provides hooks in `bind(2)` system call for both
    IPv4 and IPv6 so that one can write a program to override IP addresses
    and ports user program tries to bind to and apply such a program for
    whole cgroup.
    
    == Implementation notes ==
    
    [1]
    Separate attach types for `AF_INET` and `AF_INET6` are added
    intentionally to prevent reading/writing to offsets that don't make
    sense for corresponding socket family. E.g. if user passes `sockaddr_in`
    it doesn't make sense to read from / write to `user_ip6[]` context
    fields.
    
    [2]
    The write access to `struct bpf_sock_addr_kern` is implemented using
    special field as an additional "register".
    
    There are just two registers in `sock_addr_convert_ctx_access`: `src`
    with value to write and `dst` with pointer to context that can't be
    changed not to break later instructions. But the fields, allowed to
    write to, are not available directly and to access them address of
    corresponding pointer has to be loaded first. To get additional register
    the 1st not used by `src` and `dst` one is taken, its content is saved
    to `bpf_sock_addr_kern.tmp_reg`, then the register is used to load
    address of pointer field, and finally the register's content is restored
    from the temporary field after writing `src` value.
    
    Signed-off-by: Andrey Ignatov <rdna@fb.com>
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index e8c7fad8c329..2dec266507dc 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -450,6 +450,13 @@ int inet_bind(struct socket *sock, struct sockaddr *uaddr, int addr_len)
 	if (addr_len < sizeof(struct sockaddr_in))
 		goto out;
 
+	/* BPF prog is run before any checks are done so that if the prog
+	 * changes context in a wrong way it will be caught.
+	 */
+	err = BPF_CGROUP_RUN_PROG_INET4_BIND(sk, uaddr);
+	if (err)
+		goto out;
+
 	if (addr->sin_family != AF_INET) {
 		/* Compatibility games : accept AF_UNSPEC (mapped to AF_INET)
 		 * only if s_addr is INADDR_ANY.

commit 2f635ceeb22ba13c307236d69795fbb29cfa3e7c
Author: Kirill Tkhai <ktkhai@virtuozzo.com>
Date:   Tue Mar 27 18:02:13 2018 +0300

    net: Drop pernet_operations::async
    
    Synchronous pernet_operations are not allowed anymore.
    All are asynchronous. So, drop the structure member.
    
    Signed-off-by: Kirill Tkhai <ktkhai@virtuozzo.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index e8c7fad8c329..f98e2f0db841 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1735,7 +1735,6 @@ static __net_exit void ipv4_mib_exit_net(struct net *net)
 static __net_initdata struct pernet_operations ipv4_mib_ops = {
 	.init = ipv4_mib_init_net,
 	.exit = ipv4_mib_exit_net,
-	.async = true,
 };
 
 static int __init init_ipv4_mibs(void)
@@ -1789,7 +1788,6 @@ static __net_exit void inet_exit_net(struct net *net)
 static __net_initdata struct pernet_operations af_inet_ops = {
 	.init = inet_init_net,
 	.exit = inet_exit_net,
-	.async = true,
 };
 
 static int __init init_inet_pernet_ops(void)

commit f84c6821aa540342360067604ad156e3d53a67ed
Author: Kirill Tkhai <ktkhai@virtuozzo.com>
Date:   Tue Feb 13 12:29:52 2018 +0300

    net: Convert pernet_subsys, registered from inet_init()
    
    arp_net_ops just addr/removes /proc entry.
    
    devinet_ops allocates and frees duplicate of init_net tables
    and (un)registers sysctl entries.
    
    fib_net_ops allocates and frees pernet tables, creates/destroys
    netlink socket and (un)initializes /proc entries. Foreign
    pernet_operations do not touch them.
    
    ip_rt_proc_ops only modifies pernet /proc entries.
    
    xfrm_net_ops creates/destroys /proc entries, allocates/frees
    pernet statistics, hashes and tables, and (un)initializes
    sysctl files. These are not touched by foreigh pernet_operations
    
    xfrm4_net_ops allocates/frees private pernet memory, and
    configures sysctls.
    
    sysctl_route_ops creates/destroys sysctls.
    
    rt_genid_ops only initializes fields of just allocated net.
    
    ipv4_inetpeer_ops allocated/frees net private memory.
    
    igmp_net_ops just creates/destroys /proc files and socket,
    noone else interested in.
    
    tcp_sk_ops seems to be safe, because tcp_sk_init() does not
    depend on any other pernet_operations modifications. Iteration
    over hash table in inet_twsk_purge() is made under RCU lock,
    and it's safe to iterate the table this way. Removing from
    the table happen from inet_twsk_deschedule_put(), but this
    function is safe without any extern locks, as it's synchronized
    inside itself. There are many examples, it's used in different
    context. So, it's safe to leave tcp_sk_exit_batch() unlocked.
    
    tcp_net_metrics_ops is synchronized on tcp_metrics_lock and safe.
    
    udplite4_net_ops only creates/destroys pernet /proc file.
    
    icmp_sk_ops creates percpu sockets, not touched by foreign
    pernet_operations.
    
    ipmr_net_ops creates/destroys pernet fib tables, (un)registers
    fib rules and /proc files. This seem to be safe to execute
    in parallel with foreign pernet_operations.
    
    af_inet_ops just sets up default parameters of newly created net.
    
    ipv4_mib_ops creates and destroys pernet percpu statistics.
    
    raw_net_ops, tcp4_net_ops, udp4_net_ops, ping_v4_net_ops
    and ip_proc_ops only create/destroy pernet /proc files.
    
    ip4_frags_ops creates and destroys sysctl file.
    
    So, it's safe to make the pernet_operations async.
    
    Signed-off-by: Kirill Tkhai <ktkhai@virtuozzo.com>
    Acked-by: Andrei Vagin <avagin@virtuozzo.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index f98e2f0db841..e8c7fad8c329 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1735,6 +1735,7 @@ static __net_exit void ipv4_mib_exit_net(struct net *net)
 static __net_initdata struct pernet_operations ipv4_mib_ops = {
 	.init = ipv4_mib_init_net,
 	.exit = ipv4_mib_exit_net,
+	.async = true,
 };
 
 static int __init init_ipv4_mibs(void)
@@ -1788,6 +1789,7 @@ static __net_exit void inet_exit_net(struct net *net)
 static __net_initdata struct pernet_operations af_inet_ops = {
 	.init = inet_init_net,
 	.exit = inet_exit_net,
+	.async = true,
 };
 
 static int __init init_inet_pernet_ops(void)

commit 9b2c45d479d0fb8647c9e83359df69162b5fbe5f
Author: Denys Vlasenko <dvlasenk@redhat.com>
Date:   Mon Feb 12 20:00:20 2018 +0100

    net: make getname() functions return length rather than use int* parameter
    
    Changes since v1:
    Added changes in these files:
        drivers/infiniband/hw/usnic/usnic_transport.c
        drivers/staging/lustre/lnet/lnet/lib-socket.c
        drivers/target/iscsi/iscsi_target_login.c
        drivers/vhost/net.c
        fs/dlm/lowcomms.c
        fs/ocfs2/cluster/tcp.c
        security/tomoyo/network.c
    
    Before:
    All these functions either return a negative error indicator,
    or store length of sockaddr into "int *socklen" parameter
    and return zero on success.
    
    "int *socklen" parameter is awkward. For example, if caller does not
    care, it still needs to provide on-stack storage for the value
    it does not need.
    
    None of the many FOO_getname() functions of various protocols
    ever used old value of *socklen. They always just overwrite it.
    
    This change drops this parameter, and makes all these functions, on success,
    return length of sockaddr. It's always >= 0 and can be differentiated
    from an error.
    
    Tests in callers are changed from "if (err)" to "if (err < 0)", where needed.
    
    rpc_sockname() lost "int buflen" parameter, since its only use was
    to be passed to kernel_getsockname() as &buflen and subsequently
    not used in any way.
    
    Userspace API is not changed.
    
        text    data     bss      dec     hex filename
    30108430 2633624  873672 33615726 200ef6e vmlinux.before.o
    30108109 2633612  873672 33615393 200ee21 vmlinux.o
    
    Signed-off-by: Denys Vlasenko <dvlasenk@redhat.com>
    CC: David S. Miller <davem@davemloft.net>
    CC: linux-kernel@vger.kernel.org
    CC: netdev@vger.kernel.org
    CC: linux-bluetooth@vger.kernel.org
    CC: linux-decnet-user@lists.sourceforge.net
    CC: linux-wireless@vger.kernel.org
    CC: linux-rdma@vger.kernel.org
    CC: linux-sctp@vger.kernel.org
    CC: linux-nfs@vger.kernel.org
    CC: linux-x25@vger.kernel.org
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index e4329e161943..f98e2f0db841 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -723,7 +723,7 @@ EXPORT_SYMBOL(inet_accept);
  *	This does both peername and sockname.
  */
 int inet_getname(struct socket *sock, struct sockaddr *uaddr,
-			int *uaddr_len, int peer)
+			int peer)
 {
 	struct sock *sk		= sock->sk;
 	struct inet_sock *inet	= inet_sk(sk);
@@ -745,8 +745,7 @@ int inet_getname(struct socket *sock, struct sockaddr *uaddr,
 		sin->sin_addr.s_addr = addr;
 	}
 	memset(sin->sin_zero, 0, sizeof(sin->sin_zero));
-	*uaddr_len = sizeof(*sin);
-	return 0;
+	return sizeof(*sin);
 }
 EXPORT_SYMBOL(inet_getname);
 

commit a9a08845e9acbd224e4ee466f5c1275ed50054e8
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sun Feb 11 14:34:03 2018 -0800

    vfs: do bulk POLL* -> EPOLL* replacement
    
    This is the mindless scripted replacement of kernel use of POLL*
    variables as described by Al, done by this script:
    
        for V in IN OUT PRI ERR RDNORM RDBAND WRNORM WRBAND HUP RDHUP NVAL MSG; do
            L=`git grep -l -w POLL$V | grep -v '^t' | grep -v /um/ | grep -v '^sa' | grep -v '/poll.h$'|grep -v '^D'`
            for f in $L; do sed -i "-es/^\([^\"]*\)\(\<POLL$V\>\)/\\1E\\2/" $f; done
        done
    
    with de-mangling cleanups yet to come.
    
    NOTE! On almost all architectures, the EPOLL* constants have the same
    values as the POLL* constants do.  But they keyword here is "almost".
    For various bad reasons they aren't the same, and epoll() doesn't
    actually work quite correctly in some cases due to this on Sparc et al.
    
    The next patch from Al will sort out the final differences, and we
    should be all done.
    
    Scripted-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index c24008daa3d8..e4329e161943 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -828,7 +828,7 @@ int inet_shutdown(struct socket *sock, int how)
 	case TCP_CLOSE:
 		err = -ENOTCONN;
 		/* Hack to wake up other listeners, who can poll for
-		   POLLHUP, even on eg. unconnected UDP sockets -- RR */
+		   EPOLLHUP, even on eg. unconnected UDP sockets -- RR */
 		/* fall through */
 	default:
 		sk->sk_shutdown |= how;

commit ca25c30040f93c127ff1651aa636c0174f1e0cdb
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sat Jul 1 08:03:10 2017 -0400

    ip_rt_ioctl(): take copyin to caller
    
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 1c2bfee2e249..c24008daa3d8 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -874,6 +874,7 @@ int inet_ioctl(struct socket *sock, unsigned int cmd, unsigned long arg)
 	struct net *net = sock_net(sk);
 	void __user *p = (void __user *)arg;
 	struct ifreq ifr;
+	struct rtentry rt;
 
 	switch (cmd) {
 	case SIOCGSTAMP:
@@ -884,8 +885,12 @@ int inet_ioctl(struct socket *sock, unsigned int cmd, unsigned long arg)
 		break;
 	case SIOCADDRT:
 	case SIOCDELRT:
+		if (copy_from_user(&rt, p, sizeof(struct rtentry)))
+			return -EFAULT;
+		err = ip_rt_ioctl(net, cmd, &rt);
+		break;
 	case SIOCRTMSG:
-		err = ip_rt_ioctl(net, cmd, (void __user *)arg);
+		err = -EINVAL;
 		break;
 	case SIOCDARP:
 	case SIOCGARP:

commit 03aef17bb79b3dc02b1352ee2f55fca799dbad7f
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sat Jul 1 07:53:12 2017 -0400

    devinet_ioctl(): take copyin/copyout to caller
    
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 54cccdd8b1e3..1c2bfee2e249 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -872,6 +872,8 @@ int inet_ioctl(struct socket *sock, unsigned int cmd, unsigned long arg)
 	struct sock *sk = sock->sk;
 	int err = 0;
 	struct net *net = sock_net(sk);
+	void __user *p = (void __user *)arg;
+	struct ifreq ifr;
 
 	switch (cmd) {
 	case SIOCGSTAMP:
@@ -891,17 +893,26 @@ int inet_ioctl(struct socket *sock, unsigned int cmd, unsigned long arg)
 		err = arp_ioctl(net, cmd, (void __user *)arg);
 		break;
 	case SIOCGIFADDR:
-	case SIOCSIFADDR:
 	case SIOCGIFBRDADDR:
-	case SIOCSIFBRDADDR:
 	case SIOCGIFNETMASK:
-	case SIOCSIFNETMASK:
 	case SIOCGIFDSTADDR:
+	case SIOCGIFPFLAGS:
+		if (copy_from_user(&ifr, p, sizeof(struct ifreq)))
+			return -EFAULT;
+		err = devinet_ioctl(net, cmd, &ifr);
+		if (!err && copy_to_user(p, &ifr, sizeof(struct ifreq)))
+			err = -EFAULT;
+		break;
+
+	case SIOCSIFADDR:
+	case SIOCSIFBRDADDR:
+	case SIOCSIFNETMASK:
 	case SIOCSIFDSTADDR:
 	case SIOCSIFPFLAGS:
-	case SIOCGIFPFLAGS:
 	case SIOCSIFFLAGS:
-		err = devinet_ioctl(net, cmd, (void __user *)arg);
+		if (copy_from_user(&ifr, p, sizeof(struct ifreq)))
+			return -EFAULT;
+		err = devinet_ioctl(net, cmd, &ifr);
 		break;
 	default:
 		if (sk->sk_prot->ioctl)

commit e3f2c4a3db1413bebfd502f7ac94fb55e3ba8c84
Author: Soheil Hassas Yeganeh <soheil@google.com>
Date:   Wed Jan 3 21:47:10 2018 -0500

    ip: do not set RFS core on error queue reads
    
    We should only record RPS on normal reads and writes.
    In single threaded processes, all calls record the same state. In
    multi-threaded processes where a separate thread processes
    errors, the RFS table mispredicts.
    
    Note that, when CONFIG_RPS is disabled, sock_rps_record_flow
    is a noop and no branch is added as a result of this patch.
    
    Signed-off-by: Soheil Hassas Yeganeh <soheil@google.com>
    Signed-off-by: Willem de Bruijn <willemb@google.com>
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: Neal Cardwell <ncardwell@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index bab98a4fedad..54cccdd8b1e3 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -790,7 +790,8 @@ int inet_recvmsg(struct socket *sock, struct msghdr *msg, size_t size,
 	int addr_len = 0;
 	int err;
 
-	sock_rps_record_flow(sk);
+	if (likely(!(flags & MSG_ERRQUEUE)))
+		sock_rps_record_flow(sk);
 
 	err = sk->sk_prot->recvmsg(sk, msg, size, flags & MSG_DONTWAIT,
 				   flags & ~MSG_DONTWAIT, &addr_len);

commit 563e0bb0dc74b3ca888e24f8c08f0239fe4016b0
Author: Yafang Shao <laoar.shao@gmail.com>
Date:   Wed Dec 20 11:12:51 2017 +0800

    net: tracepoint: replace tcp_set_state tracepoint with inet_sock_set_state tracepoint
    
    As sk_state is a common field for struct sock, so the state
    transition tracepoint should not be a TCP specific feature.
    Currently it traces all AF_INET state transition, so I rename this
    tracepoint to inet_sock_set_state tracepoint with some minor changes and move it
    into trace/events/sock.h.
    We dont need to create a file named trace/events/inet_sock.h for this one single
    tracepoint.
    
    Two helpers are introduced to trace sk_state transition
        - void inet_sk_state_store(struct sock *sk, int newstate);
        - void inet_sk_set_state(struct sock *sk, int state);
    As trace header should not be included in other header files,
    so they are defined in sock.c.
    
    The protocol such as SCTP maybe compiled as a ko, hence export
    inet_sk_set_state().
    
    Signed-off-by: Yafang Shao <laoar.shao@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index f00499a46927..bab98a4fedad 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -121,6 +121,7 @@
 #endif
 #include <net/l3mdev.h>
 
+#include <trace/events/sock.h>
 
 /* The inetsw table contains everything that inet_create needs to
  * build a new socket.
@@ -1220,6 +1221,19 @@ int inet_sk_rebuild_header(struct sock *sk)
 }
 EXPORT_SYMBOL(inet_sk_rebuild_header);
 
+void inet_sk_set_state(struct sock *sk, int state)
+{
+	trace_inet_sock_set_state(sk, sk->sk_state, state);
+	sk->sk_state = state;
+}
+EXPORT_SYMBOL(inet_sk_set_state);
+
+void inet_sk_state_store(struct sock *sk, int newstate)
+{
+	trace_inet_sock_set_state(sk, sk->sk_state, newstate);
+	smp_store_release(&sk->sk_state, newstate);
+}
+
 struct sk_buff *inet_gso_segment(struct sk_buff *skb,
 				 netdev_features_t features)
 {

commit 0c19f846d582af919db66a5914a0189f9f92c936
Author: Willem de Bruijn <willemb@google.com>
Date:   Tue Nov 21 10:22:25 2017 -0500

    net: accept UFO datagrams from tuntap and packet
    
    Tuntap and similar devices can inject GSO packets. Accept type
    VIRTIO_NET_HDR_GSO_UDP, even though not generating UFO natively.
    
    Processes are expected to use feature negotiation such as TUNSETOFFLOAD
    to detect supported offload types and refrain from injecting other
    packets. This process breaks down with live migration: guest kernels
    do not renegotiate flags, so destination hosts need to expose all
    features that the source host does.
    
    Partially revert the UFO removal from 182e0b6b5846~1..d9d30adf5677.
    This patch introduces nearly(*) no new code to simplify verification.
    It brings back verbatim tuntap UFO negotiation, VIRTIO_NET_HDR_GSO_UDP
    insertion and software UFO segmentation.
    
    It does not reinstate protocol stack support, hardware offload
    (NETIF_F_UFO), SKB_GSO_UDP tunneling in SKB_GSO_SOFTWARE or reception
    of VIRTIO_NET_HDR_GSO_UDP packets in tuntap.
    
    To support SKB_GSO_UDP reappearing in the stack, also reinstate
    logic in act_csum and openvswitch. Achieve equivalence with v4.13 HEAD
    by squashing in commit 939912216fa8 ("net: skb_needs_check() removes
    CHECKSUM_UNNECESSARY check for tx.") and reverting commit 8d63bee643f1
    ("net: avoid skb_warn_bad_offload false positives on UFO").
    
    (*) To avoid having to bring back skb_shinfo(skb)->ip6_frag_id,
    ipv6_proxy_select_ident is changed to return a __be32 and this is
    assigned directly to the frag_hdr. Also, SKB_GSO_UDP is inserted
    at the end of the enum to minimize code churn.
    
    Tested
      Booted a v4.13 guest kernel with QEMU. On a host kernel before this
      patch `ethtool -k eth0` shows UFO disabled. After the patch, it is
      enabled, same as on a v4.13 host kernel.
    
      A UFO packet sent from the guest appears on the tap device:
        host:
          nc -l -p -u 8000 &
          tcpdump -n -i tap0
    
        guest:
          dd if=/dev/zero of=payload.txt bs=1 count=2000
          nc -u 192.16.1.1 8000 < payload.txt
    
      Direct tap to tap transmission of VIRTIO_NET_HDR_GSO_UDP succeeds,
      packets arriving fragmented:
    
        ./with_tap_pair.sh ./tap_send_ufo tap0 tap1
        (from https://github.com/wdebruij/kerneltools/tree/master/tests)
    
    Changes
      v1 -> v2
        - simplified set_offload change (review comment)
        - documented test procedure
    
    Link: http://lkml.kernel.org/r/<CAF=yD-LuUeDuL9YWPJD9ykOZ0QCjNeznPDr6whqZ9NGMNF12Mw@mail.gmail.com>
    Fixes: fb652fdfe837 ("macvlan/macvtap: Remove NETIF_F_UFO advertisement.")
    Reported-by: Michal Kubecek <mkubecek@suse.cz>
    Signed-off-by: Willem de Bruijn <willemb@google.com>
    Acked-by: Jason Wang <jasowang@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index ce4aa827be05..f00499a46927 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1223,9 +1223,10 @@ EXPORT_SYMBOL(inet_sk_rebuild_header);
 struct sk_buff *inet_gso_segment(struct sk_buff *skb,
 				 netdev_features_t features)
 {
-	bool fixedid = false, gso_partial, encap;
+	bool udpfrag = false, fixedid = false, gso_partial, encap;
 	struct sk_buff *segs = ERR_PTR(-EINVAL);
 	const struct net_offload *ops;
+	unsigned int offset = 0;
 	struct iphdr *iph;
 	int proto, tot_len;
 	int nhoff;
@@ -1260,6 +1261,7 @@ struct sk_buff *inet_gso_segment(struct sk_buff *skb,
 	segs = ERR_PTR(-EPROTONOSUPPORT);
 
 	if (!skb->encapsulation || encap) {
+		udpfrag = !!(skb_shinfo(skb)->gso_type & SKB_GSO_UDP);
 		fixedid = !!(skb_shinfo(skb)->gso_type & SKB_GSO_TCP_FIXEDID);
 
 		/* fixed ID is invalid if DF bit is not set */
@@ -1279,7 +1281,13 @@ struct sk_buff *inet_gso_segment(struct sk_buff *skb,
 	skb = segs;
 	do {
 		iph = (struct iphdr *)(skb_mac_header(skb) + nhoff);
-		if (skb_is_gso(skb)) {
+		if (udpfrag) {
+			iph->frag_off = htons(offset >> 3);
+			if (skb->next)
+				iph->frag_off |= htons(IP_MF);
+			offset += skb->len - nhoff - ihl;
+			tot_len = skb->len - nhoff;
+		} else if (skb_is_gso(skb)) {
 			if (!fixedid) {
 				iph->id = htons(id);
 				id += skb_shinfo(skb)->gso_segs;

commit fcfd6dfab97006d44c7db5d6c908eac383af6649
Author: Gustavo A. R. Silva <garsilva@embeddedor.com>
Date:   Mon Oct 16 15:48:55 2017 -0500

    ipv4: mark expected switch fall-throughs
    
    In preparation to enabling -Wimplicit-fallthrough, mark switch cases
    where we are expecting to fall through.
    
    Notice that in some cases I placed the "fall through" comment
    on its own line, which is what GCC is expecting to find.
    
    Addresses-Coverity-ID: 115108
    Signed-off-by: Gustavo A. R. Silva <garsilva@embeddedor.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 43a1bbed7a42..ce4aa827be05 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -827,6 +827,7 @@ int inet_shutdown(struct socket *sock, int how)
 		err = -ENOTCONN;
 		/* Hack to wake up other listeners, who can poll for
 		   POLLHUP, even on eg. unconnected UDP sockets -- RR */
+		/* fall through */
 	default:
 		sk->sk_shutdown |= how;
 		if (sk->sk_prot->shutdown)
@@ -840,7 +841,7 @@ int inet_shutdown(struct socket *sock, int how)
 	case TCP_LISTEN:
 		if (!(how & RCV_SHUTDOWN))
 			break;
-		/* Fall through */
+		/* fall through */
 	case TCP_SYN_SENT:
 		err = sk->sk_prot->disconnect(sk, O_NONBLOCK);
 		sock->state = err ? SS_DISCONNECTING : SS_UNCONNECTED;

commit 437138485656c41e32b8c63c0987cfa0348be0e6
Author: Haishuang Yan <yanhaishuang@cmss.chinamobile.com>
Date:   Wed Sep 27 11:35:42 2017 +0800

    ipv4: Namespaceify tcp_fastopen_key knob
    
    Different namespace application might require different tcp_fastopen_key
    independently of the host.
    
    David Miller pointed out there is a leak without releasing the context
    of tcp_fastopen_key during netns teardown. So add the release action in
    exit_batch path.
    
    Tested:
    1. Container namespace:
    # cat /proc/sys/net/ipv4/tcp_fastopen_key:
    2817fff2-f803cf97-eadfd1f3-78c0992b
    
    cookie key in tcp syn packets:
    Fast Open Cookie
        Kind: TCP Fast Open Cookie (34)
        Length: 10
        Fast Open Cookie: 1e5dd82a8c492ca9
    
    2. Host:
    # cat /proc/sys/net/ipv4/tcp_fastopen_key:
    107d7c5f-68eb2ac7-02fb06e6-ed341702
    
    cookie key in tcp syn packets:
    Fast Open Cookie
        Kind: TCP Fast Open Cookie (34)
        Length: 10
        Fast Open Cookie: e213c02bf0afbc8a
    
    Signed-off-by: Haishuang Yan <yanhaishuang@cmss.chinamobile.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index e73ce79d7176..43a1bbed7a42 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -222,7 +222,7 @@ int inet_listen(struct socket *sock, int backlog)
 		    (tcp_fastopen & TFO_SERVER_ENABLE) &&
 		    !inet_csk(sk)->icsk_accept_queue.fastopenq.max_qlen) {
 			fastopen_queue_tune(sk, backlog);
-			tcp_fastopen_init_key_once();
+			tcp_fastopen_init_key_once(sock_net(sk));
 		}
 
 		err = inet_csk_listen_start(sk, backlog);

commit dd000598a39b6937fcefdf143720ec9fb5250e72
Author: Haishuang Yan <yanhaishuang@cmss.chinamobile.com>
Date:   Wed Sep 27 11:35:41 2017 +0800

    ipv4: Remove the 'publish' logic in tcp_fastopen_init_key_once
    
    The 'publish' logic is not necessary after commit dfea2aa65424 ("tcp:
    Do not call tcp_fastopen_reset_cipher from interrupt context"), because
    in tcp_fastopen_cookie_gen，it wouldn't call tcp_fastopen_init_key_once.
    
    Signed-off-by: Haishuang Yan <yanhaishuang@cmss.chinamobile.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index ddd126d120ac..e73ce79d7176 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -222,7 +222,7 @@ int inet_listen(struct socket *sock, int backlog)
 		    (tcp_fastopen & TFO_SERVER_ENABLE) &&
 		    !inet_csk(sk)->icsk_accept_queue.fastopenq.max_qlen) {
 			fastopen_queue_tune(sk, backlog);
-			tcp_fastopen_init_key_once(true);
+			tcp_fastopen_init_key_once();
 		}
 
 		err = inet_csk_listen_start(sk, backlog);

commit e1cfcbe82b4534bd0f99fef92a6d33843fd85e0e
Author: Haishuang Yan <yanhaishuang@cmss.chinamobile.com>
Date:   Wed Sep 27 11:35:40 2017 +0800

    ipv4: Namespaceify tcp_fastopen knob
    
    Different namespace application might require enable TCP Fast Open
    feature independently of the host.
    
    This patch series continues making more of the TCP Fast Open related
    sysctl knobs be per net-namespace.
    
    Reported-by: Luca BRUNO <lucab@debian.org>
    Signed-off-by: Haishuang Yan <yanhaishuang@cmss.chinamobile.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index e31108e5ef79..ddd126d120ac 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -195,7 +195,7 @@ int inet_listen(struct socket *sock, int backlog)
 {
 	struct sock *sk = sock->sk;
 	unsigned char old_state;
-	int err;
+	int err, tcp_fastopen;
 
 	lock_sock(sk);
 
@@ -217,8 +217,9 @@ int inet_listen(struct socket *sock, int backlog)
 		 * because the socket was in TCP_LISTEN state previously but
 		 * was shutdown() rather than close().
 		 */
-		if ((sysctl_tcp_fastopen & TFO_SERVER_WO_SOCKOPT1) &&
-		    (sysctl_tcp_fastopen & TFO_SERVER_ENABLE) &&
+		tcp_fastopen = sock_net(sk)->ipv4.sysctl_tcp_fastopen;
+		if ((tcp_fastopen & TFO_SERVER_WO_SOCKOPT1) &&
+		    (tcp_fastopen & TFO_SERVER_ENABLE) &&
 		    !inet_csk(sk)->icsk_accept_queue.fastopenq.max_qlen) {
 			fastopen_queue_tune(sk, backlog);
 			tcp_fastopen_init_key_once(true);

commit a8e3bb347d8c32c25830af55466e08979df4e2be
Author: David Ahern <dsahern@gmail.com>
Date:   Mon Aug 28 15:14:20 2017 -0700

    net: Add comment that early_demux can change via sysctl
    
    Twice patches trying to constify inet{6}_protocol have been reverted:
    39294c3df2a8 ("Revert "ipv6: constify inet6_protocol structures"") to
    revert 3a3a4e3054137 and then 03157937fe0b5 ("Revert "ipv4: make
    net_protocol const"") to revert aa8db499ea67.
    
    Add a comment that the structures can not be const because the
    early_demux field can change based on a sysctl.
    
    Signed-off-by: David Ahern <dsahern@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index d678820e4306..e31108e5ef79 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1596,6 +1596,9 @@ static const struct net_protocol igmp_protocol = {
 };
 #endif
 
+/* thinking of making this const? Don't.
+ * early_demux can change based on sysctl.
+ */
 static struct net_protocol tcp_protocol = {
 	.early_demux	=	tcp_v4_early_demux,
 	.early_demux_handler =  tcp_v4_early_demux,
@@ -1606,6 +1609,9 @@ static struct net_protocol tcp_protocol = {
 	.icmp_strict_tag_validation = 1,
 };
 
+/* thinking of making this const? Don't.
+ * early_demux can change based on sysctl.
+ */
 static struct net_protocol udp_protocol = {
 	.early_demux =	udp_v4_early_demux,
 	.early_demux_handler =	udp_v4_early_demux,

commit 03157937fe0b5ef0431509106c096e50612fa70d
Author: David Ahern <dsahern@gmail.com>
Date:   Mon Aug 28 13:23:09 2017 -0700

    Revert "ipv4: make net_protocol const"
    
    This reverts commit aa8db499ea67cff1f5f049033810ffede2fe5ae4.
    
    Early demux structs can not be made const. Doing so results in:
    [   84.967355] BUG: unable to handle kernel paging request at ffffffff81684b10
    [   84.969272] IP: proc_configure_early_demux+0x1e/0x3d
    [   84.970544] PGD 1a0a067
    [   84.970546] P4D 1a0a067
    [   84.971212] PUD 1a0b063
    [   84.971733] PMD 80000000016001e1
    
    [   84.972669] Oops: 0003 [#1] SMP
    [   84.973065] Modules linked in: ip6table_filter ip6_tables veth vrf
    [   84.973833] CPU: 0 PID: 955 Comm: sysctl Not tainted 4.13.0-rc6+ #22
    [   84.974612] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.7.5-20140531_083030-gandalf 04/01/2014
    [   84.975855] task: ffff88003854ce00 task.stack: ffffc900005a4000
    [   84.976580] RIP: 0010:proc_configure_early_demux+0x1e/0x3d
    [   84.977253] RSP: 0018:ffffc900005a7dd0 EFLAGS: 00010246
    [   84.977891] RAX: ffffffff81684b10 RBX: 0000000000000001 RCX: 0000000000000000
    [   84.978759] RDX: 0000000000000000 RSI: 0000000000000006 RDI: 0000000000000000
    [   84.979628] RBP: ffffc900005a7dd0 R08: 0000000000000000 R09: 0000000000000000
    [   84.980501] R10: 0000000000000001 R11: 0000000000000008 R12: 0000000000000001
    [   84.981373] R13: ffffffffffffffea R14: ffffffff81a9b4c0 R15: 0000000000000002
    [   84.982249] FS:  00007feb237b7700(0000) GS:ffff88003fc00000(0000) knlGS:0000000000000000
    [   84.983231] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [   84.983941] CR2: ffffffff81684b10 CR3: 0000000038492000 CR4: 00000000000406f0
    [   84.984817] Call Trace:
    [   84.985133]  proc_tcp_early_demux+0x29/0x30
    
    I think this is the second time such a patch has been reverted.
    
    Cc: Bhumika Goyal <bhumirks@gmail.com>
    Signed-off-by: David Ahern <dsahern@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 19aee073ba29..d678820e4306 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1596,7 +1596,7 @@ static const struct net_protocol igmp_protocol = {
 };
 #endif
 
-static const struct net_protocol tcp_protocol = {
+static struct net_protocol tcp_protocol = {
 	.early_demux	=	tcp_v4_early_demux,
 	.early_demux_handler =  tcp_v4_early_demux,
 	.handler	=	tcp_v4_rcv,
@@ -1606,7 +1606,7 @@ static const struct net_protocol tcp_protocol = {
 	.icmp_strict_tag_validation = 1,
 };
 
-static const struct net_protocol udp_protocol = {
+static struct net_protocol udp_protocol = {
 	.early_demux =	udp_v4_early_demux,
 	.early_demux_handler =	udp_v4_early_demux,
 	.handler =	udp_rcv,

commit aa8db499ea67cff1f5f049033810ffede2fe5ae4
Author: Bhumika Goyal <bhumirks@gmail.com>
Date:   Fri Aug 25 19:51:44 2017 +0530

    ipv4: make net_protocol const
    
    Make these const as they are only passed to a const argument of the
    function inet_add_protocol.
    
    Signed-off-by: Bhumika Goyal <bhumirks@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index d678820e4306..19aee073ba29 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1596,7 +1596,7 @@ static const struct net_protocol igmp_protocol = {
 };
 #endif
 
-static struct net_protocol tcp_protocol = {
+static const struct net_protocol tcp_protocol = {
 	.early_demux	=	tcp_v4_early_demux,
 	.early_demux_handler =  tcp_v4_early_demux,
 	.handler	=	tcp_v4_rcv,
@@ -1606,7 +1606,7 @@ static struct net_protocol tcp_protocol = {
 	.icmp_strict_tag_validation = 1,
 };
 
-static struct net_protocol udp_protocol = {
+static const struct net_protocol udp_protocol = {
 	.early_demux =	udp_v4_early_demux,
 	.early_demux_handler =	udp_v4_early_demux,
 	.handler =	udp_rcv,

commit 3b2b69efeca734b78bc85fd02253b0465bb2bec7
Merge: 2e2d5d767c9d 26273939ace9
Author: David S. Miller <davem@davemloft.net>
Date:   Thu Aug 10 12:11:16 2017 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/davem/net
    
    Mainline had UFO fixes, but UFO is removed in net-next so we
    take the HEAD hunks.
    
    Minor context conflict in bcmsysport statistics bug fix.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 1714020e42b17135032c8606f7185b3fb2ba5d78
Author: Nikolay Borisov <nborisov@suse.com>
Date:   Wed Aug 9 14:38:04 2017 +0300

    igmp: Fix regression caused by igmp sysctl namespace code.
    
    Commit dcd87999d415 ("igmp: net: Move igmp namespace init to correct file")
    moved the igmp sysctls initialization from tcp_sk_init to igmp_net_init. This
    function is only called as part of per-namespace initialization, only if
    CONFIG_IP_MULTICAST is defined, otherwise igmp_mc_init() call in ip_init is
    compiled out, casuing the igmp pernet ops to not be registerd and those sysctl
    being left initialized with 0. However, there are certain functions, such as
    ip_mc_join_group which are always compiled and make use of some of those
    sysctls. Let's do a partial revert of the aforementioned commit and move the
    sysctl initialization into inet_init_net, that way they will always have
    sane values.
    
    Fixes: dcd87999d415 ("igmp: net: Move igmp namespace init to correct file")
    Link: https://bugzilla.kernel.org/show_bug.cgi?id=196595
    Reported-by: Gerardo Exequiel Pozzi <vmlinuz386@gmail.com>
    Signed-off-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 76c2077c3f5b..2e548eca3489 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1731,6 +1731,13 @@ static __net_init int inet_init_net(struct net *net)
 	net->ipv4.sysctl_ip_prot_sock = PROT_SOCK;
 #endif
 
+	/* Some igmp sysctl, whose values are always used */
+	net->ipv4.sysctl_igmp_max_memberships = 20;
+	net->ipv4.sysctl_igmp_max_msf = 10;
+	/* IGMP reports for link-local multicast groups are enabled by default */
+	net->ipv4.sysctl_igmp_llm_reports = 1;
+	net->ipv4.sysctl_igmp_qrv = 2;
+
 	return 0;
 }
 

commit 93b1b31f87ae7c0795afc7586d28f3ed4f859d20
Author: Tonghao Zhang <xiangxia.m.yue@gmail.com>
Date:   Wed Aug 2 09:34:15 2017 -0700

    ipv4: Introduce ipip_offload_init helper function.
    
    It's convenient to init ipip offload. We will check
    the return value, and print KERN_CRIT info on failure.
    
    Signed-off-by: Tonghao Zhang <xiangxia.m.yue@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index f0103ffe1cdb..683ffafb6ff9 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1765,6 +1765,11 @@ static const struct net_offload ipip_offload = {
 	},
 };
 
+static int __init ipip_offload_init(void)
+{
+	return inet_add_offload(&ipip_offload, IPPROTO_IPIP);
+}
+
 static int __init ipv4_offload_init(void)
 {
 	/*
@@ -1774,9 +1779,10 @@ static int __init ipv4_offload_init(void)
 		pr_crit("%s: Cannot add UDP protocol offload\n", __func__);
 	if (tcpv4_offload_init() < 0)
 		pr_crit("%s: Cannot add TCP protocol offload\n", __func__);
+	if (ipip_offload_init() < 0)
+		pr_crit("%s: Cannot add IPIP protocol offload\n", __func__);
 
 	dev_add_offload(&ip_packet_offload);
-	inet_add_offload(&ipip_offload, IPPROTO_IPIP);
 	return 0;
 }
 

commit 306b13eb3cf9515a8214bbf5d69d811371d05792
Author: Tom Herbert <tom@quantonium.net>
Date:   Fri Jul 28 16:22:41 2017 -0700

    proto_ops: Add locked held versions of sendmsg and sendpage
    
    Add new proto_ops sendmsg_locked and sendpage_locked that can be
    called when the socket lock is already held. Correspondingly, add
    kernel_sendmsg_locked and kernel_sendpage_locked as front end
    functions.
    
    These functions will be used in zero proxy so that we can take
    the socket lock in a ULP sendmsg/sendpage and then directly call the
    backend transport proto_ops functions.
    
    Signed-off-by: Tom Herbert <tom@quantonium.net>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 5ce44fb7d498..f0103ffe1cdb 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -944,6 +944,8 @@ const struct proto_ops inet_stream_ops = {
 	.sendpage	   = inet_sendpage,
 	.splice_read	   = tcp_splice_read,
 	.read_sock	   = tcp_read_sock,
+	.sendmsg_locked    = tcp_sendmsg_locked,
+	.sendpage_locked   = tcp_sendpage_locked,
 	.peek_len	   = tcp_peek_len,
 #ifdef CONFIG_COMPAT
 	.compat_setsockopt = compat_sock_common_setsockopt,

commit 880388aa3c07fdea4f9b85e35641753017b1852f
Author: David S. Miller <davem@davemloft.net>
Date:   Mon Jul 3 07:29:12 2017 -0700

    net: Remove all references to SKB_GSO_UDP.
    
    Such packets are no longer possible.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 76c2077c3f5b..5ce44fb7d498 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1219,10 +1219,9 @@ EXPORT_SYMBOL(inet_sk_rebuild_header);
 struct sk_buff *inet_gso_segment(struct sk_buff *skb,
 				 netdev_features_t features)
 {
-	bool udpfrag = false, fixedid = false, gso_partial, encap;
+	bool fixedid = false, gso_partial, encap;
 	struct sk_buff *segs = ERR_PTR(-EINVAL);
 	const struct net_offload *ops;
-	unsigned int offset = 0;
 	struct iphdr *iph;
 	int proto, tot_len;
 	int nhoff;
@@ -1257,7 +1256,6 @@ struct sk_buff *inet_gso_segment(struct sk_buff *skb,
 	segs = ERR_PTR(-EPROTONOSUPPORT);
 
 	if (!skb->encapsulation || encap) {
-		udpfrag = !!(skb_shinfo(skb)->gso_type & SKB_GSO_UDP);
 		fixedid = !!(skb_shinfo(skb)->gso_type & SKB_GSO_TCP_FIXEDID);
 
 		/* fixed ID is invalid if DF bit is not set */
@@ -1277,13 +1275,7 @@ struct sk_buff *inet_gso_segment(struct sk_buff *skb,
 	skb = segs;
 	do {
 		iph = (struct iphdr *)(skb_mac_header(skb) + nhoff);
-		if (udpfrag) {
-			iph->frag_off = htons(offset >> 3);
-			if (skb->next)
-				iph->frag_off |= htons(IP_MF);
-			offset += skb->len - nhoff - ihl;
-			tot_len = skb->len - nhoff;
-		} else if (skb_is_gso(skb)) {
+		if (skb_is_gso(skb)) {
 			if (!fixedid) {
 				iph->id = htons(id);
 				id += skb_shinfo(skb)->gso_segs;

commit 14afee4b6092fde451ee17604e5f5c89da33e71e
Author: Reshetova, Elena <elena.reshetova@intel.com>
Date:   Fri Jun 30 13:08:00 2017 +0300

    net: convert sock.sk_wmem_alloc from atomic_t to refcount_t
    
    refcount_t type and corresponding API should be
    used instead of atomic_t when the variable is used as
    a reference counter. This allows to avoid accidental
    refcounter overflows that might lead to use-after-free
    situations.
    
    Signed-off-by: Elena Reshetova <elena.reshetova@intel.com>
    Signed-off-by: Hans Liljestrand <ishkamiel@gmail.com>
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: David Windsor <dwindsor@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 58925b6597de..76c2077c3f5b 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -150,7 +150,7 @@ void inet_sock_destruct(struct sock *sk)
 	}
 
 	WARN_ON(atomic_read(&sk->sk_rmem_alloc));
-	WARN_ON(atomic_read(&sk->sk_wmem_alloc));
+	WARN_ON(refcount_read(&sk->sk_wmem_alloc));
 	WARN_ON(sk->sk_wmem_queued);
 	WARN_ON(sk->sk_forward_alloc);
 

commit 77d4b1d36926a9b8387c6b53eeba42bcaaffcea3
Author: Eric Dumazet <edumazet@google.com>
Date:   Sat Jun 3 09:29:25 2017 -0700

    net: ping: do not abuse udp_poll()
    
    Alexander reported various KASAN messages triggered in recent kernels
    
    The problem is that ping sockets should not use udp_poll() in the first
    place, and recent changes in UDP stack finally exposed this old bug.
    
    Fixes: c319b4d76b9e ("net: ipv4: add IPPROTO_ICMP socket kind")
    Fixes: 6d0bfe226116 ("net: ipv6: Add IPv6 support to the ping socket.")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: Sasha Levin <alexander.levin@verizon.com>
    Cc: Solar Designer <solar@openwall.com>
    Cc: Vasiliy Kulikov <segoon@openwall.com>
    Cc: Lorenzo Colitti <lorenzo@google.com>
    Acked-By: Lorenzo Colitti <lorenzo@google.com>
    Tested-By: Lorenzo Colitti <lorenzo@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index f3dad1661343..58925b6597de 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1043,7 +1043,7 @@ static struct inet_protosw inetsw_array[] =
 		.type =       SOCK_DGRAM,
 		.protocol =   IPPROTO_ICMP,
 		.prot =       &ping_prot,
-		.ops =        &inet_dgram_ops,
+		.ops =        &inet_sockraw_ops,
 		.flags =      INET_PROTOSW_REUSE,
        },
 

commit 8d65b08debc7e62b2c6032d7fe7389d895b92cbc
Merge: 5a0387a8a8ef 5d15af6778b8
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue May 2 16:40:27 2017 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/davem/net-next
    
    Pull networking updates from David Millar:
     "Here are some highlights from the 2065 networking commits that
      happened this development cycle:
    
       1) XDP support for IXGBE (John Fastabend) and thunderx (Sunil Kowuri)
    
       2) Add a generic XDP driver, so that anyone can test XDP even if they
          lack a networking device whose driver has explicit XDP support
          (me).
    
       3) Sparc64 now has an eBPF JIT too (me)
    
       4) Add a BPF program testing framework via BPF_PROG_TEST_RUN (Alexei
          Starovoitov)
    
       5) Make netfitler network namespace teardown less expensive (Florian
          Westphal)
    
       6) Add symmetric hashing support to nft_hash (Laura Garcia Liebana)
    
       7) Implement NAPI and GRO in netvsc driver (Stephen Hemminger)
    
       8) Support TC flower offload statistics in mlxsw (Arkadi Sharshevsky)
    
       9) Multiqueue support in stmmac driver (Joao Pinto)
    
      10) Remove TCP timewait recycling, it never really could possibly work
          well in the real world and timestamp randomization really zaps any
          hint of usability this feature had (Soheil Hassas Yeganeh)
    
      11) Support level3 vs level4 ECMP route hashing in ipv4 (Nikolay
          Aleksandrov)
    
      12) Add socket busy poll support to epoll (Sridhar Samudrala)
    
      13) Netlink extended ACK support (Johannes Berg, Pablo Neira Ayuso,
          and several others)
    
      14) IPSEC hw offload infrastructure (Steffen Klassert)"
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/davem/net-next: (2065 commits)
      tipc: refactor function tipc_sk_recv_stream()
      tipc: refactor function tipc_sk_recvmsg()
      net: thunderx: Optimize page recycling for XDP
      net: thunderx: Support for XDP header adjustment
      net: thunderx: Add support for XDP_TX
      net: thunderx: Add support for XDP_DROP
      net: thunderx: Add basic XDP support
      net: thunderx: Cleanup receive buffer allocation
      net: thunderx: Optimize CQE_TX handling
      net: thunderx: Optimize RBDR descriptor handling
      net: thunderx: Support for page recycling
      ipx: call ipxitf_put() in ioctl error path
      net: sched: add helpers to handle extended actions
      qed*: Fix issues in the ptp filter config implementation.
      qede: Fix concurrency issue in PTP Tx path processing.
      stmmac: Add support for SIMATIC IOT2000 platform
      net: hns: fix ethtool_get_strings overflow in hns driver
      tcp: fix wraparound issue in tcp_lp
      bpf, arm64: fix jit branch offset related to ldimm64
      bpf, arm64: implement jiting of BPF_XADD
      ...

commit 9b83e0319840eca758ef586776a427284ff767bf
Author: Steffen Klassert <steffen.klassert@secunet.com>
Date:   Fri Apr 28 10:54:32 2017 +0200

    ipv4: Don't pass IP fragments to upper layer GRO handlers.
    
    Upper layer GRO handlers can not handle IP fragments, so
    exit GRO processing in this case.
    
    This fixes ESP GRO because the packet must be reassembled
    before we can decapsulate, otherwise we get authentication
    failures.
    
    It also aligns IPv4 to IPv6 where packets with fragmentation
    headers are not passed to upper layer GRO handlers.
    
    Fixes: 7785bba299a8 ("esp: Add a software GRO codepath")
    Signed-off-by: Steffen Klassert <steffen.klassert@secunet.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 6b1fc6e4278e..13a9a3297eae 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1343,6 +1343,9 @@ struct sk_buff **inet_gro_receive(struct sk_buff **head, struct sk_buff *skb)
 	if (*(u8 *)iph != 0x45)
 		goto out_unlock;
 
+	if (ip_is_fragment(iph))
+		goto out_unlock;
+
 	if (unlikely(ip_fast_csum((u8 *)iph, 5)))
 		goto out_unlock;
 

commit dddb64bcb34615bf48a2c9cb9881eb76795cc5c5
Author: subashab@codeaurora.org <subashab@codeaurora.org>
Date:   Thu Mar 23 13:34:16 2017 -0600

    net: Add sysctl to toggle early demux for tcp and udp
    
    Certain system process significant unconnected UDP workload.
    It would be preferrable to disable UDP early demux for those systems
    and enable it for TCP only.
    
    By disabling UDP demux, we see these slight gains on an ARM64 system-
    782 -> 788Mbps unconnected single stream UDPv4
    633 -> 654Mbps unconnected UDPv4 different sources
    
    The performance impact can change based on CPU architecure and cache
    sizes. There will not much difference seen if entire UDP hash table
    is in cache.
    
    Both sysctls are enabled by default to preserve existing behavior.
    
    v1->v2: Change function pointer instead of adding conditional as
    suggested by Stephen.
    
    v2->v3: Read once in callers to avoid issues due to compiler
    optimizations. Also update commit message with the tests.
    
    v3->v4: Store and use read once result instead of querying pointer
    again incorrectly.
    
    v4->v5: Refactor to avoid errors due to compilation with IPV6={m,n}
    
    Signed-off-by: Subash Abhinov Kasiviswanathan <subashab@codeaurora.org>
    Suggested-by: Eric Dumazet <edumazet@google.com>
    Cc: Stephen Hemminger <stephen@networkplumber.org>
    Cc: Tom Herbert <tom@herbertland.com>
    Cc: David Miller <davem@davemloft.net>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 6b1fc6e4278e..d1a11707a126 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1599,8 +1599,9 @@ static const struct net_protocol igmp_protocol = {
 };
 #endif
 
-static const struct net_protocol tcp_protocol = {
+static struct net_protocol tcp_protocol = {
 	.early_demux	=	tcp_v4_early_demux,
+	.early_demux_handler =  tcp_v4_early_demux,
 	.handler	=	tcp_v4_rcv,
 	.err_handler	=	tcp_v4_err,
 	.no_policy	=	1,
@@ -1608,8 +1609,9 @@ static const struct net_protocol tcp_protocol = {
 	.icmp_strict_tag_validation = 1,
 };
 
-static const struct net_protocol udp_protocol = {
+static struct net_protocol udp_protocol = {
 	.early_demux =	udp_v4_early_demux,
+	.early_demux_handler =	udp_v4_early_demux,
 	.handler =	udp_rcv,
 	.err_handler =	udp_err,
 	.no_policy =	1,
@@ -1720,6 +1722,8 @@ static __net_init int inet_init_net(struct net *net)
 	net->ipv4.sysctl_ip_default_ttl = IPDEFTTL;
 	net->ipv4.sysctl_ip_dynaddr = 0;
 	net->ipv4.sysctl_ip_early_demux = 1;
+	net->ipv4.sysctl_udp_early_demux = 1;
+	net->ipv4.sysctl_tcp_early_demux = 1;
 #ifdef CONFIG_SYSCTL
 	net->ipv4.sysctl_ip_prot_sock = PROT_SOCK;
 #endif

commit cdfbabfb2f0ce983fdaa42f20e5f7842178fc01e
Author: David Howells <dhowells@redhat.com>
Date:   Thu Mar 9 08:09:05 2017 +0000

    net: Work around lockdep limitation in sockets that use sockets
    
    Lockdep issues a circular dependency warning when AFS issues an operation
    through AF_RXRPC from a context in which the VFS/VM holds the mmap_sem.
    
    The theory lockdep comes up with is as follows:
    
     (1) If the pagefault handler decides it needs to read pages from AFS, it
         calls AFS with mmap_sem held and AFS begins an AF_RXRPC call, but
         creating a call requires the socket lock:
    
            mmap_sem must be taken before sk_lock-AF_RXRPC
    
     (2) afs_open_socket() opens an AF_RXRPC socket and binds it.  rxrpc_bind()
         binds the underlying UDP socket whilst holding its socket lock.
         inet_bind() takes its own socket lock:
    
            sk_lock-AF_RXRPC must be taken before sk_lock-AF_INET
    
     (3) Reading from a TCP socket into a userspace buffer might cause a fault
         and thus cause the kernel to take the mmap_sem, but the TCP socket is
         locked whilst doing this:
    
            sk_lock-AF_INET must be taken before mmap_sem
    
    However, lockdep's theory is wrong in this instance because it deals only
    with lock classes and not individual locks.  The AF_INET lock in (2) isn't
    really equivalent to the AF_INET lock in (3) as the former deals with a
    socket entirely internal to the kernel that never sees userspace.  This is
    a limitation in the design of lockdep.
    
    Fix the general case by:
    
     (1) Double up all the locking keys used in sockets so that one set are
         used if the socket is created by userspace and the other set is used
         if the socket is created by the kernel.
    
     (2) Store the kern parameter passed to sk_alloc() in a variable in the
         sock struct (sk_kern_sock).  This informs sock_lock_init(),
         sock_init_data() and sk_clone_lock() as to the lock keys to be used.
    
         Note that the child created by sk_clone_lock() inherits the parent's
         kern setting.
    
     (3) Add a 'kern' parameter to ->accept() that is analogous to the one
         passed in to ->create() that distinguishes whether kernel_accept() or
         sys_accept4() was the caller and can be passed to sk_alloc().
    
         Note that a lot of accept functions merely dequeue an already
         allocated socket.  I haven't touched these as the new socket already
         exists before we get the parameter.
    
         Note also that there are a couple of places where I've made the accepted
         socket unconditionally kernel-based:
    
            irda_accept()
            rds_rcp_accept_one()
            tcp_accept_from_sock()
    
         because they follow a sock_create_kern() and accept off of that.
    
    Whilst creating this, I noticed that lustre and ocfs don't create sockets
    through sock_create_kern() and thus they aren't marked as for-kernel,
    though they appear to be internal.  I wonder if these should do that so
    that they use the new set of lock keys.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 5091f46826fa..6b1fc6e4278e 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -689,11 +689,12 @@ EXPORT_SYMBOL(inet_stream_connect);
  *	Accept a pending connection. The TCP layer now gives BSD semantics.
  */
 
-int inet_accept(struct socket *sock, struct socket *newsock, int flags)
+int inet_accept(struct socket *sock, struct socket *newsock, int flags,
+		bool kern)
 {
 	struct sock *sk1 = sock->sk;
 	int err = -EINVAL;
-	struct sock *sk2 = sk1->sk_prot->accept(sk1, flags, &err);
+	struct sock *sk2 = sk1->sk_prot->accept(sk1, flags, &err, kern);
 
 	if (!sk2)
 		goto do_err;

commit 294acf1c01bace5cea5d30b510504238bf5f7c25
Author: Paolo Abeni <pabeni@redhat.com>
Date:   Tue Mar 7 18:33:31 2017 +0100

    net/tunnel: set inner protocol in network gro hooks
    
    The gso code of several tunnels type (gre and udp tunnels)
    takes for granted that the skb->inner_protocol is properly
    initialized and drops the packet elsewhere.
    
    On the forwarding path no one is initializing such field,
    so gro encapsulated packets are dropped on forward.
    
    Since commit 38720352412a ("gre: Use inner_proto to obtain
    inner header protocol"), this can be reproduced when the
    encapsulated packets use gre as the tunneling protocol.
    
    The issue happens also with vxlan and geneve tunnels since
    commit 8bce6d7d0d1e ("udp: Generalize skb_udp_segment"), if the
    forwarding host's ingress nic has h/w offload for such tunnel
    and a vxlan/geneve device is configured on top of it, regardless
    of the configured peer address and vni.
    
    To address the issue, this change initialize the inner_protocol
    field for encapsulated packets in both ipv4 and ipv6 gro complete
    callbacks.
    
    Fixes: 38720352412a ("gre: Use inner_proto to obtain inner header protocol")
    Fixes: 8bce6d7d0d1e ("udp: Generalize skb_udp_segment")
    Signed-off-by: Paolo Abeni <pabeni@redhat.com>
    Acked-by: Alexander Duyck <alexander.h.duyck@intel.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 602d40f43687..5091f46826fa 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1487,8 +1487,10 @@ int inet_gro_complete(struct sk_buff *skb, int nhoff)
 	int proto = iph->protocol;
 	int err = -ENOSYS;
 
-	if (skb->encapsulation)
+	if (skb->encapsulation) {
+		skb_set_inner_protocol(skb, cpu_to_be16(ETH_P_IP));
 		skb_set_inner_network_header(skb, nhoff);
+	}
 
 	csum_replace2(&iph->check, iph->tot_len, newlen);
 	iph->tot_len = newlen;

commit 5f114163f2f5eb2edbb49c4d3e0b405c7a8a7e2a
Author: Steffen Klassert <steffen.klassert@secunet.com>
Date:   Wed Feb 15 09:39:39 2017 +0100

    net: Add a skb_gro_flush_final helper.
    
    Add a skb_gro_flush_final helper to prepare for  consuming
    skbs in call_gro_receive. We will extend this helper to not
    touch the skb if the skb is consumed by a gro callback with
    a followup patch. We need this to handle the upcomming IPsec
    ESP callbacks as they reinject the skb to the napi_gro_receive
    asynchronous. The handler is used in all gro_receive functions
    that can call the ESP gro handlers.
    
    Signed-off-by: Steffen Klassert <steffen.klassert@secunet.com>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 685ba53df2d1..602d40f43687 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1423,7 +1423,7 @@ struct sk_buff **inet_gro_receive(struct sk_buff **head, struct sk_buff *skb)
 	rcu_read_unlock();
 
 out:
-	NAPI_GRO_CB(skb)->flush |= flush;
+	skb_gro_flush_final(skb, pp, flush);
 
 	return pp;
 }

commit 3979ad7e82dfe3fb94a51c3915e64ec64afa45c3
Author: Willy Tarreau <w@1wt.eu>
Date:   Wed Jan 25 14:42:46 2017 +0100

    net/tcp-fastopen: make connect()'s return case more consistent with non-TFO
    
    Without TFO, any subsequent connect() call after a successful one returns
    -1 EISCONN. The last API update ensured that __inet_stream_connect() can
    return -1 EINPROGRESS in response to sendmsg() when TFO is in use to
    indicate that the connection is now in progress. Unfortunately since this
    function is used both for connect() and sendmsg(), it has the undesired
    side effect of making connect() now return -1 EINPROGRESS as well after
    a successful call, while at the same time poll() returns POLLOUT. This
    can confuse some applications which happen to call connect() and to
    check for -1 EISCONN to ensure the connection is usable, and for which
    EINPROGRESS indicates a need to poll, causing a loop.
    
    This problem was encountered in haproxy where a call to connect() is
    precisely used in certain cases to confirm a connection's readiness.
    While arguably haproxy's behaviour should be improved here, it seems
    important to aim at a more robust behaviour when the goal of the new
    API is to make it easier to implement TFO in existing applications.
    
    This patch simply ensures that we preserve the same semantics as in
    the non-TFO case on the connect() syscall when using TFO, while still
    returning -1 EINPROGRESS on sendmsg(). For this we simply tell
    __inet_stream_connect() whether we're doing a regular connect() or in
    fact connecting for a sendmsg() call.
    
    Cc: Wei Wang <weiwan@google.com>
    Cc: Yuchung Cheng <ycheng@google.com>
    Cc: Eric Dumazet <edumazet@google.com>
    Signed-off-by: Willy Tarreau <w@1wt.eu>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 92e7f3e957fa..685ba53df2d1 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -570,7 +570,7 @@ static long inet_wait_for_connect(struct sock *sk, long timeo, int writebias)
  *	TCP 'magic' in here.
  */
 int __inet_stream_connect(struct socket *sock, struct sockaddr *uaddr,
-			  int addr_len, int flags)
+			  int addr_len, int flags, int is_sendmsg)
 {
 	struct sock *sk = sock->sk;
 	int err;
@@ -605,7 +605,7 @@ int __inet_stream_connect(struct socket *sock, struct sockaddr *uaddr,
 		goto out;
 	case SS_CONNECTING:
 		if (inet_sk(sk)->defer_connect)
-			err = -EINPROGRESS;
+			err = is_sendmsg ? -EINPROGRESS : -EISCONN;
 		else
 			err = -EALREADY;
 		/* Fall out of switch with err, set for this state */
@@ -679,7 +679,7 @@ int inet_stream_connect(struct socket *sock, struct sockaddr *uaddr,
 	int err;
 
 	lock_sock(sock->sk);
-	err = __inet_stream_connect(sock, uaddr, addr_len, flags);
+	err = __inet_stream_connect(sock, uaddr, addr_len, flags, 0);
 	release_sock(sock->sk);
 	return err;
 }

commit 19f6d3f3c8422d65b5e3d2162e30ef07c6e21ea2
Author: Wei Wang <weiwan@google.com>
Date:   Mon Jan 23 10:59:22 2017 -0800

    net/tcp-fastopen: Add new API support
    
    This patch adds a new socket option, TCP_FASTOPEN_CONNECT, as an
    alternative way to perform Fast Open on the active side (client). Prior
    to this patch, a client needs to replace the connect() call with
    sendto(MSG_FASTOPEN). This can be cumbersome for applications who want
    to use Fast Open: these socket operations are often done in lower layer
    libraries used by many other applications. Changing these libraries
    and/or the socket call sequences are not trivial. A more convenient
    approach is to perform Fast Open by simply enabling a socket option when
    the socket is created w/o changing other socket calls sequence:
      s = socket()
        create a new socket
      setsockopt(s, IPPROTO_TCP, TCP_FASTOPEN_CONNECT …);
        newly introduced sockopt
        If set, new functionality described below will be used.
        Return ENOTSUPP if TFO is not supported or not enabled in the
        kernel.
    
      connect()
        With cookie present, return 0 immediately.
        With no cookie, initiate 3WHS with TFO cookie-request option and
        return -1 with errno = EINPROGRESS.
    
      write()/sendmsg()
        With cookie present, send out SYN with data and return the number of
        bytes buffered.
        With no cookie, and 3WHS not yet completed, return -1 with errno =
        EINPROGRESS.
        No MSG_FASTOPEN flag is needed.
    
      read()
        Return -1 with errno = EWOULDBLOCK/EAGAIN if connect() is called but
        write() is not called yet.
        Return -1 with errno = EWOULDBLOCK/EAGAIN if connection is
        established but no msg is received yet.
        Return number of bytes read if socket is established and there is
        msg received.
    
    The new API simplifies life for applications that always perform a write()
    immediately after a successful connect(). Such applications can now take
    advantage of Fast Open by merely making one new setsockopt() call at the time
    of creating the socket. Nothing else about the application's socket call
    sequence needs to change.
    
    Signed-off-by: Wei Wang <weiwan@google.com>
    Acked-by: Eric Dumazet <edumazet@google.com>
    Acked-by: Yuchung Cheng <ycheng@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 28fe8da4e1ac..92e7f3e957fa 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -576,13 +576,24 @@ int __inet_stream_connect(struct socket *sock, struct sockaddr *uaddr,
 	int err;
 	long timeo;
 
-	if (addr_len < sizeof(uaddr->sa_family))
-		return -EINVAL;
+	/*
+	 * uaddr can be NULL and addr_len can be 0 if:
+	 * sk is a TCP fastopen active socket and
+	 * TCP_FASTOPEN_CONNECT sockopt is set and
+	 * we already have a valid cookie for this socket.
+	 * In this case, user can call write() after connect().
+	 * write() will invoke tcp_sendmsg_fastopen() which calls
+	 * __inet_stream_connect().
+	 */
+	if (uaddr) {
+		if (addr_len < sizeof(uaddr->sa_family))
+			return -EINVAL;
 
-	if (uaddr->sa_family == AF_UNSPEC) {
-		err = sk->sk_prot->disconnect(sk, flags);
-		sock->state = err ? SS_DISCONNECTING : SS_UNCONNECTED;
-		goto out;
+		if (uaddr->sa_family == AF_UNSPEC) {
+			err = sk->sk_prot->disconnect(sk, flags);
+			sock->state = err ? SS_DISCONNECTING : SS_UNCONNECTED;
+			goto out;
+		}
 	}
 
 	switch (sock->state) {
@@ -593,7 +604,10 @@ int __inet_stream_connect(struct socket *sock, struct sockaddr *uaddr,
 		err = -EISCONN;
 		goto out;
 	case SS_CONNECTING:
-		err = -EALREADY;
+		if (inet_sk(sk)->defer_connect)
+			err = -EINPROGRESS;
+		else
+			err = -EALREADY;
 		/* Fall out of switch with err, set for this state */
 		break;
 	case SS_UNCONNECTED:
@@ -607,6 +621,9 @@ int __inet_stream_connect(struct socket *sock, struct sockaddr *uaddr,
 
 		sock->state = SS_CONNECTING;
 
+		if (!err && inet_sk(sk)->defer_connect)
+			goto out;
+
 		/* Just entered SS_CONNECTING state; the only
 		 * difference is that return value in non-blocking
 		 * case is EINPROGRESS, rather than EALREADY.

commit 4548b683b78137f8eadeb312b94e20bb0d4a7141
Author: Krister Johansen <kjlx@templeofstupid.com>
Date:   Fri Jan 20 17:49:11 2017 -0800

    Introduce a sysctl that modifies the value of PROT_SOCK.
    
    Add net.ipv4.ip_unprivileged_port_start, which is a per namespace sysctl
    that denotes the first unprivileged inet port in the namespace.  To
    disable all privileged ports set this to zero.  It also checks for
    overlap with the local port range.  The privileged and local range may
    not overlap.
    
    The use case for this change is to allow containerized processes to bind
    to priviliged ports, but prevent them from ever being allowed to modify
    their container's network configuration.  The latter is accomplished by
    ensuring that the network namespace is not a child of the user
    namespace.  This modification was needed to allow the container manager
    to disable a namespace's priviliged port restrictions without exposing
    control of the network namespace to processes in the user namespace.
    
    Signed-off-by: Krister Johansen <kjlx@templeofstupid.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index aae410bb655a..28fe8da4e1ac 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -479,7 +479,7 @@ int inet_bind(struct socket *sock, struct sockaddr *uaddr, int addr_len)
 
 	snum = ntohs(addr->sin_port);
 	err = -EACCES;
-	if (snum && snum < PROT_SOCK &&
+	if (snum && snum < inet_prot_sock(net) &&
 	    !ns_capable(net->user_ns, CAP_NET_BIND_SERVICE))
 		goto out;
 
@@ -1700,6 +1700,9 @@ static __net_init int inet_init_net(struct net *net)
 	net->ipv4.sysctl_ip_default_ttl = IPDEFTTL;
 	net->ipv4.sysctl_ip_dynaddr = 0;
 	net->ipv4.sysctl_ip_early_demux = 1;
+#ifdef CONFIG_SYSCTL
+	net->ipv4.sysctl_ip_prot_sock = PROT_SOCK;
+#endif
 
 	return 0;
 }

commit 1946e672c173559155a3e210fe95dbf8b7b8ddf7
Author: Haishuang Yan <yanhaishuang@cmss.chinamobile.com>
Date:   Wed Dec 28 17:52:32 2016 +0800

    ipv4: Namespaceify tcp_tw_recycle and tcp_max_tw_buckets knob
    
    Different namespace application might require fast recycling
    TIME-WAIT sockets independently of the host.
    
    Signed-off-by: Haishuang Yan <yanhaishuang@cmss.chinamobile.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index f75069883f2b..aae410bb655a 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1831,8 +1831,6 @@ static int __init inet_init(void)
 
 	ip_init();
 
-	tcp_v4_init();
-
 	/* Setup TCP slab cache for open requests. */
 	tcp_init();
 

commit 7c0f6ba682b9c7632072ffbedf8d328c8f3c42ba
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Dec 24 11:46:01 2016 -0800

    Replace <asm/uaccess.h> with <linux/uaccess.h> globally
    
    This was entirely automated, using the script by Al:
    
      PATT='^[[:blank:]]*#[[:blank:]]*include[[:blank:]]*<asm/uaccess.h>'
      sed -i -e "s!$PATT!#include <linux/uaccess.h>!" \
            $(git grep -l "$PATT"|grep -v ^include/linux/uaccess.h)
    
    to do the replacement at the end of the merge window.
    
    Requested-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 1830e6f0e9cc..f75069883f2b 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -90,7 +90,7 @@
 #include <linux/random.h>
 #include <linux/slab.h>
 
-#include <asm/uaccess.h>
+#include <linux/uaccess.h>
 
 #include <linux/inet.h>
 #include <linux/igmp.h>

commit 2745529ac7358fdac72e6b388da2e934bd9da82c
Merge: ab17cb1fea82 8dc0f265d39a
Author: David S. Miller <davem@davemloft.net>
Date:   Sat Dec 3 11:46:54 2016 -0500

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/davem/net
    
    Couple conflicts resolved here:
    
    1) In the MACB driver, a bug fix to properly initialize the
       RX tail pointer properly overlapped with some changes
       to support variable sized rings.
    
    2) In XGBE we had a "CONFIG_PM" --> "CONFIG_PM_SLEEP" fix
       overlapping with a reorganization of the driver to support
       ACPI, OF, as well as PCI variants of the chip.
    
    3) In 'net' we had several probe error path bug fixes to the
       stmmac driver, meanwhile a lot of this code was cleaned up
       and reorganized in 'net-next'.
    
    4) The cls_flower classifier obtained a helper function in
       'net-next' called __fl_delete() and this overlapped with
       Daniel Borkamann's bug fix to use RCU for object destruction
       in 'net'.  It also overlapped with Jiri's change to guard
       the rhashtable_remove_fast() call with a check against
       tc_skip_sw().
    
    5) In mlx4, a revert bug fix in 'net' overlapped with some
       unrelated changes in 'net-next'.
    
    6) In geneve, a stale header pointer after pskb_expand_head()
       bug fix in 'net' overlapped with a large reorganization of
       the same code in 'net-next'.  Since the 'net-next' code no
       longer had the bug in question, there was nothing to do
       other than to simply take the 'net-next' hunks.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 61023658760032e97869b07d54be9681d2529e77
Author: David Ahern <dsa@cumulusnetworks.com>
Date:   Thu Dec 1 08:48:04 2016 -0800

    bpf: Add new cgroup attach type to enable sock modifications
    
    Add new cgroup based program type, BPF_PROG_TYPE_CGROUP_SOCK. Similar to
    BPF_PROG_TYPE_CGROUP_SKB programs can be attached to a cgroup and run
    any time a process in the cgroup opens an AF_INET or AF_INET6 socket.
    Currently only sk_bound_dev_if is exported to userspace for modification
    by a bpf program.
    
    This allows a cgroup to be configured such that AF_INET{6} sockets opened
    by processes are automatically bound to a specific device. In turn, this
    enables the running of programs that do not support SO_BINDTODEVICE in a
    specific VRF context / L3 domain.
    
    Signed-off-by: David Ahern <dsa@cumulusnetworks.com>
    Acked-by: Alexei Starovoitov <ast@kernel.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 5ddf5cda07f4..24d2550492ee 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -374,8 +374,18 @@ static int inet_create(struct net *net, struct socket *sock, int protocol,
 
 	if (sk->sk_prot->init) {
 		err = sk->sk_prot->init(sk);
-		if (err)
+		if (err) {
+			sk_common_release(sk);
+			goto out;
+		}
+	}
+
+	if (!kern) {
+		err = BPF_CGROUP_RUN_PROG_INET_SOCK(sk);
+		if (err) {
 			sk_common_release(sk);
+			goto out;
+		}
 	}
 out:
 	return err;

commit a510887824171ad260cc4a2603396c6247fdd091
Author: Arnaldo Carvalho de Melo <acme@kernel.org>
Date:   Mon Nov 28 12:36:58 2016 -0300

    GSO: Reload iph after pskb_may_pull
    
    As it may get stale and lead to use after free.
    
    Acked-by: Eric Dumazet <eric.dumazet@gmail.com>
    Cc: Alexander Duyck <aduyck@mirantis.com>
    Cc: Andrey Konovalov <andreyknvl@google.com>
    Fixes: cbc53e08a793 ("GSO: Add GSO type for fixed IPv4 ID")
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Acked-by: Alexander Duyck <alexander.h.duyck@intel.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 5ddf5cda07f4..215143246e4b 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1233,7 +1233,7 @@ struct sk_buff *inet_gso_segment(struct sk_buff *skb,
 		fixedid = !!(skb_shinfo(skb)->gso_type & SKB_GSO_TCP_FIXEDID);
 
 		/* fixed ID is invalid if DF bit is not set */
-		if (fixedid && !(iph->frag_off & htons(IP_DF)))
+		if (fixedid && !(ip_hdr(skb)->frag_off & htons(IP_DF)))
 			goto out;
 	}
 

commit 14135f30e33ce37b22529f73660d7369cf424375
Author: WANG Cong <xiyou.wangcong@gmail.com>
Date:   Tue Nov 1 16:04:36 2016 -0700

    inet: fix sleeping inside inet_wait_for_connect()
    
    Andrey reported this kernel warning:
    
      WARNING: CPU: 0 PID: 4608 at kernel/sched/core.c:7724
      __might_sleep+0x14c/0x1a0 kernel/sched/core.c:7719
      do not call blocking ops when !TASK_RUNNING; state=1 set at
      [<ffffffff811f5a5c>] prepare_to_wait+0xbc/0x210
      kernel/sched/wait.c:178
      Modules linked in:
      CPU: 0 PID: 4608 Comm: syz-executor Not tainted 4.9.0-rc2+ #320
      Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS Bochs 01/01/2011
       ffff88006625f7a0 ffffffff81b46914 ffff88006625f818 0000000000000000
       ffffffff84052960 0000000000000000 ffff88006625f7e8 ffffffff81111237
       ffff88006aceac00 ffffffff00001e2c ffffed000cc4beff ffffffff84052960
      Call Trace:
       [<     inline     >] __dump_stack lib/dump_stack.c:15
       [<ffffffff81b46914>] dump_stack+0xb3/0x10f lib/dump_stack.c:51
       [<ffffffff81111237>] __warn+0x1a7/0x1f0 kernel/panic.c:550
       [<ffffffff8111132c>] warn_slowpath_fmt+0xac/0xd0 kernel/panic.c:565
       [<ffffffff811922fc>] __might_sleep+0x14c/0x1a0 kernel/sched/core.c:7719
       [<     inline     >] slab_pre_alloc_hook mm/slab.h:393
       [<     inline     >] slab_alloc_node mm/slub.c:2634
       [<     inline     >] slab_alloc mm/slub.c:2716
       [<ffffffff81508da0>] __kmalloc_track_caller+0x150/0x2a0 mm/slub.c:4240
       [<ffffffff8146be14>] kmemdup+0x24/0x50 mm/util.c:113
       [<ffffffff8388b2cf>] dccp_feat_clone_sp_val.part.5+0x4f/0xe0 net/dccp/feat.c:374
       [<     inline     >] dccp_feat_clone_sp_val net/dccp/feat.c:1141
       [<     inline     >] dccp_feat_change_recv net/dccp/feat.c:1141
       [<ffffffff8388d491>] dccp_feat_parse_options+0xaa1/0x13d0 net/dccp/feat.c:1411
       [<ffffffff83894f01>] dccp_parse_options+0x721/0x1010 net/dccp/options.c:128
       [<ffffffff83891280>] dccp_rcv_state_process+0x200/0x15b0 net/dccp/input.c:644
       [<ffffffff838b8a94>] dccp_v4_do_rcv+0xf4/0x1a0 net/dccp/ipv4.c:681
       [<     inline     >] sk_backlog_rcv ./include/net/sock.h:872
       [<ffffffff82b7ceb6>] __release_sock+0x126/0x3a0 net/core/sock.c:2044
       [<ffffffff82b7d189>] release_sock+0x59/0x1c0 net/core/sock.c:2502
       [<     inline     >] inet_wait_for_connect net/ipv4/af_inet.c:547
       [<ffffffff8316b2a2>] __inet_stream_connect+0x5d2/0xbb0 net/ipv4/af_inet.c:617
       [<ffffffff8316b8d5>] inet_stream_connect+0x55/0xa0 net/ipv4/af_inet.c:656
       [<ffffffff82b705e4>] SYSC_connect+0x244/0x2f0 net/socket.c:1533
       [<ffffffff82b72dd4>] SyS_connect+0x24/0x30 net/socket.c:1514
       [<ffffffff83fbf701>] entry_SYSCALL_64_fastpath+0x1f/0xc2
      arch/x86/entry/entry_64.S:209
    
    Unlike commit 26cabd31259ba43f68026ce3f62b78094124333f
    ("sched, net: Clean up sk_wait_event() vs. might_sleep()"), the
    sleeping function is called before schedule_timeout(), this is indeed
    a bug. Fix this by moving the wait logic to the new API, it is similar
    to commit ff960a731788a7408b6f66ec4fd772ff18833211
    ("netdev, sched/wait: Fix sleeping inside wait event").
    
    Reported-by: Andrey Konovalov <andreyknvl@google.com>
    Cc: Andrey Konovalov <andreyknvl@google.com>
    Cc: Eric Dumazet <eric.dumazet@gmail.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Signed-off-by: Cong Wang <xiyou.wangcong@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 9648c97e541f..5ddf5cda07f4 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -533,9 +533,9 @@ EXPORT_SYMBOL(inet_dgram_connect);
 
 static long inet_wait_for_connect(struct sock *sk, long timeo, int writebias)
 {
-	DEFINE_WAIT(wait);
+	DEFINE_WAIT_FUNC(wait, woken_wake_function);
 
-	prepare_to_wait(sk_sleep(sk), &wait, TASK_INTERRUPTIBLE);
+	add_wait_queue(sk_sleep(sk), &wait);
 	sk->sk_write_pending += writebias;
 
 	/* Basic assumption: if someone sets sk->sk_err, he _must_
@@ -545,13 +545,12 @@ static long inet_wait_for_connect(struct sock *sk, long timeo, int writebias)
 	 */
 	while ((1 << sk->sk_state) & (TCPF_SYN_SENT | TCPF_SYN_RECV)) {
 		release_sock(sk);
-		timeo = schedule_timeout(timeo);
+		timeo = wait_woken(&wait, TASK_INTERRUPTIBLE, timeo);
 		lock_sock(sk);
 		if (signal_pending(current) || !timeo)
 			break;
-		prepare_to_wait(sk_sleep(sk), &wait, TASK_INTERRUPTIBLE);
 	}
-	finish_wait(sk_sleep(sk), &wait);
+	remove_wait_queue(sk_sleep(sk), &wait);
 	sk->sk_write_pending -= writebias;
 	return timeo;
 }

commit fcd91dd449867c6bfe56a81cabba76b829fd05cd
Author: Sabrina Dubroca <sd@queasysnail.net>
Date:   Thu Oct 20 15:58:02 2016 +0200

    net: add recursion limit to GRO
    
    Currently, GRO can do unlimited recursion through the gro_receive
    handlers.  This was fixed for tunneling protocols by limiting tunnel GRO
    to one level with encap_mark, but both VLAN and TEB still have this
    problem.  Thus, the kernel is vulnerable to a stack overflow, if we
    receive a packet composed entirely of VLAN headers.
    
    This patch adds a recursion counter to the GRO layer to prevent stack
    overflow.  When a gro_receive function hits the recursion limit, GRO is
    aborted for this skb and it is processed normally.  This recursion
    counter is put in the GRO CB, but could be turned into a percpu counter
    if we run out of space in the CB.
    
    Thanks to Vladimír Beneš <vbenes@redhat.com> for the initial bug report.
    
    Fixes: CVE-2016-7039
    Fixes: 9b174d88c257 ("net: Add Transparent Ethernet Bridging GRO support.")
    Fixes: 66e5133f19e9 ("vlan: Add GRO support for non hardware accelerated vlan")
    Signed-off-by: Sabrina Dubroca <sd@queasysnail.net>
    Reviewed-by: Jiri Benc <jbenc@redhat.com>
    Acked-by: Hannes Frederic Sowa <hannes@stressinduktion.org>
    Acked-by: Tom Herbert <tom@herbertland.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 1effc986739e..9648c97e541f 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1391,7 +1391,7 @@ struct sk_buff **inet_gro_receive(struct sk_buff **head, struct sk_buff *skb)
 	skb_gro_pull(skb, sizeof(*iph));
 	skb_set_transport_header(skb, skb_gro_offset(skb));
 
-	pp = ops->callbacks.gro_receive(head, skb);
+	pp = call_gro_receive(ops->callbacks.gro_receive, head, skb);
 
 out_unlock:
 	rcu_read_unlock();

commit 07b26c9454a2a19fff86d6fcf2aba6bc801eb8d8
Author: Steffen Klassert <steffen.klassert@secunet.com>
Date:   Mon Sep 19 12:58:47 2016 +0200

    gso: Support partial splitting at the frag_list pointer
    
    Since commit 8a29111c7 ("net: gro: allow to build full sized skb")
    gro may build buffers with a frag_list. This can hurt forwarding
    because most NICs can't offload such packets, they need to be
    segmented in software. This patch splits buffers with a frag_list
    at the frag_list pointer into buffers that can be TSO offloaded.
    
    Signed-off-by: Steffen Klassert <steffen.klassert@secunet.com>
    Acked-by: Alexander Duyck <alexander.h.duyck@intel.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index e94b47be0019..1effc986739e 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1192,7 +1192,7 @@ EXPORT_SYMBOL(inet_sk_rebuild_header);
 struct sk_buff *inet_gso_segment(struct sk_buff *skb,
 				 netdev_features_t features)
 {
-	bool udpfrag = false, fixedid = false, encap;
+	bool udpfrag = false, fixedid = false, gso_partial, encap;
 	struct sk_buff *segs = ERR_PTR(-EINVAL);
 	const struct net_offload *ops;
 	unsigned int offset = 0;
@@ -1245,6 +1245,8 @@ struct sk_buff *inet_gso_segment(struct sk_buff *skb,
 	if (IS_ERR_OR_NULL(segs))
 		goto out;
 
+	gso_partial = !!(skb_shinfo(segs)->gso_type & SKB_GSO_PARTIAL);
+
 	skb = segs;
 	do {
 		iph = (struct iphdr *)(skb_mac_header(skb) + nhoff);
@@ -1259,9 +1261,13 @@ struct sk_buff *inet_gso_segment(struct sk_buff *skb,
 				iph->id = htons(id);
 				id += skb_shinfo(skb)->gso_segs;
 			}
-			tot_len = skb_shinfo(skb)->gso_size +
-				  SKB_GSO_CB(skb)->data_offset +
-				  skb->head - (unsigned char *)iph;
+
+			if (gso_partial)
+				tot_len = skb_shinfo(skb)->gso_size +
+					  SKB_GSO_CB(skb)->data_offset +
+					  skb->head - (unsigned char *)iph;
+			else
+				tot_len = skb->len - nhoff;
 		} else {
 			if (!fixedid)
 				iph->id = htons(id++);

commit 3203558589a597e0a10a66b258fbc5a4a6659ed0
Author: Tom Herbert <tom@herbertland.com>
Date:   Sun Aug 28 14:43:18 2016 -0700

    tcp: Set read_sock and peek_len proto_ops
    
    In inet_stream_ops we set read_sock to tcp_read_sock and peek_len to
    tcp_peek_len (which is just a stub function that calls tcp_inq).
    
    Signed-off-by: Tom Herbert <tom@herbertland.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 989a362814a9..e94b47be0019 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -916,6 +916,8 @@ const struct proto_ops inet_stream_ops = {
 	.mmap		   = sock_no_mmap,
 	.sendpage	   = inet_sendpage,
 	.splice_read	   = tcp_splice_read,
+	.read_sock	   = tcp_read_sock,
+	.peek_len	   = tcp_peek_len,
 #ifdef CONFIG_COMPAT
 	.compat_setsockopt = compat_sock_common_setsockopt,
 	.compat_getsockopt = compat_sock_common_getsockopt,

commit cebc5cbab48f5c58512e26aa1965284354227258
Author: Yuchung Cheng <ycheng@google.com>
Date:   Mon Aug 22 17:17:54 2016 -0700

    net-tcp: retire TFO_SERVER_WO_SOCKOPT2 config
    
    TFO_SERVER_WO_SOCKOPT2 was intended for debugging purposes during
    Fast Open development. Remove this config option and also
    update/clean-up the documentation of the Fast Open sysctl.
    
    Reported-by: Piotr Jurkiewicz <piotr.jerzy.jurkiewicz@gmail.com>
    Signed-off-by: Yuchung Cheng <ycheng@google.com>
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: Neal Cardwell <ncardwell@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 55513e654d79..989a362814a9 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -211,24 +211,19 @@ int inet_listen(struct socket *sock, int backlog)
 	 * we can only allow the backlog to be adjusted.
 	 */
 	if (old_state != TCP_LISTEN) {
-		/* Check special setups for testing purpose to enable TFO w/o
-		 * requiring TCP_FASTOPEN sockopt.
+		/* Enable TFO w/o requiring TCP_FASTOPEN socket option.
 		 * Note that only TCP sockets (SOCK_STREAM) will reach here.
-		 * Also fastopenq may already been allocated because this
-		 * socket was in TCP_LISTEN state previously but was
-		 * shutdown() (rather than close()).
+		 * Also fastopen backlog may already been set via the option
+		 * because the socket was in TCP_LISTEN state previously but
+		 * was shutdown() rather than close().
 		 */
-		if ((sysctl_tcp_fastopen & TFO_SERVER_ENABLE) != 0 &&
+		if ((sysctl_tcp_fastopen & TFO_SERVER_WO_SOCKOPT1) &&
+		    (sysctl_tcp_fastopen & TFO_SERVER_ENABLE) &&
 		    !inet_csk(sk)->icsk_accept_queue.fastopenq.max_qlen) {
-			if ((sysctl_tcp_fastopen & TFO_SERVER_WO_SOCKOPT1) != 0)
-				fastopen_queue_tune(sk, backlog);
-			else if ((sysctl_tcp_fastopen &
-				  TFO_SERVER_WO_SOCKOPT2) != 0)
-				fastopen_queue_tune(sk,
-				    ((uint)sysctl_tcp_fastopen) >> 16);
-
+			fastopen_queue_tune(sk, backlog);
 			tcp_fastopen_init_key_once(true);
 		}
+
 		err = inet_csk_listen_start(sk, backlog);
 		if (err)
 			goto out;

commit d3fc0353f7c709a6a7fea340211eeb7bbc3e4c66
Author: Paul Gortmaker <paul.gortmaker@windriver.com>
Date:   Mon Jul 11 16:37:51 2016 -0400

    ipv4: af_inet: make it explicitly non-modular
    
    The Makefile controlling compilation of this file is obj-y,
    meaning that it currently is never being built as a module.
    
    Since MODULE_ALIAS is a no-op for non-modular code, we can simply
    remove the MODULE_ALIAS_NETPROTO variant used here.
    
    We replace module.h with kmod.h since the file does make use of
    request_module() in order to load other modules from here.
    
    We don't have to worry about init.h coming in via the removed
    module.h since the file explicitly includes init.h already.
    
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Alexey Kuznetsov <kuznet@ms2.inr.ac.ru>
    Cc: James Morris <jmorris@namei.org>
    Cc: Hideaki YOSHIFUJI <yoshfuji@linux-ipv6.org>
    Cc: Patrick McHardy <kaber@trash.net>
    Cc: netdev@vger.kernel.org
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index d39e9e47a26e..55513e654d79 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -73,7 +73,7 @@
 #include <linux/socket.h>
 #include <linux/in.h>
 #include <linux/kernel.h>
-#include <linux/module.h>
+#include <linux/kmod.h>
 #include <linux/sched.h>
 #include <linux/timer.h>
 #include <linux/string.h>
@@ -1916,6 +1916,3 @@ static int __init ipv4_proc_init(void)
 	return 0;
 }
 #endif /* CONFIG_PROC_FS */
-
-MODULE_ALIAS_NETPROTO(PF_INET);
-

commit 049bbf589ec651685205bd8ce73221fdd62345cf
Author: Ezequiel Garcia <ezequiel@vanguardiasur.com.ar>
Date:   Fri May 20 13:21:10 2016 -0300

    ipv4: Fix non-initialized TTL when CONFIG_SYSCTL=n
    
    Commit fa50d974d104 ("ipv4: Namespaceify ip_default_ttl sysctl knob")
    moves the default TTL assignment, and as side-effect IPv4 TTL now
    has a default value only if sysctl support is enabled (CONFIG_SYSCTL=y).
    
    The sysctl_ip_default_ttl is fundamental for IP to work properly,
    as it provides the TTL to be used as default. The defautl TTL may be
    used in ip_selected_ttl, through the following flow:
    
      ip_select_ttl
        ip4_dst_hoplimit
          net->ipv4.sysctl_ip_default_ttl
    
    This commit fixes the issue by assigning net->ipv4.sysctl_ip_default_ttl
    in net_init_net, called during ipv4's initialization.
    
    Without this commit, a kernel built without sysctl support will send
    all IP packets with zero TTL (unless a TTL is explicitly set, e.g.
    with setsockopt).
    
    Given a similar issue might appear on the other knobs that were
    namespaceify, this commit also moves them.
    
    Fixes: fa50d974d104 ("ipv4: Namespaceify ip_default_ttl sysctl knob")
    Signed-off-by: Ezequiel Garcia <ezequiel@vanguardiasur.com.ar>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 377424ea17a4..d39e9e47a26e 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1681,6 +1681,14 @@ static __net_init int inet_init_net(struct net *net)
 	 */
 	net->ipv4.ping_group_range.range[0] = make_kgid(&init_user_ns, 1);
 	net->ipv4.ping_group_range.range[1] = make_kgid(&init_user_ns, 0);
+
+	/* Default values for sysctl-controlled parameters.
+	 * We set them here, in case sysctl is not compiled.
+	 */
+	net->ipv4.sysctl_ip_default_ttl = IPDEFTTL;
+	net->ipv4.sysctl_ip_dynaddr = 0;
+	net->ipv4.sysctl_ip_early_demux = 1;
+
 	return 0;
 }
 

commit b8921ca83eed2496108ee308e9a41c5084089680
Author: Tom Herbert <tom@herbertland.com>
Date:   Wed May 18 09:06:23 2016 -0700

    ip4ip6: Support for GSO/GRO
    
    Signed-off-by: Tom Herbert <tom@herbertland.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 25040b183a60..377424ea17a4 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1192,8 +1192,8 @@ int inet_sk_rebuild_header(struct sock *sk)
 }
 EXPORT_SYMBOL(inet_sk_rebuild_header);
 
-static struct sk_buff *inet_gso_segment(struct sk_buff *skb,
-					netdev_features_t features)
+struct sk_buff *inet_gso_segment(struct sk_buff *skb,
+				 netdev_features_t features)
 {
 	bool udpfrag = false, fixedid = false, encap;
 	struct sk_buff *segs = ERR_PTR(-EINVAL);
@@ -1280,9 +1280,9 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb,
 out:
 	return segs;
 }
+EXPORT_SYMBOL(inet_gso_segment);
 
-static struct sk_buff **inet_gro_receive(struct sk_buff **head,
-					 struct sk_buff *skb)
+struct sk_buff **inet_gro_receive(struct sk_buff **head, struct sk_buff *skb)
 {
 	const struct net_offload *ops;
 	struct sk_buff **pp = NULL;
@@ -1398,6 +1398,7 @@ static struct sk_buff **inet_gro_receive(struct sk_buff **head,
 
 	return pp;
 }
+EXPORT_SYMBOL(inet_gro_receive);
 
 static struct sk_buff **ipip_gro_receive(struct sk_buff **head,
 					 struct sk_buff *skb)
@@ -1449,7 +1450,7 @@ int inet_recv_error(struct sock *sk, struct msghdr *msg, int len, int *addr_len)
 	return -EINVAL;
 }
 
-static int inet_gro_complete(struct sk_buff *skb, int nhoff)
+int inet_gro_complete(struct sk_buff *skb, int nhoff)
 {
 	__be16 newlen = htons(skb->len - nhoff);
 	struct iphdr *iph = (struct iphdr *)(skb->data + nhoff);
@@ -1479,6 +1480,7 @@ static int inet_gro_complete(struct sk_buff *skb, int nhoff)
 
 	return err;
 }
+EXPORT_SYMBOL(inet_gro_complete);
 
 static int ipip_gro_complete(struct sk_buff *skb, int nhoff)
 {

commit 7e13318daa4a67bff2f800923a993ef3818b3c53
Author: Tom Herbert <tom@herbertland.com>
Date:   Wed May 18 09:06:10 2016 -0700

    net: define gso types for IPx over IPv4 and IPv6
    
    This patch defines two new GSO definitions SKB_GSO_IPXIP4 and
    SKB_GSO_IPXIP6 along with corresponding NETIF_F_GSO_IPXIP4 and
    NETIF_F_GSO_IPXIP6. These are used to described IP in IP
    tunnel and what the outer protocol is. The inner protocol
    can be deduced from other GSO types (e.g. SKB_GSO_TCPV4 and
    SKB_GSO_TCPV6). The GSO types of SKB_GSO_IPIP and SKB_GSO_SIT
    are removed (these are both instances of SKB_GSO_IPXIP4).
    SKB_GSO_IPXIP6 will be used when support for GSO with IP
    encapsulation over IPv6 is added.
    
    Signed-off-by: Tom Herbert <tom@herbertland.com>
    Acked-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 7f08d4525981..25040b183a60 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1483,7 +1483,7 @@ static int inet_gro_complete(struct sk_buff *skb, int nhoff)
 static int ipip_gro_complete(struct sk_buff *skb, int nhoff)
 {
 	skb->encapsulation = 1;
-	skb_shinfo(skb)->gso_type |= SKB_GSO_IPIP;
+	skb_shinfo(skb)->gso_type |= SKB_GSO_IPXIP4;
 	return inet_gro_complete(skb, nhoff);
 }
 

commit 5c7cdf339af560f980b12eb6b0b5aa5f68ac6658
Author: Tom Herbert <tom@herbertland.com>
Date:   Wed May 18 09:06:09 2016 -0700

    gso: Remove arbitrary checks for unsupported GSO
    
    In several gso_segment functions there are checks of gso_type against
    a seemingly arbitrary list of SKB_GSO_* flags. This seems like an
    attempt to identify unsupported GSO types, but since the stack is
    the one that set these GSO types in the first place this seems
    unnecessary to do. If a combination isn't valid in the first
    place that stack should not allow setting it.
    
    This is a code simplication especially for add new GSO types.
    
    Signed-off-by: Tom Herbert <tom@herbertland.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 2e6e65fc4d20..7f08d4525981 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1205,24 +1205,6 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb,
 	int ihl;
 	int id;
 
-	if (unlikely(skb_shinfo(skb)->gso_type &
-		     ~(SKB_GSO_TCPV4 |
-		       SKB_GSO_UDP |
-		       SKB_GSO_DODGY |
-		       SKB_GSO_TCP_ECN |
-		       SKB_GSO_GRE |
-		       SKB_GSO_GRE_CSUM |
-		       SKB_GSO_IPIP |
-		       SKB_GSO_SIT |
-		       SKB_GSO_TCPV6 |
-		       SKB_GSO_UDP_TUNNEL |
-		       SKB_GSO_UDP_TUNNEL_CSUM |
-		       SKB_GSO_TCP_FIXEDID |
-		       SKB_GSO_TUNNEL_REMCSUM |
-		       SKB_GSO_PARTIAL |
-		       0)))
-		goto out;
-
 	skb_reset_network_header(skb);
 	nhoff = skb_network_header(skb) - skb_mac_header(skb);
 	if (unlikely(!pskb_may_pull(skb, sizeof(*iph))))

commit 802ab55adc39a06940a1b384e9fd0387fc762d7e
Author: Alexander Duyck <aduyck@mirantis.com>
Date:   Sun Apr 10 21:45:03 2016 -0400

    GSO: Support partial segmentation offload
    
    This patch adds support for something I am referring to as GSO partial.
    The basic idea is that we can support a broader range of devices for
    segmentation if we use fixed outer headers and have the hardware only
    really deal with segmenting the inner header.  The idea behind the naming
    is due to the fact that everything before csum_start will be fixed headers,
    and everything after will be the region that is handled by hardware.
    
    With the current implementation it allows us to add support for the
    following GSO types with an inner TSO_MANGLEID or TSO6 offload:
    NETIF_F_GSO_GRE
    NETIF_F_GSO_GRE_CSUM
    NETIF_F_GSO_IPIP
    NETIF_F_GSO_SIT
    NETIF_F_UDP_TUNNEL
    NETIF_F_UDP_TUNNEL_CSUM
    
    In the case of hardware that already supports tunneling we may be able to
    extend this further to support TSO_TCPV4 without TSO_MANGLEID if the
    hardware can support updating inner IPv4 headers.
    
    Signed-off-by: Alexander Duyck <aduyck@mirantis.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 8564cab96189..2e6e65fc4d20 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1200,7 +1200,7 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb,
 	const struct net_offload *ops;
 	unsigned int offset = 0;
 	struct iphdr *iph;
-	int proto;
+	int proto, tot_len;
 	int nhoff;
 	int ihl;
 	int id;
@@ -1219,6 +1219,7 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb,
 		       SKB_GSO_UDP_TUNNEL_CSUM |
 		       SKB_GSO_TCP_FIXEDID |
 		       SKB_GSO_TUNNEL_REMCSUM |
+		       SKB_GSO_PARTIAL |
 		       0)))
 		goto out;
 
@@ -1273,10 +1274,21 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb,
 			if (skb->next)
 				iph->frag_off |= htons(IP_MF);
 			offset += skb->len - nhoff - ihl;
-		} else if (!fixedid) {
-			iph->id = htons(id++);
+			tot_len = skb->len - nhoff;
+		} else if (skb_is_gso(skb)) {
+			if (!fixedid) {
+				iph->id = htons(id);
+				id += skb_shinfo(skb)->gso_segs;
+			}
+			tot_len = skb_shinfo(skb)->gso_size +
+				  SKB_GSO_CB(skb)->data_offset +
+				  skb->head - (unsigned char *)iph;
+		} else {
+			if (!fixedid)
+				iph->id = htons(id++);
+			tot_len = skb->len - nhoff;
 		}
-		iph->tot_len = htons(skb->len - nhoff);
+		iph->tot_len = htons(tot_len);
 		ip_send_check(iph);
 		if (encap)
 			skb_reset_inner_headers(skb);

commit 1530545ed64b42e87acb43c0c16401bd1ebae6bf
Author: Alexander Duyck <aduyck@mirantis.com>
Date:   Sun Apr 10 21:44:57 2016 -0400

    GRO: Add support for TCP with fixed IPv4 ID field, limit tunnel IP ID values
    
    This patch does two things.
    
    First it allows TCP to aggregate TCP frames with a fixed IPv4 ID field.  As
    a result we should now be able to aggregate flows that were converted from
    IPv6 to IPv4.  In addition this allows us more flexibility for future
    implementations of segmentation as we may be able to use a fixed IP ID when
    segmenting the flow.
    
    The second thing this does is that it places limitations on the outer IPv4
    ID header in the case of tunneled frames.  Specifically it forces the IP ID
    to be incrementing by 1 unless the DF bit is set in the outer IPv4 header.
    This way we can avoid creating overlapping series of IP IDs that could
    possibly be fragmented if the frame goes through GRO and is then
    resegmented via GSO.
    
    Signed-off-by: Alexander Duyck <aduyck@mirantis.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 5bbea9a0ce96..8564cab96189 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1328,6 +1328,7 @@ static struct sk_buff **inet_gro_receive(struct sk_buff **head,
 
 	for (p = *head; p; p = p->next) {
 		struct iphdr *iph2;
+		u16 flush_id;
 
 		if (!NAPI_GRO_CB(p)->same_flow)
 			continue;
@@ -1351,16 +1352,36 @@ static struct sk_buff **inet_gro_receive(struct sk_buff **head,
 			(iph->tos ^ iph2->tos) |
 			((iph->frag_off ^ iph2->frag_off) & htons(IP_DF));
 
-		/* Save the IP ID check to be included later when we get to
-		 * the transport layer so only the inner most IP ID is checked.
-		 * This is because some GSO/TSO implementations do not
-		 * correctly increment the IP ID for the outer hdrs.
-		 */
-		NAPI_GRO_CB(p)->flush_id =
-			    ((u16)(ntohs(iph2->id) + NAPI_GRO_CB(p)->count) ^ id);
 		NAPI_GRO_CB(p)->flush |= flush;
+
+		/* We need to store of the IP ID check to be included later
+		 * when we can verify that this packet does in fact belong
+		 * to a given flow.
+		 */
+		flush_id = (u16)(id - ntohs(iph2->id));
+
+		/* This bit of code makes it much easier for us to identify
+		 * the cases where we are doing atomic vs non-atomic IP ID
+		 * checks.  Specifically an atomic check can return IP ID
+		 * values 0 - 0xFFFF, while a non-atomic check can only
+		 * return 0 or 0xFFFF.
+		 */
+		if (!NAPI_GRO_CB(p)->is_atomic ||
+		    !(iph->frag_off & htons(IP_DF))) {
+			flush_id ^= NAPI_GRO_CB(p)->count;
+			flush_id = flush_id ? 0xFFFF : 0;
+		}
+
+		/* If the previous IP ID value was based on an atomic
+		 * datagram we can overwrite the value and ignore it.
+		 */
+		if (NAPI_GRO_CB(skb)->is_atomic)
+			NAPI_GRO_CB(p)->flush_id = flush_id;
+		else
+			NAPI_GRO_CB(p)->flush_id |= flush_id;
 	}
 
+	NAPI_GRO_CB(skb)->is_atomic = !!(iph->frag_off & htons(IP_DF));
 	NAPI_GRO_CB(skb)->flush |= flush;
 	skb_set_network_header(skb, off);
 	/* The above will be needed by the transport layer if there is one

commit cbc53e08a793b073e79f42ca33f1f3568703540d
Author: Alexander Duyck <aduyck@mirantis.com>
Date:   Sun Apr 10 21:44:51 2016 -0400

    GSO: Add GSO type for fixed IPv4 ID
    
    This patch adds support for TSO using IPv4 headers with a fixed IP ID
    field.  This is meant to allow us to do a lossless GRO in the case of TCP
    flows that use a fixed IP ID such as those that convert IPv6 header to IPv4
    headers.
    
    In addition I am adding a feature that for now I am referring to TSO with
    IP ID mangling.  Basically when this flag is enabled the device has the
    option to either output the flow with incrementing IP IDs or with a fixed
    IP ID regardless of what the original IP ID ordering was.  This is useful
    in cases where the DF bit is set and we do not care if the original IP ID
    value is maintained.
    
    Signed-off-by: Alexander Duyck <aduyck@mirantis.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 8217cd22f921..5bbea9a0ce96 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1195,10 +1195,10 @@ EXPORT_SYMBOL(inet_sk_rebuild_header);
 static struct sk_buff *inet_gso_segment(struct sk_buff *skb,
 					netdev_features_t features)
 {
+	bool udpfrag = false, fixedid = false, encap;
 	struct sk_buff *segs = ERR_PTR(-EINVAL);
 	const struct net_offload *ops;
 	unsigned int offset = 0;
-	bool udpfrag, encap;
 	struct iphdr *iph;
 	int proto;
 	int nhoff;
@@ -1217,6 +1217,7 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb,
 		       SKB_GSO_TCPV6 |
 		       SKB_GSO_UDP_TUNNEL |
 		       SKB_GSO_UDP_TUNNEL_CSUM |
+		       SKB_GSO_TCP_FIXEDID |
 		       SKB_GSO_TUNNEL_REMCSUM |
 		       0)))
 		goto out;
@@ -1248,11 +1249,14 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb,
 
 	segs = ERR_PTR(-EPROTONOSUPPORT);
 
-	if (skb->encapsulation &&
-	    skb_shinfo(skb)->gso_type & (SKB_GSO_SIT|SKB_GSO_IPIP))
-		udpfrag = proto == IPPROTO_UDP && encap;
-	else
-		udpfrag = proto == IPPROTO_UDP && !skb->encapsulation;
+	if (!skb->encapsulation || encap) {
+		udpfrag = !!(skb_shinfo(skb)->gso_type & SKB_GSO_UDP);
+		fixedid = !!(skb_shinfo(skb)->gso_type & SKB_GSO_TCP_FIXEDID);
+
+		/* fixed ID is invalid if DF bit is not set */
+		if (fixedid && !(iph->frag_off & htons(IP_DF)))
+			goto out;
+	}
 
 	ops = rcu_dereference(inet_offloads[proto]);
 	if (likely(ops && ops->callbacks.gso_segment))
@@ -1265,12 +1269,11 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb,
 	do {
 		iph = (struct iphdr *)(skb_mac_header(skb) + nhoff);
 		if (udpfrag) {
-			iph->id = htons(id);
 			iph->frag_off = htons(offset >> 3);
 			if (skb->next)
 				iph->frag_off |= htons(IP_MF);
 			offset += skb->len - nhoff - ihl;
-		} else {
+		} else if (!fixedid) {
 			iph->id = htons(id++);
 		}
 		iph->tot_len = htons(skb->len - nhoff);

commit 1e1d04e678cf72442f57ce82803c7a407769135f
Author: Hannes Frederic Sowa <hannes@stressinduktion.org>
Date:   Tue Apr 5 17:10:15 2016 +0200

    net: introduce lockdep_is_held and update various places to use it
    
    The socket is either locked if we hold the slock spin_lock for
    lock_sock_fast and unlock_sock_fast or we own the lock (sk_lock.owned
    != 0). Check for this and at the same time improve that the current
    thread/cpu is really holding the lock.
    
    Signed-off-by: Hannes Frederic Sowa <hannes@stressinduktion.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index a38b9910af60..8217cd22f921 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1107,7 +1107,7 @@ static int inet_sk_reselect_saddr(struct sock *sk)
 	struct ip_options_rcu *inet_opt;
 
 	inet_opt = rcu_dereference_protected(inet->inet_opt,
-					     sock_owned_by_user(sk));
+					     lockdep_sock_is_held(sk));
 	if (inet_opt && inet_opt->opt.srr)
 		daddr = inet_opt->opt.faddr;
 

commit 627d2d6b550094d88f9e518e15967e7bf906ebbf
Author: samanthakumar <samanthakumar@google.com>
Date:   Tue Apr 5 12:41:16 2016 -0400

    udp: enable MSG_PEEK at non-zero offset
    
    Enable peeking at UDP datagrams at the offset specified with socket
    option SOL_SOCKET/SO_PEEK_OFF. Peek at any datagram in the queue, up
    to the end of the given datagram.
    
    Implement the SO_PEEK_OFF semantics introduced in commit ef64a54f6e55
    ("sock: Introduce the SO_PEEK_OFF sock option"). Increase the offset
    on peek, decrease it on regular reads.
    
    When peeking, always checksum the packet immediately, to avoid
    recomputation on subsequent peeks and final read.
    
    The socket lock is not held for the duration of udp_recvmsg, so
    peek and read operations can run concurrently. Only the last store
    to sk_peek_off is preserved.
    
    Signed-off-by: Sam Kumar <samanthakumar@google.com>
    Signed-off-by: Willem de Bruijn <willemb@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 9e481992dbae..a38b9910af60 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -948,6 +948,7 @@ const struct proto_ops inet_dgram_ops = {
 	.recvmsg	   = inet_recvmsg,
 	.mmap		   = sock_no_mmap,
 	.sendpage	   = inet_sendpage,
+	.set_peek_off	   = sk_set_peek_off,
 #ifdef CONFIG_COMPAT
 	.compat_setsockopt = compat_sock_common_setsockopt,
 	.compat_getsockopt = compat_sock_common_getsockopt,

commit 3ba9d300c925d89914d15beff2180064ac7ee6f6
Author: Deepa Dinamani <deepa.kernel@gmail.com>
Date:   Mon Mar 21 18:21:26 2016 -0700

    net: ipv4: Fix truncated timestamp returned by inet_current_timestamp()
    
    The millisecond timestamps returned by the function is
    converted to network byte order by making a call to htons().
    htons() only returns __be16 while __be32 is required here.
    
    This was identified by the sparse warning from the buildbot:
    net/ipv4/af_inet.c:1405:16: sparse: incorrect type in return
                                expression (different base types)
    net/ipv4/af_inet.c:1405:16: expected restricted __be32
    net/ipv4/af_inet.c:1405:16: got restricted __be16 [usertype] <noident>
    
    Change the function to use htonl() to return the correct __be32 type
    instead so that the millisecond value doesn't get truncated.
    
    Signed-off-by: Deepa Dinamani <deepa.kernel@gmail.com>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Alexey Kuznetsov <kuznet@ms2.inr.ac.ru>
    Cc: Hideaki YOSHIFUJI <yoshfuji@linux-ipv6.org>
    Cc: James Morris <jmorris@namei.org>
    Cc: Patrick McHardy <kaber@trash.net>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Fixes: 822c868532ca ("net: ipv4: Convert IP network timestamps to be y2038 safe")
    Reported-by: Fengguang Wu <fengguang.wu@intel.com> [0-day test robot]
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 0fefba64ee79..9e481992dbae 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1415,7 +1415,7 @@ __be32 inet_current_timestamp(void)
 	msecs += (u32)ts.tv_nsec / NSEC_PER_MSEC;
 
 	/* Convert to network byte order. */
-	return htons(msecs);
+	return htonl(msecs);
 }
 EXPORT_SYMBOL(inet_current_timestamp);
 

commit fac8e0f579695a3ecbc4d3cac369139d7f819971
Author: Jesse Gross <jesse@kernel.org>
Date:   Sat Mar 19 09:32:01 2016 -0700

    tunnels: Don't apply GRO to multiple layers of encapsulation.
    
    When drivers express support for TSO of encapsulated packets, they
    only mean that they can do it for one layer of encapsulation.
    Supporting additional levels would mean updating, at a minimum,
    more IP length fields and they are unaware of this.
    
    No encapsulation device expresses support for handling offloaded
    encapsulated packets, so we won't generate these types of frames
    in the transmit path. However, GRO doesn't have a check for
    multiple levels of encapsulation and will attempt to build them.
    
    UDP tunnel GRO actually does prevent this situation but it only
    handles multiple UDP tunnels stacked on top of each other. This
    generalizes that solution to prevent any kind of tunnel stacking
    that would cause problems.
    
    Fixes: bf5a755f ("net-gre-gro: Add GRE support to the GRO stack")
    Signed-off-by: Jesse Gross <jesse@kernel.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 965923325535..0fefba64ee79 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1380,6 +1380,19 @@ static struct sk_buff **inet_gro_receive(struct sk_buff **head,
 	return pp;
 }
 
+static struct sk_buff **ipip_gro_receive(struct sk_buff **head,
+					 struct sk_buff *skb)
+{
+	if (NAPI_GRO_CB(skb)->encap_mark) {
+		NAPI_GRO_CB(skb)->flush = 1;
+		return NULL;
+	}
+
+	NAPI_GRO_CB(skb)->encap_mark = 1;
+
+	return inet_gro_receive(head, skb);
+}
+
 #define SECONDS_PER_DAY	86400
 
 /* inet_current_timestamp - Return IP network timestamp
@@ -1682,7 +1695,7 @@ static struct packet_offload ip_packet_offload __read_mostly = {
 static const struct net_offload ipip_offload = {
 	.callbacks = {
 		.gso_segment	= inet_gso_segment,
-		.gro_receive	= inet_gro_receive,
+		.gro_receive	= ipip_gro_receive,
 		.gro_complete	= ipip_gro_complete,
 	},
 };

commit b8cba75bdf6a48ea4811bbefb11a94a5c7281b68
Author: Jesse Gross <jesse@kernel.org>
Date:   Sat Mar 19 09:32:00 2016 -0700

    ipip: Properly mark ipip GRO packets as encapsulated.
    
    ipip encapsulated packets can be merged together by GRO but the result
    does not have the proper GSO type set or even marked as being
    encapsulated at all. Later retransmission of these packets will likely
    fail if the device does not support ipip offloads. This is similar to
    the issue resolved in IPv6 sit in feec0cb3
    ("ipv6: gro: support sit protocol").
    
    Reported-by: Patrick Boutilier <boutilpj@ednet.ns.ca>
    Fixes: 9667e9bb ("ipip: Add gro callbacks to ipip offload")
    Tested-by: Patrick Boutilier <boutilpj@ednet.ns.ca>
    Acked-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: Jesse Gross <jesse@kernel.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 0cc923f83e10..965923325535 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1448,6 +1448,13 @@ static int inet_gro_complete(struct sk_buff *skb, int nhoff)
 	return err;
 }
 
+static int ipip_gro_complete(struct sk_buff *skb, int nhoff)
+{
+	skb->encapsulation = 1;
+	skb_shinfo(skb)->gso_type |= SKB_GSO_IPIP;
+	return inet_gro_complete(skb, nhoff);
+}
+
 int inet_ctl_sock_create(struct sock **sk, unsigned short family,
 			 unsigned short type, unsigned char protocol,
 			 struct net *net)
@@ -1676,7 +1683,7 @@ static const struct net_offload ipip_offload = {
 	.callbacks = {
 		.gso_segment	= inet_gso_segment,
 		.gro_receive	= inet_gro_receive,
-		.gro_complete	= inet_gro_complete,
+		.gro_complete	= ipip_gro_complete,
 	},
 };
 

commit 822c868532cae2cc1c51f4f18ab61c194d98aaf6
Author: Deepa Dinamani <deepa.kernel@gmail.com>
Date:   Sat Feb 27 00:32:15 2016 -0800

    net: ipv4: Convert IP network timestamps to be y2038 safe
    
    ICMP timestamp messages and IP source route options require
    timestamps to be in milliseconds modulo 24 hours from
    midnight UT format.
    
    Add inet_current_timestamp() function to support this. The function
    returns the required timestamp in network byte order.
    
    Timestamp calculation is also changed to call ktime_get_real_ts64()
    which uses struct timespec64. struct timespec64 is y2038 safe.
    Previously it called getnstimeofday() which uses struct timespec.
    struct timespec is not y2038 safe.
    
    Signed-off-by: Deepa Dinamani <deepa.kernel@gmail.com>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Alexey Kuznetsov <kuznet@ms2.inr.ac.ru>
    Cc: Hideaki YOSHIFUJI <yoshfuji@linux-ipv6.org>
    Cc: James Morris <jmorris@namei.org>
    Cc: Patrick McHardy <kaber@trash.net>
    Acked-by: YOSHIFUJI Hideaki <yoshfuji@linux-ipv6.org>
    Acked-by: Arnd Bergmann <arnd@arndb.de>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 209d1ed28954..0cc923f83e10 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1380,6 +1380,32 @@ static struct sk_buff **inet_gro_receive(struct sk_buff **head,
 	return pp;
 }
 
+#define SECONDS_PER_DAY	86400
+
+/* inet_current_timestamp - Return IP network timestamp
+ *
+ * Return milliseconds since midnight in network byte order.
+ */
+__be32 inet_current_timestamp(void)
+{
+	u32 secs;
+	u32 msecs;
+	struct timespec64 ts;
+
+	ktime_get_real_ts64(&ts);
+
+	/* Get secs since midnight. */
+	(void)div_u64_rem(ts.tv_sec, SECONDS_PER_DAY, &secs);
+	/* Convert to msecs. */
+	msecs = secs * MSEC_PER_SEC;
+	/* Convert nsec to msec. */
+	msecs += (u32)ts.tv_nsec / NSEC_PER_MSEC;
+
+	/* Convert to network byte order. */
+	return htons(msecs);
+}
+EXPORT_SYMBOL(inet_current_timestamp);
+
 int inet_recv_error(struct sock *sk, struct msghdr *msg, int len, int *addr_len)
 {
 	if (sk->sk_family == AF_INET)

commit 287b7f38fd6842e534db1783cead3843f7677b79
Author: Nikolay Borisov <kernel@kyup.com>
Date:   Mon Feb 15 12:11:29 2016 +0200

    ipv4: Namespacify ip_dynaddr sysctl knob
    
    Signed-off-by: Nikolay Borisov <kernel@kyup.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index eade66db214e..209d1ed28954 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1095,12 +1095,6 @@ void inet_unregister_protosw(struct inet_protosw *p)
 }
 EXPORT_SYMBOL(inet_unregister_protosw);
 
-/*
- *      Shall we try to damage output packets if routing dev changes?
- */
-
-int sysctl_ip_dynaddr __read_mostly;
-
 static int inet_sk_reselect_saddr(struct sock *sk)
 {
 	struct inet_sock *inet = inet_sk(sk);
@@ -1131,7 +1125,7 @@ static int inet_sk_reselect_saddr(struct sock *sk)
 	if (new_saddr == old_saddr)
 		return 0;
 
-	if (sysctl_ip_dynaddr > 1) {
+	if (sock_net(sk)->ipv4.sysctl_ip_dynaddr > 1) {
 		pr_info("%s(): shifting inet->saddr from %pI4 to %pI4\n",
 			__func__, &old_saddr, &new_saddr);
 	}
@@ -1186,7 +1180,7 @@ int inet_sk_rebuild_header(struct sock *sk)
 		 * Other protocols have to map its equivalent state to TCP_SYN_SENT.
 		 * DCCP maps its DCCP_REQUESTING state to TCP_SYN_SENT. -acme
 		 */
-		if (!sysctl_ip_dynaddr ||
+		if (!sock_net(sk)->ipv4.sysctl_ip_dynaddr ||
 		    sk->sk_state != TCP_SYN_SENT ||
 		    (sk->sk_userlocks & SOCK_BINDADDR_LOCK) ||
 		    (err = inet_sk_reselect_saddr(sk)) != 0)

commit 086c653f5862591a9cfe2386f5650d03adacc33a
Author: Craig Gallek <kraig@google.com>
Date:   Wed Feb 10 11:50:35 2016 -0500

    sock: struct proto hash function may error
    
    In order to support fast reuseport lookups in TCP, the hash function
    defined in struct proto must be capable of returning an error code.
    This patch changes the function signature of all related hash functions
    to return an integer and handles or propagates this return value at
    all call sites.
    
    Signed-off-by: Craig Gallek <kraig@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 5c5db6636704..eade66db214e 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -370,7 +370,11 @@ static int inet_create(struct net *net, struct socket *sock, int protocol,
 		 */
 		inet->inet_sport = htons(inet->inet_num);
 		/* Add to protocol hash chains. */
-		sk->sk_prot->hash(sk);
+		err = sk->sk_prot->hash(sk);
+		if (err) {
+			sk_common_release(sk);
+			goto out;
+		}
 	}
 
 	if (sk->sk_prot->init) {
@@ -1142,8 +1146,7 @@ static int inet_sk_reselect_saddr(struct sock *sk)
 	 * Besides that, it does not check for connection
 	 * uniqueness. Wait for troubles.
 	 */
-	__sk_prot_rehash(sk);
-	return 0;
+	return __sk_prot_rehash(sk);
 }
 
 int inet_sk_rebuild_header(struct sock *sk)

commit 79462ad02e861803b3840cc782248c7359451cd9
Author: Hannes Frederic Sowa <hannes@stressinduktion.org>
Date:   Mon Dec 14 22:03:39 2015 +0100

    net: add validation for the socket syscall protocol argument
    
    郭永刚 reported that one could simply crash the kernel as root by
    using a simple program:
    
            int socket_fd;
            struct sockaddr_in addr;
            addr.sin_port = 0;
            addr.sin_addr.s_addr = INADDR_ANY;
            addr.sin_family = 10;
    
            socket_fd = socket(10,3,0x40000000);
            connect(socket_fd , &addr,16);
    
    AF_INET, AF_INET6 sockets actually only support 8-bit protocol
    identifiers. inet_sock's skc_protocol field thus is sized accordingly,
    thus larger protocol identifiers simply cut off the higher bits and
    store a zero in the protocol fields.
    
    This could lead to e.g. NULL function pointer because as a result of
    the cut off inet_num is zero and we call down to inet_autobind, which
    is NULL for raw sockets.
    
    kernel: Call Trace:
    kernel:  [<ffffffff816db90e>] ? inet_autobind+0x2e/0x70
    kernel:  [<ffffffff816db9a4>] inet_dgram_connect+0x54/0x80
    kernel:  [<ffffffff81645069>] SYSC_connect+0xd9/0x110
    kernel:  [<ffffffff810ac51b>] ? ptrace_notify+0x5b/0x80
    kernel:  [<ffffffff810236d8>] ? syscall_trace_enter_phase2+0x108/0x200
    kernel:  [<ffffffff81645e0e>] SyS_connect+0xe/0x10
    kernel:  [<ffffffff81779515>] tracesys_phase2+0x84/0x89
    
    I found no particular commit which introduced this problem.
    
    CVE: CVE-2015-8543
    Cc: Cong Wang <cwang@twopensource.com>
    Reported-by: 郭永刚 <guoyonggang@360.cn>
    Signed-off-by: Hannes Frederic Sowa <hannes@stressinduktion.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 11c4ca13ec3b..5c5db6636704 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -257,6 +257,9 @@ static int inet_create(struct net *net, struct socket *sock, int protocol,
 	int try_loading_module = 0;
 	int err;
 
+	if (protocol < 0 || protocol >= IPPROTO_MAX)
+		return -EINVAL;
+
 	sock->state = SS_UNCONNECTED;
 
 	/* Look for the requested type/protocol pair. */

commit 3236b0042ba6555b45d75b6be12922922e17d66e
Author: David Ahern <dsa@cumulusnetworks.com>
Date:   Tue Sep 29 20:07:14 2015 -0700

    net: Replace vrf_dev_table and friends
    
    Replace calls to vrf_dev_table and friends with l3mdev_fib_table
    and kin.
    
    Signed-off-by: David Ahern <dsa@cumulusnetworks.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 3af85eecbe11..11c4ca13ec3b 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -119,7 +119,7 @@
 #ifdef CONFIG_IP_MROUTE
 #include <linux/mroute.h>
 #endif
-#include <net/vrf.h>
+#include <net/l3mdev.h>
 
 
 /* The inetsw table contains everything that inet_create needs to
@@ -446,7 +446,7 @@ int inet_bind(struct socket *sock, struct sockaddr *uaddr, int addr_len)
 			goto out;
 	}
 
-	tb_id = vrf_dev_table_ifindex(net, sk->sk_bound_dev_if) ? : tb_id;
+	tb_id = l3mdev_fib_table_by_index(net, sk->sk_bound_dev_if) ? : tb_id;
 	chk_addr_ret = inet_addr_type_table(net, addr->sin_addr.s_addr, tb_id);
 
 	/* Not specified by any standard per-se, however it breaks too

commit 0536fcc039a8926ec12ec587f41a83f7acafeb82
Author: Eric Dumazet <edumazet@google.com>
Date:   Tue Sep 29 07:42:52 2015 -0700

    tcp: prepare fastopen code for upcoming listener changes
    
    While auditing TCP stack for upcoming 'lockless' listener changes,
    I found I had to change fastopen_init_queue() to properly init the object
    before publishing it.
    
    Otherwise an other cpu could try to lock the spinlock before it gets
    properly initialized.
    
    Instead of adding appropriate barriers, just remove dynamic memory
    allocations :
    - Structure is 28 bytes on 64bit arches. Using additional 8 bytes
      for holding a pointer seems overkill.
    - Two listeners can share same cache line and performance would suffer.
    
    If we really want to save few bytes, we would instead dynamically allocate
    whole struct request_sock_queue in the future.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 8a556643b874..3af85eecbe11 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -219,17 +219,13 @@ int inet_listen(struct socket *sock, int backlog)
 		 * shutdown() (rather than close()).
 		 */
 		if ((sysctl_tcp_fastopen & TFO_SERVER_ENABLE) != 0 &&
-		    !inet_csk(sk)->icsk_accept_queue.fastopenq) {
+		    !inet_csk(sk)->icsk_accept_queue.fastopenq.max_qlen) {
 			if ((sysctl_tcp_fastopen & TFO_SERVER_WO_SOCKOPT1) != 0)
-				err = fastopen_init_queue(sk, backlog);
+				fastopen_queue_tune(sk, backlog);
 			else if ((sysctl_tcp_fastopen &
 				  TFO_SERVER_WO_SOCKOPT2) != 0)
-				err = fastopen_init_queue(sk,
+				fastopen_queue_tune(sk,
 				    ((uint)sysctl_tcp_fastopen) >> 16);
-			else
-				err = 0;
-			if (err)
-				goto out;
 
 			tcp_fastopen_init_key_once(true);
 		}

commit f6c53334d6c6ac7088c2e7e70ff2941bfb33f52e
Author: Junwei Zhang <martinbj2008@gmail.com>
Date:   Fri Sep 18 00:00:05 2015 -0400

    net: only check perm protocol when register proto
    
    The permanent protocol nodes are at the head of the list,
    So only need check all these nodes.
    
    No matter the new node is permanent or not,
    insert the new node after the last permanent protocol node,
    
    If the new node conflicts with existing permanent node,
    return error.
    
    Signed-off-by: Martin Zhang <martinbj2008@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 1d0c3adb6f34..8a556643b874 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1043,22 +1043,16 @@ void inet_register_protosw(struct inet_protosw *p)
 		goto out_illegal;
 
 	/* If we are trying to override a permanent protocol, bail. */
-	answer = NULL;
 	last_perm = &inetsw[p->type];
 	list_for_each(lh, &inetsw[p->type]) {
 		answer = list_entry(lh, struct inet_protosw, list);
-
 		/* Check only the non-wild match. */
-		if (INET_PROTOSW_PERMANENT & answer->flags) {
-			if (protocol == answer->protocol)
-				break;
-			last_perm = lh;
-		}
-
-		answer = NULL;
+		if ((INET_PROTOSW_PERMANENT & answer->flags) == 0)
+			break;
+		if (protocol == answer->protocol)
+			goto out_permanent;
+		last_perm = lh;
 	}
-	if (answer)
-		goto out_permanent;
 
 	/* Add the new entry after the last permanent entry if any, so that
 	 * the new entry does not override a permanent entry when matched with

commit 9b8ff51822893e743eee09350c1928daa3ef503f
Author: David Ahern <dsa@cumulusnetworks.com>
Date:   Tue Sep 1 14:26:35 2015 -0600

    net: Make table id type u32
    
    A number of VRF patches used 'int' for table id. It should be u32 to be
    consistent with the rest of the stack.
    
    Fixes:
    4e3c89920cd3a ("net: Introduce VRF related flags and helpers")
    15be405eb2ea9 ("net: Add inet_addr lookup by table")
    30bbaa1950055 ("net: Fix up inet_addr_type checks")
    021dd3b8a142d ("net: Add routes to the table associated with the device")
    dc028da54ed35 ("inet: Move VRF table lookup to inlined function")
    f6d3c19274c74 ("net: FIB tracepoints")
    
    Signed-off-by: David Ahern <dsa@cumulusnetworks.com>
    Reviewed-by: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 96773a2f95a7..1d0c3adb6f34 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -428,7 +428,7 @@ int inet_bind(struct socket *sock, struct sockaddr *uaddr, int addr_len)
 	struct net *net = sock_net(sk);
 	unsigned short snum;
 	int chk_addr_ret;
-	int tb_id = RT_TABLE_LOCAL;
+	u32 tb_id = RT_TABLE_LOCAL;
 	int err;
 
 	/* If the socket has its own bind function then use it. (RAW) */

commit d1bfc62591a0a5144dc380976e737fbbb4f40f4f
Author: Madalin Bucur <madalin.bucur@freescale.com>
Date:   Mon Aug 31 15:46:07 2015 +0300

    ipv4: fix 32b build
    
    Address remaining issue after 80ec192.
    
    Signed-off-by: Madalin Bucur <madalin.bucur@freescale.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index c2d0ebc628d7..96773a2f95a7 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1496,7 +1496,7 @@ u64 snmp_fold_field64(void __percpu *mib, int offt, size_t syncp_offset)
 	int cpu;
 
 	for_each_possible_cpu(cpu) {
-		res += snmp_get_cpu_field(mib, cpu, offt, syncp_offset);
+		res += snmp_get_cpu_field64(mib, cpu, offt, syncp_offset);
 	}
 	return res;
 }

commit 80ec1927b102480f89436e7d7f961a263e916a44
Author: David S. Miller <davem@davemloft.net>
Date:   Sun Aug 30 22:40:44 2015 -0700

    ipv4: Fix 32-bit build.
    
       net/ipv4/af_inet.c: In function 'snmp_get_cpu_field64':
    >> net/ipv4/af_inet.c:1486:26: error: 'offt' undeclared (first use in this function)
          v = *(((u64 *)bhptr) + offt);
                                 ^
       net/ipv4/af_inet.c:1486:26: note: each undeclared identifier is reported only once for each function it appears in
       net/ipv4/af_inet.c: In function 'snmp_fold_field64':
    >> net/ipv4/af_inet.c:1499:39: error: 'offct' undeclared (first use in this function)
          res += snmp_get_cpu_field(mib, cpu, offct, syncp_offset);
                                              ^
    >> net/ipv4/af_inet.c:1499:10: error: too many arguments to function 'snmp_get_cpu_field'
          res += snmp_get_cpu_field(mib, cpu, offct, syncp_offset);
                 ^
       net/ipv4/af_inet.c:1455:5: note: declared here
        u64 snmp_get_cpu_field(void __percpu *mib, int cpu, int offt)
            ^
    
    Reported-by: kbuild test robot <fengguang.wu@intel.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 0c69c0bbe1a1..c2d0ebc628d7 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1471,7 +1471,7 @@ EXPORT_SYMBOL_GPL(snmp_fold_field);
 
 #if BITS_PER_LONG==32
 
-u64 snmp_get_cpu_field64(void __percpu *mib, int cpu, int offct,
+u64 snmp_get_cpu_field64(void __percpu *mib, int cpu, int offt,
 			 size_t syncp_offset)
 {
 	void *bhptr;
@@ -1496,7 +1496,7 @@ u64 snmp_fold_field64(void __percpu *mib, int offt, size_t syncp_offset)
 	int cpu;
 
 	for_each_possible_cpu(cpu) {
-		res += snmp_get_cpu_field(mib, cpu, offct, syncp_offset);
+		res += snmp_get_cpu_field(mib, cpu, offt, syncp_offset);
 	}
 	return res;
 }

commit c4c6bc314618f60ba69b0cbf93e506e4c38a11d2
Author: Raghavendra K T <raghavendra.kt@linux.vnet.ibm.com>
Date:   Sun Aug 30 11:29:41 2015 +0530

    net: Introduce helper functions to get the per cpu data
    
    Signed-off-by: Raghavendra K T <raghavendra.kt@linux.vnet.ibm.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 675e88cac2b4..0c69c0bbe1a1 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1452,38 +1452,51 @@ int inet_ctl_sock_create(struct sock **sk, unsigned short family,
 }
 EXPORT_SYMBOL_GPL(inet_ctl_sock_create);
 
+u64 snmp_get_cpu_field(void __percpu *mib, int cpu, int offt)
+{
+	return  *(((unsigned long *)per_cpu_ptr(mib, cpu)) + offt);
+}
+EXPORT_SYMBOL_GPL(snmp_get_cpu_field);
+
 unsigned long snmp_fold_field(void __percpu *mib, int offt)
 {
 	unsigned long res = 0;
 	int i;
 
 	for_each_possible_cpu(i)
-		res += *(((unsigned long *) per_cpu_ptr(mib, i)) + offt);
+		res += snmp_get_cpu_field(mib, i, offt);
 	return res;
 }
 EXPORT_SYMBOL_GPL(snmp_fold_field);
 
 #if BITS_PER_LONG==32
 
+u64 snmp_get_cpu_field64(void __percpu *mib, int cpu, int offct,
+			 size_t syncp_offset)
+{
+	void *bhptr;
+	struct u64_stats_sync *syncp;
+	u64 v;
+	unsigned int start;
+
+	bhptr = per_cpu_ptr(mib, cpu);
+	syncp = (struct u64_stats_sync *)(bhptr + syncp_offset);
+	do {
+		start = u64_stats_fetch_begin_irq(syncp);
+		v = *(((u64 *)bhptr) + offt);
+	} while (u64_stats_fetch_retry_irq(syncp, start));
+
+	return v;
+}
+EXPORT_SYMBOL_GPL(snmp_get_cpu_field64);
+
 u64 snmp_fold_field64(void __percpu *mib, int offt, size_t syncp_offset)
 {
 	u64 res = 0;
 	int cpu;
 
 	for_each_possible_cpu(cpu) {
-		void *bhptr;
-		struct u64_stats_sync *syncp;
-		u64 v;
-		unsigned int start;
-
-		bhptr = per_cpu_ptr(mib, cpu);
-		syncp = (struct u64_stats_sync *)(bhptr + syncp_offset);
-		do {
-			start = u64_stats_fetch_begin_irq(syncp);
-			v = *(((u64 *) bhptr) + offt);
-		} while (u64_stats_fetch_retry_irq(syncp, start));
-
-		res += v;
+		res += snmp_get_cpu_field(mib, cpu, offct, syncp_offset);
 	}
 	return res;
 }

commit dc028da54ed353edd44dca88b7eb19fd5126c354
Author: David Ahern <dsa@cumulusnetworks.com>
Date:   Sun Aug 16 17:13:27 2015 -0600

    inet: Move VRF table lookup to inlined function
    
    Table lookup compiles out when VRF is not enabled.
    
    Signed-off-by: David Ahern <dsa@cumulusnetworks.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index c8b855882fa5..675e88cac2b4 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -450,15 +450,7 @@ int inet_bind(struct socket *sock, struct sockaddr *uaddr, int addr_len)
 			goto out;
 	}
 
-	if (sk->sk_bound_dev_if) {
-		struct net_device *dev;
-
-		rcu_read_lock();
-		dev = dev_get_by_index_rcu(net, sk->sk_bound_dev_if);
-		if (dev)
-			tb_id = vrf_dev_table_rcu(dev) ? : tb_id;
-		rcu_read_unlock();
-	}
+	tb_id = vrf_dev_table_ifindex(net, sk->sk_bound_dev_if) ? : tb_id;
 	chk_addr_ret = inet_addr_type_table(net, addr->sin_addr.s_addr, tb_id);
 
 	/* Not specified by any standard per-se, however it breaks too

commit 30bbaa19500559d7625c65632195413f639b3b97
Author: David Ahern <dsa@cumulusnetworks.com>
Date:   Thu Aug 13 14:59:05 2015 -0600

    net: Fix up inet_addr_type checks
    
    Currently inet_addr_type and inet_dev_addr_type expect local addresses
    to be in the local table. With the VRF device local routes for devices
    associated with a VRF will be in the table associated with the VRF.
    Provide an alternate inet_addr lookup to use a specific table rather
    than defaulting to the local table.
    
    inet_addr_type_dev_table keeps the same semantics as inet_addr_type but
    if the passed in device is enslaved to a VRF then the table for that VRF
    is used for the lookup.
    
    Signed-off-by: David Ahern <dsa@cumulusnetworks.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index cc4e498a0ccf..c8b855882fa5 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -119,6 +119,7 @@
 #ifdef CONFIG_IP_MROUTE
 #include <linux/mroute.h>
 #endif
+#include <net/vrf.h>
 
 
 /* The inetsw table contains everything that inet_create needs to
@@ -427,6 +428,7 @@ int inet_bind(struct socket *sock, struct sockaddr *uaddr, int addr_len)
 	struct net *net = sock_net(sk);
 	unsigned short snum;
 	int chk_addr_ret;
+	int tb_id = RT_TABLE_LOCAL;
 	int err;
 
 	/* If the socket has its own bind function then use it. (RAW) */
@@ -448,7 +450,16 @@ int inet_bind(struct socket *sock, struct sockaddr *uaddr, int addr_len)
 			goto out;
 	}
 
-	chk_addr_ret = inet_addr_type(net, addr->sin_addr.s_addr);
+	if (sk->sk_bound_dev_if) {
+		struct net_device *dev;
+
+		rcu_read_lock();
+		dev = dev_get_by_index_rcu(net, sk->sk_bound_dev_if);
+		if (dev)
+			tb_id = vrf_dev_table_rcu(dev) ? : tb_id;
+		rcu_read_unlock();
+	}
+	chk_addr_ret = inet_addr_type_table(net, addr->sin_addr.s_addr, tb_id);
 
 	/* Not specified by any standard per-se, however it breaks too
 	 * many applications when removed.  It is unfortunate since

commit 045a0fa0c5f5ea0f16c009f924ea579634afbba8
Author: Thomas Graf <tgraf@suug.ch>
Date:   Thu Jul 23 10:08:44 2015 +0200

    ip_tunnel: Call ip_tunnel_core_init() from inet_init()
    
    Convert the module_init() to a invocation from inet_init() since
    ip_tunnel_core is part of the INET built-in.
    
    Fixes: 3093fbe7ff4 ("route: Per route IP tunnel metadata via lightweight tunnel")
    Signed-off-by: Thomas Graf <tgraf@suug.ch>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 9532ee87151f..cc4e498a0ccf 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -112,6 +112,7 @@
 #include <net/raw.h>
 #include <net/icmp.h>
 #include <net/inet_common.h>
+#include <net/ip_tunnels.h>
 #include <net/xfrm.h>
 #include <net/net_namespace.h>
 #include <net/secure_seq.h>
@@ -1780,6 +1781,8 @@ static int __init inet_init(void)
 
 	dev_add_pack(&ip_packet_type);
 
+	ip_tunnel_core_init();
+
 	rc = 0;
 out:
 	return rc;

commit 3a07bd6fead4f00f67b1bf5f551e686661c4f52c
Merge: 204621551b2a f1590670ce06
Author: David S. Miller <davem@davemloft.net>
Date:   Wed Jun 24 02:58:51 2015 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/davem/net
    
    Conflicts:
            drivers/net/ethernet/mellanox/mlx4/main.c
            net/packet/af_packet.c
    
    Both conflicts were cases of simple overlapping changes.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit dfea2aa654243f70dc53b8648d0bbdeec55a7df1
Author: Christoph Paasch <cpaasch@apple.com>
Date:   Thu Jun 18 09:15:34 2015 -0700

    tcp: Do not call tcp_fastopen_reset_cipher from interrupt context
    
    tcp_fastopen_reset_cipher really cannot be called from interrupt
    context. It allocates the tcp_fastopen_context with GFP_KERNEL and
    calls crypto_alloc_cipher, which allocates all kind of stuff with
    GFP_KERNEL.
    
    Thus, we might sleep when the key-generation is triggered by an
    incoming TFO cookie-request which would then happen in interrupt-
    context, as shown by enabling CONFIG_DEBUG_ATOMIC_SLEEP:
    
    [   36.001813] BUG: sleeping function called from invalid context at mm/slub.c:1266
    [   36.003624] in_atomic(): 1, irqs_disabled(): 0, pid: 1016, name: packetdrill
    [   36.004859] CPU: 1 PID: 1016 Comm: packetdrill Not tainted 4.1.0-rc7 #14
    [   36.006085] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.7.5-0-ge51488c-20140602_164612-nilsson.home.kraxel.org 04/01/2014
    [   36.008250]  00000000000004f2 ffff88007f8838a8 ffffffff8171d53a ffff880075a084a8
    [   36.009630]  ffff880075a08000 ffff88007f8838c8 ffffffff810967d3 ffff88007f883928
    [   36.011076]  0000000000000000 ffff88007f8838f8 ffffffff81096892 ffff88007f89be00
    [   36.012494] Call Trace:
    [   36.012953]  <IRQ>  [<ffffffff8171d53a>] dump_stack+0x4f/0x6d
    [   36.014085]  [<ffffffff810967d3>] ___might_sleep+0x103/0x170
    [   36.015117]  [<ffffffff81096892>] __might_sleep+0x52/0x90
    [   36.016117]  [<ffffffff8118e887>] kmem_cache_alloc_trace+0x47/0x190
    [   36.017266]  [<ffffffff81680d82>] ? tcp_fastopen_reset_cipher+0x42/0x130
    [   36.018485]  [<ffffffff81680d82>] tcp_fastopen_reset_cipher+0x42/0x130
    [   36.019679]  [<ffffffff81680f01>] tcp_fastopen_init_key_once+0x61/0x70
    [   36.020884]  [<ffffffff81680f2c>] __tcp_fastopen_cookie_gen+0x1c/0x60
    [   36.022058]  [<ffffffff816814ff>] tcp_try_fastopen+0x58f/0x730
    [   36.023118]  [<ffffffff81671788>] tcp_conn_request+0x3e8/0x7b0
    [   36.024185]  [<ffffffff810e3872>] ? __module_text_address+0x12/0x60
    [   36.025327]  [<ffffffff8167b2e1>] tcp_v4_conn_request+0x51/0x60
    [   36.026410]  [<ffffffff816727e0>] tcp_rcv_state_process+0x190/0xda0
    [   36.027556]  [<ffffffff81661f97>] ? __inet_lookup_established+0x47/0x170
    [   36.028784]  [<ffffffff8167c2ad>] tcp_v4_do_rcv+0x16d/0x3d0
    [   36.029832]  [<ffffffff812e6806>] ? security_sock_rcv_skb+0x16/0x20
    [   36.030936]  [<ffffffff8167cc8a>] tcp_v4_rcv+0x77a/0x7b0
    [   36.031875]  [<ffffffff816af8c3>] ? iptable_filter_hook+0x33/0x70
    [   36.032953]  [<ffffffff81657d22>] ip_local_deliver_finish+0x92/0x1f0
    [   36.034065]  [<ffffffff81657f1a>] ip_local_deliver+0x9a/0xb0
    [   36.035069]  [<ffffffff81657c90>] ? ip_rcv+0x3d0/0x3d0
    [   36.035963]  [<ffffffff81657569>] ip_rcv_finish+0x119/0x330
    [   36.036950]  [<ffffffff81657ba7>] ip_rcv+0x2e7/0x3d0
    [   36.037847]  [<ffffffff81610652>] __netif_receive_skb_core+0x552/0x930
    [   36.038994]  [<ffffffff81610a57>] __netif_receive_skb+0x27/0x70
    [   36.040033]  [<ffffffff81610b72>] process_backlog+0xd2/0x1f0
    [   36.041025]  [<ffffffff81611482>] net_rx_action+0x122/0x310
    [   36.042007]  [<ffffffff81076743>] __do_softirq+0x103/0x2f0
    [   36.042978]  [<ffffffff81723e3c>] do_softirq_own_stack+0x1c/0x30
    
    This patch moves the call to tcp_fastopen_init_key_once to the places
    where a listener socket creates its TFO-state, which always happens in
    user-context (either from the setsockopt, or implicitly during the
    listen()-call)
    
    Cc: Eric Dumazet <eric.dumazet@gmail.com>
    Cc: Hannes Frederic Sowa <hannes@stressinduktion.org>
    Fixes: 222e83d2e0ae ("tcp: switch tcp_fastopen key generation to net_get_random_once")
    Signed-off-by: Christoph Paasch <cpaasch@apple.com>
    Acked-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 8b47a4d79d04..a5aa54ea6533 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -228,6 +228,8 @@ int inet_listen(struct socket *sock, int backlog)
 				err = 0;
 			if (err)
 				goto out;
+
+			tcp_fastopen_init_key_once(true);
 		}
 		err = inet_csk_listen_start(sk, backlog);
 		if (err)

commit 90c337da1524863838658078ec34241f45d8394d
Author: Eric Dumazet <edumazet@google.com>
Date:   Sat Jun 6 21:17:57 2015 -0700

    inet: add IP_BIND_ADDRESS_NO_PORT to overcome bind(0) limitations
    
    When an application needs to force a source IP on an active TCP socket
    it has to use bind(IP, port=x).
    
    As most applications do not want to deal with already used ports, x is
    often set to 0, meaning the kernel is in charge to find an available
    port.
    But kernel does not know yet if this socket is going to be a listener or
    be connected.
    It has very limited choices (no full knowledge of final 4-tuple for a
    connect())
    
    With limited ephemeral port range (about 32K ports), it is very easy to
    fill the space.
    
    This patch adds a new SOL_IP socket option, asking kernel to ignore
    the 0 port provided by application in bind(IP, port=0) and only
    remember the given IP address.
    
    The port will be automatically chosen at connect() time, in a way
    that allows sharing a source port as long as the 4-tuples are unique.
    
    This new feature is available for both IPv4 and IPv6 (Thanks Neal)
    
    Tested:
    
    Wrote a test program and checked its behavior on IPv4 and IPv6.
    
    strace(1) shows sequences of bind(IP=127.0.0.2, port=0) followed by
    connect().
    Also getsockname() show that the port is still 0 right after bind()
    but properly allocated after connect().
    
    socket(PF_INET, SOCK_STREAM, IPPROTO_IP) = 5
    setsockopt(5, SOL_IP, IP_BIND_ADDRESS_NO_PORT, [1], 4) = 0
    bind(5, {sa_family=AF_INET, sin_port=htons(0), sin_addr=inet_addr("127.0.0.2")}, 16) = 0
    getsockname(5, {sa_family=AF_INET, sin_port=htons(0), sin_addr=inet_addr("127.0.0.2")}, [16]) = 0
    connect(5, {sa_family=AF_INET, sin_port=htons(53174), sin_addr=inet_addr("127.0.0.3")}, 16) = 0
    getsockname(5, {sa_family=AF_INET, sin_port=htons(38050), sin_addr=inet_addr("127.0.0.2")}, [16]) = 0
    
    IPv6 test :
    
    socket(PF_INET6, SOCK_STREAM, IPPROTO_IP) = 7
    setsockopt(7, SOL_IP, IP_BIND_ADDRESS_NO_PORT, [1], 4) = 0
    bind(7, {sa_family=AF_INET6, sin6_port=htons(0), inet_pton(AF_INET6, "::1", &sin6_addr), sin6_flowinfo=0, sin6_scope_id=0}, 28) = 0
    getsockname(7, {sa_family=AF_INET6, sin6_port=htons(0), inet_pton(AF_INET6, "::1", &sin6_addr), sin6_flowinfo=0, sin6_scope_id=0}, [28]) = 0
    connect(7, {sa_family=AF_INET6, sin6_port=htons(57300), inet_pton(AF_INET6, "::1", &sin6_addr), sin6_flowinfo=0, sin6_scope_id=0}, 28) = 0
    getsockname(7, {sa_family=AF_INET6, sin6_port=htons(60964), inet_pton(AF_INET6, "::1", &sin6_addr), sin6_flowinfo=0, sin6_scope_id=0}, [28]) = 0
    
    I was able to bind()/connect() a million concurrent IPv4 sockets,
    instead of ~32000 before patch.
    
    lpaa23:~# ulimit -n 1000010
    lpaa23:~# ./bind --connect --num-flows=1000000 &
    1000000 sockets
    
    lpaa23:~# grep TCP /proc/net/sockstat
    TCP: inuse 2000063 orphan 0 tw 47 alloc 2000157 mem 66
    
    Check that a given source port is indeed used by many different
    connections :
    
    lpaa23:~# ss -t src :40000 | head -10
    State      Recv-Q Send-Q   Local Address:Port          Peer Address:Port
    ESTAB      0      0           127.0.0.2:40000         127.0.202.33:44983
    ESTAB      0      0           127.0.0.2:40000         127.2.27.240:44983
    ESTAB      0      0           127.0.0.2:40000           127.2.98.5:44983
    ESTAB      0      0           127.0.0.2:40000        127.0.124.196:44983
    ESTAB      0      0           127.0.0.2:40000         127.2.139.38:44983
    ESTAB      0      0           127.0.0.2:40000          127.1.59.80:44983
    ESTAB      0      0           127.0.0.2:40000          127.3.6.228:44983
    ESTAB      0      0           127.0.0.2:40000          127.0.38.53:44983
    ESTAB      0      0           127.0.0.2:40000         127.1.197.10:44983
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 6ad0f7a711c9..cc858ef44451 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -488,7 +488,8 @@ int inet_bind(struct socket *sock, struct sockaddr *uaddr, int addr_len)
 		inet->inet_saddr = 0;  /* Use device */
 
 	/* Make sure we are allowed to bind here. */
-	if (sk->sk_prot->get_port(sk, snum)) {
+	if ((snum || !inet->bind_address_no_port) &&
+	    sk->sk_prot->get_port(sk, snum)) {
 		inet->inet_saddr = inet->inet_rcv_saddr = 0;
 		err = -EADDRINUSE;
 		goto out_release_sock;

commit 07f4c90062f8fc7c8c26f8f95324cbe8fa3145a5
Author: Eric Dumazet <edumazet@google.com>
Date:   Sun May 24 14:49:35 2015 -0700

    tcp/dccp: try to not exhaust ip_local_port_range in connect()
    
    A long standing problem on busy servers is the tiny available TCP port
    range (/proc/sys/net/ipv4/ip_local_port_range) and the default
    sequential allocation of source ports in connect() system call.
    
    If a host is having a lot of active TCP sessions, chances are
    very high that all ports are in use by at least one flow,
    and subsequent bind(0) attempts fail, or have to scan a big portion of
    space to find a slot.
    
    In this patch, I changed the starting point in __inet_hash_connect()
    so that we try to favor even [1] ports, leaving odd ports for bind()
    users.
    
    We still perform a sequential search, so there is no guarantee, but
    if connect() targets are very different, end result is we leave
    more ports available to bind(), and we spread them all over the range,
    lowering time for both connect() and bind() to find a slot.
    
    This strategy only works well if /proc/sys/net/ipv4/ip_local_port_range
    is even, ie if start/end values have different parity.
    
    Therefore, default /proc/sys/net/ipv4/ip_local_port_range was changed to
    32768 - 60999 (instead of 32768 - 61000)
    
    There is no change on security aspects here, only some poor hashing
    schemes could be eventually impacted by this change.
    
    [1] : The odd/even property depends on ip_local_port_range values parity
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 235d36afece3..6ad0f7a711c9 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1595,7 +1595,7 @@ static __net_init int inet_init_net(struct net *net)
 	 */
 	seqlock_init(&net->ipv4.ip_local_ports.lock);
 	net->ipv4.ip_local_ports.range[0] =  32768;
-	net->ipv4.ip_local_ports.range[1] =  61000;
+	net->ipv4.ip_local_ports.range[1] =  60999;
 
 	seqlock_init(&net->ipv4.ping_group_range.lock);
 	/*

commit 26abe14379f8e2fa3fd1bcf97c9a7ad9364886fe
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Fri May 8 21:10:31 2015 -0500

    net: Modify sk_alloc to not reference count the netns of kernel sockets.
    
    Now that sk_alloc knows when a kernel socket is being allocated modify
    it to not reference count the network namespace of kernel sockets.
    
    Keep track of if a socket needs reference counting by adding a flag to
    struct sock called sk_net_refcnt.
    
    Update all of the callers of sock_create_kern to stop using
    sk_change_net and sk_release_kernel as those hacks are no longer
    needed, to avoid reference counting a kernel socket.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index e2dd9cb99d61..235d36afece3 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1430,7 +1430,7 @@ int inet_ctl_sock_create(struct sock **sk, unsigned short family,
 			 struct net *net)
 {
 	struct socket *sock;
-	int rc = sock_create_kern(&init_net, family, type, protocol, &sock);
+	int rc = sock_create_kern(net, family, type, protocol, &sock);
 
 	if (rc == 0) {
 		*sk = sock->sk;
@@ -1440,8 +1440,6 @@ int inet_ctl_sock_create(struct sock **sk, unsigned short family,
 		 * we do not wish this socket to see incoming packets.
 		 */
 		(*sk)->sk_prot->unhash(*sk);
-
-		sk_change_net(*sk, net);
 	}
 	return rc;
 }

commit 11aa9c28b4209242a9de0a661a7b3405adb568a0
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Fri May 8 21:09:13 2015 -0500

    net: Pass kern from net_proto_family.create to sk_alloc
    
    In preparation for changing how struct net is refcounted
    on kernel sockets pass the knowledge that we are creating
    a kernel socket from sock_create_kern through to sk_alloc.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 09f4d024dfe5..e2dd9cb99d61 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -317,7 +317,7 @@ static int inet_create(struct net *net, struct socket *sock, int protocol,
 	WARN_ON(!answer_prot->slab);
 
 	err = -ENOBUFS;
-	sk = sk_alloc(net, PF_INET, GFP_KERNEL, answer_prot);
+	sk = sk_alloc(net, PF_INET, GFP_KERNEL, answer_prot, kern);
 	if (!sk)
 		goto out;
 

commit eeb1bd5c40edb0e2fd925c8535e2fdebdbc5cef2
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Fri May 8 21:08:05 2015 -0500

    net: Add a struct net parameter to sock_create_kern
    
    This is long overdue, and is part of cleaning up how we allocate kernel
    sockets that don't reference count struct net.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 8b47a4d79d04..09f4d024dfe5 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1430,7 +1430,7 @@ int inet_ctl_sock_create(struct sock **sk, unsigned short family,
 			 struct net *net)
 {
 	struct socket *sock;
-	int rc = sock_create_kern(family, type, protocol, &sock);
+	int rc = sock_create_kern(&init_net, family, type, protocol, &sock);
 
 	if (rc == 0) {
 		*sk = sock->sk;

commit 00db41243e8d5032c2e0f5bf6063bb19324bfdb3
Author: Ian Morris <ipm@chirality.org.uk>
Date:   Fri Apr 3 09:17:27 2015 +0100

    ipv4: coding style: comparison for inequality with NULL
    
    The ipv4 code uses a mixture of coding styles. In some instances check
    for non-NULL pointer is done as x != NULL and sometimes as x. x is
    preferred according to checkpatch and this patch makes the code
    consistent by adopting the latter form.
    
    No changes detected by objdiff.
    
    Signed-off-by: Ian Morris <ipm@chirality.org.uk>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 7d3b00c01bc8..8b47a4d79d04 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1269,7 +1269,7 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb,
 		if (udpfrag) {
 			iph->id = htons(id);
 			iph->frag_off = htons(offset >> 3);
-			if (skb->next != NULL)
+			if (skb->next)
 				iph->frag_off |= htons(IP_MF);
 			offset += skb->len - nhoff - ihl;
 		} else {

commit 51456b2914a34d16b1255b7c55d5cbf6a681d306
Author: Ian Morris <ipm@chirality.org.uk>
Date:   Fri Apr 3 09:17:26 2015 +0100

    ipv4: coding style: comparison for equality with NULL
    
    The ipv4 code uses a mixture of coding styles. In some instances check
    for NULL pointer is done as x == NULL and sometimes as !x. !x is
    preferred according to checkpatch and this patch makes the code
    consistent by adopting the latter form.
    
    No changes detected by objdiff.
    
    Signed-off-by: Ian Morris <ipm@chirality.org.uk>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 64a9c0fdc4aa..7d3b00c01bc8 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -217,7 +217,7 @@ int inet_listen(struct socket *sock, int backlog)
 		 * shutdown() (rather than close()).
 		 */
 		if ((sysctl_tcp_fastopen & TFO_SERVER_ENABLE) != 0 &&
-		    inet_csk(sk)->icsk_accept_queue.fastopenq == NULL) {
+		    !inet_csk(sk)->icsk_accept_queue.fastopenq) {
 			if ((sysctl_tcp_fastopen & TFO_SERVER_WO_SOCKOPT1) != 0)
 				err = fastopen_init_queue(sk, backlog);
 			else if ((sysctl_tcp_fastopen &
@@ -314,11 +314,11 @@ static int inet_create(struct net *net, struct socket *sock, int protocol,
 	answer_flags = answer->flags;
 	rcu_read_unlock();
 
-	WARN_ON(answer_prot->slab == NULL);
+	WARN_ON(!answer_prot->slab);
 
 	err = -ENOBUFS;
 	sk = sk_alloc(net, PF_INET, GFP_KERNEL, answer_prot);
-	if (sk == NULL)
+	if (!sk)
 		goto out;
 
 	err = 0;

commit 1b784140474e4fc94281a49e96c67d29df0efbde
Author: Ying Xue <ying.xue@windriver.com>
Date:   Mon Mar 2 15:37:48 2015 +0800

    net: Remove iocb argument from sendmsg and recvmsg
    
    After TIPC doesn't depend on iocb argument in its internal
    implementations of sendmsg() and recvmsg() hooks defined in proto
    structure, no any user is using iocb argument in them at all now.
    Then we can drop the redundant iocb argument completely from kinds of
    implementations of both sendmsg() and recvmsg() in the entire
    networking stack.
    
    Cc: Christoph Hellwig <hch@lst.de>
    Suggested-by: Al Viro <viro@ZenIV.linux.org.uk>
    Signed-off-by: Ying Xue <ying.xue@windriver.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 4ce954cc94a4..64a9c0fdc4aa 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -716,8 +716,7 @@ int inet_getname(struct socket *sock, struct sockaddr *uaddr,
 }
 EXPORT_SYMBOL(inet_getname);
 
-int inet_sendmsg(struct kiocb *iocb, struct socket *sock, struct msghdr *msg,
-		 size_t size)
+int inet_sendmsg(struct socket *sock, struct msghdr *msg, size_t size)
 {
 	struct sock *sk = sock->sk;
 
@@ -728,7 +727,7 @@ int inet_sendmsg(struct kiocb *iocb, struct socket *sock, struct msghdr *msg,
 	    inet_autobind(sk))
 		return -EAGAIN;
 
-	return sk->sk_prot->sendmsg(iocb, sk, msg, size);
+	return sk->sk_prot->sendmsg(sk, msg, size);
 }
 EXPORT_SYMBOL(inet_sendmsg);
 
@@ -750,8 +749,8 @@ ssize_t inet_sendpage(struct socket *sock, struct page *page, int offset,
 }
 EXPORT_SYMBOL(inet_sendpage);
 
-int inet_recvmsg(struct kiocb *iocb, struct socket *sock, struct msghdr *msg,
-		 size_t size, int flags)
+int inet_recvmsg(struct socket *sock, struct msghdr *msg, size_t size,
+		 int flags)
 {
 	struct sock *sk = sock->sk;
 	int addr_len = 0;
@@ -759,7 +758,7 @@ int inet_recvmsg(struct kiocb *iocb, struct socket *sock, struct msghdr *msg,
 
 	sock_rps_record_flow(sk);
 
-	err = sk->sk_prot->recvmsg(iocb, sk, msg, size, flags & MSG_DONTWAIT,
+	err = sk->sk_prot->recvmsg(sk, msg, size, flags & MSG_DONTWAIT,
 				   flags & ~MSG_DONTWAIT, &addr_len);
 	if (err >= 0)
 		msg->msg_namelen = addr_len;

commit b4772ef879a8f7d8c56118c2ae5a296fcf6f81d2
Author: Eyal Birger <eyal.birger@gmail.com>
Date:   Sun Mar 1 14:58:29 2015 +0200

    net: use common macro for assering skb->cb[] available size in protocol families
    
    As part of an effort to move skb->dropcount to skb->cb[] use a common
    macro in protocol families using skb->cb[] for ancillary data to
    validate available room in skb->cb[].
    
    Signed-off-by: Eyal Birger <eyal.birger@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index d2e49baaff63..4ce954cc94a4 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1675,7 +1675,7 @@ static int __init inet_init(void)
 	struct list_head *r;
 	int rc = -EINVAL;
 
-	BUILD_BUG_ON(sizeof(struct inet_skb_parm) > FIELD_SIZEOF(struct sk_buff, cb));
+	sock_skb_cb_check_size(sizeof(struct inet_skb_parm));
 
 	rc = proto_register(&tcp_prot, 1);
 	if (rc)

commit 567e4b79731c352a17d73c483959f795d3593e03
Author: Eric Dumazet <edumazet@google.com>
Date:   Fri Feb 6 12:59:01 2015 -0800

    net: rfs: add hash collision detection
    
    Receive Flow Steering is a nice solution but suffers from
    hash collisions when a mix of connected and unconnected traffic
    is received on the host, when flow hash table is populated.
    
    Also, clearing flow in inet_release() makes RFS not very good
    for short lived flows, as many packets can follow close().
    (FIN , ACK packets, ...)
    
    This patch extends the information stored into global hash table
    to not only include cpu number, but upper part of the hash value.
    
    I use a 32bit value, and dynamically split it in two parts.
    
    For host with less than 64 possible cpus, this gives 6 bits for the
    cpu number, and 26 (32-6) bits for the upper part of the hash.
    
    Since hash bucket selection use low order bits of the hash, we have
    a full hash match, if /proc/sys/net/core/rps_sock_flow_entries is big
    enough.
    
    If the hash found in flow table does not match, we fallback to RPS (if
    it is enabled for the rxqueue).
    
    This means that a packet for an non connected flow can avoid the
    IPI through a unrelated/victim CPU.
    
    This also means we no longer have to clear the table at socket
    close time, and this helps short lived flows performance.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Acked-by: Tom Herbert <therbert@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index a44773c8346c..d2e49baaff63 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -395,8 +395,6 @@ int inet_release(struct socket *sock)
 	if (sk) {
 		long timeout;
 
-		sock_rps_reset_flow(sk);
-
 		/* Applications forget to leave groups before exiting */
 		ip_mc_drop_socket(sk);
 

commit 60b7379dc5b1743427b031cca53e30860a38ada6
Merge: a523a5ecc8c6 7a5a4f978750
Author: David S. Miller <davem@davemloft.net>
Date:   Sat Nov 29 20:47:48 2014 -0800

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/davem/net

commit f4713a3dfad045d46afcb9c2a7d0bba288920ed4
Author: Willem de Bruijn <willemb@google.com>
Date:   Wed Nov 26 14:53:02 2014 -0500

    net-timestamp: make tcp_recvmsg call ipv6_recv_error for AF_INET6 socks
    
    TCP timestamping introduced MSG_ERRQUEUE handling for TCP sockets.
    If the socket is of family AF_INET6, call ipv6_recv_error instead
    of ip_recv_error.
    
    This change is more complex than a single branch due to the loadable
    ipv6 module. It reuses a pre-existing indirect function call from
    ping. The ping code is safe to call, because it is part of the core
    ipv6 module and always present when AF_INET6 sockets are active.
    
    Fixes: 4ed2d765 (net-timestamp: TCP timestamping)
    Signed-off-by: Willem de Bruijn <willemb@google.com>
    
    ----
    
    It may also be worthwhile to add WARN_ON_ONCE(sk->family == AF_INET6)
    to ip_recv_error.
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 8b7fe5b03906..e67da4e6c324 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1386,6 +1386,17 @@ static struct sk_buff **inet_gro_receive(struct sk_buff **head,
 	return pp;
 }
 
+int inet_recv_error(struct sock *sk, struct msghdr *msg, int len, int *addr_len)
+{
+	if (sk->sk_family == AF_INET)
+		return ip_recv_error(sk, msg, len, addr_len);
+#if IS_ENABLED(CONFIG_IPV6)
+	if (sk->sk_family == AF_INET6)
+		return pingv6_ops.ipv6_recv_error(sk, msg, len, addr_len);
+#endif
+	return -EINVAL;
+}
+
 static int inet_gro_complete(struct sk_buff *skb, int nhoff)
 {
 	__be16 newlen = htons(skb->len - nhoff);

commit 59b93b41e7fa71138734a911b11b044340dd16bd
Author: Pravin B Shelar <pshelar@nicira.com>
Date:   Wed Nov 5 15:27:48 2014 -0800

    net: Remove MPLS GSO feature.
    
    Device can export MPLS GSO support in dev->mpls_features same way
    it export vlan features in dev->vlan_features. So it is safe to
    remove NETIF_F_GSO_MPLS redundant flag.
    
    Signed-off-by: Pravin B Shelar <pshelar@nicira.com>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index ed2c672c5b01..3a096bb2d596 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1223,7 +1223,6 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb,
 		       SKB_GSO_UDP_TUNNEL |
 		       SKB_GSO_UDP_TUNNEL_CSUM |
 		       SKB_GSO_TUNNEL_REMCSUM |
-		       SKB_GSO_MPLS |
 		       0)))
 		goto out;
 

commit e585f23636370320bc2071ca5ba2744ae37c3e51
Author: Tom Herbert <therbert@google.com>
Date:   Tue Nov 4 09:06:54 2014 -0800

    udp: Changes to udp_offload to support remote checksum offload
    
    Add a new GSO type, SKB_GSO_TUNNEL_REMCSUM, which indicates remote
    checksum offload being done (in this case inner checksum must not
    be offloaded to the NIC).
    
    Added logic in __skb_udp_tunnel_segment to handle remote checksum
    offload case.
    
    Signed-off-by: Tom Herbert <therbert@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 8b7fe5b03906..ed2c672c5b01 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1222,6 +1222,7 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb,
 		       SKB_GSO_TCPV6 |
 		       SKB_GSO_UDP_TUNNEL |
 		       SKB_GSO_UDP_TUNNEL_CSUM |
+		       SKB_GSO_TUNNEL_REMCSUM |
 		       SKB_GSO_MPLS |
 		       0)))
 		goto out;

commit 1e16aa3ddf863c6b9f37eddf52503230a62dedb3
Author: Florian Westphal <fw@strlen.de>
Date:   Mon Oct 20 13:49:16 2014 +0200

    net: gso: use feature flag argument in all protocol gso handlers
    
    skb_gso_segment() has a 'features' argument representing offload features
    available to the output path.
    
    A few handlers, e.g. GRE, instead re-fetch the features of skb->dev and use
    those instead of the provided ones when handing encapsulation/tunnels.
    
    Depending on dev->hw_enc_features of the output device skb_gso_segment() can
    then return NULL even when the caller has disabled all GSO feature bits,
    as segmentation of inner header thinks device will take care of segmentation.
    
    This e.g. affects the tbf scheduler, which will silently drop GRE-encap GSO skbs
    that did not fit the remaining token quota as the segmentation does not work
    when device supports corresponding hw offload capabilities.
    
    Cc: Pravin B Shelar <pshelar@nicira.com>
    Signed-off-by: Florian Westphal <fw@strlen.de>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 92db7a69f2b9..8b7fe5b03906 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1246,7 +1246,7 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb,
 
 	encap = SKB_GSO_CB(skb)->encap_level > 0;
 	if (encap)
-		features = skb->dev->hw_enc_features & netif_skb_features(skb);
+		features &= skb->dev->hw_enc_features;
 	SKB_GSO_CB(skb)->encap_level += ihl;
 
 	skb_reset_transport_header(skb);

commit 2c804d0f8fc7799981d9fdd8c88653541b28c1a7
Author: Eric Dumazet <edumazet@google.com>
Date:   Tue Sep 30 22:12:05 2014 -0700

    ipv4: mentions skb_gro_postpull_rcsum() in inet_gro_receive()
    
    Proper CHECKSUM_COMPLETE support needs to adjust skb->csum
    when we remove one header. Its done using skb_gro_postpull_rcsum()
    
    In the case of IPv4, we know that the adjustment is not really needed,
    because the checksum over IPv4 header is 0. Lets add a comment to
    ease code comprehension and avoid copy/paste errors.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 28e589c5f32d..92db7a69f2b9 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1369,6 +1369,9 @@ static struct sk_buff **inet_gro_receive(struct sk_buff **head,
 	 * immediately following this IP hdr.
 	 */
 
+	/* Note : No need to call skb_gro_postpull_rcsum() here,
+	 * as we already checked checksum over ipv4 header was 0
+	 */
 	skb_gro_pull(skb, sizeof(*iph));
 	skb_set_transport_header(skb, skb_gro_offset(skb));
 

commit 53e50398968d43338c4d932114e68bc099fc5fbd
Author: Tom Herbert <therbert@google.com>
Date:   Sat Sep 20 14:52:30 2014 -0700

    net: Remove gso_send_check as an offload callback
    
    The send_check logic was only interesting in cases of TCP offload and
    UDP UFO where the checksum needed to be initialized to the pseudo
    header checksum. Now we've moved that logic into the related
    gso_segment functions so gso_send_check is no longer needed.
    
    Signed-off-by: Tom Herbert <therbert@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 72011cc4c13b..28e589c5f32d 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1197,40 +1197,6 @@ int inet_sk_rebuild_header(struct sock *sk)
 }
 EXPORT_SYMBOL(inet_sk_rebuild_header);
 
-static int inet_gso_send_check(struct sk_buff *skb)
-{
-	const struct net_offload *ops;
-	const struct iphdr *iph;
-	int proto;
-	int ihl;
-	int err = -EINVAL;
-
-	if (unlikely(!pskb_may_pull(skb, sizeof(*iph))))
-		goto out;
-
-	iph = ip_hdr(skb);
-	ihl = iph->ihl * 4;
-	if (ihl < sizeof(*iph))
-		goto out;
-
-	proto = iph->protocol;
-
-	/* Warning: after this point, iph might be no longer valid */
-	if (unlikely(!pskb_may_pull(skb, ihl)))
-		goto out;
-	__skb_pull(skb, ihl);
-
-	skb_reset_transport_header(skb);
-	err = -EPROTONOSUPPORT;
-
-	ops = rcu_dereference(inet_offloads[proto]);
-	if (likely(ops && ops->callbacks.gso_send_check))
-		err = ops->callbacks.gso_send_check(skb);
-
-out:
-	return err;
-}
-
 static struct sk_buff *inet_gso_segment(struct sk_buff *skb,
 					netdev_features_t features)
 {
@@ -1655,7 +1621,6 @@ static int ipv4_proc_init(void);
 static struct packet_offload ip_packet_offload __read_mostly = {
 	.type = cpu_to_be16(ETH_P_IP),
 	.callbacks = {
-		.gso_send_check = inet_gso_send_check,
 		.gso_segment = inet_gso_segment,
 		.gro_receive = inet_gro_receive,
 		.gro_complete = inet_gro_complete,
@@ -1664,7 +1629,6 @@ static struct packet_offload ip_packet_offload __read_mostly = {
 
 static const struct net_offload ipip_offload = {
 	.callbacks = {
-		.gso_send_check = inet_gso_send_check,
 		.gso_segment	= inet_gso_segment,
 		.gro_receive	= inet_gro_receive,
 		.gro_complete	= inet_gro_complete,

commit 9667e9bb3f366435dde74f22578876daae850feb
Author: Tom Herbert <therbert@google.com>
Date:   Tue Sep 9 11:23:15 2014 -0700

    ipip: Add gro callbacks to ipip offload
    
    Add inet_gro_receive and inet_gro_complete to ipip_offload to
    support GRO.
    
    Signed-off-by: Tom Herbert <therbert@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index b537bd94906c..72011cc4c13b 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1666,6 +1666,8 @@ static const struct net_offload ipip_offload = {
 	.callbacks = {
 		.gso_send_check = inet_gso_send_check,
 		.gso_segment	= inet_gso_segment,
+		.gro_receive	= inet_gro_receive,
+		.gro_complete	= inet_gro_complete,
 	},
 };
 

commit 49a601589caaf0e93194c0cc9b4ecddbe75dd2d5
Author: Vincent Bernat <vincent@bernat.im>
Date:   Fri Sep 5 15:09:03 2014 +0200

    net/ipv4: bind ip_nonlocal_bind to current netns
    
    net.ipv4.ip_nonlocal_bind sysctl was global to all network
    namespaces. This patch allows to set a different value for each
    network namespace.
    
    Signed-off-by: Vincent Bernat <vincent@bernat.im>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index d156b3c5f363..b537bd94906c 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -418,10 +418,6 @@ int inet_release(struct socket *sock)
 }
 EXPORT_SYMBOL(inet_release);
 
-/* It is off by default, see below. */
-int sysctl_ip_nonlocal_bind __read_mostly;
-EXPORT_SYMBOL(sysctl_ip_nonlocal_bind);
-
 int inet_bind(struct socket *sock, struct sockaddr *uaddr, int addr_len)
 {
 	struct sockaddr_in *addr = (struct sockaddr_in *)uaddr;
@@ -461,7 +457,7 @@ int inet_bind(struct socket *sock, struct sockaddr *uaddr, int addr_len)
 	 *  is temporarily down)
 	 */
 	err = -EADDRNOTAVAIL;
-	if (!sysctl_ip_nonlocal_bind &&
+	if (!net->ipv4.sysctl_ip_nonlocal_bind &&
 	    !(inet->freebind || inet->transparent) &&
 	    addr->sin_addr.s_addr != htonl(INADDR_ANY) &&
 	    chk_addr_ret != RTN_LOCAL &&

commit c3caf1192f904de2f1381211f564537235d50de3
Author: Jerry Chu <hkchu@google.com>
Date:   Mon Jul 14 15:54:46 2014 -0700

    net-gre-gro: Fix a bug that breaks the forwarding path
    
    Fixed a bug that was introduced by my GRE-GRO patch
    (bf5a755f5e9186406bbf50f4087100af5bd68e40 net-gre-gro: Add GRE
    support to the GRO stack) that breaks the forwarding path
    because various GSO related fields were not set. The bug will
    cause on the egress path either the GSO code to fail, or a
    GRE-TSO capable (NETIF_F_GSO_GRE) NICs to choke. The following
    fix has been tested for both cases.
    
    Signed-off-by: H.K. Jerry Chu <hkchu@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index d5e6836cf772..d156b3c5f363 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1429,6 +1429,9 @@ static int inet_gro_complete(struct sk_buff *skb, int nhoff)
 	int proto = iph->protocol;
 	int err = -ENOSYS;
 
+	if (skb->encapsulation)
+		skb_set_inner_network_header(skb, nhoff);
+
 	csum_replace2(&iph->check, iph->tot_len, newlen);
 	iph->tot_len = newlen;
 

commit 4749c09c37030ccdc44aecebe0f71b02a377fc14
Author: Tom Herbert <therbert@google.com>
Date:   Wed Jun 4 17:20:23 2014 -0700

    gre: Call gso_make_checksum
    
    Call gso_make_checksum. This should have the benefit of using a
    checksum that may have been previously computed for the packet.
    
    This also adds NETIF_F_GSO_GRE_CSUM to differentiate devices that
    offload GRE GSO with and without the GRE checksum offloaed.
    
    Signed-off-by: Tom Herbert <therbert@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 0070ab87109b..d5e6836cf772 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1254,6 +1254,7 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb,
 		       SKB_GSO_DODGY |
 		       SKB_GSO_TCP_ECN |
 		       SKB_GSO_GRE |
+		       SKB_GSO_GRE_CSUM |
 		       SKB_GSO_IPIP |
 		       SKB_GSO_SIT |
 		       SKB_GSO_TCPV6 |

commit 0f4f4ffa7b7c3d29d0537a126145c9f8d8ed5dbc
Author: Tom Herbert <therbert@google.com>
Date:   Wed Jun 4 17:20:16 2014 -0700

    net: Add GSO support for UDP tunnels with checksum
    
    Added a new netif feature for GSO_UDP_TUNNEL_CSUM. This indicates
    that a device is capable of computing the UDP checksum in the
    encapsulating header of a UDP tunnel.
    
    Signed-off-by: Tom Herbert <therbert@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 0e9bb08a91e4..0070ab87109b 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1258,6 +1258,7 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb,
 		       SKB_GSO_SIT |
 		       SKB_GSO_TCPV6 |
 		       SKB_GSO_UDP_TUNNEL |
+		       SKB_GSO_UDP_TUNNEL_CSUM |
 		       SKB_GSO_MPLS |
 		       0)))
 		goto out;

commit b26ba202e0500eb852e89499ece1b2deaa64c3a7
Author: Tom Herbert <therbert@google.com>
Date:   Fri May 23 08:47:09 2014 -0700

    net: Eliminate no_check from protosw
    
    It doesn't seem like an protocols are setting anything other
    than the default, and allowing to arbitrarily disable checksums
    for a whole protocol seems dangerous. This can be done on a per
    socket basis.
    
    Signed-off-by: Tom Herbert <therbert@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 279132bcadd9..0e9bb08a91e4 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -254,7 +254,6 @@ static int inet_create(struct net *net, struct socket *sock, int protocol,
 	struct inet_sock *inet;
 	struct proto *answer_prot;
 	unsigned char answer_flags;
-	char answer_no_check;
 	int try_loading_module = 0;
 	int err;
 
@@ -312,7 +311,6 @@ static int inet_create(struct net *net, struct socket *sock, int protocol,
 
 	sock->ops = answer->ops;
 	answer_prot = answer->prot;
-	answer_no_check = answer->no_check;
 	answer_flags = answer->flags;
 	rcu_read_unlock();
 
@@ -324,7 +322,6 @@ static int inet_create(struct net *net, struct socket *sock, int protocol,
 		goto out;
 
 	err = 0;
-	sk->sk_no_check = answer_no_check;
 	if (INET_PROTOSW_REUSE & answer_flags)
 		sk->sk_reuse = SK_CAN_REUSE;
 
@@ -1002,7 +999,6 @@ static struct inet_protosw inetsw_array[] =
 		.protocol =   IPPROTO_TCP,
 		.prot =       &tcp_prot,
 		.ops =        &inet_stream_ops,
-		.no_check =   0,
 		.flags =      INET_PROTOSW_PERMANENT |
 			      INET_PROTOSW_ICSK,
 	},
@@ -1012,7 +1008,6 @@ static struct inet_protosw inetsw_array[] =
 		.protocol =   IPPROTO_UDP,
 		.prot =       &udp_prot,
 		.ops =        &inet_dgram_ops,
-		.no_check =   UDP_CSUM_DEFAULT,
 		.flags =      INET_PROTOSW_PERMANENT,
        },
 
@@ -1021,7 +1016,6 @@ static struct inet_protosw inetsw_array[] =
 		.protocol =   IPPROTO_ICMP,
 		.prot =       &ping_prot,
 		.ops =        &inet_dgram_ops,
-		.no_check =   UDP_CSUM_DEFAULT,
 		.flags =      INET_PROTOSW_REUSE,
        },
 
@@ -1030,7 +1024,6 @@ static struct inet_protosw inetsw_array[] =
 	       .protocol =   IPPROTO_IP,	/* wild card */
 	       .prot =       &raw_prot,
 	       .ops =        &inet_sockraw_ops,
-	       .no_check =   UDP_CSUM_DEFAULT,
 	       .flags =      INET_PROTOSW_REUSE,
        }
 };

commit 122ff243f5f104194750ecbc76d5946dd1eec934
Author: WANG Cong <xiyou.wangcong@gmail.com>
Date:   Mon May 12 16:04:53 2014 -0700

    ipv4: make ip_local_reserved_ports per netns
    
    ip_local_port_range is already per netns, so should ip_local_reserved_ports
    be. And since it is none by default we don't actually need it when we don't
    enable CONFIG_SYSCTL.
    
    By the way, rename inet_is_reserved_local_port() to inet_is_local_reserved_port()
    
    Cc: "David S. Miller" <davem@davemloft.net>
    Signed-off-by: Cong Wang <xiyou.wangcong@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 211c0cc6c3d3..279132bcadd9 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1705,13 +1705,9 @@ static int __init inet_init(void)
 
 	BUILD_BUG_ON(sizeof(struct inet_skb_parm) > FIELD_SIZEOF(struct sk_buff, cb));
 
-	sysctl_local_reserved_ports = kzalloc(65536 / 8, GFP_KERNEL);
-	if (!sysctl_local_reserved_ports)
-		goto out;
-
 	rc = proto_register(&tcp_prot, 1);
 	if (rc)
-		goto out_free_reserved_ports;
+		goto out;
 
 	rc = proto_register(&udp_prot, 1);
 	if (rc)
@@ -1821,8 +1817,6 @@ static int __init inet_init(void)
 	proto_unregister(&udp_prot);
 out_unregister_tcp_proto:
 	proto_unregister(&tcp_prot);
-out_free_reserved_ports:
-	kfree(sysctl_local_reserved_ports);
 	goto out;
 }
 

commit 5f013c9bc70214dcacd5fbed5a06c217d6ff9c59
Merge: 51ee42efa082 1a466ae96e9f
Author: David S. Miller <davem@davemloft.net>
Date:   Mon May 12 13:19:14 2014 -0400

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/davem/net
    
    Conflicts:
            drivers/net/ethernet/altera/altera_sgdma.c
            net/netlink/af_netlink.c
            net/sched/cls_api.c
            net/sched/sch_api.c
    
    The netlink conflict dealt with moving to netlink_capable() and
    netlink_ns_capable() in the 'net' tree vs. supporting 'tc' operations
    in non-init namespaces.  These were simple transformations from
    netlink_capable to netlink_ns_capable.
    
    The Altera driver conflict was simply code removal overlapping some
    void pointer cast cleanups in net-next.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit ba6b918ab234186d3aa1663e296586a1b526b77a
Author: Cong Wang <xiyou.wangcong@gmail.com>
Date:   Tue May 6 11:02:50 2014 -0700

    ping: move ping_group_range out of CONFIG_SYSCTL
    
    Similarly, when CONFIG_SYSCTL is not set, ping_group_range should still
    work, just that no one can change it. Therefore we should move it out of
    sysctl_net_ipv4.c. And, it should not share the same seqlock with
    ip_local_port_range.
    
    BTW, rename it to ->ping_group_range instead.
    
    Cc: David S. Miller <davem@davemloft.net>
    Cc: Francois Romieu <romieu@fr.zoreil.com>
    Reported-by: Stefan de Konink <stefan@konink.de>
    Signed-off-by: Cong Wang <xiyou.wangcong@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index cccc8e487c7e..6d6dd345bc4d 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1658,6 +1658,14 @@ static __net_init int inet_init_net(struct net *net)
 	seqlock_init(&net->ipv4.ip_local_ports.lock);
 	net->ipv4.ip_local_ports.range[0] =  32768;
 	net->ipv4.ip_local_ports.range[1] =  61000;
+
+	seqlock_init(&net->ipv4.ping_group_range.lock);
+	/*
+	 * Sane defaults - nobody may create ping sockets.
+	 * Boot scripts should set this to distro-specific group.
+	 */
+	net->ipv4.ping_group_range.range[0] = make_kgid(&init_user_ns, 1);
+	net->ipv4.ping_group_range.range[1] = make_kgid(&init_user_ns, 0);
 	return 0;
 }
 

commit c9d8f1a64225dfcc2f721d73a5984a2444920744
Author: Cong Wang <xiyou.wangcong@gmail.com>
Date:   Tue May 6 11:02:49 2014 -0700

    ipv4: move local_port_range out of CONFIG_SYSCTL
    
    When CONFIG_SYSCTL is not set, ip_local_port_range should still work,
    just that no one can change it. Therefore we should move it out of sysctl_inet.c.
    Also, rename it to ->ip_local_ports instead.
    
    Cc: David S. Miller <davem@davemloft.net>
    Cc: Francois Romieu <romieu@fr.zoreil.com>
    Reported-by: Stefan de Konink <stefan@konink.de>
    Signed-off-by: Cong Wang <xiyou.wangcong@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 8c54870db792..cccc8e487c7e 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1650,6 +1650,31 @@ static int __init init_ipv4_mibs(void)
 	return register_pernet_subsys(&ipv4_mib_ops);
 }
 
+static __net_init int inet_init_net(struct net *net)
+{
+	/*
+	 * Set defaults for local port range
+	 */
+	seqlock_init(&net->ipv4.ip_local_ports.lock);
+	net->ipv4.ip_local_ports.range[0] =  32768;
+	net->ipv4.ip_local_ports.range[1] =  61000;
+	return 0;
+}
+
+static __net_exit void inet_exit_net(struct net *net)
+{
+}
+
+static __net_initdata struct pernet_operations af_inet_ops = {
+	.init = inet_init_net,
+	.exit = inet_exit_net,
+};
+
+static int __init init_inet_pernet_ops(void)
+{
+	return register_pernet_subsys(&af_inet_ops);
+}
+
 static int ipv4_proc_init(void);
 
 /*
@@ -1794,6 +1819,9 @@ static int __init inet_init(void)
 	if (ip_mr_init())
 		pr_crit("%s: Cannot init ipv4 mroute\n", __func__);
 #endif
+
+	if (init_inet_pernet_ops())
+		pr_crit("%s: Cannot init ipv4 inet pernet ops\n", __func__);
 	/*
 	 *	Initialise per-cpu ipv4 mibs
 	 */

commit 698365fa1874aa7635d51667a34a2842228e9837
Author: WANG Cong <xiyou.wangcong@gmail.com>
Date:   Mon May 5 15:55:55 2014 -0700

    net: clean up snmp stats code
    
    commit 8f0ea0fe3a036a47767f9c80e (snmp: reduce percpu needs by 50%)
    reduced snmp array size to 1, so technically it doesn't have to be
    an array any more. What's more, after the following commit:
    
            commit 933393f58fef9963eac61db8093689544e29a600
            Date:   Thu Dec 22 11:58:51 2011 -0600
    
                percpu: Remove irqsafe_cpu_xxx variants
    
                We simply say that regular this_cpu use must be safe regardless of
                preemption and interrupt state.  That has no material change for x86
                and s390 implementations of this_cpu operations.  However, arches that
                do not provide their own implementation for this_cpu operations will
                now get code generated that disables interrupts instead of preemption.
    
    probably no arch wants to have SNMP_ARRAY_SZ == 2. At least after
    almost 3 years, no one complains.
    
    So, just convert the array to a single pointer and remove snmp_mib_init()
    and snmp_mib_free() as well.
    
    Cc: Christoph Lameter <cl@linux.com>
    Cc: Eric Dumazet <eric.dumazet@gmail.com>
    Cc: David S. Miller <davem@davemloft.net>
    Signed-off-by: Cong Wang <xiyou.wangcong@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 8c54870db792..6765d91b8e75 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1476,22 +1476,20 @@ int inet_ctl_sock_create(struct sock **sk, unsigned short family,
 }
 EXPORT_SYMBOL_GPL(inet_ctl_sock_create);
 
-unsigned long snmp_fold_field(void __percpu *mib[], int offt)
+unsigned long snmp_fold_field(void __percpu *mib, int offt)
 {
 	unsigned long res = 0;
-	int i, j;
+	int i;
 
-	for_each_possible_cpu(i) {
-		for (j = 0; j < SNMP_ARRAY_SZ; j++)
-			res += *(((unsigned long *) per_cpu_ptr(mib[j], i)) + offt);
-	}
+	for_each_possible_cpu(i)
+		res += *(((unsigned long *) per_cpu_ptr(mib, i)) + offt);
 	return res;
 }
 EXPORT_SYMBOL_GPL(snmp_fold_field);
 
 #if BITS_PER_LONG==32
 
-u64 snmp_fold_field64(void __percpu *mib[], int offt, size_t syncp_offset)
+u64 snmp_fold_field64(void __percpu *mib, int offt, size_t syncp_offset)
 {
 	u64 res = 0;
 	int cpu;
@@ -1502,7 +1500,7 @@ u64 snmp_fold_field64(void __percpu *mib[], int offt, size_t syncp_offset)
 		u64 v;
 		unsigned int start;
 
-		bhptr = per_cpu_ptr(mib[0], cpu);
+		bhptr = per_cpu_ptr(mib, cpu);
 		syncp = (struct u64_stats_sync *)(bhptr + syncp_offset);
 		do {
 			start = u64_stats_fetch_begin_irq(syncp);
@@ -1516,25 +1514,6 @@ u64 snmp_fold_field64(void __percpu *mib[], int offt, size_t syncp_offset)
 EXPORT_SYMBOL_GPL(snmp_fold_field64);
 #endif
 
-int snmp_mib_init(void __percpu *ptr[2], size_t mibsize, size_t align)
-{
-	BUG_ON(ptr == NULL);
-	ptr[0] = __alloc_percpu(mibsize, align);
-	if (!ptr[0])
-		return -ENOMEM;
-
-#if SNMP_ARRAY_SZ == 2
-	ptr[1] = __alloc_percpu(mibsize, align);
-	if (!ptr[1]) {
-		free_percpu(ptr[0]);
-		ptr[0] = NULL;
-		return -ENOMEM;
-	}
-#endif
-	return 0;
-}
-EXPORT_SYMBOL_GPL(snmp_mib_init);
-
 #ifdef CONFIG_IP_MULTICAST
 static const struct net_protocol igmp_protocol = {
 	.handler =	igmp_rcv,
@@ -1570,40 +1549,30 @@ static __net_init int ipv4_mib_init_net(struct net *net)
 {
 	int i;
 
-	if (snmp_mib_init((void __percpu **)net->mib.tcp_statistics,
-			  sizeof(struct tcp_mib),
-			  __alignof__(struct tcp_mib)) < 0)
+	net->mib.tcp_statistics = alloc_percpu(struct tcp_mib);
+	if (!net->mib.tcp_statistics)
 		goto err_tcp_mib;
-	if (snmp_mib_init((void __percpu **)net->mib.ip_statistics,
-			  sizeof(struct ipstats_mib),
-			  __alignof__(struct ipstats_mib)) < 0)
+	net->mib.ip_statistics = alloc_percpu(struct ipstats_mib);
+	if (!net->mib.ip_statistics)
 		goto err_ip_mib;
 
 	for_each_possible_cpu(i) {
 		struct ipstats_mib *af_inet_stats;
-		af_inet_stats = per_cpu_ptr(net->mib.ip_statistics[0], i);
+		af_inet_stats = per_cpu_ptr(net->mib.ip_statistics, i);
 		u64_stats_init(&af_inet_stats->syncp);
-#if SNMP_ARRAY_SZ == 2
-		af_inet_stats = per_cpu_ptr(net->mib.ip_statistics[1], i);
-		u64_stats_init(&af_inet_stats->syncp);
-#endif
 	}
 
-	if (snmp_mib_init((void __percpu **)net->mib.net_statistics,
-			  sizeof(struct linux_mib),
-			  __alignof__(struct linux_mib)) < 0)
+	net->mib.net_statistics = alloc_percpu(struct linux_mib);
+	if (!net->mib.net_statistics)
 		goto err_net_mib;
-	if (snmp_mib_init((void __percpu **)net->mib.udp_statistics,
-			  sizeof(struct udp_mib),
-			  __alignof__(struct udp_mib)) < 0)
+	net->mib.udp_statistics = alloc_percpu(struct udp_mib);
+	if (!net->mib.udp_statistics)
 		goto err_udp_mib;
-	if (snmp_mib_init((void __percpu **)net->mib.udplite_statistics,
-			  sizeof(struct udp_mib),
-			  __alignof__(struct udp_mib)) < 0)
+	net->mib.udplite_statistics = alloc_percpu(struct udp_mib);
+	if (!net->mib.udplite_statistics)
 		goto err_udplite_mib;
-	if (snmp_mib_init((void __percpu **)net->mib.icmp_statistics,
-			  sizeof(struct icmp_mib),
-			  __alignof__(struct icmp_mib)) < 0)
+	net->mib.icmp_statistics = alloc_percpu(struct icmp_mib);
+	if (!net->mib.icmp_statistics)
 		goto err_icmp_mib;
 	net->mib.icmpmsg_statistics = kzalloc(sizeof(struct icmpmsg_mib),
 					      GFP_KERNEL);
@@ -1614,17 +1583,17 @@ static __net_init int ipv4_mib_init_net(struct net *net)
 	return 0;
 
 err_icmpmsg_mib:
-	snmp_mib_free((void __percpu **)net->mib.icmp_statistics);
+	free_percpu(net->mib.icmp_statistics);
 err_icmp_mib:
-	snmp_mib_free((void __percpu **)net->mib.udplite_statistics);
+	free_percpu(net->mib.udplite_statistics);
 err_udplite_mib:
-	snmp_mib_free((void __percpu **)net->mib.udp_statistics);
+	free_percpu(net->mib.udp_statistics);
 err_udp_mib:
-	snmp_mib_free((void __percpu **)net->mib.net_statistics);
+	free_percpu(net->mib.net_statistics);
 err_net_mib:
-	snmp_mib_free((void __percpu **)net->mib.ip_statistics);
+	free_percpu(net->mib.ip_statistics);
 err_ip_mib:
-	snmp_mib_free((void __percpu **)net->mib.tcp_statistics);
+	free_percpu(net->mib.tcp_statistics);
 err_tcp_mib:
 	return -ENOMEM;
 }
@@ -1632,12 +1601,12 @@ static __net_init int ipv4_mib_init_net(struct net *net)
 static __net_exit void ipv4_mib_exit_net(struct net *net)
 {
 	kfree(net->mib.icmpmsg_statistics);
-	snmp_mib_free((void __percpu **)net->mib.icmp_statistics);
-	snmp_mib_free((void __percpu **)net->mib.udplite_statistics);
-	snmp_mib_free((void __percpu **)net->mib.udp_statistics);
-	snmp_mib_free((void __percpu **)net->mib.net_statistics);
-	snmp_mib_free((void __percpu **)net->mib.ip_statistics);
-	snmp_mib_free((void __percpu **)net->mib.tcp_statistics);
+	free_percpu(net->mib.icmp_statistics);
+	free_percpu(net->mib.udplite_statistics);
+	free_percpu(net->mib.udp_statistics);
+	free_percpu(net->mib.net_statistics);
+	free_percpu(net->mib.ip_statistics);
+	free_percpu(net->mib.tcp_statistics);
 }
 
 static __net_initdata struct pernet_operations ipv4_mib_ops = {

commit 57a7744e09867ebcfa0ccf1d6d529caa7728d552
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Thu Mar 13 21:26:42 2014 -0700

    net: Replace u64_stats_fetch_begin_bh to u64_stats_fetch_begin_irq
    
    Replace the bh safe variant with the hard irq safe variant.
    
    We need a hard irq safe variant to deal with netpoll transmitting
    packets from hard irq context, and we need it in most if not all of
    the places using the bh safe variant.
    
    Except on 32bit uni-processor the code is exactly the same so don't
    bother with a bh variant, just have a hard irq safe variant that
    everyone can use.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 19ab78aca547..8c54870db792 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1505,9 +1505,9 @@ u64 snmp_fold_field64(void __percpu *mib[], int offt, size_t syncp_offset)
 		bhptr = per_cpu_ptr(mib[0], cpu);
 		syncp = (struct u64_stats_sync *)(bhptr + syncp_offset);
 		do {
-			start = u64_stats_fetch_begin_bh(syncp);
+			start = u64_stats_fetch_begin_irq(syncp);
 			v = *(((u64 *) bhptr) + offt);
-		} while (u64_stats_fetch_retry_bh(syncp, start));
+		} while (u64_stats_fetch_retry_irq(syncp, start));
 
 		res += v;
 	}

commit 91a48a2e85a3b70ce10ead34b4ab5347f8d215c9
Author: Hannes Frederic Sowa <hannes@stressinduktion.org>
Date:   Mon Feb 24 00:48:05 2014 +0100

    ipv4: ipv6: better estimate tunnel header cut for correct ufo handling
    
    Currently the UFO fragmentation process does not correctly handle inner
    UDP frames.
    
    (The following tcpdumps are captured on the parent interface with ufo
    disabled while tunnel has ufo enabled, 2000 bytes payload, mtu 1280,
    both sit device):
    
    IPv6:
    16:39:10.031613 IP (tos 0x0, ttl 64, id 3208, offset 0, flags [DF], proto IPv6 (41), length 1300)
        192.168.122.151 > 1.1.1.1: IP6 (hlim 64, next-header Fragment (44) payload length: 1240) 2001::1 > 2001::8: frag (0x00000001:0|1232) 44883 > distinct: UDP, length 2000
    16:39:10.031709 IP (tos 0x0, ttl 64, id 3209, offset 0, flags [DF], proto IPv6 (41), length 844)
        192.168.122.151 > 1.1.1.1: IP6 (hlim 64, next-header Fragment (44) payload length: 784) 2001::1 > 2001::8: frag (0x00000001:0|776) 58979 > 46366: UDP, length 5471
    
    We can see that fragmentation header offset is not correctly updated.
    (fragmentation id handling is corrected by 916e4cf46d0204 ("ipv6: reuse
    ip6_frag_id from ip6_ufo_append_data")).
    
    IPv4:
    16:39:57.737761 IP (tos 0x0, ttl 64, id 3209, offset 0, flags [DF], proto IPIP (4), length 1296)
        192.168.122.151 > 1.1.1.1: IP (tos 0x0, ttl 64, id 57034, offset 0, flags [none], proto UDP (17), length 1276)
        192.168.99.1.35961 > 192.168.99.2.distinct: UDP, length 2000
    16:39:57.738028 IP (tos 0x0, ttl 64, id 3210, offset 0, flags [DF], proto IPIP (4), length 792)
        192.168.122.151 > 1.1.1.1: IP (tos 0x0, ttl 64, id 57035, offset 0, flags [none], proto UDP (17), length 772)
        192.168.99.1.13531 > 192.168.99.2.20653: UDP, length 51109
    
    In this case fragmentation id is incremented and offset is not updated.
    
    First, I aligned inet_gso_segment and ipv6_gso_segment:
    * align naming of flags
    * ipv6_gso_segment: setting skb->encapsulation is unnecessary, as we
      always ensure that the state of this flag is left untouched when
      returning from upper gso segmenation function
    * ipv6_gso_segment: move skb_reset_inner_headers below updating the
      fragmentation header data, we don't care for updating fragmentation
      header data
    * remove currently unneeded comment indicating skb->encapsulation might
      get changed by upper gso_segment callback (gre and udp-tunnel reset
      encapsulation after segmentation on each fragment)
    
    If we encounter an IPIP or SIT gso skb we now check for the protocol ==
    IPPROTO_UDP and that we at least have already traversed another ip(6)
    protocol header.
    
    The reason why we have to special case GSO_IPIP and GSO_SIT is that
    we reset skb->encapsulation to 0 while skb_mac_gso_segment the inner
    protocol of GSO_UDP_TUNNEL or GSO_GRE packets.
    
    Reported-by: Wolfgang Walter <linux@stwm.de>
    Cc: Cong Wang <xiyou.wangcong@gmail.com>
    Cc: Tom Herbert <therbert@google.com>
    Cc: Eric Dumazet <eric.dumazet@gmail.com>
    Signed-off-by: Hannes Frederic Sowa <hannes@stressinduktion.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index ecd2c3f245ce..19ab78aca547 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1296,8 +1296,11 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb,
 
 	segs = ERR_PTR(-EPROTONOSUPPORT);
 
-	/* Note : following gso_segment() might change skb->encapsulation */
-	udpfrag = !skb->encapsulation && proto == IPPROTO_UDP;
+	if (skb->encapsulation &&
+	    skb_shinfo(skb)->gso_type & (SKB_GSO_SIT|SKB_GSO_IPIP))
+		udpfrag = proto == IPPROTO_UDP && encap;
+	else
+		udpfrag = proto == IPPROTO_UDP && !skb->encapsulation;
 
 	ops = rcu_dereference(inet_offloads[proto]);
 	if (likely(ops && ops->callbacks.gso_segment))

commit 8ed1dc44d3e9e8387a104b1ae8f92e9a3fbf1b1e
Author: Hannes Frederic Sowa <hannes@stressinduktion.org>
Date:   Thu Jan 9 10:01:17 2014 +0100

    ipv4: introduce hardened ip_no_pmtu_disc mode
    
    This new ip_no_pmtu_disc mode only allowes fragmentation-needed errors
    to be honored by protocols which do more stringent validation on the
    ICMP's packet payload. This knob is useful for people who e.g. want to
    run an unmodified DNS server in a namespace where they need to use pmtu
    for TCP connections (as they are used for zone transfers or fallback
    for requests) but don't want to use possibly spoofed UDP pmtu information.
    
    Currently the whitelisted protocols are TCP, SCTP and DCCP as they check
    if the returned packet is in the window or if the association is valid.
    
    Cc: Eric Dumazet <eric.dumazet@gmail.com>
    Cc: David Miller <davem@davemloft.net>
    Cc: John Heffner <johnwheffner@gmail.com>
    Suggested-by: Florian Weimer <fweimer@redhat.com>
    Signed-off-by: Hannes Frederic Sowa <hannes@stressinduktion.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 6268a4751e64..ecd2c3f245ce 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1545,6 +1545,7 @@ static const struct net_protocol tcp_protocol = {
 	.err_handler	=	tcp_v4_err,
 	.no_policy	=	1,
 	.netns_ok	=	1,
+	.icmp_strict_tag_validation = 1,
 };
 
 static const struct net_protocol udp_protocol = {

commit bf5a755f5e9186406bbf50f4087100af5bd68e40
Author: Jerry Chu <hkchu@google.com>
Date:   Tue Jan 7 10:23:19 2014 -0800

    net-gre-gro: Add GRE support to the GRO stack
    
    This patch built on top of Commit 299603e8370a93dd5d8e8d800f0dff1ce2c53d36
    ("net-gro: Prepare GRO stack for the upcoming tunneling support") to add
    the support of the standard GRE (RFC1701/RFC2784/RFC2890) to the GRO
    stack. It also serves as an example for supporting other encapsulation
    protocols in the GRO stack in the future.
    
    The patch supports version 0 and all the flags (key, csum, seq#) but
    will flush any pkt with the S (seq#) flag. This is because the S flag
    is not support by GSO, and a GRO pkt may end up in the forwarding path,
    thus requiring GSO support to break it up correctly.
    
    Currently the "packet_offload" structure only contains L3 (ETH_P_IP/
    ETH_P_IPV6) GRO offload support so the encapped pkts are limited to
    IP pkts (i.e., w/o L2 hdr). But support for other protocol type can
    be easily added, so is the support for GRE variations like NVGRE.
    
    The patch also support csum offload. Specifically if the csum flag is on
    and the h/w is capable of checksumming the payload (CHECKSUM_COMPLETE),
    the code will take advantage of the csum computed by the h/w when
    validating the GRE csum.
    
    Note that commit 60769a5dcd8755715c7143b4571d5c44f01796f1 "ipv4: gre:
    add GRO capability" already introduces GRO capability to IPv4 GRE
    tunnels, using the gro_cells infrastructure. But GRO is done after
    GRE hdr has been removed (i.e., decapped). The following patch applies
    GRO when pkts first come in (before hitting the GRE tunnel code). There
    is some performance advantage for applying GRO as early as possible.
    Also this approach is transparent to other subsystem like Open vSwitch
    where GRE decap is handled outside of the IP stack hence making it
    harder for the gro_cells stuff to apply. On the other hand, some NICs
    are still not capable of hashing on the inner hdr of a GRE pkt (RSS).
    In that case the GRO processing of pkts from the same remote host will
    all happen on the same CPU and the performance may be suboptimal.
    
    I'm including some rough preliminary performance numbers below. Note
    that the performance will be highly dependent on traffic load, mix as
    usual. Moreover it also depends on NIC offload features hence the
    following is by no means a comprehesive study. Local testing and tuning
    will be needed to decide the best setting.
    
    All tests spawned 50 copies of netperf TCP_STREAM and ran for 30 secs.
    (super_netperf 50 -H 192.168.1.18 -l 30)
    
    An IP GRE tunnel with only the key flag on (e.g., ip tunnel add gre1
    mode gre local 10.246.17.18 remote 10.246.17.17 ttl 255 key 123)
    is configured.
    
    The GRO support for pkts AFTER decap are controlled through the device
    feature of the GRE device (e.g., ethtool -K gre1 gro on/off).
    
    1.1 ethtool -K gre1 gro off; ethtool -K eth0 gro off
    thruput: 9.16Gbps
    CPU utilization: 19%
    
    1.2 ethtool -K gre1 gro on; ethtool -K eth0 gro off
    thruput: 5.9Gbps
    CPU utilization: 15%
    
    1.3 ethtool -K gre1 gro off; ethtool -K eth0 gro on
    thruput: 9.26Gbps
    CPU utilization: 12-13%
    
    1.4 ethtool -K gre1 gro on; ethtool -K eth0 gro on
    thruput: 9.26Gbps
    CPU utilization: 10%
    
    The following tests were performed on a different NIC that is capable of
    csum offload. I.e., the h/w is capable of computing IP payload csum
    (CHECKSUM_COMPLETE).
    
    2.1 ethtool -K gre1 gro on (hence will use gro_cells)
    
    2.1.1 ethtool -K eth0 gro off; csum offload disabled
    thruput: 8.53Gbps
    CPU utilization: 9%
    
    2.1.2 ethtool -K eth0 gro off; csum offload enabled
    thruput: 8.97Gbps
    CPU utilization: 7-8%
    
    2.1.3 ethtool -K eth0 gro on; csum offload disabled
    thruput: 8.83Gbps
    CPU utilization: 5-6%
    
    2.1.4 ethtool -K eth0 gro on; csum offload enabled
    thruput: 8.98Gbps
    CPU utilization: 5%
    
    2.2 ethtool -K gre1 gro off
    
    2.2.1 ethtool -K eth0 gro off; csum offload disabled
    thruput: 5.93Gbps
    CPU utilization: 9%
    
    2.2.2 ethtool -K eth0 gro off; csum offload enabled
    thruput: 5.62Gbps
    CPU utilization: 8%
    
    2.2.3 ethtool -K eth0 gro on; csum offload disabled
    thruput: 7.69Gbps
    CPU utilization: 8%
    
    2.2.4 ethtool -K eth0 gro on; csum offload enabled
    thruput: 8.96Gbps
    CPU utilization: 5-6%
    
    Signed-off-by: H.K. Jerry Chu <hkchu@google.com>
    Reviewed-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index b8bc1a3d5cf1..6268a4751e64 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1391,9 +1391,15 @@ static struct sk_buff **inet_gro_receive(struct sk_buff **head,
 		NAPI_GRO_CB(p)->flush |=
 			(iph->ttl ^ iph2->ttl) |
 			(iph->tos ^ iph2->tos) |
-			(__force int)((iph->frag_off ^ iph2->frag_off) & htons(IP_DF)) |
-			((u16)(ntohs(iph2->id) + NAPI_GRO_CB(p)->count) ^ id);
+			((iph->frag_off ^ iph2->frag_off) & htons(IP_DF));
 
+		/* Save the IP ID check to be included later when we get to
+		 * the transport layer so only the inner most IP ID is checked.
+		 * This is because some GSO/TSO implementations do not
+		 * correctly increment the IP ID for the outer hdrs.
+		 */
+		NAPI_GRO_CB(p)->flush_id =
+			    ((u16)(ntohs(iph2->id) + NAPI_GRO_CB(p)->count) ^ id);
 		NAPI_GRO_CB(p)->flush |= flush;
 	}
 

commit 1669cb9855050fe9d2a13391846f9aceccf42559
Merge: cb4eae3d525a b3c6efbc36e2
Author: David S. Miller <davem@davemloft.net>
Date:   Thu Dec 19 18:37:49 2013 -0500

    Merge branch 'master' of git://git.kernel.org/pub/scm/linux/kernel/git/klassert/ipsec-next
    
    Steffen Klassert says:
    
    ====================
    pull request (net-next): ipsec-next 2013-12-19
    
    1) Use the user supplied policy index instead of a generated one
       if present. From Fan Du.
    
    2) Make xfrm migration namespace aware. From Fan Du.
    
    3) Make the xfrm state and policy locks namespace aware. From Fan Du.
    
    4) Remove ancient sleeping when the SA is in acquire state,
       we now queue packets to the policy instead. This replaces the
       sleeping code.
    
    5) Remove FLOWI_FLAG_CAN_SLEEP. This was used to notify xfrm about the
       posibility to sleep. The sleeping code is gone, so remove it.
    
    6) Check user specified spi for IPComp. Thr spi for IPcomp is only
       16 bit wide, so check for a valid value. From Fan Du.
    
    7) Export verify_userspi_info to check for valid user supplied spi ranges
       with pfkey and netlink. From Fan Du.
    
    8) RFC3173 states that if the total size of a compressed payload and the IPComp
       header is not smaller than the size of the original payload, the IP datagram
       must be sent in the original non-compressed form. These packets are dropped
       by the inbound policy check because they are not transformed. Document the need
       to set 'level use' for IPcomp to receive such packets anyway. From Fan Du.
    
    Please pull or let me know if there are problems.
    ====================
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 974eda11c54290a1be8f8b155edae7d791e5ce57
Author: Hannes Frederic Sowa <hannes@stressinduktion.org>
Date:   Sat Dec 14 05:13:38 2013 +0100

    inet: make no_pmtu_disc per namespace and kill ipv4_config
    
    The other field in ipv4_config, log_martians, was converted to a
    per-interface setting, so we can just remove the whole structure.
    
    Signed-off-by: Hannes Frederic Sowa <hannes@stressinduktion.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index ef4f9df6d698..6b1193e63911 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -126,9 +126,6 @@
 static struct list_head inetsw[SOCK_MAX];
 static DEFINE_SPINLOCK(inetsw_lock);
 
-struct ipv4_config ipv4_config;
-EXPORT_SYMBOL(ipv4_config);
-
 /* New destruction routine */
 
 void inet_sock_destruct(struct sock *sk)
@@ -342,7 +339,7 @@ static int inet_create(struct net *net, struct socket *sock, int protocol,
 			inet->hdrincl = 1;
 	}
 
-	if (ipv4_config.no_pmtu_disc)
+	if (net->ipv4.sysctl_ip_no_pmtu_disc)
 		inet->pmtudisc = IP_PMTUDISC_DONT;
 	else
 		inet->pmtudisc = IP_PMTUDISC_WANT;

commit 299603e8370a93dd5d8e8d800f0dff1ce2c53d36
Author: Jerry Chu <hkchu@google.com>
Date:   Wed Dec 11 20:53:45 2013 -0800

    net-gro: Prepare GRO stack for the upcoming tunneling support
    
    This patch modifies the GRO stack to avoid the use of "network_header"
    and associated macros like ip_hdr() and ipv6_hdr() in order to allow
    an arbitary number of IP hdrs (v4 or v6) to be used in the
    encapsulation chain. This lays the foundation for various IP
    tunneling support (IP-in-IP, GRE, VXLAN, SIT,...) to be added later.
    
    With this patch, the GRO stack traversing now is mostly based on
    skb_gro_offset rather than special hdr offsets saved in skb (e.g.,
    skb->network_header). As a result all but the top layer (i.e., the
    the transport layer) must have hdrs of the same length in order for
    a pkt to be considered for aggregation. Therefore when adding a new
    encap layer (e.g., for tunneling), one must check and skip flows
    (e.g., by setting NAPI_GRO_CB(p)->same_flow to 0) that have a
    different hdr length.
    
    Note that unlike the network header, the transport header can and
    will continue to be set by the GRO code since there will be at
    most one "transport layer" in the encap chain.
    
    Signed-off-by: H.K. Jerry Chu <hkchu@google.com>
    Suggested-by: Eric Dumazet <edumazet@google.com>
    Reviewed-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 70011e029ac1..ef4f9df6d698 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1377,8 +1377,12 @@ static struct sk_buff **inet_gro_receive(struct sk_buff **head,
 		if (!NAPI_GRO_CB(p)->same_flow)
 			continue;
 
-		iph2 = ip_hdr(p);
-
+		iph2 = (struct iphdr *)(p->data + off);
+		/* The above works because, with the exception of the top
+		 * (inner most) layer, we only aggregate pkts with the same
+		 * hdr length so all the hdrs we'll need to verify will start
+		 * at the same offset.
+		 */
 		if ((iph->protocol ^ iph2->protocol) |
 		    ((__force u32)iph->saddr ^ (__force u32)iph2->saddr) |
 		    ((__force u32)iph->daddr ^ (__force u32)iph2->daddr)) {
@@ -1397,6 +1401,11 @@ static struct sk_buff **inet_gro_receive(struct sk_buff **head,
 	}
 
 	NAPI_GRO_CB(skb)->flush |= flush;
+	skb_set_network_header(skb, off);
+	/* The above will be needed by the transport layer if there is one
+	 * immediately following this IP hdr.
+	 */
+
 	skb_gro_pull(skb, sizeof(*iph));
 	skb_set_transport_header(skb, skb_gro_offset(skb));
 
@@ -1411,10 +1420,10 @@ static struct sk_buff **inet_gro_receive(struct sk_buff **head,
 	return pp;
 }
 
-static int inet_gro_complete(struct sk_buff *skb)
+static int inet_gro_complete(struct sk_buff *skb, int nhoff)
 {
-	__be16 newlen = htons(skb->len - skb_network_offset(skb));
-	struct iphdr *iph = ip_hdr(skb);
+	__be16 newlen = htons(skb->len - nhoff);
+	struct iphdr *iph = (struct iphdr *)(skb->data + nhoff);
 	const struct net_offload *ops;
 	int proto = iph->protocol;
 	int err = -ENOSYS;
@@ -1427,7 +1436,11 @@ static int inet_gro_complete(struct sk_buff *skb)
 	if (WARN_ON(!ops || !ops->callbacks.gro_complete))
 		goto out_unlock;
 
-	err = ops->callbacks.gro_complete(skb);
+	/* Only need to add sizeof(*iph) to get to the next hdr below
+	 * because any hdr with option will have been flushed in
+	 * inet_gro_receive().
+	 */
+	err = ops->callbacks.gro_complete(skb, nhoff + sizeof(*iph));
 
 out_unlock:
 	rcu_read_unlock();

commit 0e0d44ab4275549998567cd4700b43f7496eb62b
Author: Steffen Klassert <steffen.klassert@secunet.com>
Date:   Wed Aug 28 08:04:14 2013 +0200

    net: Remove FLOWI_FLAG_CAN_SLEEP
    
    FLOWI_FLAG_CAN_SLEEP was used to notify xfrm about the posibility
    to sleep until the needed states are resolved. This code is gone,
    so FLOWI_FLAG_CAN_SLEEP is not needed anymore.
    
    Signed-off-by: Steffen Klassert <steffen.klassert@secunet.com>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 70011e029ac1..4f6d50bda093 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1133,7 +1133,7 @@ static int inet_sk_reselect_saddr(struct sock *sk)
 	fl4 = &inet->cork.fl.u.ip4;
 	rt = ip_route_connect(fl4, daddr, 0, RT_CONN_FLAGS(sk),
 			      sk->sk_bound_dev_if, sk->sk_protocol,
-			      inet->inet_sport, inet->inet_dport, sk, false);
+			      inet->inet_sport, inet->inet_dport, sk);
 	if (IS_ERR(rt))
 		return PTR_ERR(rt);
 

commit 5e30025a319910695f5010dc0fb53a23299da14d
Merge: 7971e23a66c9 90d3839b90fe
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Nov 14 16:30:30 2013 +0900

    Merge branch 'core-locking-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull core locking changes from Ingo Molnar:
     "The biggest changes:
    
       - add lockdep support for seqcount/seqlocks structures, this
         unearthed both bugs and required extra annotation.
    
       - move the various kernel locking primitives to the new
         kernel/locking/ directory"
    
    * 'core-locking-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (21 commits)
      block: Use u64_stats_init() to initialize seqcounts
      locking/lockdep: Mark __lockdep_count_forward_deps() as static
      lockdep/proc: Fix lock-time avg computation
      locking/doc: Update references to kernel/mutex.c
      ipv6: Fix possible ipv6 seqlock deadlock
      cpuset: Fix potential deadlock w/ set_mems_allowed
      seqcount: Add lockdep functionality to seqcount/seqlock structures
      net: Explicitly initialize u64_stats_sync structures for lockdep
      locking: Move the percpu-rwsem code to kernel/locking/
      locking: Move the lglocks code to kernel/locking/
      locking: Move the rwsem code to kernel/locking/
      locking: Move the rtmutex code to kernel/locking/
      locking: Move the semaphore core to kernel/locking/
      locking: Move the spinlock code to kernel/locking/
      locking: Move the lockdep code to kernel/locking/
      locking: Move the mutex code to kernel/locking/
      hung_task debugging: Add tracepoint to report the hang
      x86/locking/kconfig: Update paravirt spinlock Kconfig description
      lockstat: Report avg wait and hold times
      lockdep, x86/alternatives: Drop ancient lockdep fixup message
      ...

commit dcd607718385d02ce3741de225927a57f528f93b
Author: Eric Dumazet <edumazet@google.com>
Date:   Thu Nov 7 18:32:06 2013 -0800

    inet: fix a UFO regression
    
    While testing virtio_net and skb_segment() changes, Hannes reported
    that UFO was sending wrong frames.
    
    It appears this was introduced by a recent commit :
    8c3a897bfab1 ("inet: restore gso for vxlan")
    
    The old condition to perform IP frag was :
    
    tunnel = !!skb->encapsulation;
    ...
            if (!tunnel && proto == IPPROTO_UDP) {
    
    So the new one should be :
    
    udpfrag = !skb->encapsulation && proto == IPPROTO_UDP;
    ...
            if (udpfrag) {
    
    Initialization of udpfrag must be done before call
    to ops->callbacks.gso_segment(skb, features), as
    skb_udp_tunnel_segment() clears skb->encapsulation
    
    (We want udpfrag to be true for UFO, false for VXLAN)
    
    With help from Alexei Starovoitov
    
    Reported-by: Hannes Frederic Sowa <hannes@stressinduktion.org>
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Cc: Alexei Starovoitov <ast@plumgrid.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 09d78d4a3cff..68af9aac91d0 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1299,6 +1299,9 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb,
 
 	segs = ERR_PTR(-EPROTONOSUPPORT);
 
+	/* Note : following gso_segment() might change skb->encapsulation */
+	udpfrag = !skb->encapsulation && proto == IPPROTO_UDP;
+
 	ops = rcu_dereference(inet_offloads[proto]);
 	if (likely(ops && ops->callbacks.gso_segment))
 		segs = ops->callbacks.gso_segment(skb, features);
@@ -1306,7 +1309,6 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb,
 	if (IS_ERR_OR_NULL(segs))
 		goto out;
 
-	udpfrag = !!skb->encapsulation && proto == IPPROTO_UDP;
 	skb = segs;
 	do {
 		iph = (struct iphdr *)(skb_mac_header(skb) + nhoff);

commit 827da44c61419f29ae3be198c342e2147f1a10cb
Author: John Stultz <john.stultz@linaro.org>
Date:   Mon Oct 7 15:51:58 2013 -0700

    net: Explicitly initialize u64_stats_sync structures for lockdep
    
    In order to enable lockdep on seqcount/seqlock structures, we
    must explicitly initialize any locks.
    
    The u64_stats_sync structure, uses a seqcount, and thus we need
    to introduce a u64_stats_init() function and use it to initialize
    the structure.
    
    This unfortunately adds a lot of fairly trivial initialization code
    to a number of drivers. But the benefit of ensuring correctness makes
    this worth while.
    
    Because these changes are required for lockdep to be enabled, and the
    changes are quite trivial, I've not yet split this patch out into 30-some
    separate patches, as I figured it would be better to get the various
    maintainers thoughts on how to best merge this change along with
    the seqcount lockdep enablement.
    
    Feedback would be appreciated!
    
    Signed-off-by: John Stultz <john.stultz@linaro.org>
    Acked-by: Julian Anastasov <ja@ssi.bg>
    Signed-off-by: Peter Zijlstra <peterz@infradead.org>
    Cc: Alexey Kuznetsov <kuznet@ms2.inr.ac.ru>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Eric Dumazet <eric.dumazet@gmail.com>
    Cc: Hideaki YOSHIFUJI <yoshfuji@linux-ipv6.org>
    Cc: James Morris <jmorris@namei.org>
    Cc: Jesse Gross <jesse@nicira.com>
    Cc: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
    Cc: "Michael S. Tsirkin" <mst@redhat.com>
    Cc: Mirko Lindner <mlindner@marvell.com>
    Cc: Patrick McHardy <kaber@trash.net>
    Cc: Roger Luethi <rl@hellgate.ch>
    Cc: Rusty Russell <rusty@rustcorp.com.au>
    Cc: Simon Horman <horms@verge.net.au>
    Cc: Stephen Hemminger <stephen@networkplumber.org>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Thomas Petazzoni <thomas.petazzoni@free-electrons.com>
    Cc: Wensong Zhang <wensong@linux-vs.org>
    Cc: netdev@vger.kernel.org
    Link: http://lkml.kernel.org/r/1381186321-4906-2-git-send-email-john.stultz@linaro.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index cfeb85cff4f0..5f4617e377b8 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1518,6 +1518,7 @@ int snmp_mib_init(void __percpu *ptr[2], size_t mibsize, size_t align)
 	ptr[0] = __alloc_percpu(mibsize, align);
 	if (!ptr[0])
 		return -ENOMEM;
+
 #if SNMP_ARRAY_SZ == 2
 	ptr[1] = __alloc_percpu(mibsize, align);
 	if (!ptr[1]) {
@@ -1561,6 +1562,8 @@ static const struct net_protocol icmp_protocol = {
 
 static __net_init int ipv4_mib_init_net(struct net *net)
 {
+	int i;
+
 	if (snmp_mib_init((void __percpu **)net->mib.tcp_statistics,
 			  sizeof(struct tcp_mib),
 			  __alignof__(struct tcp_mib)) < 0)
@@ -1569,6 +1572,17 @@ static __net_init int ipv4_mib_init_net(struct net *net)
 			  sizeof(struct ipstats_mib),
 			  __alignof__(struct ipstats_mib)) < 0)
 		goto err_ip_mib;
+
+	for_each_possible_cpu(i) {
+		struct ipstats_mib *af_inet_stats;
+		af_inet_stats = per_cpu_ptr(net->mib.ip_statistics[0], i);
+		u64_stats_init(&af_inet_stats->syncp);
+#if SNMP_ARRAY_SZ == 2
+		af_inet_stats = per_cpu_ptr(net->mib.ip_statistics[1], i);
+		u64_stats_init(&af_inet_stats->syncp);
+#endif
+	}
+
 	if (snmp_mib_init((void __percpu **)net->mib.net_statistics,
 			  sizeof(struct linux_mib),
 			  __alignof__(struct linux_mib)) < 0)

commit 8c3a897bfab10f68f90252440bb29e6749a7312a
Author: Eric Dumazet <edumazet@google.com>
Date:   Sun Oct 27 18:18:16 2013 -0700

    inet: restore gso for vxlan
    
    Alexei reported a performance regression on vxlan, caused
    by commit 3347c9602955 "ipv4: gso: make inet_gso_segment() stackable"
    
    GSO vxlan packets were not properly segmented, adding IP fragments
    while they were not expected.
    
    Rename 'bool tunnel' to 'bool encap', and add a new boolean
    to express the fact that UDP should be fragmented.
    This fragmentation is triggered by skb->encapsulation being set.
    
    Remove a "skb->encapsulation = 1" added in above commit,
    as its not needed, as frags inherit skb->frag from original
    GSO skb.
    
    Reported-by: Alexei Starovoitov <ast@plumgrid.com>
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Tested-by: Alexei Starovoitov <ast@plumgrid.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index f4a159e705c0..09d78d4a3cff 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1251,8 +1251,8 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb,
 	struct sk_buff *segs = ERR_PTR(-EINVAL);
 	const struct net_offload *ops;
 	unsigned int offset = 0;
+	bool udpfrag, encap;
 	struct iphdr *iph;
-	bool tunnel;
 	int proto;
 	int nhoff;
 	int ihl;
@@ -1290,8 +1290,8 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb,
 		goto out;
 	__skb_pull(skb, ihl);
 
-	tunnel = SKB_GSO_CB(skb)->encap_level > 0;
-	if (tunnel)
+	encap = SKB_GSO_CB(skb)->encap_level > 0;
+	if (encap)
 		features = skb->dev->hw_enc_features & netif_skb_features(skb);
 	SKB_GSO_CB(skb)->encap_level += ihl;
 
@@ -1306,24 +1306,23 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb,
 	if (IS_ERR_OR_NULL(segs))
 		goto out;
 
+	udpfrag = !!skb->encapsulation && proto == IPPROTO_UDP;
 	skb = segs;
 	do {
 		iph = (struct iphdr *)(skb_mac_header(skb) + nhoff);
-		if (!tunnel && proto == IPPROTO_UDP) {
+		if (udpfrag) {
 			iph->id = htons(id);
 			iph->frag_off = htons(offset >> 3);
 			if (skb->next != NULL)
 				iph->frag_off |= htons(IP_MF);
 			offset += skb->len - nhoff - ihl;
-		} else  {
+		} else {
 			iph->id = htons(id++);
 		}
 		iph->tot_len = htons(skb->len - nhoff);
 		ip_send_check(iph);
-		if (tunnel) {
+		if (encap)
 			skb_reset_inner_headers(skb);
-			skb->encapsulation = 1;
-		}
 		skb->network_header = (u8 *)iph - skb->head;
 	} while ((skb = skb->next));
 

commit 61c1db7fae21ed33c614356a43bf6580c5e53118
Author: Eric Dumazet <edumazet@google.com>
Date:   Sun Oct 20 20:47:30 2013 -0700

    ipv6: sit: add GSO/TSO support
    
    Now ipv6_gso_segment() is stackable, its relatively easy to
    implement GSO/TSO support for SIT tunnels
    
    Performance results, when segmentation is done after tunnel
    device (as no NIC is yet enabled for TSO SIT support) :
    
    Before patch :
    
    lpq84:~# ./netperf -H 2002:af6:1153:: -Cc
    MIGRATED TCP STREAM TEST from ::0 (::) port 0 AF_INET6 to 2002:af6:1153:: () port 0 AF_INET6
    Recv   Send    Send                          Utilization       Service Demand
    Socket Socket  Message  Elapsed              Send     Recv     Send    Recv
    Size   Size    Size     Time     Throughput  local    remote   local   remote
    bytes  bytes   bytes    secs.    10^6bits/s  % S      % S      us/KB   us/KB
    
     87380  16384  16384    10.00      3168.31   4.81     4.64     2.988   2.877
    
    After patch :
    
    lpq84:~# ./netperf -H 2002:af6:1153:: -Cc
    MIGRATED TCP STREAM TEST from ::0 (::) port 0 AF_INET6 to 2002:af6:1153:: () port 0 AF_INET6
    Recv   Send    Send                          Utilization       Service Demand
    Socket Socket  Message  Elapsed              Send     Recv     Send    Recv
    Size   Size    Size     Time     Throughput  local    remote   local   remote
    bytes  bytes   bytes    secs.    10^6bits/s  % S      % S      us/KB   us/KB
    
     87380  16384  16384    10.00      5525.00   7.76     5.17     2.763   1.840
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 24a53fc275b0..f4a159e705c0 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1265,6 +1265,7 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb,
 		       SKB_GSO_TCP_ECN |
 		       SKB_GSO_GRE |
 		       SKB_GSO_IPIP |
+		       SKB_GSO_SIT |
 		       SKB_GSO_TCPV6 |
 		       SKB_GSO_UDP_TUNNEL |
 		       SKB_GSO_MPLS |

commit a4fe34bf902b8f709c635ab37f1f39de0b86cff2
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Sat Oct 19 16:25:36 2013 -0700

    tcp_memcontrol: Remove the per netns control.
    
    The code that is implemented is per memory cgroup not per netns, and
    having per netns bits is just confusing.  Remove the per netns bits to
    make it easier to see what is really going on.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 9433a6186f54..24a53fc275b0 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1697,8 +1697,6 @@ static int __init inet_init(void)
 	ip_static_sysctl_init();
 #endif
 
-	tcp_prot.sysctl_mem = init_net.ipv4.sysctl_tcp_mem;
-
 	/*
 	 *	Add all the base protocols.
 	 */

commit 1bbdceef1e535add893bf71d7b7ab102e4eb69eb
Author: Hannes Frederic Sowa <hannes@stressinduktion.org>
Date:   Sat Oct 19 21:48:57 2013 +0200

    inet: convert inet_ehash_secret and ipv6_hash_secret to net_get_random_once
    
    Initialize the ehash and ipv6_hash_secrets with net_get_random_once.
    
    Each compilation unit gets its own secret now:
      ipv4/inet_hashtables.o
      ipv4/udp.o
      ipv6/inet6_hashtables.o
      ipv6/udp.o
      rds/connection.o
    
    The functions still get inlined into the hashing functions. In the fast
    path we have at most two (needed in ipv6) if (unlikely(...)).
    
    Cc: Eric Dumazet <edumazet@google.com>
    Cc: "David S. Miller" <davem@davemloft.net>
    Signed-off-by: Hannes Frederic Sowa <hannes@stressinduktion.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 4049906010f7..9433a6186f54 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -245,29 +245,6 @@ int inet_listen(struct socket *sock, int backlog)
 }
 EXPORT_SYMBOL(inet_listen);
 
-u32 inet_ehash_secret __read_mostly;
-EXPORT_SYMBOL(inet_ehash_secret);
-
-u32 ipv6_hash_secret __read_mostly;
-EXPORT_SYMBOL(ipv6_hash_secret);
-
-/*
- * inet_ehash_secret must be set exactly once, and to a non nul value
- * ipv6_hash_secret must be set exactly once.
- */
-void build_ehash_secret(void)
-{
-	u32 rnd;
-
-	do {
-		get_random_bytes(&rnd, sizeof(rnd));
-	} while (rnd == 0);
-
-	if (cmpxchg(&inet_ehash_secret, 0, rnd) == 0)
-		get_random_bytes(&ipv6_hash_secret, sizeof(ipv6_hash_secret));
-}
-EXPORT_SYMBOL(build_ehash_secret);
-
 /*
  *	Create an inet socket.
  */
@@ -284,10 +261,6 @@ static int inet_create(struct net *net, struct socket *sock, int protocol,
 	int try_loading_module = 0;
 	int err;
 
-	if (unlikely(!inet_ehash_secret))
-		if (sock->type != SOCK_RAW && sock->type != SOCK_DGRAM)
-			build_ehash_secret();
-
 	sock->state = SS_UNCONNECTED;
 
 	/* Look for the requested type/protocol pair. */

commit cb32f511a70be8967ac9025cf49c44324ced9a39
Author: Eric Dumazet <edumazet@google.com>
Date:   Sat Oct 19 11:42:57 2013 -0700

    ipip: add GSO/TSO support
    
    Now inet_gso_segment() is stackable, its relatively easy to
    implement GSO/TSO support for IPIP
    
    Performance results, when segmentation is done after tunnel
    device (as no NIC is yet enabled for TSO IPIP support) :
    
    Before patch :
    
    lpq83:~# ./netperf -H 7.7.9.84 -Cc
    MIGRATED TCP STREAM TEST from 0.0.0.0 (0.0.0.0) port 0 AF_INET to 7.7.9.84 () port 0 AF_INET
    Recv   Send    Send                          Utilization       Service Demand
    Socket Socket  Message  Elapsed              Send     Recv     Send    Recv
    Size   Size    Size     Time     Throughput  local    remote   local   remote
    bytes  bytes   bytes    secs.    10^6bits/s  % S      % S      us/KB   us/KB
    
     87380  16384  16384    10.00      3357.88   5.09     3.70     2.983   2.167
    
    After patch :
    
    lpq83:~# ./netperf -H 7.7.9.84 -Cc
    MIGRATED TCP STREAM TEST from 0.0.0.0 (0.0.0.0) port 0 AF_INET to 7.7.9.84 () port 0 AF_INET
    Recv   Send    Send                          Utilization       Service Demand
    Socket Socket  Message  Elapsed              Send     Recv     Send    Recv
    Size   Size    Size     Time     Throughput  local    remote   local   remote
    bytes  bytes   bytes    secs.    10^6bits/s  % S      % S      us/KB   us/KB
    
     87380  16384  16384    10.00      7710.19   4.52     6.62     1.152   1.687
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 5783ab5b5ef8..4049906010f7 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1291,6 +1291,7 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb,
 		       SKB_GSO_DODGY |
 		       SKB_GSO_TCP_ECN |
 		       SKB_GSO_GRE |
+		       SKB_GSO_IPIP |
 		       SKB_GSO_TCPV6 |
 		       SKB_GSO_UDP_TUNNEL |
 		       SKB_GSO_MPLS |
@@ -1656,6 +1657,13 @@ static struct packet_offload ip_packet_offload __read_mostly = {
 	},
 };
 
+static const struct net_offload ipip_offload = {
+	.callbacks = {
+		.gso_send_check = inet_gso_send_check,
+		.gso_segment	= inet_gso_segment,
+	},
+};
+
 static int __init ipv4_offload_init(void)
 {
 	/*
@@ -1667,6 +1675,7 @@ static int __init ipv4_offload_init(void)
 		pr_crit("%s: Cannot add TCP protocol offload\n", __func__);
 
 	dev_add_offload(&ip_packet_offload);
+	inet_add_offload(&ipip_offload, IPPROTO_IPIP);
 	return 0;
 }
 

commit 3347c960295583eee3fd58e5c539fb1972fbc005
Author: Eric Dumazet <edumazet@google.com>
Date:   Sat Oct 19 11:42:56 2013 -0700

    ipv4: gso: make inet_gso_segment() stackable
    
    In order to support GSO on IPIP, we need to make
    inet_gso_segment() stackable.
    
    It should not assume network header starts right after mac
    header.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 4f8cd4fc451d..5783ab5b5ef8 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1273,16 +1273,17 @@ static int inet_gso_send_check(struct sk_buff *skb)
 }
 
 static struct sk_buff *inet_gso_segment(struct sk_buff *skb,
-	netdev_features_t features)
+					netdev_features_t features)
 {
 	struct sk_buff *segs = ERR_PTR(-EINVAL);
 	const struct net_offload *ops;
+	unsigned int offset = 0;
 	struct iphdr *iph;
+	bool tunnel;
 	int proto;
+	int nhoff;
 	int ihl;
 	int id;
-	unsigned int offset = 0;
-	bool tunnel;
 
 	if (unlikely(skb_shinfo(skb)->gso_type &
 		     ~(SKB_GSO_TCPV4 |
@@ -1296,6 +1297,8 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb,
 		       0)))
 		goto out;
 
+	skb_reset_network_header(skb);
+	nhoff = skb_network_header(skb) - skb_mac_header(skb);
 	if (unlikely(!pskb_may_pull(skb, sizeof(*iph))))
 		goto out;
 
@@ -1312,7 +1315,10 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb,
 		goto out;
 	__skb_pull(skb, ihl);
 
-	tunnel = !!skb->encapsulation;
+	tunnel = SKB_GSO_CB(skb)->encap_level > 0;
+	if (tunnel)
+		features = skb->dev->hw_enc_features & netif_skb_features(skb);
+	SKB_GSO_CB(skb)->encap_level += ihl;
 
 	skb_reset_transport_header(skb);
 
@@ -1327,18 +1333,23 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb,
 
 	skb = segs;
 	do {
-		iph = ip_hdr(skb);
+		iph = (struct iphdr *)(skb_mac_header(skb) + nhoff);
 		if (!tunnel && proto == IPPROTO_UDP) {
 			iph->id = htons(id);
 			iph->frag_off = htons(offset >> 3);
 			if (skb->next != NULL)
 				iph->frag_off |= htons(IP_MF);
-			offset += (skb->len - skb->mac_len - iph->ihl * 4);
+			offset += skb->len - nhoff - ihl;
 		} else  {
 			iph->id = htons(id++);
 		}
-		iph->tot_len = htons(skb->len - skb->mac_len);
+		iph->tot_len = htons(skb->len - nhoff);
 		ip_send_check(iph);
+		if (tunnel) {
+			skb_reset_inner_headers(skb);
+			skb->encapsulation = 1;
+		}
+		skb->network_header = (u8 *)iph - skb->head;
 	} while ((skb = skb->next));
 
 out:

commit 47d27aad44169372f358cda88a223883f6760fa5
Author: Eric Dumazet <edumazet@google.com>
Date:   Fri Oct 18 13:13:27 2013 -0700

    ipv4: gso: send_check() & segment() cleanups
    
    inet_gso_segment() and inet_gso_send_check() are called by
    skb_mac_gso_segment() under rcu lock, no need to use
    rcu_read_lock() / rcu_read_unlock()
    
    Avoid calling ip_hdr() twice per function.
    
    We can use ip_send_check() helper.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 35913fb77dc8..4f8cd4fc451d 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1254,20 +1254,19 @@ static int inet_gso_send_check(struct sk_buff *skb)
 	if (ihl < sizeof(*iph))
 		goto out;
 
+	proto = iph->protocol;
+
+	/* Warning: after this point, iph might be no longer valid */
 	if (unlikely(!pskb_may_pull(skb, ihl)))
 		goto out;
-
 	__skb_pull(skb, ihl);
+
 	skb_reset_transport_header(skb);
-	iph = ip_hdr(skb);
-	proto = iph->protocol;
 	err = -EPROTONOSUPPORT;
 
-	rcu_read_lock();
 	ops = rcu_dereference(inet_offloads[proto]);
 	if (likely(ops && ops->callbacks.gso_send_check))
 		err = ops->callbacks.gso_send_check(skb);
-	rcu_read_unlock();
 
 out:
 	return err;
@@ -1305,23 +1304,23 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb,
 	if (ihl < sizeof(*iph))
 		goto out;
 
+	id = ntohs(iph->id);
+	proto = iph->protocol;
+
+	/* Warning: after this point, iph might be no longer valid */
 	if (unlikely(!pskb_may_pull(skb, ihl)))
 		goto out;
+	__skb_pull(skb, ihl);
 
 	tunnel = !!skb->encapsulation;
 
-	__skb_pull(skb, ihl);
 	skb_reset_transport_header(skb);
-	iph = ip_hdr(skb);
-	id = ntohs(iph->id);
-	proto = iph->protocol;
+
 	segs = ERR_PTR(-EPROTONOSUPPORT);
 
-	rcu_read_lock();
 	ops = rcu_dereference(inet_offloads[proto]);
 	if (likely(ops && ops->callbacks.gso_segment))
 		segs = ops->callbacks.gso_segment(skb, features);
-	rcu_read_unlock();
 
 	if (IS_ERR_OR_NULL(segs))
 		goto out;
@@ -1339,8 +1338,7 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb,
 			iph->id = htons(id++);
 		}
 		iph->tot_len = htons(skb->len - skb->mac_len);
-		iph->check = 0;
-		iph->check = ip_fast_csum(skb_network_header(skb), iph->ihl);
+		ip_send_check(iph);
 	} while ((skb = skb->next));
 
 out:

commit 421b3885bf6d56391297844f43fb7154a6396e12
Author: Shawn Bohrer <sbohrer@rgmadvisors.com>
Date:   Mon Oct 7 11:01:39 2013 -0500

    udp: ipv4: Add udp early demux
    
    The removal of the routing cache introduced a performance regression for
    some UDP workloads since a dst lookup must be done for each packet.
    This change caches the dst per socket in a similar manner to what we do
    for TCP by implementing early_demux.
    
    For UDP multicast we can only cache the dst if there is only one
    receiving socket on the host.  Since caching only works when there is
    one receiving socket we do the multicast socket lookup using RCU.
    
    For UDP unicast we only demux sockets with an exact match in order to
    not break forwarding setups.  Additionally since the hash chains may be
    long we only check the first socket to see if it is a match and not
    waste extra time searching the whole chain when we might not find an
    exact match.
    
    Benchmark results from a netperf UDP_RR test:
    Before 87961.22 transactions/s
    After  89789.68 transactions/s
    
    Benchmark results from a fio 1 byte UDP multicast pingpong test
    (Multicast one way unicast response):
    Before 12.97us RTT
    After  12.63us RTT
    
    Signed-off-by: Shawn Bohrer <sbohrer@rgmadvisors.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index cfeb85cff4f0..35913fb77dc8 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1546,6 +1546,7 @@ static const struct net_protocol tcp_protocol = {
 };
 
 static const struct net_protocol udp_protocol = {
+	.early_demux =	udp_v4_early_demux,
 	.handler =	udp_rcv,
 	.err_handler =	udp_err,
 	.no_policy =	1,

commit 9a3bab6b05383f1e4c3716b3615500c51285959e
Author: Eric Dumazet <edumazet@google.com>
Date:   Tue Sep 24 06:19:57 2013 -0700

    net: net_secret should not depend on TCP
    
    A host might need net_secret[] and never open a single socket.
    
    Problem added in commit aebda156a570782
    ("net: defer net_secret[] initialization")
    
    Based on prior patch from Hannes Frederic Sowa.
    
    Reported-by: Hannes Frederic Sowa <hannes@stressinduktion.org>
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Acked-by: Hannes Frederic Sowa <hannes@strressinduktion.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 7a1874b7b8fd..cfeb85cff4f0 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -263,10 +263,8 @@ void build_ehash_secret(void)
 		get_random_bytes(&rnd, sizeof(rnd));
 	} while (rnd == 0);
 
-	if (cmpxchg(&inet_ehash_secret, 0, rnd) == 0) {
+	if (cmpxchg(&inet_ehash_secret, 0, rnd) == 0)
 		get_random_bytes(&ipv6_hash_secret, sizeof(ipv6_hash_secret));
-		net_secret_init();
-	}
 }
 EXPORT_SYMBOL(build_ehash_secret);
 

commit 5a17a390de7bdbcfff9b8f344273a886ca4cf8bf
Author: Cong Wang <amwang@redhat.com>
Date:   Mon Sep 2 10:06:53 2013 +0800

    net: make snmp_mib_free static inline
    
    Fengguang reported:
    
       net/built-in.o: In function `in6_dev_finish_destroy':
       (.text+0x4ca7d): undefined reference to `snmp_mib_free'
    
    this is due to snmp_mib_free() is defined when CONFIG_INET is enabled,
    but in6_dev_finish_destroy() is now moved to core kernel.
    
    I think snmp_mib_free() is small enough to be inlined, so just make it
    static inline.
    
    Reported-by: kbuild test robot <fengguang.wu@intel.com>
    Signed-off-by: Cong Wang <amwang@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index b4d0be2b7ce9..7a1874b7b8fd 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1532,18 +1532,6 @@ int snmp_mib_init(void __percpu *ptr[2], size_t mibsize, size_t align)
 }
 EXPORT_SYMBOL_GPL(snmp_mib_init);
 
-void snmp_mib_free(void __percpu *ptr[SNMP_ARRAY_SZ])
-{
-	int i;
-
-	BUG_ON(ptr == NULL);
-	for (i = 0; i < SNMP_ARRAY_SZ; i++) {
-		free_percpu(ptr[i]);
-		ptr[i] = NULL;
-	}
-}
-EXPORT_SYMBOL_GPL(snmp_mib_free);
-
 #ifdef CONFIG_IP_MULTICAST
 static const struct net_protocol igmp_protocol = {
 	.handler =	igmp_rcv,

commit 5b9b6263775d45ccc0c8b27344bfb1a97cf6f725
Author: Eric Dumazet <edumazet@google.com>
Date:   Wed Jun 12 14:23:15 2013 -0700

    gro: remove a sparse error
    
    Fix following sparse error :
    
    net/ipv4/af_inet.c:1410:59: warning: restricted __be16 degrades to
    integer
    
    added in commit db8caf3dbc77599
    ("gro: should aggregate frames without DF")
    
    Reported-by: kbuild test robot <fengguang.wu@intel.com>
    From: Eric Dumazet <edumazet@google.com>
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 5598b06d62db..b4d0be2b7ce9 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1407,7 +1407,7 @@ static struct sk_buff **inet_gro_receive(struct sk_buff **head,
 		NAPI_GRO_CB(p)->flush |=
 			(iph->ttl ^ iph2->ttl) |
 			(iph->tos ^ iph2->tos) |
-			((iph->frag_off ^ iph2->frag_off) & htons(IP_DF)) |
+			(__force int)((iph->frag_off ^ iph2->frag_off) & htons(IP_DF)) |
 			((u16)(ntohs(iph2->id) + NAPI_GRO_CB(p)->count) ^ id);
 
 		NAPI_GRO_CB(p)->flush |= flush;

commit da5bab079f9b7d90ba234965a14914ace55e45e9
Author: Daniel Borkmann <dborkman@redhat.com>
Date:   Sat Jun 8 12:56:03 2013 +0200

    net: udp4: move GSO functions to udp_offload
    
    Similarly to TCP offloading and UDPv6 offloading, move all related
    UDPv4 functions to udp_offload.c to make things more explicit. Also,
    by this, we can make those functions static.
    
    Signed-off-by: Daniel Borkmann <dborkman@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 7b514290efc6..5598b06d62db 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1566,13 +1566,6 @@ static const struct net_protocol udp_protocol = {
 	.netns_ok =	1,
 };
 
-static const struct net_offload udp_offload = {
-	.callbacks = {
-		.gso_send_check = udp4_ufo_send_check,
-		.gso_segment = udp4_ufo_fragment,
-	},
-};
-
 static const struct net_protocol icmp_protocol = {
 	.handler =	icmp_rcv,
 	.err_handler =	icmp_err,
@@ -1672,7 +1665,7 @@ static int __init ipv4_offload_init(void)
 	/*
 	 * Add offloads
 	 */
-	if (inet_add_offload(&udp_offload, IPPROTO_UDP) < 0)
+	if (udpv4_offload_init() < 0)
 		pr_crit("%s: Cannot add UDP protocol offload\n", __func__);
 	if (tcpv4_offload_init() < 0)
 		pr_crit("%s: Cannot add TCP protocol offload\n", __func__);

commit 28850dc7c71da9d0c0e39246e9ff6913f41f8d0a
Author: Daniel Borkmann <dborkman@redhat.com>
Date:   Fri Jun 7 05:11:46 2013 +0000

    net: tcp: move GRO/GSO functions to tcp_offload
    
    Would be good to make things explicit and move those functions to
    a new file called tcp_offload.c, thus make this similar to tcpv6_offload.c.
    While moving all related functions into tcp_offload.c, we can also
    make some of them static, since they are only used there. Also, add
    an explicit registration function.
    
    Suggested-by: Eric Dumazet <eric.dumazet@gmail.com>
    Signed-off-by: Daniel Borkmann <dborkman@redhat.com>
    Acked-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 9c090c7daea1..7b514290efc6 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1559,15 +1559,6 @@ static const struct net_protocol tcp_protocol = {
 	.netns_ok	=	1,
 };
 
-static const struct net_offload tcp_offload = {
-	.callbacks = {
-		.gso_send_check	=	tcp_v4_gso_send_check,
-		.gso_segment	=	tcp_tso_segment,
-		.gro_receive	=	tcp4_gro_receive,
-		.gro_complete	=	tcp4_gro_complete,
-	},
-};
-
 static const struct net_protocol udp_protocol = {
 	.handler =	udp_rcv,
 	.err_handler =	udp_err,
@@ -1683,8 +1674,8 @@ static int __init ipv4_offload_init(void)
 	 */
 	if (inet_add_offload(&udp_offload, IPPROTO_UDP) < 0)
 		pr_crit("%s: Cannot add UDP protocol offload\n", __func__);
-	if (inet_add_offload(&tcp_offload, IPPROTO_TCP) < 0)
-		pr_crit("%s: Cannot add TCP protocol offlaod\n", __func__);
+	if (tcpv4_offload_init() < 0)
+		pr_crit("%s: Cannot add TCP protocol offload\n", __func__);
 
 	dev_add_offload(&ip_packet_offload);
 	return 0;

commit db8caf3dbc77599dc90f4ea0a803cd1d97116f30
Author: Eric Dumazet <edumazet@google.com>
Date:   Fri May 31 11:18:10 2013 +0000

    gro: should aggregate frames without DF
    
    GRO on IPv4 doesn't aggregate frames if they don't have DF bit set.
    
    Some servers use IP_MTU_DISCOVER/IP_PMTUDISC_PROBE, so linux receivers
    are unable to aggregate this kind of traffic.
    
    The right thing to do is to allow aggregation as long as the DF bit has
    same value on all segments.
    
    bnx2x LRO does this correctly.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Cc: Jerry Chu <hkchu@google.com>
    Cc: Herbert Xu <herbert@gondor.apana.org.au>
    Cc: Ben Hutchings <bhutchings@solarflare.com>
    Reviewed-by: Ben Hutchings <bhutchings@solarflare.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index b05ae96aec44..9c090c7daea1 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1385,7 +1385,7 @@ static struct sk_buff **inet_gro_receive(struct sk_buff **head,
 		goto out_unlock;
 
 	id = ntohl(*(__be32 *)&iph->id);
-	flush = (u16)((ntohl(*(__be32 *)iph) ^ skb_gro_len(skb)) | (id ^ IP_DF));
+	flush = (u16)((ntohl(*(__be32 *)iph) ^ skb_gro_len(skb)) | (id & ~IP_DF));
 	id >>= 16;
 
 	for (p = *head; p; p = p->next) {
@@ -1407,6 +1407,7 @@ static struct sk_buff **inet_gro_receive(struct sk_buff **head,
 		NAPI_GRO_CB(p)->flush |=
 			(iph->ttl ^ iph2->ttl) |
 			(iph->tos ^ iph2->tos) |
+			((iph->frag_off ^ iph2->frag_off) & htons(IP_DF)) |
 			((u16)(ntohs(iph2->id) + NAPI_GRO_CB(p)->count) ^ id);
 
 		NAPI_GRO_CB(p)->flush |= flush;

commit 0d89d2035fe063461a5ddb609b2c12e7fb006e44
Author: Simon Horman <horms@verge.net.au>
Date:   Thu May 23 21:02:52 2013 +0000

    MPLS: Add limited GSO support
    
    In the case where a non-MPLS packet is received and an MPLS stack is
    added it may well be the case that the original skb is GSO but the
    NIC used for transmit does not support GSO of MPLS packets.
    
    The aim of this code is to provide GSO in software for MPLS packets
    whose skbs are GSO.
    
    SKB Usage:
    
    When an implementation adds an MPLS stack to a non-MPLS packet it should do
    the following to skb metadata:
    
    * Set skb->inner_protocol to the old non-MPLS ethertype of the packet.
      skb->inner_protocol is added by this patch.
    
    * Set skb->protocol to the new MPLS ethertype of the packet.
    
    * Set skb->network_header to correspond to the
      end of the L3 header, including the MPLS label stack.
    
    I have posted a patch, "[PATCH v3.29] datapath: Add basic MPLS support to
    kernel" which adds MPLS support to the kernel datapath of Open vSwtich.
    That patch sets the above requirements in datapath/actions.c:push_mpls()
    and was used to exercise this code.  The datapath patch is against the Open
    vSwtich tree but it is intended that it be added to the Open vSwtich code
    present in the mainline Linux kernel at some point.
    
    Features:
    
    I believe that the approach that I have taken is at least partially
    consistent with the handling of other protocols.  Jesse, I understand that
    you have some ideas here.  I am more than happy to change my implementation.
    
    This patch adds dev->mpls_features which may be used by devices
    to advertise features supported for MPLS packets.
    
    A new NETIF_F_MPLS_GSO feature is added for devices which support
    hardware MPLS GSO offload.  Currently no devices support this
    and MPLS GSO always falls back to software.
    
    Alternate Implementation:
    
    One possible alternate implementation is to teach netif_skb_features()
    and skb_network_protocol() about MPLS, in a similar way to their
    understanding of VLANs. I believe this would avoid the need
    for net/mpls/mpls_gso.c and in particular the calls to
    __skb_push() and __skb_push() in mpls_gso_segment().
    
    I have decided on the implementation in this patch as it should
    not introduce any overhead in the case where mpls_gso is not compiled
    into the kernel or inserted as a module.
    
    MPLS GSO suggested by Jesse Gross.
    Based in part on "v4 GRE: Add TCP segmentation offload for GRE"
    by Pravin B Shelar.
    
    Cc: Jesse Gross <jesse@nicira.com>
    Cc: Pravin B Shelar <pshelar@nicira.com>
    Signed-off-by: Simon Horman <horms@verge.net.au>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index d01be2a3ae53..b05ae96aec44 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1295,6 +1295,7 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb,
 		       SKB_GSO_GRE |
 		       SKB_GSO_TCPV6 |
 		       SKB_GSO_UDP_TUNNEL |
+		       SKB_GSO_MPLS |
 		       0)))
 		goto out;
 

commit 9b3eb5edf33897dc9128aa27300066153d4f8b9c
Author: Pravin B Shelar <pshelar@nicira.com>
Date:   Thu May 2 16:14:19 2013 +0000

    gre: Fix GREv4 TCPv6 segmentation.
    
    For ipv6 traffic, GRE can generate packet with strange GSO
    bits, e.g. ipv4 packet with SKB_GSO_TCPV6 flag set.  Therefore
    following patch relaxes check in inet gso handler to allow
    such packet for segmentation.
    This patch also fixes wrong skb->protocol set that was done in
    gre_gso_segment() handler.
    
    Reported-by: Steinar H. Gunderson <sesse@google.com>
    CC: Eric Dumazet <eric.dumazet@gmail.com>
    Signed-off-by: Pravin B Shelar <pshelar@nicira.com>
    Acked-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index c61b3bb87a16..d01be2a3ae53 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1293,6 +1293,7 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb,
 		       SKB_GSO_DODGY |
 		       SKB_GSO_TCP_ECN |
 		       SKB_GSO_GRE |
+		       SKB_GSO_TCPV6 |
 		       SKB_GSO_UDP_TUNNEL |
 		       0)))
 		goto out;

commit aebda156a570782a86fc4426842152237a19427d
Author: Eric Dumazet <edumazet@google.com>
Date:   Mon Apr 29 05:58:52 2013 +0000

    net: defer net_secret[] initialization
    
    Instead of feeding net_secret[] at boot time, defer the init
    at the point first socket is created.
    
    This permits some platforms to use better entropy sources than
    the ones available at boot time.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 93824c57b108..c61b3bb87a16 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -114,6 +114,7 @@
 #include <net/inet_common.h>
 #include <net/xfrm.h>
 #include <net/net_namespace.h>
+#include <net/secure_seq.h>
 #ifdef CONFIG_IP_MROUTE
 #include <linux/mroute.h>
 #endif
@@ -262,8 +263,10 @@ void build_ehash_secret(void)
 		get_random_bytes(&rnd, sizeof(rnd));
 	} while (rnd == 0);
 
-	if (cmpxchg(&inet_ehash_secret, 0, rnd) == 0)
+	if (cmpxchg(&inet_ehash_secret, 0, rnd) == 0) {
 		get_random_bytes(&ipv6_hash_secret, sizeof(ipv6_hash_secret));
+		net_secret_init();
+	}
 }
 EXPORT_SYMBOL(build_ehash_secret);
 

commit c54419321455631079c7d6e60bc732dd0c5914c5
Author: Pravin B Shelar <pshelar@nicira.com>
Date:   Mon Mar 25 14:49:35 2013 +0000

    GRE: Refactor GRE tunneling code.
    
    Following patch refactors GRE code into ip tunneling code and GRE
    specific code. Common tunneling code is moved to ip_tunnel module.
    ip_tunnel module is written as generic library which can be used
    by different tunneling implementations.
    
    ip_tunnel module contains following components:
     - packet xmit and rcv generic code. xmit flow looks like
       (gre_xmit/ipip_xmit)->ip_tunnel_xmit->ip_local_out.
     - hash table of all devices.
     - lookup for tunnel devices.
     - control plane operations like device create, destroy, ioctl, netlink
       operations code.
     - registration for tunneling modules, like gre, ipip etc.
     - define single pcpu_tstats dev->tstats.
     - struct tnl_ptk_info added to pass parsed tunnel packet parameters.
    
    ipip.h header is renamed to ip_tunnel.h
    
    Signed-off-by: Pravin B Shelar <pshelar@nicira.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 70b2d4cf5801..93824c57b108 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -111,7 +111,6 @@
 #include <net/sock.h>
 #include <net/raw.h>
 #include <net/icmp.h>
-#include <net/ipip.h>
 #include <net/inet_common.h>
 #include <net/xfrm.h>
 #include <net/net_namespace.h>

commit 25c7704d8bdcf6746dab4397953df51759924b37
Author: Pravin B Shelar <pshelar@nicira.com>
Date:   Sun Mar 24 17:36:29 2013 +0000

    ipv4: Fix ip-header identification for gso packets.
    
    ip-header id needs to be incremented even if IP_DF flag is set.
    This behaviour was changed in commit 490ab08127cebc25e3a26
    (IP_GRE: Fix IP-Identification).
    
    Following patch fixes it so that identification is always
    incremented.
    
    Reported-by: Cong Wang <amwang@redhat.com>
    Acked-by: Cong Wang <amwang@redhat.com>
    Signed-off-by: Pravin B Shelar <pshelar@nicira.com>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 9e5882caf8a7..70b2d4cf5801 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1334,8 +1334,7 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb,
 				iph->frag_off |= htons(IP_MF);
 			offset += (skb->len - skb->mac_len - iph->ihl * 4);
 		} else  {
-			if (!(iph->frag_off & htons(IP_DF)))
-				iph->id = htons(id++);
+			iph->id = htons(id++);
 		}
 		iph->tot_len = htons(skb->len - skb->mac_len);
 		iph->check = 0;

commit 731362674580cb0c696cd1b1a03d8461a10cf90a
Author: Pravin B Shelar <pshelar@nicira.com>
Date:   Thu Mar 7 13:21:51 2013 +0000

    tunneling: Add generic Tunnel segmentation.
    
    Adds generic tunneling offloading support for IPv4-UDP based
    tunnels.
    GSO type is added to request this offload for a skb.
    netdev feature NETIF_F_UDP_TUNNEL is added for hardware offloaded
    udp-tunnel support. Currently no device supports this feature,
    software offload is used.
    
    This can be used by tunneling protocols like VXLAN.
    
    CC: Jesse Gross <jesse@nicira.com>
    Signed-off-by: Pravin B Shelar <pshelar@nicira.com>
    Acked-by: Stephen Hemminger <stephen@networkplumber.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index dc3f677360a5..9e5882caf8a7 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1283,6 +1283,7 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb,
 	int ihl;
 	int id;
 	unsigned int offset = 0;
+	bool tunnel;
 
 	if (unlikely(skb_shinfo(skb)->gso_type &
 		     ~(SKB_GSO_TCPV4 |
@@ -1290,6 +1291,7 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb,
 		       SKB_GSO_DODGY |
 		       SKB_GSO_TCP_ECN |
 		       SKB_GSO_GRE |
+		       SKB_GSO_UDP_TUNNEL |
 		       0)))
 		goto out;
 
@@ -1304,6 +1306,8 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb,
 	if (unlikely(!pskb_may_pull(skb, ihl)))
 		goto out;
 
+	tunnel = !!skb->encapsulation;
+
 	__skb_pull(skb, ihl);
 	skb_reset_transport_header(skb);
 	iph = ip_hdr(skb);
@@ -1323,7 +1327,7 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb,
 	skb = segs;
 	do {
 		iph = ip_hdr(skb);
-		if (proto == IPPROTO_UDP) {
+		if (!tunnel && proto == IPPROTO_UDP) {
 			iph->id = htons(id);
 			iph->frag_off = htons(offset >> 3);
 			if (skb->next != NULL)

commit ec5f061564238892005257c83565a0b58ec79295
Author: Pravin B Shelar <pshelar@nicira.com>
Date:   Thu Mar 7 09:28:01 2013 +0000

    net: Kill link between CSUM and SG features.
    
    Earlier SG was unset if CSUM was not available for given device to
    force skb copy to avoid sending inconsistent csum.
    Commit c9af6db4c11c (net: Fix possible wrong checksum generation)
    added explicit flag to force copy to fix this issue.  Therefore
    there is no need to link SG and CSUM, following patch kills this
    link between there two features.
    
    This patch is also required following patch in series.
    
    Signed-off-by: Pravin B Shelar <pshelar@nicira.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 68f6a94f7661..dc3f677360a5 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1284,9 +1284,6 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb,
 	int id;
 	unsigned int offset = 0;
 
-	if (!(features & NETIF_F_V4_CSUM))
-		features &= ~NETIF_F_SG;
-
 	if (unlikely(skb_shinfo(skb)->gso_type &
 		     ~(SKB_GSO_TCPV4 |
 		       SKB_GSO_UDP |

commit 490ab08127cebc25e3a260a74556b56ce5f47c0f
Author: Pravin B Shelar <pshelar@nicira.com>
Date:   Fri Feb 22 07:30:30 2013 +0000

    IP_GRE: Fix IP-Identification.
    
    GRE-GSO generates ip fragments with id 0,2,3,4... for every
    GSO packet, which is not correct. Following patch fixes it
    by setting ip-header id unique id of fragments are allowed.
    As Eric Dumazet suggested it is optimized by using inner ip-header
    whenever inner packet is ipv4.
    
    Signed-off-by: Pravin B Shelar <pshelar@nicira.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 15847e19b7dd..68f6a94f7661 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1332,8 +1332,10 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb,
 			if (skb->next != NULL)
 				iph->frag_off |= htons(IP_MF);
 			offset += (skb->len - skb->mac_len - iph->ihl * 4);
-		} else
-			iph->id = htons(id++);
+		} else  {
+			if (!(iph->frag_off & htons(IP_DF)))
+				iph->id = htons(id++);
+		}
 		iph->tot_len = htons(skb->len - skb->mac_len);
 		iph->check = 0;
 		iph->check = ip_fast_csum(skb_network_header(skb), iph->ihl);

commit 5b0520425e5ea81ba95ec486dd6bbb59a09fff0e
Author: Li Wei <lw@cn.fujitsu.com>
Date:   Thu Feb 21 22:18:44 2013 +0000

    ipv4: fix error handling in icmp_protocol.
    
    Now we handle icmp errors in each transport protocol's err_handler,
    for icmp protocols, that is ping_err. Since this handler only care
    of those icmp errors triggered by echo request, errors triggered
    by echo reply(which sent by kernel) are sliently ignored.
    
    So wrap ping_err() with icmp_err() to deal with those icmp errors.
    
    Signed-off-by: Li Wei <lw@cn.fujitsu.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 9cbcb94a4c6d..15847e19b7dd 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1577,7 +1577,7 @@ static const struct net_offload udp_offload = {
 
 static const struct net_protocol icmp_protocol = {
 	.handler =	icmp_rcv,
-	.err_handler =	ping_err,
+	.err_handler =	icmp_err,
 	.no_policy =	1,
 	.netns_ok =	1,
 };

commit 08dcdbf6a7b9d14c2302c5bd0c5390ddf122f664
Author: Eric Dumazet <edumazet@google.com>
Date:   Thu Feb 21 12:18:52 2013 +0000

    ipv6: use a stronger hash for tcp
    
    It looks like its possible to open thousands of TCP IPv6
    sessions on a server, all landing in a single slot of TCP hash
    table. Incoming packets have to lookup sockets in a very
    long list.
    
    We should hash all bits from foreign IPv6 addresses, using
    a salt and hash mix, not a simple XOR.
    
    inet6_ehashfn() can also separately use the ports, instead
    of xoring them.
    
    Reported-by: Neal Cardwell <ncardwell@google.com>
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Cc: Yuchung Cheng <ycheng@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index e225a4e5b572..9cbcb94a4c6d 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -248,8 +248,12 @@ EXPORT_SYMBOL(inet_listen);
 u32 inet_ehash_secret __read_mostly;
 EXPORT_SYMBOL(inet_ehash_secret);
 
+u32 ipv6_hash_secret __read_mostly;
+EXPORT_SYMBOL(ipv6_hash_secret);
+
 /*
- * inet_ehash_secret must be set exactly once
+ * inet_ehash_secret must be set exactly once, and to a non nul value
+ * ipv6_hash_secret must be set exactly once.
  */
 void build_ehash_secret(void)
 {
@@ -259,7 +263,8 @@ void build_ehash_secret(void)
 		get_random_bytes(&rnd, sizeof(rnd));
 	} while (rnd == 0);
 
-	cmpxchg(&inet_ehash_secret, 0, rnd);
+	if (cmpxchg(&inet_ehash_secret, 0, rnd) == 0)
+		get_random_bytes(&ipv6_hash_secret, sizeof(ipv6_hash_secret));
 }
 EXPORT_SYMBOL(build_ehash_secret);
 

commit 68c331631143f5f039baac99a650e0b9e1ea02b6
Author: Pravin B Shelar <pshelar@nicira.com>
Date:   Thu Feb 14 14:02:41 2013 +0000

    v4 GRE: Add TCP segmentation offload for GRE
    
    Following patch adds GRE protocol offload handler so that
    skb_gso_segment() can segment GRE packets.
    SKB GSO CB is added to keep track of total header length so that
    skb_segment can push entire header. e.g. in case of GRE, skb_segment
    need to push inner and outer headers to every segment.
    New NETIF_F_GRE_GSO feature is added for devices which support HW
    GRE TSO offload. Currently none of devices support it therefore GRE GSO
    always fall backs to software GSO.
    
    [ Compute pkt_len before ip_local_out() invocation. -DaveM ]
    
    Signed-off-by: Pravin B Shelar <pshelar@nicira.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index e6e5d8506336..e225a4e5b572 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1287,6 +1287,7 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb,
 		       SKB_GSO_UDP |
 		       SKB_GSO_DODGY |
 		       SKB_GSO_TCP_ECN |
+		       SKB_GSO_GRE |
 		       0)))
 		goto out;
 

commit c9af6db4c11ccc6c3e7f19bbc15d54023956f97c
Author: Pravin B Shelar <pshelar@nicira.com>
Date:   Mon Feb 11 09:27:41 2013 +0000

    net: Fix possible wrong checksum generation.
    
    Patch cef401de7be8c4e (net: fix possible wrong checksum
    generation) fixed wrong checksum calculation but it broke TSO by
    defining new GSO type but not a netdev feature for that type.
    net_gso_ok() would not allow hardware checksum/segmentation
    offload of such packets without the feature.
    
    Following patch fixes TSO and wrong checksum. This patch uses
    same logic that Eric Dumazet used. Patch introduces new flag
    SKBTX_SHARED_FRAG if at least one frag can be modified by
    the user. but SKBTX_SHARED_FRAG flag is kept in skb shared
    info tx_flags rather than gso_type.
    
    tx_flags is better compared to gso_type since we can have skb with
    shared frag without gso packet. It does not link SHARED_FRAG to
    GSO, So there is no need to define netdev feature for this.
    
    Signed-off-by: Pravin B Shelar <pshelar@nicira.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 1aec92bf8018..e6e5d8506336 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1287,7 +1287,6 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb,
 		       SKB_GSO_UDP |
 		       SKB_GSO_DODGY |
 		       SKB_GSO_TCP_ECN |
-		       SKB_GSO_SHARED_FRAG |
 		       0)))
 		goto out;
 

commit 547472b8e1da72ae226430c0c4273e36fc8ca768
Author: David S. Miller <davem@davemloft.net>
Date:   Tue Feb 5 14:42:23 2013 -0500

    ipv4: Disallow non-namespace aware protocols to register.
    
    All in-tree ipv4 protocol implementations are now namespace
    aware.  Therefore all the run-time checks are superfluous.
    
    Reject registry of any non-namespace aware ipv4 protocol.
    Eventually we'll remove prot->netns_ok and this registry
    time check as well.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 49ddca31c4da..1aec92bf8018 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -263,21 +263,6 @@ void build_ehash_secret(void)
 }
 EXPORT_SYMBOL(build_ehash_secret);
 
-static inline int inet_netns_ok(struct net *net, __u8 protocol)
-{
-	const struct net_protocol *ipprot;
-
-	if (net_eq(net, &init_net))
-		return 1;
-
-	ipprot = rcu_dereference(inet_protos[protocol]);
-	if (ipprot == NULL) {
-		/* raw IP is OK */
-		return 1;
-	}
-	return ipprot->netns_ok;
-}
-
 /*
  *	Create an inet socket.
  */
@@ -350,10 +335,6 @@ static int inet_create(struct net *net, struct socket *sock, int protocol,
 	    !ns_capable(net->user_ns, CAP_NET_RAW))
 		goto out_rcu_unlock;
 
-	err = -EAFNOSUPPORT;
-	if (!inet_netns_ok(net, protocol))
-		goto out_rcu_unlock;
-
 	sock->ops = answer->ops;
 	answer_prot = answer->prot;
 	answer_no_check = answer->no_check;

commit cef401de7be8c4e155c6746bfccf721a4fa5fab9
Author: Eric Dumazet <edumazet@google.com>
Date:   Fri Jan 25 20:34:37 2013 +0000

    net: fix possible wrong checksum generation
    
    Pravin Shelar mentioned that GSO could potentially generate
    wrong TX checksum if skb has fragments that are overwritten
    by the user between the checksum computation and transmit.
    
    He suggested to linearize skbs but this extra copy can be
    avoided for normal tcp skbs cooked by tcp_sendmsg().
    
    This patch introduces a new SKB_GSO_SHARED_FRAG flag, set
    in skb_shinfo(skb)->gso_type if at least one frag can be
    modified by the user.
    
    Typical sources of such possible overwrites are {vm}splice(),
    sendfile(), and macvtap/tun/virtio_net drivers.
    
    Tested:
    
    $ netperf -H 7.7.8.84
    MIGRATED TCP STREAM TEST from 0.0.0.0 (0.0.0.0) port 0 AF_INET to
    7.7.8.84 () port 0 AF_INET
    Recv   Send    Send
    Socket Socket  Message  Elapsed
    Size   Size    Size     Time     Throughput
    bytes  bytes   bytes    secs.    10^6bits/sec
    
     87380  16384  16384    10.00    3959.52
    
    $ netperf -H 7.7.8.84 -t TCP_SENDFILE
    TCP SENDFILE TEST from 0.0.0.0 (0.0.0.0) port 0 AF_INET to 7.7.8.84 ()
    port 0 AF_INET
    Recv   Send    Send
    Socket Socket  Message  Elapsed
    Size   Size    Size     Time     Throughput
    bytes  bytes   bytes    secs.    10^6bits/sec
    
     87380  16384  16384    10.00    3216.80
    
    Performance of the SENDFILE is impacted by the extra allocation and
    copy, and because we use order-0 pages, while the TCP_STREAM uses
    bigger pages.
    
    Reported-by: Pravin Shelar <pshelar@nicira.com>
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 4b7053919976..49ddca31c4da 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1306,6 +1306,7 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb,
 		       SKB_GSO_UDP |
 		       SKB_GSO_DODGY |
 		       SKB_GSO_TCP_ECN |
+		       SKB_GSO_SHARED_FRAG |
 		       0)))
 		goto out;
 

commit 50c3a487d507568359ccbce1b15bcdfc01edf7ef
Author: YOSHIFUJI Hideaki / 吉藤英明 <yoshfuji@linux-ipv6.org>
Date:   Tue Jan 22 06:32:49 2013 +0000

    ipv4: Use IS_ERR_OR_NULL().
    
    Signed-off-by: YOSHIFUJI Hideaki <yoshfuji@linux-ipv6.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 4fdf96710d45..4b7053919976 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1333,7 +1333,7 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb,
 		segs = ops->callbacks.gso_segment(skb, features);
 	rcu_read_unlock();
 
-	if (!segs || IS_ERR(segs))
+	if (IS_ERR_OR_NULL(segs))
 		goto out;
 
 	skb = segs;

commit 95c7e0e4d4792f9c9629ad759c9be047a3ddbcc5
Author: YOSHIFUJI Hideaki / 吉藤英明 <yoshfuji@linux-ipv6.org>
Date:   Wed Jan 9 07:19:37 2013 +0000

    ipv4: Use FIELD_SIZEOF() in inet_init().
    
    Signed-off-by: YOSHIFUJI Hideaki <yoshfuji@linux-ipv6.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 24b384b7903e..4fdf96710d45 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1705,12 +1705,11 @@ static struct packet_type ip_packet_type __read_mostly = {
 
 static int __init inet_init(void)
 {
-	struct sk_buff *dummy_skb;
 	struct inet_protosw *q;
 	struct list_head *r;
 	int rc = -EINVAL;
 
-	BUILD_BUG_ON(sizeof(struct inet_skb_parm) > sizeof(dummy_skb->cb));
+	BUILD_BUG_ON(sizeof(struct inet_skb_parm) > FIELD_SIZEOF(struct sk_buff, cb));
 
 	sysctl_local_reserved_ports = kzalloc(65536 / 8, GFP_KERNEL);
 	if (!sysctl_local_reserved_ports)

commit 3594698a1fb8e5ae60a92c72ce9ca280256939a7
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Fri Nov 16 03:03:12 2012 +0000

    net: Make CAP_NET_BIND_SERVICE per user namespace
    
    Allow privileged users in any user namespace to bind to
    privileged sockets in network namespaces they control.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 4f5f22061e1c..24b384b7903e 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -474,6 +474,7 @@ int inet_bind(struct socket *sock, struct sockaddr *uaddr, int addr_len)
 	struct sockaddr_in *addr = (struct sockaddr_in *)uaddr;
 	struct sock *sk = sock->sk;
 	struct inet_sock *inet = inet_sk(sk);
+	struct net *net = sock_net(sk);
 	unsigned short snum;
 	int chk_addr_ret;
 	int err;
@@ -497,7 +498,7 @@ int inet_bind(struct socket *sock, struct sockaddr *uaddr, int addr_len)
 			goto out;
 	}
 
-	chk_addr_ret = inet_addr_type(sock_net(sk), addr->sin_addr.s_addr);
+	chk_addr_ret = inet_addr_type(net, addr->sin_addr.s_addr);
 
 	/* Not specified by any standard per-se, however it breaks too
 	 * many applications when removed.  It is unfortunate since
@@ -517,7 +518,8 @@ int inet_bind(struct socket *sock, struct sockaddr *uaddr, int addr_len)
 
 	snum = ntohs(addr->sin_port);
 	err = -EACCES;
-	if (snum && snum < PROT_SOCK && !capable(CAP_NET_BIND_SERVICE))
+	if (snum && snum < PROT_SOCK &&
+	    !ns_capable(net->user_ns, CAP_NET_BIND_SERVICE))
 		goto out;
 
 	/*      We keep a pair of addresses. rcv_saddr is the one

commit 52e804c6dfaa5df1e4b0e290357b82ad4e4cda2c
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Fri Nov 16 03:03:05 2012 +0000

    net: Allow userns root to control ipv4
    
    Allow an unpriviled user who has created a user namespace, and then
    created a network namespace to effectively use the new network
    namespace, by reducing capable(CAP_NET_ADMIN) and
    capable(CAP_NET_RAW) calls to be ns_capable(net->user_ns,
    CAP_NET_ADMIN), or capable(net->user_ns, CAP_NET_RAW) calls.
    
    Settings that merely control a single network device are allowed.
    Either the network device is a logical network device where
    restrictions make no difference or the network device is hardware NIC
    that has been explicity moved from the initial network namespace.
    
    In general policy and network stack state changes are allowed
    while resource control is left unchanged.
    
    Allow creating raw sockets.
    Allow the SIOCSARP ioctl to control the arp cache.
    Allow the SIOCSIFFLAG ioctl to allow setting network device flags.
    Allow the SIOCSIFADDR ioctl to allow setting a netdevice ipv4 address.
    Allow the SIOCSIFBRDADDR ioctl to allow setting a netdevice ipv4 broadcast address.
    Allow the SIOCSIFDSTADDR ioctl to allow setting a netdevice ipv4 destination address.
    Allow the SIOCSIFNETMASK ioctl to allow setting a netdevice ipv4 netmask.
    Allow the SIOCADDRT and SIOCDELRT ioctls to allow adding and deleting ipv4 routes.
    
    Allow the SIOCADDTUNNEL, SIOCCHGTUNNEL and SIOCDELTUNNEL ioctls for
    adding, changing and deleting gre tunnels.
    
    Allow the SIOCADDTUNNEL, SIOCCHGTUNNEL and SIOCDELTUNNEL ioctls for
    adding, changing and deleting ipip tunnels.
    
    Allow the SIOCADDTUNNEL, SIOCCHGTUNNEL and SIOCDELTUNNEL ioctls for
    adding, changing and deleting ipsec virtual tunnel interfaces.
    
    Allow setting the MRT_INIT, MRT_DONE, MRT_ADD_VIF, MRT_DEL_VIF, MRT_ADD_MFC,
    MRT_DEL_MFC, MRT_ASSERT, MRT_PIM, MRT_TABLE socket options on multicast routing
    sockets.
    
    Allow setting and receiving IPOPT_CIPSO, IP_OPT_SEC, IP_OPT_SID and
    arbitrary ip options.
    
    Allow setting IP_SEC_POLICY/IP_XFRM_POLICY ipv4 socket option.
    Allow setting the IP_TRANSPARENT ipv4 socket option.
    Allow setting the TCP_REPAIR socket option.
    Allow setting the TCP_CONGESTION socket option.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index d5e5a054123c..4f5f22061e1c 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -346,7 +346,8 @@ static int inet_create(struct net *net, struct socket *sock, int protocol,
 	}
 
 	err = -EPERM;
-	if (sock->type == SOCK_RAW && !kern && !capable(CAP_NET_RAW))
+	if (sock->type == SOCK_RAW && !kern &&
+	    !ns_capable(net->user_ns, CAP_NET_RAW))
 		goto out_rcu_unlock;
 
 	err = -EAFNOSUPPORT;

commit f191a1d17f227032c159e5499809f545402b6dc6
Author: Vlad Yasevich <vyasevic@redhat.com>
Date:   Thu Nov 15 08:49:23 2012 +0000

    net: Remove code duplication between offload structures
    
    Move the offload callbacks into its own structure.
    
    Signed-off-by: Vlad Yasevich <vyasevic@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 9f2e7fd8bea8..d5e5a054123c 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1276,8 +1276,8 @@ static int inet_gso_send_check(struct sk_buff *skb)
 
 	rcu_read_lock();
 	ops = rcu_dereference(inet_offloads[proto]);
-	if (likely(ops && ops->gso_send_check))
-		err = ops->gso_send_check(skb);
+	if (likely(ops && ops->callbacks.gso_send_check))
+		err = ops->callbacks.gso_send_check(skb);
 	rcu_read_unlock();
 
 out:
@@ -1326,8 +1326,8 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb,
 
 	rcu_read_lock();
 	ops = rcu_dereference(inet_offloads[proto]);
-	if (likely(ops && ops->gso_segment))
-		segs = ops->gso_segment(skb, features);
+	if (likely(ops && ops->callbacks.gso_segment))
+		segs = ops->callbacks.gso_segment(skb, features);
 	rcu_read_unlock();
 
 	if (!segs || IS_ERR(segs))
@@ -1379,7 +1379,7 @@ static struct sk_buff **inet_gro_receive(struct sk_buff **head,
 
 	rcu_read_lock();
 	ops = rcu_dereference(inet_offloads[proto]);
-	if (!ops || !ops->gro_receive)
+	if (!ops || !ops->callbacks.gro_receive)
 		goto out_unlock;
 
 	if (*(u8 *)iph != 0x45)
@@ -1420,7 +1420,7 @@ static struct sk_buff **inet_gro_receive(struct sk_buff **head,
 	skb_gro_pull(skb, sizeof(*iph));
 	skb_set_transport_header(skb, skb_gro_offset(skb));
 
-	pp = ops->gro_receive(head, skb);
+	pp = ops->callbacks.gro_receive(head, skb);
 
 out_unlock:
 	rcu_read_unlock();
@@ -1444,10 +1444,10 @@ static int inet_gro_complete(struct sk_buff *skb)
 
 	rcu_read_lock();
 	ops = rcu_dereference(inet_offloads[proto]);
-	if (WARN_ON(!ops || !ops->gro_complete))
+	if (WARN_ON(!ops || !ops->callbacks.gro_complete))
 		goto out_unlock;
 
-	err = ops->gro_complete(skb);
+	err = ops->callbacks.gro_complete(skb);
 
 out_unlock:
 	rcu_read_unlock();
@@ -1563,10 +1563,12 @@ static const struct net_protocol tcp_protocol = {
 };
 
 static const struct net_offload tcp_offload = {
-	.gso_send_check	=	tcp_v4_gso_send_check,
-	.gso_segment	=	tcp_tso_segment,
-	.gro_receive	=	tcp4_gro_receive,
-	.gro_complete	=	tcp4_gro_complete,
+	.callbacks = {
+		.gso_send_check	=	tcp_v4_gso_send_check,
+		.gso_segment	=	tcp_tso_segment,
+		.gro_receive	=	tcp4_gro_receive,
+		.gro_complete	=	tcp4_gro_complete,
+	},
 };
 
 static const struct net_protocol udp_protocol = {
@@ -1577,8 +1579,10 @@ static const struct net_protocol udp_protocol = {
 };
 
 static const struct net_offload udp_offload = {
-	.gso_send_check = udp4_ufo_send_check,
-	.gso_segment = udp4_ufo_fragment,
+	.callbacks = {
+		.gso_send_check = udp4_ufo_send_check,
+		.gso_segment = udp4_ufo_fragment,
+	},
 };
 
 static const struct net_protocol icmp_protocol = {
@@ -1667,10 +1671,12 @@ static int ipv4_proc_init(void);
 
 static struct packet_offload ip_packet_offload __read_mostly = {
 	.type = cpu_to_be16(ETH_P_IP),
-	.gso_send_check = inet_gso_send_check,
-	.gso_segment = inet_gso_segment,
-	.gro_receive = inet_gro_receive,
-	.gro_complete = inet_gro_complete,
+	.callbacks = {
+		.gso_send_check = inet_gso_send_check,
+		.gso_segment = inet_gso_segment,
+		.gro_receive = inet_gro_receive,
+		.gro_complete = inet_gro_complete,
+	},
 };
 
 static int __init ipv4_offload_init(void)

commit 808a8f884554f93315f663b2694addb4a177c578
Author: Vlad Yasevich <vyasevic@redhat.com>
Date:   Thu Nov 15 08:49:21 2012 +0000

    ipv4: Pull GSO registration out of inet_init()
    
    Since GSO/GRO support is now separated, make IPv4 GSO a
    stand-alone init call and not part of inet_init().
    
    Signed-off-by: Vlad Yasevich <vyasevic@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 66f63ce07ac8..9f2e7fd8bea8 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1665,11 +1665,6 @@ static int ipv4_proc_init(void);
  *	IP protocol layer initialiser
  */
 
-static struct packet_type ip_packet_type __read_mostly = {
-	.type = cpu_to_be16(ETH_P_IP),
-	.func = ip_rcv,
-};
-
 static struct packet_offload ip_packet_offload __read_mostly = {
 	.type = cpu_to_be16(ETH_P_IP),
 	.gso_send_check = inet_gso_send_check,
@@ -1678,6 +1673,27 @@ static struct packet_offload ip_packet_offload __read_mostly = {
 	.gro_complete = inet_gro_complete,
 };
 
+static int __init ipv4_offload_init(void)
+{
+	/*
+	 * Add offloads
+	 */
+	if (inet_add_offload(&udp_offload, IPPROTO_UDP) < 0)
+		pr_crit("%s: Cannot add UDP protocol offload\n", __func__);
+	if (inet_add_offload(&tcp_offload, IPPROTO_TCP) < 0)
+		pr_crit("%s: Cannot add TCP protocol offlaod\n", __func__);
+
+	dev_add_offload(&ip_packet_offload);
+	return 0;
+}
+
+fs_initcall(ipv4_offload_init);
+
+static struct packet_type ip_packet_type __read_mostly = {
+	.type = cpu_to_be16(ETH_P_IP),
+	.func = ip_rcv,
+};
+
 static int __init inet_init(void)
 {
 	struct sk_buff *dummy_skb;
@@ -1719,14 +1735,6 @@ static int __init inet_init(void)
 
 	tcp_prot.sysctl_mem = init_net.ipv4.sysctl_tcp_mem;
 
-	/*
-	 * Add offloads
-	 */
-	if (inet_add_offload(&udp_offload, IPPROTO_UDP) < 0)
-		pr_crit("%s: Cannot add UDP protocol offload\n", __func__);
-	if (inet_add_offload(&tcp_offload, IPPROTO_TCP) < 0)
-		pr_crit("%s: Cannot add TCP protocol offlaod\n", __func__);
-
 	/*
 	 *	Add all the base protocols.
 	 */
@@ -1799,7 +1807,6 @@ static int __init inet_init(void)
 
 	ipfrag_init();
 
-	dev_add_offload(&ip_packet_offload);
 	dev_add_pack(&ip_packet_type);
 
 	rc = 0;

commit bca49f843eac59cbb1ddd1f4a5d65fcc23b62efd
Author: Vlad Yasevich <vyasevic@redhat.com>
Date:   Thu Nov 15 08:49:14 2012 +0000

    ipv4: Switch to using the new offload infrastructure.
    
    Switch IPv4 code base to using the new GRO/GSO calls and data.
    
    Signed-off-by: Vlad Yasevich <vyasevic@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 3918d869d6d4..66f63ce07ac8 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1251,7 +1251,7 @@ EXPORT_SYMBOL(inet_sk_rebuild_header);
 
 static int inet_gso_send_check(struct sk_buff *skb)
 {
-	const struct net_protocol *ops;
+	const struct net_offload *ops;
 	const struct iphdr *iph;
 	int proto;
 	int ihl;
@@ -1275,7 +1275,7 @@ static int inet_gso_send_check(struct sk_buff *skb)
 	err = -EPROTONOSUPPORT;
 
 	rcu_read_lock();
-	ops = rcu_dereference(inet_protos[proto]);
+	ops = rcu_dereference(inet_offloads[proto]);
 	if (likely(ops && ops->gso_send_check))
 		err = ops->gso_send_check(skb);
 	rcu_read_unlock();
@@ -1288,7 +1288,7 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb,
 	netdev_features_t features)
 {
 	struct sk_buff *segs = ERR_PTR(-EINVAL);
-	const struct net_protocol *ops;
+	const struct net_offload *ops;
 	struct iphdr *iph;
 	int proto;
 	int ihl;
@@ -1325,7 +1325,7 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb,
 	segs = ERR_PTR(-EPROTONOSUPPORT);
 
 	rcu_read_lock();
-	ops = rcu_dereference(inet_protos[proto]);
+	ops = rcu_dereference(inet_offloads[proto]);
 	if (likely(ops && ops->gso_segment))
 		segs = ops->gso_segment(skb, features);
 	rcu_read_unlock();
@@ -1356,7 +1356,7 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb,
 static struct sk_buff **inet_gro_receive(struct sk_buff **head,
 					 struct sk_buff *skb)
 {
-	const struct net_protocol *ops;
+	const struct net_offload *ops;
 	struct sk_buff **pp = NULL;
 	struct sk_buff *p;
 	const struct iphdr *iph;
@@ -1378,7 +1378,7 @@ static struct sk_buff **inet_gro_receive(struct sk_buff **head,
 	proto = iph->protocol;
 
 	rcu_read_lock();
-	ops = rcu_dereference(inet_protos[proto]);
+	ops = rcu_dereference(inet_offloads[proto]);
 	if (!ops || !ops->gro_receive)
 		goto out_unlock;
 
@@ -1435,7 +1435,7 @@ static int inet_gro_complete(struct sk_buff *skb)
 {
 	__be16 newlen = htons(skb->len - skb_network_offset(skb));
 	struct iphdr *iph = ip_hdr(skb);
-	const struct net_protocol *ops;
+	const struct net_offload *ops;
 	int proto = iph->protocol;
 	int err = -ENOSYS;
 
@@ -1443,7 +1443,7 @@ static int inet_gro_complete(struct sk_buff *skb)
 	iph->tot_len = newlen;
 
 	rcu_read_lock();
-	ops = rcu_dereference(inet_protos[proto]);
+	ops = rcu_dereference(inet_offloads[proto]);
 	if (WARN_ON(!ops || !ops->gro_complete))
 		goto out_unlock;
 
@@ -1558,10 +1558,6 @@ static const struct net_protocol tcp_protocol = {
 	.early_demux	=	tcp_v4_early_demux,
 	.handler	=	tcp_v4_rcv,
 	.err_handler	=	tcp_v4_err,
-	.gso_send_check	=	tcp_v4_gso_send_check,
-	.gso_segment	=	tcp_tso_segment,
-	.gro_receive	=	tcp4_gro_receive,
-	.gro_complete	=	tcp4_gro_complete,
 	.no_policy	=	1,
 	.netns_ok	=	1,
 };
@@ -1576,8 +1572,6 @@ static const struct net_offload tcp_offload = {
 static const struct net_protocol udp_protocol = {
 	.handler =	udp_rcv,
 	.err_handler =	udp_err,
-	.gso_send_check = udp4_ufo_send_check,
-	.gso_segment = udp4_ufo_fragment,
 	.no_policy =	1,
 	.netns_ok =	1,
 };
@@ -1725,6 +1719,14 @@ static int __init inet_init(void)
 
 	tcp_prot.sysctl_mem = init_net.ipv4.sysctl_tcp_mem;
 
+	/*
+	 * Add offloads
+	 */
+	if (inet_add_offload(&udp_offload, IPPROTO_UDP) < 0)
+		pr_crit("%s: Cannot add UDP protocol offload\n", __func__);
+	if (inet_add_offload(&tcp_offload, IPPROTO_TCP) < 0)
+		pr_crit("%s: Cannot add TCP protocol offlaod\n", __func__);
+
 	/*
 	 *	Add all the base protocols.
 	 */

commit de27d001d187721de775ed9e0c485aa6f517c745
Author: Vlad Yasevich <vyasevic@redhat.com>
Date:   Thu Nov 15 08:49:12 2012 +0000

    net: Add net protocol offload registration infrustructure
    
    Create a new data structure for IPv4 protocols that holds GRO/GSO
    callbacks and a new array to track the protocols that register GRO/GSO.
    
    Signed-off-by: Vlad Yasevich <vyasevic@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 4c99c5fdba3f..3918d869d6d4 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1566,6 +1566,13 @@ static const struct net_protocol tcp_protocol = {
 	.netns_ok	=	1,
 };
 
+static const struct net_offload tcp_offload = {
+	.gso_send_check	=	tcp_v4_gso_send_check,
+	.gso_segment	=	tcp_tso_segment,
+	.gro_receive	=	tcp4_gro_receive,
+	.gro_complete	=	tcp4_gro_complete,
+};
+
 static const struct net_protocol udp_protocol = {
 	.handler =	udp_rcv,
 	.err_handler =	udp_err,
@@ -1575,6 +1582,11 @@ static const struct net_protocol udp_protocol = {
 	.netns_ok =	1,
 };
 
+static const struct net_offload udp_offload = {
+	.gso_send_check = udp4_ufo_send_check,
+	.gso_segment = udp4_ufo_fragment,
+};
+
 static const struct net_protocol icmp_protocol = {
 	.handler =	icmp_rcv,
 	.err_handler =	ping_err,

commit 22061d8014455b01eb018bd6c35a1b3040ccc230
Author: Vlad Yasevich <vyasevic@redhat.com>
Date:   Thu Nov 15 08:49:11 2012 +0000

    net: Switch to using the new packet offload infrustructure
    
    Convert to using the new GSO/GRO registration mechanism and new
    packet offload structure.
    
    Signed-off-by: Vlad Yasevich <vyasevic@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 766c59658563..4c99c5fdba3f 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1662,6 +1662,10 @@ static int ipv4_proc_init(void);
 static struct packet_type ip_packet_type __read_mostly = {
 	.type = cpu_to_be16(ETH_P_IP),
 	.func = ip_rcv,
+};
+
+static struct packet_offload ip_packet_offload __read_mostly = {
+	.type = cpu_to_be16(ETH_P_IP),
 	.gso_send_check = inet_gso_send_check,
 	.gso_segment = inet_gso_segment,
 	.gro_receive = inet_gro_receive,
@@ -1781,6 +1785,7 @@ static int __init inet_init(void)
 
 	ipfrag_init();
 
+	dev_add_offload(&ip_packet_offload);
 	dev_add_pack(&ip_packet_type);
 
 	rc = 0;

commit bb68b64724a4fd6b93d83b39aeffa4aadb2562fc
Author: Christoph Paasch <christoph.paasch@uclouvain.be>
Date:   Tue Sep 18 14:19:23 2012 +0000

    ipv4: Don't add TCP-code in inet_sock_destruct
    
    Signed-off-by: Christoph Paasch <christoph.paasch@uclouvain.be>
    Acked-by: H.K. Jerry Chu <hkchu@google.com>
    Acked-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 845372b025f6..766c59658563 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -149,8 +149,6 @@ void inet_sock_destruct(struct sock *sk)
 		pr_err("Attempt to release alive inet socket %p\n", sk);
 		return;
 	}
-	if (sk->sk_protocol == IPPROTO_TCP)
-		kfree(inet_csk(sk)->icsk_accept_queue.fastopenq);
 
 	WARN_ON(atomic_read(&sk->sk_rmem_alloc));
 	WARN_ON(atomic_read(&sk->sk_wmem_alloc));

commit 7ab4551f3b391818e29263279031dca1e26417c6
Author: Eric Dumazet <edumazet@google.com>
Date:   Thu Sep 6 08:07:13 2012 +0000

    tcp: fix TFO regression
    
    Fengguang Wu reported various panics and bisected to commit
    8336886f786fdac (tcp: TCP Fast Open Server - support TFO listeners)
    
    Fix this by making sure socket is a TCP socket before accessing TFO data
    structures.
    
    [  233.046014] kfree_debugcheck: out of range ptr ea6000000bb8h.
    [  233.047399] ------------[ cut here ]------------
    [  233.048393] kernel BUG at /c/kernel-tests/src/stable/mm/slab.c:3074!
    [  233.048393] invalid opcode: 0000 [#1] SMP DEBUG_PAGEALLOC
    [  233.048393] Modules linked in:
    [  233.048393] CPU 0
    [  233.048393] Pid: 3929, comm: trinity-watchdo Not tainted 3.6.0-rc3+
    #4192 Bochs Bochs
    [  233.048393] RIP: 0010:[<ffffffff81169653>]  [<ffffffff81169653>]
    kfree_debugcheck+0x27/0x2d
    [  233.048393] RSP: 0018:ffff88000facbca8  EFLAGS: 00010092
    [  233.048393] RAX: 0000000000000031 RBX: 0000ea6000000bb8 RCX:
    00000000a189a188
    [  233.048393] RDX: 000000000000a189 RSI: ffffffff8108ad32 RDI:
    ffffffff810d30f9
    [  233.048393] RBP: ffff88000facbcb8 R08: 0000000000000002 R09:
    ffffffff843846f0
    [  233.048393] R10: ffffffff810ae37c R11: 0000000000000908 R12:
    0000000000000202
    [  233.048393] R13: ffffffff823dbd5a R14: ffff88000ec5bea8 R15:
    ffffffff8363c780
    [  233.048393] FS:  00007faa6899c700(0000) GS:ffff88001f200000(0000)
    knlGS:0000000000000000
    [  233.048393] CS:  0010 DS: 0000 ES: 0000 CR0: 000000008005003b
    [  233.048393] CR2: 00007faa6841019c CR3: 0000000012c82000 CR4:
    00000000000006f0
    [  233.048393] DR0: 0000000000000000 DR1: 0000000000000000 DR2:
    0000000000000000
    [  233.048393] DR3: 0000000000000000 DR6: 00000000ffff0ff0 DR7:
    0000000000000400
    [  233.048393] Process trinity-watchdo (pid: 3929, threadinfo
    ffff88000faca000, task ffff88000faec600)
    [  233.048393] Stack:
    [  233.048393]  0000000000000000 0000ea6000000bb8 ffff88000facbce8
    ffffffff8116ad81
    [  233.048393]  ffff88000ff588a0 ffff88000ff58850 ffff88000ff588a0
    0000000000000000
    [  233.048393]  ffff88000facbd08 ffffffff823dbd5a ffffffff823dbcb0
    ffff88000ff58850
    [  233.048393] Call Trace:
    [  233.048393]  [<ffffffff8116ad81>] kfree+0x5f/0xca
    [  233.048393]  [<ffffffff823dbd5a>] inet_sock_destruct+0xaa/0x13c
    [  233.048393]  [<ffffffff823dbcb0>] ? inet_sk_rebuild_header
    +0x319/0x319
    [  233.048393]  [<ffffffff8231c307>] __sk_free+0x21/0x14b
    [  233.048393]  [<ffffffff8231c4bd>] sk_free+0x26/0x2a
    [  233.048393]  [<ffffffff825372db>] sctp_close+0x215/0x224
    [  233.048393]  [<ffffffff810d6835>] ? lock_release+0x16f/0x1b9
    [  233.048393]  [<ffffffff823daf12>] inet_release+0x7e/0x85
    [  233.048393]  [<ffffffff82317d15>] sock_release+0x1f/0x77
    [  233.048393]  [<ffffffff82317d94>] sock_close+0x27/0x2b
    [  233.048393]  [<ffffffff81173bbe>] __fput+0x101/0x20a
    [  233.048393]  [<ffffffff81173cd5>] ____fput+0xe/0x10
    [  233.048393]  [<ffffffff810a3794>] task_work_run+0x5d/0x75
    [  233.048393]  [<ffffffff8108da70>] do_exit+0x290/0x7f5
    [  233.048393]  [<ffffffff82707415>] ? retint_swapgs+0x13/0x1b
    [  233.048393]  [<ffffffff8108e23f>] do_group_exit+0x7b/0xba
    [  233.048393]  [<ffffffff8108e295>] sys_exit_group+0x17/0x17
    [  233.048393]  [<ffffffff8270de10>] tracesys+0xdd/0xe2
    [  233.048393] Code: 59 01 5d c3 55 48 89 e5 53 41 50 0f 1f 44 00 00 48
    89 fb e8 d4 b0 f0 ff 84 c0 75 11 48 89 de 48 c7 c7 fc fa f7 82 e8 0d 0f
    57 01 <0f> 0b 5f 5b 5d c3 55 48 89 e5 0f 1f 44 00 00 48 63 87 d8 00 00
    [  233.048393] RIP  [<ffffffff81169653>] kfree_debugcheck+0x27/0x2d
    [  233.048393]  RSP <ffff88000facbca8>
    
    Reported-by: Fengguang Wu <wfg@linux.intel.com>
    Tested-by: Fengguang Wu <wfg@linux.intel.com>
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Cc: "H.K. Jerry Chu" <hkchu@google.com>
    Acked-by: Neal Cardwell <ncardwell@google.com>
    Acked-by: H.K. Jerry Chu <hkchu@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 4f70ef0b946d..845372b025f6 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -149,11 +149,8 @@ void inet_sock_destruct(struct sock *sk)
 		pr_err("Attempt to release alive inet socket %p\n", sk);
 		return;
 	}
-	if (sk->sk_type == SOCK_STREAM) {
-		struct fastopen_queue *fastopenq =
-			inet_csk(sk)->icsk_accept_queue.fastopenq;
-		kfree(fastopenq);
-	}
+	if (sk->sk_protocol == IPPROTO_TCP)
+		kfree(inet_csk(sk)->icsk_accept_queue.fastopenq);
 
 	WARN_ON(atomic_read(&sk->sk_rmem_alloc));
 	WARN_ON(atomic_read(&sk->sk_wmem_alloc));

commit 8336886f786fdacbc19b719c1f7ea91eb70706d4
Author: Jerry Chu <hkchu@google.com>
Date:   Fri Aug 31 12:29:12 2012 +0000

    tcp: TCP Fast Open Server - support TFO listeners
    
    This patch builds on top of the previous patch to add the support
    for TFO listeners. This includes -
    
    1. allocating, properly initializing, and managing the per listener
    fastopen_queue structure when TFO is enabled
    
    2. changes to the inet_csk_accept code to support TFO. E.g., the
    request_sock can no longer be freed upon accept(), not until 3WHS
    finishes
    
    3. allowing a TCP_SYN_RECV socket to properly poll() and sendmsg()
    if it's a TFO socket
    
    4. properly closing a TFO listener, and a TFO socket before 3WHS
    finishes
    
    5. supporting TCP_FASTOPEN socket option
    
    6. modifying tcp_check_req() to use to check a TFO socket as well
    as request_sock
    
    7. supporting TCP's TFO cookie option
    
    8. adding a new SYN-ACK retransmit handler to use the timer directly
    off the TFO socket rather than the listener socket. Note that TFO
    server side will not retransmit anything other than SYN-ACK until
    the 3WHS is completed.
    
    The patch also contains an important function
    "reqsk_fastopen_remove()" to manage the somewhat complex relation
    between a listener, its request_sock, and the corresponding child
    socket. See the comment above the function for the detail.
    
    Signed-off-by: H.K. Jerry Chu <hkchu@google.com>
    Cc: Yuchung Cheng <ycheng@google.com>
    Cc: Neal Cardwell <ncardwell@google.com>
    Cc: Eric Dumazet <edumazet@google.com>
    Cc: Tom Herbert <therbert@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 6681ccf5c3ee..4f70ef0b946d 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -149,6 +149,11 @@ void inet_sock_destruct(struct sock *sk)
 		pr_err("Attempt to release alive inet socket %p\n", sk);
 		return;
 	}
+	if (sk->sk_type == SOCK_STREAM) {
+		struct fastopen_queue *fastopenq =
+			inet_csk(sk)->icsk_accept_queue.fastopenq;
+		kfree(fastopenq);
+	}
 
 	WARN_ON(atomic_read(&sk->sk_rmem_alloc));
 	WARN_ON(atomic_read(&sk->sk_wmem_alloc));
@@ -212,6 +217,26 @@ int inet_listen(struct socket *sock, int backlog)
 	 * we can only allow the backlog to be adjusted.
 	 */
 	if (old_state != TCP_LISTEN) {
+		/* Check special setups for testing purpose to enable TFO w/o
+		 * requiring TCP_FASTOPEN sockopt.
+		 * Note that only TCP sockets (SOCK_STREAM) will reach here.
+		 * Also fastopenq may already been allocated because this
+		 * socket was in TCP_LISTEN state previously but was
+		 * shutdown() (rather than close()).
+		 */
+		if ((sysctl_tcp_fastopen & TFO_SERVER_ENABLE) != 0 &&
+		    inet_csk(sk)->icsk_accept_queue.fastopenq == NULL) {
+			if ((sysctl_tcp_fastopen & TFO_SERVER_WO_SOCKOPT1) != 0)
+				err = fastopen_init_queue(sk, backlog);
+			else if ((sysctl_tcp_fastopen &
+				  TFO_SERVER_WO_SOCKOPT2) != 0)
+				err = fastopen_init_queue(sk,
+				    ((uint)sysctl_tcp_fastopen) >> 16);
+			else
+				err = 0;
+			if (err)
+				goto out;
+		}
 		err = inet_csk_listen_start(sk, backlog);
 		if (err)
 			goto out;
@@ -701,7 +726,8 @@ int inet_accept(struct socket *sock, struct socket *newsock, int flags)
 
 	sock_rps_record_flow(sk2);
 	WARN_ON(!((1 << sk2->sk_state) &
-		  (TCPF_ESTABLISHED | TCPF_CLOSE_WAIT | TCPF_CLOSE)));
+		  (TCPF_ESTABLISHED | TCPF_SYN_RECV |
+		  TCPF_CLOSE_WAIT | TCPF_CLOSE)));
 
 	sock_graft(sk2, newsock);
 

commit a9e050f4e7f9d36afe0dcc0bddba864ee442715e
Author: Eric Dumazet <edumazet@google.com>
Date:   Sun Aug 5 22:34:50 2012 +0000

    net: tcp: GRO should be ECN friendly
    
    While doing TCP ECN tests, I discovered GRO was reordering packets if it
    receives one packet with CE set, while previous packets in same NAPI run
    have ECT(0) for the same flow :
    
    09:25:25.857620 IP (tos 0x2,ECT(0), ttl 64, id 27893, offset 0, flags
    [DF], proto TCP (6), length 4396)
        172.30.42.19.54550 > 172.30.42.13.44139: Flags [.], seq
    233801:238145, ack 1, win 115, options [nop,nop,TS val 3397779 ecr
    1990627], length 4344
    
    09:25:25.857626 IP (tos 0x3,CE, ttl 64, id 27892, offset 0, flags [DF],
    proto TCP (6), length 1500)
        172.30.42.19.54550 > 172.30.42.13.44139: Flags [.], seq
    232353:233801, ack 1, win 115, options [nop,nop,TS val 3397779 ecr
    1990627], length 1448
    
    09:25:25.857638 IP (tos 0x0, ttl 64, id 34581, offset 0, flags [DF],
    proto TCP (6), length 64)
        172.30.42.13.44139 > 172.30.42.19.54550: Flags [.], cksum 0xac8f
    (incorrect -> 0xca69), ack 232353, win 1271, options [nop,nop,TS val
    1990627 ecr 3397779,nop,nop,sack 1 {233801:238145}], length 0
    
    We have two problems here :
    
    1) GRO reorders packets
    
      If NIC gave packet1, then packet2, which happen to be from "different
    flows"  GRO feeds stack with packet2, then packet1. I have yet to
    understand how to solve this problem.
    
    2) GRO is not ECN friendly
    
    Delivering packets out of order makes TCP stack not as fast as it could
    be.
    
    In this patch I suggest we make the tos test not part of the 'same_flow'
    determination, but part of the 'should flush' logic
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Cc: Herbert Xu <herbert@gondor.apana.org.au>
    Acked-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index fe4582ca969a..6681ccf5c3ee 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1364,7 +1364,7 @@ static struct sk_buff **inet_gro_receive(struct sk_buff **head,
 	if (*(u8 *)iph != 0x45)
 		goto out_unlock;
 
-	if (unlikely(ip_fast_csum((u8 *)iph, iph->ihl)))
+	if (unlikely(ip_fast_csum((u8 *)iph, 5)))
 		goto out_unlock;
 
 	id = ntohl(*(__be32 *)&iph->id);
@@ -1380,7 +1380,6 @@ static struct sk_buff **inet_gro_receive(struct sk_buff **head,
 		iph2 = ip_hdr(p);
 
 		if ((iph->protocol ^ iph2->protocol) |
-		    (iph->tos ^ iph2->tos) |
 		    ((__force u32)iph->saddr ^ (__force u32)iph2->saddr) |
 		    ((__force u32)iph->daddr ^ (__force u32)iph2->daddr)) {
 			NAPI_GRO_CB(p)->same_flow = 0;
@@ -1390,6 +1389,7 @@ static struct sk_buff **inet_gro_receive(struct sk_buff **head,
 		/* All fields must match except length and checksum. */
 		NAPI_GRO_CB(p)->flush |=
 			(iph->ttl ^ iph2->ttl) |
+			(iph->tos ^ iph2->tos) |
 			((u16)(ntohs(iph2->id) + NAPI_GRO_CB(p)->count) ^ id);
 
 		NAPI_GRO_CB(p)->flush |= flush;

commit cf60af03ca4e71134206809ea892e49b92a88896
Author: Yuchung Cheng <ycheng@google.com>
Date:   Thu Jul 19 06:43:09 2012 +0000

    net-tcp: Fast Open client - sendmsg(MSG_FASTOPEN)
    
    sendmsg() (or sendto()) with MSG_FASTOPEN is a combo of connect(2)
    and write(2). The application should replace connect() with it to
    send data in the opening SYN packet.
    
    For blocking socket, sendmsg() blocks until all the data are buffered
    locally and the handshake is completed like connect() call. It
    returns similar errno like connect() if the TCP handshake fails.
    
    For non-blocking socket, it returns the number of bytes queued (and
    transmitted in the SYN-data packet) if cookie is available. If cookie
    is not available, it transmits a data-less SYN packet with Fast Open
    cookie request option and returns -EINPROGRESS like connect().
    
    Using MSG_FASTOPEN on connecting or connected socket will result in
    simlar errno like repeating connect() calls. Therefore the application
    should only use this flag on new sockets.
    
    The buffer size of sendmsg() is independent of the MSS of the connection.
    
    Signed-off-by: Yuchung Cheng <ycheng@google.com>
    Acked-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index edc414625be2..fe4582ca969a 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -585,8 +585,8 @@ static long inet_wait_for_connect(struct sock *sk, long timeo, int writebias)
  *	Connect to a remote host. There is regrettably still a little
  *	TCP 'magic' in here.
  */
-int inet_stream_connect(struct socket *sock, struct sockaddr *uaddr,
-			int addr_len, int flags)
+int __inet_stream_connect(struct socket *sock, struct sockaddr *uaddr,
+			  int addr_len, int flags)
 {
 	struct sock *sk = sock->sk;
 	int err;
@@ -595,8 +595,6 @@ int inet_stream_connect(struct socket *sock, struct sockaddr *uaddr,
 	if (addr_len < sizeof(uaddr->sa_family))
 		return -EINVAL;
 
-	lock_sock(sk);
-
 	if (uaddr->sa_family == AF_UNSPEC) {
 		err = sk->sk_prot->disconnect(sk, flags);
 		sock->state = err ? SS_DISCONNECTING : SS_UNCONNECTED;
@@ -663,7 +661,6 @@ int inet_stream_connect(struct socket *sock, struct sockaddr *uaddr,
 	sock->state = SS_CONNECTED;
 	err = 0;
 out:
-	release_sock(sk);
 	return err;
 
 sock_error:
@@ -673,6 +670,18 @@ int inet_stream_connect(struct socket *sock, struct sockaddr *uaddr,
 		sock->state = SS_DISCONNECTING;
 	goto out;
 }
+EXPORT_SYMBOL(__inet_stream_connect);
+
+int inet_stream_connect(struct socket *sock, struct sockaddr *uaddr,
+			int addr_len, int flags)
+{
+	int err;
+
+	lock_sock(sock->sk);
+	err = __inet_stream_connect(sock, uaddr, addr_len, flags);
+	release_sock(sock->sk);
+	return err;
+}
 EXPORT_SYMBOL(inet_stream_connect);
 
 /*

commit 783237e8daf13481ee234997cbbbb823872ac388
Author: Yuchung Cheng <ycheng@google.com>
Date:   Thu Jul 19 06:43:07 2012 +0000

    net-tcp: Fast Open client - sending SYN-data
    
    This patch implements sending SYN-data in tcp_connect(). The data is
    from tcp_sendmsg() with flag MSG_FASTOPEN (implemented in a later patch).
    
    The length of the cookie in tcp_fastopen_req, init'd to 0, controls the
    type of the SYN. If the cookie is not cached (len==0), the host sends
    data-less SYN with Fast Open cookie request option to solicit a cookie
    from the remote. If cookie is not available (len > 0), the host sends
    a SYN-data with Fast Open cookie option. If cookie length is negative,
      the SYN will not include any Fast Open option (for fall back operations).
    
    To deal with middleboxes that may drop SYN with data or experimental TCP
    option, the SYN-data is only sent once. SYN retransmits do not include
    data or Fast Open options. The connection will fall back to regular TCP
    handshake.
    
    Signed-off-by: Yuchung Cheng <ycheng@google.com>
    Acked-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 07a02f6e9696..edc414625be2 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -556,11 +556,12 @@ int inet_dgram_connect(struct socket *sock, struct sockaddr *uaddr,
 }
 EXPORT_SYMBOL(inet_dgram_connect);
 
-static long inet_wait_for_connect(struct sock *sk, long timeo)
+static long inet_wait_for_connect(struct sock *sk, long timeo, int writebias)
 {
 	DEFINE_WAIT(wait);
 
 	prepare_to_wait(sk_sleep(sk), &wait, TASK_INTERRUPTIBLE);
+	sk->sk_write_pending += writebias;
 
 	/* Basic assumption: if someone sets sk->sk_err, he _must_
 	 * change state of the socket from TCP_SYN_*.
@@ -576,6 +577,7 @@ static long inet_wait_for_connect(struct sock *sk, long timeo)
 		prepare_to_wait(sk_sleep(sk), &wait, TASK_INTERRUPTIBLE);
 	}
 	finish_wait(sk_sleep(sk), &wait);
+	sk->sk_write_pending -= writebias;
 	return timeo;
 }
 
@@ -634,8 +636,12 @@ int inet_stream_connect(struct socket *sock, struct sockaddr *uaddr,
 	timeo = sock_sndtimeo(sk, flags & O_NONBLOCK);
 
 	if ((1 << sk->sk_state) & (TCPF_SYN_SENT | TCPF_SYN_RECV)) {
+		int writebias = (sk->sk_protocol == IPPROTO_TCP) &&
+				tcp_sk(sk)->fastopen_req &&
+				tcp_sk(sk)->fastopen_req->data ? 1 : 0;
+
 		/* Error code is set above */
-		if (!timeo || !inet_wait_for_connect(sk, timeo))
+		if (!timeo || !inet_wait_for_connect(sk, timeo, writebias))
 			goto out;
 
 		err = sock_intr_errno(timeo);

commit 41063e9dd11956f2d285e12e4342e1d232ba0ea2
Author: David S. Miller <davem@davemloft.net>
Date:   Tue Jun 19 21:22:05 2012 -0700

    ipv4: Early TCP socket demux.
    
    Input packet processing for local sockets involves two major demuxes.
    One for the route and one for the socket.
    
    But we can optimize this down to one demux for certain kinds of local
    sockets.
    
    Currently we only do this for established TCP sockets, but it could
    at least in theory be expanded to other kinds of connections.
    
    If a TCP socket is established then it's identity is fully specified.
    
    This means that whatever input route was used during the three-way
    handshake must work equally well for the rest of the connection since
    the keys will not change.
    
    Once we move to established state, we cache the receive packet's input
    route to use later.
    
    Like the existing cached route in sk->sk_dst_cache used for output
    packets, we have to check for route invalidations using dst->obsolete
    and dst->ops->check().
    
    Early demux occurs outside of a socket locked section, so when a route
    invalidation occurs we defer the fixup of sk->sk_rx_dst until we are
    actually inside of established state packet processing and thus have
    the socket locked.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 85a3b1763136..07a02f6e9696 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -157,6 +157,7 @@ void inet_sock_destruct(struct sock *sk)
 
 	kfree(rcu_dereference_protected(inet->inet_opt, 1));
 	dst_release(rcu_dereference_check(sk->sk_dst_cache, 1));
+	dst_release(sk->sk_rx_dst);
 	sk_refcnt_debug_dec(sk);
 }
 EXPORT_SYMBOL(inet_sock_destruct);
@@ -1518,14 +1519,15 @@ static const struct net_protocol igmp_protocol = {
 #endif
 
 static const struct net_protocol tcp_protocol = {
-	.handler =	tcp_v4_rcv,
-	.err_handler =	tcp_v4_err,
-	.gso_send_check = tcp_v4_gso_send_check,
-	.gso_segment =	tcp_tso_segment,
-	.gro_receive =	tcp4_gro_receive,
-	.gro_complete =	tcp4_gro_complete,
-	.no_policy =	1,
-	.netns_ok =	1,
+	.early_demux	=	tcp_v4_early_demux,
+	.handler	=	tcp_v4_rcv,
+	.err_handler	=	tcp_v4_err,
+	.gso_send_check	=	tcp_v4_gso_send_check,
+	.gso_segment	=	tcp_tso_segment,
+	.gro_receive	=	tcp4_gro_receive,
+	.gro_complete	=	tcp4_gro_complete,
+	.no_policy	=	1,
+	.netns_ok	=	1,
 };
 
 static const struct net_protocol udp_protocol = {

commit f9242b6b28d61295f2bf7e8adfb1060b382e5381
Author: David S. Miller <davem@davemloft.net>
Date:   Tue Jun 19 18:56:21 2012 -0700

    inet: Sanitize inet{,6} protocol demux.
    
    Don't pretend that inet_protos[] and inet6_protos[] are hashes, thay
    are just a straight arrays.  Remove all unnecessary hash masking.
    
    Document MAX_INET_PROTOS.
    
    Use RAW_HTABLE_SIZE when appropriate.
    
    Reported-by: Ben Hutchings <bhutchings@solarflare.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index e4e8e00a2c91..85a3b1763136 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -242,20 +242,18 @@ void build_ehash_secret(void)
 }
 EXPORT_SYMBOL(build_ehash_secret);
 
-static inline int inet_netns_ok(struct net *net, int protocol)
+static inline int inet_netns_ok(struct net *net, __u8 protocol)
 {
-	int hash;
 	const struct net_protocol *ipprot;
 
 	if (net_eq(net, &init_net))
 		return 1;
 
-	hash = protocol & (MAX_INET_PROTOS - 1);
-	ipprot = rcu_dereference(inet_protos[hash]);
-
-	if (ipprot == NULL)
+	ipprot = rcu_dereference(inet_protos[protocol]);
+	if (ipprot == NULL) {
 		/* raw IP is OK */
 		return 1;
+	}
 	return ipprot->netns_ok;
 }
 
@@ -1216,8 +1214,8 @@ EXPORT_SYMBOL(inet_sk_rebuild_header);
 
 static int inet_gso_send_check(struct sk_buff *skb)
 {
-	const struct iphdr *iph;
 	const struct net_protocol *ops;
+	const struct iphdr *iph;
 	int proto;
 	int ihl;
 	int err = -EINVAL;
@@ -1236,7 +1234,7 @@ static int inet_gso_send_check(struct sk_buff *skb)
 	__skb_pull(skb, ihl);
 	skb_reset_transport_header(skb);
 	iph = ip_hdr(skb);
-	proto = iph->protocol & (MAX_INET_PROTOS - 1);
+	proto = iph->protocol;
 	err = -EPROTONOSUPPORT;
 
 	rcu_read_lock();
@@ -1253,8 +1251,8 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb,
 	netdev_features_t features)
 {
 	struct sk_buff *segs = ERR_PTR(-EINVAL);
-	struct iphdr *iph;
 	const struct net_protocol *ops;
+	struct iphdr *iph;
 	int proto;
 	int ihl;
 	int id;
@@ -1286,7 +1284,7 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb,
 	skb_reset_transport_header(skb);
 	iph = ip_hdr(skb);
 	id = ntohs(iph->id);
-	proto = iph->protocol & (MAX_INET_PROTOS - 1);
+	proto = iph->protocol;
 	segs = ERR_PTR(-EPROTONOSUPPORT);
 
 	rcu_read_lock();
@@ -1340,7 +1338,7 @@ static struct sk_buff **inet_gro_receive(struct sk_buff **head,
 			goto out;
 	}
 
-	proto = iph->protocol & (MAX_INET_PROTOS - 1);
+	proto = iph->protocol;
 
 	rcu_read_lock();
 	ops = rcu_dereference(inet_protos[proto]);
@@ -1398,11 +1396,11 @@ static struct sk_buff **inet_gro_receive(struct sk_buff **head,
 
 static int inet_gro_complete(struct sk_buff *skb)
 {
-	const struct net_protocol *ops;
+	__be16 newlen = htons(skb->len - skb_network_offset(skb));
 	struct iphdr *iph = ip_hdr(skb);
-	int proto = iph->protocol & (MAX_INET_PROTOS - 1);
+	const struct net_protocol *ops;
+	int proto = iph->protocol;
 	int err = -ENOSYS;
-	__be16 newlen = htons(skb->len - skb_network_offset(skb));
 
 	csum_replace2(&iph->check, iph->tot_len, newlen);
 	iph->tot_len = newlen;

commit e3192690a3c889767d1161b228374f4926d92af0
Author: Joe Perches <joe@perches.com>
Date:   Sun Jun 3 17:41:40 2012 +0000

    net: Remove casts to same type
    
    Adding casts of objects to the same type is unnecessary
    and confusing for a human reader.
    
    For example, this cast:
    
            int y;
            int *p = (int *)&y;
    
    I used the coccinelle script below to find and remove these
    unnecessary casts.  I manually removed the conversions this
    script produces of casts with __force and __user.
    
    @@
    type T;
    T *p;
    @@
    
    -       (T *)p
    +       p
    
    Signed-off-by: Joe Perches <joe@perches.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index c8f7aee587d1..e4e8e00a2c91 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -553,7 +553,7 @@ int inet_dgram_connect(struct socket *sock, struct sockaddr *uaddr,
 
 	if (!inet_sk(sk)->inet_num && inet_autobind(sk))
 		return -EAGAIN;
-	return sk->sk_prot->connect(sk, (struct sockaddr *)uaddr, addr_len);
+	return sk->sk_prot->connect(sk, uaddr, addr_len);
 }
 EXPORT_SYMBOL(inet_dgram_connect);
 

commit 4a17fd5229c1b6066aa478f6b690f8293ce811a1
Author: Pavel Emelyanov <xemul@parallels.com>
Date:   Thu Apr 19 03:39:36 2012 +0000

    sock: Introduce named constants for sk_reuse
    
    Name them in a "backward compatible" manner, i.e. reuse or not
    are still 1 and 0 respectively. The reuse value of 2 means that
    the socket with it will forcibly reuse everyone else's port.
    
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 3744c1c0af5a..c8f7aee587d1 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -350,7 +350,7 @@ static int inet_create(struct net *net, struct socket *sock, int protocol,
 	err = 0;
 	sk->sk_no_check = answer_no_check;
 	if (INET_PROTOSW_REUSE & answer_flags)
-		sk->sk_reuse = 1;
+		sk->sk_reuse = SK_CAN_REUSE;
 
 	inet = inet_sk(sk);
 	inet->is_icsk = (INET_PROTOSW_ICSK & answer_flags) != 0;

commit 5e73ea1a31c3612aa6dfe44f864ca5b7b6a4cff9
Author: Daniel Baluta <dbaluta@ixiacom.com>
Date:   Sun Apr 15 01:34:41 2012 +0000

    ipv4: fix checkpatch errors
    
    Fix checkpatch errors of the following type:
            * ERROR: "foo * bar" should be "foo *bar"
            * ERROR: "(foo*)" should be "(foo *)"
    
    Signed-off-by: Daniel Baluta <dbaluta@ixiacom.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 10e3751466b5..3744c1c0af5a 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -541,7 +541,7 @@ int inet_bind(struct socket *sock, struct sockaddr *uaddr, int addr_len)
 }
 EXPORT_SYMBOL(inet_bind);
 
-int inet_dgram_connect(struct socket *sock, struct sockaddr * uaddr,
+int inet_dgram_connect(struct socket *sock, struct sockaddr *uaddr,
 		       int addr_len, int flags)
 {
 	struct sock *sk = sock->sk;

commit 9ffc93f203c18a70623f21950f1dd473c9ec48cd
Author: David Howells <dhowells@redhat.com>
Date:   Wed Mar 28 18:30:03 2012 +0100

    Remove all #inclusions of asm/system.h
    
    Remove all #inclusions of asm/system.h preparatory to splitting and killing
    it.  Performed with the following command:
    
    perl -p -i -e 's!^#\s*include\s*<asm/system[.]h>.*\n!!' `grep -Irl '^#\s*include\s*<asm/system[.]h>' *`
    
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index fdf49fd44bb4..10e3751466b5 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -91,7 +91,6 @@
 #include <linux/slab.h>
 
 #include <asm/uaccess.h>
-#include <asm/system.h>
 
 #include <linux/inet.h>
 #include <linux/igmp.h>

commit afd465030acb4098abcb6b965a5aebc7ea2209e0
Author: Joe Perches <joe@perches.com>
Date:   Mon Mar 12 07:03:32 2012 +0000

    net: ipv4: Standardize prefixes for message logging
    
    Add #define pr_fmt(fmt) as appropriate.
    
    Add "IPv4: ", "TCP: ", and "IPsec: " to appropriate files.
    Standardize on "UDPLite: " for appropriate uses.
    Some prefixes were previously "UDPLITE: " and "UDP-Lite: ".
    
    Add KBUILD_MODNAME ": " to icmp and gre.
    Remove embedded prefixes as appropriate.
    
    Add missing "\n" to pr_info in gre.c.
    
    Signed-off-by: Joe Perches <joe@perches.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index b7a946611f2f..fdf49fd44bb4 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -65,6 +65,8 @@
  *		2 of the License, or (at your option) any later version.
  */
 
+#define pr_fmt(fmt) "IPv4: " fmt
+
 #include <linux/err.h>
 #include <linux/errno.h>
 #include <linux/types.h>

commit 058bd4d2a4ff0aaa4a5381c67e776729d840c785
Author: Joe Perches <joe@perches.com>
Date:   Sun Mar 11 18:36:11 2012 +0000

    net: Convert printks to pr_<level>
    
    Use a more current kernel messaging style.
    
    Convert a printk block to print_hex_dump.
    Coalesce formats, align arguments.
    Use %s, __func__ instead of embedding function names.
    
    Some messages that were prefixed with <foo>_close are
    now prefixed with <foo>_fini.  Some ah4 and esp messages
    are now not prefixed with "ip ".
    
    The intent of this patch is to later add something like
      #define pr_fmt(fmt) "IPv4: " fmt.
    to standardize the output messages.
    
    Text size is trivially reduced. (x86-32 allyesconfig)
    
    $ size net/ipv4/built-in.o*
       text    data     bss     dec     hex filename
     887888   31558  249696 1169142  11d6f6 net/ipv4/built-in.o.new
     887934   31558  249800 1169292  11d78c net/ipv4/built-in.o.old
    
    Signed-off-by: Joe Perches <joe@perches.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index e588a34e85c2..b7a946611f2f 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1085,13 +1085,11 @@ void inet_register_protosw(struct inet_protosw *p)
 	return;
 
 out_permanent:
-	printk(KERN_ERR "Attempt to override permanent protocol %d.\n",
-	       protocol);
+	pr_err("Attempt to override permanent protocol %d\n", protocol);
 	goto out;
 
 out_illegal:
-	printk(KERN_ERR
-	       "Ignoring attempt to register invalid socket type %d.\n",
+	pr_err("Ignoring attempt to register invalid socket type %d\n",
 	       p->type);
 	goto out;
 }
@@ -1100,8 +1098,7 @@ EXPORT_SYMBOL(inet_register_protosw);
 void inet_unregister_protosw(struct inet_protosw *p)
 {
 	if (INET_PROTOSW_PERMANENT & p->flags) {
-		printk(KERN_ERR
-		       "Attempt to unregister permanent protocol %d.\n",
+		pr_err("Attempt to unregister permanent protocol %d\n",
 		       p->protocol);
 	} else {
 		spin_lock_bh(&inetsw_lock);
@@ -1150,8 +1147,8 @@ static int inet_sk_reselect_saddr(struct sock *sk)
 		return 0;
 
 	if (sysctl_ip_dynaddr > 1) {
-		printk(KERN_INFO "%s(): shifting inet->saddr from %pI4 to %pI4\n",
-		       __func__, &old_saddr, &new_saddr);
+		pr_info("%s(): shifting inet->saddr from %pI4 to %pI4\n",
+			__func__, &old_saddr, &new_saddr);
 	}
 
 	inet->inet_saddr = inet->inet_rcv_saddr = new_saddr;
@@ -1680,14 +1677,14 @@ static int __init inet_init(void)
 	 */
 
 	if (inet_add_protocol(&icmp_protocol, IPPROTO_ICMP) < 0)
-		printk(KERN_CRIT "inet_init: Cannot add ICMP protocol\n");
+		pr_crit("%s: Cannot add ICMP protocol\n", __func__);
 	if (inet_add_protocol(&udp_protocol, IPPROTO_UDP) < 0)
-		printk(KERN_CRIT "inet_init: Cannot add UDP protocol\n");
+		pr_crit("%s: Cannot add UDP protocol\n", __func__);
 	if (inet_add_protocol(&tcp_protocol, IPPROTO_TCP) < 0)
-		printk(KERN_CRIT "inet_init: Cannot add TCP protocol\n");
+		pr_crit("%s: Cannot add TCP protocol\n", __func__);
 #ifdef CONFIG_IP_MULTICAST
 	if (inet_add_protocol(&igmp_protocol, IPPROTO_IGMP) < 0)
-		printk(KERN_CRIT "inet_init: Cannot add IGMP protocol\n");
+		pr_crit("%s: Cannot add IGMP protocol\n", __func__);
 #endif
 
 	/* Register the socket-side information for inet_create. */
@@ -1734,14 +1731,14 @@ static int __init inet_init(void)
 	 */
 #if defined(CONFIG_IP_MROUTE)
 	if (ip_mr_init())
-		printk(KERN_CRIT "inet_init: Cannot init ipv4 mroute\n");
+		pr_crit("%s: Cannot init ipv4 mroute\n", __func__);
 #endif
 	/*
 	 *	Initialise per-cpu ipv4 mibs
 	 */
 
 	if (init_ipv4_mibs())
-		printk(KERN_CRIT "inet_init: Cannot init ipv4 mibs\n");
+		pr_crit("%s: Cannot init ipv4 mibs\n", __func__);
 
 	ipv4_proc_init();
 

commit 4c507d2897bd9be810b3403ade73b04cf6fdfd4a
Author: Jiri Benc <jbenc@redhat.com>
Date:   Thu Feb 9 09:35:49 2012 +0000

    net: implement IP_RECVTOS for IP_PKTOPTIONS
    
    Currently, it is not easily possible to get TOS/DSCP value of packets from
    an incoming TCP stream. The mechanism is there, IP_PKTOPTIONS getsockopt
    with IP_RECVTOS set, the same way as incoming TTL can be queried. This is
    not actually implemented for TOS, though.
    
    This patch adds this functionality, both for IPv4 (IP_PKTOPTIONS) and IPv6
    (IPV6_2292PKTOPTIONS). For IPv4, like in the IP_RECVTTL case, the value of
    the TOS field is stored from the other party's ACK.
    
    This is needed for proxies which require DSCP transparency. One such example
    is at http://zph.bratcheda.org/.
    
    Signed-off-by: Jiri Benc <jbenc@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index f7b5670744f0..e588a34e85c2 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -381,6 +381,7 @@ static int inet_create(struct net *net, struct socket *sock, int protocol,
 	inet->mc_all	= 1;
 	inet->mc_index	= 0;
 	inet->mc_list	= NULL;
+	inet->rcv_tos	= 0;
 
 	sk_refcnt_debug_inc(sk);
 

commit 3dc43e3e4d0b52197d3205214fe8f162f9e0c334
Author: Glauber Costa <glommer@parallels.com>
Date:   Sun Dec 11 21:47:05 2011 +0000

    per-netns ipv4 sysctl_tcp_mem
    
    This patch allows each namespace to independently set up
    its levels for tcp memory pressure thresholds. This patch
    alone does not buy much: we need to make this values
    per group of process somehow. This is achieved in the
    patches that follows in this patchset.
    
    Signed-off-by: Glauber Costa <glommer@parallels.com>
    Reviewed-by: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    CC: David S. Miller <davem@davemloft.net>
    CC: Eric W. Biederman <ebiederm@xmission.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 15dc4c4828de..f7b5670744f0 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1672,6 +1672,8 @@ static int __init inet_init(void)
 	ip_static_sysctl_init();
 #endif
 
+	tcp_prot.sysctl_mem = init_net.ipv4.sysctl_tcp_mem;
+
 	/*
 	 *	Add all the base protocols.
 	 */

commit c8f44affb7244f2ac3e703cab13d55ede27621bb
Author: Michał Mirosław <mirq-linux@rere.qmqm.pl>
Date:   Tue Nov 15 15:29:55 2011 +0000

    net: introduce and use netdev_features_t for device features sets
    
    v2:     add couple missing conversions in drivers
            split unexporting netdev_fix_features()
            implemented %pNF
            convert sock::sk_route_(no?)caps
    
    Signed-off-by: Michał Mirosław <mirq-linux@rere.qmqm.pl>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index b2bbcd0ebd19..15dc4c4828de 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1250,7 +1250,8 @@ static int inet_gso_send_check(struct sk_buff *skb)
 	return err;
 }
 
-static struct sk_buff *inet_gso_segment(struct sk_buff *skb, u32 features)
+static struct sk_buff *inet_gso_segment(struct sk_buff *skb,
+	netdev_features_t features)
 {
 	struct sk_buff *segs = ERR_PTR(-EINVAL);
 	struct iphdr *iph;

commit acb32ba3dee66d58704caeeb8c6ff95f60efdc66
Author: Eric Dumazet <eric.dumazet@gmail.com>
Date:   Tue Nov 8 13:04:43 2011 +0000

    ipv4: reduce percpu needs for icmpmsg mibs
    
    Reading /proc/net/snmp on a machine with a lot of cpus is very expensive
    (can be ~88000 us).
    
    This is because ICMPMSG MIB uses 4096 bytes per cpu, and folding values
    for all possible cpus can read 16 Mbytes of memory.
    
    ICMP messages are not considered as fast path on a typical server, and
    eventually few cpus handle them anyway. We can afford an atomic
    operation instead of using percpu data.
    
    This saves 4096 bytes per cpu and per network namespace.
    
    Signed-off-by: Eric Dumazet <eric.dumazet@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 1b5096a9875a..b2bbcd0ebd19 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1572,9 +1572,9 @@ static __net_init int ipv4_mib_init_net(struct net *net)
 			  sizeof(struct icmp_mib),
 			  __alignof__(struct icmp_mib)) < 0)
 		goto err_icmp_mib;
-	if (snmp_mib_init((void __percpu **)net->mib.icmpmsg_statistics,
-			  sizeof(struct icmpmsg_mib),
-			  __alignof__(struct icmpmsg_mib)) < 0)
+	net->mib.icmpmsg_statistics = kzalloc(sizeof(struct icmpmsg_mib),
+					      GFP_KERNEL);
+	if (!net->mib.icmpmsg_statistics)
 		goto err_icmpmsg_mib;
 
 	tcp_mib_init(net);
@@ -1598,7 +1598,7 @@ static __net_init int ipv4_mib_init_net(struct net *net)
 
 static __net_exit void ipv4_mib_exit_net(struct net *net)
 {
-	snmp_mib_free((void __percpu **)net->mib.icmpmsg_statistics);
+	kfree(net->mib.icmpmsg_statistics);
 	snmp_mib_free((void __percpu **)net->mib.icmp_statistics);
 	snmp_mib_free((void __percpu **)net->mib.udplite_statistics);
 	snmp_mib_free((void __percpu **)net->mib.udp_statistics);

commit 686dc6b64b58e69715ce92177da0732a6464db69
Author: Gerrit Renker <gerrit@erg.abdn.ac.uk>
Date:   Sat Oct 15 09:26:56 2011 +0000

    ipv4: compat_ioctl is local to af_inet.c, make it static
    
    ipv4: compat_ioctl is local to af_inet.c, make it static
    
    Signed-off-by: Gerrit Renker <gerrit@erg.abdn.ac.uk>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index dd2b9478ddd1..1b5096a9875a 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -893,7 +893,7 @@ int inet_ioctl(struct socket *sock, unsigned int cmd, unsigned long arg)
 EXPORT_SYMBOL(inet_ioctl);
 
 #ifdef CONFIG_COMPAT
-int inet_compat_ioctl(struct socket *sock, unsigned int cmd, unsigned long arg)
+static int inet_compat_ioctl(struct socket *sock, unsigned int cmd, unsigned long arg)
 {
 	struct sock *sk = sock->sk;
 	int err = -ENOIOCTLCMD;

commit 29c486df6a208432b370bd4be99ae1369ede28d8
Author: Eric Dumazet <eric.dumazet@gmail.com>
Date:   Tue Aug 30 18:57:00 2011 -0400

    net: ipv4: relax AF_INET check in bind()
    
    commit d0733d2e29b65 (Check for mistakenly passed in non-IPv4 address)
    added regression on legacy apps that use bind() with AF_UNSPEC family.
    
    Relax the check, but make sure the bind() is done on INADDR_ANY
    addresses, as AF_UNSPEC has probably no sane meaning for other
    addresses.
    
    Bugzilla reference : https://bugzilla.kernel.org/show_bug.cgi?id=42012
    
    Signed-off-by: Eric Dumazet <eric.dumazet@gmail.com>
    Reported-and-bisected-by: Rene Meier <r_meier@freenet.de>
    CC: Marcus Meissner <meissner@suse.de>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 1b745d412cf6..dd2b9478ddd1 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -466,8 +466,13 @@ int inet_bind(struct socket *sock, struct sockaddr *uaddr, int addr_len)
 		goto out;
 
 	if (addr->sin_family != AF_INET) {
+		/* Compatibility games : accept AF_UNSPEC (mapped to AF_INET)
+		 * only if s_addr is INADDR_ANY.
+		 */
 		err = -EAFNOSUPPORT;
-		goto out;
+		if (addr->sin_family != AF_UNSPEC ||
+		    addr->sin_addr.s_addr != htonl(INADDR_ANY))
+			goto out;
 	}
 
 	chk_addr_ret = inet_addr_type(sock_net(sk), addr->sin_addr.s_addr);

commit e12fe68ce34d60c04bb1ddb1d3cc5c3022388fe4
Merge: 7329f0d58de0 712ae51afd55
Author: David S. Miller <davem@davemloft.net>
Date:   Tue Jul 5 23:23:37 2011 -0700

    Merge branch 'master' of master.kernel.org:/pub/scm/linux/kernel/git/davem/net-2.6

commit c349a528cd47e2272ded0ea358363855e86180da
Author: Marcus Meissner <meissner@novell.com>
Date:   Mon Jul 4 01:30:29 2011 +0000

    net: bind() fix error return on wrong address family
    
    Hi,
    
    Reinhard Max also pointed out that the error should EAFNOSUPPORT according
    to POSIX.
    
    The Linux manpages have it as EINVAL, some other OSes (Minix, HPUX, perhaps BSD) use
    EAFNOSUPPORT. Windows uses WSAEFAULT according to MSDN.
    
    Other protocols error values in their af bind() methods in current mainline git as far
    as a brief look shows:
            EAFNOSUPPORT: atm, appletalk, l2tp, llc, phonet, rxrpc
            EINVAL: ax25, bluetooth, decnet, econet, ieee802154, iucv, netlink, netrom, packet, rds, rose, unix, x25,
            No check?: can/raw, ipv6/raw, irda, l2tp/l2tp_ip
    
    Ciao, Marcus
    
    Signed-off-by: Marcus Meissner <meissner@suse.de>
    Cc: Reinhard Max <max@suse.de>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index eae1f676f870..ef1528af7abf 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -465,8 +465,10 @@ int inet_bind(struct socket *sock, struct sockaddr *uaddr, int addr_len)
 	if (addr_len < sizeof(struct sockaddr_in))
 		goto out;
 
-	if (addr->sin_family != AF_INET)
+	if (addr->sin_family != AF_INET) {
+		err = -EAFNOSUPPORT;
 		goto out;
+	}
 
 	chk_addr_ret = inet_addr_type(sock_net(sk), addr->sin_addr.s_addr);
 

commit 9f6ec8d697c08963d83880ccd35c13c5ace716ea
Merge: 4aa3a715551c 56299378726d
Author: David S. Miller <davem@davemloft.net>
Date:   Mon Jun 20 22:29:08 2011 -0700

    Merge branch 'master' of master.kernel.org:/pub/scm/linux/kernel/git/davem/net-2.6
    
    Conflicts:
            drivers/net/wireless/iwlwifi/iwl-agn-rxon.c
            drivers/net/wireless/rtlwifi/pci.c
            net/netfilter/ipvs/ip_vs_core.c

commit 1eddceadb0d6441cd39b2c38705a8f5fec86e770
Author: Eric Dumazet <eric.dumazet@gmail.com>
Date:   Fri Jun 17 03:45:15 2011 +0000

    net: rfs: enable RFS before first data packet is received
    
    Le jeudi 16 juin 2011 à 23:38 -0400, David Miller a écrit :
    > From: Ben Hutchings <bhutchings@solarflare.com>
    > Date: Fri, 17 Jun 2011 00:50:46 +0100
    >
    > > On Wed, 2011-06-15 at 04:15 +0200, Eric Dumazet wrote:
    > >> @@ -1594,6 +1594,7 @@ int tcp_v4_do_rcv(struct sock *sk, struct sk_buff *skb)
    > >>                    goto discard;
    > >>
    > >>            if (nsk != sk) {
    > >> +                  sock_rps_save_rxhash(nsk, skb->rxhash);
    > >>                    if (tcp_child_process(sk, nsk, skb)) {
    > >>                            rsk = nsk;
    > >>                            goto reset;
    > >>
    > >
    > > I haven't tried this, but it looks reasonable to me.
    > >
    > > What about IPv6?  The logic in tcp_v6_do_rcv() looks very similar.
    >
    > Indeed ipv6 side needs the same fix.
    >
    > Eric please add that part and resubmit.  And in fact I might stick
    > this into net-2.6 instead of net-next-2.6
    >
    
    OK, here is the net-2.6 based one then, thanks !
    
    [PATCH v2] net: rfs: enable RFS before first data packet is received
    
    First packet received on a passive tcp flow is not correctly RFS
    steered.
    
    One sock_rps_record_flow() call is missing in inet_accept()
    
    But before that, we also must record rxhash when child socket is setup.
    
    Signed-off-by: Eric Dumazet <eric.dumazet@gmail.com>
    CC: Tom Herbert <therbert@google.com>
    CC: Ben Hutchings <bhutchings@solarflare.com>
    CC: Jamal Hadi Salim <hadi@cyberus.ca>
    Signed-off-by: David S. Miller <davem@conan.davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 9c1926027a26..eae1f676f870 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -676,6 +676,7 @@ int inet_accept(struct socket *sock, struct socket *newsock, int flags)
 
 	lock_sock(sk2);
 
+	sock_rps_record_flow(sk2);
 	WARN_ON(!((1 << sk2->sk_state) &
 		  (TCPF_ESTABLISHED | TCPF_CLOSE_WAIT | TCPF_CLOSE)));
 

commit 8f0ea0fe3a036a47767f9c80e81b13e379a1f43b
Author: Eric Dumazet <eric.dumazet@gmail.com>
Date:   Fri Jun 10 19:45:51 2011 +0000

    snmp: reduce percpu needs by 50%
    
    SNMP mibs use two percpu arrays, one used in BH context, another in USER
    context. With increasing number of cpus in machines, and fact that ipv6
    uses per network device ipstats_mib, this is consuming a lot of memory
    if many network devices are registered.
    
    commit be281e554e2a (ipv6: reduce per device ICMP mib sizes) shrinked
    percpu needs for ipv6, but we can reduce memory use a bit more.
    
    With recent percpu infrastructure (irqsafe_cpu_inc() ...), we no longer
    need this BH/USER separation since we can update counters in a single
    x86 instruction, regardless of the BH/USER context.
    
    Other arches than x86 might need to disable irq in their
    irqsafe_cpu_inc() implementation : If this happens to be a problem, we
    can make SNMP_ARRAY_SZ arch dependent, but a previous poll
    ( https://lkml.org/lkml/2011/3/17/174 ) to arch maintainers did not
    raise strong opposition.
    
    Only on 32bit arches, we need to disable BH for 64bit counters updates
    done from USER context (currently used for IP MIB)
    
    This also reduces vmlinux size :
    
    1) x86_64 build
    $ size vmlinux.before vmlinux.after
       text    data     bss     dec     hex filename
    7853650 1293772 1896448 11043870         a8841e vmlinux.before
    7850578 1293772 1896448 11040798         a8781e vmlinux.after
    
    2) i386  build
    $ size vmlinux.before vmlinux.afterpatch
       text    data     bss     dec     hex filename
    6039335  635076 3670016 10344427         9dd7eb vmlinux.before
    6037342  635076 3670016 10342434         9dd022 vmlinux.afterpatch
    
    Signed-off-by: Eric Dumazet <eric.dumazet@gmail.com>
    CC: Andi Kleen <andi@firstfloor.org>
    CC: Ingo Molnar <mingo@elte.hu>
    CC: Tejun Heo <tj@kernel.org>
    CC: Christoph Lameter <cl@linux-foundation.org>
    CC: Benjamin Herrenschmidt <benh@kernel.crashing.org
    CC: linux-arch@vger.kernel.org
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 9c1926027a26..83673d23d4dd 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1437,11 +1437,11 @@ EXPORT_SYMBOL_GPL(inet_ctl_sock_create);
 unsigned long snmp_fold_field(void __percpu *mib[], int offt)
 {
 	unsigned long res = 0;
-	int i;
+	int i, j;
 
 	for_each_possible_cpu(i) {
-		res += *(((unsigned long *) per_cpu_ptr(mib[0], i)) + offt);
-		res += *(((unsigned long *) per_cpu_ptr(mib[1], i)) + offt);
+		for (j = 0; j < SNMP_ARRAY_SZ; j++)
+			res += *(((unsigned long *) per_cpu_ptr(mib[j], i)) + offt);
 	}
 	return res;
 }
@@ -1455,28 +1455,19 @@ u64 snmp_fold_field64(void __percpu *mib[], int offt, size_t syncp_offset)
 	int cpu;
 
 	for_each_possible_cpu(cpu) {
-		void *bhptr, *userptr;
+		void *bhptr;
 		struct u64_stats_sync *syncp;
-		u64 v_bh, v_user;
+		u64 v;
 		unsigned int start;
 
-		/* first mib used by softirq context, we must use _bh() accessors */
-		bhptr = per_cpu_ptr(SNMP_STAT_BHPTR(mib), cpu);
+		bhptr = per_cpu_ptr(mib[0], cpu);
 		syncp = (struct u64_stats_sync *)(bhptr + syncp_offset);
 		do {
 			start = u64_stats_fetch_begin_bh(syncp);
-			v_bh = *(((u64 *) bhptr) + offt);
+			v = *(((u64 *) bhptr) + offt);
 		} while (u64_stats_fetch_retry_bh(syncp, start));
 
-		/* second mib used in USER context */
-		userptr = per_cpu_ptr(SNMP_STAT_USRPTR(mib), cpu);
-		syncp = (struct u64_stats_sync *)(userptr + syncp_offset);
-		do {
-			start = u64_stats_fetch_begin(syncp);
-			v_user = *(((u64 *) userptr) + offt);
-		} while (u64_stats_fetch_retry(syncp, start));
-
-		res += v_bh + v_user;
+		res += v;
 	}
 	return res;
 }
@@ -1488,25 +1479,28 @@ int snmp_mib_init(void __percpu *ptr[2], size_t mibsize, size_t align)
 	BUG_ON(ptr == NULL);
 	ptr[0] = __alloc_percpu(mibsize, align);
 	if (!ptr[0])
-		goto err0;
+		return -ENOMEM;
+#if SNMP_ARRAY_SZ == 2
 	ptr[1] = __alloc_percpu(mibsize, align);
-	if (!ptr[1])
-		goto err1;
+	if (!ptr[1]) {
+		free_percpu(ptr[0]);
+		ptr[0] = NULL;
+		return -ENOMEM;
+	}
+#endif
 	return 0;
-err1:
-	free_percpu(ptr[0]);
-	ptr[0] = NULL;
-err0:
-	return -ENOMEM;
 }
 EXPORT_SYMBOL_GPL(snmp_mib_init);
 
-void snmp_mib_free(void __percpu *ptr[2])
+void snmp_mib_free(void __percpu *ptr[SNMP_ARRAY_SZ])
 {
+	int i;
+
 	BUG_ON(ptr == NULL);
-	free_percpu(ptr[0]);
-	free_percpu(ptr[1]);
-	ptr[0] = ptr[1] = NULL;
+	for (i = 0; i < SNMP_ARRAY_SZ; i++) {
+		free_percpu(ptr[i]);
+		ptr[i] = NULL;
+	}
 }
 EXPORT_SYMBOL_GPL(snmp_mib_free);
 

commit d0733d2e29b652b2e7b1438ececa732e4eed98eb
Author: Marcus Meissner <meissner@suse.de>
Date:   Wed Jun 1 21:05:22 2011 -0700

    net/ipv4: Check for mistakenly passed in non-IPv4 address
    
    Check against mistakenly passing in IPv6 addresses (which would result
    in an INADDR_ANY bind) or similar incompatible sockaddrs.
    
    Signed-off-by: Marcus Meissner <meissner@suse.de>
    Cc: Reinhard Max <max@suse.de>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index cc1463156cd0..9c1926027a26 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -465,6 +465,9 @@ int inet_bind(struct socket *sock, struct sockaddr *uaddr, int addr_len)
 	if (addr_len < sizeof(struct sockaddr_in))
 		goto out;
 
+	if (addr->sin_family != AF_INET)
+		goto out;
+
 	chk_addr_ret = inet_addr_type(sock_net(sk), addr->sin_addr.s_addr);
 
 	/* Not specified by any standard per-se, however it breaks too

commit c319b4d76b9e583a5d88d6bf190e079c4e43213d
Author: Vasiliy Kulikov <segoon@openwall.com>
Date:   Fri May 13 10:01:00 2011 +0000

    net: ipv4: add IPPROTO_ICMP socket kind
    
    This patch adds IPPROTO_ICMP socket kind.  It makes it possible to send
    ICMP_ECHO messages and receive the corresponding ICMP_ECHOREPLY messages
    without any special privileges.  In other words, the patch makes it
    possible to implement setuid-less and CAP_NET_RAW-less /bin/ping.  In
    order not to increase the kernel's attack surface, the new functionality
    is disabled by default, but is enabled at bootup by supporting Linux
    distributions, optionally with restriction to a group or a group range
    (see below).
    
    Similar functionality is implemented in Mac OS X:
    http://www.manpagez.com/man/4/icmp/
    
    A new ping socket is created with
    
        socket(PF_INET, SOCK_DGRAM, PROT_ICMP)
    
    Message identifiers (octets 4-5 of ICMP header) are interpreted as local
    ports. Addresses are stored in struct sockaddr_in. No port numbers are
    reserved for privileged processes, port 0 is reserved for API ("let the
    kernel pick a free number"). There is no notion of remote ports, remote
    port numbers provided by the user (e.g. in connect()) are ignored.
    
    Data sent and received include ICMP headers. This is deliberate to:
    1) Avoid the need to transport headers values like sequence numbers by
    other means.
    2) Make it easier to port existing programs using raw sockets.
    
    ICMP headers given to send() are checked and sanitized. The type must be
    ICMP_ECHO and the code must be zero (future extensions might relax this,
    see below). The id is set to the number (local port) of the socket, the
    checksum is always recomputed.
    
    ICMP reply packets received from the network are demultiplexed according
    to their id's, and are returned by recv() without any modifications.
    IP header information and ICMP errors of those packets may be obtained
    via ancillary data (IP_RECVTTL, IP_RETOPTS, and IP_RECVERR). ICMP source
    quenches and redirects are reported as fake errors via the error queue
    (IP_RECVERR); the next hop address for redirects is saved to ee_info (in
    network order).
    
    socket(2) is restricted to the group range specified in
    "/proc/sys/net/ipv4/ping_group_range".  It is "1 0" by default, meaning
    that nobody (not even root) may create ping sockets.  Setting it to "100
    100" would grant permissions to the single group (to either make
    /sbin/ping g+s and owned by this group or to grant permissions to the
    "netadmins" group), "0 4294967295" would enable it for the world, "100
    4294967295" would enable it for the users, but not daemons.
    
    The existing code might be (in the unlikely case anyone needs it)
    extended rather easily to handle other similar pairs of ICMP messages
    (Timestamp/Reply, Information Request/Reply, Address Mask Request/Reply
    etc.).
    
    Userspace ping util & patch for it:
    http://openwall.info/wiki/people/segoon/ping
    
    For Openwall GNU/*/Linux it was the last step on the road to the
    setuid-less distro.  A revision of this patch (for RHEL5/OpenVZ kernels)
    is in use in Owl-current, such as in the 2011/03/12 LiveCD ISOs:
    http://mirrors.kernel.org/openwall/Owl/current/iso/
    
    Initially this functionality was written by Pavel Kankovsky for
    Linux 2.4.32, but unfortunately it was never made public.
    
    All ping options (-b, -p, -Q, -R, -s, -t, -T, -M, -I), are tested with
    the patch.
    
    PATCH v3:
        - switched to flowi4.
        - minor changes to be consistent with raw sockets code.
    
    PATCH v2:
        - changed ping_debug() to pr_debug().
        - removed CONFIG_IP_PING.
        - removed ping_seq_fops.owner field (unused for procfs).
        - switched to proc_net_fops_create().
        - switched to %pK in seq_printf().
    
    PATCH v1:
        - fixed checksumming bug.
        - CAP_NET_RAW may not create icmp sockets anymore.
    
    RFC v2:
        - minor cleanups.
        - introduced sysctl'able group range to restrict socket(2).
    
    Signed-off-by: Vasiliy Kulikov <segoon@openwall.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 851aa056854b..cc1463156cd0 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -105,6 +105,7 @@
 #include <net/tcp.h>
 #include <net/udp.h>
 #include <net/udplite.h>
+#include <net/ping.h>
 #include <linux/skbuff.h>
 #include <net/sock.h>
 #include <net/raw.h>
@@ -1008,6 +1009,14 @@ static struct inet_protosw inetsw_array[] =
 		.flags =      INET_PROTOSW_PERMANENT,
        },
 
+       {
+		.type =       SOCK_DGRAM,
+		.protocol =   IPPROTO_ICMP,
+		.prot =       &ping_prot,
+		.ops =        &inet_dgram_ops,
+		.no_check =   UDP_CSUM_DEFAULT,
+		.flags =      INET_PROTOSW_REUSE,
+       },
 
        {
 	       .type =       SOCK_RAW,
@@ -1527,6 +1536,7 @@ static const struct net_protocol udp_protocol = {
 
 static const struct net_protocol icmp_protocol = {
 	.handler =	icmp_rcv,
+	.err_handler =	ping_err,
 	.no_policy =	1,
 	.netns_ok =	1,
 };
@@ -1642,6 +1652,10 @@ static int __init inet_init(void)
 	if (rc)
 		goto out_unregister_udp_proto;
 
+	rc = proto_register(&ping_prot, 1);
+	if (rc)
+		goto out_unregister_raw_proto;
+
 	/*
 	 *	Tell SOCKET that we are alive...
 	 */
@@ -1697,6 +1711,8 @@ static int __init inet_init(void)
 	/* Add UDP-Lite (RFC 3828) */
 	udplite4_register();
 
+	ping_init();
+
 	/*
 	 *	Set the ICMP layer up
 	 */
@@ -1727,6 +1743,8 @@ static int __init inet_init(void)
 	rc = 0;
 out:
 	return rc;
+out_unregister_raw_proto:
+	proto_unregister(&raw_prot);
 out_unregister_udp_proto:
 	proto_unregister(&udp_prot);
 out_unregister_tcp_proto:
@@ -1751,11 +1769,15 @@ static int __init ipv4_proc_init(void)
 		goto out_tcp;
 	if (udp4_proc_init())
 		goto out_udp;
+	if (ping_proc_init())
+		goto out_ping;
 	if (ip_misc_proc_init())
 		goto out_misc;
 out:
 	return rc;
 out_misc:
+	ping_proc_exit();
+out_ping:
 	udp4_proc_exit();
 out_udp:
 	tcp4_proc_exit();

commit 6e869138101bc607e4780187210b79d531f9b2ce
Author: David S. Miller <davem@davemloft.net>
Date:   Fri May 6 16:18:04 2011 -0700

    ipv4: Use cork flow in inet_sk_{reselect_saddr,rebuild_header}()
    
    These two functions must be invoked only when the socket is locked
    (because socket identity modifications are made non-atomically).
    
    Therefore we can use the cork flow for output route lookups.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 7b91fa8bf83c..851aa056854b 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1103,7 +1103,7 @@ static int inet_sk_reselect_saddr(struct sock *sk)
 	struct inet_sock *inet = inet_sk(sk);
 	__be32 old_saddr = inet->inet_saddr;
 	__be32 daddr = inet->inet_daddr;
-	struct flowi4 fl4;
+	struct flowi4 *fl4;
 	struct rtable *rt;
 	__be32 new_saddr;
 	struct ip_options_rcu *inet_opt;
@@ -1114,7 +1114,8 @@ static int inet_sk_reselect_saddr(struct sock *sk)
 		daddr = inet_opt->opt.faddr;
 
 	/* Query new route. */
-	rt = ip_route_connect(&fl4, daddr, 0, RT_CONN_FLAGS(sk),
+	fl4 = &inet->cork.fl.u.ip4;
+	rt = ip_route_connect(fl4, daddr, 0, RT_CONN_FLAGS(sk),
 			      sk->sk_bound_dev_if, sk->sk_protocol,
 			      inet->inet_sport, inet->inet_dport, sk, false);
 	if (IS_ERR(rt))
@@ -1122,7 +1123,7 @@ static int inet_sk_reselect_saddr(struct sock *sk)
 
 	sk_setup_caps(sk, &rt->dst);
 
-	new_saddr = fl4.saddr;
+	new_saddr = fl4->saddr;
 
 	if (new_saddr == old_saddr)
 		return 0;
@@ -1152,7 +1153,7 @@ int inet_sk_rebuild_header(struct sock *sk)
 	struct rtable *rt = (struct rtable *)__sk_dst_check(sk, 0);
 	__be32 daddr;
 	struct ip_options_rcu *inet_opt;
-	struct flowi4 fl4;
+	struct flowi4 *fl4;
 	int err;
 
 	/* Route is OK, nothing to do. */
@@ -1166,7 +1167,8 @@ int inet_sk_rebuild_header(struct sock *sk)
 	if (inet_opt && inet_opt->opt.srr)
 		daddr = inet_opt->opt.faddr;
 	rcu_read_unlock();
-	rt = ip_route_output_ports(sock_net(sk), &fl4, sk, daddr, inet->inet_saddr,
+	fl4 = &inet->cork.fl.u.ip4;
+	rt = ip_route_output_ports(sock_net(sk), fl4, sk, daddr, inet->inet_saddr,
 				   inet->inet_dport, inet->inet_sport,
 				   sk->sk_protocol, RT_CONN_FLAGS(sk),
 				   sk->sk_bound_dev_if);

commit 31e4543db29fb85496a122b965d6482c8d1a2bfe
Author: David S. Miller <davem@davemloft.net>
Date:   Tue May 3 20:25:42 2011 -0700

    ipv4: Make caller provide on-stack flow key to ip_route_output_ports().
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 4e734992e266..7b91fa8bf83c 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1152,6 +1152,7 @@ int inet_sk_rebuild_header(struct sock *sk)
 	struct rtable *rt = (struct rtable *)__sk_dst_check(sk, 0);
 	__be32 daddr;
 	struct ip_options_rcu *inet_opt;
+	struct flowi4 fl4;
 	int err;
 
 	/* Route is OK, nothing to do. */
@@ -1165,7 +1166,7 @@ int inet_sk_rebuild_header(struct sock *sk)
 	if (inet_opt && inet_opt->opt.srr)
 		daddr = inet_opt->opt.faddr;
 	rcu_read_unlock();
-	rt = ip_route_output_ports(sock_net(sk), sk, daddr, inet->inet_saddr,
+	rt = ip_route_output_ports(sock_net(sk), &fl4, sk, daddr, inet->inet_saddr,
 				   inet->inet_dport, inet->inet_sport,
 				   sk->sk_protocol, RT_CONN_FLAGS(sk),
 				   sk->sk_bound_dev_if);

commit b883187785004cacea053569f1655fada0dfc299
Author: David S. Miller <davem@davemloft.net>
Date:   Thu Apr 28 23:16:53 2011 -0700

    ipv4: Fetch route saddr from flow key in inet_sk_reselect_saddr().
    
    Now that output route lookups update the flow with
    source address selection, we can fetch it from
    fl4->saddr instead of rt->rt_src
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 963a621e75c7..4e734992e266 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1122,7 +1122,7 @@ static int inet_sk_reselect_saddr(struct sock *sk)
 
 	sk_setup_caps(sk, &rt->dst);
 
-	new_saddr = rt->rt_src;
+	new_saddr = fl4.saddr;
 
 	if (new_saddr == old_saddr)
 		return 0;

commit f6d8bd051c391c1c0458a30b2a7abcd939329259
Author: Eric Dumazet <eric.dumazet@gmail.com>
Date:   Thu Apr 21 09:45:37 2011 +0000

    inet: add RCU protection to inet->opt
    
    We lack proper synchronization to manipulate inet->opt ip_options
    
    Problem is ip_make_skb() calls ip_setup_cork() and
    ip_setup_cork() possibly makes a copy of ipc->opt (struct ip_options),
    without any protection against another thread manipulating inet->opt.
    
    Another thread can change inet->opt pointer and free old one under us.
    
    Use RCU to protect inet->opt (changed to inet->inet_opt).
    
    Instead of handling atomic refcounts, just copy ip_options when
    necessary, to avoid cache line dirtying.
    
    We cant insert an rcu_head in struct ip_options since its included in
    skb->cb[], so this patch is large because I had to introduce a new
    ip_options_rcu structure.
    
    Signed-off-by: Eric Dumazet <eric.dumazet@gmail.com>
    Cc: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 0413af3e2285..963a621e75c7 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -153,7 +153,7 @@ void inet_sock_destruct(struct sock *sk)
 	WARN_ON(sk->sk_wmem_queued);
 	WARN_ON(sk->sk_forward_alloc);
 
-	kfree(inet->opt);
+	kfree(rcu_dereference_protected(inet->inet_opt, 1));
 	dst_release(rcu_dereference_check(sk->sk_dst_cache, 1));
 	sk_refcnt_debug_dec(sk);
 }
@@ -1106,9 +1106,12 @@ static int inet_sk_reselect_saddr(struct sock *sk)
 	struct flowi4 fl4;
 	struct rtable *rt;
 	__be32 new_saddr;
+	struct ip_options_rcu *inet_opt;
 
-	if (inet->opt && inet->opt->srr)
-		daddr = inet->opt->faddr;
+	inet_opt = rcu_dereference_protected(inet->inet_opt,
+					     sock_owned_by_user(sk));
+	if (inet_opt && inet_opt->opt.srr)
+		daddr = inet_opt->opt.faddr;
 
 	/* Query new route. */
 	rt = ip_route_connect(&fl4, daddr, 0, RT_CONN_FLAGS(sk),
@@ -1148,6 +1151,7 @@ int inet_sk_rebuild_header(struct sock *sk)
 	struct inet_sock *inet = inet_sk(sk);
 	struct rtable *rt = (struct rtable *)__sk_dst_check(sk, 0);
 	__be32 daddr;
+	struct ip_options_rcu *inet_opt;
 	int err;
 
 	/* Route is OK, nothing to do. */
@@ -1155,9 +1159,12 @@ int inet_sk_rebuild_header(struct sock *sk)
 		return 0;
 
 	/* Reroute. */
+	rcu_read_lock();
+	inet_opt = rcu_dereference(inet->inet_opt);
 	daddr = inet->inet_daddr;
-	if (inet->opt && inet->opt->srr)
-		daddr = inet->opt->faddr;
+	if (inet_opt && inet_opt->opt.srr)
+		daddr = inet_opt->opt.faddr;
+	rcu_read_unlock();
 	rt = ip_route_output_ports(sock_net(sk), sk, daddr, inet->inet_saddr,
 				   inet->inet_dport, inet->inet_sport,
 				   sk->sk_protocol, RT_CONN_FLAGS(sk),

commit 2d7192d6cbab20e153c47fa1559ffd41ceef0e79
Author: David S. Miller <davem@davemloft.net>
Date:   Tue Apr 26 13:28:44 2011 -0700

    ipv4: Sanitize and simplify ip_route_{connect,newports}()
    
    These functions are used together as a unit for route resolution
    during connect().  They address the chicken-and-egg problem that
    exists when ports need to be allocated during connect() processing,
    yet such port allocations require addressing information from the
    routing code.
    
    It's currently more heavy handed than it needs to be, and in
    particular we allocate and initialize a flow object twice.
    
    Let the callers provide the on-stack flow object.  That way we only
    need to initialize it once in the ip_route_connect() call.
    
    Later, if ip_route_newports() needs to do anything, it re-uses that
    flow object as-is except for the ports which it updates before the
    route re-lookup.
    
    Also, describe why this set of facilities are needed and how it works
    in a big comment.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Reviewed-by: Eric Dumazet <eric.dumazet@gmail.com>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index cae75ef21fea..0413af3e2285 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1103,6 +1103,7 @@ static int inet_sk_reselect_saddr(struct sock *sk)
 	struct inet_sock *inet = inet_sk(sk);
 	__be32 old_saddr = inet->inet_saddr;
 	__be32 daddr = inet->inet_daddr;
+	struct flowi4 fl4;
 	struct rtable *rt;
 	__be32 new_saddr;
 
@@ -1110,7 +1111,7 @@ static int inet_sk_reselect_saddr(struct sock *sk)
 		daddr = inet->opt->faddr;
 
 	/* Query new route. */
-	rt = ip_route_connect(daddr, 0, RT_CONN_FLAGS(sk),
+	rt = ip_route_connect(&fl4, daddr, 0, RT_CONN_FLAGS(sk),
 			      sk->sk_bound_dev_if, sk->sk_protocol,
 			      inet->inet_sport, inet->inet_dport, sk, false);
 	if (IS_ERR(rt))

commit b71d1d426d263b0b6cb5760322efebbfc89d4463
Author: Eric Dumazet <eric.dumazet@gmail.com>
Date:   Fri Apr 22 04:53:02 2011 +0000

    inet: constify ip headers and in6_addr
    
    Add const qualifiers to structs iphdr, ipv6hdr and in6_addr pointers
    where possible, to make code intention more obvious.
    
    Signed-off-by: Eric Dumazet <eric.dumazet@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 807d83c02ef6..cae75ef21fea 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1186,7 +1186,7 @@ EXPORT_SYMBOL(inet_sk_rebuild_header);
 
 static int inet_gso_send_check(struct sk_buff *skb)
 {
-	struct iphdr *iph;
+	const struct iphdr *iph;
 	const struct net_protocol *ops;
 	int proto;
 	int ihl;
@@ -1293,7 +1293,7 @@ static struct sk_buff **inet_gro_receive(struct sk_buff **head,
 	const struct net_protocol *ops;
 	struct sk_buff **pp = NULL;
 	struct sk_buff *p;
-	struct iphdr *iph;
+	const struct iphdr *iph;
 	unsigned int hlen;
 	unsigned int off;
 	unsigned int id;

commit 78fbfd8a653ca972afe479517a40661bfff6d8c3
Author: David S. Miller <davem@davemloft.net>
Date:   Sat Mar 12 00:00:52 2011 -0500

    ipv4: Create and use route lookup helpers.
    
    The idea here is this minimizes the number of places one has to edit
    in order to make changes to how flows are defined and used.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 35a502055018..807d83c02ef6 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1157,22 +1157,10 @@ int inet_sk_rebuild_header(struct sock *sk)
 	daddr = inet->inet_daddr;
 	if (inet->opt && inet->opt->srr)
 		daddr = inet->opt->faddr;
-	{
-	struct flowi fl = {
-		.oif = sk->sk_bound_dev_if,
-		.mark = sk->sk_mark,
-		.fl4_dst = daddr,
-		.fl4_src = inet->inet_saddr,
-		.fl4_tos = RT_CONN_FLAGS(sk),
-		.proto = sk->sk_protocol,
-		.flags = inet_sk_flowi_flags(sk),
-		.fl_ip_sport = inet->inet_sport,
-		.fl_ip_dport = inet->inet_dport,
-	};
-
-	security_sk_classify_flow(sk, &fl);
-	rt = ip_route_output_flow(sock_net(sk), &fl, sk);
-	}
+	rt = ip_route_output_ports(sock_net(sk), sk, daddr, inet->inet_saddr,
+				   inet->inet_dport, inet->inet_sport,
+				   sk->sk_protocol, RT_CONN_FLAGS(sk),
+				   sk->sk_bound_dev_if);
 	if (!IS_ERR(rt)) {
 		err = 0;
 		sk_setup_caps(sk, &rt->dst);

commit b23dd4fe42b455af5c6e20966b7d6959fa8352ea
Author: David S. Miller <davem@davemloft.net>
Date:   Wed Mar 2 14:31:35 2011 -0800

    ipv4: Make output route lookup return rtable directly.
    
    Instead of on the stack.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 44513bb8ac2e..35a502055018 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1101,23 +1101,20 @@ int sysctl_ip_dynaddr __read_mostly;
 static int inet_sk_reselect_saddr(struct sock *sk)
 {
 	struct inet_sock *inet = inet_sk(sk);
-	int err;
-	struct rtable *rt;
 	__be32 old_saddr = inet->inet_saddr;
-	__be32 new_saddr;
 	__be32 daddr = inet->inet_daddr;
+	struct rtable *rt;
+	__be32 new_saddr;
 
 	if (inet->opt && inet->opt->srr)
 		daddr = inet->opt->faddr;
 
 	/* Query new route. */
-	err = ip_route_connect(&rt, daddr, 0,
-			       RT_CONN_FLAGS(sk),
-			       sk->sk_bound_dev_if,
-			       sk->sk_protocol,
-			       inet->inet_sport, inet->inet_dport, sk, false);
-	if (err)
-		return err;
+	rt = ip_route_connect(daddr, 0, RT_CONN_FLAGS(sk),
+			      sk->sk_bound_dev_if, sk->sk_protocol,
+			      inet->inet_sport, inet->inet_dport, sk, false);
+	if (IS_ERR(rt))
+		return PTR_ERR(rt);
 
 	sk_setup_caps(sk, &rt->dst);
 
@@ -1160,7 +1157,7 @@ int inet_sk_rebuild_header(struct sock *sk)
 	daddr = inet->inet_daddr;
 	if (inet->opt && inet->opt->srr)
 		daddr = inet->opt->faddr;
-{
+	{
 	struct flowi fl = {
 		.oif = sk->sk_bound_dev_if,
 		.mark = sk->sk_mark,
@@ -1174,11 +1171,14 @@ int inet_sk_rebuild_header(struct sock *sk)
 	};
 
 	security_sk_classify_flow(sk, &fl);
-	err = ip_route_output_flow(sock_net(sk), &rt, &fl, sk);
-}
-	if (!err)
+	rt = ip_route_output_flow(sock_net(sk), &fl, sk);
+	}
+	if (!IS_ERR(rt)) {
+		err = 0;
 		sk_setup_caps(sk, &rt->dst);
-	else {
+	} else {
+		err = PTR_ERR(rt);
+
 		/* Routing failed... */
 		sk->sk_route_caps = 0;
 		/*

commit 273447b352e69c327efdecfd6e1d6fe3edbdcd14
Author: David S. Miller <davem@davemloft.net>
Date:   Tue Mar 1 14:27:04 2011 -0800

    ipv4: Kill can_sleep arg to ip_route_output_flow()
    
    This boolean state is now available in the flow flags.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 7d90fe0ee5a6..44513bb8ac2e 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1174,7 +1174,7 @@ int inet_sk_rebuild_header(struct sock *sk)
 	};
 
 	security_sk_classify_flow(sk, &fl);
-	err = ip_route_output_flow(sock_net(sk), &rt, &fl, sk, false);
+	err = ip_route_output_flow(sock_net(sk), &rt, &fl, sk);
 }
 	if (!err)
 		sk_setup_caps(sk, &rt->dst);

commit 420d44daa7aa1cc847e9e527f0a27a9ce61768ca
Author: David S. Miller <davem@davemloft.net>
Date:   Tue Mar 1 14:19:23 2011 -0800

    ipv4: Make final arg to ip_route_output_flow to be boolean "can_sleep"
    
    Since that is what the current vague "flags" argument means.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index d16687db9713..7d90fe0ee5a6 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1174,7 +1174,7 @@ int inet_sk_rebuild_header(struct sock *sk)
 	};
 
 	security_sk_classify_flow(sk, &fl);
-	err = ip_route_output_flow(sock_net(sk), &rt, &fl, sk, 0);
+	err = ip_route_output_flow(sock_net(sk), &rt, &fl, sk, false);
 }
 	if (!err)
 		sk_setup_caps(sk, &rt->dst);

commit abdf7e7239da270e68262728f125ea94b9b7d42d
Author: David S. Miller <davem@davemloft.net>
Date:   Tue Mar 1 14:15:24 2011 -0800

    ipv4: Can final ip_route_connect() arg to boolean "can_sleep".
    
    Since that's what the current vague "flags" thing means.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 7ceb80447631..d16687db9713 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1115,7 +1115,7 @@ static int inet_sk_reselect_saddr(struct sock *sk)
 			       RT_CONN_FLAGS(sk),
 			       sk->sk_bound_dev_if,
 			       sk->sk_protocol,
-			       inet->inet_sport, inet->inet_dport, sk, 0);
+			       inet->inet_sport, inet->inet_dport, sk, false);
 	if (err)
 		return err;
 

commit 5403c8a29521a6eb02f9283dbbe0184527f8f42b
Merge: c79b9e493614 c4c93106741b
Author: David S. Miller <davem@davemloft.net>
Date:   Mon Jan 31 13:13:24 2011 -0800

    Merge branch 'master' of master.kernel.org:/pub/scm/linux/kernel/git/davem/net-2.6

commit 709b46e8d90badda1898caea50483c12af178e96
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Sat Jan 29 16:15:56 2011 +0000

    net: Add compat ioctl support for the ipv4 multicast ioctl SIOCGETSGCNT
    
    SIOCGETSGCNT is not a unique ioctl value as it it maps tio SIOCPROTOPRIVATE +1,
    which unfortunately means the existing infrastructure for compat networking
    ioctls is insufficient.  A trivial compact ioctl implementation would conflict
    with:
    
    SIOCAX25ADDUID
    SIOCAIPXPRISLT
    SIOCGETSGCNT_IN6
    SIOCGETSGCNT
    SIOCRSSCAUSE
    SIOCX25SSUBSCRIP
    SIOCX25SDTEFACILITIES
    
    To make this work I have updated the compat_ioctl decode path to mirror the
    the normal ioctl decode path.  I have added an ipv4 inet_compat_ioctl function
    so that I can have ipv4 specific compat ioctls.   I have added a compat_ioctl
    function into struct proto so I can break out ioctls by which kind of ip socket
    I am using.  I have added a compat_raw_ioctl function because SIOCGETSGCNT only
    works on raw sockets.  I have added a ipmr_compat_ioctl that mirrors the normal
    ipmr_ioctl.
    
    This was necessary because unfortunately the struct layout for the SIOCGETSGCNT
    has unsigned longs in it so changes between 32bit and 64bit kernels.
    
    This change was sufficient to run a 32bit ip multicast routing daemon on a
    64bit kernel.
    
    Reported-by: Bill Fenner <fenner@aristanetworks.com>
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index f2b61107df6c..45b89d7bda5a 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -880,6 +880,19 @@ int inet_ioctl(struct socket *sock, unsigned int cmd, unsigned long arg)
 }
 EXPORT_SYMBOL(inet_ioctl);
 
+#ifdef CONFIG_COMPAT
+int inet_compat_ioctl(struct socket *sock, unsigned int cmd, unsigned long arg)
+{
+	struct sock *sk = sock->sk;
+	int err = -ENOIOCTLCMD;
+
+	if (sk->sk_prot->compat_ioctl)
+		err = sk->sk_prot->compat_ioctl(sk, cmd, arg);
+
+	return err;
+}
+#endif
+
 const struct proto_ops inet_stream_ops = {
 	.family		   = PF_INET,
 	.owner		   = THIS_MODULE,
@@ -903,6 +916,7 @@ const struct proto_ops inet_stream_ops = {
 #ifdef CONFIG_COMPAT
 	.compat_setsockopt = compat_sock_common_setsockopt,
 	.compat_getsockopt = compat_sock_common_getsockopt,
+	.compat_ioctl	   = inet_compat_ioctl,
 #endif
 };
 EXPORT_SYMBOL(inet_stream_ops);
@@ -929,6 +943,7 @@ const struct proto_ops inet_dgram_ops = {
 #ifdef CONFIG_COMPAT
 	.compat_setsockopt = compat_sock_common_setsockopt,
 	.compat_getsockopt = compat_sock_common_getsockopt,
+	.compat_ioctl	   = inet_compat_ioctl,
 #endif
 };
 EXPORT_SYMBOL(inet_dgram_ops);
@@ -959,6 +974,7 @@ static const struct proto_ops inet_sockraw_ops = {
 #ifdef CONFIG_COMPAT
 	.compat_setsockopt = compat_sock_common_setsockopt,
 	.compat_getsockopt = compat_sock_common_getsockopt,
+	.compat_ioctl	   = inet_compat_ioctl,
 #endif
 };
 

commit 04ed3e741d0f133e02bed7fa5c98edba128f90e7
Author: Michał Mirosław <mirq-linux@rere.qmqm.pl>
Date:   Mon Jan 24 15:32:47 2011 -0800

    net: change netdev->features to u32
    
    Quoting Ben Hutchings: we presumably won't be defining features that
    can only be enabled on 64-bit architectures.
    
    Occurences found by `grep -r` on net/, drivers/net, include/
    
    [ Move features and vlan_features next to each other in
      struct netdev, as per Eric Dumazet's suggestion -DaveM ]
    
    Signed-off-by: Michał Mirosław <mirq-linux@rere.qmqm.pl>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index f2b61107df6c..e5e2d9d64abb 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1215,7 +1215,7 @@ static int inet_gso_send_check(struct sk_buff *skb)
 	return err;
 }
 
-static struct sk_buff *inet_gso_segment(struct sk_buff *skb, int features)
+static struct sk_buff *inet_gso_segment(struct sk_buff *skb, u32 features)
 {
 	struct sk_buff *segs = ERR_PTR(-EINVAL);
 	struct iphdr *iph;

commit 5811662b15db018c740c57d037523683fd3e6123
Author: Changli Gao <xiaosuo@gmail.com>
Date:   Fri Nov 12 18:43:55 2010 +0000

    net: use the macros defined for the members of flowi
    
    Use the macros defined for the members of flowi to clean the code up.
    
    Signed-off-by: Changli Gao <xiaosuo@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index f581f77d1097..f2b61107df6c 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1148,21 +1148,13 @@ int inet_sk_rebuild_header(struct sock *sk)
 	struct flowi fl = {
 		.oif = sk->sk_bound_dev_if,
 		.mark = sk->sk_mark,
-		.nl_u = {
-			.ip4_u = {
-				.daddr	= daddr,
-				.saddr	= inet->inet_saddr,
-				.tos	= RT_CONN_FLAGS(sk),
-			},
-		},
+		.fl4_dst = daddr,
+		.fl4_src = inet->inet_saddr,
+		.fl4_tos = RT_CONN_FLAGS(sk),
 		.proto = sk->sk_protocol,
 		.flags = inet_sk_flowi_flags(sk),
-		.uli_u = {
-			.ports = {
-				.sport = inet->inet_sport,
-				.dport = inet->inet_dport,
-			},
-		},
+		.fl_ip_sport = inet->inet_sport,
+		.fl_ip_dport = inet->inet_dport,
 	};
 
 	security_sk_classify_flow(sk, &fl);

commit 49e8ab03ebcacd8e37660ffec20c0c46721a2800
Author: Eric Dumazet <eric.dumazet@gmail.com>
Date:   Thu Aug 19 06:10:45 2010 +0000

    net: build_ehash_secret() and rt_bind_peer() cleanups
    
    Now cmpxchg() is available on all arches, we can use it in
    build_ehash_secret() and rt_bind_peer() instead of using spinlocks.
    
    Signed-off-by: Eric Dumazet <eric.dumazet@gmail.com>
    CC: Mathieu Desnoyers <mathieu.desnoyers@polymtl.ca>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 6a1100c25a9f..f581f77d1097 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -227,18 +227,16 @@ EXPORT_SYMBOL(inet_ehash_secret);
 
 /*
  * inet_ehash_secret must be set exactly once
- * Instead of using a dedicated spinlock, we (ab)use inetsw_lock
  */
 void build_ehash_secret(void)
 {
 	u32 rnd;
+
 	do {
 		get_random_bytes(&rnd, sizeof(rnd));
 	} while (rnd == 0);
-	spin_lock_bh(&inetsw_lock);
-	if (!inet_ehash_secret)
-		inet_ehash_secret = rnd;
-	spin_unlock_bh(&inetsw_lock);
+
+	cmpxchg(&inet_ehash_secret, 0, rnd);
 }
 EXPORT_SYMBOL(build_ehash_secret);
 

commit 7ba42910073f8432934d61a6c08b1023c408fb62
Author: Changli Gao <xiaosuo@gmail.com>
Date:   Sat Jul 10 20:41:55 2010 +0000

    inet, inet6: make tcp_sendmsg() and tcp_sendpage() through inet_sendmsg() and inet_sendpage()
    
    a new boolean flag no_autobind is added to structure proto to avoid the autobind
    calls when the protocol is TCP. Then sock_rps_record_flow() is called int the
    TCP's sendmsg() and sendpage() pathes.
    
    Signed-off-by: Changli Gao <xiaosuo@gmail.com>
    ----
     include/net/inet_common.h |    4 ++++
     include/net/sock.h        |    1 +
     include/net/tcp.h         |    8 ++++----
     net/ipv4/af_inet.c        |   15 +++++++++------
     net/ipv4/tcp.c            |   11 +++++------
     net/ipv4/tcp_ipv4.c       |    3 +++
     net/ipv6/af_inet6.c       |    8 ++++----
     net/ipv6/tcp_ipv6.c       |    3 +++
     8 files changed, 33 insertions(+), 20 deletions(-)
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 3ceb025b16f2..6a1100c25a9f 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -727,28 +727,31 @@ int inet_sendmsg(struct kiocb *iocb, struct socket *sock, struct msghdr *msg,
 	sock_rps_record_flow(sk);
 
 	/* We may need to bind the socket. */
-	if (!inet_sk(sk)->inet_num && inet_autobind(sk))
+	if (!inet_sk(sk)->inet_num && !sk->sk_prot->no_autobind &&
+	    inet_autobind(sk))
 		return -EAGAIN;
 
 	return sk->sk_prot->sendmsg(iocb, sk, msg, size);
 }
 EXPORT_SYMBOL(inet_sendmsg);
 
-static ssize_t inet_sendpage(struct socket *sock, struct page *page, int offset,
-			     size_t size, int flags)
+ssize_t inet_sendpage(struct socket *sock, struct page *page, int offset,
+		      size_t size, int flags)
 {
 	struct sock *sk = sock->sk;
 
 	sock_rps_record_flow(sk);
 
 	/* We may need to bind the socket. */
-	if (!inet_sk(sk)->inet_num && inet_autobind(sk))
+	if (!inet_sk(sk)->inet_num && !sk->sk_prot->no_autobind &&
+	    inet_autobind(sk))
 		return -EAGAIN;
 
 	if (sk->sk_prot->sendpage)
 		return sk->sk_prot->sendpage(sk, page, offset, size, flags);
 	return sock_no_sendpage(sock, page, offset, size, flags);
 }
+EXPORT_SYMBOL(inet_sendpage);
 
 int inet_recvmsg(struct kiocb *iocb, struct socket *sock, struct msghdr *msg,
 		 size_t size, int flags)
@@ -894,10 +897,10 @@ const struct proto_ops inet_stream_ops = {
 	.shutdown	   = inet_shutdown,
 	.setsockopt	   = sock_common_setsockopt,
 	.getsockopt	   = sock_common_getsockopt,
-	.sendmsg	   = tcp_sendmsg,
+	.sendmsg	   = inet_sendmsg,
 	.recvmsg	   = inet_recvmsg,
 	.mmap		   = sock_no_mmap,
-	.sendpage	   = tcp_sendpage,
+	.sendpage	   = inet_sendpage,
 	.splice_read	   = tcp_splice_read,
 #ifdef CONFIG_COMPAT
 	.compat_setsockopt = compat_sock_common_setsockopt,

commit 4ce3c183fcade7f4b30a33dae90cd774c3d9e094
Author: Eric Dumazet <eric.dumazet@gmail.com>
Date:   Wed Jun 30 13:31:19 2010 -0700

    snmp: 64bit ipstats_mib for all arches
    
    /proc/net/snmp and /proc/net/netstat expose SNMP counters.
    
    Width of these counters is either 32 or 64 bits, depending on the size
    of "unsigned long" in kernel.
    
    This means user program parsing these files must already be prepared to
    deal with 64bit values, regardless of user program being 32 or 64 bit.
    
    This patch introduces 64bit snmp values for IPSTAT mib, where some
    counters can wrap pretty fast if they are 32bit wide.
    
    # netstat -s|egrep "InOctets|OutOctets"
        InOctets: 244068329096
        OutOctets: 244069348848
    
    Signed-off-by: Eric Dumazet <eric.dumazet@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 640db9b90330..3ceb025b16f2 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1427,6 +1427,42 @@ unsigned long snmp_fold_field(void __percpu *mib[], int offt)
 }
 EXPORT_SYMBOL_GPL(snmp_fold_field);
 
+#if BITS_PER_LONG==32
+
+u64 snmp_fold_field64(void __percpu *mib[], int offt, size_t syncp_offset)
+{
+	u64 res = 0;
+	int cpu;
+
+	for_each_possible_cpu(cpu) {
+		void *bhptr, *userptr;
+		struct u64_stats_sync *syncp;
+		u64 v_bh, v_user;
+		unsigned int start;
+
+		/* first mib used by softirq context, we must use _bh() accessors */
+		bhptr = per_cpu_ptr(SNMP_STAT_BHPTR(mib), cpu);
+		syncp = (struct u64_stats_sync *)(bhptr + syncp_offset);
+		do {
+			start = u64_stats_fetch_begin_bh(syncp);
+			v_bh = *(((u64 *) bhptr) + offt);
+		} while (u64_stats_fetch_retry_bh(syncp, start));
+
+		/* second mib used in USER context */
+		userptr = per_cpu_ptr(SNMP_STAT_USRPTR(mib), cpu);
+		syncp = (struct u64_stats_sync *)(userptr + syncp_offset);
+		do {
+			start = u64_stats_fetch_begin(syncp);
+			v_user = *(((u64 *) userptr) + offt);
+		} while (u64_stats_fetch_retry(syncp, start));
+
+		res += v_bh + v_user;
+	}
+	return res;
+}
+EXPORT_SYMBOL_GPL(snmp_fold_field64);
+#endif
+
 int snmp_mib_init(void __percpu *ptr[2], size_t mibsize, size_t align)
 {
 	BUG_ON(ptr == NULL);

commit 1823e4c80eeae2a774c75569ce3035070e5ee009
Author: Eric Dumazet <eric.dumazet@gmail.com>
Date:   Tue Jun 22 20:58:41 2010 +0000

    snmp: add align parameter to snmp_mib_init()
    
    In preparation for 64bit snmp counters for some mibs,
    add an 'align' parameter to snmp_mib_init(), instead
    of assuming mibs only contain 'unsigned long' fields.
    
    Callers can use __alignof__(type) to provide correct
    alignment.
    
    Signed-off-by: Eric Dumazet <eric.dumazet@gmail.com>
    CC: Herbert Xu <herbert@gondor.apana.org.au>
    CC: Arnaldo Carvalho de Melo <acme@ghostprotocols.net>
    CC: Hideaki YOSHIFUJI <yoshfuji@linux-ipv6.org>
    CC: Vlad Yasevich <vladislav.yasevich@hp.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index b4c0969137cb..640db9b90330 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1427,13 +1427,13 @@ unsigned long snmp_fold_field(void __percpu *mib[], int offt)
 }
 EXPORT_SYMBOL_GPL(snmp_fold_field);
 
-int snmp_mib_init(void __percpu *ptr[2], size_t mibsize)
+int snmp_mib_init(void __percpu *ptr[2], size_t mibsize, size_t align)
 {
 	BUG_ON(ptr == NULL);
-	ptr[0] = __alloc_percpu(mibsize, __alignof__(unsigned long));
+	ptr[0] = __alloc_percpu(mibsize, align);
 	if (!ptr[0])
 		goto err0;
-	ptr[1] = __alloc_percpu(mibsize, __alignof__(unsigned long));
+	ptr[1] = __alloc_percpu(mibsize, align);
 	if (!ptr[1])
 		goto err1;
 	return 0;
@@ -1490,25 +1490,32 @@ static const struct net_protocol icmp_protocol = {
 static __net_init int ipv4_mib_init_net(struct net *net)
 {
 	if (snmp_mib_init((void __percpu **)net->mib.tcp_statistics,
-			  sizeof(struct tcp_mib)) < 0)
+			  sizeof(struct tcp_mib),
+			  __alignof__(struct tcp_mib)) < 0)
 		goto err_tcp_mib;
 	if (snmp_mib_init((void __percpu **)net->mib.ip_statistics,
-			  sizeof(struct ipstats_mib)) < 0)
+			  sizeof(struct ipstats_mib),
+			  __alignof__(struct ipstats_mib)) < 0)
 		goto err_ip_mib;
 	if (snmp_mib_init((void __percpu **)net->mib.net_statistics,
-			  sizeof(struct linux_mib)) < 0)
+			  sizeof(struct linux_mib),
+			  __alignof__(struct linux_mib)) < 0)
 		goto err_net_mib;
 	if (snmp_mib_init((void __percpu **)net->mib.udp_statistics,
-			  sizeof(struct udp_mib)) < 0)
+			  sizeof(struct udp_mib),
+			  __alignof__(struct udp_mib)) < 0)
 		goto err_udp_mib;
 	if (snmp_mib_init((void __percpu **)net->mib.udplite_statistics,
-			  sizeof(struct udp_mib)) < 0)
+			  sizeof(struct udp_mib),
+			  __alignof__(struct udp_mib)) < 0)
 		goto err_udplite_mib;
 	if (snmp_mib_init((void __percpu **)net->mib.icmp_statistics,
-			  sizeof(struct icmp_mib)) < 0)
+			  sizeof(struct icmp_mib),
+			  __alignof__(struct icmp_mib)) < 0)
 		goto err_icmp_mib;
 	if (snmp_mib_init((void __percpu **)net->mib.icmpmsg_statistics,
-			  sizeof(struct icmpmsg_mib)) < 0)
+			  sizeof(struct icmpmsg_mib),
+			  __alignof__(struct icmpmsg_mib)) < 0)
 		goto err_icmpmsg_mib;
 
 	tcp_mib_init(net);

commit 7b2ff18ee7b0ec4bc3162f821e221781aaca48bd
Author: Jiri Olsa <jolsa@redhat.com>
Date:   Tue Jun 15 01:07:31 2010 +0000

    net - IP_NODEFRAG option for IPv4 socket
    
    this patch is implementing IP_NODEFRAG option for IPv4 socket.
    The reason is, there's no other way to send out the packet with user
    customized header of the reassembly part.
    
    Signed-off-by: Jiri Olsa <jolsa@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index d99e7e020189..b4c0969137cb 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -355,6 +355,8 @@ static int inet_create(struct net *net, struct socket *sock, int protocol,
 	inet = inet_sk(sk);
 	inet->is_icsk = (INET_PROTOSW_ICSK & answer_flags) != 0;
 
+	inet->nodefrag = 0;
+
 	if (SOCK_RAW == sock->type) {
 		inet->inet_num = protocol;
 		if (IPPROTO_RAW == protocol)

commit d8d1f30b95a635dbd610dcc5eb641aca8f4768cf
Author: Changli Gao <xiaosuo@gmail.com>
Date:   Thu Jun 10 23:31:35 2010 -0700

    net-next: remove useless union keyword
    
    remove useless union keyword in rtable, rt6_info and dn_route.
    
    Since there is only one member in a union, the union keyword isn't useful.
    
    Signed-off-by: Changli Gao <xiaosuo@gmail.com>
    Signed-off-by: Eric Dumazet <eric.dumazet@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 551ce564b035..d99e7e020189 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1100,7 +1100,7 @@ static int inet_sk_reselect_saddr(struct sock *sk)
 	if (err)
 		return err;
 
-	sk_setup_caps(sk, &rt->u.dst);
+	sk_setup_caps(sk, &rt->dst);
 
 	new_saddr = rt->rt_src;
 
@@ -1166,7 +1166,7 @@ int inet_sk_rebuild_header(struct sock *sk)
 	err = ip_route_output_flow(sock_net(sk), &rt, &fl, sk, 0);
 }
 	if (!err)
-		sk_setup_caps(sk, &rt->u.dst);
+		sk_setup_caps(sk, &rt->dst);
 	else {
 		/* Routing failed... */
 		sk->sk_route_caps = 0;

commit e3826f1e946e7d2354943232f1457be1455a29e2
Author: Amerigo Wang <amwang@redhat.com>
Date:   Wed May 5 00:27:06 2010 +0000

    net: reserve ports for applications using fixed port numbers
    
    (Dropped the infiniband part, because Tetsuo modified the related code,
    I will send a separate patch for it once this is accepted.)
    
    This patch introduces /proc/sys/net/ipv4/ip_local_reserved_ports which
    allows users to reserve ports for third-party applications.
    
    The reserved ports will not be used by automatic port assignments
    (e.g. when calling connect() or bind() with port number 0). Explicit
    port allocation behavior is unchanged.
    
    Signed-off-by: Octavian Purdila <opurdila@ixiacom.com>
    Signed-off-by: WANG Cong <amwang@redhat.com>
    Cc: Neil Horman <nhorman@tuxdriver.com>
    Cc: Eric Dumazet <eric.dumazet@gmail.com>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index c6c43bcd1c6f..551ce564b035 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1573,9 +1573,13 @@ static int __init inet_init(void)
 
 	BUILD_BUG_ON(sizeof(struct inet_skb_parm) > sizeof(dummy_skb->cb));
 
+	sysctl_local_reserved_ports = kzalloc(65536 / 8, GFP_KERNEL);
+	if (!sysctl_local_reserved_ports)
+		goto out;
+
 	rc = proto_register(&tcp_prot, 1);
 	if (rc)
-		goto out;
+		goto out_free_reserved_ports;
 
 	rc = proto_register(&udp_prot, 1);
 	if (rc)
@@ -1674,6 +1678,8 @@ static int __init inet_init(void)
 	proto_unregister(&udp_prot);
 out_unregister_tcp_proto:
 	proto_unregister(&tcp_prot);
+out_free_reserved_ports:
+	kfree(sysctl_local_reserved_ports);
 	goto out;
 }
 

commit c58dc01babfd58ec9e71a6ce080150dc27755d88
Author: David S. Miller <davem@davemloft.net>
Date:   Tue Apr 27 15:05:31 2010 -0700

    net: Make RFS socket operations not be inet specific.
    
    Idea from Eric Dumazet.
    
    As for placement inside of struct sock, I tried to choose a place
    that otherwise has a 32-bit hole on 64-bit systems.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Acked-by: Eric Dumazet <eric.dumazet@gmail.com>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 9f52880fae10..c6c43bcd1c6f 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -419,7 +419,7 @@ int inet_release(struct socket *sock)
 	if (sk) {
 		long timeout;
 
-		inet_rps_reset_flow(sk);
+		sock_rps_reset_flow(sk);
 
 		/* Applications forget to leave groups before exiting */
 		ip_mc_drop_socket(sk);
@@ -722,7 +722,7 @@ int inet_sendmsg(struct kiocb *iocb, struct socket *sock, struct msghdr *msg,
 {
 	struct sock *sk = sock->sk;
 
-	inet_rps_record_flow(sk);
+	sock_rps_record_flow(sk);
 
 	/* We may need to bind the socket. */
 	if (!inet_sk(sk)->inet_num && inet_autobind(sk))
@@ -737,7 +737,7 @@ static ssize_t inet_sendpage(struct socket *sock, struct page *page, int offset,
 {
 	struct sock *sk = sock->sk;
 
-	inet_rps_record_flow(sk);
+	sock_rps_record_flow(sk);
 
 	/* We may need to bind the socket. */
 	if (!inet_sk(sk)->inet_num && inet_autobind(sk))
@@ -755,7 +755,7 @@ int inet_recvmsg(struct kiocb *iocb, struct socket *sock, struct msghdr *msg,
 	int addr_len = 0;
 	int err;
 
-	inet_rps_record_flow(sk);
+	sock_rps_record_flow(sk);
 
 	err = sk->sk_prot->recvmsg(iocb, sk, msg, size, flags & MSG_DONTWAIT,
 				   flags & ~MSG_DONTWAIT, &addr_len);

commit 0eae88f31ca2b88911ce843452054139e028771f
Author: Eric Dumazet <eric.dumazet@gmail.com>
Date:   Tue Apr 20 19:06:52 2010 -0700

    net: Fix various endianness glitches
    
    Sparse can help us find endianness bugs, but we need to make some
    cleanups to be able to more easily spot real bugs.
    
    Signed-off-by: Eric Dumazet <eric.dumazet@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 5ca7290c2e61..9f52880fae10 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1323,8 +1323,8 @@ static struct sk_buff **inet_gro_receive(struct sk_buff **head,
 	if (unlikely(ip_fast_csum((u8 *)iph, iph->ihl)))
 		goto out_unlock;
 
-	id = ntohl(*(u32 *)&iph->id);
-	flush = (u16)((ntohl(*(u32 *)iph) ^ skb_gro_len(skb)) | (id ^ IP_DF));
+	id = ntohl(*(__be32 *)&iph->id);
+	flush = (u16)((ntohl(*(__be32 *)iph) ^ skb_gro_len(skb)) | (id ^ IP_DF));
 	id >>= 16;
 
 	for (p = *head; p; p = p->next) {
@@ -1337,8 +1337,8 @@ static struct sk_buff **inet_gro_receive(struct sk_buff **head,
 
 		if ((iph->protocol ^ iph2->protocol) |
 		    (iph->tos ^ iph2->tos) |
-		    (iph->saddr ^ iph2->saddr) |
-		    (iph->daddr ^ iph2->daddr)) {
+		    ((__force u32)iph->saddr ^ (__force u32)iph2->saddr) |
+		    ((__force u32)iph->daddr ^ (__force u32)iph2->daddr)) {
 			NAPI_GRO_CB(p)->same_flow = 0;
 			continue;
 		}

commit aa395145165cb06a0d0885221bbe0ce4a564391d
Author: Eric Dumazet <eric.dumazet@gmail.com>
Date:   Tue Apr 20 13:03:51 2010 +0000

    net: sk_sleep() helper
    
    Define a new function to return the waitqueue of a "struct sock".
    
    static inline wait_queue_head_t *sk_sleep(struct sock *sk)
    {
            return sk->sk_sleep;
    }
    
    Change all read occurrences of sk_sleep by a call to this function.
    
    Needed for a future RCU conversion. sk_sleep wont be a field directly
    available.
    
    Signed-off-by: Eric Dumazet <eric.dumazet@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index c5376c725503..5ca7290c2e61 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -548,7 +548,7 @@ static long inet_wait_for_connect(struct sock *sk, long timeo)
 {
 	DEFINE_WAIT(wait);
 
-	prepare_to_wait(sk->sk_sleep, &wait, TASK_INTERRUPTIBLE);
+	prepare_to_wait(sk_sleep(sk), &wait, TASK_INTERRUPTIBLE);
 
 	/* Basic assumption: if someone sets sk->sk_err, he _must_
 	 * change state of the socket from TCP_SYN_*.
@@ -561,9 +561,9 @@ static long inet_wait_for_connect(struct sock *sk, long timeo)
 		lock_sock(sk);
 		if (signal_pending(current) || !timeo)
 			break;
-		prepare_to_wait(sk->sk_sleep, &wait, TASK_INTERRUPTIBLE);
+		prepare_to_wait(sk_sleep(sk), &wait, TASK_INTERRUPTIBLE);
 	}
-	finish_wait(sk->sk_sleep, &wait);
+	finish_wait(sk_sleep(sk), &wait);
 	return timeo;
 }
 

commit fec5e652e58fa6017b2c9e06466cb2a6538de5b4
Author: Tom Herbert <therbert@google.com>
Date:   Fri Apr 16 16:01:27 2010 -0700

    rfs: Receive Flow Steering
    
    This patch implements receive flow steering (RFS).  RFS steers
    received packets for layer 3 and 4 processing to the CPU where
    the application for the corresponding flow is running.  RFS is an
    extension of Receive Packet Steering (RPS).
    
    The basic idea of RFS is that when an application calls recvmsg
    (or sendmsg) the application's running CPU is stored in a hash
    table that is indexed by the connection's rxhash which is stored in
    the socket structure.  The rxhash is passed in skb's received on
    the connection from netif_receive_skb.  For each received packet,
    the associated rxhash is used to look up the CPU in the hash table,
    if a valid CPU is set then the packet is steered to that CPU using
    the RPS mechanisms.
    
    The convolution of the simple approach is that it would potentially
    allow OOO packets.  If threads are thrashing around CPUs or multiple
    threads are trying to read from the same sockets, a quickly changing
    CPU value in the hash table could cause rampant OOO packets--
    we consider this a non-starter.
    
    To avoid OOO packets, this solution implements two types of hash
    tables: rps_sock_flow_table and rps_dev_flow_table.
    
    rps_sock_table is a global hash table.  Each entry is just a CPU
    number and it is populated in recvmsg and sendmsg as described above.
    This table contains the "desired" CPUs for flows.
    
    rps_dev_flow_table is specific to each device queue.  Each entry
    contains a CPU and a tail queue counter.  The CPU is the "current"
    CPU for a matching flow.  The tail queue counter holds the value
    of a tail queue counter for the associated CPU's backlog queue at
    the time of last enqueue for a flow matching the entry.
    
    Each backlog queue has a queue head counter which is incremented
    on dequeue, and so a queue tail counter is computed as queue head
    count + queue length.  When a packet is enqueued on a backlog queue,
    the current value of the queue tail counter is saved in the hash
    entry of the rps_dev_flow_table.
    
    And now the trick: when selecting the CPU for RPS (get_rps_cpu)
    the rps_sock_flow table and the rps_dev_flow table for the RX queue
    are consulted.  When the desired CPU for the flow (found in the
    rps_sock_flow table) does not match the current CPU (found in the
    rps_dev_flow table), the current CPU is changed to the desired CPU
    if one of the following is true:
    
    - The current CPU is unset (equal to RPS_NO_CPU)
    - Current CPU is offline
    - The current CPU's queue head counter >= queue tail counter in the
    rps_dev_flow table.  This checks if the queue tail has advanced
    beyond the last packet that was enqueued using this table entry.
    This guarantees that all packets queued using this entry have been
    dequeued, thus preserving in order delivery.
    
    Making each queue have its own rps_dev_flow table has two advantages:
    1) the tail queue counters will be written on each receive, so
    keeping the table local to interrupting CPU s good for locality.  2)
    this allows lockless access to the table-- the CPU number and queue
    tail counter need to be accessed together under mutual exclusion
    from netif_receive_skb, we assume that this is only called from
    device napi_poll which is non-reentrant.
    
    This patch implements RFS for TCP and connected UDP sockets.
    It should be usable for other flow oriented protocols.
    
    There are two configuration parameters for RFS.  The
    "rps_flow_entries" kernel init parameter sets the number of
    entries in the rps_sock_flow_table, the per rxqueue sysfs entry
    "rps_flow_cnt" contains the number of entries in the rps_dev_flow
    table for the rxqueue.  Both are rounded to power of two.
    
    The obvious benefit of RFS (over just RPS) is that it achieves
    CPU locality between the receive processing for a flow and the
    applications processing; this can result in increased performance
    (higher pps, lower latency).
    
    The benefits of RFS are dependent on cache hierarchy, application
    load, and other factors.  On simple benchmarks, we don't necessarily
    see improvement and sometimes see degradation.  However, for more
    complex benchmarks and for applications where cache pressure is
    much higher this technique seems to perform very well.
    
    Below are some benchmark results which show the potential benfit of
    this patch.  The netperf test has 500 instances of netperf TCP_RR
    test with 1 byte req. and resp.  The RPC test is an request/response
    test similar in structure to netperf RR test ith 100 threads on
    each host, but does more work in userspace that netperf.
    
    e1000e on 8 core Intel
       No RFS or RPS                104K tps at 30% CPU
       No RFS (best RPS config):    290K tps at 63% CPU
       RFS                          303K tps at 61% CPU
    
    RPC test        tps     CPU%    50/90/99% usec latency  Latency StdDev
      No RFS/RPS    103K    48%     757/900/3185            4472.35
      RPS only:     174K    73%     415/993/2468            491.66
      RFS           223K    73%     379/651/1382            315.61
    
    Signed-off-by: Tom Herbert <therbert@google.com>
    Signed-off-by: Eric Dumazet <eric.dumazet@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 193dcd6ed64f..c5376c725503 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -419,6 +419,8 @@ int inet_release(struct socket *sock)
 	if (sk) {
 		long timeout;
 
+		inet_rps_reset_flow(sk);
+
 		/* Applications forget to leave groups before exiting */
 		ip_mc_drop_socket(sk);
 
@@ -720,6 +722,8 @@ int inet_sendmsg(struct kiocb *iocb, struct socket *sock, struct msghdr *msg,
 {
 	struct sock *sk = sock->sk;
 
+	inet_rps_record_flow(sk);
+
 	/* We may need to bind the socket. */
 	if (!inet_sk(sk)->inet_num && inet_autobind(sk))
 		return -EAGAIN;
@@ -728,12 +732,13 @@ int inet_sendmsg(struct kiocb *iocb, struct socket *sock, struct msghdr *msg,
 }
 EXPORT_SYMBOL(inet_sendmsg);
 
-
 static ssize_t inet_sendpage(struct socket *sock, struct page *page, int offset,
 			     size_t size, int flags)
 {
 	struct sock *sk = sock->sk;
 
+	inet_rps_record_flow(sk);
+
 	/* We may need to bind the socket. */
 	if (!inet_sk(sk)->inet_num && inet_autobind(sk))
 		return -EAGAIN;
@@ -743,6 +748,22 @@ static ssize_t inet_sendpage(struct socket *sock, struct page *page, int offset,
 	return sock_no_sendpage(sock, page, offset, size, flags);
 }
 
+int inet_recvmsg(struct kiocb *iocb, struct socket *sock, struct msghdr *msg,
+		 size_t size, int flags)
+{
+	struct sock *sk = sock->sk;
+	int addr_len = 0;
+	int err;
+
+	inet_rps_record_flow(sk);
+
+	err = sk->sk_prot->recvmsg(iocb, sk, msg, size, flags & MSG_DONTWAIT,
+				   flags & ~MSG_DONTWAIT, &addr_len);
+	if (err >= 0)
+		msg->msg_namelen = addr_len;
+	return err;
+}
+EXPORT_SYMBOL(inet_recvmsg);
 
 int inet_shutdown(struct socket *sock, int how)
 {
@@ -872,7 +893,7 @@ const struct proto_ops inet_stream_ops = {
 	.setsockopt	   = sock_common_setsockopt,
 	.getsockopt	   = sock_common_getsockopt,
 	.sendmsg	   = tcp_sendmsg,
-	.recvmsg	   = sock_common_recvmsg,
+	.recvmsg	   = inet_recvmsg,
 	.mmap		   = sock_no_mmap,
 	.sendpage	   = tcp_sendpage,
 	.splice_read	   = tcp_splice_read,
@@ -899,7 +920,7 @@ const struct proto_ops inet_dgram_ops = {
 	.setsockopt	   = sock_common_setsockopt,
 	.getsockopt	   = sock_common_getsockopt,
 	.sendmsg	   = inet_sendmsg,
-	.recvmsg	   = sock_common_recvmsg,
+	.recvmsg	   = inet_recvmsg,
 	.mmap		   = sock_no_mmap,
 	.sendpage	   = inet_sendpage,
 #ifdef CONFIG_COMPAT
@@ -929,7 +950,7 @@ static const struct proto_ops inet_sockraw_ops = {
 	.setsockopt	   = sock_common_setsockopt,
 	.getsockopt	   = sock_common_getsockopt,
 	.sendmsg	   = inet_sendmsg,
-	.recvmsg	   = sock_common_recvmsg,
+	.recvmsg	   = inet_recvmsg,
 	.mmap		   = sock_no_mmap,
 	.sendpage	   = inet_sendpage,
 #ifdef CONFIG_COMPAT

commit b6c6712a42ca3f9fa7f4a3d7c40e3a9dd1fd9e03
Author: Eric Dumazet <eric.dumazet@gmail.com>
Date:   Thu Apr 8 23:03:29 2010 +0000

    net: sk_dst_cache RCUification
    
    With latest CONFIG_PROVE_RCU stuff, I felt more comfortable to make this
    work.
    
    sk->sk_dst_cache is currently protected by a rwlock (sk_dst_lock)
    
    This rwlock is readlocked for a very small amount of time, and dst
    entries are already freed after RCU grace period. This calls for RCU
    again :)
    
    This patch converts sk_dst_lock to a spinlock, and use RCU for readers.
    
    __sk_dst_get() is supposed to be called with rcu_read_lock() or if
    socket locked by user, so use appropriate rcu_dereference_check()
    condition (rcu_read_lock_held() || sock_owned_by_user(sk))
    
    This patch avoids two atomic ops per tx packet on UDP connected sockets,
    for example, and permits sk_dst_lock to be much less dirtied.
    
    Signed-off-by: Eric Dumazet <eric.dumazet@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index a0beb32beaa3..193dcd6ed64f 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -154,7 +154,7 @@ void inet_sock_destruct(struct sock *sk)
 	WARN_ON(sk->sk_forward_alloc);
 
 	kfree(inet->opt);
-	dst_release(sk->sk_dst_cache);
+	dst_release(rcu_dereference_check(sk->sk_dst_cache, 1));
 	sk_refcnt_debug_dec(sk);
 }
 EXPORT_SYMBOL(inet_sock_destruct);

commit 871039f02f8ec4ab2e5e9010718caa8e085786f1
Merge: e4077e018b5e 4a1032faac94
Author: David S. Miller <davem@davemloft.net>
Date:   Sun Apr 11 14:53:53 2010 -0700

    Merge branch 'master' of master.kernel.org:/pub/scm/linux/kernel/git/davem/net-2.6
    
    Conflicts:
            drivers/net/stmmac/stmmac_main.c
            drivers/net/wireless/wl12xx/wl1271_cmd.c
            drivers/net/wireless/wl12xx/wl1271_main.c
            drivers/net/wireless/wl12xx/wl1271_spi.c
            net/core/ethtool.c
            net/mac80211/scan.c

commit 4a35ecf8bf1c4b039503fa554100fe85c761de76
Merge: b4d562e3c355 fb9e2d887243
Author: David S. Miller <davem@davemloft.net>
Date:   Tue Apr 6 23:53:30 2010 -0700

    Merge branch 'master' of master.kernel.org:/pub/scm/linux/kernel/git/davem/net-2.6
    
    Conflicts:
            drivers/net/bonding/bond_main.c
            drivers/net/via-velocity.c
            drivers/net/wireless/iwlwifi/iwl-agn.c

commit cb4361c1dc29cd870f664c004b1817106fbce0fa
Merge: 309361e09ca9 fb9e2d887243
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Apr 6 08:34:06 2010 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/davem/net-2.6
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/davem/net-2.6: (37 commits)
      smc91c92_cs: fix the problem of "Unable to find hardware address"
      r8169: clean up my printk uglyness
      net: Hook up cxgb4 to Kconfig and Makefile
      cxgb4: Add main driver file and driver Makefile
      cxgb4: Add remaining driver headers and L2T management
      cxgb4: Add packet queues and packet DMA code
      cxgb4: Add HW and FW support code
      cxgb4: Add register, message, and FW definitions
      netlabel: Fix several rcu_dereference() calls used without RCU read locks
      bonding: fix potential deadlock in bond_uninit()
      net: check the length of the socket address passed to connect(2)
      stmmac: add documentation for the driver.
      stmmac: fix kconfig for crc32 build error
      be2net: fix bug in vlan rx path for big endian architecture
      be2net: fix flashing on big endian architectures
      be2net: fix a bug in flashing the redboot section
      bonding: bond_xmit_roundrobin() fix
      drivers/net: Add missing unlock
      net: gianfar - align BD ring size console messages
      net: gianfar - initialize per-queue statistics
      ...

commit 6503d96168f891ffa3b70ae6c9698a1a722025a0
Author: Changli Gao <xiaosuo@gmail.com>
Date:   Wed Mar 31 22:58:26 2010 +0000

    net: check the length of the socket address passed to connect(2)
    
    check the length of the socket address passed to connect(2).
    
    Check the length of the socket address passed to connect(2). If the
    length is invalid, -EINVAL will be returned.
    
    Signed-off-by: Changli Gao <xiaosuo@gmail.com>
    ----
    net/bluetooth/l2cap.c | 3 ++-
    net/bluetooth/rfcomm/sock.c | 3 ++-
    net/bluetooth/sco.c | 3 ++-
    net/can/bcm.c | 3 +++
    net/ieee802154/af_ieee802154.c | 3 +++
    net/ipv4/af_inet.c | 5 +++++
    net/netlink/af_netlink.c | 3 +++
    7 files changed, 20 insertions(+), 3 deletions(-)
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 33b7dffa7732..a366861bf4cd 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -530,6 +530,8 @@ int inet_dgram_connect(struct socket *sock, struct sockaddr * uaddr,
 {
 	struct sock *sk = sock->sk;
 
+	if (addr_len < sizeof(uaddr->sa_family))
+		return -EINVAL;
 	if (uaddr->sa_family == AF_UNSPEC)
 		return sk->sk_prot->disconnect(sk, flags);
 
@@ -573,6 +575,9 @@ int inet_stream_connect(struct socket *sock, struct sockaddr *uaddr,
 	int err;
 	long timeo;
 
+	if (addr_len < sizeof(uaddr->sa_family))
+		return -EINVAL;
+
 	lock_sock(sk);
 
 	if (uaddr->sa_family == AF_UNSPEC) {

commit 5a0e3ad6af8660be21ca98a971cd00f331318c05
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Mar 24 17:04:11 2010 +0900

    include cleanup: Update gfp.h and slab.h includes to prepare for breaking implicit slab.h inclusion from percpu.h
    
    percpu.h is included by sched.h and module.h and thus ends up being
    included when building most .c files.  percpu.h includes slab.h which
    in turn includes gfp.h making everything defined by the two files
    universally available and complicating inclusion dependencies.
    
    percpu.h -> slab.h dependency is about to be removed.  Prepare for
    this change by updating users of gfp and slab facilities include those
    headers directly instead of assuming availability.  As this conversion
    needs to touch large number of source files, the following script is
    used as the basis of conversion.
    
      http://userweb.kernel.org/~tj/misc/slabh-sweep.py
    
    The script does the followings.
    
    * Scan files for gfp and slab usages and update includes such that
      only the necessary includes are there.  ie. if only gfp is used,
      gfp.h, if slab is used, slab.h.
    
    * When the script inserts a new include, it looks at the include
      blocks and try to put the new include such that its order conforms
      to its surrounding.  It's put in the include block which contains
      core kernel includes, in the same order that the rest are ordered -
      alphabetical, Christmas tree, rev-Xmas-tree or at the end if there
      doesn't seem to be any matching order.
    
    * If the script can't find a place to put a new include (mostly
      because the file doesn't have fitting include block), it prints out
      an error message indicating which .h file needs to be added to the
      file.
    
    The conversion was done in the following steps.
    
    1. The initial automatic conversion of all .c files updated slightly
       over 4000 files, deleting around 700 includes and adding ~480 gfp.h
       and ~3000 slab.h inclusions.  The script emitted errors for ~400
       files.
    
    2. Each error was manually checked.  Some didn't need the inclusion,
       some needed manual addition while adding it to implementation .h or
       embedding .c file was more appropriate for others.  This step added
       inclusions to around 150 files.
    
    3. The script was run again and the output was compared to the edits
       from #2 to make sure no file was left behind.
    
    4. Several build tests were done and a couple of problems were fixed.
       e.g. lib/decompress_*.c used malloc/free() wrappers around slab
       APIs requiring slab.h to be added manually.
    
    5. The script was run on all .h files but without automatically
       editing them as sprinkling gfp.h and slab.h inclusions around .h
       files could easily lead to inclusion dependency hell.  Most gfp.h
       inclusion directives were ignored as stuff from gfp.h was usually
       wildly available and often used in preprocessor macros.  Each
       slab.h inclusion directive was examined and added manually as
       necessary.
    
    6. percpu.h was updated not to include slab.h.
    
    7. Build test were done on the following configurations and failures
       were fixed.  CONFIG_GCOV_KERNEL was turned off for all tests (as my
       distributed build env didn't work with gcov compiles) and a few
       more options had to be turned off depending on archs to make things
       build (like ipr on powerpc/64 which failed due to missing writeq).
    
       * x86 and x86_64 UP and SMP allmodconfig and a custom test config.
       * powerpc and powerpc64 SMP allmodconfig
       * sparc and sparc64 SMP allmodconfig
       * ia64 SMP allmodconfig
       * s390 SMP allmodconfig
       * alpha SMP allmodconfig
       * um on x86_64 SMP allmodconfig
    
    8. percpu.h modifications were reverted so that it could be applied as
       a separate patch and serve as bisection point.
    
    Given the fact that I had only a couple of failures from tests on step
    6, I'm fairly confident about the coverage of this conversion patch.
    If there is a breakage, it's likely to be something in one of the arch
    headers which should be easily discoverable easily on most builds of
    the specific arch.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Guess-its-ok-by: Christoph Lameter <cl@linux-foundation.org>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Lee Schermerhorn <Lee.Schermerhorn@hp.com>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 33b7dffa7732..2ed85714540f 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -86,6 +86,7 @@
 #include <linux/poll.h>
 #include <linux/netfilter_ipv4.h>
 #include <linux/random.h>
+#include <linux/slab.h>
 
 #include <asm/uaccess.h>
 #include <asm/system.h>

commit ec733b15a3ef0b5759141a177f8044a2f40c41e7
Author: Eric Dumazet <eric.dumazet@gmail.com>
Date:   Thu Mar 18 20:36:06 2010 +0000

    net: snmp mib cleanup
    
    There is no point to align or pad mibs to cache lines, they are per cpu
    allocated with a 8 bytes alignment anyway.
    This wastes space for no gain. This patch removes __SNMP_MIB_ALIGN__
    
    Since SNMP mibs contain "unsigned long" fields only, we can relax the
    allocation alignment from "unsigned long long" to "unsigned long"
    
    Signed-off-by: Eric Dumazet <eric.dumazet@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 33b7dffa7732..55e11906a73a 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1401,10 +1401,10 @@ EXPORT_SYMBOL_GPL(snmp_fold_field);
 int snmp_mib_init(void __percpu *ptr[2], size_t mibsize)
 {
 	BUG_ON(ptr == NULL);
-	ptr[0] = __alloc_percpu(mibsize, __alignof__(unsigned long long));
+	ptr[0] = __alloc_percpu(mibsize, __alignof__(unsigned long));
 	if (!ptr[0])
 		goto err0;
-	ptr[1] = __alloc_percpu(mibsize, __alignof__(unsigned long long));
+	ptr[1] = __alloc_percpu(mibsize, __alignof__(unsigned long));
 	if (!ptr[1])
 		goto err1;
 	return 0;

commit 7d720c3e4f0c4fc152a6bf17e24244a3c85412d2
Author: Tejun Heo <tj@kernel.org>
Date:   Tue Feb 16 15:20:26 2010 +0000

    percpu: add __percpu sparse annotations to net
    
    Add __percpu sparse annotations to net.
    
    These annotations are to make sparse consider percpu variables to be
    in a different address space and warn if accessed without going
    through percpu accessors.  This patch doesn't affect normal builds.
    
    The macro and type tricks around snmp stats make things a bit
    interesting.  DEFINE/DECLARE_SNMP_STAT() macros mark the target field
    as __percpu and SNMP_UPD_PO_STATS() macro is updated accordingly.  All
    snmp_mib_*() users which used to cast the argument to (void **) are
    updated to cast it to (void __percpu **).
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: David S. Miller <davem@davemloft.net>
    Cc: Patrick McHardy <kaber@trash.net>
    Cc: Arnaldo Carvalho de Melo <acme@ghostprotocols.net>
    Cc: Vlad Yasevich <vladislav.yasevich@hp.com>
    Cc: netdev@vger.kernel.org
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 7d12c6a9b19b..33b7dffa7732 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1385,7 +1385,7 @@ int inet_ctl_sock_create(struct sock **sk, unsigned short family,
 }
 EXPORT_SYMBOL_GPL(inet_ctl_sock_create);
 
-unsigned long snmp_fold_field(void *mib[], int offt)
+unsigned long snmp_fold_field(void __percpu *mib[], int offt)
 {
 	unsigned long res = 0;
 	int i;
@@ -1398,7 +1398,7 @@ unsigned long snmp_fold_field(void *mib[], int offt)
 }
 EXPORT_SYMBOL_GPL(snmp_fold_field);
 
-int snmp_mib_init(void *ptr[2], size_t mibsize)
+int snmp_mib_init(void __percpu *ptr[2], size_t mibsize)
 {
 	BUG_ON(ptr == NULL);
 	ptr[0] = __alloc_percpu(mibsize, __alignof__(unsigned long long));
@@ -1416,7 +1416,7 @@ int snmp_mib_init(void *ptr[2], size_t mibsize)
 }
 EXPORT_SYMBOL_GPL(snmp_mib_init);
 
-void snmp_mib_free(void *ptr[2])
+void snmp_mib_free(void __percpu *ptr[2])
 {
 	BUG_ON(ptr == NULL);
 	free_percpu(ptr[0]);
@@ -1460,25 +1460,25 @@ static const struct net_protocol icmp_protocol = {
 
 static __net_init int ipv4_mib_init_net(struct net *net)
 {
-	if (snmp_mib_init((void **)net->mib.tcp_statistics,
+	if (snmp_mib_init((void __percpu **)net->mib.tcp_statistics,
 			  sizeof(struct tcp_mib)) < 0)
 		goto err_tcp_mib;
-	if (snmp_mib_init((void **)net->mib.ip_statistics,
+	if (snmp_mib_init((void __percpu **)net->mib.ip_statistics,
 			  sizeof(struct ipstats_mib)) < 0)
 		goto err_ip_mib;
-	if (snmp_mib_init((void **)net->mib.net_statistics,
+	if (snmp_mib_init((void __percpu **)net->mib.net_statistics,
 			  sizeof(struct linux_mib)) < 0)
 		goto err_net_mib;
-	if (snmp_mib_init((void **)net->mib.udp_statistics,
+	if (snmp_mib_init((void __percpu **)net->mib.udp_statistics,
 			  sizeof(struct udp_mib)) < 0)
 		goto err_udp_mib;
-	if (snmp_mib_init((void **)net->mib.udplite_statistics,
+	if (snmp_mib_init((void __percpu **)net->mib.udplite_statistics,
 			  sizeof(struct udp_mib)) < 0)
 		goto err_udplite_mib;
-	if (snmp_mib_init((void **)net->mib.icmp_statistics,
+	if (snmp_mib_init((void __percpu **)net->mib.icmp_statistics,
 			  sizeof(struct icmp_mib)) < 0)
 		goto err_icmp_mib;
-	if (snmp_mib_init((void **)net->mib.icmpmsg_statistics,
+	if (snmp_mib_init((void __percpu **)net->mib.icmpmsg_statistics,
 			  sizeof(struct icmpmsg_mib)) < 0)
 		goto err_icmpmsg_mib;
 
@@ -1486,30 +1486,30 @@ static __net_init int ipv4_mib_init_net(struct net *net)
 	return 0;
 
 err_icmpmsg_mib:
-	snmp_mib_free((void **)net->mib.icmp_statistics);
+	snmp_mib_free((void __percpu **)net->mib.icmp_statistics);
 err_icmp_mib:
-	snmp_mib_free((void **)net->mib.udplite_statistics);
+	snmp_mib_free((void __percpu **)net->mib.udplite_statistics);
 err_udplite_mib:
-	snmp_mib_free((void **)net->mib.udp_statistics);
+	snmp_mib_free((void __percpu **)net->mib.udp_statistics);
 err_udp_mib:
-	snmp_mib_free((void **)net->mib.net_statistics);
+	snmp_mib_free((void __percpu **)net->mib.net_statistics);
 err_net_mib:
-	snmp_mib_free((void **)net->mib.ip_statistics);
+	snmp_mib_free((void __percpu **)net->mib.ip_statistics);
 err_ip_mib:
-	snmp_mib_free((void **)net->mib.tcp_statistics);
+	snmp_mib_free((void __percpu **)net->mib.tcp_statistics);
 err_tcp_mib:
 	return -ENOMEM;
 }
 
 static __net_exit void ipv4_mib_exit_net(struct net *net)
 {
-	snmp_mib_free((void **)net->mib.icmpmsg_statistics);
-	snmp_mib_free((void **)net->mib.icmp_statistics);
-	snmp_mib_free((void **)net->mib.udplite_statistics);
-	snmp_mib_free((void **)net->mib.udp_statistics);
-	snmp_mib_free((void **)net->mib.net_statistics);
-	snmp_mib_free((void **)net->mib.ip_statistics);
-	snmp_mib_free((void **)net->mib.tcp_statistics);
+	snmp_mib_free((void __percpu **)net->mib.icmpmsg_statistics);
+	snmp_mib_free((void __percpu **)net->mib.icmp_statistics);
+	snmp_mib_free((void __percpu **)net->mib.udplite_statistics);
+	snmp_mib_free((void __percpu **)net->mib.udp_statistics);
+	snmp_mib_free((void __percpu **)net->mib.net_statistics);
+	snmp_mib_free((void __percpu **)net->mib.ip_statistics);
+	snmp_mib_free((void __percpu **)net->mib.tcp_statistics);
 }
 
 static __net_initdata struct pernet_operations ipv4_mib_ops = {

commit c84b3268da3b85c9d8a9e504e1001a14ed829e94
Author: Eric Paris <eparis@redhat.com>
Date:   Thu Nov 5 20:45:52 2009 -0800

    net: check kern before calling security subsystem
    
    Before calling capable(CAP_NET_RAW) check if this operations is on behalf
    of the kernel or on behalf of userspace.  Do not do the security check if
    it is on behalf of the kernel.
    
    Signed-off-by: Eric Paris <eparis@redhat.com>
    Acked-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 5c7e42c02afb..7d12c6a9b19b 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -326,7 +326,7 @@ static int inet_create(struct net *net, struct socket *sock, int protocol,
 	}
 
 	err = -EPERM;
-	if (sock->type == SOCK_RAW && !capable(CAP_NET_RAW))
+	if (sock->type == SOCK_RAW && !kern && !capable(CAP_NET_RAW))
 		goto out_rcu_unlock;
 
 	err = -EAFNOSUPPORT;

commit 3f378b684453f2a028eda463ce383370545d9cc9
Author: Eric Paris <eparis@redhat.com>
Date:   Thu Nov 5 22:18:14 2009 -0800

    net: pass kern to net_proto_family create function
    
    The generic __sock_create function has a kern argument which allows the
    security system to make decisions based on if a socket is being created by
    the kernel or by userspace.  This patch passes that flag to the
    net_proto_family specific create function, so it can do the same thing.
    
    Signed-off-by: Eric Paris <eparis@redhat.com>
    Acked-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 180ec4c94919..5c7e42c02afb 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -262,7 +262,8 @@ static inline int inet_netns_ok(struct net *net, int protocol)
  *	Create an inet socket.
  */
 
-static int inet_create(struct net *net, struct socket *sock, int protocol)
+static int inet_create(struct net *net, struct socket *sock, int protocol,
+		       int kern)
 {
 	struct sock *sk;
 	struct inet_protosw *answer;

commit 13f18aa05f5abe135f47b6417537ae2b2fedc18c
Author: Eric Paris <eparis@redhat.com>
Date:   Thu Nov 5 20:44:37 2009 -0800

    net: drop capability from protocol definitions
    
    struct can_proto had a capability field which wasn't ever used.  It is
    dropped entirely.
    
    struct inet_protosw had a capability field which can be more clearly
    expressed in the code by just checking if sock->type = SOCK_RAW.
    
    Signed-off-by: Eric Paris <eparis@redhat.com>
    Acked-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 538e84d0bcba..180ec4c94919 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -325,7 +325,7 @@ static int inet_create(struct net *net, struct socket *sock, int protocol)
 	}
 
 	err = -EPERM;
-	if (answer->capability > 0 && !capable(answer->capability))
+	if (sock->type == SOCK_RAW && !capable(CAP_NET_RAW))
 		goto out_rcu_unlock;
 
 	err = -EAFNOSUPPORT;
@@ -947,7 +947,6 @@ static struct inet_protosw inetsw_array[] =
 		.protocol =   IPPROTO_TCP,
 		.prot =       &tcp_prot,
 		.ops =        &inet_stream_ops,
-		.capability = -1,
 		.no_check =   0,
 		.flags =      INET_PROTOSW_PERMANENT |
 			      INET_PROTOSW_ICSK,
@@ -958,7 +957,6 @@ static struct inet_protosw inetsw_array[] =
 		.protocol =   IPPROTO_UDP,
 		.prot =       &udp_prot,
 		.ops =        &inet_dgram_ops,
-		.capability = -1,
 		.no_check =   UDP_CSUM_DEFAULT,
 		.flags =      INET_PROTOSW_PERMANENT,
        },
@@ -969,7 +967,6 @@ static struct inet_protosw inetsw_array[] =
 	       .protocol =   IPPROTO_IP,	/* wild card */
 	       .prot =       &raw_prot,
 	       .ops =        &inet_sockraw_ops,
-	       .capability = CAP_NET_RAW,
 	       .no_check =   UDP_CSUM_DEFAULT,
 	       .flags =      INET_PROTOSW_REUSE,
        }

commit 38bfd8f5bec496e8e0db8849e01c99a33479418a
Author: Cyrill Gorcunov <gorcunov@openvz.org>
Date:   Thu Oct 29 02:59:18 2009 -0700

    net,socket: introduce DECLARE_SOCKADDR helper to catch overflow at build time
    
    proto_ops->getname implies copying protocol specific data
    into storage unit (particulary to __kernel_sockaddr_storage).
    So when we implement new protocol support we should keep such
    a detail in mind (which is easy to forget about).
    
    Lets introduce DECLARE_SOCKADDR helper which check if
    storage unit is not overfowed at build time.
    
    Eventually inet_getname is switched to use DECLARE_SOCKADDR
    (to show example of usage).
    
    Signed-off-by: Cyrill Gorcunov <gorcunov@openvz.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 04a14b1600ac..538e84d0bcba 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -685,7 +685,7 @@ int inet_getname(struct socket *sock, struct sockaddr *uaddr,
 {
 	struct sock *sk		= sock->sk;
 	struct inet_sock *inet	= inet_sk(sk);
-	struct sockaddr_in *sin	= (struct sockaddr_in *)uaddr;
+	DECLARE_SOCKADDR(struct sockaddr_in *, sin, uaddr);
 
 	sin->sin_family = AF_INET;
 	if (peer) {

commit c720c7e8383aff1cb219bddf474ed89d850336e3
Author: Eric Dumazet <eric.dumazet@gmail.com>
Date:   Thu Oct 15 06:30:45 2009 +0000

    inet: rename some inet_sock fields
    
    In order to have better cache layouts of struct sock (separate zones
    for rx/tx paths), we need this preliminary patch.
    
    Goal is to transfert fields used at lookup time in the first
    read-mostly cache line (inside struct sock_common) and move sk_refcnt
    to a separate cache line (only written by rx path)
    
    This patch adds inet_ prefix to daddr, rcv_saddr, dport, num, saddr,
    sport and id fields. This allows a future patch to define these
    fields as macros, like sk_refcnt, without name clashes.
    
    Signed-off-by: Eric Dumazet <eric.dumazet@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 1deff48b122e..04a14b1600ac 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -174,12 +174,12 @@ static int inet_autobind(struct sock *sk)
 	/* We may need to bind the socket. */
 	lock_sock(sk);
 	inet = inet_sk(sk);
-	if (!inet->num) {
+	if (!inet->inet_num) {
 		if (sk->sk_prot->get_port(sk, 0)) {
 			release_sock(sk);
 			return -EAGAIN;
 		}
-		inet->sport = htons(inet->num);
+		inet->inet_sport = htons(inet->inet_num);
 	}
 	release_sock(sk);
 	return 0;
@@ -354,7 +354,7 @@ static int inet_create(struct net *net, struct socket *sock, int protocol)
 	inet->is_icsk = (INET_PROTOSW_ICSK & answer_flags) != 0;
 
 	if (SOCK_RAW == sock->type) {
-		inet->num = protocol;
+		inet->inet_num = protocol;
 		if (IPPROTO_RAW == protocol)
 			inet->hdrincl = 1;
 	}
@@ -364,7 +364,7 @@ static int inet_create(struct net *net, struct socket *sock, int protocol)
 	else
 		inet->pmtudisc = IP_PMTUDISC_WANT;
 
-	inet->id = 0;
+	inet->inet_id = 0;
 
 	sock_init_data(sock, sk);
 
@@ -381,13 +381,13 @@ static int inet_create(struct net *net, struct socket *sock, int protocol)
 
 	sk_refcnt_debug_inc(sk);
 
-	if (inet->num) {
+	if (inet->inet_num) {
 		/* It assumes that any protocol which allows
 		 * the user to assign a number at socket
 		 * creation time automatically
 		 * shares.
 		 */
-		inet->sport = htons(inet->num);
+		inet->inet_sport = htons(inet->inet_num);
 		/* Add to protocol hash chains. */
 		sk->sk_prot->hash(sk);
 	}
@@ -494,27 +494,27 @@ int inet_bind(struct socket *sock, struct sockaddr *uaddr, int addr_len)
 
 	/* Check these errors (active socket, double bind). */
 	err = -EINVAL;
-	if (sk->sk_state != TCP_CLOSE || inet->num)
+	if (sk->sk_state != TCP_CLOSE || inet->inet_num)
 		goto out_release_sock;
 
-	inet->rcv_saddr = inet->saddr = addr->sin_addr.s_addr;
+	inet->inet_rcv_saddr = inet->inet_saddr = addr->sin_addr.s_addr;
 	if (chk_addr_ret == RTN_MULTICAST || chk_addr_ret == RTN_BROADCAST)
-		inet->saddr = 0;  /* Use device */
+		inet->inet_saddr = 0;  /* Use device */
 
 	/* Make sure we are allowed to bind here. */
 	if (sk->sk_prot->get_port(sk, snum)) {
-		inet->saddr = inet->rcv_saddr = 0;
+		inet->inet_saddr = inet->inet_rcv_saddr = 0;
 		err = -EADDRINUSE;
 		goto out_release_sock;
 	}
 
-	if (inet->rcv_saddr)
+	if (inet->inet_rcv_saddr)
 		sk->sk_userlocks |= SOCK_BINDADDR_LOCK;
 	if (snum)
 		sk->sk_userlocks |= SOCK_BINDPORT_LOCK;
-	inet->sport = htons(inet->num);
-	inet->daddr = 0;
-	inet->dport = 0;
+	inet->inet_sport = htons(inet->inet_num);
+	inet->inet_daddr = 0;
+	inet->inet_dport = 0;
 	sk_dst_reset(sk);
 	err = 0;
 out_release_sock:
@@ -532,7 +532,7 @@ int inet_dgram_connect(struct socket *sock, struct sockaddr * uaddr,
 	if (uaddr->sa_family == AF_UNSPEC)
 		return sk->sk_prot->disconnect(sk, flags);
 
-	if (!inet_sk(sk)->num && inet_autobind(sk))
+	if (!inet_sk(sk)->inet_num && inet_autobind(sk))
 		return -EAGAIN;
 	return sk->sk_prot->connect(sk, (struct sockaddr *)uaddr, addr_len);
 }
@@ -689,17 +689,17 @@ int inet_getname(struct socket *sock, struct sockaddr *uaddr,
 
 	sin->sin_family = AF_INET;
 	if (peer) {
-		if (!inet->dport ||
+		if (!inet->inet_dport ||
 		    (((1 << sk->sk_state) & (TCPF_CLOSE | TCPF_SYN_SENT)) &&
 		     peer == 1))
 			return -ENOTCONN;
-		sin->sin_port = inet->dport;
-		sin->sin_addr.s_addr = inet->daddr;
+		sin->sin_port = inet->inet_dport;
+		sin->sin_addr.s_addr = inet->inet_daddr;
 	} else {
-		__be32 addr = inet->rcv_saddr;
+		__be32 addr = inet->inet_rcv_saddr;
 		if (!addr)
-			addr = inet->saddr;
-		sin->sin_port = inet->sport;
+			addr = inet->inet_saddr;
+		sin->sin_port = inet->inet_sport;
 		sin->sin_addr.s_addr = addr;
 	}
 	memset(sin->sin_zero, 0, sizeof(sin->sin_zero));
@@ -714,7 +714,7 @@ int inet_sendmsg(struct kiocb *iocb, struct socket *sock, struct msghdr *msg,
 	struct sock *sk = sock->sk;
 
 	/* We may need to bind the socket. */
-	if (!inet_sk(sk)->num && inet_autobind(sk))
+	if (!inet_sk(sk)->inet_num && inet_autobind(sk))
 		return -EAGAIN;
 
 	return sk->sk_prot->sendmsg(iocb, sk, msg, size);
@@ -728,7 +728,7 @@ static ssize_t inet_sendpage(struct socket *sock, struct page *page, int offset,
 	struct sock *sk = sock->sk;
 
 	/* We may need to bind the socket. */
-	if (!inet_sk(sk)->num && inet_autobind(sk))
+	if (!inet_sk(sk)->inet_num && inet_autobind(sk))
 		return -EAGAIN;
 
 	if (sk->sk_prot->sendpage)
@@ -1059,9 +1059,9 @@ static int inet_sk_reselect_saddr(struct sock *sk)
 	struct inet_sock *inet = inet_sk(sk);
 	int err;
 	struct rtable *rt;
-	__be32 old_saddr = inet->saddr;
+	__be32 old_saddr = inet->inet_saddr;
 	__be32 new_saddr;
-	__be32 daddr = inet->daddr;
+	__be32 daddr = inet->inet_daddr;
 
 	if (inet->opt && inet->opt->srr)
 		daddr = inet->opt->faddr;
@@ -1071,7 +1071,7 @@ static int inet_sk_reselect_saddr(struct sock *sk)
 			       RT_CONN_FLAGS(sk),
 			       sk->sk_bound_dev_if,
 			       sk->sk_protocol,
-			       inet->sport, inet->dport, sk, 0);
+			       inet->inet_sport, inet->inet_dport, sk, 0);
 	if (err)
 		return err;
 
@@ -1087,7 +1087,7 @@ static int inet_sk_reselect_saddr(struct sock *sk)
 		       __func__, &old_saddr, &new_saddr);
 	}
 
-	inet->saddr = inet->rcv_saddr = new_saddr;
+	inet->inet_saddr = inet->inet_rcv_saddr = new_saddr;
 
 	/*
 	 * XXX The only one ugly spot where we need to
@@ -1113,7 +1113,7 @@ int inet_sk_rebuild_header(struct sock *sk)
 		return 0;
 
 	/* Reroute. */
-	daddr = inet->daddr;
+	daddr = inet->inet_daddr;
 	if (inet->opt && inet->opt->srr)
 		daddr = inet->opt->faddr;
 {
@@ -1123,7 +1123,7 @@ int inet_sk_rebuild_header(struct sock *sk)
 		.nl_u = {
 			.ip4_u = {
 				.daddr	= daddr,
-				.saddr	= inet->saddr,
+				.saddr	= inet->inet_saddr,
 				.tos	= RT_CONN_FLAGS(sk),
 			},
 		},
@@ -1131,8 +1131,8 @@ int inet_sk_rebuild_header(struct sock *sk)
 		.flags = inet_sk_flowi_flags(sk),
 		.uli_u = {
 			.ports = {
-				.sport = inet->sport,
-				.dport = inet->dport,
+				.sport = inet->inet_sport,
+				.dport = inet->inet_dport,
 			},
 		},
 	};

commit ec1b4cf74c81bfd0fbe5bf62bafc86c45917e72f
Author: Stephen Hemminger <shemminger@vyatta.com>
Date:   Mon Oct 5 05:58:39 2009 +0000

    net: mark net_proto_ops as const
    
    All usages of structure net_proto_ops should be declared const.
    
    Signed-off-by: Stephen Hemminger <shemminger@vyatta.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 57737b8d1711..1deff48b122e 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -931,7 +931,7 @@ static const struct proto_ops inet_sockraw_ops = {
 #endif
 };
 
-static struct net_proto_family inet_family_ops = {
+static const struct net_proto_family inet_family_ops = {
 	.family = PF_INET,
 	.create = inet_create,
 	.owner	= THIS_MODULE,

commit 914a9ab386a288d0f22252fc268ecbc048cdcbd5
Author: Atis Elsts <atis@mikrotik.com>
Date:   Thu Oct 1 15:16:49 2009 -0700

    net: Use sk_mark for routing lookup in more places
    
    This patch against v2.6.31 adds support for route lookup using sk_mark in some
    more places. The benefits from this patch are the following.
    First, SO_MARK option now has effect on UDP sockets too.
    Second, ip_queue_xmit() and inet_sk_rebuild_header() could fail to do routing
    lookup correctly if TCP sockets with SO_MARK were used.
    
    Signed-off-by: Atis Elsts <atis@mikrotik.com>
    Acked-by: Eric Dumazet <eric.dumazet@gmail.com>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 58c4b0f7c4aa..57737b8d1711 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1119,6 +1119,7 @@ int inet_sk_rebuild_header(struct sock *sk)
 {
 	struct flowi fl = {
 		.oif = sk->sk_bound_dev_if,
+		.mark = sk->sk_mark,
 		.nl_u = {
 			.ip4_u = {
 				.daddr	= daddr,

commit 32613090a96dba2ca2cc524c8d4749d3126fdde5
Author: Alexey Dobriyan <adobriyan@gmail.com>
Date:   Mon Sep 14 12:21:47 2009 +0000

    net: constify struct net_protocol
    
    Remove long removed "inet_protocol_base" declaration.
    
    Signed-off-by: Alexey Dobriyan <adobriyan@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 6c30a73f03f5..58c4b0f7c4aa 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -244,7 +244,7 @@ EXPORT_SYMBOL(build_ehash_secret);
 static inline int inet_netns_ok(struct net *net, int protocol)
 {
 	int hash;
-	struct net_protocol *ipprot;
+	const struct net_protocol *ipprot;
 
 	if (net_eq(net, &init_net))
 		return 1;
@@ -1162,7 +1162,7 @@ EXPORT_SYMBOL(inet_sk_rebuild_header);
 static int inet_gso_send_check(struct sk_buff *skb)
 {
 	struct iphdr *iph;
-	struct net_protocol *ops;
+	const struct net_protocol *ops;
 	int proto;
 	int ihl;
 	int err = -EINVAL;
@@ -1198,7 +1198,7 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb, int features)
 {
 	struct sk_buff *segs = ERR_PTR(-EINVAL);
 	struct iphdr *iph;
-	struct net_protocol *ops;
+	const struct net_protocol *ops;
 	int proto;
 	int ihl;
 	int id;
@@ -1265,7 +1265,7 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb, int features)
 static struct sk_buff **inet_gro_receive(struct sk_buff **head,
 					 struct sk_buff *skb)
 {
-	struct net_protocol *ops;
+	const struct net_protocol *ops;
 	struct sk_buff **pp = NULL;
 	struct sk_buff *p;
 	struct iphdr *iph;
@@ -1342,7 +1342,7 @@ static struct sk_buff **inet_gro_receive(struct sk_buff **head,
 
 static int inet_gro_complete(struct sk_buff *skb)
 {
-	struct net_protocol *ops;
+	const struct net_protocol *ops;
 	struct iphdr *iph = ip_hdr(skb);
 	int proto = iph->protocol & (MAX_INET_PROTOS - 1);
 	int err = -ENOSYS;
@@ -1427,13 +1427,13 @@ void snmp_mib_free(void *ptr[2])
 EXPORT_SYMBOL_GPL(snmp_mib_free);
 
 #ifdef CONFIG_IP_MULTICAST
-static struct net_protocol igmp_protocol = {
+static const struct net_protocol igmp_protocol = {
 	.handler =	igmp_rcv,
 	.netns_ok =	1,
 };
 #endif
 
-static struct net_protocol tcp_protocol = {
+static const struct net_protocol tcp_protocol = {
 	.handler =	tcp_v4_rcv,
 	.err_handler =	tcp_v4_err,
 	.gso_send_check = tcp_v4_gso_send_check,
@@ -1444,7 +1444,7 @@ static struct net_protocol tcp_protocol = {
 	.netns_ok =	1,
 };
 
-static struct net_protocol udp_protocol = {
+static const struct net_protocol udp_protocol = {
 	.handler =	udp_rcv,
 	.err_handler =	udp_err,
 	.gso_send_check = udp4_ufo_send_check,
@@ -1453,7 +1453,7 @@ static struct net_protocol udp_protocol = {
 	.netns_ok =	1,
 };
 
-static struct net_protocol icmp_protocol = {
+static const struct net_protocol icmp_protocol = {
 	.handler =	icmp_rcv,
 	.no_policy =	1,
 	.netns_ok =	1,

commit 3d1427f87002735aa54c370558e0c2bacc61f31e
Author: Eric Dumazet <eric.dumazet@gmail.com>
Date:   Fri Aug 28 23:45:21 2009 -0700

    ipv4: af_inet.c cleanups
    
    Signed-off-by: Eric Dumazet <eric.dumazet@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 197d024b2536..6c30a73f03f5 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -124,7 +124,6 @@ static struct list_head inetsw[SOCK_MAX];
 static DEFINE_SPINLOCK(inetsw_lock);
 
 struct ipv4_config ipv4_config;
-
 EXPORT_SYMBOL(ipv4_config);
 
 /* New destruction routine */
@@ -139,12 +138,12 @@ void inet_sock_destruct(struct sock *sk)
 	sk_mem_reclaim(sk);
 
 	if (sk->sk_type == SOCK_STREAM && sk->sk_state != TCP_CLOSE) {
-		printk("Attempt to release TCP socket in state %d %p\n",
+		pr_err("Attempt to release TCP socket in state %d %p\n",
 		       sk->sk_state, sk);
 		return;
 	}
 	if (!sock_flag(sk, SOCK_DEAD)) {
-		printk("Attempt to release alive inet socket %p\n", sk);
+		pr_err("Attempt to release alive inet socket %p\n", sk);
 		return;
 	}
 
@@ -157,6 +156,7 @@ void inet_sock_destruct(struct sock *sk)
 	dst_release(sk->sk_dst_cache);
 	sk_refcnt_debug_dec(sk);
 }
+EXPORT_SYMBOL(inet_sock_destruct);
 
 /*
  *	The routines beyond this point handle the behaviour of an AF_INET
@@ -219,6 +219,7 @@ int inet_listen(struct socket *sock, int backlog)
 	release_sock(sk);
 	return err;
 }
+EXPORT_SYMBOL(inet_listen);
 
 u32 inet_ehash_secret __read_mostly;
 EXPORT_SYMBOL(inet_ehash_secret);
@@ -435,9 +436,11 @@ int inet_release(struct socket *sock)
 	}
 	return 0;
 }
+EXPORT_SYMBOL(inet_release);
 
 /* It is off by default, see below. */
 int sysctl_ip_nonlocal_bind __read_mostly;
+EXPORT_SYMBOL(sysctl_ip_nonlocal_bind);
 
 int inet_bind(struct socket *sock, struct sockaddr *uaddr, int addr_len)
 {
@@ -519,6 +522,7 @@ int inet_bind(struct socket *sock, struct sockaddr *uaddr, int addr_len)
 out:
 	return err;
 }
+EXPORT_SYMBOL(inet_bind);
 
 int inet_dgram_connect(struct socket *sock, struct sockaddr * uaddr,
 		       int addr_len, int flags)
@@ -532,6 +536,7 @@ int inet_dgram_connect(struct socket *sock, struct sockaddr * uaddr,
 		return -EAGAIN;
 	return sk->sk_prot->connect(sk, (struct sockaddr *)uaddr, addr_len);
 }
+EXPORT_SYMBOL(inet_dgram_connect);
 
 static long inet_wait_for_connect(struct sock *sk, long timeo)
 {
@@ -641,6 +646,7 @@ int inet_stream_connect(struct socket *sock, struct sockaddr *uaddr,
 		sock->state = SS_DISCONNECTING;
 	goto out;
 }
+EXPORT_SYMBOL(inet_stream_connect);
 
 /*
  *	Accept a pending connection. The TCP layer now gives BSD semantics.
@@ -668,6 +674,7 @@ int inet_accept(struct socket *sock, struct socket *newsock, int flags)
 do_err:
 	return err;
 }
+EXPORT_SYMBOL(inet_accept);
 
 
 /*
@@ -699,6 +706,7 @@ int inet_getname(struct socket *sock, struct sockaddr *uaddr,
 	*uaddr_len = sizeof(*sin);
 	return 0;
 }
+EXPORT_SYMBOL(inet_getname);
 
 int inet_sendmsg(struct kiocb *iocb, struct socket *sock, struct msghdr *msg,
 		 size_t size)
@@ -711,9 +719,11 @@ int inet_sendmsg(struct kiocb *iocb, struct socket *sock, struct msghdr *msg,
 
 	return sk->sk_prot->sendmsg(iocb, sk, msg, size);
 }
+EXPORT_SYMBOL(inet_sendmsg);
 
 
-static ssize_t inet_sendpage(struct socket *sock, struct page *page, int offset, size_t size, int flags)
+static ssize_t inet_sendpage(struct socket *sock, struct page *page, int offset,
+			     size_t size, int flags)
 {
 	struct sock *sk = sock->sk;
 
@@ -780,6 +790,7 @@ int inet_shutdown(struct socket *sock, int how)
 	release_sock(sk);
 	return err;
 }
+EXPORT_SYMBOL(inet_shutdown);
 
 /*
  *	ioctl() calls you can issue on an INET socket. Most of these are
@@ -798,44 +809,45 @@ int inet_ioctl(struct socket *sock, unsigned int cmd, unsigned long arg)
 	struct net *net = sock_net(sk);
 
 	switch (cmd) {
-		case SIOCGSTAMP:
-			err = sock_get_timestamp(sk, (struct timeval __user *)arg);
-			break;
-		case SIOCGSTAMPNS:
-			err = sock_get_timestampns(sk, (struct timespec __user *)arg);
-			break;
-		case SIOCADDRT:
-		case SIOCDELRT:
-		case SIOCRTMSG:
-			err = ip_rt_ioctl(net, cmd, (void __user *)arg);
-			break;
-		case SIOCDARP:
-		case SIOCGARP:
-		case SIOCSARP:
-			err = arp_ioctl(net, cmd, (void __user *)arg);
-			break;
-		case SIOCGIFADDR:
-		case SIOCSIFADDR:
-		case SIOCGIFBRDADDR:
-		case SIOCSIFBRDADDR:
-		case SIOCGIFNETMASK:
-		case SIOCSIFNETMASK:
-		case SIOCGIFDSTADDR:
-		case SIOCSIFDSTADDR:
-		case SIOCSIFPFLAGS:
-		case SIOCGIFPFLAGS:
-		case SIOCSIFFLAGS:
-			err = devinet_ioctl(net, cmd, (void __user *)arg);
-			break;
-		default:
-			if (sk->sk_prot->ioctl)
-				err = sk->sk_prot->ioctl(sk, cmd, arg);
-			else
-				err = -ENOIOCTLCMD;
-			break;
+	case SIOCGSTAMP:
+		err = sock_get_timestamp(sk, (struct timeval __user *)arg);
+		break;
+	case SIOCGSTAMPNS:
+		err = sock_get_timestampns(sk, (struct timespec __user *)arg);
+		break;
+	case SIOCADDRT:
+	case SIOCDELRT:
+	case SIOCRTMSG:
+		err = ip_rt_ioctl(net, cmd, (void __user *)arg);
+		break;
+	case SIOCDARP:
+	case SIOCGARP:
+	case SIOCSARP:
+		err = arp_ioctl(net, cmd, (void __user *)arg);
+		break;
+	case SIOCGIFADDR:
+	case SIOCSIFADDR:
+	case SIOCGIFBRDADDR:
+	case SIOCSIFBRDADDR:
+	case SIOCGIFNETMASK:
+	case SIOCSIFNETMASK:
+	case SIOCGIFDSTADDR:
+	case SIOCSIFDSTADDR:
+	case SIOCSIFPFLAGS:
+	case SIOCGIFPFLAGS:
+	case SIOCSIFFLAGS:
+		err = devinet_ioctl(net, cmd, (void __user *)arg);
+		break;
+	default:
+		if (sk->sk_prot->ioctl)
+			err = sk->sk_prot->ioctl(sk, cmd, arg);
+		else
+			err = -ENOIOCTLCMD;
+		break;
 	}
 	return err;
 }
+EXPORT_SYMBOL(inet_ioctl);
 
 const struct proto_ops inet_stream_ops = {
 	.family		   = PF_INET,
@@ -862,6 +874,7 @@ const struct proto_ops inet_stream_ops = {
 	.compat_getsockopt = compat_sock_common_getsockopt,
 #endif
 };
+EXPORT_SYMBOL(inet_stream_ops);
 
 const struct proto_ops inet_dgram_ops = {
 	.family		   = PF_INET,
@@ -887,6 +900,7 @@ const struct proto_ops inet_dgram_ops = {
 	.compat_getsockopt = compat_sock_common_getsockopt,
 #endif
 };
+EXPORT_SYMBOL(inet_dgram_ops);
 
 /*
  * For SOCK_RAW sockets; should be the same as inet_dgram_ops but without
@@ -1016,6 +1030,7 @@ void inet_register_protosw(struct inet_protosw *p)
 	       p->type);
 	goto out;
 }
+EXPORT_SYMBOL(inet_register_protosw);
 
 void inet_unregister_protosw(struct inet_protosw *p)
 {
@@ -1031,6 +1046,7 @@ void inet_unregister_protosw(struct inet_protosw *p)
 		synchronize_net();
 	}
 }
+EXPORT_SYMBOL(inet_unregister_protosw);
 
 /*
  *      Shall we try to damage output packets if routing dev changes?
@@ -1141,7 +1157,6 @@ int inet_sk_rebuild_header(struct sock *sk)
 
 	return err;
 }
-
 EXPORT_SYMBOL(inet_sk_rebuild_header);
 
 static int inet_gso_send_check(struct sk_buff *skb)
@@ -1369,7 +1384,6 @@ int inet_ctl_sock_create(struct sock **sk, unsigned short family,
 	}
 	return rc;
 }
-
 EXPORT_SYMBOL_GPL(inet_ctl_sock_create);
 
 unsigned long snmp_fold_field(void *mib[], int offt)
@@ -1676,19 +1690,3 @@ static int __init ipv4_proc_init(void)
 
 MODULE_ALIAS_NETPROTO(PF_INET);
 
-EXPORT_SYMBOL(inet_accept);
-EXPORT_SYMBOL(inet_bind);
-EXPORT_SYMBOL(inet_dgram_connect);
-EXPORT_SYMBOL(inet_dgram_ops);
-EXPORT_SYMBOL(inet_getname);
-EXPORT_SYMBOL(inet_ioctl);
-EXPORT_SYMBOL(inet_listen);
-EXPORT_SYMBOL(inet_register_protosw);
-EXPORT_SYMBOL(inet_release);
-EXPORT_SYMBOL(inet_sendmsg);
-EXPORT_SYMBOL(inet_shutdown);
-EXPORT_SYMBOL(inet_sock_destruct);
-EXPORT_SYMBOL(inet_stream_connect);
-EXPORT_SYMBOL(inet_stream_ops);
-EXPORT_SYMBOL(inet_unregister_protosw);
-EXPORT_SYMBOL(sysctl_ip_nonlocal_bind);

commit d7ca4cc01fd154f2da30ae6dae160fa5800af758
Author: Sridhar Samudrala <sri@us.ibm.com>
Date:   Thu Jul 9 08:09:47 2009 +0000

    udpv4: Handle large incoming UDP/IPv4 packets and support software UFO.
    
    - validate and forward GSO UDP/IPv4 packets from untrusted sources.
    - do software UFO if the outgoing device doesn't support UFO.
    
    Signed-off-by: Sridhar Samudrala <sri@us.ibm.com>
    Acked-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 566ea6c4321d..197d024b2536 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1187,6 +1187,7 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb, int features)
 	int proto;
 	int ihl;
 	int id;
+	unsigned int offset = 0;
 
 	if (!(features & NETIF_F_V4_CSUM))
 		features &= ~NETIF_F_SG;
@@ -1229,7 +1230,14 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb, int features)
 	skb = segs;
 	do {
 		iph = ip_hdr(skb);
-		iph->id = htons(id++);
+		if (proto == IPPROTO_UDP) {
+			iph->id = htons(id);
+			iph->frag_off = htons(offset >> 3);
+			if (skb->next != NULL)
+				iph->frag_off |= htons(IP_MF);
+			offset += (skb->len - skb->mac_len - iph->ihl * 4);
+		} else
+			iph->id = htons(id++);
 		iph->tot_len = htons(skb->len - skb->mac_len);
 		iph->check = 0;
 		iph->check = ip_fast_csum(skb_network_header(skb), iph->ihl);
@@ -1425,6 +1433,8 @@ static struct net_protocol tcp_protocol = {
 static struct net_protocol udp_protocol = {
 	.handler =	udp_rcv,
 	.err_handler =	udp_err,
+	.gso_send_check = udp4_ufo_send_check,
+	.gso_segment = udp4_ufo_fragment,
 	.no_policy =	1,
 	.netns_ok =	1,
 };

commit 2307f866f542f3397d24f78d0efd74f4ab214a96
Author: Rami Rosen <ramirose@gmail.com>
Date:   Wed Jun 3 21:43:26 2009 -0700

    ipv4: remove ip_mc_drop_socket() declaration from af_inet.c.
    
    ip_mc_drop_socket() method is declared in linux/igmp.h, which
    is included anyhow in af_inet.c. So there is no need for this declaration.
    This patch removes it from af_inet.c.
    
    Signed-off-by: Rami Rosen <ramirose@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index d87362178588..566ea6c4321d 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -116,7 +116,6 @@
 #include <linux/mroute.h>
 #endif
 
-extern void ip_mc_drop_socket(struct sock *sk);
 
 /* The inetsw table contains everything that inet_create needs to
  * build a new socket.

commit f771bef98004d9d141b085d987a77d06669d4f4f
Author: Nivedita Singhvi <niv@us.ibm.com>
Date:   Thu May 28 07:00:46 2009 +0000

    ipv4: New multicast-all socket option
    
    After some discussion offline with Christoph Lameter and David Stevens
    regarding multicast behaviour in Linux, I'm submitting a slightly
    modified patch from the one Christoph submitted earlier.
    
    This patch provides a new socket option IP_MULTICAST_ALL.
    
    In this case, default behaviour is _unchanged_ from the current
    Linux standard. The socket option is set by default to provide
    original behaviour. Sockets wishing to receive data only from
    multicast groups they join explicitly will need to clear this
    socket option.
    
    Signed-off-by: Nivedita Singhvi <niv@us.ibm.com>
    Signed-off-by: Christoph Lameter<cl@linux.com>
    Acked-by: David Stevens <dlstevens@us.ibm.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 5abee4c97449..d87362178588 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -375,6 +375,7 @@ static int inet_create(struct net *net, struct socket *sock, int protocol)
 	inet->uc_ttl	= -1;
 	inet->mc_loop	= 1;
 	inet->mc_ttl	= 1;
+	inet->mc_all	= 1;
 	inet->mc_index	= 0;
 	inet->mc_list	= NULL;
 

commit 1075f3f65d0e0f49351b7d4310e9f94483972a51
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Tue May 26 18:50:29 2009 +0000

    ipv4: Use 32-bit loads for ID and length in GRO
    
    This patch optimises the IPv4 GRO code by using 32-bit loads
    (instead of 16-bit ones) on the ID and length checks in the receive
    function.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 644cc5535319..5abee4c97449 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1248,9 +1248,9 @@ static struct sk_buff **inet_gro_receive(struct sk_buff **head,
 	struct iphdr *iph;
 	unsigned int hlen;
 	unsigned int off;
+	unsigned int id;
 	int flush = 1;
 	int proto;
-	int id;
 
 	off = skb_gro_offset(skb);
 	hlen = off + sizeof(*iph);
@@ -1274,9 +1274,9 @@ static struct sk_buff **inet_gro_receive(struct sk_buff **head,
 	if (unlikely(ip_fast_csum((u8 *)iph, iph->ihl)))
 		goto out_unlock;
 
-	flush = ntohs(iph->tot_len) != skb_gro_len(skb) ||
-		iph->frag_off != htons(IP_DF);
-	id = ntohs(iph->id);
+	id = ntohl(*(u32 *)&iph->id);
+	flush = (u16)((ntohl(*(u32 *)iph) ^ skb_gro_len(skb)) | (id ^ IP_DF));
+	id >>= 16;
 
 	for (p = *head; p; p = p->next) {
 		struct iphdr *iph2;

commit a5b1cf288d4200506ab62fbb86cc81ace948a306
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Tue May 26 18:50:28 2009 +0000

    gro: Avoid unnecessary comparison after skb_gro_header
    
    For the overwhelming majority of cases, skb_gro_header's return
    value cannot be NULL.  Yet we must check it because of its current
    form.  This patch splits it up into multiple functions in order
    to avoid this.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 170689681aa2..644cc5535319 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1246,13 +1246,20 @@ static struct sk_buff **inet_gro_receive(struct sk_buff **head,
 	struct sk_buff **pp = NULL;
 	struct sk_buff *p;
 	struct iphdr *iph;
+	unsigned int hlen;
+	unsigned int off;
 	int flush = 1;
 	int proto;
 	int id;
 
-	iph = skb_gro_header(skb, sizeof(*iph));
-	if (unlikely(!iph))
-		goto out;
+	off = skb_gro_offset(skb);
+	hlen = off + sizeof(*iph);
+	iph = skb_gro_header_fast(skb, off);
+	if (skb_gro_header_hard(skb, hlen)) {
+		iph = skb_gro_header_slow(skb, hlen, off);
+		if (unlikely(!iph))
+			goto out;
+	}
 
 	proto = iph->protocol & (MAX_INET_PROTOS - 1);
 

commit 573636cbafeba88f7c88832ae053dafe265bf94b
Author: Eric Dumazet <dada1@cosmosbay.com>
Date:   Fri Apr 17 04:52:48 2009 -0700

    [PATCH] net: remove superfluous call to synchronize_net()
    
    inet_register_protosw() function is responsible for adding a new
    inet protocol into a global table (inetsw[]) that is used with RCU rules.
    
    As soon as the store of the pointer is done, other cpus might see
    this new protocol in inetsw[], so we have to make sure new protocol
    is ready for use. All pending memory updates should thus be committed
    to memory before setting the pointer.
    This is correctly done using rcu_assign_pointer()
    
    synchronize_net() is typically used at unregister time, after
    unsetting the pointer, to make sure no other cpu is still using
    the object we want to dismantle. Using it at register time
    is only adding an artificial delay that could hide a real bug,
    and this bug could popup if/when synchronize_rcu() can proceed
    faster than now.
    
    This saves about 13 ms on boot time on a HZ=1000 8 cpus machine  ;)
    (4 calls to inet_register_protosw(), and about 3200 us per call)
    
    Signed-off-by: Eric Dumazet <dada1@cosmosbay.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 7f03373b8c07..170689681aa2 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1003,8 +1003,6 @@ void inet_register_protosw(struct inet_protosw *p)
 out:
 	spin_unlock_bh(&inetsw_lock);
 
-	synchronize_net();
-
 	return;
 
 out_permanent:

commit 6e15cf04860074ad032e88c306bea656bbdd0f22
Merge: be0ea69674ed 60db56422043
Author: Ingo Molnar <mingo@elte.hu>
Date:   Thu Mar 26 21:39:17 2009 +0100

    Merge branch 'core/percpu' into percpu-cpumask-x86-for-linus-2
    
    Conflicts:
            arch/parisc/kernel/irq.c
            arch/x86/include/asm/fixmap_64.h
            arch/x86/include/asm/setup.h
            kernel/irq/handle.c
    
    Semantic merge:
            arch/x86/include/asm/fixmap.h
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit 7546dd97d27306d939c13e03318aae695badaa88
Author: Stephen Hemminger <shemminger@vyatta.com>
Date:   Mon Mar 9 08:18:29 2009 +0000

    net: convert usage of packet_type to read_mostly
    
    Protocols that use packet_type can be __read_mostly section for better
    locality. Elminate any unnecessary initializations of NULL.
    
    Signed-off-by: Stephen Hemminger <shemminger@vyatta.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 627be4dc7fb0..d5aaabbb7cb3 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1500,7 +1500,7 @@ static int ipv4_proc_init(void);
  *	IP protocol layer initialiser
  */
 
-static struct packet_type ip_packet_type = {
+static struct packet_type ip_packet_type __read_mostly = {
 	.type = cpu_to_be16(ETH_P_IP),
 	.func = ip_rcv,
 	.gso_send_check = inet_gso_send_check,

commit 313e458f81ec3852106c5a83830fe0d4f405a71a
Author: Rusty Russell <rusty@rustcorp.com.au>
Date:   Fri Feb 20 16:29:08 2009 +0900

    alloc_percpu: add align argument to __alloc_percpu.
    
    This prepares for a real __alloc_percpu, by adding an alignment argument.
    Only one place uses __alloc_percpu directly, and that's for a string.
    
    tj: af_inet also uses __alloc_percpu(), update it.
    
    Signed-off-by: Rusty Russell <rusty@rustcorp.com.au>
    Cc: Christoph Lameter <cl@linux-foundation.org>
    Cc: Jens Axboe <axboe@kernel.dk>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 743f5542d65a..3a3dad801354 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1375,10 +1375,10 @@ EXPORT_SYMBOL_GPL(snmp_fold_field);
 int snmp_mib_init(void *ptr[2], size_t mibsize)
 {
 	BUG_ON(ptr == NULL);
-	ptr[0] = __alloc_percpu(mibsize);
+	ptr[0] = __alloc_percpu(mibsize, __alignof__(unsigned long long));
 	if (!ptr[0])
 		goto err0;
-	ptr[1] = __alloc_percpu(mibsize);
+	ptr[1] = __alloc_percpu(mibsize, __alignof__(unsigned long long));
 	if (!ptr[1])
 		goto err1;
 	return 0;

commit a5ad24be728d4352b71a81fba471aa41eb71f83a
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Sun Feb 8 18:00:39 2009 +0000

    gro: Optimise IPv4 packet reception
    
    As this function can be called more than half a million times for
    10GbE, it's important to optimise it as much as we can.
    
    This patch does some obvious changes to use 2-byte and 4-byte
    operations instead of byte-oriented ones where possible.  Bit
    ops are also used to replace logical ops to reduce branching.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index c79087719df0..627be4dc7fb0 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1263,7 +1263,7 @@ static struct sk_buff **inet_gro_receive(struct sk_buff **head,
 	if (!ops || !ops->gro_receive)
 		goto out_unlock;
 
-	if (iph->version != 4 || iph->ihl != 5)
+	if (*(u8 *)iph != 0x45)
 		goto out_unlock;
 
 	if (unlikely(ip_fast_csum((u8 *)iph, iph->ihl)))
@@ -1281,17 +1281,18 @@ static struct sk_buff **inet_gro_receive(struct sk_buff **head,
 
 		iph2 = ip_hdr(p);
 
-		if (iph->protocol != iph2->protocol ||
-		    iph->tos != iph2->tos ||
-		    memcmp(&iph->saddr, &iph2->saddr, 8)) {
+		if ((iph->protocol ^ iph2->protocol) |
+		    (iph->tos ^ iph2->tos) |
+		    (iph->saddr ^ iph2->saddr) |
+		    (iph->daddr ^ iph2->daddr)) {
 			NAPI_GRO_CB(p)->same_flow = 0;
 			continue;
 		}
 
 		/* All fields must match except length and checksum. */
 		NAPI_GRO_CB(p)->flush |=
-			memcmp(&iph->frag_off, &iph2->frag_off, 4) ||
-			(u16)(ntohs(iph2->id) + NAPI_GRO_CB(p)->count) != id;
+			(iph->ttl ^ iph2->ttl) |
+			((u16)(ntohs(iph2->id) + NAPI_GRO_CB(p)->count) ^ id);
 
 		NAPI_GRO_CB(p)->flush |= flush;
 	}

commit f15fbcd7d857ca2ea20b57ba6dfe63aab89d0b8b
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Sun Feb 1 22:24:43 2009 -0800

    ipv4: Delete redundant sk_family assignment
    
    sk_alloc now sets sk_family so this is redundant.  In fact it caught
    my eye because sock_init_data already uses sk_family so this is too
    late anyway.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 957cd054732c..c79087719df0 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -369,7 +369,6 @@ static int inet_create(struct net *net, struct socket *sock, int protocol)
 	sock_init_data(sock, sk);
 
 	sk->sk_destruct	   = inet_sock_destruct;
-	sk->sk_family	   = PF_INET;
 	sk->sk_protocol	   = protocol;
 	sk->sk_backlog_rcv = sk->sk_prot->backlog_rcv;
 

commit 09640e6365c679b5642b1c41b6d7078f51689ddf
Author: Harvey Harrison <harvey.harrison@gmail.com>
Date:   Sun Feb 1 00:45:17 2009 -0800

    net: replace uses of __constant_{endian}
    
    Base versions handle constant folding now.
    
    Signed-off-by: Harvey Harrison <harvey.harrison@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index d6770f295d5b..957cd054732c 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1501,7 +1501,7 @@ static int ipv4_proc_init(void);
  */
 
 static struct packet_type ip_packet_type = {
-	.type = __constant_htons(ETH_P_IP),
+	.type = cpu_to_be16(ETH_P_IP),
 	.func = ip_rcv,
 	.gso_send_check = inet_gso_send_check,
 	.gso_segment = inet_gso_segment,

commit 86911732d3996a9da07914b280621450111bb6da
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Thu Jan 29 14:19:50 2009 +0000

    gro: Avoid copying headers of unmerged packets
    
    Unfortunately simplicity isn't always the best.  The fraginfo
    interface turned out to be suboptimal.  The problem was quite
    obvious.  For every packet, we have to copy the headers from
    the frags structure into skb->head, even though for 99% of the
    packets this part is immediately thrown away after the merge.
    
    LRO didn't have this problem because it directly read the headers
    from the frags structure.
    
    This patch attempts to address this by creating an interface
    that allows GRO to access the headers in the first frag without
    having to copy it.  Because all drivers that use frags place the
    headers in the first frag this optimisation should be enough.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 743f5542d65a..d6770f295d5b 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1253,10 +1253,10 @@ static struct sk_buff **inet_gro_receive(struct sk_buff **head,
 	int proto;
 	int id;
 
-	if (unlikely(!pskb_may_pull(skb, sizeof(*iph))))
+	iph = skb_gro_header(skb, sizeof(*iph));
+	if (unlikely(!iph))
 		goto out;
 
-	iph = ip_hdr(skb);
 	proto = iph->protocol & (MAX_INET_PROTOS - 1);
 
 	rcu_read_lock();
@@ -1270,7 +1270,7 @@ static struct sk_buff **inet_gro_receive(struct sk_buff **head,
 	if (unlikely(ip_fast_csum((u8 *)iph, iph->ihl)))
 		goto out_unlock;
 
-	flush = ntohs(iph->tot_len) != skb->len ||
+	flush = ntohs(iph->tot_len) != skb_gro_len(skb) ||
 		iph->frag_off != htons(IP_DF);
 	id = ntohs(iph->id);
 
@@ -1298,8 +1298,8 @@ static struct sk_buff **inet_gro_receive(struct sk_buff **head,
 	}
 
 	NAPI_GRO_CB(skb)->flush |= flush;
-	__skb_pull(skb, sizeof(*iph));
-	skb_reset_transport_header(skb);
+	skb_gro_pull(skb, sizeof(*iph));
+	skb_set_transport_header(skb, skb_gro_offset(skb));
 
 	pp = ops->gro_receive(head, skb);
 

commit b4ee07df3d8121060200dbe1c6686a4e0682bee2
Author: Alexey Dobriyan <adobriyan@gmail.com>
Date:   Thu Dec 25 16:42:23 2008 -0800

    netns: igmp: allow IPPROTO_IGMP sockets in netns
    
    Looks like everything is already ready.
    
    Required for ebtables(8) for one thing.
    
    Also, required for ipmr per-netns (coming soon). (Benjamin)
    
    Signed-off-by: Alexey Dobriyan <adobriyan@gmail.com>
    Acked-by: Benjamin Thery <benjamin.thery@bull.net>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 664ff0ee1c83..743f5542d65a 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1402,6 +1402,7 @@ EXPORT_SYMBOL_GPL(snmp_mib_free);
 #ifdef CONFIG_IP_MULTICAST
 static struct net_protocol igmp_protocol = {
 	.handler =	igmp_rcv,
+	.netns_ok =	1,
 };
 #endif
 

commit bf296b125b21b8d558ceb6ec30bb4eba2730cd6b
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Mon Dec 15 23:43:36 2008 -0800

    tcp: Add GRO support
    
    This patch adds the TCP-specific portion of GRO.  The criterion for
    merging is extremely strict (the TCP header must match exactly apart
    from the checksum) so as to allow refragmentation.  Otherwise this
    is pretty much identical to LRO, except that we support the merging
    of ECN packets.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index a85595307fa7..664ff0ee1c83 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1410,6 +1410,8 @@ static struct net_protocol tcp_protocol = {
 	.err_handler =	tcp_v4_err,
 	.gso_send_check = tcp_v4_gso_send_check,
 	.gso_segment =	tcp_tso_segment,
+	.gro_receive =	tcp4_gro_receive,
+	.gro_complete =	tcp4_gro_complete,
 	.no_policy =	1,
 	.netns_ok =	1,
 };

commit 73cc19f1556b95976934de236fd9043f7208844f
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Mon Dec 15 23:41:09 2008 -0800

    ipv4: Add GRO infrastructure
    
    This patch adds GRO support for IPv4.
    
    The criteria for merging is more stringent than LRO, in particular,
    we require all fields in the IP header to be identical except for
    the length, ID and checksum.  In addition, the ID must form an
    arithmetic sequence with a difference of one.
    
    The ID requirement might seem overly strict, however, most hardware
    TSO solutions already obey this rule.  Linux itself also obeys this
    whether GSO is in use or not.
    
    In future we could relax this rule by storing the IDs (or rather
    making sure that we don't drop them when pulling the aggregate
    skb's tail).
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index fe03048c130d..a85595307fa7 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -94,6 +94,7 @@
 #include <linux/igmp.h>
 #include <linux/inetdevice.h>
 #include <linux/netdevice.h>
+#include <net/checksum.h>
 #include <net/ip.h>
 #include <net/protocol.h>
 #include <net/arp.h>
@@ -1241,6 +1242,100 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb, int features)
 	return segs;
 }
 
+static struct sk_buff **inet_gro_receive(struct sk_buff **head,
+					 struct sk_buff *skb)
+{
+	struct net_protocol *ops;
+	struct sk_buff **pp = NULL;
+	struct sk_buff *p;
+	struct iphdr *iph;
+	int flush = 1;
+	int proto;
+	int id;
+
+	if (unlikely(!pskb_may_pull(skb, sizeof(*iph))))
+		goto out;
+
+	iph = ip_hdr(skb);
+	proto = iph->protocol & (MAX_INET_PROTOS - 1);
+
+	rcu_read_lock();
+	ops = rcu_dereference(inet_protos[proto]);
+	if (!ops || !ops->gro_receive)
+		goto out_unlock;
+
+	if (iph->version != 4 || iph->ihl != 5)
+		goto out_unlock;
+
+	if (unlikely(ip_fast_csum((u8 *)iph, iph->ihl)))
+		goto out_unlock;
+
+	flush = ntohs(iph->tot_len) != skb->len ||
+		iph->frag_off != htons(IP_DF);
+	id = ntohs(iph->id);
+
+	for (p = *head; p; p = p->next) {
+		struct iphdr *iph2;
+
+		if (!NAPI_GRO_CB(p)->same_flow)
+			continue;
+
+		iph2 = ip_hdr(p);
+
+		if (iph->protocol != iph2->protocol ||
+		    iph->tos != iph2->tos ||
+		    memcmp(&iph->saddr, &iph2->saddr, 8)) {
+			NAPI_GRO_CB(p)->same_flow = 0;
+			continue;
+		}
+
+		/* All fields must match except length and checksum. */
+		NAPI_GRO_CB(p)->flush |=
+			memcmp(&iph->frag_off, &iph2->frag_off, 4) ||
+			(u16)(ntohs(iph2->id) + NAPI_GRO_CB(p)->count) != id;
+
+		NAPI_GRO_CB(p)->flush |= flush;
+	}
+
+	NAPI_GRO_CB(skb)->flush |= flush;
+	__skb_pull(skb, sizeof(*iph));
+	skb_reset_transport_header(skb);
+
+	pp = ops->gro_receive(head, skb);
+
+out_unlock:
+	rcu_read_unlock();
+
+out:
+	NAPI_GRO_CB(skb)->flush |= flush;
+
+	return pp;
+}
+
+static int inet_gro_complete(struct sk_buff *skb)
+{
+	struct net_protocol *ops;
+	struct iphdr *iph = ip_hdr(skb);
+	int proto = iph->protocol & (MAX_INET_PROTOS - 1);
+	int err = -ENOSYS;
+	__be16 newlen = htons(skb->len - skb_network_offset(skb));
+
+	csum_replace2(&iph->check, iph->tot_len, newlen);
+	iph->tot_len = newlen;
+
+	rcu_read_lock();
+	ops = rcu_dereference(inet_protos[proto]);
+	if (WARN_ON(!ops || !ops->gro_complete))
+		goto out_unlock;
+
+	err = ops->gro_complete(skb);
+
+out_unlock:
+	rcu_read_unlock();
+
+	return err;
+}
+
 int inet_ctl_sock_create(struct sock **sk, unsigned short family,
 			 unsigned short type, unsigned char protocol,
 			 struct net *net)
@@ -1407,6 +1502,8 @@ static struct packet_type ip_packet_type = {
 	.func = ip_rcv,
 	.gso_send_check = inet_gso_send_check,
 	.gso_segment = inet_gso_segment,
+	.gro_receive = inet_gro_receive,
+	.gro_complete = inet_gro_complete,
 };
 
 static int __init inet_init(void)

commit 04f258ce7f085dd69422fa01d41c8f0194a0e270
Author: Eric Dumazet <dada1@cosmosbay.com>
Date:   Sun Nov 23 15:42:23 2008 -0800

    net: some optimizations in af_inet
    
    1) Use eq_net() in inet_netns_ok() to speedup socket creation if
       !CONFIG_NET_NS
    
    2) Reorder the tests about inet_ehash_secret generation (once only)
       Use the unlikely() macro when testing if inet_ehash_secret already
       generated.
    
    Signed-off-by: Eric Dumazet <dada1@cosmosbay.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index b1462e8c64cf..fe03048c130d 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -245,7 +245,7 @@ static inline int inet_netns_ok(struct net *net, int protocol)
 	int hash;
 	struct net_protocol *ipprot;
 
-	if (net == &init_net)
+	if (net_eq(net, &init_net))
 		return 1;
 
 	hash = protocol & (MAX_INET_PROTOS - 1);
@@ -272,10 +272,9 @@ static int inet_create(struct net *net, struct socket *sock, int protocol)
 	int try_loading_module = 0;
 	int err;
 
-	if (sock->type != SOCK_RAW &&
-	    sock->type != SOCK_DGRAM &&
-	    !inet_ehash_secret)
-		build_ehash_secret();
+	if (unlikely(!inet_ehash_secret))
+		if (sock->type != SOCK_RAW && sock->type != SOCK_DGRAM)
+			build_ehash_secret();
 
 	sock->state = SS_UNCONNECTED;
 

commit 6ab33d51713d6d60c7677c0d020910a8cb37e513
Merge: 7be6065b39c3 13d428afc007
Author: David S. Miller <davem@davemloft.net>
Date:   Thu Nov 20 16:44:00 2008 -0800

    Merge branch 'master' of master.kernel.org:/pub/scm/linux/kernel/git/davem/net-2.6
    
    Conflicts:
    
            drivers/net/ixgbe/ixgbe_main.c
            include/net/mac80211.h
            net/phonet/af_phonet.c

commit c82838458200ec4167ce7083b0a17474150c5bf7
Author: Balazs Scheidler <bazsi@balabit.hu>
Date:   Thu Nov 20 01:08:06 2008 -0800

    TPROXY: supply a struct flowi->flags argument in inet_sk_rebuild_header()
    
        inet_sk_rebuild_header() does a new route lookup if the dst_entry
        associated with a socket becomes stale. However inet_sk_rebuild_header()
        didn't use struct flowi->flags, causing the route lookup to
        fail for foreign-bound IP_TRANSPARENT sockets, causing an error
        state to be set for the sockets in question.
    
    Signed-off-by: Balazs Scheidler <bazsi@balabit.hu>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 1fbff5fa4241..1aa2dc9e380e 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1117,6 +1117,7 @@ int inet_sk_rebuild_header(struct sock *sk)
 			},
 		},
 		.proto = sk->sk_protocol,
+		.flags = inet_sk_flowi_flags(sk),
 		.uli_u = {
 			.ports = {
 				.sport = inet->sport,

commit 673d57e72398edfedc93fb50ff58048077c9d587
Author: Harvey Harrison <harvey.harrison@gmail.com>
Date:   Fri Oct 31 00:53:57 2008 -0700

    net: replace NIPQUAD() in net/ipv4/ net/ipv6/
    
    Using NIPQUAD() with NIPQUAD_FMT, %d.%d.%d.%d or %u.%u.%u.%u
    can be replaced with %pI4
    
    Signed-off-by: Harvey Harrison <harvey.harrison@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 1fbff5fa4241..e3286814c8d9 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1070,11 +1070,8 @@ static int inet_sk_reselect_saddr(struct sock *sk)
 		return 0;
 
 	if (sysctl_ip_dynaddr > 1) {
-		printk(KERN_INFO "%s(): shifting inet->"
-				 "saddr from " NIPQUAD_FMT " to " NIPQUAD_FMT "\n",
-		       __func__,
-		       NIPQUAD(old_saddr),
-		       NIPQUAD(new_saddr));
+		printk(KERN_INFO "%s(): shifting inet->saddr from %pI4 to %pI4\n",
+		       __func__, &old_saddr, &new_saddr);
 	}
 
 	inet->saddr = inet->rcv_saddr = new_saddr;

commit b9fb15067ce93497bef852c05e406d7a96212a9a
Author: Tóth László Attila <panther@balabit.hu>
Date:   Wed Oct 1 07:31:24 2008 -0700

    ipv4: Allow binding to non-local addresses if IP_TRANSPARENT is set
    
    Setting IP_TRANSPARENT is not really useful without allowing non-local
    binds for the socket. To make user-space code simpler we allow these
    binds even if IP_TRANSPARENT is set but IP_FREEBIND is not.
    
    Signed-off-by: Tóth László Attila <panther@balabit.hu>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 8a3ac1fa71a9..1fbff5fa4241 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -469,7 +469,7 @@ int inet_bind(struct socket *sock, struct sockaddr *uaddr, int addr_len)
 	 */
 	err = -EADDRNOTAVAIL;
 	if (!sysctl_ip_nonlocal_bind &&
-	    !inet->freebind &&
+	    !(inet->freebind || inet->transparent) &&
 	    addr->sin_addr.s_addr != htonl(INADDR_ANY) &&
 	    chk_addr_ret != RTN_LOCAL &&
 	    chk_addr_ret != RTN_MULTICAST &&

commit 4836e3007882984279ca63d3c42bf0b14616eb78
Merge: 5c7c204aeca5 4e1e018ecc6f
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Jul 26 20:23:44 2008 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs-2.6
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs-2.6: (39 commits)
      [PATCH] fix RLIM_NOFILE handling
      [PATCH] get rid of corner case in dup3() entirely
      [PATCH] remove remaining namei_{32,64}.h crap
      [PATCH] get rid of indirect users of namei.h
      [PATCH] get rid of __user_path_lookup_open
      [PATCH] f_count may wrap around
      [PATCH] dup3 fix
      [PATCH] don't pass nameidata to __ncp_lookup_validate()
      [PATCH] don't pass nameidata to gfs2_lookupi()
      [PATCH] new (local) helper: user_path_parent()
      [PATCH] sanitize __user_walk_fd() et.al.
      [PATCH] preparation to __user_walk_fd cleanup
      [PATCH] kill nameidata passing to permission(), rename to inode_permission()
      [PATCH] take noexec checks to very few callers that care
      Re: [PATCH 3/6] vfs: open_exec cleanup
      [patch 4/4] vfs: immutable inode checking cleanup
      [patch 3/4] fat: dont call notify_change
      [patch 2/4] vfs: utimes cleanup
      [patch 1/4] vfs: utimes: move owner check into inode_change_ok()
      [PATCH] vfs: use kstrdup() and check failing allocation
      ...

commit 228428428138e231a155464239880201e5cc8b44
Merge: 78681ac08a61 6c3b8fc61890
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Jul 26 20:17:56 2008 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/davem/net-2.6
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/davem/net-2.6:
      netns: fix ip_rt_frag_needed rt_is_expired
      netfilter: nf_conntrack_extend: avoid unnecessary "ct->ext" dereferences
      netfilter: fix double-free and use-after free
      netfilter: arptables in netns for real
      netfilter: ip{,6}tables_security: fix future section mismatch
      selinux: use nf_register_hooks()
      netfilter: ebtables: use nf_register_hooks()
      Revert "pkt_sched: sch_sfq: dump a real number of flows"
      qeth: use dev->ml_priv instead of dev->priv
      syncookies: Make sure ECN is disabled
      net: drop unused BUG_TRAP()
      net: convert BUG_TRAP to generic WARN_ON
      drivers/net: convert BUG_TRAP to generic WARN_ON

commit bd7b1533cd6a68c734062aa69394bec7e2b1718e
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Tue Jul 15 16:00:59 2008 -0400

    [PATCH] sysctl: make sure that /proc/sys/net/ipv4 appears before per-ns ones
    
    Massage ipv4 initialization - make sure that net.ipv4 appears as
    non-per-net-namespace before it shows up in per-net-namespace sysctls.
    That's the only change outside of sysctl.c needed to get sane ordering
    rules and data structures for sysctls (esp. for procfs side of that
    mess).
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index f440a9f54924..354f6b54e492 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1439,6 +1439,10 @@ static int __init inet_init(void)
 
 	(void)sock_register(&inet_family_ops);
 
+#ifdef CONFIG_SYSCTL
+	ip_static_sysctl_init();
+#endif
+
 	/*
 	 *	Add all the base protocols.
 	 */

commit 547b792cac0a038b9dbf958d3c120df3740b5572
Author: Ilpo Järvinen <ilpo.jarvinen@helsinki.fi>
Date:   Fri Jul 25 21:43:18 2008 -0700

    net: convert BUG_TRAP to generic WARN_ON
    
    Removes legacy reinvent-the-wheel type thing. The generic
    machinery integrates much better to automated debugging aids
    such as kerneloops.org (and others), and is unambiguous due to
    better naming. Non-intuively BUG_TRAP() is actually equal to
    WARN_ON() rather than BUG_ON() though some might actually be
    promoted to BUG_ON() but I left that to future.
    
    I could make at least one BUILD_BUG_ON conversion.
    
    Signed-off-by: Ilpo Järvinen <ilpo.jarvinen@helsinki.fi>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index dd919d84285f..a107f49eea41 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -148,10 +148,10 @@ void inet_sock_destruct(struct sock *sk)
 		return;
 	}
 
-	BUG_TRAP(!atomic_read(&sk->sk_rmem_alloc));
-	BUG_TRAP(!atomic_read(&sk->sk_wmem_alloc));
-	BUG_TRAP(!sk->sk_wmem_queued);
-	BUG_TRAP(!sk->sk_forward_alloc);
+	WARN_ON(atomic_read(&sk->sk_rmem_alloc));
+	WARN_ON(atomic_read(&sk->sk_wmem_alloc));
+	WARN_ON(sk->sk_wmem_queued);
+	WARN_ON(sk->sk_forward_alloc);
 
 	kfree(inet->opt);
 	dst_release(sk->sk_dst_cache);
@@ -341,7 +341,7 @@ static int inet_create(struct net *net, struct socket *sock, int protocol)
 	answer_flags = answer->flags;
 	rcu_read_unlock();
 
-	BUG_TRAP(answer_prot->slab != NULL);
+	WARN_ON(answer_prot->slab == NULL);
 
 	err = -ENOBUFS;
 	sk = sk_alloc(net, PF_INET, GFP_KERNEL, answer_prot);
@@ -661,8 +661,8 @@ int inet_accept(struct socket *sock, struct socket *newsock, int flags)
 
 	lock_sock(sk2);
 
-	BUG_TRAP((1 << sk2->sk_state) &
-		 (TCPF_ESTABLISHED | TCPF_CLOSE_WAIT | TCPF_CLOSE));
+	WARN_ON(!((1 << sk2->sk_state) &
+		  (TCPF_ESTABLISHED | TCPF_CLOSE_WAIT | TCPF_CLOSE)));
 
 	sock_graft(sk2, newsock);
 

commit 696adfe84c11c571a1e0863460ff0ec142b4e5a9
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Fri Jul 25 01:45:34 2008 -0700

    list_for_each_rcu must die: networking
    
    All uses of list_for_each_rcu() can be profitably replaced by the
    easier-to-use list_for_each_entry_rcu().  This patch makes this change for
    networking, in preparation for removing the list_for_each_rcu() API
    entirely.
    
    Acked-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index dd919d84285f..f440a9f54924 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -264,7 +264,6 @@ static inline int inet_netns_ok(struct net *net, int protocol)
 static int inet_create(struct net *net, struct socket *sock, int protocol)
 {
 	struct sock *sk;
-	struct list_head *p;
 	struct inet_protosw *answer;
 	struct inet_sock *inet;
 	struct proto *answer_prot;
@@ -281,13 +280,12 @@ static int inet_create(struct net *net, struct socket *sock, int protocol)
 	sock->state = SS_UNCONNECTED;
 
 	/* Look for the requested type/protocol pair. */
-	answer = NULL;
 lookup_protocol:
 	err = -ESOCKTNOSUPPORT;
 	rcu_read_lock();
-	list_for_each_rcu(p, &inetsw[sock->type]) {
-		answer = list_entry(p, struct inet_protosw, list);
+	list_for_each_entry_rcu(answer, &inetsw[sock->type], list) {
 
+		err = 0;
 		/* Check the non-wild match. */
 		if (protocol == answer->protocol) {
 			if (protocol != IPPROTO_IP)
@@ -302,10 +300,9 @@ static int inet_create(struct net *net, struct socket *sock, int protocol)
 				break;
 		}
 		err = -EPROTONOSUPPORT;
-		answer = NULL;
 	}
 
-	if (unlikely(answer == NULL)) {
+	if (unlikely(err)) {
 		if (try_loading_module < 2) {
 			rcu_read_unlock();
 			/*

commit d89cbbb1e69a3bfea38038fb058bd51013902ef3
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Fri Jul 18 04:04:51 2008 -0700

    ipv4: clean the init_ipv4_mibs error paths
    
    After moving all the stuff outside this function it looks
    a bit ugly - make it look better.
    
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 36ff6dc769c6..dd919d84285f 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1399,13 +1399,7 @@ static __net_initdata struct pernet_operations ipv4_mib_ops = {
 
 static int __init init_ipv4_mibs(void)
 {
-	if (register_pernet_subsys(&ipv4_mib_ops))
-		goto err_net;
-
-	return 0;
-
-err_net:
-	return -ENOMEM;
+	return register_pernet_subsys(&ipv4_mib_ops);
 }
 
 static int ipv4_proc_init(void);

commit 923c6586b0dc0a00df07a1608185437145a0c68b
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Fri Jul 18 04:04:22 2008 -0700

    mib: put icmpmsg statistics on struct net
    
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 5c72bb3adadd..36ff6dc769c6 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1358,10 +1358,15 @@ static __net_init int ipv4_mib_init_net(struct net *net)
 	if (snmp_mib_init((void **)net->mib.icmp_statistics,
 			  sizeof(struct icmp_mib)) < 0)
 		goto err_icmp_mib;
+	if (snmp_mib_init((void **)net->mib.icmpmsg_statistics,
+			  sizeof(struct icmpmsg_mib)) < 0)
+		goto err_icmpmsg_mib;
 
 	tcp_mib_init(net);
 	return 0;
 
+err_icmpmsg_mib:
+	snmp_mib_free((void **)net->mib.icmp_statistics);
 err_icmp_mib:
 	snmp_mib_free((void **)net->mib.udplite_statistics);
 err_udplite_mib:
@@ -1378,6 +1383,7 @@ static __net_init int ipv4_mib_init_net(struct net *net)
 
 static __net_exit void ipv4_mib_exit_net(struct net *net)
 {
+	snmp_mib_free((void **)net->mib.icmpmsg_statistics);
 	snmp_mib_free((void **)net->mib.icmp_statistics);
 	snmp_mib_free((void **)net->mib.udplite_statistics);
 	snmp_mib_free((void **)net->mib.udp_statistics);
@@ -1393,18 +1399,12 @@ static __net_initdata struct pernet_operations ipv4_mib_ops = {
 
 static int __init init_ipv4_mibs(void)
 {
-	if (snmp_mib_init((void **)icmpmsg_statistics,
-			  sizeof(struct icmpmsg_mib)) < 0)
-		goto err_icmpmsg_mib;
-
 	if (register_pernet_subsys(&ipv4_mib_ops))
 		goto err_net;
 
 	return 0;
 
 err_net:
-	snmp_mib_free((void **)icmpmsg_statistics);
-err_icmpmsg_mib:
 	return -ENOMEM;
 }
 

commit b60538a0d737609213e4b758881913498d3ff0b4
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Fri Jul 18 04:04:02 2008 -0700

    mib: put icmp statistics on struct net
    
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index bf1f200c6575..5c72bb3adadd 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1355,10 +1355,15 @@ static __net_init int ipv4_mib_init_net(struct net *net)
 	if (snmp_mib_init((void **)net->mib.udplite_statistics,
 			  sizeof(struct udp_mib)) < 0)
 		goto err_udplite_mib;
+	if (snmp_mib_init((void **)net->mib.icmp_statistics,
+			  sizeof(struct icmp_mib)) < 0)
+		goto err_icmp_mib;
 
 	tcp_mib_init(net);
 	return 0;
 
+err_icmp_mib:
+	snmp_mib_free((void **)net->mib.udplite_statistics);
 err_udplite_mib:
 	snmp_mib_free((void **)net->mib.udp_statistics);
 err_udp_mib:
@@ -1373,6 +1378,7 @@ static __net_init int ipv4_mib_init_net(struct net *net)
 
 static __net_exit void ipv4_mib_exit_net(struct net *net)
 {
+	snmp_mib_free((void **)net->mib.icmp_statistics);
 	snmp_mib_free((void **)net->mib.udplite_statistics);
 	snmp_mib_free((void **)net->mib.udp_statistics);
 	snmp_mib_free((void **)net->mib.net_statistics);
@@ -1387,9 +1393,6 @@ static __net_initdata struct pernet_operations ipv4_mib_ops = {
 
 static int __init init_ipv4_mibs(void)
 {
-	if (snmp_mib_init((void **)icmp_statistics,
-			  sizeof(struct icmp_mib)) < 0)
-		goto err_icmp_mib;
 	if (snmp_mib_init((void **)icmpmsg_statistics,
 			  sizeof(struct icmpmsg_mib)) < 0)
 		goto err_icmpmsg_mib;
@@ -1402,8 +1405,6 @@ static int __init init_ipv4_mibs(void)
 err_net:
 	snmp_mib_free((void **)icmpmsg_statistics);
 err_icmpmsg_mib:
-	snmp_mib_free((void **)icmp_statistics);
-err_icmp_mib:
 	return -ENOMEM;
 }
 

commit 386019d3514b3ed9de8d0b05b67e638a7048375b
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Fri Jul 18 04:03:45 2008 -0700

    mib: put udplite statistics on struct net
    
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 1f418164ebf2..bf1f200c6575 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1352,10 +1352,15 @@ static __net_init int ipv4_mib_init_net(struct net *net)
 	if (snmp_mib_init((void **)net->mib.udp_statistics,
 			  sizeof(struct udp_mib)) < 0)
 		goto err_udp_mib;
+	if (snmp_mib_init((void **)net->mib.udplite_statistics,
+			  sizeof(struct udp_mib)) < 0)
+		goto err_udplite_mib;
 
 	tcp_mib_init(net);
 	return 0;
 
+err_udplite_mib:
+	snmp_mib_free((void **)net->mib.udp_statistics);
 err_udp_mib:
 	snmp_mib_free((void **)net->mib.net_statistics);
 err_net_mib:
@@ -1368,6 +1373,7 @@ static __net_init int ipv4_mib_init_net(struct net *net)
 
 static __net_exit void ipv4_mib_exit_net(struct net *net)
 {
+	snmp_mib_free((void **)net->mib.udplite_statistics);
 	snmp_mib_free((void **)net->mib.udp_statistics);
 	snmp_mib_free((void **)net->mib.net_statistics);
 	snmp_mib_free((void **)net->mib.ip_statistics);
@@ -1387,9 +1393,6 @@ static int __init init_ipv4_mibs(void)
 	if (snmp_mib_init((void **)icmpmsg_statistics,
 			  sizeof(struct icmpmsg_mib)) < 0)
 		goto err_icmpmsg_mib;
-	if (snmp_mib_init((void **)udplite_statistics,
-			  sizeof(struct udp_mib)) < 0)
-		goto err_udplite_mib;
 
 	if (register_pernet_subsys(&ipv4_mib_ops))
 		goto err_net;
@@ -1397,8 +1400,6 @@ static int __init init_ipv4_mibs(void)
 	return 0;
 
 err_net:
-	snmp_mib_free((void **)udplite_statistics);
-err_udplite_mib:
 	snmp_mib_free((void **)icmpmsg_statistics);
 err_icmpmsg_mib:
 	snmp_mib_free((void **)icmp_statistics);

commit 2f275f91a438abd8eec5321798d66a4ffe6869fa
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Fri Jul 18 04:03:27 2008 -0700

    mib: put udp statistics on struct net
    
    Similar to... ouch, I repeat myself.
    
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 776ed3199b52..1f418164ebf2 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1349,10 +1349,15 @@ static __net_init int ipv4_mib_init_net(struct net *net)
 	if (snmp_mib_init((void **)net->mib.net_statistics,
 			  sizeof(struct linux_mib)) < 0)
 		goto err_net_mib;
+	if (snmp_mib_init((void **)net->mib.udp_statistics,
+			  sizeof(struct udp_mib)) < 0)
+		goto err_udp_mib;
 
 	tcp_mib_init(net);
 	return 0;
 
+err_udp_mib:
+	snmp_mib_free((void **)net->mib.net_statistics);
 err_net_mib:
 	snmp_mib_free((void **)net->mib.ip_statistics);
 err_ip_mib:
@@ -1363,6 +1368,7 @@ static __net_init int ipv4_mib_init_net(struct net *net)
 
 static __net_exit void ipv4_mib_exit_net(struct net *net)
 {
+	snmp_mib_free((void **)net->mib.udp_statistics);
 	snmp_mib_free((void **)net->mib.net_statistics);
 	snmp_mib_free((void **)net->mib.ip_statistics);
 	snmp_mib_free((void **)net->mib.tcp_statistics);
@@ -1381,9 +1387,6 @@ static int __init init_ipv4_mibs(void)
 	if (snmp_mib_init((void **)icmpmsg_statistics,
 			  sizeof(struct icmpmsg_mib)) < 0)
 		goto err_icmpmsg_mib;
-	if (snmp_mib_init((void **)udp_statistics,
-			  sizeof(struct udp_mib)) < 0)
-		goto err_udp_mib;
 	if (snmp_mib_init((void **)udplite_statistics,
 			  sizeof(struct udp_mib)) < 0)
 		goto err_udplite_mib;
@@ -1396,8 +1399,6 @@ static int __init init_ipv4_mibs(void)
 err_net:
 	snmp_mib_free((void **)udplite_statistics);
 err_udplite_mib:
-	snmp_mib_free((void **)udp_statistics);
-err_udp_mib:
 	snmp_mib_free((void **)icmpmsg_statistics);
 err_icmpmsg_mib:
 	snmp_mib_free((void **)icmp_statistics);

commit 61a7e26028b94805fd686a6dc9dbd9941f8f19b0
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Fri Jul 18 04:03:08 2008 -0700

    mib: put net statistics on struct net
    
    Similar to ip and tcp ones :)
    
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 3090a9307c46..776ed3199b52 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -115,8 +115,6 @@
 #include <linux/mroute.h>
 #endif
 
-DEFINE_SNMP_STAT(struct linux_mib, net_statistics) __read_mostly;
-
 extern void ip_mc_drop_socket(struct sock *sk);
 
 /* The inetsw table contains everything that inet_create needs to
@@ -1348,10 +1346,15 @@ static __net_init int ipv4_mib_init_net(struct net *net)
 	if (snmp_mib_init((void **)net->mib.ip_statistics,
 			  sizeof(struct ipstats_mib)) < 0)
 		goto err_ip_mib;
+	if (snmp_mib_init((void **)net->mib.net_statistics,
+			  sizeof(struct linux_mib)) < 0)
+		goto err_net_mib;
 
 	tcp_mib_init(net);
 	return 0;
 
+err_net_mib:
+	snmp_mib_free((void **)net->mib.ip_statistics);
 err_ip_mib:
 	snmp_mib_free((void **)net->mib.tcp_statistics);
 err_tcp_mib:
@@ -1360,6 +1363,7 @@ static __net_init int ipv4_mib_init_net(struct net *net)
 
 static __net_exit void ipv4_mib_exit_net(struct net *net)
 {
+	snmp_mib_free((void **)net->mib.net_statistics);
 	snmp_mib_free((void **)net->mib.ip_statistics);
 	snmp_mib_free((void **)net->mib.tcp_statistics);
 }
@@ -1371,9 +1375,6 @@ static __net_initdata struct pernet_operations ipv4_mib_ops = {
 
 static int __init init_ipv4_mibs(void)
 {
-	if (snmp_mib_init((void **)net_statistics,
-			  sizeof(struct linux_mib)) < 0)
-		goto err_net_mib;
 	if (snmp_mib_init((void **)icmp_statistics,
 			  sizeof(struct icmp_mib)) < 0)
 		goto err_icmp_mib;
@@ -1401,8 +1402,6 @@ static int __init init_ipv4_mibs(void)
 err_icmpmsg_mib:
 	snmp_mib_free((void **)icmp_statistics);
 err_icmp_mib:
-	snmp_mib_free((void **)net_statistics);
-err_net_mib:
 	return -ENOMEM;
 }
 
@@ -1582,5 +1581,4 @@ EXPORT_SYMBOL(inet_sock_destruct);
 EXPORT_SYMBOL(inet_stream_connect);
 EXPORT_SYMBOL(inet_stream_ops);
 EXPORT_SYMBOL(inet_unregister_protosw);
-EXPORT_SYMBOL(net_statistics);
 EXPORT_SYMBOL(sysctl_ip_nonlocal_bind);

commit a20f5799ca7ceb24d63c74b6fdad4b0c0ee91f4f
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Fri Jul 18 04:02:42 2008 -0700

    mib: put ip statistics on struct net
    
    Similar to tcp one.
    
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index c1a3e986f8b4..3090a9307c46 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1345,16 +1345,22 @@ static __net_init int ipv4_mib_init_net(struct net *net)
 	if (snmp_mib_init((void **)net->mib.tcp_statistics,
 			  sizeof(struct tcp_mib)) < 0)
 		goto err_tcp_mib;
+	if (snmp_mib_init((void **)net->mib.ip_statistics,
+			  sizeof(struct ipstats_mib)) < 0)
+		goto err_ip_mib;
 
 	tcp_mib_init(net);
 	return 0;
 
+err_ip_mib:
+	snmp_mib_free((void **)net->mib.tcp_statistics);
 err_tcp_mib:
 	return -ENOMEM;
 }
 
 static __net_exit void ipv4_mib_exit_net(struct net *net)
 {
+	snmp_mib_free((void **)net->mib.ip_statistics);
 	snmp_mib_free((void **)net->mib.tcp_statistics);
 }
 
@@ -1368,9 +1374,6 @@ static int __init init_ipv4_mibs(void)
 	if (snmp_mib_init((void **)net_statistics,
 			  sizeof(struct linux_mib)) < 0)
 		goto err_net_mib;
-	if (snmp_mib_init((void **)ip_statistics,
-			  sizeof(struct ipstats_mib)) < 0)
-		goto err_ip_mib;
 	if (snmp_mib_init((void **)icmp_statistics,
 			  sizeof(struct icmp_mib)) < 0)
 		goto err_icmp_mib;
@@ -1398,8 +1401,6 @@ static int __init init_ipv4_mibs(void)
 err_icmpmsg_mib:
 	snmp_mib_free((void **)icmp_statistics);
 err_icmp_mib:
-	snmp_mib_free((void **)ip_statistics);
-err_ip_mib:
 	snmp_mib_free((void **)net_statistics);
 err_net_mib:
 	return -ENOMEM;

commit 57ef42d59d1c1d79be59fc3c6380ae14234e38c3
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Fri Jul 18 04:02:08 2008 -0700

    mib: put tcp statistics on struct net
    
    Proc temporary uses stats from init_net.
    
    BTW, TCP_XXX_STATS are beautiful (w/o do { } while (0) facing) again :)
    
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index b4b77aa07953..c1a3e986f8b4 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1342,11 +1342,20 @@ static struct net_protocol icmp_protocol = {
 
 static __net_init int ipv4_mib_init_net(struct net *net)
 {
+	if (snmp_mib_init((void **)net->mib.tcp_statistics,
+			  sizeof(struct tcp_mib)) < 0)
+		goto err_tcp_mib;
+
+	tcp_mib_init(net);
 	return 0;
+
+err_tcp_mib:
+	return -ENOMEM;
 }
 
 static __net_exit void ipv4_mib_exit_net(struct net *net)
 {
+	snmp_mib_free((void **)net->mib.tcp_statistics);
 }
 
 static __net_initdata struct pernet_operations ipv4_mib_ops = {
@@ -1368,9 +1377,6 @@ static int __init init_ipv4_mibs(void)
 	if (snmp_mib_init((void **)icmpmsg_statistics,
 			  sizeof(struct icmpmsg_mib)) < 0)
 		goto err_icmpmsg_mib;
-	if (snmp_mib_init((void **)tcp_statistics,
-			  sizeof(struct tcp_mib)) < 0)
-		goto err_tcp_mib;
 	if (snmp_mib_init((void **)udp_statistics,
 			  sizeof(struct udp_mib)) < 0)
 		goto err_udp_mib;
@@ -1378,8 +1384,6 @@ static int __init init_ipv4_mibs(void)
 			  sizeof(struct udp_mib)) < 0)
 		goto err_udplite_mib;
 
-	tcp_mib_init(&init_net);
-
 	if (register_pernet_subsys(&ipv4_mib_ops))
 		goto err_net;
 
@@ -1390,8 +1394,6 @@ static int __init init_ipv4_mibs(void)
 err_udplite_mib:
 	snmp_mib_free((void **)udp_statistics);
 err_udp_mib:
-	snmp_mib_free((void **)tcp_statistics);
-err_tcp_mib:
 	snmp_mib_free((void **)icmpmsg_statistics);
 err_icmpmsg_mib:
 	snmp_mib_free((void **)icmp_statistics);

commit 9b4661bd6e5437508e0920608f3213c23212cd1b
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Fri Jul 18 04:01:44 2008 -0700

    ipv4: add pernet mib operations
    
    These ones are currently empty, but stuff from init_ipv4_mibs will
    sequentially migrate there.
    
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 95a966dd1916..b4b77aa07953 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -110,6 +110,7 @@
 #include <net/ipip.h>
 #include <net/inet_common.h>
 #include <net/xfrm.h>
+#include <net/net_namespace.h>
 #ifdef CONFIG_IP_MROUTE
 #include <linux/mroute.h>
 #endif
@@ -1339,6 +1340,20 @@ static struct net_protocol icmp_protocol = {
 	.netns_ok =	1,
 };
 
+static __net_init int ipv4_mib_init_net(struct net *net)
+{
+	return 0;
+}
+
+static __net_exit void ipv4_mib_exit_net(struct net *net)
+{
+}
+
+static __net_initdata struct pernet_operations ipv4_mib_ops = {
+	.init = ipv4_mib_init_net,
+	.exit = ipv4_mib_exit_net,
+};
+
 static int __init init_ipv4_mibs(void)
 {
 	if (snmp_mib_init((void **)net_statistics,
@@ -1365,8 +1380,13 @@ static int __init init_ipv4_mibs(void)
 
 	tcp_mib_init(&init_net);
 
+	if (register_pernet_subsys(&ipv4_mib_ops))
+		goto err_net;
+
 	return 0;
 
+err_net:
+	snmp_mib_free((void **)udplite_statistics);
 err_udplite_mib:
 	snmp_mib_free((void **)udp_statistics);
 err_udp_mib:

commit a9c19329eccdb145a08a4a2e969d7b40c54c9bcc
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Wed Jul 16 20:21:42 2008 -0700

    tcp: add net to tcp_mib_init
    
    This one sets TCP MIBs after zeroing them, and thus requires
    the net.
    
    The existing single caller can use init_net (temporarily).
    
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index dc411335c14f..95a966dd1916 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1363,7 +1363,7 @@ static int __init init_ipv4_mibs(void)
 			  sizeof(struct udp_mib)) < 0)
 		goto err_udplite_mib;
 
-	tcp_mib_init();
+	tcp_mib_init(&init_net);
 
 	return 0;
 

commit 03d2f897e9fb3218989baa2139a951ce7f5414bf
Author: Wang Chen <wangchen@cn.fujitsu.com>
Date:   Thu Jul 3 12:13:36 2008 +0800

    ipv4: Do cleanup for ip_mr_init
    
    Same as ip6_mr_init(), make ip_mr_init() return errno if fails.
    But do not do error handling in inet_init(), just print a msg.
    
    Signed-off-by: Wang Chen <wangchen@cn.fujitsu.com>
    Signed-off-by: YOSHIFUJI Hideaki <yoshfuji@linux-ipv6.org>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 42bd24b64b57..dc411335c14f 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1479,14 +1479,15 @@ static int __init inet_init(void)
 	 *	Initialise the multicast router
 	 */
 #if defined(CONFIG_IP_MROUTE)
-	ip_mr_init();
+	if (ip_mr_init())
+		printk(KERN_CRIT "inet_init: Cannot init ipv4 mroute\n");
 #endif
 	/*
 	 *	Initialise per-cpu ipv4 mibs
 	 */
 
 	if (init_ipv4_mibs())
-		printk(KERN_CRIT "inet_init: Cannot init ipv4 mibs\n"); ;
+		printk(KERN_CRIT "inet_init: Cannot init ipv4 mibs\n");
 
 	ipv4_proc_init();
 

commit 0b040829952d84bf2a62526f0e24b624e0699447
Author: Adrian Bunk <bunk@kernel.org>
Date:   Tue Jun 10 22:46:50 2008 -0700

    net: remove CVS keywords
    
    This patch removes CVS keywords that weren't updated for a long time
    from comments.
    
    Signed-off-by: Adrian Bunk <bunk@kernel.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 24eca23c2db3..42bd24b64b57 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -5,8 +5,6 @@
  *
  *		PF_INET protocol family socket handler.
  *
- * Version:	$Id: af_inet.c,v 1.137 2002/02/01 22:01:03 davem Exp $
- *
  * Authors:	Ross Biro
  *		Fred N. van Kempen, <waltje@uWalt.NL.Mugnet.ORG>
  *		Florian La Roche, <flla@stud.uni-sb.de>

commit 801678c5a3b4c79236970bcca27c733f5559e0d1
Author: Hirofumi Nakagawa <hnakagawa@miraclelinux.com>
Date:   Tue Apr 29 01:03:09 2008 -0700

    Remove duplicated unlikely() in IS_ERR()
    
    Some drivers have duplicated unlikely() macros.  IS_ERR() already has
    unlikely() in itself.
    
    This patch cleans up such pointless code.
    
    Signed-off-by: Hirofumi Nakagawa <hnakagawa@miraclelinux.com>
    Acked-by: David S. Miller <davem@davemloft.net>
    Acked-by: Jeff Garzik <jeff@garzik.org>
    Cc: Paul Clements <paul.clements@steeleye.com>
    Cc: Richard Purdie <rpurdie@rpsys.net>
    Cc: Alessandro Zummo <a.zummo@towertech.it>
    Cc: David Brownell <david-b@pacbell.net>
    Cc: James Bottomley <James.Bottomley@HansenPartnership.com>
    Cc: Michael Halcrow <mhalcrow@us.ibm.com>
    Cc: Anton Altaparmakov <aia21@cantab.net>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Carsten Otte <cotte@de.ibm.com>
    Cc: Patrick McHardy <kaber@trash.net>
    Cc: Paul Mundt <lethal@linux-sh.org>
    Cc: Jaroslav Kysela <perex@perex.cz>
    Cc: Takashi Iwai <tiwai@suse.de>
    Acked-by: Mike Frysinger <vapier@gentoo.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index f2b5270efdaa..24eca23c2db3 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1234,7 +1234,7 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb, int features)
 		segs = ops->gso_segment(skb, features);
 	rcu_read_unlock();
 
-	if (!segs || unlikely(IS_ERR(segs)))
+	if (!segs || IS_ERR(segs))
 		goto out;
 
 	skb = segs;

commit a7d632b6b4ad1c92746ed409e41f9dc571ec04e2
Author: YOSHIFUJI Hideaki <yoshfuji@linux-ipv6.org>
Date:   Mon Apr 14 04:09:00 2008 -0700

    [IPV4]: Use NIPQUAD_FMT to format ipv4 addresses.
    
    And use %u to format port.
    
    Signed-off-by: YOSHIFUJI Hideaki <yoshfuji@linux-ipv6.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 72ae8ed5a3d7..f2b5270efdaa 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1077,7 +1077,7 @@ static int inet_sk_reselect_saddr(struct sock *sk)
 
 	if (sysctl_ip_dynaddr > 1) {
 		printk(KERN_INFO "%s(): shifting inet->"
-				 "saddr from %d.%d.%d.%d to %d.%d.%d.%d\n",
+				 "saddr from " NIPQUAD_FMT " to " NIPQUAD_FMT "\n",
 		       __func__,
 		       NIPQUAD(old_saddr),
 		       NIPQUAD(new_saddr));

commit 5616bdd6dfeb4e36be499dbac245e4d3be90a138
Author: Denis V. Lunev <den@openvz.org>
Date:   Thu Apr 3 14:30:12 2008 -0700

    [INET]: uc_ttl assignment in inet_ctl_sock_create is redundant.
    
    uc_ttl is initialized in inet(6)_create and never changed except
    setsockopt ioctl. Remove this assignment.
    
    Signed-off-by: Denis V. Lunev <den@openvz.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index cf766ad15776..72ae8ed5a3d7 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1260,7 +1260,6 @@ int inet_ctl_sock_create(struct sock **sk, unsigned short family,
 	if (rc == 0) {
 		*sk = sock->sk;
 		(*sk)->sk_allocation = GFP_ATOMIC;
-		inet_sk(*sk)->uc_ttl = -1;
 		/*
 		 * Unhash it so that IP input processing does not even see it,
 		 * we do not wish this socket to see incoming packets.

commit 5677242f432102dea9e6eceec1dc089e2f709ca4
Author: Denis V. Lunev <den@openvz.org>
Date:   Thu Apr 3 14:28:30 2008 -0700

    [NETNS]: Inet control socket should not hold a namespace.
    
    This is a generic requirement, so make inet_ctl_sock_create namespace
    aware and create a inet_ctl_sock_destroy wrapper around
    sk_release_kernel.
    
    Signed-off-by: Denis V. Lunev <den@openvz.org>
    Acked-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index cad664bf3f2e..cf766ad15776 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1251,7 +1251,8 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb, int features)
 }
 
 int inet_ctl_sock_create(struct sock **sk, unsigned short family,
-			 unsigned short type, unsigned char protocol)
+			 unsigned short type, unsigned char protocol,
+			 struct net *net)
 {
 	struct socket *sock;
 	int rc = sock_create_kern(family, type, protocol, &sock);
@@ -1265,6 +1266,8 @@ int inet_ctl_sock_create(struct sock **sk, unsigned short family,
 		 * we do not wish this socket to see incoming packets.
 		 */
 		(*sk)->sk_prot->unhash(*sk);
+
+		sk_change_net(*sk, net);
 	}
 	return rc;
 }

commit eee4fe4ded6e9c196168aee8f9787771f4df9c90
Author: Denis V. Lunev <den@openvz.org>
Date:   Thu Apr 3 14:27:58 2008 -0700

    [INET]: Let inet_ctl_sock_create return sock rather than socket.
    
    All upper protocol layers are already use sock internally.
    
    Signed-off-by: Denis V. Lunev <den@openvz.org>
    Acked-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 7ab0bd64c9d1..cad664bf3f2e 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1250,19 +1250,21 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb, int features)
 	return segs;
 }
 
-int inet_ctl_sock_create(struct socket **sock, unsigned short family,
+int inet_ctl_sock_create(struct sock **sk, unsigned short family,
 			 unsigned short type, unsigned char protocol)
 {
-	int rc = sock_create_kern(family, type, protocol, sock);
+	struct socket *sock;
+	int rc = sock_create_kern(family, type, protocol, &sock);
 
 	if (rc == 0) {
-		(*sock)->sk->sk_allocation = GFP_ATOMIC;
-		inet_sk((*sock)->sk)->uc_ttl = -1;
+		*sk = sock->sk;
+		(*sk)->sk_allocation = GFP_ATOMIC;
+		inet_sk(*sk)->uc_ttl = -1;
 		/*
 		 * Unhash it so that IP input processing does not even see it,
 		 * we do not wish this socket to see incoming packets.
 		 */
-		(*sock)->sk->sk_prot->unhash((*sock)->sk);
+		(*sk)->sk_prot->unhash(*sk);
 	}
 	return rc;
 }

commit 3d58b5fa8e4c461ab09afdacd3d1754fccca06ad
Author: Denis V. Lunev <den@openvz.org>
Date:   Thu Apr 3 14:22:32 2008 -0700

    [INET]: Rename inet_csk_ctl_sock_create to inet_ctl_sock_create.
    
    This call is nothing common with INET connection sockets code. It
    simply creates an unhashes kernel sockets for protocol messages.
    
    Move the new call into af_inet.c after the rename.
    
    Signed-off-by: Denis V. Lunev <den@openvz.org>
    Acked-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 5882a1316441..7ab0bd64c9d1 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1250,6 +1250,25 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb, int features)
 	return segs;
 }
 
+int inet_ctl_sock_create(struct socket **sock, unsigned short family,
+			 unsigned short type, unsigned char protocol)
+{
+	int rc = sock_create_kern(family, type, protocol, sock);
+
+	if (rc == 0) {
+		(*sock)->sk->sk_allocation = GFP_ATOMIC;
+		inet_sk((*sock)->sk)->uc_ttl = -1;
+		/*
+		 * Unhash it so that IP input processing does not even see it,
+		 * we do not wish this socket to see incoming packets.
+		 */
+		(*sock)->sk->sk_prot->unhash((*sock)->sk);
+	}
+	return rc;
+}
+
+EXPORT_SYMBOL_GPL(inet_ctl_sock_create);
+
 unsigned long snmp_fold_field(void *mib[], int offt)
 {
 	unsigned long res = 0;

commit 3b1e0a655f8eba44ab1ee2a1068d169ccfb853b9
Author: YOSHIFUJI Hideaki <yoshfuji@linux-ipv6.org>
Date:   Wed Mar 26 02:26:21 2008 +0900

    [NET] NETNS: Omit sock->sk_net without CONFIG_NET_NS.
    
    Introduce per-sock inlines: sock_net(), sock_net_set()
    and per-inet_timewait_sock inlines: twsk_net(), twsk_net_set().
    Without CONFIG_NET_NS, no namespace other than &init_net exists.
    Let's explicitly define them to help compiler optimizations.
    
    Signed-off-by: YOSHIFUJI Hideaki <yoshfuji@linux-ipv6.org>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 06cfb0bed631..5882a1316441 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -464,7 +464,7 @@ int inet_bind(struct socket *sock, struct sockaddr *uaddr, int addr_len)
 	if (addr_len < sizeof(struct sockaddr_in))
 		goto out;
 
-	chk_addr_ret = inet_addr_type(sk->sk_net, addr->sin_addr.s_addr);
+	chk_addr_ret = inet_addr_type(sock_net(sk), addr->sin_addr.s_addr);
 
 	/* Not specified by any standard per-se, however it breaks too
 	 * many applications when removed.  It is unfortunate since
@@ -802,7 +802,7 @@ int inet_ioctl(struct socket *sock, unsigned int cmd, unsigned long arg)
 {
 	struct sock *sk = sock->sk;
 	int err = 0;
-	struct net *net = sk->sk_net;
+	struct net *net = sock_net(sk);
 
 	switch (cmd) {
 		case SIOCGSTAMP:
@@ -1132,7 +1132,7 @@ int inet_sk_rebuild_header(struct sock *sk)
 	};
 
 	security_sk_classify_flow(sk, &fl);
-	err = ip_route_output_flow(sk->sk_net, &rt, &fl, sk, 0);
+	err = ip_route_output_flow(sock_net(sk), &rt, &fl, sk, 0);
 }
 	if (!err)
 		sk_setup_caps(sk, &rt->u.dst);

commit 92f1fecb45ef97acae94463302f79228a4b454d9
Author: Denis V. Lunev <den@openvz.org>
Date:   Mon Mar 24 15:34:06 2008 -0700

    [NETNS]: Enable TCP/UDP/ICMP inside namespace.
    
    Signed-off-by: Denis V. Lunev <den@openvz.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 39ddb84b1b78..06cfb0bed631 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1302,17 +1302,20 @@ static struct net_protocol tcp_protocol = {
 	.gso_send_check = tcp_v4_gso_send_check,
 	.gso_segment =	tcp_tso_segment,
 	.no_policy =	1,
+	.netns_ok =	1,
 };
 
 static struct net_protocol udp_protocol = {
 	.handler =	udp_rcv,
 	.err_handler =	udp_err,
 	.no_policy =	1,
+	.netns_ok =	1,
 };
 
 static struct net_protocol icmp_protocol = {
 	.handler =	icmp_rcv,
 	.no_policy =	1,
+	.netns_ok =	1,
 };
 
 static int __init init_ipv4_mibs(void)

commit 2342fd7e146f05edeb13feb03490c13a1bdab2e0
Author: Denis V. Lunev <den@openvz.org>
Date:   Mon Mar 24 15:33:42 2008 -0700

    [NETNS]: Allow to create sockets in non-initial namespace.
    
    Allow to create sockets in the namespace if the protocol ok with this.
    
    Signed-off-by: Denis V. Lunev <den@openvz.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index a9e241cdc5b2..39ddb84b1b78 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -243,6 +243,23 @@ void build_ehash_secret(void)
 }
 EXPORT_SYMBOL(build_ehash_secret);
 
+static inline int inet_netns_ok(struct net *net, int protocol)
+{
+	int hash;
+	struct net_protocol *ipprot;
+
+	if (net == &init_net)
+		return 1;
+
+	hash = protocol & (MAX_INET_PROTOS - 1);
+	ipprot = rcu_dereference(inet_protos[hash]);
+
+	if (ipprot == NULL)
+		/* raw IP is OK */
+		return 1;
+	return ipprot->netns_ok;
+}
+
 /*
  *	Create an inet socket.
  */
@@ -259,9 +276,6 @@ static int inet_create(struct net *net, struct socket *sock, int protocol)
 	int try_loading_module = 0;
 	int err;
 
-	if (net != &init_net)
-		return -EAFNOSUPPORT;
-
 	if (sock->type != SOCK_RAW &&
 	    sock->type != SOCK_DGRAM &&
 	    !inet_ehash_secret)
@@ -320,6 +334,10 @@ static int inet_create(struct net *net, struct socket *sock, int protocol)
 	if (answer->capability > 0 && !capable(answer->capability))
 		goto out_rcu_unlock;
 
+	err = -EAFNOSUPPORT;
+	if (!inet_netns_ok(net, protocol))
+		goto out_rcu_unlock;
+
 	sock->ops = answer->ops;
 	answer_prot = answer->prot;
 	answer_no_check = answer->no_check;

commit 05cf89d40c85e622dac20e44713168767be5c520
Author: Denis V. Lunev <den@openvz.org>
Date:   Mon Mar 24 15:31:35 2008 -0700

    [NETNS]: Process INET socket layer in the correct namespace.
    
    Replace all the reast of the init_net with a proper net on the socket
    layer.
    
    Signed-off-by: Denis V. Lunev <den@openvz.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 44f5ce1fbfa4..a9e241cdc5b2 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -446,7 +446,7 @@ int inet_bind(struct socket *sock, struct sockaddr *uaddr, int addr_len)
 	if (addr_len < sizeof(struct sockaddr_in))
 		goto out;
 
-	chk_addr_ret = inet_addr_type(&init_net, addr->sin_addr.s_addr);
+	chk_addr_ret = inet_addr_type(sk->sk_net, addr->sin_addr.s_addr);
 
 	/* Not specified by any standard per-se, however it breaks too
 	 * many applications when removed.  It is unfortunate since
@@ -1114,7 +1114,7 @@ int inet_sk_rebuild_header(struct sock *sk)
 	};
 
 	security_sk_classify_flow(sk, &fl);
-	err = ip_route_output_flow(&init_net, &rt, &fl, sk, 0);
+	err = ip_route_output_flow(sk->sk_net, &rt, &fl, sk, 0);
 }
 	if (!err)
 		sk_setup_caps(sk, &rt->u.dst);

commit 577f99c1d08cf9cbdafd4e858dd13ff04d855090
Merge: 26c0f03f6b77 2f633928cbba
Author: David S. Miller <davem@davemloft.net>
Date:   Tue Mar 18 00:37:55 2008 -0700

    Merge branch 'master' of git://git.kernel.org/pub/scm/linux/kernel/git/davem/net-2.6
    
    Conflicts:
    
            drivers/net/wireless/rt2x00/rt2x00dev.c
            net/8021q/vlan_dev.c

commit e6f1cebf71c4e7aae7dfa43414ce2631291def9f
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Mon Mar 17 22:44:53 2008 -0700

    [NET] endianness noise: INADDR_ANY
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 09ca5293d08f..0d109504ed86 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -458,7 +458,7 @@ int inet_bind(struct socket *sock, struct sockaddr *uaddr, int addr_len)
 	err = -EADDRNOTAVAIL;
 	if (!sysctl_ip_nonlocal_bind &&
 	    !inet->freebind &&
-	    addr->sin_addr.s_addr != INADDR_ANY &&
+	    addr->sin_addr.s_addr != htonl(INADDR_ANY) &&
 	    chk_addr_ret != RTN_LOCAL &&
 	    chk_addr_ret != RTN_MULTICAST &&
 	    chk_addr_ret != RTN_BROADCAST)

commit db8dac20d5199307dcfcf4e01dac4bda5edf9e89
Author: David S. Miller <davem@davemloft.net>
Date:   Thu Mar 6 16:22:02 2008 -0800

    [UDP]: Revert udplite and code split.
    
    This reverts commit db1ed684f6c430c4cdad67d058688b8a1b5e607c ("[IPV6]
    UDP: Rename IPv6 UDP files."), commit
    8be8af8fa4405652e6c0797db5465a4be8afb998 ("[IPV4] UDP: Move
    IPv4-specific bits to other file.") and commit
    e898d4db2749c6052072e9bc4448e396cbdeb06a ("[UDP]: Allow users to
    configure UDP-Lite.").
    
    First, udplite is of such small cost, and it is a core protocol just
    like TCP and normal UDP are.
    
    We spent enormous amounts of effort to make udplite share as much code
    with core UDP as possible.  All of that work is less valuable if we're
    just going to slap a config option on udplite support.
    
    It is also causing build failures, as reported on linux-next, showing
    that the changeset was not tested very well.  In fact, this is the
    second build failure resulting from the udplite change.
    
    Finally, the config options provided was a bool, instead of a modular
    option.  Meaning the udplite code does not even get build tested
    by allmodconfig builds, and furthermore the user is not presented
    with a reasonable modular build option which is particularly needed
    by distribution vendors.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 25871c6c7444..4cb8a1385539 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1317,18 +1317,15 @@ static int __init init_ipv4_mibs(void)
 	if (snmp_mib_init((void **)udp_statistics,
 			  sizeof(struct udp_mib)) < 0)
 		goto err_udp_mib;
-#ifdef CONFIG_IP_UDPLITE
 	if (snmp_mib_init((void **)udplite_statistics,
 			  sizeof(struct udp_mib)) < 0)
 		goto err_udplite_mib;
-#endif
+
 	tcp_mib_init();
 
 	return 0;
 
-#ifdef CONFIG_IP_UDPLITE
 err_udplite_mib:
-#endif
 	snmp_mib_free((void **)udp_statistics);
 err_udp_mib:
 	snmp_mib_free((void **)tcp_statistics);
@@ -1426,10 +1423,8 @@ static int __init inet_init(void)
 	/* Setup UDP memory threshold */
 	udp_init();
 
-#ifdef CONFIG_IP_UDPLITE
 	/* Add UDP-Lite (RFC 3828) */
 	udplite4_register();
-#endif
 
 	/*
 	 *	Set the ICMP layer up

commit 0dc47877a3de00ceadea0005189656ae8dc52669
Author: Harvey Harrison <harvey.harrison@gmail.com>
Date:   Wed Mar 5 20:47:47 2008 -0800

    net: replace remaining __FUNCTION__ occurrences
    
    __FUNCTION__ is gcc-specific, use __func__
    
    Signed-off-by: Harvey Harrison <harvey.harrison@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 67260c0eaaa8..25871c6c7444 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1060,7 +1060,7 @@ static int inet_sk_reselect_saddr(struct sock *sk)
 	if (sysctl_ip_dynaddr > 1) {
 		printk(KERN_INFO "%s(): shifting inet->"
 				 "saddr from %d.%d.%d.%d to %d.%d.%d.%d\n",
-		       __FUNCTION__,
+		       __func__,
 		       NIPQUAD(old_saddr),
 		       NIPQUAD(new_saddr));
 	}

commit e898d4db2749c6052072e9bc4448e396cbdeb06a
Author: YOSHIFUJI Hideaki <yoshfuji@linux-ipv6.org>
Date:   Sat Mar 1 01:06:47 2008 +0900

    [UDP]: Allow users to configure UDP-Lite.
    
    Let's give users an option for disabling UDP-Lite (~4K).
    
    old:
    |    text          data     bss     dec     hex filename
    |  286498         12432    6072  305002   4a76a net/ipv4/built-in.o
    |  193830          8192    3204  205226   321aa net/ipv6/ipv6.o
    
    new (without UDP-Lite):
    |    text          data     bss     dec     hex filename
    |  284086         12136    5432  301654   49a56 net/ipv4/built-in.o
    |  191835          7832    3076  202743   317f7 net/ipv6/ipv6.o
    
    Signed-off-by: YOSHIFUJI Hideaki <yoshfuji@linux-ipv6.org>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 4f539bd48718..67260c0eaaa8 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1317,15 +1317,18 @@ static int __init init_ipv4_mibs(void)
 	if (snmp_mib_init((void **)udp_statistics,
 			  sizeof(struct udp_mib)) < 0)
 		goto err_udp_mib;
+#ifdef CONFIG_IP_UDPLITE
 	if (snmp_mib_init((void **)udplite_statistics,
 			  sizeof(struct udp_mib)) < 0)
 		goto err_udplite_mib;
-
+#endif
 	tcp_mib_init();
 
 	return 0;
 
+#ifdef CONFIG_IP_UDPLITE
 err_udplite_mib:
+#endif
 	snmp_mib_free((void **)udp_statistics);
 err_udp_mib:
 	snmp_mib_free((void **)tcp_statistics);
@@ -1423,8 +1426,10 @@ static int __init inet_init(void)
 	/* Setup UDP memory threshold */
 	udp_init();
 
+#ifdef CONFIG_IP_UDPLITE
 	/* Add UDP-Lite (RFC 3828) */
 	udplite4_register();
+#endif
 
 	/*
 	 *	Set the ICMP layer up

commit a5710d6582868a96cf0fe02eac11d34cfbc783c9
Author: Denis V. Lunev <den@openvz.org>
Date:   Fri Feb 29 11:14:50 2008 -0800

    [ICMP]: Add return code to icmp_init.
    
    icmp_init could fail and this is normal for namespace other than initial.
    So, the panic should be triggered only on init_net initialization path.
    
    Additionally create rollback path for icmp_init as a separate function.
    It will also be used later during namespace destruction.
    
    Signed-off-by: Denis V. Lunev <den@openvz.org>
    Acked-by: Daniel Lezcano <dlezcano@fr.ibm.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index a7a99ac856dc..4f539bd48718 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1430,7 +1430,8 @@ static int __init inet_init(void)
 	 *	Set the ICMP layer up
 	 */
 
-	icmp_init();
+	if (icmp_init() < 0)
+		panic("Failed to create the ICMP control socket.\n");
 
 	/*
 	 *	Initialise the multicast router

commit 9b0f976f27f00a81cf47643d90854659626795b4
Author: Denis V. Lunev <den@openvz.org>
Date:   Fri Feb 29 11:13:15 2008 -0800

    [INET]: Remove struct net_proto_family* from _init calls.
    
    struct net_proto_family* is not used in icmp[v6]_init, ndisc_init,
    igmp_init and tcp_v4_init. Remove it.
    
    Signed-off-by: Denis V. Lunev <den@openvz.org>
    Acked-by: Daniel Lezcano <dlezcano@fr.ibm.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index c270080f370e..a7a99ac856dc 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1415,7 +1415,7 @@ static int __init inet_init(void)
 
 	ip_init();
 
-	tcp_v4_init(&inet_family_ops);
+	tcp_v4_init();
 
 	/* Setup TCP slab cache for open requests. */
 	tcp_init();
@@ -1430,7 +1430,7 @@ static int __init inet_init(void)
 	 *	Set the ICMP layer up
 	 */
 
-	icmp_init(&inet_family_ops);
+	icmp_init();
 
 	/*
 	 *	Initialise the multicast router

commit e5b13cb10de209f924fdf9478214bcf7e4008d6d
Author: Denis V. Lunev <den@openvz.org>
Date:   Thu Feb 28 20:51:43 2008 -0800

    [NETNS]: Process devinet ioctl in the correct namespace.
    
    Add namespace parameter to devinet_ioctl and locate device inside it for
    state changes.
    
    Signed-off-by: Denis V. Lunev <den@openvz.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 09ca5293d08f..c270080f370e 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -784,6 +784,7 @@ int inet_ioctl(struct socket *sock, unsigned int cmd, unsigned long arg)
 {
 	struct sock *sk = sock->sk;
 	int err = 0;
+	struct net *net = sk->sk_net;
 
 	switch (cmd) {
 		case SIOCGSTAMP:
@@ -795,12 +796,12 @@ int inet_ioctl(struct socket *sock, unsigned int cmd, unsigned long arg)
 		case SIOCADDRT:
 		case SIOCDELRT:
 		case SIOCRTMSG:
-			err = ip_rt_ioctl(sk->sk_net, cmd, (void __user *)arg);
+			err = ip_rt_ioctl(net, cmd, (void __user *)arg);
 			break;
 		case SIOCDARP:
 		case SIOCGARP:
 		case SIOCSARP:
-			err = arp_ioctl(sk->sk_net, cmd, (void __user *)arg);
+			err = arp_ioctl(net, cmd, (void __user *)arg);
 			break;
 		case SIOCGIFADDR:
 		case SIOCSIFADDR:
@@ -813,7 +814,7 @@ int inet_ioctl(struct socket *sock, unsigned int cmd, unsigned long arg)
 		case SIOCSIFPFLAGS:
 		case SIOCGIFPFLAGS:
 		case SIOCSIFFLAGS:
-			err = devinet_ioctl(cmd, (void __user *)arg);
+			err = devinet_ioctl(net, cmd, (void __user *)arg);
 			break;
 		default:
 			if (sk->sk_prot->ioctl)

commit f1b050bf7a88910f9f00c9c8989c1bf5a67dd140
Author: Denis V. Lunev <den@openvz.org>
Date:   Tue Jan 22 22:07:10 2008 -0800

    [NETNS]: Add namespace parameter to ip_route_output_flow.
    
    Needed to propagate it down to the __ip_route_output_key.
    
    Signed_off_by: Denis V. Lunev <den@openvz.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index bcf8c8a4a3ad..09ca5293d08f 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1113,7 +1113,7 @@ int inet_sk_rebuild_header(struct sock *sk)
 	};
 
 	security_sk_classify_flow(sk, &fl);
-	err = ip_route_output_flow(&rt, &fl, sk, 0);
+	err = ip_route_output_flow(&init_net, &rt, &fl, sk, 0);
 }
 	if (!err)
 		sk_setup_caps(sk, &rt->u.dst);

commit 1bad118a330d494b23663fce94d4e9d9d5065fa7
Author: Denis V. Lunev <den@openvz.org>
Date:   Thu Jan 10 03:29:53 2008 -0800

    [NETNS]: Pass namespace through ip_rt_ioctl.
    
    ... up to rtentry_to_fib_config
    
    Acked-by: Benjamin Thery <benjamin.thery@bull.net>
    Acked-by: Daniel Lezcano <dlezcano@fr.ibm.com>
    Signed-off-by: Denis V. Lunev <den@openvz.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index d76f8d8d5eba..bcf8c8a4a3ad 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -795,7 +795,7 @@ int inet_ioctl(struct socket *sock, unsigned int cmd, unsigned long arg)
 		case SIOCADDRT:
 		case SIOCDELRT:
 		case SIOCRTMSG:
-			err = ip_rt_ioctl(cmd, (void __user *)arg);
+			err = ip_rt_ioctl(sk->sk_net, cmd, (void __user *)arg);
 			break;
 		case SIOCDARP:
 		case SIOCGARP:

commit 6b175b26c1048d331508940ad3516ead1998084f
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Thu Jan 10 03:25:28 2008 -0800

    [NETNS]: Add netns parameter to inet_(dev_)add_type.
    
    The patch extends the inet_addr_type and inet_dev_addr_type with the
    network namespace pointer. That allows to access the different tables
    relatively to the network namespace.
    
    The modification of the signature function is reported in all the
    callers of the inet_addr_type using the pointer to the well known
    init_net.
    
    Acked-by: Benjamin Thery <benjamin.thery@bull.net>
    Acked-by: Daniel Lezcano <dlezcano@fr.ibm.com>
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 40ecaae7be32..d76f8d8d5eba 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -446,7 +446,7 @@ int inet_bind(struct socket *sock, struct sockaddr *uaddr, int addr_len)
 	if (addr_len < sizeof(struct sockaddr_in))
 		goto out;
 
-	chk_addr_ret = inet_addr_type(addr->sin_addr.s_addr);
+	chk_addr_ret = inet_addr_type(&init_net, addr->sin_addr.s_addr);
 
 	/* Not specified by any standard per-se, however it breaks too
 	 * many applications when removed.  It is unfortunate since

commit 7b1a74fdbb9ec38a9780620fae25519fde4b21ee
Author: Denis V. Lunev <den@openvz.org>
Date:   Thu Jan 10 03:22:17 2008 -0800

    [NETNS]: Refactor fib initialization so it can handle multiple namespaces.
    
    This patch makes the fib to be initialized as a subsystem for the
    network namespaces. The code does not handle several namespaces yet,
    so in case of a creation of a network namespace, the
    creation/initialization will not occur.
    
    Acked-by: Benjamin Thery <benjamin.thery@bull.net>
    Acked-by: Daniel Lezcano <dlezcano@fr.ibm.com>
    Signed-off-by: Denis V. Lunev <den@openvz.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index d5b8cb1dad67..40ecaae7be32 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1475,15 +1475,11 @@ static int __init ipv4_proc_init(void)
 		goto out_tcp;
 	if (udp4_proc_init())
 		goto out_udp;
-	if (fib_proc_init(&init_net))
-		goto out_fib;
 	if (ip_misc_proc_init())
 		goto out_misc;
 out:
 	return rc;
 out_misc:
-	fib_proc_exit(&init_net);
-out_fib:
 	udp4_proc_exit();
 out_udp:
 	tcp4_proc_exit();

commit 61a0265344786a548e8a0b26cb668e78a71f9602
Author: Denis V. Lunev <den@openvz.org>
Date:   Thu Jan 10 03:21:09 2008 -0800

    [NETNS]: Add namespace to API for routing /proc entries creation.
    
    This adds netns parameter to fib_proc_init/exit and replaces __init
    specifier with __net_init. After this, we will not yet have these proc
    files show info from the specific namespace - this will be done when
    these tables become namespaced.
    
    Acked-by: Benjamin Thery <benjamin.thery@bull.net>
    Acked-by: Daniel Lezcano <dlezcano@fr.ibm.com>
    Signed-off-by: Denis V. Lunev <den@openvz.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 0e12cf646071..d5b8cb1dad67 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1475,14 +1475,14 @@ static int __init ipv4_proc_init(void)
 		goto out_tcp;
 	if (udp4_proc_init())
 		goto out_udp;
-	if (fib_proc_init())
+	if (fib_proc_init(&init_net))
 		goto out_fib;
 	if (ip_misc_proc_init())
 		goto out_misc;
 out:
 	return rc;
 out_misc:
-	fib_proc_exit();
+	fib_proc_exit(&init_net);
 out_fib:
 	udp4_proc_exit();
 out_udp:

commit 95766fff6b9a78d11fc2d3812dd035381690b55d
Author: Hideo Aoki <haoki@redhat.com>
Date:   Mon Dec 31 00:29:24 2007 -0800

    [UDP]: Add memory accounting.
    
    Signed-off-by: Takahiro Yasui <tyasui@redhat.com>
    Signed-off-by: Hideo Aoki <haoki@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 03633b7b9b4a..0e12cf646071 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -139,6 +139,8 @@ void inet_sock_destruct(struct sock *sk)
 	__skb_queue_purge(&sk->sk_receive_queue);
 	__skb_queue_purge(&sk->sk_error_queue);
 
+	sk_mem_reclaim(sk);
+
 	if (sk->sk_type == SOCK_STREAM && sk->sk_state != TCP_CLOSE) {
 		printk("Attempt to release TCP socket in state %d %p\n",
 		       sk->sk_state, sk);
@@ -1417,6 +1419,9 @@ static int __init inet_init(void)
 	/* Setup TCP slab cache for open requests. */
 	tcp_init();
 
+	/* Setup UDP memory threshold */
+	udp_init();
+
 	/* Add UDP-Lite (RFC 3828) */
 	udplite4_register();
 

commit 32e569b7277f13c4b27bb29c761189963e49ce7a
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Sun Dec 16 13:30:39 2007 -0800

    [IPV4]: Pass the net pointer to the arp_req_set_proxy()
    
    This one will need to set the IPV4_DEVCONF_ALL(PROXY_ARP), but
    there's no ways to get the net right in place, so we have to
    pull one from the inet_ioctl's struct sock.
    
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 5089a369e99c..03633b7b9b4a 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -798,7 +798,7 @@ int inet_ioctl(struct socket *sock, unsigned int cmd, unsigned long arg)
 		case SIOCDARP:
 		case SIOCGARP:
 		case SIOCSARP:
-			err = arp_ioctl(cmd, (void __user *)arg);
+			err = arp_ioctl(sk->sk_net, cmd, (void __user *)arg);
 			break;
 		case SIOCGIFADDR:
 		case SIOCSIFADDR:

commit 8b7817f3a959ed99d7443afc12f78a7e1fcc2063
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Wed Dec 12 10:44:43 2007 -0800

    [IPSEC]: Add ICMP host relookup support
    
    RFC 4301 requires us to relookup ICMP traffic that does not match any
    policies using the reverse of its payload.  This patch implements this
    for ICMP traffic that originates from or terminates on localhost.
    
    This is activated on outbound with the new policy flag XFRM_POLICY_ICMP,
    and on inbound by the new state flag XFRM_STATE_ICMP.
    
    On inbound the policy check is now performed by the ICMP protocol so
    that it can repeat the policy check where necessary.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 7f8b27ff94ff..5089a369e99c 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1291,6 +1291,7 @@ static struct net_protocol udp_protocol = {
 
 static struct net_protocol icmp_protocol = {
 	.handler =	icmp_rcv,
+	.no_policy =	1,
 };
 
 static int __init init_ipv4_mibs(void)

commit c69bce20dda7f79160856a338298d65a284ba303
Author: YOSHIFUJI Hideaki <yoshfuji@linux-ipv6.org>
Date:   Wed Jan 23 22:31:45 2008 -0800

    [NET]: Remove unused "mibalign" argument for snmp_mib_init().
    
    With fixes from Arnaldo Carvalho de Melo.
    
    Signed-off-by: YOSHIFUJI Hideaki <yoshfuji@linux-ipv6.org>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 0e4b6eba2340..7f8b27ff94ff 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1242,7 +1242,7 @@ unsigned long snmp_fold_field(void *mib[], int offt)
 }
 EXPORT_SYMBOL_GPL(snmp_fold_field);
 
-int snmp_mib_init(void *ptr[2], size_t mibsize, size_t mibalign)
+int snmp_mib_init(void *ptr[2], size_t mibsize)
 {
 	BUG_ON(ptr == NULL);
 	ptr[0] = __alloc_percpu(mibsize);
@@ -1296,32 +1296,25 @@ static struct net_protocol icmp_protocol = {
 static int __init init_ipv4_mibs(void)
 {
 	if (snmp_mib_init((void **)net_statistics,
-			  sizeof(struct linux_mib),
-			  __alignof__(struct linux_mib)) < 0)
+			  sizeof(struct linux_mib)) < 0)
 		goto err_net_mib;
 	if (snmp_mib_init((void **)ip_statistics,
-			  sizeof(struct ipstats_mib),
-			  __alignof__(struct ipstats_mib)) < 0)
+			  sizeof(struct ipstats_mib)) < 0)
 		goto err_ip_mib;
 	if (snmp_mib_init((void **)icmp_statistics,
-			  sizeof(struct icmp_mib),
-			  __alignof__(struct icmp_mib)) < 0)
+			  sizeof(struct icmp_mib)) < 0)
 		goto err_icmp_mib;
 	if (snmp_mib_init((void **)icmpmsg_statistics,
-			  sizeof(struct icmpmsg_mib),
-			  __alignof__(struct icmpmsg_mib)) < 0)
+			  sizeof(struct icmpmsg_mib)) < 0)
 		goto err_icmpmsg_mib;
 	if (snmp_mib_init((void **)tcp_statistics,
-			  sizeof(struct tcp_mib),
-			  __alignof__(struct tcp_mib)) < 0)
+			  sizeof(struct tcp_mib)) < 0)
 		goto err_tcp_mib;
 	if (snmp_mib_init((void **)udp_statistics,
-			  sizeof(struct udp_mib),
-			  __alignof__(struct udp_mib)) < 0)
+			  sizeof(struct udp_mib)) < 0)
 		goto err_udp_mib;
 	if (snmp_mib_init((void **)udplite_statistics,
-			  sizeof(struct udp_mib),
-			  __alignof__(struct udp_mib)) < 0)
+			  sizeof(struct udp_mib)) < 0)
 		goto err_udplite_mib;
 
 	tcp_mib_init();

commit 9ba639797606acbcd97be886f41fbce163914e7b
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Wed Dec 5 01:38:23 2007 -0800

    [IPV4]: Cleanup the sysctl_net_ipv4.c file
    
    This includes several cleanups:
    
     * tune Makefile to compile out this file when SYSCTL=n. Now
       it looks like net/core/sysctl_net_core.c one;
     * move the ipv4_config to af_inet.c to exist all the time;
     * remove additional sysctl_ip_nonlocal_bind declaration
       (it is already declared in net/ip.h);
     * remove no nonger needed ifdefs from this file.
    
    This is a preparation for using ctl paths for net/ipv4/
    sysctl table.
    
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index c75f20b49935..0e4b6eba2340 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -126,6 +126,10 @@ extern void ip_mc_drop_socket(struct sock *sk);
 static struct list_head inetsw[SOCK_MAX];
 static DEFINE_SPINLOCK(inetsw_lock);
 
+struct ipv4_config ipv4_config;
+
+EXPORT_SYMBOL(ipv4_config);
+
 /* New destruction routine */
 
 void inet_sock_destruct(struct sock *sk)

commit 9c55e01c0cc835818475a6ce8c4d684df9949ac8
Author: Jens Axboe <jens.axboe@oracle.com>
Date:   Tue Nov 6 23:30:13 2007 -0800

    [TCP]: Splice receive support.
    
    Support for network splice receive.
    
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index d2f22e74b267..c75f20b49935 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -838,6 +838,7 @@ const struct proto_ops inet_stream_ops = {
 	.recvmsg	   = sock_common_recvmsg,
 	.mmap		   = sock_no_mmap,
 	.sendpage	   = tcp_sendpage,
+	.splice_read	   = tcp_splice_read,
 #ifdef CONFIG_COMPAT
 	.compat_setsockopt = compat_sock_common_setsockopt,
 	.compat_getsockopt = compat_sock_common_getsockopt,

commit 6257ff2177ff02d7f260a7a501876aa41cb9a9f6
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Thu Nov 1 00:39:31 2007 -0700

    [NET]: Forget the zero_it argument of sk_alloc()
    
    Finally, the zero_it argument can be completely removed from
    the callers and from the function prototype.
    
    Besides, fix the checkpatch.pl warnings about using the
    assignments inside if-s.
    
    This patch is rather big, and it is a part of the previous one.
    I splitted it wishing to make the patches more readable. Hope
    this particular split helped.
    
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 621b128897d7..d2f22e74b267 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -323,7 +323,7 @@ static int inet_create(struct net *net, struct socket *sock, int protocol)
 	BUG_TRAP(answer_prot->slab != NULL);
 
 	err = -ENOBUFS;
-	sk = sk_alloc(net, PF_INET, GFP_KERNEL, answer_prot, 1);
+	sk = sk_alloc(net, PF_INET, GFP_KERNEL, answer_prot);
 	if (sk == NULL)
 		goto out;
 

commit 96793b482540f3a26e2188eaf75cb56b7829d3e3
Author: David L Stevens <dlstevens@us.ibm.com>
Date:   Mon Sep 17 09:57:33 2007 -0700

    [IPV4]: Add ICMPMsgStats MIB (RFC 4293)
    
    Background: RFC 4293 deprecates existing individual, named ICMP
    type counters to be replaced with the ICMPMsgStatsTable. This table
    includes entries for both IPv4 and IPv6, and requires counting of all
    ICMP types, whether or not the machine implements the type.
    
    These patches "remove" (but not really) the existing counters, and
    replace them with the ICMPMsgStats tables for v4 and v6.
    It includes the named counters in the /proc places they were, but gets the
    values for them from the new tables. It also counts packets generated
    from raw socket output (e.g., OutEchoes, MLD queries, RA's from
    radvd, etc).
    
    Changes:
    1) create icmpmsg_statistics mib
    2) create icmpv6msg_statistics mib
    3) modify existing counters to use these
    4) modify /proc/net/snmp to add "IcmpMsg" with all ICMP types
            listed by number for easy SNMP parsing
    5) modify /proc/net/snmp printing for "Icmp" to get the named data
            from new counters.
    
    Signed-off-by: David L Stevens <dlstevens@us.ibm.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index e594a2c89661..621b128897d7 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1302,6 +1302,10 @@ static int __init init_ipv4_mibs(void)
 			  sizeof(struct icmp_mib),
 			  __alignof__(struct icmp_mib)) < 0)
 		goto err_icmp_mib;
+	if (snmp_mib_init((void **)icmpmsg_statistics,
+			  sizeof(struct icmpmsg_mib),
+			  __alignof__(struct icmpmsg_mib)) < 0)
+		goto err_icmpmsg_mib;
 	if (snmp_mib_init((void **)tcp_statistics,
 			  sizeof(struct tcp_mib),
 			  __alignof__(struct tcp_mib)) < 0)
@@ -1324,6 +1328,8 @@ static int __init init_ipv4_mibs(void)
 err_udp_mib:
 	snmp_mib_free((void **)tcp_statistics);
 err_tcp_mib:
+	snmp_mib_free((void **)icmpmsg_statistics);
+err_icmpmsg_mib:
 	snmp_mib_free((void **)icmp_statistics);
 err_icmp_mib:
 	snmp_mib_free((void **)ip_statistics);

commit c40f6fff401f693f627d3d44ef7663b993943517
Author: Denis Cheng <crquan@gmail.com>
Date:   Sun Sep 16 16:39:25 2007 -0700

    [IPV4] af_inet.c: use ARRAY_SIZE macro from kernel.h instead
    
    Signed-off-by: Denis Cheng <crquan@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 110a19edacc8..e594a2c89661 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -942,7 +942,7 @@ static struct inet_protosw inetsw_array[] =
        }
 };
 
-#define INETSW_ARRAY_LEN (sizeof(inetsw_array) / sizeof(struct inet_protosw))
+#define INETSW_ARRAY_LEN ARRAY_SIZE(inetsw_array)
 
 void inet_register_protosw(struct inet_protosw *p)
 {

commit 1b8d7ae42d02e483ad94035cca851e4f7fbecb40
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Mon Oct 8 23:24:22 2007 -0700

    [NET]: Make socket creation namespace safe.
    
    This patch passes in the namespace a new socket should be created in
    and has the socket code do the appropriate reference counting.  By
    virtue of this all socket create methods are touched.  In addition
    the socket create methods are modified so that they will fail if
    you attempt to create a socket in a non-default network namespace.
    
    Failing if we attempt to create a socket outside of the default
    network namespace ensures that as we incrementally make the network stack
    network namespace aware we will not export functionality that someone
    has not audited and made certain is network namespace safe.
    Allowing us to partially enable network namespaces before all of the
    exotic protocols are supported.
    
    Any protocol layers I have missed will fail to compile because I now
    pass an extra parameter into the socket creation code.
    
    [ Integrated AF_IUCV build fixes from Andrew Morton... -DaveM ]
    
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index e68103475cca..110a19edacc8 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -241,7 +241,7 @@ EXPORT_SYMBOL(build_ehash_secret);
  *	Create an inet socket.
  */
 
-static int inet_create(struct socket *sock, int protocol)
+static int inet_create(struct net *net, struct socket *sock, int protocol)
 {
 	struct sock *sk;
 	struct list_head *p;
@@ -253,6 +253,9 @@ static int inet_create(struct socket *sock, int protocol)
 	int try_loading_module = 0;
 	int err;
 
+	if (net != &init_net)
+		return -EAFNOSUPPORT;
+
 	if (sock->type != SOCK_RAW &&
 	    sock->type != SOCK_DGRAM &&
 	    !inet_ehash_secret)
@@ -320,7 +323,7 @@ static int inet_create(struct socket *sock, int protocol)
 	BUG_TRAP(answer_prot->slab != NULL);
 
 	err = -ENOBUFS;
-	sk = sk_alloc(PF_INET, GFP_KERNEL, answer_prot, 1);
+	sk = sk_alloc(net, PF_INET, GFP_KERNEL, answer_prot, 1);
 	if (sk == NULL)
 		goto out;
 

commit 3516ffb0fef710749daf288c0fe146503e0cf9d4
Author: David S. Miller <davem@sunset.davemloft.net>
Date:   Thu Aug 2 19:23:56 2007 -0700

    [TCP]: Invoke tcp_sendmsg() directly, do not use inet_sendmsg().
    
    As discovered by Evegniy Polyakov, if we try to sendmsg after
    a connection reset, we can do incredibly stupid things.
    
    The core issue is that inet_sendmsg() tries to autobind the
    socket, but we should never do that for TCP.  Instead we should
    just go straight into TCP's sendmsg() code which will do all
    of the necessary state and pending socket error checks.
    
    TCP's sendpage already directly vectors to tcp_sendpage(), so this
    merely brings sendmsg() in line with that.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 06c08e5740fb..e68103475cca 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -831,7 +831,7 @@ const struct proto_ops inet_stream_ops = {
 	.shutdown	   = inet_shutdown,
 	.setsockopt	   = sock_common_setsockopt,
 	.getsockopt	   = sock_common_getsockopt,
-	.sendmsg	   = inet_sendmsg,
+	.sendmsg	   = tcp_sendmsg,
 	.recvmsg	   = sock_common_recvmsg,
 	.mmap		   = sock_no_mmap,
 	.sendpage	   = tcp_sendpage,

commit d212f87b068c9d72065ef579d85b5ee6b8b59381
Author: Stephen Hemminger <shemminger@linux-foundation.org>
Date:   Wed Jun 27 00:47:37 2007 -0700

    [NET]: IPV6 checksum offloading in network devices
    
    The existing model for checksum offload does not correctly handle
    devices that can offload IPV4 and IPV6 only. The NETIF_F_HW_CSUM flag
    implies device can do any arbitrary protocol.
    
    This patch:
     * adds NETIF_F_IPV6_CSUM for those devices
     * fixes bnx2 and tg3 devices that need it
     * add NETIF_F_IPV6_CSUM to ipv6 output (incl GSO)
     * fixes assumptions about NETIF_F_ALL_CSUM in nat
     * adjusts bridge union of checksumming computation
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 041fba3fa0aa..06c08e5740fb 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1170,6 +1170,9 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb, int features)
 	int ihl;
 	int id;
 
+	if (!(features & NETIF_F_V4_CSUM))
+		features &= ~NETIF_F_SG;
+
 	if (unlikely(skb_shinfo(skb)->gso_type &
 		     ~(SKB_GSO_TCPV4 |
 		       SKB_GSO_UDP |

commit e63340ae6b6205fef26b40a75673d1c9c0c8bb90
Author: Randy Dunlap <randy.dunlap@oracle.com>
Date:   Tue May 8 00:28:08 2007 -0700

    header cleaning: don't include smp_lock.h when not used
    
    Remove includes of <linux/smp_lock.h> where it is not used/needed.
    Suggested by Al Viro.
    
    Builds cleanly on x86_64, i386, alpha, ia64, powerpc, sparc,
    sparc64, and arm (all 59 defconfigs).
    
    Signed-off-by: Randy Dunlap <randy.dunlap@oracle.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 16aae8ef5555..041fba3fa0aa 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -92,7 +92,6 @@
 #include <asm/uaccess.h>
 #include <asm/system.h>
 
-#include <linux/smp_lock.h>
 #include <linux/inet.h>
 #include <linux/igmp.h>
 #include <linux/inetdevice.h>

commit 5e0f04351d11e07a23b5ab4914282cbb78027e50
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Tue Apr 24 21:53:35 2007 -0700

    [IPV4]: Consolidate common SNMP code
    
    This patch moves the SNMP code shared between IPv4/IPv6 from proc.c
    into net/ipv4/af_inet.c.  This makes sense because these functions
    aren't specific to /proc.
    
    As a result we can again skip proc.o if /proc is disabled.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
    Acked-by: YOSHIFUJI Hideaki <yoshfuji@linux-ipv6.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index a33ca7e7e8f8..16aae8ef5555 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1219,6 +1219,46 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb, int features)
 	return segs;
 }
 
+unsigned long snmp_fold_field(void *mib[], int offt)
+{
+	unsigned long res = 0;
+	int i;
+
+	for_each_possible_cpu(i) {
+		res += *(((unsigned long *) per_cpu_ptr(mib[0], i)) + offt);
+		res += *(((unsigned long *) per_cpu_ptr(mib[1], i)) + offt);
+	}
+	return res;
+}
+EXPORT_SYMBOL_GPL(snmp_fold_field);
+
+int snmp_mib_init(void *ptr[2], size_t mibsize, size_t mibalign)
+{
+	BUG_ON(ptr == NULL);
+	ptr[0] = __alloc_percpu(mibsize);
+	if (!ptr[0])
+		goto err0;
+	ptr[1] = __alloc_percpu(mibsize);
+	if (!ptr[1])
+		goto err1;
+	return 0;
+err1:
+	free_percpu(ptr[0]);
+	ptr[0] = NULL;
+err0:
+	return -ENOMEM;
+}
+EXPORT_SYMBOL_GPL(snmp_mib_init);
+
+void snmp_mib_free(void *ptr[2])
+{
+	BUG_ON(ptr == NULL);
+	free_percpu(ptr[0]);
+	free_percpu(ptr[1]);
+	ptr[0] = ptr[1] = NULL;
+}
+EXPORT_SYMBOL_GPL(snmp_mib_free);
+
 #ifdef CONFIG_IP_MULTICAST
 static struct net_protocol igmp_protocol = {
 	.handler =	igmp_rcv,

commit 334901700f9f58993ebd7f6136d3f9062460d34d
Author: YOSHIFUJI Hideaki <yoshfuji@linux-ipv6.org>
Date:   Fri Apr 20 15:57:15 2007 -0700

    [IPV4] SNMP: Move some statistic bits to net/ipv4/proc.c.
    
    This also fixes memory leak in error path.
    
    Signed-off-by: YOSHIFUJI Hideaki <yoshfuji@linux-ipv6.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 45ced52c03d4..a33ca7e7e8f8 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1245,28 +1245,47 @@ static struct net_protocol icmp_protocol = {
 
 static int __init init_ipv4_mibs(void)
 {
-	net_statistics[0] = alloc_percpu(struct linux_mib);
-	net_statistics[1] = alloc_percpu(struct linux_mib);
-	ip_statistics[0] = alloc_percpu(struct ipstats_mib);
-	ip_statistics[1] = alloc_percpu(struct ipstats_mib);
-	icmp_statistics[0] = alloc_percpu(struct icmp_mib);
-	icmp_statistics[1] = alloc_percpu(struct icmp_mib);
-	tcp_statistics[0] = alloc_percpu(struct tcp_mib);
-	tcp_statistics[1] = alloc_percpu(struct tcp_mib);
-	udp_statistics[0] = alloc_percpu(struct udp_mib);
-	udp_statistics[1] = alloc_percpu(struct udp_mib);
-	udplite_statistics[0] = alloc_percpu(struct udp_mib);
-	udplite_statistics[1] = alloc_percpu(struct udp_mib);
-	if (!
-	    (net_statistics[0] && net_statistics[1] && ip_statistics[0]
-	     && ip_statistics[1] && tcp_statistics[0] && tcp_statistics[1]
-	     && udp_statistics[0] && udp_statistics[1]
-	     && udplite_statistics[0] && udplite_statistics[1]             ) )
-		return -ENOMEM;
-
-	(void) tcp_mib_init();
+	if (snmp_mib_init((void **)net_statistics,
+			  sizeof(struct linux_mib),
+			  __alignof__(struct linux_mib)) < 0)
+		goto err_net_mib;
+	if (snmp_mib_init((void **)ip_statistics,
+			  sizeof(struct ipstats_mib),
+			  __alignof__(struct ipstats_mib)) < 0)
+		goto err_ip_mib;
+	if (snmp_mib_init((void **)icmp_statistics,
+			  sizeof(struct icmp_mib),
+			  __alignof__(struct icmp_mib)) < 0)
+		goto err_icmp_mib;
+	if (snmp_mib_init((void **)tcp_statistics,
+			  sizeof(struct tcp_mib),
+			  __alignof__(struct tcp_mib)) < 0)
+		goto err_tcp_mib;
+	if (snmp_mib_init((void **)udp_statistics,
+			  sizeof(struct udp_mib),
+			  __alignof__(struct udp_mib)) < 0)
+		goto err_udp_mib;
+	if (snmp_mib_init((void **)udplite_statistics,
+			  sizeof(struct udp_mib),
+			  __alignof__(struct udp_mib)) < 0)
+		goto err_udplite_mib;
+
+	tcp_mib_init();
 
 	return 0;
+
+err_udplite_mib:
+	snmp_mib_free((void **)udp_statistics);
+err_udp_mib:
+	snmp_mib_free((void **)tcp_statistics);
+err_tcp_mib:
+	snmp_mib_free((void **)icmp_statistics);
+err_icmp_mib:
+	snmp_mib_free((void **)ip_statistics);
+err_ip_mib:
+	snmp_mib_free((void **)net_statistics);
+err_net_mib:
+	return -ENOMEM;
 }
 
 static int ipv4_proc_init(void);

commit be776281aee54626a474ba06f91926b98bdd180d
Author: Eric Dumazet <dada1@cosmosbay.com>
Date:   Tue Mar 27 13:53:04 2007 -0700

    [NET]: inet_ehash_secret should be __read_mostly and set only once
    
    There is a very tiny probability that build_ehash_secret() is called
    at the same time by different CPUS.
    
    Also, using __read_mostly is a must for inet_ehash_secret
    
    Signed-off-by: Eric Dumazet <dada1@cosmosbay.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index b7b7278d801c..45ced52c03d4 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -218,13 +218,23 @@ int inet_listen(struct socket *sock, int backlog)
 	return err;
 }
 
-u32 inet_ehash_secret;
+u32 inet_ehash_secret __read_mostly;
 EXPORT_SYMBOL(inet_ehash_secret);
 
+/*
+ * inet_ehash_secret must be set exactly once
+ * Instead of using a dedicated spinlock, we (ab)use inetsw_lock
+ */
 void build_ehash_secret(void)
 {
-	while (!inet_ehash_secret)
-		get_random_bytes(&inet_ehash_secret, 4);
+	u32 rnd;
+	do {
+		get_random_bytes(&rnd, sizeof(rnd));
+	} while (rnd == 0);
+	spin_lock_bh(&inetsw_lock);
+	if (!inet_ehash_secret)
+		inet_ehash_secret = rnd;
+	spin_unlock_bh(&inetsw_lock);
 }
 EXPORT_SYMBOL(build_ehash_secret);
 

commit b3da2cf37c5c6e47698957a25ab43a7223dbb90f
Author: David S. Miller <davem@davemloft.net>
Date:   Fri Mar 23 11:40:27 2007 -0700

    [INET]: Use jhash + random secret for ehash.
    
    The days are gone when this was not an issue, there are folks out
    there with huge bot networks that can be used to attack the
    established hash tables on remote systems.
    
    So just like the routing cache and connection tracking
    hash, use Jenkins hash with random secret input.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index f011390f19c9..b7b7278d801c 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -87,6 +87,7 @@
 #include <linux/init.h>
 #include <linux/poll.h>
 #include <linux/netfilter_ipv4.h>
+#include <linux/random.h>
 
 #include <asm/uaccess.h>
 #include <asm/system.h>
@@ -217,6 +218,16 @@ int inet_listen(struct socket *sock, int backlog)
 	return err;
 }
 
+u32 inet_ehash_secret;
+EXPORT_SYMBOL(inet_ehash_secret);
+
+void build_ehash_secret(void)
+{
+	while (!inet_ehash_secret)
+		get_random_bytes(&inet_ehash_secret, 4);
+}
+EXPORT_SYMBOL(build_ehash_secret);
+
 /*
  *	Create an inet socket.
  */
@@ -233,6 +244,11 @@ static int inet_create(struct socket *sock, int protocol)
 	int try_loading_module = 0;
 	int err;
 
+	if (sock->type != SOCK_RAW &&
+	    sock->type != SOCK_DGRAM &&
+	    !inet_ehash_secret)
+		build_ehash_secret();
+
 	sock->state = SS_UNCONNECTED;
 
 	/* Look for the requested type/protocol pair. */

commit badff6d01a8589a1c828b0bf118903ca38627f4e
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Tue Mar 13 13:06:52 2007 -0300

    [SK_BUFF]: Introduce skb_reset_transport_header(skb)
    
    For the common, open coded 'skb->h.raw = skb->data' operation, so that we can
    later turn skb->h.raw into a offset, reducing the size of struct sk_buff in
    64bit land while possibly keeping it as a pointer on 32bit.
    
    This one touches just the most simple cases:
    
    skb->h.raw = skb->data;
    skb->h.raw = {skb_push|[__]skb_pull}()
    
    The next ones will handle the slightly more "complex" cases.
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index e7720c72a6e2..f011390f19c9 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1120,7 +1120,8 @@ static int inet_gso_send_check(struct sk_buff *skb)
 	if (unlikely(!pskb_may_pull(skb, ihl)))
 		goto out;
 
-	skb->h.raw = __skb_pull(skb, ihl);
+	__skb_pull(skb, ihl);
+	skb_reset_transport_header(skb);
 	iph = ip_hdr(skb);
 	proto = iph->protocol & (MAX_INET_PROTOS - 1);
 	err = -EPROTONOSUPPORT;
@@ -1163,7 +1164,8 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb, int features)
 	if (unlikely(!pskb_may_pull(skb, ihl)))
 		goto out;
 
-	skb->h.raw = __skb_pull(skb, ihl);
+	__skb_pull(skb, ihl);
+	skb_reset_transport_header(skb);
 	iph = ip_hdr(skb);
 	id = ntohs(iph->id);
 	proto = iph->protocol & (MAX_INET_PROTOS - 1);

commit eddc9ec53be2ecdbf4efe0efd4a83052594f0ac0
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Fri Apr 20 22:47:35 2007 -0700

    [SK_BUFF]: Introduce ip_hdr(), remove skb->nh.iph
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index ab552a6098f9..e7720c72a6e2 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1112,7 +1112,7 @@ static int inet_gso_send_check(struct sk_buff *skb)
 	if (unlikely(!pskb_may_pull(skb, sizeof(*iph))))
 		goto out;
 
-	iph = skb->nh.iph;
+	iph = ip_hdr(skb);
 	ihl = iph->ihl * 4;
 	if (ihl < sizeof(*iph))
 		goto out;
@@ -1121,7 +1121,7 @@ static int inet_gso_send_check(struct sk_buff *skb)
 		goto out;
 
 	skb->h.raw = __skb_pull(skb, ihl);
-	iph = skb->nh.iph;
+	iph = ip_hdr(skb);
 	proto = iph->protocol & (MAX_INET_PROTOS - 1);
 	err = -EPROTONOSUPPORT;
 
@@ -1155,7 +1155,7 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb, int features)
 	if (unlikely(!pskb_may_pull(skb, sizeof(*iph))))
 		goto out;
 
-	iph = skb->nh.iph;
+	iph = ip_hdr(skb);
 	ihl = iph->ihl * 4;
 	if (ihl < sizeof(*iph))
 		goto out;
@@ -1164,7 +1164,7 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb, int features)
 		goto out;
 
 	skb->h.raw = __skb_pull(skb, ihl);
-	iph = skb->nh.iph;
+	iph = ip_hdr(skb);
 	id = ntohs(iph->id);
 	proto = iph->protocol & (MAX_INET_PROTOS - 1);
 	segs = ERR_PTR(-EPROTONOSUPPORT);
@@ -1180,7 +1180,7 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb, int features)
 
 	skb = segs;
 	do {
-		iph = skb->nh.iph;
+		iph = ip_hdr(skb);
 		iph->id = htons(id++);
 		iph->tot_len = htons(skb->len - skb->mac_len);
 		iph->check = 0;

commit d56f90a7c96da5187f0cdf07ee7434fe6aa78bbc
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Tue Apr 10 20:50:43 2007 -0700

    [SK_BUFF]: Introduce skb_network_header()
    
    For the places where we need a pointer to the network header, it is still legal
    to touch skb->nh.raw directly if just adding to, subtracting from or setting it
    to another layer header.
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 6e5575b0abef..ab552a6098f9 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1184,7 +1184,7 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb, int features)
 		iph->id = htons(id++);
 		iph->tot_len = htons(skb->len - skb->mac_len);
 		iph->check = 0;
-		iph->check = ip_fast_csum(skb->nh.raw, iph->ihl);
+		iph->check = ip_fast_csum(skb_network_header(skb), iph->ihl);
 	} while ((skb = skb->next));
 
 out:

commit 132adf54639cf7dd9315e8df89c2faa59f6e46d9
Author: Stephen Hemminger <shemminger@linux-foundation.org>
Date:   Thu Mar 8 20:44:43 2007 -0800

    [IPV4]: cleanup
    
    Add whitespace around keywords.
    
    Signed-off-by: Stephen Hemminger <shemminger@linux-foundation.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index df41856fc603..6e5575b0abef 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1339,7 +1339,7 @@ static int __init inet_init(void)
 	 *	Initialise per-cpu ipv4 mibs
 	 */
 
-	if(init_ipv4_mibs())
+	if (init_ipv4_mibs())
 		printk(KERN_CRIT "inet_init: Cannot init ipv4 mibs\n"); ;
 
 	ipv4_proc_init();

commit ae40eb1ef30ab4120bd3c8b7e3da99ee53d27a23
Author: Eric Dumazet <dada1@cosmosbay.com>
Date:   Sun Mar 18 17:33:16 2007 -0700

    [NET]: Introduce SIOCGSTAMPNS ioctl to get timestamps with nanosec resolution
    
    Now network timestamps use ktime_t infrastructure, we can add a new
    ioctl() SIOCGSTAMPNS command to get timestamps in 'struct timespec'.
    User programs can thus access to nanosecond resolution.
    
    Signed-off-by: Eric Dumazet <dada1@cosmosbay.com>
    CC: Stephen Hemminger <shemminger@linux-foundation.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index cf358c84c440..df41856fc603 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -755,6 +755,9 @@ int inet_ioctl(struct socket *sock, unsigned int cmd, unsigned long arg)
 		case SIOCGSTAMP:
 			err = sock_get_timestamp(sk, (struct timeval __user *)arg);
 			break;
+		case SIOCGSTAMPNS:
+			err = sock_get_timestampns(sk, (struct timespec __user *)arg);
+			break;
 		case SIOCADDRT:
 		case SIOCDELRT:
 		case SIOCRTMSG:

commit e905a9edab7f4f14f9213b52234e4a346c690911
Author: YOSHIFUJI Hideaki <yoshfuji@linux-ipv6.org>
Date:   Fri Feb 9 23:24:47 2007 +0900

    [NET] IPV4: Fix whitespace errors.
    
    Signed-off-by: YOSHIFUJI Hideaki <yoshfuji@linux-ipv6.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 5750a2b2a0d6..cf358c84c440 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -550,7 +550,7 @@ int inet_stream_connect(struct socket *sock, struct sockaddr *uaddr,
 		if (err < 0)
 			goto out;
 
-  		sock->state = SS_CONNECTING;
+		sock->state = SS_CONNECTING;
 
 		/* Just entered SS_CONNECTING state; the only
 		 * difference is that return value in non-blocking
@@ -878,36 +878,36 @@ static struct net_proto_family inet_family_ops = {
  */
 static struct inet_protosw inetsw_array[] =
 {
-        {
-                .type =       SOCK_STREAM,
-                .protocol =   IPPROTO_TCP,
-                .prot =       &tcp_prot,
-                .ops =        &inet_stream_ops,
-                .capability = -1,
-                .no_check =   0,
-                .flags =      INET_PROTOSW_PERMANENT |
+	{
+		.type =       SOCK_STREAM,
+		.protocol =   IPPROTO_TCP,
+		.prot =       &tcp_prot,
+		.ops =        &inet_stream_ops,
+		.capability = -1,
+		.no_check =   0,
+		.flags =      INET_PROTOSW_PERMANENT |
 			      INET_PROTOSW_ICSK,
-        },
-
-        {
-                .type =       SOCK_DGRAM,
-                .protocol =   IPPROTO_UDP,
-                .prot =       &udp_prot,
-                .ops =        &inet_dgram_ops,
-                .capability = -1,
-                .no_check =   UDP_CSUM_DEFAULT,
-                .flags =      INET_PROTOSW_PERMANENT,
+	},
+
+	{
+		.type =       SOCK_DGRAM,
+		.protocol =   IPPROTO_UDP,
+		.prot =       &udp_prot,
+		.ops =        &inet_dgram_ops,
+		.capability = -1,
+		.no_check =   UDP_CSUM_DEFAULT,
+		.flags =      INET_PROTOSW_PERMANENT,
        },
-        
+
 
        {
-               .type =       SOCK_RAW,
-               .protocol =   IPPROTO_IP,	/* wild card */
-               .prot =       &raw_prot,
-               .ops =        &inet_sockraw_ops,
-               .capability = CAP_NET_RAW,
-               .no_check =   UDP_CSUM_DEFAULT,
-               .flags =      INET_PROTOSW_REUSE,
+	       .type =       SOCK_RAW,
+	       .protocol =   IPPROTO_IP,	/* wild card */
+	       .prot =       &raw_prot,
+	       .ops =        &inet_sockraw_ops,
+	       .capability = CAP_NET_RAW,
+	       .no_check =   UDP_CSUM_DEFAULT,
+	       .flags =      INET_PROTOSW_REUSE,
        }
 };
 
@@ -946,7 +946,7 @@ void inet_register_protosw(struct inet_protosw *p)
 	/* Add the new entry after the last permanent entry if any, so that
 	 * the new entry does not override a permanent entry when matched with
 	 * a wild-card protocol. But it is allowed to override any existing
-	 * non-permanent entry.  This means that when we remove this entry, the 
+	 * non-permanent entry.  This means that when we remove this entry, the
 	 * system automatically returns to the old behavior.
 	 */
 	list_add_rcu(&p->list, last_perm);
@@ -1073,7 +1073,7 @@ int inet_sk_rebuild_header(struct sock *sk)
 			},
 		},
 	};
-						
+
 	security_sk_classify_flow(sk, &fl);
 	err = ip_route_output_flow(&rt, &fl, sk, 0);
 }
@@ -1273,10 +1273,10 @@ static int __init inet_init(void)
 		goto out_unregister_udp_proto;
 
 	/*
-	 *	Tell SOCKET that we are alive... 
+	 *	Tell SOCKET that we are alive...
 	 */
 
-  	(void)sock_register(&inet_family_ops);
+	(void)sock_register(&inet_family_ops);
 
 	/*
 	 *	Add all the base protocols.
@@ -1306,9 +1306,9 @@ static int __init inet_init(void)
 
 	arp_init();
 
-  	/*
-  	 *	Set the IP module up
-  	 */
+	/*
+	 *	Set the IP module up
+	 */
 
 	ip_init();
 
@@ -1334,11 +1334,11 @@ static int __init inet_init(void)
 #endif
 	/*
 	 *	Initialise per-cpu ipv4 mibs
-	 */ 
+	 */
 
 	if(init_ipv4_mibs())
 		printk(KERN_CRIT "inet_init: Cannot init ipv4 mibs\n"); ;
-	
+
 	ipv4_proc_init();
 
 	ipfrag_init();

commit 8eb9086f21c73b38b5ca27558db4c91d62d0e70b
Author: David S. Miller <davem@sunset.davemloft.net>
Date:   Thu Feb 8 02:09:21 2007 -0800

    [IPV4/IPV6]: Always wait for IPSEC SA resolution in socket contexts.
    
    Do this even for non-blocking sockets.  This avoids the silly -EAGAIN
    that applications can see now, even for non-blocking sockets in some
    cases (f.e. connect()).
    
    With help from Venkat Tekkirala.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 864009643675..5750a2b2a0d6 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1007,7 +1007,7 @@ static int inet_sk_reselect_saddr(struct sock *sk)
 			       RT_CONN_FLAGS(sk),
 			       sk->sk_bound_dev_if,
 			       sk->sk_protocol,
-			       inet->sport, inet->dport, sk);
+			       inet->sport, inet->dport, sk, 0);
 	if (err)
 		return err;
 

commit 469de9b90f739f130ab3d483e819888e977596b8
Author: Paul Moore <paul.moore@hp.com>
Date:   Tue Jan 9 14:37:06 2007 -0800

    [INET]: style updates for the inet_sock->is_icsk assignment fix
    
    A quick patch to change the inet_sock->is_icsk assignment to better fit with
    existing kernel coding style.
    
    Signed-off-by: Paul Moore <paul.moore@hp.com>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@ghostprotocols.net>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index d60fd7321e63..864009643675 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -305,7 +305,7 @@ static int inet_create(struct socket *sock, int protocol)
 		sk->sk_reuse = 1;
 
 	inet = inet_sk(sk);
-	inet->is_icsk = (INET_PROTOSW_ICSK & answer_flags) == INET_PROTOSW_ICSK;
+	inet->is_icsk = (INET_PROTOSW_ICSK & answer_flags) != 0;
 
 	if (SOCK_RAW == sock->type) {
 		inet->num = protocol;

commit cbbd7d4f36a61631f8c0d73be43df985d1e7d6a6
Author: Paul Moore <paul.moore@hp.com>
Date:   Thu Jan 4 16:56:46 2007 -0800

    [INET]: Fix incorrect "inet_sock->is_icsk" assignment.
    
    The inet_create() and inet6_create() functions incorrectly set the
    inet_sock->is_icsk field.  Both functions assume that the is_icsk field is
    large enough to hold at least a INET_PROTOSW_ICSK value when it is actually
    only a single bit.  This patch corrects the assignment by doing a boolean
    comparison whose result will safely fit into a single bit field.
    
    Signed-off-by: Paul Moore <paul.moore@hp.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 1144900d37f6..d60fd7321e63 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -305,7 +305,7 @@ static int inet_create(struct socket *sock, int protocol)
 		sk->sk_reuse = 1;
 
 	inet = inet_sk(sk);
-	inet->is_icsk = INET_PROTOSW_ICSK & answer_flags;
+	inet->is_icsk = (INET_PROTOSW_ICSK & answer_flags) == INET_PROTOSW_ICSK;
 
 	if (SOCK_RAW == sock->type) {
 		inet->num = protocol;

commit 714e85be3557222bc25f69c252326207c900a7db
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Tue Nov 14 20:51:49 2006 -0800

    [IPV6]: Assorted trivial endianness annotations.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 8db39f7e3bf0..1144900d37f6 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -644,7 +644,7 @@ int inet_getname(struct socket *sock, struct sockaddr *uaddr,
 		sin->sin_port = inet->dport;
 		sin->sin_addr.s_addr = inet->daddr;
 	} else {
-		__u32 addr = inet->rcv_saddr;
+		__be32 addr = inet->rcv_saddr;
 		if (!addr)
 			addr = inet->saddr;
 		sin->sin_port = inet->sport;
@@ -995,8 +995,8 @@ static int inet_sk_reselect_saddr(struct sock *sk)
 	struct inet_sock *inet = inet_sk(sk);
 	int err;
 	struct rtable *rt;
-	__u32 old_saddr = inet->saddr;
-	__u32 new_saddr;
+	__be32 old_saddr = inet->saddr;
+	__be32 new_saddr;
 	__be32 daddr = inet->daddr;
 
 	if (inet->opt && inet->opt->srr)

commit ba4e58eca8aa9473b44fdfd312f26c4a2e7798b3
Author: Gerrit Renker <gerrit@erg.abdn.ac.uk>
Date:   Mon Nov 27 11:10:57 2006 -0800

    [NET]: Supporting UDP-Lite (RFC 3828) in Linux
    
    This is a revision of the previously submitted patch, which alters
    the way files are organized and compiled in the following manner:
    
            * UDP and UDP-Lite now use separate object files
            * source file dependencies resolved via header files
              net/ipv{4,6}/udp_impl.h
            * order of inclusion files in udp.c/udplite.c adapted
              accordingly
    
    [NET/IPv4]: Support for the UDP-Lite protocol (RFC 3828)
    
    This patch adds support for UDP-Lite to the IPv4 stack, provided as an
    extension to the existing UDPv4 code:
            * generic routines are all located in net/ipv4/udp.c
            * UDP-Lite specific routines are in net/ipv4/udplite.c
            * MIB/statistics support in /proc/net/snmp and /proc/net/udplite
            * shared API with extensions for partial checksum coverage
    
    [NET/IPv6]: Extension for UDP-Lite over IPv6
    
    It extends the existing UDPv6 code base with support for UDP-Lite
    in the same manner as per UDPv4. In particular,
            * UDPv6 generic and shared code is in net/ipv6/udp.c
            * UDP-Litev6 specific extensions are in net/ipv6/udplite.c
            * MIB/statistics support in /proc/net/snmp6 and /proc/net/udplite6
            * support for IPV6_ADDRFORM
            * aligned the coding style of protocol initialisation with af_inet6.c
            * made the error handling in udpv6_queue_rcv_skb consistent;
              to return `-1' on error on all error cases
            * consolidation of shared code
    
    [NET]: UDP-Lite Documentation and basic XFRM/Netfilter support
    
    The UDP-Lite patch further provides
            * API documentation for UDP-Lite
            * basic xfrm support
            * basic netfilter support for IPv4 and IPv6 (LOG target)
    
    Signed-off-by: Gerrit Renker <gerrit@erg.abdn.ac.uk>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 4a81d54a7569..8db39f7e3bf0 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -104,6 +104,7 @@
 #include <net/inet_connection_sock.h>
 #include <net/tcp.h>
 #include <net/udp.h>
+#include <net/udplite.h>
 #include <linux/skbuff.h>
 #include <net/sock.h>
 #include <net/raw.h>
@@ -1223,10 +1224,13 @@ static int __init init_ipv4_mibs(void)
 	tcp_statistics[1] = alloc_percpu(struct tcp_mib);
 	udp_statistics[0] = alloc_percpu(struct udp_mib);
 	udp_statistics[1] = alloc_percpu(struct udp_mib);
+	udplite_statistics[0] = alloc_percpu(struct udp_mib);
+	udplite_statistics[1] = alloc_percpu(struct udp_mib);
 	if (!
 	    (net_statistics[0] && net_statistics[1] && ip_statistics[0]
 	     && ip_statistics[1] && tcp_statistics[0] && tcp_statistics[1]
-	     && udp_statistics[0] && udp_statistics[1]))
+	     && udp_statistics[0] && udp_statistics[1]
+	     && udplite_statistics[0] && udplite_statistics[1]             ) )
 		return -ENOMEM;
 
 	(void) tcp_mib_init();
@@ -1313,6 +1317,8 @@ static int __init inet_init(void)
 	/* Setup TCP slab cache for open requests. */
 	tcp_init();
 
+	/* Add UDP-Lite (RFC 3828) */
+	udplite4_register();
 
 	/*
 	 *	Set the ICMP layer up

commit 72a3effaf633bcae9034b7e176bdbd78d64a71db
Author: Eric Dumazet <dada1@cosmosbay.com>
Date:   Thu Nov 16 02:30:37 2006 -0800

    [NET]: Size listen hash tables using backlog hint
    
    We currently allocate a fixed size (TCP_SYNQ_HSIZE=512) slots hash table for
    each LISTEN socket, regardless of various parameters (listen backlog for
    example)
    
    On x86_64, this means order-1 allocations (might fail), even for 'small'
    sockets, expecting few connections. On the contrary, a huge server wanting a
    backlog of 50000 is slowed down a bit because of this fixed limit.
    
    This patch makes the sizing of listen hash table a dynamic parameter,
    depending of :
    - net.core.somaxconn tunable (default is 128)
    - net.ipv4.tcp_max_syn_backlog tunable (default : 256, 1024 or 128)
    - backlog value given by user application  (2nd parameter of listen())
    
    For large allocations (bigger than PAGE_SIZE), we use vmalloc() instead of
    kmalloc().
    
    We still limit memory allocation with the two existing tunables (somaxconn &
    tcp_max_syn_backlog). So for standard setups, this patch actually reduce RAM
    usage.
    
    Signed-off-by: Eric Dumazet <dada1@cosmosbay.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index edcf0932ac6d..4a81d54a7569 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -204,7 +204,7 @@ int inet_listen(struct socket *sock, int backlog)
 	 * we can only allow the backlog to be adjusted.
 	 */
 	if (old_state != TCP_LISTEN) {
-		err = inet_csk_listen_start(sk, TCP_SYNQ_HSIZE);
+		err = inet_csk_listen_start(sk, backlog);
 		if (err)
 			goto out;
 	}

commit 3ca3c68e76686bee058937ade2b96f4de58ee434
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Wed Sep 27 18:28:07 2006 -0700

    [IPV4]: struct ip_options annotations
    
    ->faddr is net-endian; annotated as such, variables inferred to be net-endian
    annotated.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index ea5844832683..edcf0932ac6d 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1043,7 +1043,7 @@ int inet_sk_rebuild_header(struct sock *sk)
 {
 	struct inet_sock *inet = inet_sk(sk);
 	struct rtable *rt = (struct rtable *)__sk_dst_check(sk, 0);
-	u32 daddr;
+	__be32 daddr;
 	int err;
 
 	/* Route is OK, nothing to do. */

commit 321efff7c3b7a26fa0522cb12b2af2ac82c05f1e
Author: Olaf Kirch <okir@suse.de>
Date:   Wed Sep 27 16:33:45 2006 -0700

    [IPV4]: Fix order in inet_init failure path.
    
    This is just a minor buglet I came across by accident - when inet_init
    fails to register raw_prot, it jumps to out_unregister_udp_proto which
    should unregister UDP _and_ TCP.
    
    Signed-off-by: Olaf Kirch <okir@suse.de>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 250a02b23e4e..ea5844832683 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1342,10 +1342,10 @@ static int __init inet_init(void)
 	rc = 0;
 out:
 	return rc;
-out_unregister_tcp_proto:
-	proto_unregister(&tcp_prot);
 out_unregister_udp_proto:
 	proto_unregister(&udp_prot);
+out_unregister_tcp_proto:
+	proto_unregister(&tcp_prot);
 	goto out;
 }
 

commit bada8adc4e6622764205921e6ba3f717aa03c882
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Tue Sep 26 21:27:15 2006 -0700

    [IPV4]: ip_route_connect() ipv4 address arguments annotated
    
    annotated address arguments (port number left alone for now); ditto
    for inferred net-endian variables in callers.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index fdd89e37b9aa..250a02b23e4e 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -996,7 +996,7 @@ static int inet_sk_reselect_saddr(struct sock *sk)
 	struct rtable *rt;
 	__u32 old_saddr = inet->saddr;
 	__u32 new_saddr;
-	__u32 daddr = inet->daddr;
+	__be32 daddr = inet->daddr;
 
 	if (inet->opt && inet->opt->srr)
 		daddr = inet->opt->faddr;

commit ef047f5e1085d6393748d1ee27d6327905f098dc
Author: YOSHIFUJI Hideaki <yoshfuji@linux-ipv6.org>
Date:   Fri Sep 1 00:29:06 2006 -0700

    [NET]: Use BUILD_BUG_ON() for checking size of skb->cb.
    
    Signed-off-by: YOSHIFUJI Hideaki <yoshfuji@linux-ipv6.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index f2e8927f4596..fdd89e37b9aa 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1254,10 +1254,7 @@ static int __init inet_init(void)
 	struct list_head *r;
 	int rc = -EINVAL;
 
-	if (sizeof(struct inet_skb_parm) > sizeof(dummy_skb->cb)) {
-		printk(KERN_CRIT "%s: panic\n", __FUNCTION__);
-		goto out;
-	}
+	BUILD_BUG_ON(sizeof(struct inet_skb_parm) > sizeof(dummy_skb->cb));
 
 	rc = proto_register(&tcp_prot, 1);
 	if (rc)

commit ab32ea5d8a760e7dd4339634e95d7be24ee5b842
Author: Brian Haley <brian.haley@hp.com>
Date:   Fri Sep 22 14:15:41 2006 -0700

    [NET/IPV4/IPV6]: Change some sysctl variables to __read_mostly
    
    Change net/core, ipv4 and ipv6 sysctl variables to __read_mostly.
    
    Couldn't actually measure any performance increase while testing (.3%
    I consider noise), but seems like the right thing to do.
    
    Signed-off-by: Brian Haley <brian.haley@hp.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 36c38bffb474..f2e8927f4596 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -391,7 +391,7 @@ int inet_release(struct socket *sock)
 }
 
 /* It is off by default, see below. */
-int sysctl_ip_nonlocal_bind;
+int sysctl_ip_nonlocal_bind __read_mostly;
 
 int inet_bind(struct socket *sock, struct sockaddr *uaddr, int addr_len)
 {
@@ -987,7 +987,7 @@ void inet_unregister_protosw(struct inet_protosw *p)
  *      Shall we try to damage output packets if routing dev changes?
  */
 
-int sysctl_ip_dynaddr;
+int sysctl_ip_dynaddr __read_mostly;
 
 static int inet_sk_reselect_saddr(struct sock *sk)
 {

commit bf0d52492d82ad70684e17c8a46942c13d0e140e
Author: Dave Jones <davej@redhat.com>
Date:   Fri Sep 22 14:00:29 2006 -0700

    [NET]: Remove unnecessary config.h includes from net/
    
    config.h is automatically included by kbuild these days.
    
    Signed-off-by: Dave Jones <davej@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index fc40da3b6d39..36c38bffb474 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -67,7 +67,6 @@
  *		2 of the License, or (at your option) any later version.
  */
 
-#include <linux/config.h>
 #include <linux/err.h>
 #include <linux/errno.h>
 #include <linux/types.h>

commit beb8d13bed80f8388f1a9a107d07ddd342e627e8
Author: Venkat Yekkirala <vyekkirala@TrustedCS.com>
Date:   Fri Aug 4 23:12:42 2006 -0700

    [MLSXFRM]: Add flow labeling
    
    This labels the flows that could utilize IPSec xfrms at the points the
    flows are defined so that IPSec policy and SAs at the right label can
    be used.
    
    The following protos are currently not handled, but they should
    continue to be able to use single-labeled IPSec like they currently
    do.
    
    ipmr
    ip_gre
    ipip
    igmp
    sit
    sctp
    ip6_tunnel (IPv6 over IPv6 tunnel device)
    decnet
    
    Signed-off-by: Venkat Yekkirala <vyekkirala@TrustedCS.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index c84a32070f8d..fc40da3b6d39 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1074,6 +1074,7 @@ int inet_sk_rebuild_header(struct sock *sk)
 		},
 	};
 						
+	security_sk_classify_flow(sk, &fl);
 	err = ip_route_output_flow(&rt, &fl, sk, 0);
 }
 	if (!err)

commit a430a43d087545c96542ee64573237919109d370
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Sat Jul 8 13:34:56 2006 -0700

    [NET] gso: Fix up GSO packets with broken checksums
    
    Certain subsystems in the stack (e.g., netfilter) can break the partial
    checksum on GSO packets.  Until they're fixed, this patch allows this to
    work by recomputing the partial checksums through the GSO mechanism.
    
    Once they've all been converted to update the partial checksum instead of
    clearing it, this workaround can be removed.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 318d4674faa1..c84a32070f8d 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1097,6 +1097,40 @@ int inet_sk_rebuild_header(struct sock *sk)
 
 EXPORT_SYMBOL(inet_sk_rebuild_header);
 
+static int inet_gso_send_check(struct sk_buff *skb)
+{
+	struct iphdr *iph;
+	struct net_protocol *ops;
+	int proto;
+	int ihl;
+	int err = -EINVAL;
+
+	if (unlikely(!pskb_may_pull(skb, sizeof(*iph))))
+		goto out;
+
+	iph = skb->nh.iph;
+	ihl = iph->ihl * 4;
+	if (ihl < sizeof(*iph))
+		goto out;
+
+	if (unlikely(!pskb_may_pull(skb, ihl)))
+		goto out;
+
+	skb->h.raw = __skb_pull(skb, ihl);
+	iph = skb->nh.iph;
+	proto = iph->protocol & (MAX_INET_PROTOS - 1);
+	err = -EPROTONOSUPPORT;
+
+	rcu_read_lock();
+	ops = rcu_dereference(inet_protos[proto]);
+	if (likely(ops && ops->gso_send_check))
+		err = ops->gso_send_check(skb);
+	rcu_read_unlock();
+
+out:
+	return err;
+}
+
 static struct sk_buff *inet_gso_segment(struct sk_buff *skb, int features)
 {
 	struct sk_buff *segs = ERR_PTR(-EINVAL);
@@ -1162,6 +1196,7 @@ static struct net_protocol igmp_protocol = {
 static struct net_protocol tcp_protocol = {
 	.handler =	tcp_v4_rcv,
 	.err_handler =	tcp_v4_err,
+	.gso_send_check = tcp_v4_gso_send_check,
 	.gso_segment =	tcp_tso_segment,
 	.no_policy =	1,
 };
@@ -1208,6 +1243,7 @@ static int ipv4_proc_init(void);
 static struct packet_type ip_packet_type = {
 	.type = __constant_htons(ETH_P_IP),
 	.func = ip_rcv,
+	.gso_send_check = inet_gso_send_check,
 	.gso_segment = inet_gso_segment,
 };
 

commit bbcf467dab42ea3c85f368df346c82af2fbba665
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Mon Jul 3 19:38:35 2006 -0700

    [NET]: Verify gso_type too in gso_segment
    
    We don't want nasty Xen guests to pass a TCPv6 packet in with gso_type set
    to TCPv4 or even UDP (or a packet that's both TCP and UDP).
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 8d157157bf8e..318d4674faa1 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1106,7 +1106,15 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb, int features)
 	int ihl;
 	int id;
 
-	if (!pskb_may_pull(skb, sizeof(*iph)))
+	if (unlikely(skb_shinfo(skb)->gso_type &
+		     ~(SKB_GSO_TCPV4 |
+		       SKB_GSO_UDP |
+		       SKB_GSO_DODGY |
+		       SKB_GSO_TCP_ECN |
+		       0)))
+		goto out;
+
+	if (unlikely(!pskb_may_pull(skb, sizeof(*iph))))
 		goto out;
 
 	iph = skb->nh.iph;
@@ -1114,7 +1122,7 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb, int features)
 	if (ihl < sizeof(*iph))
 		goto out;
 
-	if (!pskb_may_pull(skb, ihl))
+	if (unlikely(!pskb_may_pull(skb, ihl)))
 		goto out;
 
 	skb->h.raw = __skb_pull(skb, ihl);
@@ -1125,7 +1133,7 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb, int features)
 
 	rcu_read_lock();
 	ops = rcu_dereference(inet_protos[proto]);
-	if (ops && ops->gso_segment)
+	if (likely(ops && ops->gso_segment))
 		segs = ops->gso_segment(skb, features);
 	rcu_read_unlock();
 

commit 576a30eb6453439b3c37ba24455ac7090c247b5a
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Tue Jun 27 13:22:38 2006 -0700

    [NET]: Added GSO header verification
    
    When GSO packets come from an untrusted source (e.g., a Xen guest domain),
    we need to verify the header integrity before passing it to the hardware.
    
    Since the first step in GSO is to verify the header, we can reuse that
    code by adding a new bit to gso_type: SKB_GSO_DODGY.  Packets with this
    bit set can only be fed directly to devices with the corresponding bit
    NETIF_F_GSO_ROBUST.  If the device doesn't have that bit, then the skb
    is fed to the GSO engine which will allow the packet to be sent to the
    hardware if it passes the header check.
    
    This patch changes the sg flag to a full features flag.  The same method
    can be used to implement TSO ECN support.  We simply have to mark packets
    with CWR set with SKB_GSO_ECN so that only hardware with a corresponding
    NETIF_F_TSO_ECN can accept them.  The GSO engine can either fully segment
    the packet, or segment the first MTU and pass the rest to the hardware for
    further segmentation.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 461216b47948..8d157157bf8e 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1097,7 +1097,7 @@ int inet_sk_rebuild_header(struct sock *sk)
 
 EXPORT_SYMBOL(inet_sk_rebuild_header);
 
-static struct sk_buff *inet_gso_segment(struct sk_buff *skb, int sg)
+static struct sk_buff *inet_gso_segment(struct sk_buff *skb, int features)
 {
 	struct sk_buff *segs = ERR_PTR(-EINVAL);
 	struct iphdr *iph;
@@ -1126,10 +1126,10 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb, int sg)
 	rcu_read_lock();
 	ops = rcu_dereference(inet_protos[proto]);
 	if (ops && ops->gso_segment)
-		segs = ops->gso_segment(skb, sg);
+		segs = ops->gso_segment(skb, features);
 	rcu_read_unlock();
 
-	if (IS_ERR(segs))
+	if (!segs || unlikely(IS_ERR(segs)))
 		goto out;
 
 	skb = segs;

commit f4c50d990dcf11a296679dc05de3873783236711
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Thu Jun 22 03:02:40 2006 -0700

    [NET]: Add software TSOv4
    
    This patch adds the GSO implementation for IPv4 TCP.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 0a277453526b..461216b47948 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -68,6 +68,7 @@
  */
 
 #include <linux/config.h>
+#include <linux/err.h>
 #include <linux/errno.h>
 #include <linux/types.h>
 #include <linux/socket.h>
@@ -1096,6 +1097,54 @@ int inet_sk_rebuild_header(struct sock *sk)
 
 EXPORT_SYMBOL(inet_sk_rebuild_header);
 
+static struct sk_buff *inet_gso_segment(struct sk_buff *skb, int sg)
+{
+	struct sk_buff *segs = ERR_PTR(-EINVAL);
+	struct iphdr *iph;
+	struct net_protocol *ops;
+	int proto;
+	int ihl;
+	int id;
+
+	if (!pskb_may_pull(skb, sizeof(*iph)))
+		goto out;
+
+	iph = skb->nh.iph;
+	ihl = iph->ihl * 4;
+	if (ihl < sizeof(*iph))
+		goto out;
+
+	if (!pskb_may_pull(skb, ihl))
+		goto out;
+
+	skb->h.raw = __skb_pull(skb, ihl);
+	iph = skb->nh.iph;
+	id = ntohs(iph->id);
+	proto = iph->protocol & (MAX_INET_PROTOS - 1);
+	segs = ERR_PTR(-EPROTONOSUPPORT);
+
+	rcu_read_lock();
+	ops = rcu_dereference(inet_protos[proto]);
+	if (ops && ops->gso_segment)
+		segs = ops->gso_segment(skb, sg);
+	rcu_read_unlock();
+
+	if (IS_ERR(segs))
+		goto out;
+
+	skb = segs;
+	do {
+		iph = skb->nh.iph;
+		iph->id = htons(id++);
+		iph->tot_len = htons(skb->len - skb->mac_len);
+		iph->check = 0;
+		iph->check = ip_fast_csum(skb->nh.raw, iph->ihl);
+	} while ((skb = skb->next));
+
+out:
+	return segs;
+}
+
 #ifdef CONFIG_IP_MULTICAST
 static struct net_protocol igmp_protocol = {
 	.handler =	igmp_rcv,
@@ -1105,6 +1154,7 @@ static struct net_protocol igmp_protocol = {
 static struct net_protocol tcp_protocol = {
 	.handler =	tcp_v4_rcv,
 	.err_handler =	tcp_v4_err,
+	.gso_segment =	tcp_tso_segment,
 	.no_policy =	1,
 };
 
@@ -1150,6 +1200,7 @@ static int ipv4_proc_init(void);
 static struct packet_type ip_packet_type = {
 	.type = __constant_htons(ETH_P_IP),
 	.func = ip_rcv,
+	.gso_segment = inet_gso_segment,
 };
 
 static int __init inet_init(void)

commit a536e0778781c1f2ce38cf8e1d82ce258f0193c1
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Fri Apr 28 15:19:17 2006 -0700

    [IPV4]: inet_init() -> fs_initcall
    
    Convert inet_init to an fs_initcall to make sure its called before any
    device driver's initcall.
    
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index dc206f1f914f..0a277453526b 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1257,7 +1257,7 @@ static int __init inet_init(void)
 	goto out;
 }
 
-module_init(inet_init);
+fs_initcall(inet_init);
 
 /* ------------------------------------------------------------------------ */
 

commit 543d9cfeec4d58ad3fd974db5531b06b6b95deb4
Author: Arnaldo Carvalho de Melo <acme@mandriva.com>
Date:   Mon Mar 20 22:48:35 2006 -0800

    [NET]: Identation & other cleanups related to compat_[gs]etsockopt cset
    
    No code changes, just tidying up, in some cases moving EXPORT_SYMBOLs
    to just after the function exported, etc.
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@mandriva.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 454e523b506a..dc206f1f914f 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -788,53 +788,53 @@ int inet_ioctl(struct socket *sock, unsigned int cmd, unsigned long arg)
 }
 
 const struct proto_ops inet_stream_ops = {
-	.family =	PF_INET,
-	.owner =	THIS_MODULE,
-	.release =	inet_release,
-	.bind =		inet_bind,
-	.connect =	inet_stream_connect,
-	.socketpair =	sock_no_socketpair,
-	.accept =	inet_accept,
-	.getname =	inet_getname,
-	.poll =		tcp_poll,
-	.ioctl =	inet_ioctl,
-	.listen =	inet_listen,
-	.shutdown =	inet_shutdown,
-	.setsockopt =	sock_common_setsockopt,
-	.getsockopt =	sock_common_getsockopt,
+	.family		   = PF_INET,
+	.owner		   = THIS_MODULE,
+	.release	   = inet_release,
+	.bind		   = inet_bind,
+	.connect	   = inet_stream_connect,
+	.socketpair	   = sock_no_socketpair,
+	.accept		   = inet_accept,
+	.getname	   = inet_getname,
+	.poll		   = tcp_poll,
+	.ioctl		   = inet_ioctl,
+	.listen		   = inet_listen,
+	.shutdown	   = inet_shutdown,
+	.setsockopt	   = sock_common_setsockopt,
+	.getsockopt	   = sock_common_getsockopt,
+	.sendmsg	   = inet_sendmsg,
+	.recvmsg	   = sock_common_recvmsg,
+	.mmap		   = sock_no_mmap,
+	.sendpage	   = tcp_sendpage,
 #ifdef CONFIG_COMPAT
-	.compat_setsockopt	= compat_sock_common_setsockopt,
-	.compat_getsockopt	= compat_sock_common_getsockopt,
+	.compat_setsockopt = compat_sock_common_setsockopt,
+	.compat_getsockopt = compat_sock_common_getsockopt,
 #endif
-	.sendmsg =	inet_sendmsg,
-	.recvmsg =	sock_common_recvmsg,
-	.mmap =		sock_no_mmap,
-	.sendpage =	tcp_sendpage
 };
 
 const struct proto_ops inet_dgram_ops = {
-	.family =	PF_INET,
-	.owner =	THIS_MODULE,
-	.release =	inet_release,
-	.bind =		inet_bind,
-	.connect =	inet_dgram_connect,
-	.socketpair =	sock_no_socketpair,
-	.accept =	sock_no_accept,
-	.getname =	inet_getname,
-	.poll =		udp_poll,
-	.ioctl =	inet_ioctl,
-	.listen =	sock_no_listen,
-	.shutdown =	inet_shutdown,
-	.setsockopt =	sock_common_setsockopt,
-	.getsockopt =	sock_common_getsockopt,
+	.family		   = PF_INET,
+	.owner		   = THIS_MODULE,
+	.release	   = inet_release,
+	.bind		   = inet_bind,
+	.connect	   = inet_dgram_connect,
+	.socketpair	   = sock_no_socketpair,
+	.accept		   = sock_no_accept,
+	.getname	   = inet_getname,
+	.poll		   = udp_poll,
+	.ioctl		   = inet_ioctl,
+	.listen		   = sock_no_listen,
+	.shutdown	   = inet_shutdown,
+	.setsockopt	   = sock_common_setsockopt,
+	.getsockopt	   = sock_common_getsockopt,
+	.sendmsg	   = inet_sendmsg,
+	.recvmsg	   = sock_common_recvmsg,
+	.mmap		   = sock_no_mmap,
+	.sendpage	   = inet_sendpage,
 #ifdef CONFIG_COMPAT
-	.compat_setsockopt	= compat_sock_common_setsockopt,
-	.compat_getsockopt	= compat_sock_common_getsockopt,
+	.compat_setsockopt = compat_sock_common_setsockopt,
+	.compat_getsockopt = compat_sock_common_getsockopt,
 #endif
-	.sendmsg =	inet_sendmsg,
-	.recvmsg =	sock_common_recvmsg,
-	.mmap =		sock_no_mmap,
-	.sendpage =	inet_sendpage,
 };
 
 /*
@@ -842,28 +842,28 @@ const struct proto_ops inet_dgram_ops = {
  * udp_poll
  */
 static const struct proto_ops inet_sockraw_ops = {
-	.family =	PF_INET,
-	.owner =	THIS_MODULE,
-	.release =	inet_release,
-	.bind =		inet_bind,
-	.connect =	inet_dgram_connect,
-	.socketpair =	sock_no_socketpair,
-	.accept =	sock_no_accept,
-	.getname =	inet_getname,
-	.poll =		datagram_poll,
-	.ioctl =	inet_ioctl,
-	.listen =	sock_no_listen,
-	.shutdown =	inet_shutdown,
-	.setsockopt =	sock_common_setsockopt,
-	.getsockopt =	sock_common_getsockopt,
+	.family		   = PF_INET,
+	.owner		   = THIS_MODULE,
+	.release	   = inet_release,
+	.bind		   = inet_bind,
+	.connect	   = inet_dgram_connect,
+	.socketpair	   = sock_no_socketpair,
+	.accept		   = sock_no_accept,
+	.getname	   = inet_getname,
+	.poll		   = datagram_poll,
+	.ioctl		   = inet_ioctl,
+	.listen		   = sock_no_listen,
+	.shutdown	   = inet_shutdown,
+	.setsockopt	   = sock_common_setsockopt,
+	.getsockopt	   = sock_common_getsockopt,
+	.sendmsg	   = inet_sendmsg,
+	.recvmsg	   = sock_common_recvmsg,
+	.mmap		   = sock_no_mmap,
+	.sendpage	   = inet_sendpage,
 #ifdef CONFIG_COMPAT
-	.compat_setsockopt	= compat_sock_common_setsockopt,
-	.compat_getsockopt	= compat_sock_common_getsockopt,
+	.compat_setsockopt = compat_sock_common_setsockopt,
+	.compat_getsockopt = compat_sock_common_getsockopt,
 #endif
-	.sendmsg =	inet_sendmsg,
-	.recvmsg =	sock_common_recvmsg,
-	.mmap =		sock_no_mmap,
-	.sendpage =	inet_sendpage,
 };
 
 static struct net_proto_family inet_family_ops = {

commit 3fdadf7d27e3fbcf72930941884387d1f4936f04
Author: Dmitry Mishin <dim@openvz.org>
Date:   Mon Mar 20 22:45:21 2006 -0800

    [NET]: {get|set}sockopt compatibility layer
    
    This patch extends {get|set}sockopt compatibility layer in order to
    move protocol specific parts to their place and avoid huge universal
    net/compat.c file in the future.
    
    Signed-off-by: Dmitry Mishin <dim@openvz.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 97c276f95b35..454e523b506a 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -802,6 +802,10 @@ const struct proto_ops inet_stream_ops = {
 	.shutdown =	inet_shutdown,
 	.setsockopt =	sock_common_setsockopt,
 	.getsockopt =	sock_common_getsockopt,
+#ifdef CONFIG_COMPAT
+	.compat_setsockopt	= compat_sock_common_setsockopt,
+	.compat_getsockopt	= compat_sock_common_getsockopt,
+#endif
 	.sendmsg =	inet_sendmsg,
 	.recvmsg =	sock_common_recvmsg,
 	.mmap =		sock_no_mmap,
@@ -823,6 +827,10 @@ const struct proto_ops inet_dgram_ops = {
 	.shutdown =	inet_shutdown,
 	.setsockopt =	sock_common_setsockopt,
 	.getsockopt =	sock_common_getsockopt,
+#ifdef CONFIG_COMPAT
+	.compat_setsockopt	= compat_sock_common_setsockopt,
+	.compat_getsockopt	= compat_sock_common_getsockopt,
+#endif
 	.sendmsg =	inet_sendmsg,
 	.recvmsg =	sock_common_recvmsg,
 	.mmap =		sock_no_mmap,
@@ -848,6 +856,10 @@ static const struct proto_ops inet_sockraw_ops = {
 	.shutdown =	inet_shutdown,
 	.setsockopt =	sock_common_setsockopt,
 	.getsockopt =	sock_common_getsockopt,
+#ifdef CONFIG_COMPAT
+	.compat_setsockopt	= compat_sock_common_setsockopt,
+	.compat_getsockopt	= compat_sock_common_getsockopt,
+#endif
 	.sendmsg =	inet_sendmsg,
 	.recvmsg =	sock_common_recvmsg,
 	.mmap =		sock_no_mmap,

commit 4fc268d24ceb9f4150777c1b5b2b8e6214e56b2b
Author: Randy Dunlap <rdunlap@xenotime.net>
Date:   Wed Jan 11 12:17:47 2006 -0800

    [PATCH] capable/capability.h (net/)
    
    net: Use <linux/capability.h> where capable() is used.
    
    Signed-off-by: Randy Dunlap <rdunlap@xenotime.net>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 966a071a408c..97c276f95b35 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -79,6 +79,7 @@
 #include <linux/string.h>
 #include <linux/sockios.h>
 #include <linux/net.h>
+#include <linux/capability.h>
 #include <linux/fcntl.h>
 #include <linux/mm.h>
 #include <linux/interrupt.h>

commit b5e5fa5e093e42cab4ee3d6dcbc4f450ad29a723
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue Jan 3 14:18:33 2006 -0800

    [NET]: Add a dev_ioctl() fallback to sock_ioctl()
    
    Currently all network protocols need to call dev_ioctl as the default
    fallback in their ioctl implementations.  This patch adds a fallback
    to dev_ioctl to sock_ioctl if the protocol returned -ENOIOCTLCMD.
    This way all the procotol ioctl handlers can be simplified and we don't
    need to export dev_ioctl.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 36a6306ca5a3..966a071a408c 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -777,10 +777,10 @@ int inet_ioctl(struct socket *sock, unsigned int cmd, unsigned long arg)
 			err = devinet_ioctl(cmd, (void __user *)arg);
 			break;
 		default:
-			if (!sk->sk_prot->ioctl ||
-			    (err = sk->sk_prot->ioctl(sk, cmd, arg)) ==
-			    					-ENOIOCTLCMD)
-				err = dev_ioctl(cmd, (void __user *)arg);
+			if (sk->sk_prot->ioctl)
+				err = sk->sk_prot->ioctl(sk, cmd, arg);
+			else
+				err = -ENOIOCTLCMD;
 			break;
 	}
 	return err;

commit 14c850212ed8f8cbb5972ad6b8812e08a0bc901c
Author: Arnaldo Carvalho de Melo <acme@mandriva.com>
Date:   Tue Dec 27 02:43:12 2005 -0200

    [INET_SOCK]: Move struct inet_sock & helper functions to net/inet_sock.h
    
    To help in reducing the number of include dependencies, several files were
    touched as they were getting needed headers indirectly for stuff they use.
    
    Thanks also to Alan Menegotto for pointing out that net/dccp/proto.c had
    linux/dccp.h include twice.
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@mandriva.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 4ed8a814c6cb..36a6306ca5a3 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -93,6 +93,7 @@
 #include <linux/smp_lock.h>
 #include <linux/inet.h>
 #include <linux/igmp.h>
+#include <linux/inetdevice.h>
 #include <linux/netdevice.h>
 #include <net/ip.h>
 #include <net/protocol.h>

commit 90ddc4f0470427df306f308ad03db6b6b21644b8
Author: Eric Dumazet <dada1@cosmosbay.com>
Date:   Thu Dec 22 12:49:22 2005 -0800

    [NET]: move struct proto_ops to const
    
    I noticed that some of 'struct proto_ops' used in the kernel may share
    a cache line used by locks or other heavily modified data. (default
    linker alignement is 32 bytes, and L1_CACHE_LINE is 64 or 128 at
    least)
    
    This patch makes sure a 'struct proto_ops' can be declared as const,
    so that all cpus can share all parts of it without false sharing.
    
    This is not mandatory : a driver can still use a read/write structure
    if it needs to (and eventually a __read_mostly)
    
    I made a global stubstitute to change all existing occurences to make
    them const.
    
    This should reduce the possibility of false sharing on SMP, and
    speedup some socket system calls.
    
    Signed-off-by: Eric Dumazet <dada1@cosmosbay.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 617e858beff1..4ed8a814c6cb 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -785,7 +785,7 @@ int inet_ioctl(struct socket *sock, unsigned int cmd, unsigned long arg)
 	return err;
 }
 
-struct proto_ops inet_stream_ops = {
+const struct proto_ops inet_stream_ops = {
 	.family =	PF_INET,
 	.owner =	THIS_MODULE,
 	.release =	inet_release,
@@ -806,7 +806,7 @@ struct proto_ops inet_stream_ops = {
 	.sendpage =	tcp_sendpage
 };
 
-struct proto_ops inet_dgram_ops = {
+const struct proto_ops inet_dgram_ops = {
 	.family =	PF_INET,
 	.owner =	THIS_MODULE,
 	.release =	inet_release,
@@ -831,7 +831,7 @@ struct proto_ops inet_dgram_ops = {
  * For SOCK_RAW sockets; should be the same as inet_dgram_ops but without
  * udp_poll
  */
-static struct proto_ops inet_sockraw_ops = {
+static const struct proto_ops inet_sockraw_ops = {
 	.family =	PF_INET,
 	.owner =	THIS_MODULE,
 	.release =	inet_release,

commit d83d8461f902c672bc1bd8fbc6a94e19f092da97
Author: Arnaldo Carvalho de Melo <acme@mandriva.com>
Date:   Tue Dec 13 23:26:10 2005 -0800

    [IP_SOCKGLUE]: Remove most of the tcp specific calls
    
    As DCCP needs to be called in the same spots.
    
    Now we have a member in inet_sock (is_icsk), set at sock creation time from
    struct inet_protosw->flags (if INET_PROTOSW_ICSK is set, like for TCP and
    DCCP) to see if a struct sock instance is a inet_connection_sock for places
    like the ones in ip_sockglue.c (v4 and v6) where we previously were looking if
    sk_type was SOCK_STREAM, that is insufficient because we now use the same code
    for DCCP, that has sk_type SOCK_DCCP.
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@mandriva.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index d368cf249000..617e858beff1 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -302,6 +302,7 @@ static int inet_create(struct socket *sock, int protocol)
 		sk->sk_reuse = 1;
 
 	inet = inet_sk(sk);
+	inet->is_icsk = INET_PROTOSW_ICSK & answer_flags;
 
 	if (SOCK_RAW == sock->type) {
 		inet->num = protocol;
@@ -869,7 +870,8 @@ static struct inet_protosw inetsw_array[] =
                 .ops =        &inet_stream_ops,
                 .capability = -1,
                 .no_check =   0,
-                .flags =      INET_PROTOSW_PERMANENT,
+                .flags =      INET_PROTOSW_PERMANENT |
+			      INET_PROTOSW_ICSK,
         },
 
         {

commit 86c8f9d158f68538a971a47206a46a22c7479bac
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Fri Dec 2 20:43:26 2005 -0800

    [IPV4] Fix EPROTONOSUPPORT error in inet_create
    
    There is a coding error in inet_create that causes it to always return
    ESOCKTNOSUPPORT.  It should return EPROTONOSUPPORT when there are
    protocols registered for a given socket type but none of them match
    the requested protocol.
    
    This is based on a patch by Jayachandran C.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index eaa150c33b04..d368cf249000 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -228,13 +228,14 @@ static int inet_create(struct socket *sock, int protocol)
 	unsigned char answer_flags;
 	char answer_no_check;
 	int try_loading_module = 0;
-	int err = -ESOCKTNOSUPPORT;
+	int err;
 
 	sock->state = SS_UNCONNECTED;
 
 	/* Look for the requested type/protocol pair. */
 	answer = NULL;
 lookup_protocol:
+	err = -ESOCKTNOSUPPORT;
 	rcu_read_lock();
 	list_for_each_rcu(p, &inetsw[sock->type]) {
 		answer = list_entry(p, struct inet_protosw, list);
@@ -252,6 +253,7 @@ static int inet_create(struct socket *sock, int protocol)
 			if (IPPROTO_IP == answer->protocol)
 				break;
 		}
+		err = -EPROTONOSUPPORT;
 		answer = NULL;
 	}
 
@@ -280,9 +282,6 @@ static int inet_create(struct socket *sock, int protocol)
 	err = -EPERM;
 	if (answer->capability > 0 && !capable(answer->capability))
 		goto out_rcu_unlock;
-	err = -EPROTONOSUPPORT;
-	if (!protocol)
-		goto out_rcu_unlock;
 
 	sock->ops = answer->ops;
 	answer_prot = answer->prot;

commit a51482bde22f99c63fbbb57d5d46cc666384e379
Author: Jesper Juhl <jesper.juhl@gmail.com>
Date:   Tue Nov 8 09:41:34 2005 -0800

    [NET]: kfree cleanup
    
    From: Jesper Juhl <jesper.juhl@gmail.com>
    
    This is the net/ part of the big kfree cleanup patch.
    
    Remove pointless checks for NULL prior to calling kfree() in net/.
    
    Signed-off-by: Jesper Juhl <jesper.juhl@gmail.com>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Arnaldo Carvalho de Melo <acme@conectiva.com.br>
    Acked-by: Marcel Holtmann <marcel@holtmann.org>
    Acked-by: YOSHIFUJI Hideaki <yoshfuji@linux-ipv6.org>
    Signed-off-by: Andrew Morton <akpm@osdl.org>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index a9d84f93442c..eaa150c33b04 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -147,8 +147,7 @@ void inet_sock_destruct(struct sock *sk)
 	BUG_TRAP(!sk->sk_wmem_queued);
 	BUG_TRAP(!sk->sk_forward_alloc);
 
-	if (inet->opt)
-		kfree(inet->opt);
+	kfree(inet->opt);
 	dst_release(sk->sk_dst_cache);
 	sk_refcnt_debug_dec(sk);
 }

commit cb7b593c2c808b32a1ea188599713c434b95f849
Author: Stephen Hemminger <shemminger@osdl.org>
Date:   Fri Sep 9 13:35:42 2005 -0700

    [IPV4] fib_trie: fix proc interface
    
    Create one iterator for walking over FIB trie, and use it
    for all the /proc functions. Add a /proc/net/route
    output for backwards compatibility with old applications.
    
    Make initialization of fib_trie same as fib_hash so no #ifdef
    is needed in af_inet.c
    
    Fixes: http://bugzilla.kernel.org/show_bug.cgi?id=5209
    
    Signed-off-by: Stephen Hemminger <shemminger@osdl.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index bf147f8db399..a9d84f93442c 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1248,11 +1248,6 @@ module_init(inet_init);
 /* ------------------------------------------------------------------------ */
 
 #ifdef CONFIG_PROC_FS
-#ifdef CONFIG_IP_FIB_TRIE
-extern int  fib_stat_proc_init(void);
-extern void fib_stat_proc_exit(void);
-#endif
-
 static int __init ipv4_proc_init(void)
 {
 	int rc = 0;
@@ -1265,19 +1260,11 @@ static int __init ipv4_proc_init(void)
 		goto out_udp;
 	if (fib_proc_init())
 		goto out_fib;
-#ifdef CONFIG_IP_FIB_TRIE
-         if (fib_stat_proc_init())
-                 goto out_fib_stat;
-#endif
 	if (ip_misc_proc_init())
 		goto out_misc;
 out:
 	return rc;
 out_misc:
-#ifdef CONFIG_IP_FIB_TRIE
- 	fib_stat_proc_exit();
-out_fib_stat:
-#endif
 	fib_proc_exit();
 out_fib:
 	udp4_proc_exit();

commit ba89966c1984513f4f2cc0a6c182266be44ddd03
Author: Eric Dumazet <dada1@cosmosbay.com>
Date:   Fri Aug 26 12:05:31 2005 -0700

    [NET]: use __read_mostly on kmem_cache_t , DEFINE_SNMP_STAT pointers
    
    This patch puts mostly read only data in the right section
    (read_mostly), to help sharing of these data between CPUS without
    memory ping pongs.
    
    On one of my production machine, tcp_statistics was sitting in a
    heavily modified cache line, so *every* SNMP update had to force a
    reload.
    
    Signed-off-by: Eric Dumazet <dada1@cosmosbay.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 5810f9d14914..bf147f8db399 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -113,7 +113,7 @@
 #include <linux/mroute.h>
 #endif
 
-DEFINE_SNMP_STAT(struct linux_mib, net_statistics);
+DEFINE_SNMP_STAT(struct linux_mib, net_statistics) __read_mostly;
 
 extern void ip_mc_drop_socket(struct sock *sk);
 

commit 20380731bc2897f2952ae055420972ded4cd786e
Author: Arnaldo Carvalho de Melo <acme@mandriva.com>
Date:   Tue Aug 16 02:18:02 2005 -0300

    [NET]: Fix sparse warnings
    
    Of this type, mostly:
    
    CHECK   net/ipv6/netfilter.c
    net/ipv6/netfilter.c:96:12: warning: symbol 'ipv6_netfilter_init' was not declared. Should it be static?
    net/ipv6/netfilter.c:101:6: warning: symbol 'ipv6_netfilter_fini' was not declared. Should it be static?
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@mandriva.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 20f52b5f5dea..5810f9d14914 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -859,10 +859,6 @@ static struct net_proto_family inet_family_ops = {
 	.owner	= THIS_MODULE,
 };
 
-
-extern void tcp_init(void);
-extern void tcp_v4_init(struct net_proto_family *);
-
 /* Upon startup we insert all the elements in inetsw_array[] into
  * the linked list inetsw.
  */
@@ -1132,7 +1128,6 @@ static int __init init_ipv4_mibs(void)
 }
 
 static int ipv4_proc_init(void);
-extern void ipfrag_init(void);
 
 /*
  *	IP protocol layer initialiser
@@ -1253,19 +1248,10 @@ module_init(inet_init);
 /* ------------------------------------------------------------------------ */
 
 #ifdef CONFIG_PROC_FS
-extern int  fib_proc_init(void);
-extern void fib_proc_exit(void);
 #ifdef CONFIG_IP_FIB_TRIE
 extern int  fib_stat_proc_init(void);
 extern void fib_stat_proc_exit(void);
 #endif
-extern int  ip_misc_proc_init(void);
-extern int  raw_proc_init(void);
-extern void raw_proc_exit(void);
-extern int  tcp4_proc_init(void);
-extern void tcp4_proc_exit(void);
-extern int  udp4_proc_init(void);
-extern void udp4_proc_exit(void);
 
 static int __init ipv4_proc_init(void)
 {

commit bb97d31f5130d677644d9931ef38613d1164ec94
Author: Arnaldo Carvalho de Melo <acme@ghostprotocols.net>
Date:   Tue Aug 9 20:19:14 2005 -0700

    [INET]: Make inet_create try to load protocol modules
    
    Syntax is net-pf-PROTOCOL_FAMILY-PROTOCOL-SOCK_TYPE and if this
    fails net-pf-PROTOCOL_FAMILY-PROTOCOL.
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@ghostprotocols.net>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 52f5ecc58c46..20f52b5f5dea 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -228,12 +228,14 @@ static int inet_create(struct socket *sock, int protocol)
 	struct proto *answer_prot;
 	unsigned char answer_flags;
 	char answer_no_check;
-	int err;
+	int try_loading_module = 0;
+	int err = -ESOCKTNOSUPPORT;
 
 	sock->state = SS_UNCONNECTED;
 
 	/* Look for the requested type/protocol pair. */
 	answer = NULL;
+lookup_protocol:
 	rcu_read_lock();
 	list_for_each_rcu(p, &inetsw[sock->type]) {
 		answer = list_entry(p, struct inet_protosw, list);
@@ -254,9 +256,28 @@ static int inet_create(struct socket *sock, int protocol)
 		answer = NULL;
 	}
 
-	err = -ESOCKTNOSUPPORT;
-	if (!answer)
-		goto out_rcu_unlock;
+	if (unlikely(answer == NULL)) {
+		if (try_loading_module < 2) {
+			rcu_read_unlock();
+			/*
+			 * Be more specific, e.g. net-pf-2-proto-132-type-1
+			 * (net-pf-PF_INET-proto-IPPROTO_SCTP-type-SOCK_STREAM)
+			 */
+			if (++try_loading_module == 1)
+				request_module("net-pf-%d-proto-%d-type-%d",
+					       PF_INET, protocol, sock->type);
+			/*
+			 * Fall back to generic, e.g. net-pf-2-proto-132
+			 * (net-pf-PF_INET-proto-IPPROTO_SCTP)
+			 */
+			else
+				request_module("net-pf-%d-proto-%d",
+					       PF_INET, protocol);
+			goto lookup_protocol;
+		} else
+			goto out_rcu_unlock;
+	}
+
 	err = -EPERM;
 	if (answer->capability > 0 && !capable(answer->capability))
 		goto out_rcu_unlock;

commit 295f7324ff8d9ea58b4d3ec93b1aaa1d80e048a9
Author: Arnaldo Carvalho de Melo <acme@ghostprotocols.net>
Date:   Tue Aug 9 20:11:56 2005 -0700

    [ICSK]: Introduce reqsk_queue_prune from code in tcp_synack_timer
    
    With this we're very close to getting all of the current TCP
    refactorings in my dccp-2.6 tree merged, next changeset will export
    some functions needed by the current DCCP code and then dccp-2.6.git
    will be born!
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@ghostprotocols.net>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index f691058cf599..52f5ecc58c46 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -99,6 +99,7 @@
 #include <net/arp.h>
 #include <net/route.h>
 #include <net/ip_fib.h>
+#include <net/inet_connection_sock.h>
 #include <net/tcp.h>
 #include <net/udp.h>
 #include <linux/skbuff.h>

commit 0a5578cf8e5e045aaa68643c17ce885426697c6b
Author: Arnaldo Carvalho de Melo <acme@ghostprotocols.net>
Date:   Tue Aug 9 20:11:41 2005 -0700

    [ICSK]: Generalise tcp_listen_{start,stop}
    
    This also moved inet_iif from tcp to inet_hashtables.h, as it is
    needed by the inet_lookup callers, perhaps this needs a bit of
    polishing, but for now seems fine.
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@ghostprotocols.net>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 7137e6420d66..f691058cf599 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -202,7 +202,7 @@ int inet_listen(struct socket *sock, int backlog)
 	 * we can only allow the backlog to be adjusted.
 	 */
 	if (old_state != TCP_LISTEN) {
-		err = tcp_listen_start(sk);
+		err = inet_csk_listen_start(sk, TCP_SYNQ_HSIZE);
 		if (err)
 			goto out;
 	}

commit 32519f11d38ea8f4f60896763bacec7db1760f9c
Author: Arnaldo Carvalho de Melo <acme@ghostprotocols.net>
Date:   Tue Aug 9 19:50:02 2005 -0700

    [INET]: Introduce inet_sk_rebuild_header
    
    From tcp_v4_rebuild_header, that already was pretty generic, I only
    needed to use sk->sk_protocol instead of the hardcoded IPPROTO_TCP and
    establish the requirement that INET transport layer protocols that
    want to use this function map TCP_SYN_SENT to its equivalent state.
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@ghostprotocols.net>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 9e83d7773d8f..7137e6420d66 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -951,6 +951,119 @@ void inet_unregister_protosw(struct inet_protosw *p)
 	}
 }
 
+/*
+ *      Shall we try to damage output packets if routing dev changes?
+ */
+
+int sysctl_ip_dynaddr;
+
+static int inet_sk_reselect_saddr(struct sock *sk)
+{
+	struct inet_sock *inet = inet_sk(sk);
+	int err;
+	struct rtable *rt;
+	__u32 old_saddr = inet->saddr;
+	__u32 new_saddr;
+	__u32 daddr = inet->daddr;
+
+	if (inet->opt && inet->opt->srr)
+		daddr = inet->opt->faddr;
+
+	/* Query new route. */
+	err = ip_route_connect(&rt, daddr, 0,
+			       RT_CONN_FLAGS(sk),
+			       sk->sk_bound_dev_if,
+			       sk->sk_protocol,
+			       inet->sport, inet->dport, sk);
+	if (err)
+		return err;
+
+	sk_setup_caps(sk, &rt->u.dst);
+
+	new_saddr = rt->rt_src;
+
+	if (new_saddr == old_saddr)
+		return 0;
+
+	if (sysctl_ip_dynaddr > 1) {
+		printk(KERN_INFO "%s(): shifting inet->"
+				 "saddr from %d.%d.%d.%d to %d.%d.%d.%d\n",
+		       __FUNCTION__,
+		       NIPQUAD(old_saddr),
+		       NIPQUAD(new_saddr));
+	}
+
+	inet->saddr = inet->rcv_saddr = new_saddr;
+
+	/*
+	 * XXX The only one ugly spot where we need to
+	 * XXX really change the sockets identity after
+	 * XXX it has entered the hashes. -DaveM
+	 *
+	 * Besides that, it does not check for connection
+	 * uniqueness. Wait for troubles.
+	 */
+	__sk_prot_rehash(sk);
+	return 0;
+}
+
+int inet_sk_rebuild_header(struct sock *sk)
+{
+	struct inet_sock *inet = inet_sk(sk);
+	struct rtable *rt = (struct rtable *)__sk_dst_check(sk, 0);
+	u32 daddr;
+	int err;
+
+	/* Route is OK, nothing to do. */
+	if (rt)
+		return 0;
+
+	/* Reroute. */
+	daddr = inet->daddr;
+	if (inet->opt && inet->opt->srr)
+		daddr = inet->opt->faddr;
+{
+	struct flowi fl = {
+		.oif = sk->sk_bound_dev_if,
+		.nl_u = {
+			.ip4_u = {
+				.daddr	= daddr,
+				.saddr	= inet->saddr,
+				.tos	= RT_CONN_FLAGS(sk),
+			},
+		},
+		.proto = sk->sk_protocol,
+		.uli_u = {
+			.ports = {
+				.sport = inet->sport,
+				.dport = inet->dport,
+			},
+		},
+	};
+						
+	err = ip_route_output_flow(&rt, &fl, sk, 0);
+}
+	if (!err)
+		sk_setup_caps(sk, &rt->u.dst);
+	else {
+		/* Routing failed... */
+		sk->sk_route_caps = 0;
+		/*
+		 * Other protocols have to map its equivalent state to TCP_SYN_SENT.
+		 * DCCP maps its DCCP_REQUESTING state to TCP_SYN_SENT. -acme
+		 */
+		if (!sysctl_ip_dynaddr ||
+		    sk->sk_state != TCP_SYN_SENT ||
+		    (sk->sk_userlocks & SOCK_BINDADDR_LOCK) ||
+		    (err = inet_sk_reselect_saddr(sk)) != 0)
+			sk->sk_err_soft = -err;
+	}
+
+	return err;
+}
+
+EXPORT_SYMBOL(inet_sk_rebuild_header);
+
 #ifdef CONFIG_IP_MULTICAST
 static struct net_protocol igmp_protocol = {
 	.handler =	igmp_rcv,

commit e6848976b721eeb5551cd94673faafeef78d9f35
Author: Arnaldo Carvalho de Melo <acme@ghostprotocols.net>
Date:   Tue Aug 9 19:45:38 2005 -0700

    [NET]: Cleanup INET_REFCNT_DEBUG code
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@ghostprotocols.net>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 163ae4068b5f..9e83d7773d8f 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -114,10 +114,6 @@
 
 DEFINE_SNMP_STAT(struct linux_mib, net_statistics);
 
-#ifdef INET_REFCNT_DEBUG
-atomic_t inet_sock_nr;
-#endif
-
 extern void ip_mc_drop_socket(struct sock *sk);
 
 /* The inetsw table contains everything that inet_create needs to
@@ -153,11 +149,7 @@ void inet_sock_destruct(struct sock *sk)
 	if (inet->opt)
 		kfree(inet->opt);
 	dst_release(sk->sk_dst_cache);
-#ifdef INET_REFCNT_DEBUG
-	atomic_dec(&inet_sock_nr);
-	printk(KERN_DEBUG "INET socket %p released, %d are still alive\n",
-	       sk, atomic_read(&inet_sock_nr));
-#endif
+	sk_refcnt_debug_dec(sk);
 }
 
 /*
@@ -317,9 +309,7 @@ static int inet_create(struct socket *sock, int protocol)
 	inet->mc_index	= 0;
 	inet->mc_list	= NULL;
 
-#ifdef INET_REFCNT_DEBUG
-	atomic_inc(&inet_sock_nr);
-#endif
+	sk_refcnt_debug_inc(sk);
 
 	if (inet->num) {
 		/* It assumes that any protocol which allows
@@ -1205,7 +1195,3 @@ EXPORT_SYMBOL(inet_stream_ops);
 EXPORT_SYMBOL(inet_unregister_protosw);
 EXPORT_SYMBOL(net_statistics);
 EXPORT_SYMBOL(sysctl_ip_nonlocal_bind);
-
-#ifdef INET_REFCNT_DEBUG
-EXPORT_SYMBOL(inet_sock_nr);
-#endif

commit c877efb207bf4629cfa97ac13412f7392a873485
Author: Stephen Hemminger <shemminger@osdl.org>
Date:   Tue Jul 19 14:01:51 2005 -0700

    [IPV4]: Fix up lots of little whitespace indentation stuff in fib_trie.
    
    Signed-off-by: Stephen Hemminger <shemminger@osdl.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index ef7468376ae6..163ae4068b5f 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1157,7 +1157,7 @@ static int __init ipv4_proc_init(void)
 #ifdef CONFIG_IP_FIB_TRIE
          if (fib_stat_proc_init())
                  goto out_fib_stat;
- #endif
+#endif
 	if (ip_misc_proc_init())
 		goto out_misc;
 out:

commit 30e224d76f34e041c30df66a4dcbeeb53556ea3f
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Tue Jul 5 14:40:10 2005 -0700

    [IPV4]: Fix crash in ip_rcv while booting related to netconsole
    
    Makes IPv4 ip_rcv registration happen last in af_inet.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 658e7977924d..ef7468376ae6 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1009,6 +1009,15 @@ static int __init init_ipv4_mibs(void)
 static int ipv4_proc_init(void);
 extern void ipfrag_init(void);
 
+/*
+ *	IP protocol layer initialiser
+ */
+
+static struct packet_type ip_packet_type = {
+	.type = __constant_htons(ETH_P_IP),
+	.func = ip_rcv,
+};
+
 static int __init inet_init(void)
 {
 	struct sk_buff *dummy_skb;
@@ -1102,6 +1111,8 @@ static int __init inet_init(void)
 
 	ipfrag_init();
 
+	dev_add_pack(&ip_packet_type);
+
 	rc = 0;
 out:
 	return rc;

commit 19baf839ff4a8daa1f2a7400897094fc18e4f5e9
Author: Robert Olsson <Robert.Olsson@data.slu.se>
Date:   Tue Jun 21 12:43:18 2005 -0700

    [IPV4]: Add LC-Trie FIB lookup algorithm.
    
    Signed-off-by: Robert Olsson <Robert.Olsson@data.slu.se>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 03942f133944..658e7977924d 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1119,6 +1119,10 @@ module_init(inet_init);
 #ifdef CONFIG_PROC_FS
 extern int  fib_proc_init(void);
 extern void fib_proc_exit(void);
+#ifdef CONFIG_IP_FIB_TRIE
+extern int  fib_stat_proc_init(void);
+extern void fib_stat_proc_exit(void);
+#endif
 extern int  ip_misc_proc_init(void);
 extern int  raw_proc_init(void);
 extern void raw_proc_exit(void);
@@ -1139,11 +1143,19 @@ static int __init ipv4_proc_init(void)
 		goto out_udp;
 	if (fib_proc_init())
 		goto out_fib;
+#ifdef CONFIG_IP_FIB_TRIE
+         if (fib_stat_proc_init())
+                 goto out_fib_stat;
+ #endif
 	if (ip_misc_proc_init())
 		goto out_misc;
 out:
 	return rc;
 out_misc:
+#ifdef CONFIG_IP_FIB_TRIE
+ 	fib_stat_proc_exit();
+out_fib_stat:
+#endif
 	fib_proc_exit();
 out_fib:
 	udp4_proc_exit();

commit cdac4e07748934e37e415437055ed591aed9eb21
Author: Neil Horman <nhorman@redhat.com>
Date:   Mon Jun 13 15:12:33 2005 -0700

    [SCTP] Add support for ip_nonlocal_bind sysctl & IP_FREEBIND socket option
    
    Signed-off-by: Neil Horman <nhorman@redhat.com>
    Signed-off-by: Sridhar Samudrala <sri@us.ibm.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index b3cb49ce5fad..03942f133944 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1181,6 +1181,7 @@ EXPORT_SYMBOL(inet_stream_connect);
 EXPORT_SYMBOL(inet_stream_ops);
 EXPORT_SYMBOL(inet_unregister_protosw);
 EXPORT_SYMBOL(net_statistics);
+EXPORT_SYMBOL(sysctl_ip_nonlocal_bind);
 
 #ifdef INET_REFCNT_DEBUG
 EXPORT_SYMBOL(inet_sock_nr);

commit 02c30a84e6298b6b20a56f0896ac80b47839e134
Author: Jesper Juhl <juhl-lkml@dif.dk>
Date:   Thu May 5 16:16:16 2005 -0700

    [PATCH] update Ross Biro bouncing email address
    
    Ross moved.  Remove the bad email address so people will find the correct
    one in ./CREDITS.
    
    Signed-off-by: Jesper Juhl <juhl-lkml@dif.dk>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index cdad47642ae7..b3cb49ce5fad 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -7,7 +7,7 @@
  *
  * Version:	$Id: af_inet.c,v 1.137 2002/02/01 22:01:03 davem Exp $
  *
- * Authors:	Ross Biro, <bir7@leland.Stanford.Edu>
+ * Authors:	Ross Biro
  *		Fred N. van Kempen, <waltje@uWalt.NL.Mugnet.ORG>
  *		Florian La Roche, <flla@stud.uni-sb.de>
  *		Alan Cox, <A.Cox@swansea.ac.uk>

commit b453257f057b834fdf9f4a6ad6133598b79bd982
Author: Al Viro <viro@www.linux.org.uk>
Date:   Mon Apr 25 18:32:13 2005 -0700

    [PATCH] kill gratitious includes of major.h under net/*
    
    A lot of places in there are including major.h for no reason whatsoever.
    Removed.  And yes, it still builds.
    
    The history of that stuff is often amusing.  E.g.  for net/core/sock.c
    the story looks so, as far as I've been able to reconstruct it: we used
    to need major.h in net/socket.c circa 1.1.early.  In 1.1.13 that need
    had disappeared, along with register_chrdev(SOCKET_MAJOR, "socket",
    &net_fops) in sock_init().  Include had not.  When 1.2 -> 1.3 reorg of
    net/* had moved a lot of stuff from net/socket.c to net/core/sock.c,
    this crap had followed...
    
    Signed-off-by: Al Viro <viro@parcelfarce.linux.theplanet.co.uk>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index c34dab67e461..cdad47642ae7 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -73,7 +73,6 @@
 #include <linux/socket.h>
 #include <linux/in.h>
 #include <linux/kernel.h>
-#include <linux/major.h>
 #include <linux/module.h>
 #include <linux/sched.h>
 #include <linux/timer.h>

commit 1da177e4c3f41524e886b7f1b8a0c1fc7321cac2
Author: Linus Torvalds <torvalds@ppc970.osdl.org>
Date:   Sat Apr 16 15:20:36 2005 -0700

    Linux-2.6.12-rc2
    
    Initial git repository build. I'm not bothering with the full history,
    even though we have it. We can create a separate "historical" git
    archive of that later if we want to, and in the meantime it's about
    3.2GB when imported into git - space that would just make the early
    git days unnecessarily complicated, when we don't have a lot of good
    infrastructure for it.
    
    Let it rip!

diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
new file mode 100644
index 000000000000..c34dab67e461
--- /dev/null
+++ b/net/ipv4/af_inet.c
@@ -0,0 +1,1188 @@
+/*
+ * INET		An implementation of the TCP/IP protocol suite for the LINUX
+ *		operating system.  INET is implemented using the  BSD Socket
+ *		interface as the means of communication with the user level.
+ *
+ *		PF_INET protocol family socket handler.
+ *
+ * Version:	$Id: af_inet.c,v 1.137 2002/02/01 22:01:03 davem Exp $
+ *
+ * Authors:	Ross Biro, <bir7@leland.Stanford.Edu>
+ *		Fred N. van Kempen, <waltje@uWalt.NL.Mugnet.ORG>
+ *		Florian La Roche, <flla@stud.uni-sb.de>
+ *		Alan Cox, <A.Cox@swansea.ac.uk>
+ *
+ * Changes (see also sock.c)
+ *
+ *		piggy,
+ *		Karl Knutson	:	Socket protocol table
+ *		A.N.Kuznetsov	:	Socket death error in accept().
+ *		John Richardson :	Fix non blocking error in connect()
+ *					so sockets that fail to connect
+ *					don't return -EINPROGRESS.
+ *		Alan Cox	:	Asynchronous I/O support
+ *		Alan Cox	:	Keep correct socket pointer on sock
+ *					structures
+ *					when accept() ed
+ *		Alan Cox	:	Semantics of SO_LINGER aren't state
+ *					moved to close when you look carefully.
+ *					With this fixed and the accept bug fixed
+ *					some RPC stuff seems happier.
+ *		Niibe Yutaka	:	4.4BSD style write async I/O
+ *		Alan Cox,
+ *		Tony Gale 	:	Fixed reuse semantics.
+ *		Alan Cox	:	bind() shouldn't abort existing but dead
+ *					sockets. Stops FTP netin:.. I hope.
+ *		Alan Cox	:	bind() works correctly for RAW sockets.
+ *					Note that FreeBSD at least was broken
+ *					in this respect so be careful with
+ *					compatibility tests...
+ *		Alan Cox	:	routing cache support
+ *		Alan Cox	:	memzero the socket structure for
+ *					compactness.
+ *		Matt Day	:	nonblock connect error handler
+ *		Alan Cox	:	Allow large numbers of pending sockets
+ *					(eg for big web sites), but only if
+ *					specifically application requested.
+ *		Alan Cox	:	New buffering throughout IP. Used
+ *					dumbly.
+ *		Alan Cox	:	New buffering now used smartly.
+ *		Alan Cox	:	BSD rather than common sense
+ *					interpretation of listen.
+ *		Germano Caronni	:	Assorted small races.
+ *		Alan Cox	:	sendmsg/recvmsg basic support.
+ *		Alan Cox	:	Only sendmsg/recvmsg now supported.
+ *		Alan Cox	:	Locked down bind (see security list).
+ *		Alan Cox	:	Loosened bind a little.
+ *		Mike McLagan	:	ADD/DEL DLCI Ioctls
+ *	Willy Konynenberg	:	Transparent proxying support.
+ *		David S. Miller	:	New socket lookup architecture.
+ *					Some other random speedups.
+ *		Cyrus Durgin	:	Cleaned up file for kmod hacks.
+ *		Andi Kleen	:	Fix inet_stream_connect TCP race.
+ *
+ *		This program is free software; you can redistribute it and/or
+ *		modify it under the terms of the GNU General Public License
+ *		as published by the Free Software Foundation; either version
+ *		2 of the License, or (at your option) any later version.
+ */
+
+#include <linux/config.h>
+#include <linux/errno.h>
+#include <linux/types.h>
+#include <linux/socket.h>
+#include <linux/in.h>
+#include <linux/kernel.h>
+#include <linux/major.h>
+#include <linux/module.h>
+#include <linux/sched.h>
+#include <linux/timer.h>
+#include <linux/string.h>
+#include <linux/sockios.h>
+#include <linux/net.h>
+#include <linux/fcntl.h>
+#include <linux/mm.h>
+#include <linux/interrupt.h>
+#include <linux/stat.h>
+#include <linux/init.h>
+#include <linux/poll.h>
+#include <linux/netfilter_ipv4.h>
+
+#include <asm/uaccess.h>
+#include <asm/system.h>
+
+#include <linux/smp_lock.h>
+#include <linux/inet.h>
+#include <linux/igmp.h>
+#include <linux/netdevice.h>
+#include <net/ip.h>
+#include <net/protocol.h>
+#include <net/arp.h>
+#include <net/route.h>
+#include <net/ip_fib.h>
+#include <net/tcp.h>
+#include <net/udp.h>
+#include <linux/skbuff.h>
+#include <net/sock.h>
+#include <net/raw.h>
+#include <net/icmp.h>
+#include <net/ipip.h>
+#include <net/inet_common.h>
+#include <net/xfrm.h>
+#ifdef CONFIG_IP_MROUTE
+#include <linux/mroute.h>
+#endif
+
+DEFINE_SNMP_STAT(struct linux_mib, net_statistics);
+
+#ifdef INET_REFCNT_DEBUG
+atomic_t inet_sock_nr;
+#endif
+
+extern void ip_mc_drop_socket(struct sock *sk);
+
+/* The inetsw table contains everything that inet_create needs to
+ * build a new socket.
+ */
+static struct list_head inetsw[SOCK_MAX];
+static DEFINE_SPINLOCK(inetsw_lock);
+
+/* New destruction routine */
+
+void inet_sock_destruct(struct sock *sk)
+{
+	struct inet_sock *inet = inet_sk(sk);
+
+	__skb_queue_purge(&sk->sk_receive_queue);
+	__skb_queue_purge(&sk->sk_error_queue);
+
+	if (sk->sk_type == SOCK_STREAM && sk->sk_state != TCP_CLOSE) {
+		printk("Attempt to release TCP socket in state %d %p\n",
+		       sk->sk_state, sk);
+		return;
+	}
+	if (!sock_flag(sk, SOCK_DEAD)) {
+		printk("Attempt to release alive inet socket %p\n", sk);
+		return;
+	}
+
+	BUG_TRAP(!atomic_read(&sk->sk_rmem_alloc));
+	BUG_TRAP(!atomic_read(&sk->sk_wmem_alloc));
+	BUG_TRAP(!sk->sk_wmem_queued);
+	BUG_TRAP(!sk->sk_forward_alloc);
+
+	if (inet->opt)
+		kfree(inet->opt);
+	dst_release(sk->sk_dst_cache);
+#ifdef INET_REFCNT_DEBUG
+	atomic_dec(&inet_sock_nr);
+	printk(KERN_DEBUG "INET socket %p released, %d are still alive\n",
+	       sk, atomic_read(&inet_sock_nr));
+#endif
+}
+
+/*
+ *	The routines beyond this point handle the behaviour of an AF_INET
+ *	socket object. Mostly it punts to the subprotocols of IP to do
+ *	the work.
+ */
+
+/*
+ *	Automatically bind an unbound socket.
+ */
+
+static int inet_autobind(struct sock *sk)
+{
+	struct inet_sock *inet;
+	/* We may need to bind the socket. */
+	lock_sock(sk);
+	inet = inet_sk(sk);
+	if (!inet->num) {
+		if (sk->sk_prot->get_port(sk, 0)) {
+			release_sock(sk);
+			return -EAGAIN;
+		}
+		inet->sport = htons(inet->num);
+	}
+	release_sock(sk);
+	return 0;
+}
+
+/*
+ *	Move a socket into listening state.
+ */
+int inet_listen(struct socket *sock, int backlog)
+{
+	struct sock *sk = sock->sk;
+	unsigned char old_state;
+	int err;
+
+	lock_sock(sk);
+
+	err = -EINVAL;
+	if (sock->state != SS_UNCONNECTED || sock->type != SOCK_STREAM)
+		goto out;
+
+	old_state = sk->sk_state;
+	if (!((1 << old_state) & (TCPF_CLOSE | TCPF_LISTEN)))
+		goto out;
+
+	/* Really, if the socket is already in listen state
+	 * we can only allow the backlog to be adjusted.
+	 */
+	if (old_state != TCP_LISTEN) {
+		err = tcp_listen_start(sk);
+		if (err)
+			goto out;
+	}
+	sk->sk_max_ack_backlog = backlog;
+	err = 0;
+
+out:
+	release_sock(sk);
+	return err;
+}
+
+/*
+ *	Create an inet socket.
+ */
+
+static int inet_create(struct socket *sock, int protocol)
+{
+	struct sock *sk;
+	struct list_head *p;
+	struct inet_protosw *answer;
+	struct inet_sock *inet;
+	struct proto *answer_prot;
+	unsigned char answer_flags;
+	char answer_no_check;
+	int err;
+
+	sock->state = SS_UNCONNECTED;
+
+	/* Look for the requested type/protocol pair. */
+	answer = NULL;
+	rcu_read_lock();
+	list_for_each_rcu(p, &inetsw[sock->type]) {
+		answer = list_entry(p, struct inet_protosw, list);
+
+		/* Check the non-wild match. */
+		if (protocol == answer->protocol) {
+			if (protocol != IPPROTO_IP)
+				break;
+		} else {
+			/* Check for the two wild cases. */
+			if (IPPROTO_IP == protocol) {
+				protocol = answer->protocol;
+				break;
+			}
+			if (IPPROTO_IP == answer->protocol)
+				break;
+		}
+		answer = NULL;
+	}
+
+	err = -ESOCKTNOSUPPORT;
+	if (!answer)
+		goto out_rcu_unlock;
+	err = -EPERM;
+	if (answer->capability > 0 && !capable(answer->capability))
+		goto out_rcu_unlock;
+	err = -EPROTONOSUPPORT;
+	if (!protocol)
+		goto out_rcu_unlock;
+
+	sock->ops = answer->ops;
+	answer_prot = answer->prot;
+	answer_no_check = answer->no_check;
+	answer_flags = answer->flags;
+	rcu_read_unlock();
+
+	BUG_TRAP(answer_prot->slab != NULL);
+
+	err = -ENOBUFS;
+	sk = sk_alloc(PF_INET, GFP_KERNEL, answer_prot, 1);
+	if (sk == NULL)
+		goto out;
+
+	err = 0;
+	sk->sk_no_check = answer_no_check;
+	if (INET_PROTOSW_REUSE & answer_flags)
+		sk->sk_reuse = 1;
+
+	inet = inet_sk(sk);
+
+	if (SOCK_RAW == sock->type) {
+		inet->num = protocol;
+		if (IPPROTO_RAW == protocol)
+			inet->hdrincl = 1;
+	}
+
+	if (ipv4_config.no_pmtu_disc)
+		inet->pmtudisc = IP_PMTUDISC_DONT;
+	else
+		inet->pmtudisc = IP_PMTUDISC_WANT;
+
+	inet->id = 0;
+
+	sock_init_data(sock, sk);
+
+	sk->sk_destruct	   = inet_sock_destruct;
+	sk->sk_family	   = PF_INET;
+	sk->sk_protocol	   = protocol;
+	sk->sk_backlog_rcv = sk->sk_prot->backlog_rcv;
+
+	inet->uc_ttl	= -1;
+	inet->mc_loop	= 1;
+	inet->mc_ttl	= 1;
+	inet->mc_index	= 0;
+	inet->mc_list	= NULL;
+
+#ifdef INET_REFCNT_DEBUG
+	atomic_inc(&inet_sock_nr);
+#endif
+
+	if (inet->num) {
+		/* It assumes that any protocol which allows
+		 * the user to assign a number at socket
+		 * creation time automatically
+		 * shares.
+		 */
+		inet->sport = htons(inet->num);
+		/* Add to protocol hash chains. */
+		sk->sk_prot->hash(sk);
+	}
+
+	if (sk->sk_prot->init) {
+		err = sk->sk_prot->init(sk);
+		if (err)
+			sk_common_release(sk);
+	}
+out:
+	return err;
+out_rcu_unlock:
+	rcu_read_unlock();
+	goto out;
+}
+
+
+/*
+ *	The peer socket should always be NULL (or else). When we call this
+ *	function we are destroying the object and from then on nobody
+ *	should refer to it.
+ */
+int inet_release(struct socket *sock)
+{
+	struct sock *sk = sock->sk;
+
+	if (sk) {
+		long timeout;
+
+		/* Applications forget to leave groups before exiting */
+		ip_mc_drop_socket(sk);
+
+		/* If linger is set, we don't return until the close
+		 * is complete.  Otherwise we return immediately. The
+		 * actually closing is done the same either way.
+		 *
+		 * If the close is due to the process exiting, we never
+		 * linger..
+		 */
+		timeout = 0;
+		if (sock_flag(sk, SOCK_LINGER) &&
+		    !(current->flags & PF_EXITING))
+			timeout = sk->sk_lingertime;
+		sock->sk = NULL;
+		sk->sk_prot->close(sk, timeout);
+	}
+	return 0;
+}
+
+/* It is off by default, see below. */
+int sysctl_ip_nonlocal_bind;
+
+int inet_bind(struct socket *sock, struct sockaddr *uaddr, int addr_len)
+{
+	struct sockaddr_in *addr = (struct sockaddr_in *)uaddr;
+	struct sock *sk = sock->sk;
+	struct inet_sock *inet = inet_sk(sk);
+	unsigned short snum;
+	int chk_addr_ret;
+	int err;
+
+	/* If the socket has its own bind function then use it. (RAW) */
+	if (sk->sk_prot->bind) {
+		err = sk->sk_prot->bind(sk, uaddr, addr_len);
+		goto out;
+	}
+	err = -EINVAL;
+	if (addr_len < sizeof(struct sockaddr_in))
+		goto out;
+
+	chk_addr_ret = inet_addr_type(addr->sin_addr.s_addr);
+
+	/* Not specified by any standard per-se, however it breaks too
+	 * many applications when removed.  It is unfortunate since
+	 * allowing applications to make a non-local bind solves
+	 * several problems with systems using dynamic addressing.
+	 * (ie. your servers still start up even if your ISDN link
+	 *  is temporarily down)
+	 */
+	err = -EADDRNOTAVAIL;
+	if (!sysctl_ip_nonlocal_bind &&
+	    !inet->freebind &&
+	    addr->sin_addr.s_addr != INADDR_ANY &&
+	    chk_addr_ret != RTN_LOCAL &&
+	    chk_addr_ret != RTN_MULTICAST &&
+	    chk_addr_ret != RTN_BROADCAST)
+		goto out;
+
+	snum = ntohs(addr->sin_port);
+	err = -EACCES;
+	if (snum && snum < PROT_SOCK && !capable(CAP_NET_BIND_SERVICE))
+		goto out;
+
+	/*      We keep a pair of addresses. rcv_saddr is the one
+	 *      used by hash lookups, and saddr is used for transmit.
+	 *
+	 *      In the BSD API these are the same except where it
+	 *      would be illegal to use them (multicast/broadcast) in
+	 *      which case the sending device address is used.
+	 */
+	lock_sock(sk);
+
+	/* Check these errors (active socket, double bind). */
+	err = -EINVAL;
+	if (sk->sk_state != TCP_CLOSE || inet->num)
+		goto out_release_sock;
+
+	inet->rcv_saddr = inet->saddr = addr->sin_addr.s_addr;
+	if (chk_addr_ret == RTN_MULTICAST || chk_addr_ret == RTN_BROADCAST)
+		inet->saddr = 0;  /* Use device */
+
+	/* Make sure we are allowed to bind here. */
+	if (sk->sk_prot->get_port(sk, snum)) {
+		inet->saddr = inet->rcv_saddr = 0;
+		err = -EADDRINUSE;
+		goto out_release_sock;
+	}
+
+	if (inet->rcv_saddr)
+		sk->sk_userlocks |= SOCK_BINDADDR_LOCK;
+	if (snum)
+		sk->sk_userlocks |= SOCK_BINDPORT_LOCK;
+	inet->sport = htons(inet->num);
+	inet->daddr = 0;
+	inet->dport = 0;
+	sk_dst_reset(sk);
+	err = 0;
+out_release_sock:
+	release_sock(sk);
+out:
+	return err;
+}
+
+int inet_dgram_connect(struct socket *sock, struct sockaddr * uaddr,
+		       int addr_len, int flags)
+{
+	struct sock *sk = sock->sk;
+
+	if (uaddr->sa_family == AF_UNSPEC)
+		return sk->sk_prot->disconnect(sk, flags);
+
+	if (!inet_sk(sk)->num && inet_autobind(sk))
+		return -EAGAIN;
+	return sk->sk_prot->connect(sk, (struct sockaddr *)uaddr, addr_len);
+}
+
+static long inet_wait_for_connect(struct sock *sk, long timeo)
+{
+	DEFINE_WAIT(wait);
+
+	prepare_to_wait(sk->sk_sleep, &wait, TASK_INTERRUPTIBLE);
+
+	/* Basic assumption: if someone sets sk->sk_err, he _must_
+	 * change state of the socket from TCP_SYN_*.
+	 * Connect() does not allow to get error notifications
+	 * without closing the socket.
+	 */
+	while ((1 << sk->sk_state) & (TCPF_SYN_SENT | TCPF_SYN_RECV)) {
+		release_sock(sk);
+		timeo = schedule_timeout(timeo);
+		lock_sock(sk);
+		if (signal_pending(current) || !timeo)
+			break;
+		prepare_to_wait(sk->sk_sleep, &wait, TASK_INTERRUPTIBLE);
+	}
+	finish_wait(sk->sk_sleep, &wait);
+	return timeo;
+}
+
+/*
+ *	Connect to a remote host. There is regrettably still a little
+ *	TCP 'magic' in here.
+ */
+int inet_stream_connect(struct socket *sock, struct sockaddr *uaddr,
+			int addr_len, int flags)
+{
+	struct sock *sk = sock->sk;
+	int err;
+	long timeo;
+
+	lock_sock(sk);
+
+	if (uaddr->sa_family == AF_UNSPEC) {
+		err = sk->sk_prot->disconnect(sk, flags);
+		sock->state = err ? SS_DISCONNECTING : SS_UNCONNECTED;
+		goto out;
+	}
+
+	switch (sock->state) {
+	default:
+		err = -EINVAL;
+		goto out;
+	case SS_CONNECTED:
+		err = -EISCONN;
+		goto out;
+	case SS_CONNECTING:
+		err = -EALREADY;
+		/* Fall out of switch with err, set for this state */
+		break;
+	case SS_UNCONNECTED:
+		err = -EISCONN;
+		if (sk->sk_state != TCP_CLOSE)
+			goto out;
+
+		err = sk->sk_prot->connect(sk, uaddr, addr_len);
+		if (err < 0)
+			goto out;
+
+  		sock->state = SS_CONNECTING;
+
+		/* Just entered SS_CONNECTING state; the only
+		 * difference is that return value in non-blocking
+		 * case is EINPROGRESS, rather than EALREADY.
+		 */
+		err = -EINPROGRESS;
+		break;
+	}
+
+	timeo = sock_sndtimeo(sk, flags & O_NONBLOCK);
+
+	if ((1 << sk->sk_state) & (TCPF_SYN_SENT | TCPF_SYN_RECV)) {
+		/* Error code is set above */
+		if (!timeo || !inet_wait_for_connect(sk, timeo))
+			goto out;
+
+		err = sock_intr_errno(timeo);
+		if (signal_pending(current))
+			goto out;
+	}
+
+	/* Connection was closed by RST, timeout, ICMP error
+	 * or another process disconnected us.
+	 */
+	if (sk->sk_state == TCP_CLOSE)
+		goto sock_error;
+
+	/* sk->sk_err may be not zero now, if RECVERR was ordered by user
+	 * and error was received after socket entered established state.
+	 * Hence, it is handled normally after connect() return successfully.
+	 */
+
+	sock->state = SS_CONNECTED;
+	err = 0;
+out:
+	release_sock(sk);
+	return err;
+
+sock_error:
+	err = sock_error(sk) ? : -ECONNABORTED;
+	sock->state = SS_UNCONNECTED;
+	if (sk->sk_prot->disconnect(sk, flags))
+		sock->state = SS_DISCONNECTING;
+	goto out;
+}
+
+/*
+ *	Accept a pending connection. The TCP layer now gives BSD semantics.
+ */
+
+int inet_accept(struct socket *sock, struct socket *newsock, int flags)
+{
+	struct sock *sk1 = sock->sk;
+	int err = -EINVAL;
+	struct sock *sk2 = sk1->sk_prot->accept(sk1, flags, &err);
+
+	if (!sk2)
+		goto do_err;
+
+	lock_sock(sk2);
+
+	BUG_TRAP((1 << sk2->sk_state) &
+		 (TCPF_ESTABLISHED | TCPF_CLOSE_WAIT | TCPF_CLOSE));
+
+	sock_graft(sk2, newsock);
+
+	newsock->state = SS_CONNECTED;
+	err = 0;
+	release_sock(sk2);
+do_err:
+	return err;
+}
+
+
+/*
+ *	This does both peername and sockname.
+ */
+int inet_getname(struct socket *sock, struct sockaddr *uaddr,
+			int *uaddr_len, int peer)
+{
+	struct sock *sk		= sock->sk;
+	struct inet_sock *inet	= inet_sk(sk);
+	struct sockaddr_in *sin	= (struct sockaddr_in *)uaddr;
+
+	sin->sin_family = AF_INET;
+	if (peer) {
+		if (!inet->dport ||
+		    (((1 << sk->sk_state) & (TCPF_CLOSE | TCPF_SYN_SENT)) &&
+		     peer == 1))
+			return -ENOTCONN;
+		sin->sin_port = inet->dport;
+		sin->sin_addr.s_addr = inet->daddr;
+	} else {
+		__u32 addr = inet->rcv_saddr;
+		if (!addr)
+			addr = inet->saddr;
+		sin->sin_port = inet->sport;
+		sin->sin_addr.s_addr = addr;
+	}
+	memset(sin->sin_zero, 0, sizeof(sin->sin_zero));
+	*uaddr_len = sizeof(*sin);
+	return 0;
+}
+
+int inet_sendmsg(struct kiocb *iocb, struct socket *sock, struct msghdr *msg,
+		 size_t size)
+{
+	struct sock *sk = sock->sk;
+
+	/* We may need to bind the socket. */
+	if (!inet_sk(sk)->num && inet_autobind(sk))
+		return -EAGAIN;
+
+	return sk->sk_prot->sendmsg(iocb, sk, msg, size);
+}
+
+
+static ssize_t inet_sendpage(struct socket *sock, struct page *page, int offset, size_t size, int flags)
+{
+	struct sock *sk = sock->sk;
+
+	/* We may need to bind the socket. */
+	if (!inet_sk(sk)->num && inet_autobind(sk))
+		return -EAGAIN;
+
+	if (sk->sk_prot->sendpage)
+		return sk->sk_prot->sendpage(sk, page, offset, size, flags);
+	return sock_no_sendpage(sock, page, offset, size, flags);
+}
+
+
+int inet_shutdown(struct socket *sock, int how)
+{
+	struct sock *sk = sock->sk;
+	int err = 0;
+
+	/* This should really check to make sure
+	 * the socket is a TCP socket. (WHY AC...)
+	 */
+	how++; /* maps 0->1 has the advantage of making bit 1 rcvs and
+		       1->2 bit 2 snds.
+		       2->3 */
+	if ((how & ~SHUTDOWN_MASK) || !how)	/* MAXINT->0 */
+		return -EINVAL;
+
+	lock_sock(sk);
+	if (sock->state == SS_CONNECTING) {
+		if ((1 << sk->sk_state) &
+		    (TCPF_SYN_SENT | TCPF_SYN_RECV | TCPF_CLOSE))
+			sock->state = SS_DISCONNECTING;
+		else
+			sock->state = SS_CONNECTED;
+	}
+
+	switch (sk->sk_state) {
+	case TCP_CLOSE:
+		err = -ENOTCONN;
+		/* Hack to wake up other listeners, who can poll for
+		   POLLHUP, even on eg. unconnected UDP sockets -- RR */
+	default:
+		sk->sk_shutdown |= how;
+		if (sk->sk_prot->shutdown)
+			sk->sk_prot->shutdown(sk, how);
+		break;
+
+	/* Remaining two branches are temporary solution for missing
+	 * close() in multithreaded environment. It is _not_ a good idea,
+	 * but we have no choice until close() is repaired at VFS level.
+	 */
+	case TCP_LISTEN:
+		if (!(how & RCV_SHUTDOWN))
+			break;
+		/* Fall through */
+	case TCP_SYN_SENT:
+		err = sk->sk_prot->disconnect(sk, O_NONBLOCK);
+		sock->state = err ? SS_DISCONNECTING : SS_UNCONNECTED;
+		break;
+	}
+
+	/* Wake up anyone sleeping in poll. */
+	sk->sk_state_change(sk);
+	release_sock(sk);
+	return err;
+}
+
+/*
+ *	ioctl() calls you can issue on an INET socket. Most of these are
+ *	device configuration and stuff and very rarely used. Some ioctls
+ *	pass on to the socket itself.
+ *
+ *	NOTE: I like the idea of a module for the config stuff. ie ifconfig
+ *	loads the devconfigure module does its configuring and unloads it.
+ *	There's a good 20K of config code hanging around the kernel.
+ */
+
+int inet_ioctl(struct socket *sock, unsigned int cmd, unsigned long arg)
+{
+	struct sock *sk = sock->sk;
+	int err = 0;
+
+	switch (cmd) {
+		case SIOCGSTAMP:
+			err = sock_get_timestamp(sk, (struct timeval __user *)arg);
+			break;
+		case SIOCADDRT:
+		case SIOCDELRT:
+		case SIOCRTMSG:
+			err = ip_rt_ioctl(cmd, (void __user *)arg);
+			break;
+		case SIOCDARP:
+		case SIOCGARP:
+		case SIOCSARP:
+			err = arp_ioctl(cmd, (void __user *)arg);
+			break;
+		case SIOCGIFADDR:
+		case SIOCSIFADDR:
+		case SIOCGIFBRDADDR:
+		case SIOCSIFBRDADDR:
+		case SIOCGIFNETMASK:
+		case SIOCSIFNETMASK:
+		case SIOCGIFDSTADDR:
+		case SIOCSIFDSTADDR:
+		case SIOCSIFPFLAGS:
+		case SIOCGIFPFLAGS:
+		case SIOCSIFFLAGS:
+			err = devinet_ioctl(cmd, (void __user *)arg);
+			break;
+		default:
+			if (!sk->sk_prot->ioctl ||
+			    (err = sk->sk_prot->ioctl(sk, cmd, arg)) ==
+			    					-ENOIOCTLCMD)
+				err = dev_ioctl(cmd, (void __user *)arg);
+			break;
+	}
+	return err;
+}
+
+struct proto_ops inet_stream_ops = {
+	.family =	PF_INET,
+	.owner =	THIS_MODULE,
+	.release =	inet_release,
+	.bind =		inet_bind,
+	.connect =	inet_stream_connect,
+	.socketpair =	sock_no_socketpair,
+	.accept =	inet_accept,
+	.getname =	inet_getname,
+	.poll =		tcp_poll,
+	.ioctl =	inet_ioctl,
+	.listen =	inet_listen,
+	.shutdown =	inet_shutdown,
+	.setsockopt =	sock_common_setsockopt,
+	.getsockopt =	sock_common_getsockopt,
+	.sendmsg =	inet_sendmsg,
+	.recvmsg =	sock_common_recvmsg,
+	.mmap =		sock_no_mmap,
+	.sendpage =	tcp_sendpage
+};
+
+struct proto_ops inet_dgram_ops = {
+	.family =	PF_INET,
+	.owner =	THIS_MODULE,
+	.release =	inet_release,
+	.bind =		inet_bind,
+	.connect =	inet_dgram_connect,
+	.socketpair =	sock_no_socketpair,
+	.accept =	sock_no_accept,
+	.getname =	inet_getname,
+	.poll =		udp_poll,
+	.ioctl =	inet_ioctl,
+	.listen =	sock_no_listen,
+	.shutdown =	inet_shutdown,
+	.setsockopt =	sock_common_setsockopt,
+	.getsockopt =	sock_common_getsockopt,
+	.sendmsg =	inet_sendmsg,
+	.recvmsg =	sock_common_recvmsg,
+	.mmap =		sock_no_mmap,
+	.sendpage =	inet_sendpage,
+};
+
+/*
+ * For SOCK_RAW sockets; should be the same as inet_dgram_ops but without
+ * udp_poll
+ */
+static struct proto_ops inet_sockraw_ops = {
+	.family =	PF_INET,
+	.owner =	THIS_MODULE,
+	.release =	inet_release,
+	.bind =		inet_bind,
+	.connect =	inet_dgram_connect,
+	.socketpair =	sock_no_socketpair,
+	.accept =	sock_no_accept,
+	.getname =	inet_getname,
+	.poll =		datagram_poll,
+	.ioctl =	inet_ioctl,
+	.listen =	sock_no_listen,
+	.shutdown =	inet_shutdown,
+	.setsockopt =	sock_common_setsockopt,
+	.getsockopt =	sock_common_getsockopt,
+	.sendmsg =	inet_sendmsg,
+	.recvmsg =	sock_common_recvmsg,
+	.mmap =		sock_no_mmap,
+	.sendpage =	inet_sendpage,
+};
+
+static struct net_proto_family inet_family_ops = {
+	.family = PF_INET,
+	.create = inet_create,
+	.owner	= THIS_MODULE,
+};
+
+
+extern void tcp_init(void);
+extern void tcp_v4_init(struct net_proto_family *);
+
+/* Upon startup we insert all the elements in inetsw_array[] into
+ * the linked list inetsw.
+ */
+static struct inet_protosw inetsw_array[] =
+{
+        {
+                .type =       SOCK_STREAM,
+                .protocol =   IPPROTO_TCP,
+                .prot =       &tcp_prot,
+                .ops =        &inet_stream_ops,
+                .capability = -1,
+                .no_check =   0,
+                .flags =      INET_PROTOSW_PERMANENT,
+        },
+
+        {
+                .type =       SOCK_DGRAM,
+                .protocol =   IPPROTO_UDP,
+                .prot =       &udp_prot,
+                .ops =        &inet_dgram_ops,
+                .capability = -1,
+                .no_check =   UDP_CSUM_DEFAULT,
+                .flags =      INET_PROTOSW_PERMANENT,
+       },
+        
+
+       {
+               .type =       SOCK_RAW,
+               .protocol =   IPPROTO_IP,	/* wild card */
+               .prot =       &raw_prot,
+               .ops =        &inet_sockraw_ops,
+               .capability = CAP_NET_RAW,
+               .no_check =   UDP_CSUM_DEFAULT,
+               .flags =      INET_PROTOSW_REUSE,
+       }
+};
+
+#define INETSW_ARRAY_LEN (sizeof(inetsw_array) / sizeof(struct inet_protosw))
+
+void inet_register_protosw(struct inet_protosw *p)
+{
+	struct list_head *lh;
+	struct inet_protosw *answer;
+	int protocol = p->protocol;
+	struct list_head *last_perm;
+
+	spin_lock_bh(&inetsw_lock);
+
+	if (p->type >= SOCK_MAX)
+		goto out_illegal;
+
+	/* If we are trying to override a permanent protocol, bail. */
+	answer = NULL;
+	last_perm = &inetsw[p->type];
+	list_for_each(lh, &inetsw[p->type]) {
+		answer = list_entry(lh, struct inet_protosw, list);
+
+		/* Check only the non-wild match. */
+		if (INET_PROTOSW_PERMANENT & answer->flags) {
+			if (protocol == answer->protocol)
+				break;
+			last_perm = lh;
+		}
+
+		answer = NULL;
+	}
+	if (answer)
+		goto out_permanent;
+
+	/* Add the new entry after the last permanent entry if any, so that
+	 * the new entry does not override a permanent entry when matched with
+	 * a wild-card protocol. But it is allowed to override any existing
+	 * non-permanent entry.  This means that when we remove this entry, the 
+	 * system automatically returns to the old behavior.
+	 */
+	list_add_rcu(&p->list, last_perm);
+out:
+	spin_unlock_bh(&inetsw_lock);
+
+	synchronize_net();
+
+	return;
+
+out_permanent:
+	printk(KERN_ERR "Attempt to override permanent protocol %d.\n",
+	       protocol);
+	goto out;
+
+out_illegal:
+	printk(KERN_ERR
+	       "Ignoring attempt to register invalid socket type %d.\n",
+	       p->type);
+	goto out;
+}
+
+void inet_unregister_protosw(struct inet_protosw *p)
+{
+	if (INET_PROTOSW_PERMANENT & p->flags) {
+		printk(KERN_ERR
+		       "Attempt to unregister permanent protocol %d.\n",
+		       p->protocol);
+	} else {
+		spin_lock_bh(&inetsw_lock);
+		list_del_rcu(&p->list);
+		spin_unlock_bh(&inetsw_lock);
+
+		synchronize_net();
+	}
+}
+
+#ifdef CONFIG_IP_MULTICAST
+static struct net_protocol igmp_protocol = {
+	.handler =	igmp_rcv,
+};
+#endif
+
+static struct net_protocol tcp_protocol = {
+	.handler =	tcp_v4_rcv,
+	.err_handler =	tcp_v4_err,
+	.no_policy =	1,
+};
+
+static struct net_protocol udp_protocol = {
+	.handler =	udp_rcv,
+	.err_handler =	udp_err,
+	.no_policy =	1,
+};
+
+static struct net_protocol icmp_protocol = {
+	.handler =	icmp_rcv,
+};
+
+static int __init init_ipv4_mibs(void)
+{
+	net_statistics[0] = alloc_percpu(struct linux_mib);
+	net_statistics[1] = alloc_percpu(struct linux_mib);
+	ip_statistics[0] = alloc_percpu(struct ipstats_mib);
+	ip_statistics[1] = alloc_percpu(struct ipstats_mib);
+	icmp_statistics[0] = alloc_percpu(struct icmp_mib);
+	icmp_statistics[1] = alloc_percpu(struct icmp_mib);
+	tcp_statistics[0] = alloc_percpu(struct tcp_mib);
+	tcp_statistics[1] = alloc_percpu(struct tcp_mib);
+	udp_statistics[0] = alloc_percpu(struct udp_mib);
+	udp_statistics[1] = alloc_percpu(struct udp_mib);
+	if (!
+	    (net_statistics[0] && net_statistics[1] && ip_statistics[0]
+	     && ip_statistics[1] && tcp_statistics[0] && tcp_statistics[1]
+	     && udp_statistics[0] && udp_statistics[1]))
+		return -ENOMEM;
+
+	(void) tcp_mib_init();
+
+	return 0;
+}
+
+static int ipv4_proc_init(void);
+extern void ipfrag_init(void);
+
+static int __init inet_init(void)
+{
+	struct sk_buff *dummy_skb;
+	struct inet_protosw *q;
+	struct list_head *r;
+	int rc = -EINVAL;
+
+	if (sizeof(struct inet_skb_parm) > sizeof(dummy_skb->cb)) {
+		printk(KERN_CRIT "%s: panic\n", __FUNCTION__);
+		goto out;
+	}
+
+	rc = proto_register(&tcp_prot, 1);
+	if (rc)
+		goto out;
+
+	rc = proto_register(&udp_prot, 1);
+	if (rc)
+		goto out_unregister_tcp_proto;
+
+	rc = proto_register(&raw_prot, 1);
+	if (rc)
+		goto out_unregister_udp_proto;
+
+	/*
+	 *	Tell SOCKET that we are alive... 
+	 */
+
+  	(void)sock_register(&inet_family_ops);
+
+	/*
+	 *	Add all the base protocols.
+	 */
+
+	if (inet_add_protocol(&icmp_protocol, IPPROTO_ICMP) < 0)
+		printk(KERN_CRIT "inet_init: Cannot add ICMP protocol\n");
+	if (inet_add_protocol(&udp_protocol, IPPROTO_UDP) < 0)
+		printk(KERN_CRIT "inet_init: Cannot add UDP protocol\n");
+	if (inet_add_protocol(&tcp_protocol, IPPROTO_TCP) < 0)
+		printk(KERN_CRIT "inet_init: Cannot add TCP protocol\n");
+#ifdef CONFIG_IP_MULTICAST
+	if (inet_add_protocol(&igmp_protocol, IPPROTO_IGMP) < 0)
+		printk(KERN_CRIT "inet_init: Cannot add IGMP protocol\n");
+#endif
+
+	/* Register the socket-side information for inet_create. */
+	for (r = &inetsw[0]; r < &inetsw[SOCK_MAX]; ++r)
+		INIT_LIST_HEAD(r);
+
+	for (q = inetsw_array; q < &inetsw_array[INETSW_ARRAY_LEN]; ++q)
+		inet_register_protosw(q);
+
+	/*
+	 *	Set the ARP module up
+	 */
+
+	arp_init();
+
+  	/*
+  	 *	Set the IP module up
+  	 */
+
+	ip_init();
+
+	tcp_v4_init(&inet_family_ops);
+
+	/* Setup TCP slab cache for open requests. */
+	tcp_init();
+
+
+	/*
+	 *	Set the ICMP layer up
+	 */
+
+	icmp_init(&inet_family_ops);
+
+	/*
+	 *	Initialise the multicast router
+	 */
+#if defined(CONFIG_IP_MROUTE)
+	ip_mr_init();
+#endif
+	/*
+	 *	Initialise per-cpu ipv4 mibs
+	 */ 
+
+	if(init_ipv4_mibs())
+		printk(KERN_CRIT "inet_init: Cannot init ipv4 mibs\n"); ;
+	
+	ipv4_proc_init();
+
+	ipfrag_init();
+
+	rc = 0;
+out:
+	return rc;
+out_unregister_tcp_proto:
+	proto_unregister(&tcp_prot);
+out_unregister_udp_proto:
+	proto_unregister(&udp_prot);
+	goto out;
+}
+
+module_init(inet_init);
+
+/* ------------------------------------------------------------------------ */
+
+#ifdef CONFIG_PROC_FS
+extern int  fib_proc_init(void);
+extern void fib_proc_exit(void);
+extern int  ip_misc_proc_init(void);
+extern int  raw_proc_init(void);
+extern void raw_proc_exit(void);
+extern int  tcp4_proc_init(void);
+extern void tcp4_proc_exit(void);
+extern int  udp4_proc_init(void);
+extern void udp4_proc_exit(void);
+
+static int __init ipv4_proc_init(void)
+{
+	int rc = 0;
+
+	if (raw_proc_init())
+		goto out_raw;
+	if (tcp4_proc_init())
+		goto out_tcp;
+	if (udp4_proc_init())
+		goto out_udp;
+	if (fib_proc_init())
+		goto out_fib;
+	if (ip_misc_proc_init())
+		goto out_misc;
+out:
+	return rc;
+out_misc:
+	fib_proc_exit();
+out_fib:
+	udp4_proc_exit();
+out_udp:
+	tcp4_proc_exit();
+out_tcp:
+	raw_proc_exit();
+out_raw:
+	rc = -ENOMEM;
+	goto out;
+}
+
+#else /* CONFIG_PROC_FS */
+static int __init ipv4_proc_init(void)
+{
+	return 0;
+}
+#endif /* CONFIG_PROC_FS */
+
+MODULE_ALIAS_NETPROTO(PF_INET);
+
+EXPORT_SYMBOL(inet_accept);
+EXPORT_SYMBOL(inet_bind);
+EXPORT_SYMBOL(inet_dgram_connect);
+EXPORT_SYMBOL(inet_dgram_ops);
+EXPORT_SYMBOL(inet_getname);
+EXPORT_SYMBOL(inet_ioctl);
+EXPORT_SYMBOL(inet_listen);
+EXPORT_SYMBOL(inet_register_protosw);
+EXPORT_SYMBOL(inet_release);
+EXPORT_SYMBOL(inet_sendmsg);
+EXPORT_SYMBOL(inet_shutdown);
+EXPORT_SYMBOL(inet_sock_destruct);
+EXPORT_SYMBOL(inet_stream_connect);
+EXPORT_SYMBOL(inet_stream_ops);
+EXPORT_SYMBOL(inet_unregister_protosw);
+EXPORT_SYMBOL(net_statistics);
+
+#ifdef INET_REFCNT_DEBUG
+EXPORT_SYMBOL(inet_sock_nr);
+#endif
