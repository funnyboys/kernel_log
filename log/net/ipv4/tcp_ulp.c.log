commit 7b70973d7edb2f005511102d5a2e0116464a46a1
Author: Lorenz Bauer <lmb@cloudflare.com>
Date:   Mon Mar 9 11:12:32 2020 +0000

    bpf: sockmap: Only check ULP for TCP sockets
    
    The sock map code checks that a socket does not have an active upper
    layer protocol before inserting it into the map. This requires casting
    via inet_csk, which isn't valid for UDP sockets.
    
    Guard checks for ULP by checking inet_sk(sk)->is_icsk first.
    
    Signed-off-by: Lorenz Bauer <lmb@cloudflare.com>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Reviewed-by: Jakub Sitnicki <jakub@cloudflare.com>
    Acked-by: John Fastabend <john.fastabend@gmail.com>
    Link: https://lore.kernel.org/bpf/20200309111243.6982-2-lmb@cloudflare.com

diff --git a/net/ipv4/tcp_ulp.c b/net/ipv4/tcp_ulp.c
index 2703f24c5d1a..7c27aa629af1 100644
--- a/net/ipv4/tcp_ulp.c
+++ b/net/ipv4/tcp_ulp.c
@@ -105,13 +105,6 @@ void tcp_update_ulp(struct sock *sk, struct proto *proto,
 {
 	struct inet_connection_sock *icsk = inet_csk(sk);
 
-	if (!icsk->icsk_ulp_ops) {
-		sk->sk_write_space = write_space;
-		/* Pairs with lockless read in sk_clone_lock() */
-		WRITE_ONCE(sk->sk_prot, proto);
-		return;
-	}
-
 	if (icsk->icsk_ulp_ops->update)
 		icsk->icsk_ulp_ops->update(sk, proto, write_space);
 }

commit 958a93c15466c69e2ec531332e67011f549943bd
Author: Amol Grover <frextrite@gmail.com>
Date:   Fri Feb 21 20:45:38 2020 +0530

    tcp, ulp: Pass lockdep expression to RCU lists
    
    tcp_ulp_list is traversed using list_for_each_entry_rcu
    outside an RCU read-side critical section but under the protection
    of tcp_ulp_list_lock.
    
    Hence, add corresponding lockdep expression to silence false-positive
    warnings, and harden RCU lists.t
    
    Signed-off-by: Amol Grover <frextrite@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/tcp_ulp.c b/net/ipv4/tcp_ulp.c
index 6c43fa189195..2703f24c5d1a 100644
--- a/net/ipv4/tcp_ulp.c
+++ b/net/ipv4/tcp_ulp.c
@@ -22,7 +22,8 @@ static struct tcp_ulp_ops *tcp_ulp_find(const char *name)
 {
 	struct tcp_ulp_ops *e;
 
-	list_for_each_entry_rcu(e, &tcp_ulp_list, list) {
+	list_for_each_entry_rcu(e, &tcp_ulp_list, list,
+				lockdep_is_held(&tcp_ulp_list_lock)) {
 		if (strcmp(e->name, name) == 0)
 			return e;
 	}

commit b8e202d1d1d0f182f01062804efb523ea9a9008c
Author: Jakub Sitnicki <jakub@cloudflare.com>
Date:   Tue Feb 18 17:10:13 2020 +0000

    net, sk_msg: Annotate lockless access to sk_prot on clone
    
    sk_msg and ULP frameworks override protocol callbacks pointer in
    sk->sk_prot, while tcp accesses it locklessly when cloning the listening
    socket, that is with neither sk_lock nor sk_callback_lock held.
    
    Once we enable use of listening sockets with sockmap (and hence sk_msg),
    there will be shared access to sk->sk_prot if socket is getting cloned
    while being inserted/deleted to/from the sockmap from another CPU:
    
    Read side:
    
    tcp_v4_rcv
      sk = __inet_lookup_skb(...)
      tcp_check_req(sk)
        inet_csk(sk)->icsk_af_ops->syn_recv_sock
          tcp_v4_syn_recv_sock
            tcp_create_openreq_child
              inet_csk_clone_lock
                sk_clone_lock
                  READ_ONCE(sk->sk_prot)
    
    Write side:
    
    sock_map_ops->map_update_elem
      sock_map_update_elem
        sock_map_update_common
          sock_map_link_no_progs
            tcp_bpf_init
              tcp_bpf_update_sk_prot
                sk_psock_update_proto
                  WRITE_ONCE(sk->sk_prot, ops)
    
    sock_map_ops->map_delete_elem
      sock_map_delete_elem
        __sock_map_delete
         sock_map_unref
           sk_psock_put
             sk_psock_drop
               sk_psock_restore_proto
                 tcp_update_ulp
                   WRITE_ONCE(sk->sk_prot, proto)
    
    Mark the shared access with READ_ONCE/WRITE_ONCE annotations.
    
    Signed-off-by: Jakub Sitnicki <jakub@cloudflare.com>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Link: https://lore.kernel.org/bpf/20200218171023.844439-2-jakub@cloudflare.com

diff --git a/net/ipv4/tcp_ulp.c b/net/ipv4/tcp_ulp.c
index 38d3ad141161..6c43fa189195 100644
--- a/net/ipv4/tcp_ulp.c
+++ b/net/ipv4/tcp_ulp.c
@@ -106,7 +106,8 @@ void tcp_update_ulp(struct sock *sk, struct proto *proto,
 
 	if (!icsk->icsk_ulp_ops) {
 		sk->sk_write_space = write_space;
-		sk->sk_prot = proto;
+		/* Pairs with lockless read in sk_clone_lock() */
+		WRITE_ONCE(sk->sk_prot, proto);
 		return;
 	}
 

commit 33bfe20dd7117dd81fd896a53f743a233e1ad64f
Author: John Fastabend <john.fastabend@gmail.com>
Date:   Sat Jan 11 06:12:01 2020 +0000

    bpf: Sockmap/tls, push write_space updates through ulp updates
    
    When sockmap sock with TLS enabled is removed we cleanup bpf/psock state
    and call tcp_update_ulp() to push updates to TLS ULP on top. However, we
    don't push the write_space callback up and instead simply overwrite the
    op with the psock stored previous op. This may or may not be correct so
    to ensure we don't overwrite the TLS write space hook pass this field to
    the ULP and have it fixup the ctx.
    
    This completes a previous fix that pushed the ops through to the ULP
    but at the time missed doing this for write_space, presumably because
    write_space TLS hook was added around the same time.
    
    Fixes: 95fa145479fbc ("bpf: sockmap/tls, close can race with map free")
    Signed-off-by: John Fastabend <john.fastabend@gmail.com>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Reviewed-by: Jakub Sitnicki <jakub@cloudflare.com>
    Acked-by: Jonathan Lemon <jonathan.lemon@gmail.com>
    Cc: stable@vger.kernel.org
    Link: https://lore.kernel.org/bpf/20200111061206.8028-4-john.fastabend@gmail.com

diff --git a/net/ipv4/tcp_ulp.c b/net/ipv4/tcp_ulp.c
index 12ab5db2b71c..38d3ad141161 100644
--- a/net/ipv4/tcp_ulp.c
+++ b/net/ipv4/tcp_ulp.c
@@ -99,17 +99,19 @@ void tcp_get_available_ulp(char *buf, size_t maxlen)
 	rcu_read_unlock();
 }
 
-void tcp_update_ulp(struct sock *sk, struct proto *proto)
+void tcp_update_ulp(struct sock *sk, struct proto *proto,
+		    void (*write_space)(struct sock *sk))
 {
 	struct inet_connection_sock *icsk = inet_csk(sk);
 
 	if (!icsk->icsk_ulp_ops) {
+		sk->sk_write_space = write_space;
 		sk->sk_prot = proto;
 		return;
 	}
 
 	if (icsk->icsk_ulp_ops->update)
-		icsk->icsk_ulp_ops->update(sk, proto);
+		icsk->icsk_ulp_ops->update(sk, proto, write_space);
 }
 
 void tcp_cleanup_ulp(struct sock *sk)

commit 9bb59a21f53e7231696257d5e6283a4fbacfb43f
Author: Hangbin Liu <liuhangbin@gmail.com>
Date:   Wed Nov 20 16:38:08 2019 +0800

    tcp: warn if offset reach the maxlen limit when using snprintf
    
    snprintf returns the number of chars that would be written, not number
    of chars that were actually written. As such, 'offs' may get larger than
    'tbl.maxlen', causing the 'tbl.maxlen - offs' being < 0, and since the
    parameter is size_t, it would overflow.
    
    Since using scnprintf may hide the limit error, while the buffer is still
    enough now, let's just add a WARN_ON_ONCE in case it reach the limit
    in future.
    
    v2: Use WARN_ON_ONCE as Jiri and Eric suggested.
    
    Suggested-by: Jiri Benc <jbenc@redhat.com>
    Signed-off-by: Hangbin Liu <liuhangbin@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/tcp_ulp.c b/net/ipv4/tcp_ulp.c
index 4849edb62d52..12ab5db2b71c 100644
--- a/net/ipv4/tcp_ulp.c
+++ b/net/ipv4/tcp_ulp.c
@@ -92,6 +92,9 @@ void tcp_get_available_ulp(char *buf, size_t maxlen)
 		offs += snprintf(buf + offs, maxlen - offs,
 				 "%s%s",
 				 offs == 0 ? "" : " ", ulp_ops->name);
+
+		if (WARN_ON_ONCE(offs >= maxlen))
+			break;
 	}
 	rcu_read_unlock();
 }

commit 95fa145479fbc0a0c1fd3274ceb42ec03c042a4a
Author: John Fastabend <john.fastabend@gmail.com>
Date:   Fri Jul 19 10:29:22 2019 -0700

    bpf: sockmap/tls, close can race with map free
    
    When a map free is called and in parallel a socket is closed we
    have two paths that can potentially reset the socket prot ops, the
    bpf close() path and the map free path. This creates a problem
    with which prot ops should be used from the socket closed side.
    
    If the map_free side completes first then we want to call the
    original lowest level ops. However, if the tls path runs first
    we want to call the sockmap ops. Additionally there was no locking
    around prot updates in TLS code paths so the prot ops could
    be changed multiple times once from TLS path and again from sockmap
    side potentially leaving ops pointed at either TLS or sockmap
    when psock and/or tls context have already been destroyed.
    
    To fix this race first only update ops inside callback lock
    so that TLS, sockmap and lowest level all agree on prot state.
    Second and a ULP callback update() so that lower layers can
    inform the upper layer when they are being removed allowing the
    upper layer to reset prot ops.
    
    This gets us close to allowing sockmap and tls to be stacked
    in arbitrary order but will save that patch for *next trees.
    
    v4:
     - make sure we don't free things for device;
     - remove the checks which swap the callbacks back
       only if TLS is at the top.
    
    Reported-by: syzbot+06537213db7ba2745c4a@syzkaller.appspotmail.com
    Fixes: 02c558b2d5d6 ("bpf: sockmap, support for msg_peek in sk_msg with redirect ingress")
    Signed-off-by: John Fastabend <john.fastabend@gmail.com>
    Signed-off-by: Jakub Kicinski <jakub.kicinski@netronome.com>
    Reviewed-by: Dirk van der Merwe <dirk.vandermerwe@netronome.com>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>

diff --git a/net/ipv4/tcp_ulp.c b/net/ipv4/tcp_ulp.c
index 3d8a1d835471..4849edb62d52 100644
--- a/net/ipv4/tcp_ulp.c
+++ b/net/ipv4/tcp_ulp.c
@@ -96,6 +96,19 @@ void tcp_get_available_ulp(char *buf, size_t maxlen)
 	rcu_read_unlock();
 }
 
+void tcp_update_ulp(struct sock *sk, struct proto *proto)
+{
+	struct inet_connection_sock *icsk = inet_csk(sk);
+
+	if (!icsk->icsk_ulp_ops) {
+		sk->sk_prot = proto;
+		return;
+	}
+
+	if (icsk->icsk_ulp_ops->update)
+		icsk->icsk_ulp_ops->update(sk, proto);
+}
+
 void tcp_cleanup_ulp(struct sock *sk)
 {
 	struct inet_connection_sock *icsk = inet_csk(sk);

commit 457c89965399115e5cd8bf38f9c597293405703d
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sun May 19 13:08:55 2019 +0100

    treewide: Add SPDX license identifier for missed files
    
    Add SPDX license identifiers to all files which:
    
     - Have no license information of any form
    
     - Have EXPORT_.*_SYMBOL_GPL inside which was used in the
       initial scan/conversion to ignore the file
    
    These files fall under the project license, GPL v2 only. The resulting SPDX
    license identifier is:
    
      GPL-2.0-only
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/net/ipv4/tcp_ulp.c b/net/ipv4/tcp_ulp.c
index 95df7f7f6328..3d8a1d835471 100644
--- a/net/ipv4/tcp_ulp.c
+++ b/net/ipv4/tcp_ulp.c
@@ -1,3 +1,4 @@
+// SPDX-License-Identifier: GPL-2.0-only
 /*
  * Pluggable TCP upper layer protocol support.
  *

commit aadd4355918fe6e9044a9042fa5968e0a0901681
Author: Daniel Borkmann <daniel@iogearbox.net>
Date:   Tue Oct 16 21:31:35 2018 +0200

    tcp, ulp: remove socket lock assertion on ULP cleanup
    
    Eric reported that syzkaller triggered a splat in tcp_cleanup_ulp()
    where assertion sock_owned_by_me() failed. This happened through
    inet_csk_prepare_forced_close() first releasing the socket lock,
    then calling into tcp_done(newsk) which is called after the
    inet_csk_prepare_forced_close() and therefore without the socket
    lock held. The sock_owned_by_me() assertion can generally be
    removed as the only place where tcp_cleanup_ulp() is called from
    now is out of inet_csk_destroy_sock() -> sk->sk_prot->destroy()
    where socket is in dead state and unreachable. Therefore, add a
    comment why the check is not needed instead.
    
    Fixes: 8b9088f806e1 ("tcp, ulp: enforce sock_owned_by_me upon ulp init and cleanup")
    Reported-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/tcp_ulp.c b/net/ipv4/tcp_ulp.c
index a9162aa11af9..95df7f7f6328 100644
--- a/net/ipv4/tcp_ulp.c
+++ b/net/ipv4/tcp_ulp.c
@@ -99,8 +99,10 @@ void tcp_cleanup_ulp(struct sock *sk)
 {
 	struct inet_connection_sock *icsk = inet_csk(sk);
 
-	sock_owned_by_me(sk);
-
+	/* No sock_owned_by_me() check here as at the time the
+	 * stack calls this function, the socket is dead and
+	 * about to be destroyed.
+	 */
 	if (!icsk->icsk_ulp_ops)
 		return;
 

commit 1243a51f6c05ecbb2c5c9e02fdcc1e7a06f76f26
Author: Daniel Borkmann <daniel@iogearbox.net>
Date:   Sat Oct 13 02:45:57 2018 +0200

    tcp, ulp: remove ulp bits from sockmap
    
    In order to prepare sockmap logic to be used in combination with kTLS
    we need to detangle it from ULP, and further split it in later commits
    into a generic API.
    
    Joint work with John.
    
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Signed-off-by: John Fastabend <john.fastabend@gmail.com>
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>

diff --git a/net/ipv4/tcp_ulp.c b/net/ipv4/tcp_ulp.c
index 34e96353f115..a9162aa11af9 100644
--- a/net/ipv4/tcp_ulp.c
+++ b/net/ipv4/tcp_ulp.c
@@ -6,7 +6,7 @@
  *
  */
 
-#include<linux/module.h>
+#include <linux/module.h>
 #include <linux/mm.h>
 #include <linux/types.h>
 #include <linux/list.h>
@@ -29,18 +29,6 @@ static struct tcp_ulp_ops *tcp_ulp_find(const char *name)
 	return NULL;
 }
 
-static struct tcp_ulp_ops *tcp_ulp_find_id(const int ulp)
-{
-	struct tcp_ulp_ops *e;
-
-	list_for_each_entry_rcu(e, &tcp_ulp_list, list) {
-		if (e->uid == ulp)
-			return e;
-	}
-
-	return NULL;
-}
-
 static const struct tcp_ulp_ops *__tcp_ulp_find_autoload(const char *name)
 {
 	const struct tcp_ulp_ops *ulp = NULL;
@@ -63,18 +51,6 @@ static const struct tcp_ulp_ops *__tcp_ulp_find_autoload(const char *name)
 	return ulp;
 }
 
-static const struct tcp_ulp_ops *__tcp_ulp_lookup(const int uid)
-{
-	const struct tcp_ulp_ops *ulp;
-
-	rcu_read_lock();
-	ulp = tcp_ulp_find_id(uid);
-	if (!ulp || !try_module_get(ulp->owner))
-		ulp = NULL;
-	rcu_read_unlock();
-	return ulp;
-}
-
 /* Attach new upper layer protocol to the list
  * of available protocols.
  */
@@ -135,56 +111,35 @@ void tcp_cleanup_ulp(struct sock *sk)
 	icsk->icsk_ulp_ops = NULL;
 }
 
-/* Change upper layer protocol for socket */
-int tcp_set_ulp(struct sock *sk, const char *name)
+static int __tcp_set_ulp(struct sock *sk, const struct tcp_ulp_ops *ulp_ops)
 {
 	struct inet_connection_sock *icsk = inet_csk(sk);
-	const struct tcp_ulp_ops *ulp_ops;
-	int err = 0;
+	int err;
 
-	sock_owned_by_me(sk);
+	err = -EEXIST;
 	if (icsk->icsk_ulp_ops)
-		return -EEXIST;
-
-	ulp_ops = __tcp_ulp_find_autoload(name);
-	if (!ulp_ops)
-		return -ENOENT;
-
-	if (!ulp_ops->user_visible) {
-		module_put(ulp_ops->owner);
-		return -ENOENT;
-	}
+		goto out_err;
 
 	err = ulp_ops->init(sk);
-	if (err) {
-		module_put(ulp_ops->owner);
-		return err;
-	}
+	if (err)
+		goto out_err;
 
 	icsk->icsk_ulp_ops = ulp_ops;
 	return 0;
+out_err:
+	module_put(ulp_ops->owner);
+	return err;
 }
 
-int tcp_set_ulp_id(struct sock *sk, int ulp)
+int tcp_set_ulp(struct sock *sk, const char *name)
 {
-	struct inet_connection_sock *icsk = inet_csk(sk);
 	const struct tcp_ulp_ops *ulp_ops;
-	int err;
 
 	sock_owned_by_me(sk);
-	if (icsk->icsk_ulp_ops)
-		return -EEXIST;
 
-	ulp_ops = __tcp_ulp_lookup(ulp);
+	ulp_ops = __tcp_ulp_find_autoload(name);
 	if (!ulp_ops)
 		return -ENOENT;
 
-	err = ulp_ops->init(sk);
-	if (err) {
-		module_put(ulp_ops->owner);
-		return err;
-	}
-
-	icsk->icsk_ulp_ops = ulp_ops;
-	return 0;
+	return __tcp_set_ulp(sk, ulp_ops);
 }

commit 8b9088f806e1ccd10c3d48b3b6d3d5d7855d92c5
Author: Daniel Borkmann <daniel@iogearbox.net>
Date:   Sat Oct 13 02:45:56 2018 +0200

    tcp, ulp: enforce sock_owned_by_me upon ulp init and cleanup
    
    Whenever the ULP data on the socket is mangled, enforce that the
    caller has the socket lock held as otherwise things may race with
    initialization and cleanup callbacks from ulp ops as both would
    mangle internal socket state.
    
    Joint work with John.
    
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Signed-off-by: John Fastabend <john.fastabend@gmail.com>
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>

diff --git a/net/ipv4/tcp_ulp.c b/net/ipv4/tcp_ulp.c
index a5995bb2eaca..34e96353f115 100644
--- a/net/ipv4/tcp_ulp.c
+++ b/net/ipv4/tcp_ulp.c
@@ -123,6 +123,8 @@ void tcp_cleanup_ulp(struct sock *sk)
 {
 	struct inet_connection_sock *icsk = inet_csk(sk);
 
+	sock_owned_by_me(sk);
+
 	if (!icsk->icsk_ulp_ops)
 		return;
 
@@ -140,6 +142,7 @@ int tcp_set_ulp(struct sock *sk, const char *name)
 	const struct tcp_ulp_ops *ulp_ops;
 	int err = 0;
 
+	sock_owned_by_me(sk);
 	if (icsk->icsk_ulp_ops)
 		return -EEXIST;
 
@@ -168,6 +171,7 @@ int tcp_set_ulp_id(struct sock *sk, int ulp)
 	const struct tcp_ulp_ops *ulp_ops;
 	int err;
 
+	sock_owned_by_me(sk);
 	if (icsk->icsk_ulp_ops)
 		return -EEXIST;
 

commit 90545cdc3f2b2ea700e24335610cd181e73756da
Author: Daniel Borkmann <daniel@iogearbox.net>
Date:   Thu Aug 16 21:49:07 2018 +0200

    tcp, ulp: fix leftover icsk_ulp_ops preventing sock from reattach
    
    I found that in BPF sockmap programs once we either delete a socket
    from the map or we updated a map slot and the old socket was purged
    from the map that these socket can never get reattached into a map
    even though their related psock has been dropped entirely at that
    point.
    
    Reason is that tcp_cleanup_ulp() leaves the old icsk->icsk_ulp_ops
    intact, so that on the next tcp_set_ulp_id() the kernel returns an
    -EEXIST thinking there is still some active ULP attached.
    
    BPF sockmap is the only one that has this issue as the other user,
    kTLS, only calls tcp_cleanup_ulp() from tcp_v4_destroy_sock() whereas
    sockmap semantics allow dropping the socket from the map with all
    related psock state being cleaned up.
    
    Fixes: 1aa12bdf1bfb ("bpf: sockmap, add sock close() hook to remove socks")
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Acked-by: John Fastabend <john.fastabend@gmail.com>
    Acked-by: Song Liu <songliubraving@fb.com>
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>

diff --git a/net/ipv4/tcp_ulp.c b/net/ipv4/tcp_ulp.c
index 7dd44b6156c7..a5995bb2eaca 100644
--- a/net/ipv4/tcp_ulp.c
+++ b/net/ipv4/tcp_ulp.c
@@ -129,6 +129,8 @@ void tcp_cleanup_ulp(struct sock *sk)
 	if (icsk->icsk_ulp_ops->release)
 		icsk->icsk_ulp_ops->release(sk);
 	module_put(icsk->icsk_ulp_ops->owner);
+
+	icsk->icsk_ulp_ops = NULL;
 }
 
 /* Change upper layer protocol for socket */

commit 037b0b86ecf5646f8eae777d8b52ff8b401692ec
Author: Daniel Borkmann <daniel@iogearbox.net>
Date:   Thu Aug 16 21:49:06 2018 +0200

    tcp, ulp: add alias for all ulp modules
    
    Lets not turn the TCP ULP lookup into an arbitrary module loader as
    we only intend to load ULP modules through this mechanism, not other
    unrelated kernel modules:
    
      [root@bar]# cat foo.c
      #include <sys/types.h>
      #include <sys/socket.h>
      #include <linux/tcp.h>
      #include <linux/in.h>
    
      int main(void)
      {
          int sock = socket(PF_INET, SOCK_STREAM, 0);
          setsockopt(sock, IPPROTO_TCP, TCP_ULP, "sctp", sizeof("sctp"));
          return 0;
      }
    
      [root@bar]# gcc foo.c -O2 -Wall
      [root@bar]# lsmod | grep sctp
      [root@bar]# ./a.out
      [root@bar]# lsmod | grep sctp
      sctp                 1077248  4
      libcrc32c              16384  3 nf_conntrack,nf_nat,sctp
      [root@bar]#
    
    Fix it by adding module alias to TCP ULP modules, so probing module
    via request_module() will be limited to tcp-ulp-[name]. The existing
    modules like kTLS will load fine given tcp-ulp-tls alias, but others
    will fail to load:
    
      [root@bar]# lsmod | grep sctp
      [root@bar]# ./a.out
      [root@bar]# lsmod | grep sctp
      [root@bar]#
    
    Sockmap is not affected from this since it's either built-in or not.
    
    Fixes: 734942cc4ea6 ("tcp: ULP infrastructure")
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Acked-by: John Fastabend <john.fastabend@gmail.com>
    Acked-by: Song Liu <songliubraving@fb.com>
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>

diff --git a/net/ipv4/tcp_ulp.c b/net/ipv4/tcp_ulp.c
index 622caa4039e0..7dd44b6156c7 100644
--- a/net/ipv4/tcp_ulp.c
+++ b/net/ipv4/tcp_ulp.c
@@ -51,7 +51,7 @@ static const struct tcp_ulp_ops *__tcp_ulp_find_autoload(const char *name)
 #ifdef CONFIG_MODULES
 	if (!ulp && capable(CAP_NET_ADMIN)) {
 		rcu_read_unlock();
-		request_module("%s", name);
+		request_module("tcp-ulp-%s", name);
 		rcu_read_lock();
 		ulp = tcp_ulp_find(name);
 	}

commit b11a632c442eef34a0afeba61fab923241f317e9
Author: John Fastabend <john.fastabend@gmail.com>
Date:   Mon Feb 5 10:17:43 2018 -0800

    net: add a UID to use for ULP socket assignment
    
    Create a UID field and enum that can be used to assign ULPs to
    sockets. This saves a set of string comparisons if the ULP id
    is known.
    
    For sockmap, which is added in the next patches, a ULP is used to
    hook into TCP sockets close state. In this case the ULP being added
    is done at map insert time and the ULP is known and done on the kernel
    side. In this case the named lookup is not needed. Because we don't
    want to expose psock internals to user space socket options a user
    visible flag is also added. For TLS this is set for BPF it will be
    cleared.
    
    Alos remove pr_notice, user gets an error code back and should check
    that rather than rely on logs.
    
    Signed-off-by: John Fastabend <john.fastabend@gmail.com>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>

diff --git a/net/ipv4/tcp_ulp.c b/net/ipv4/tcp_ulp.c
index 6bb9e14c710a..622caa4039e0 100644
--- a/net/ipv4/tcp_ulp.c
+++ b/net/ipv4/tcp_ulp.c
@@ -29,6 +29,18 @@ static struct tcp_ulp_ops *tcp_ulp_find(const char *name)
 	return NULL;
 }
 
+static struct tcp_ulp_ops *tcp_ulp_find_id(const int ulp)
+{
+	struct tcp_ulp_ops *e;
+
+	list_for_each_entry_rcu(e, &tcp_ulp_list, list) {
+		if (e->uid == ulp)
+			return e;
+	}
+
+	return NULL;
+}
+
 static const struct tcp_ulp_ops *__tcp_ulp_find_autoload(const char *name)
 {
 	const struct tcp_ulp_ops *ulp = NULL;
@@ -51,6 +63,18 @@ static const struct tcp_ulp_ops *__tcp_ulp_find_autoload(const char *name)
 	return ulp;
 }
 
+static const struct tcp_ulp_ops *__tcp_ulp_lookup(const int uid)
+{
+	const struct tcp_ulp_ops *ulp;
+
+	rcu_read_lock();
+	ulp = tcp_ulp_find_id(uid);
+	if (!ulp || !try_module_get(ulp->owner))
+		ulp = NULL;
+	rcu_read_unlock();
+	return ulp;
+}
+
 /* Attach new upper layer protocol to the list
  * of available protocols.
  */
@@ -59,13 +83,10 @@ int tcp_register_ulp(struct tcp_ulp_ops *ulp)
 	int ret = 0;
 
 	spin_lock(&tcp_ulp_list_lock);
-	if (tcp_ulp_find(ulp->name)) {
-		pr_notice("%s already registered or non-unique name\n",
-			  ulp->name);
+	if (tcp_ulp_find(ulp->name))
 		ret = -EEXIST;
-	} else {
+	else
 		list_add_tail_rcu(&ulp->list, &tcp_ulp_list);
-	}
 	spin_unlock(&tcp_ulp_list_lock);
 
 	return ret;
@@ -124,6 +145,34 @@ int tcp_set_ulp(struct sock *sk, const char *name)
 	if (!ulp_ops)
 		return -ENOENT;
 
+	if (!ulp_ops->user_visible) {
+		module_put(ulp_ops->owner);
+		return -ENOENT;
+	}
+
+	err = ulp_ops->init(sk);
+	if (err) {
+		module_put(ulp_ops->owner);
+		return err;
+	}
+
+	icsk->icsk_ulp_ops = ulp_ops;
+	return 0;
+}
+
+int tcp_set_ulp_id(struct sock *sk, int ulp)
+{
+	struct inet_connection_sock *icsk = inet_csk(sk);
+	const struct tcp_ulp_ops *ulp_ops;
+	int err;
+
+	if (icsk->icsk_ulp_ops)
+		return -EEXIST;
+
+	ulp_ops = __tcp_ulp_lookup(ulp);
+	if (!ulp_ops)
+		return -ENOENT;
+
 	err = ulp_ops->init(sk);
 	if (err) {
 		module_put(ulp_ops->owner);

commit 539a06baedd06127389b254f6b9f016ca072da13
Author: Sabrina Dubroca <sd@queasysnail.net>
Date:   Mon Aug 14 18:04:24 2017 +0200

    tcp: ulp: avoid module refcnt leak in tcp_set_ulp
    
    __tcp_ulp_find_autoload returns tcp_ulp_ops after taking a reference on
    the module. Then, if ->init fails, tcp_set_ulp propagates the error but
    nothing releases that reference.
    
    Fixes: 734942cc4ea6 ("tcp: ULP infrastructure")
    Signed-off-by: Sabrina Dubroca <sd@queasysnail.net>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/tcp_ulp.c b/net/ipv4/tcp_ulp.c
index 2417f55374c5..6bb9e14c710a 100644
--- a/net/ipv4/tcp_ulp.c
+++ b/net/ipv4/tcp_ulp.c
@@ -122,14 +122,14 @@ int tcp_set_ulp(struct sock *sk, const char *name)
 
 	ulp_ops = __tcp_ulp_find_autoload(name);
 	if (!ulp_ops)
-		err = -ENOENT;
-	else
-		err = ulp_ops->init(sk);
+		return -ENOENT;
 
-	if (err)
-		goto out;
+	err = ulp_ops->init(sk);
+	if (err) {
+		module_put(ulp_ops->owner);
+		return err;
+	}
 
 	icsk->icsk_ulp_ops = ulp_ops;
- out:
-	return err;
+	return 0;
 }

commit 926f38e9744b2ee6d92085c28ebb50744e9e1182
Author: Jakub Kicinski <jakub.kicinski@netronome.com>
Date:   Thu Jun 22 18:57:55 2017 -0700

    tcp: fix out-of-bounds access in ULP sysctl
    
    KASAN reports out-of-bound access in proc_dostring() coming from
    proc_tcp_available_ulp() because in case TCP ULP list is empty
    the buffer allocated for the response will not have anything
    printed into it.  Set the first byte to zero to avoid strlen()
    going out-of-bounds.
    
    Fixes: 734942cc4ea6 ("tcp: ULP infrastructure")
    Signed-off-by: Jakub Kicinski <jakub.kicinski@netronome.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/tcp_ulp.c b/net/ipv4/tcp_ulp.c
index e855ea70819b..2417f55374c5 100644
--- a/net/ipv4/tcp_ulp.c
+++ b/net/ipv4/tcp_ulp.c
@@ -88,6 +88,7 @@ void tcp_get_available_ulp(char *buf, size_t maxlen)
 	struct tcp_ulp_ops *ulp_ops;
 	size_t offs = 0;
 
+	*buf = '\0';
 	rcu_read_lock();
 	list_for_each_entry_rcu(ulp_ops, &tcp_ulp_list, list) {
 		offs += snprintf(buf + offs, maxlen - offs,

commit 734942cc4ea6478eed125af258da1bdbb4afe578
Author: Dave Watson <davejwatson@fb.com>
Date:   Wed Jun 14 11:37:14 2017 -0700

    tcp: ULP infrastructure
    
    Add the infrustructure for attaching Upper Layer Protocols (ULPs) over TCP
    sockets. Based on a similar infrastructure in tcp_cong.  The idea is that any
    ULP can add its own logic by changing the TCP proto_ops structure to its own
    methods.
    
    Example usage:
    
    setsockopt(sock, SOL_TCP, TCP_ULP, "tls", sizeof("tls"));
    
    modules will call:
    tcp_register_ulp(&tcp_tls_ulp_ops);
    
    to register/unregister their ulp, with an init function and name.
    
    A list of registered ulps will be returned by tcp_get_available_ulp, which is
    hooked up to /proc.  Example:
    
    $ cat /proc/sys/net/ipv4/tcp_available_ulp
    tls
    
    There is currently no functionality to remove or chain ULPs, but
    it should be possible to add these in the future if needed.
    
    Signed-off-by: Boris Pismenny <borisp@mellanox.com>
    Signed-off-by: Dave Watson <davejwatson@fb.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/ipv4/tcp_ulp.c b/net/ipv4/tcp_ulp.c
new file mode 100644
index 000000000000..e855ea70819b
--- /dev/null
+++ b/net/ipv4/tcp_ulp.c
@@ -0,0 +1,134 @@
+/*
+ * Pluggable TCP upper layer protocol support.
+ *
+ * Copyright (c) 2016-2017, Mellanox Technologies. All rights reserved.
+ * Copyright (c) 2016-2017, Dave Watson <davejwatson@fb.com>. All rights reserved.
+ *
+ */
+
+#include<linux/module.h>
+#include <linux/mm.h>
+#include <linux/types.h>
+#include <linux/list.h>
+#include <linux/gfp.h>
+#include <net/tcp.h>
+
+static DEFINE_SPINLOCK(tcp_ulp_list_lock);
+static LIST_HEAD(tcp_ulp_list);
+
+/* Simple linear search, don't expect many entries! */
+static struct tcp_ulp_ops *tcp_ulp_find(const char *name)
+{
+	struct tcp_ulp_ops *e;
+
+	list_for_each_entry_rcu(e, &tcp_ulp_list, list) {
+		if (strcmp(e->name, name) == 0)
+			return e;
+	}
+
+	return NULL;
+}
+
+static const struct tcp_ulp_ops *__tcp_ulp_find_autoload(const char *name)
+{
+	const struct tcp_ulp_ops *ulp = NULL;
+
+	rcu_read_lock();
+	ulp = tcp_ulp_find(name);
+
+#ifdef CONFIG_MODULES
+	if (!ulp && capable(CAP_NET_ADMIN)) {
+		rcu_read_unlock();
+		request_module("%s", name);
+		rcu_read_lock();
+		ulp = tcp_ulp_find(name);
+	}
+#endif
+	if (!ulp || !try_module_get(ulp->owner))
+		ulp = NULL;
+
+	rcu_read_unlock();
+	return ulp;
+}
+
+/* Attach new upper layer protocol to the list
+ * of available protocols.
+ */
+int tcp_register_ulp(struct tcp_ulp_ops *ulp)
+{
+	int ret = 0;
+
+	spin_lock(&tcp_ulp_list_lock);
+	if (tcp_ulp_find(ulp->name)) {
+		pr_notice("%s already registered or non-unique name\n",
+			  ulp->name);
+		ret = -EEXIST;
+	} else {
+		list_add_tail_rcu(&ulp->list, &tcp_ulp_list);
+	}
+	spin_unlock(&tcp_ulp_list_lock);
+
+	return ret;
+}
+EXPORT_SYMBOL_GPL(tcp_register_ulp);
+
+void tcp_unregister_ulp(struct tcp_ulp_ops *ulp)
+{
+	spin_lock(&tcp_ulp_list_lock);
+	list_del_rcu(&ulp->list);
+	spin_unlock(&tcp_ulp_list_lock);
+
+	synchronize_rcu();
+}
+EXPORT_SYMBOL_GPL(tcp_unregister_ulp);
+
+/* Build string with list of available upper layer protocl values */
+void tcp_get_available_ulp(char *buf, size_t maxlen)
+{
+	struct tcp_ulp_ops *ulp_ops;
+	size_t offs = 0;
+
+	rcu_read_lock();
+	list_for_each_entry_rcu(ulp_ops, &tcp_ulp_list, list) {
+		offs += snprintf(buf + offs, maxlen - offs,
+				 "%s%s",
+				 offs == 0 ? "" : " ", ulp_ops->name);
+	}
+	rcu_read_unlock();
+}
+
+void tcp_cleanup_ulp(struct sock *sk)
+{
+	struct inet_connection_sock *icsk = inet_csk(sk);
+
+	if (!icsk->icsk_ulp_ops)
+		return;
+
+	if (icsk->icsk_ulp_ops->release)
+		icsk->icsk_ulp_ops->release(sk);
+	module_put(icsk->icsk_ulp_ops->owner);
+}
+
+/* Change upper layer protocol for socket */
+int tcp_set_ulp(struct sock *sk, const char *name)
+{
+	struct inet_connection_sock *icsk = inet_csk(sk);
+	const struct tcp_ulp_ops *ulp_ops;
+	int err = 0;
+
+	if (icsk->icsk_ulp_ops)
+		return -EEXIST;
+
+	ulp_ops = __tcp_ulp_find_autoload(name);
+	if (!ulp_ops)
+		err = -ENOENT;
+	else
+		err = ulp_ops->init(sk);
+
+	if (err)
+		goto out;
+
+	icsk->icsk_ulp_ops = ulp_ops;
+ out:
+	return err;
+}
