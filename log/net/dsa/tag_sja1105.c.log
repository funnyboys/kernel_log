commit fb9f2e92864f51d25e790947cca2ac4426a12f9c
Author: Vladimir Oltean <olteanv@gmail.com>
Date:   Wed May 13 03:23:27 2020 +0300

    net: dsa: tag_sja1105: appease sparse checks for ethertype accessors
    
    A comparison between a value from the packet and an integer constant
    value needs to be done by converting the value from the packet from
    net->host, or the constant from host->net. Not the other way around.
    Even though it makes no practical difference, correct that.
    
    Fixes: 38b5beeae7a4 ("net: dsa: sja1105: prepare tagger for handling DSA tags and VLAN simultaneously")
    Signed-off-by: Vladimir Oltean <olteanv@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dsa/tag_sja1105.c b/net/dsa/tag_sja1105.c
index ad105550b145..9b4a4d719291 100644
--- a/net/dsa/tag_sja1105.c
+++ b/net/dsa/tag_sja1105.c
@@ -73,10 +73,10 @@ static bool sja1105_can_use_vlan_as_tags(const struct sk_buff *skb)
 {
 	struct vlan_ethhdr *hdr = vlan_eth_hdr(skb);
 
-	if (hdr->h_vlan_proto == ntohs(ETH_P_SJA1105))
+	if (hdr->h_vlan_proto == htons(ETH_P_SJA1105))
 		return true;
 
-	if (hdr->h_vlan_proto != ntohs(ETH_P_8021Q))
+	if (hdr->h_vlan_proto != htons(ETH_P_8021Q))
 		return false;
 
 	return vid_is_dsa_8021q(ntohs(hdr->h_vlan_TCI) & VLAN_VID_MASK);

commit 84eeb5d460e399795e9a92a0cd44999254886150
Author: Vladimir Oltean <vladimir.oltean@nxp.com>
Date:   Tue May 12 20:20:34 2020 +0300

    net: dsa: tag_sja1105: implement sub-VLAN decoding
    
    Create a subvlan_map as part of each port's tagger private structure.
    This keeps reverse mappings of bridge-to-dsa_8021q VLAN retagging rules.
    
    Note that as of this patch, this piece of code is never engaged, due to
    the fact that the driver hasn't installed any retagging rule, so we'll
    always see packets with a subvlan code of 0 (untagged).
    
    Signed-off-by: Vladimir Oltean <vladimir.oltean@nxp.com>
    Reviewed-by: Florian Fainelli <f.fainelli@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dsa/tag_sja1105.c b/net/dsa/tag_sja1105.c
index 398e2b9a1b96..ad105550b145 100644
--- a/net/dsa/tag_sja1105.c
+++ b/net/dsa/tag_sja1105.c
@@ -254,6 +254,20 @@ static struct sk_buff
 	return skb;
 }
 
+static void sja1105_decode_subvlan(struct sk_buff *skb, u16 subvlan)
+{
+	struct dsa_port *dp = dsa_slave_to_port(skb->dev);
+	struct sja1105_port *sp = dp->priv;
+	u16 vid = sp->subvlan_map[subvlan];
+	u16 vlan_tci;
+
+	if (vid == VLAN_N_VID)
+		return;
+
+	vlan_tci = (skb->priority << VLAN_PRIO_SHIFT) | vid;
+	__vlan_hwaccel_put_tag(skb, htons(ETH_P_8021Q), vlan_tci);
+}
+
 static struct sk_buff *sja1105_rcv(struct sk_buff *skb,
 				   struct net_device *netdev,
 				   struct packet_type *pt)
@@ -263,6 +277,7 @@ static struct sk_buff *sja1105_rcv(struct sk_buff *skb,
 	struct ethhdr *hdr;
 	u16 tpid, vid, tci;
 	bool is_link_local;
+	u16 subvlan = 0;
 	bool is_tagged;
 	bool is_meta;
 
@@ -286,6 +301,7 @@ static struct sk_buff *sja1105_rcv(struct sk_buff *skb,
 		source_port = dsa_8021q_rx_source_port(vid);
 		switch_id = dsa_8021q_rx_switch_id(vid);
 		skb->priority = (tci & VLAN_PRIO_MASK) >> VLAN_PRIO_SHIFT;
+		subvlan = dsa_8021q_rx_subvlan(vid);
 	} else if (is_link_local) {
 		/* Management traffic path. Switch embeds the switch ID and
 		 * port ID into bytes of the destination MAC, courtesy of
@@ -310,6 +326,9 @@ static struct sk_buff *sja1105_rcv(struct sk_buff *skb,
 		return NULL;
 	}
 
+	if (subvlan)
+		sja1105_decode_subvlan(skb, subvlan);
+
 	return sja1105_rcv_meta_state_machine(skb, &meta, is_link_local,
 					      is_meta);
 }

commit 38b5beeae7a4cde87edabb0196fac1f55ae668ee
Author: Vladimir Oltean <vladimir.oltean@nxp.com>
Date:   Tue May 12 20:20:32 2020 +0300

    net: dsa: sja1105: prepare tagger for handling DSA tags and VLAN simultaneously
    
    In VLAN-unaware mode, sja1105 uses VLAN tags with a custom TPID of
    0xdadb. While in the yet-to-be introduced best_effort_vlan_filtering
    mode, it needs to work with normal VLAN TPID values.
    
    A complication arises when we must transmit a VLAN-tagged packet to the
    switch when it's in VLAN-aware mode. We need to construct a packet with
    2 VLAN tags, and the switch will use the outer header for routing and
    pop it on egress. But sadly, here the 2 hardware generations don't
    behave the same:
    
    - E/T switches won't pop an ETH_P_8021AD tag on egress, it seems
      (packets will remain double-tagged).
    - P/Q/R/S switches will drop a packet with 2 ETH_P_8021Q tags (it looks
      like it tries to prevent VLAN hopping).
    
    But looks like the reverse is also true:
    
    - E/T switches have no problem popping the outer tag from packets with
      2 ETH_P_8021Q tags.
    - P/Q/R/S will have no problem popping a single tag even if that is
      ETH_P_8021AD.
    
    So it is clear that if we want the hardware to work with dsa_8021q
    tagging in VLAN-aware mode, we need to send different TPIDs depending on
    revision. Keep that information in priv->info->qinq_tpid.
    
    The per-port tagger structure will hold an xmit_tpid value that depends
    not only upon the qinq_tpid, but also upon the VLAN awareness state
    itself (in case we must transmit using 0xdadb).
    
    Signed-off-by: Vladimir Oltean <vladimir.oltean@nxp.com>
    Reviewed-by: Florian Fainelli <f.fainelli@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dsa/tag_sja1105.c b/net/dsa/tag_sja1105.c
index 5ecac5921a7d..398e2b9a1b96 100644
--- a/net/dsa/tag_sja1105.c
+++ b/net/dsa/tag_sja1105.c
@@ -69,12 +69,25 @@ static inline bool sja1105_is_meta_frame(const struct sk_buff *skb)
 	return true;
 }
 
+static bool sja1105_can_use_vlan_as_tags(const struct sk_buff *skb)
+{
+	struct vlan_ethhdr *hdr = vlan_eth_hdr(skb);
+
+	if (hdr->h_vlan_proto == ntohs(ETH_P_SJA1105))
+		return true;
+
+	if (hdr->h_vlan_proto != ntohs(ETH_P_8021Q))
+		return false;
+
+	return vid_is_dsa_8021q(ntohs(hdr->h_vlan_TCI) & VLAN_VID_MASK);
+}
+
 /* This is the first time the tagger sees the frame on RX.
  * Figure out if we can decode it.
  */
 static bool sja1105_filter(const struct sk_buff *skb, struct net_device *dev)
 {
-	if (!dsa_port_is_vlan_filtering(dev->dsa_ptr))
+	if (sja1105_can_use_vlan_as_tags(skb))
 		return true;
 	if (sja1105_is_link_local(skb))
 		return true;
@@ -96,6 +109,11 @@ static struct sk_buff *sja1105_defer_xmit(struct sja1105_port *sp,
 	return NULL;
 }
 
+static u16 sja1105_xmit_tpid(struct sja1105_port *sp)
+{
+	return sp->xmit_tpid;
+}
+
 static struct sk_buff *sja1105_xmit(struct sk_buff *skb,
 				    struct net_device *netdev)
 {
@@ -111,15 +129,7 @@ static struct sk_buff *sja1105_xmit(struct sk_buff *skb,
 	if (unlikely(sja1105_is_link_local(skb)))
 		return sja1105_defer_xmit(dp->priv, skb);
 
-	/* If we are under a vlan_filtering bridge, IP termination on
-	 * switch ports based on 802.1Q tags is simply too brittle to
-	 * be passable. So just defer to the dsa_slave_notag_xmit
-	 * implementation.
-	 */
-	if (dsa_port_is_vlan_filtering(dp))
-		return skb;
-
-	return dsa_8021q_xmit(skb, netdev, ETH_P_SJA1105,
+	return dsa_8021q_xmit(skb, netdev, sja1105_xmit_tpid(dp->priv),
 			     ((pcp << VLAN_PRIO_SHIFT) | tx_vid));
 }
 
@@ -258,7 +268,7 @@ static struct sk_buff *sja1105_rcv(struct sk_buff *skb,
 
 	hdr = eth_hdr(skb);
 	tpid = ntohs(hdr->h_proto);
-	is_tagged = (tpid == ETH_P_SJA1105);
+	is_tagged = (tpid == ETH_P_SJA1105 || tpid == ETH_P_8021Q);
 	is_link_local = sja1105_is_link_local(skb);
 	is_meta = sja1105_is_meta_frame(skb);
 

commit 097f024454fca0e13bbba0ab54dfe63ac5610953
Author: Florian Fainelli <f.fainelli@gmail.com>
Date:   Mon May 11 16:47:15 2020 -0700

    net: dsa: tag_sja1105: Constify dsa_device_ops
    
    sja1105_netdev_ops should be const since that is what the DSA layer
    expects.
    
    Signed-off-by: Florian Fainelli <f.fainelli@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dsa/tag_sja1105.c b/net/dsa/tag_sja1105.c
index d553bf36bd41..5ecac5921a7d 100644
--- a/net/dsa/tag_sja1105.c
+++ b/net/dsa/tag_sja1105.c
@@ -304,7 +304,7 @@ static struct sk_buff *sja1105_rcv(struct sk_buff *skb,
 					      is_meta);
 }
 
-static struct dsa_device_ops sja1105_netdev_ops = {
+static const struct dsa_device_ops sja1105_netdev_ops = {
 	.name = "sja1105",
 	.proto = DSA_TAG_PROTO_SJA1105,
 	.xmit = sja1105_xmit,

commit e80f40cbe4dd51371818e967d40da8fe305db5e4
Author: Vladimir Oltean <vladimir.oltean@nxp.com>
Date:   Tue Mar 24 11:45:34 2020 +0200

    net: dsa: tag_8021q: replace dsa_8021q_remove_header with __skb_vlan_pop
    
    Not only did this wheel did not need reinventing, but there is also
    an issue with it: It doesn't remove the VLAN header in a way that
    preserves the L2 payload checksum when that is being provided by the DSA
    master hw.  It should recalculate checksum both for the push, before
    removing the header, and for the pull afterwards. But the current
    implementation is quite dizzying, with pulls followed immediately
    afterwards by pushes, the memmove is done before the push, etc.  This
    makes a DSA master with RX checksumming offload to print stack traces
    with the infamous 'hw csum failure' message.
    
    So remove the dsa_8021q_remove_header function and replace it with
    something that actually works with inet checksumming.
    
    Fixes: d461933638ae ("net: dsa: tag_8021q: Create helper function for removing VLAN header")
    Signed-off-by: Vladimir Oltean <vladimir.oltean@nxp.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dsa/tag_sja1105.c b/net/dsa/tag_sja1105.c
index 5366ea430349..d553bf36bd41 100644
--- a/net/dsa/tag_sja1105.c
+++ b/net/dsa/tag_sja1105.c
@@ -250,14 +250,14 @@ static struct sk_buff *sja1105_rcv(struct sk_buff *skb,
 {
 	struct sja1105_meta meta = {0};
 	int source_port, switch_id;
-	struct vlan_ethhdr *hdr;
+	struct ethhdr *hdr;
 	u16 tpid, vid, tci;
 	bool is_link_local;
 	bool is_tagged;
 	bool is_meta;
 
-	hdr = vlan_eth_hdr(skb);
-	tpid = ntohs(hdr->h_vlan_proto);
+	hdr = eth_hdr(skb);
+	tpid = ntohs(hdr->h_proto);
 	is_tagged = (tpid == ETH_P_SJA1105);
 	is_link_local = sja1105_is_link_local(skb);
 	is_meta = sja1105_is_meta_frame(skb);
@@ -266,7 +266,12 @@ static struct sk_buff *sja1105_rcv(struct sk_buff *skb,
 
 	if (is_tagged) {
 		/* Normal traffic path. */
-		tci = ntohs(hdr->h_vlan_TCI);
+		skb_push_rcsum(skb, ETH_HLEN);
+		__skb_vlan_pop(skb, &tci);
+		skb_pull_rcsum(skb, ETH_HLEN);
+		skb_reset_network_header(skb);
+		skb_reset_transport_header(skb);
+
 		vid = tci & VLAN_VID_MASK;
 		source_port = dsa_8021q_rx_source_port(vid);
 		switch_id = dsa_8021q_rx_switch_id(vid);
@@ -295,12 +300,6 @@ static struct sk_buff *sja1105_rcv(struct sk_buff *skb,
 		return NULL;
 	}
 
-	/* Delete/overwrite fake VLAN header, DSA expects to not find
-	 * it there, see dsa_switch_rcv: skb_push(skb, ETH_HLEN).
-	 */
-	if (is_tagged)
-		skb = dsa_8021q_remove_header(skb);
-
 	return sja1105_rcv_meta_state_machine(skb, &meta, is_link_local,
 					      is_meta);
 }

commit 2821d50fc0c45e45bc10781d4dd332e21e7fb980
Author: Vladimir Oltean <olteanv@gmail.com>
Date:   Sat Jan 4 02:37:11 2020 +0200

    net: dsa: tag_sja1105: Slightly improve the Xmas tree in sja1105_xmit
    
    This is a cosmetic patch that makes the dp, tx_vid, queue_mapping and
    pcp local variable definitions a bit closer in length, so they don't
    look like an eyesore as much.
    
    The 'ds' variable is not used otherwise, except for ds->dp.
    
    Signed-off-by: Vladimir Oltean <olteanv@gmail.com>
    Reviewed-by: Florian Fainelli <f.fainelli@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dsa/tag_sja1105.c b/net/dsa/tag_sja1105.c
index 7c2b84393cc6..5366ea430349 100644
--- a/net/dsa/tag_sja1105.c
+++ b/net/dsa/tag_sja1105.c
@@ -100,8 +100,7 @@ static struct sk_buff *sja1105_xmit(struct sk_buff *skb,
 				    struct net_device *netdev)
 {
 	struct dsa_port *dp = dsa_slave_to_port(netdev);
-	struct dsa_switch *ds = dp->ds;
-	u16 tx_vid = dsa_8021q_tx_vid(ds, dp->index);
+	u16 tx_vid = dsa_8021q_tx_vid(dp->ds, dp->index);
 	u16 queue_mapping = skb_get_queue_mapping(skb);
 	u8 pcp = netdev_txq_to_tc(netdev, queue_mapping);
 

commit a68578c20a9667463ee3000402b21644ea62d753
Author: Vladimir Oltean <olteanv@gmail.com>
Date:   Sat Jan 4 02:37:10 2020 +0200

    net: dsa: Make deferred_xmit private to sja1105
    
    There are 3 things that are wrong with the DSA deferred xmit mechanism:
    
    1. Its introduction has made the DSA hotpath ever so slightly more
       inefficient for everybody, since DSA_SKB_CB(skb)->deferred_xmit needs
       to be initialized to false for every transmitted frame, in order to
       figure out whether the driver requested deferral or not (a very rare
       occasion, rare even for the only driver that does use this mechanism:
       sja1105). That was necessary to avoid kfree_skb from freeing the skb.
    
    2. Because L2 PTP is a link-local protocol like STP, it requires
       management routes and deferred xmit with this switch. But as opposed
       to STP, the deferred work mechanism needs to schedule the packet
       rather quickly for the TX timstamp to be collected in time and sent
       to user space. But there is no provision for controlling the
       scheduling priority of this deferred xmit workqueue. Too bad this is
       a rather specific requirement for a feature that nobody else uses
       (more below).
    
    3. Perhaps most importantly, it makes the DSA core adhere a bit too
       much to the NXP company-wide policy "Innovate Where It Doesn't
       Matter". The sja1105 is probably the only DSA switch that requires
       some frames sent from the CPU to be routed to the slave port via an
       out-of-band configuration (register write) rather than in-band (DSA
       tag). And there are indeed very good reasons to not want to do that:
       if that out-of-band register is at the other end of a slow bus such
       as SPI, then you limit that Ethernet flow's throughput to effectively
       the throughput of the SPI bus. So hardware vendors should definitely
       not be encouraged to design this way. We do _not_ want more
       widespread use of this mechanism.
    
    Luckily we have a solution for each of the 3 issues:
    
    For 1, we can just remove that variable in the skb->cb and counteract
    the effect of kfree_skb with skb_get, much to the same effect. The
    advantage, of course, being that anybody who doesn't use deferred xmit
    doesn't need to do any extra operation in the hotpath.
    
    For 2, we can create a kernel thread for each port's deferred xmit work.
    If the user switch ports are named swp0, swp1, swp2, the kernel threads
    will be named swp0_xmit, swp1_xmit, swp2_xmit (there appears to be a 15
    character length limit on kernel thread names). With this, the user can
    change the scheduling priority with chrt $(pidof swp2_xmit).
    
    For 3, we can actually move the entire implementation to the sja1105
    driver.
    
    So this patch deletes the generic implementation from the DSA core and
    adds a new one, more adequate to the requirements of PTP TX
    timestamping, in sja1105_main.c.
    
    Suggested-by: Florian Fainelli <f.fainelli@gmail.com>
    Signed-off-by: Vladimir Oltean <olteanv@gmail.com>
    Reviewed-by: Florian Fainelli <f.fainelli@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dsa/tag_sja1105.c b/net/dsa/tag_sja1105.c
index 63ef2a14c934..7c2b84393cc6 100644
--- a/net/dsa/tag_sja1105.c
+++ b/net/dsa/tag_sja1105.c
@@ -83,6 +83,19 @@ static bool sja1105_filter(const struct sk_buff *skb, struct net_device *dev)
 	return false;
 }
 
+/* Calls sja1105_port_deferred_xmit in sja1105_main.c */
+static struct sk_buff *sja1105_defer_xmit(struct sja1105_port *sp,
+					  struct sk_buff *skb)
+{
+	/* Increase refcount so the kfree_skb in dsa_slave_xmit
+	 * won't really free the packet.
+	 */
+	skb_queue_tail(&sp->xmit_queue, skb_get(skb));
+	kthread_queue_work(sp->xmit_worker, &sp->xmit_work);
+
+	return NULL;
+}
+
 static struct sk_buff *sja1105_xmit(struct sk_buff *skb,
 				    struct net_device *netdev)
 {
@@ -97,7 +110,7 @@ static struct sk_buff *sja1105_xmit(struct sk_buff *skb,
 	 * is the .port_deferred_xmit driver callback.
 	 */
 	if (unlikely(sja1105_is_link_local(skb)))
-		return dsa_defer_xmit(skb, netdev);
+		return sja1105_defer_xmit(dp->priv, skb);
 
 	/* If we are under a vlan_filtering bridge, IP termination on
 	 * switch ports based on 802.1Q tags is simply too brittle to

commit 3e8db7e56082156a37b71d7334860c10fcea8025
Author: Vladimir Oltean <olteanv@gmail.com>
Date:   Tue Oct 1 21:58:19 2019 +0300

    net: dsa: sja1105: Fix sleeping while atomic in .port_hwtstamp_set
    
    Currently this stack trace can be seen with CONFIG_DEBUG_ATOMIC_SLEEP=y:
    
    [   41.568348] BUG: sleeping function called from invalid context at kernel/locking/mutex.c:909
    [   41.576757] in_atomic(): 1, irqs_disabled(): 0, pid: 208, name: ptp4l
    [   41.583212] INFO: lockdep is turned off.
    [   41.587123] CPU: 1 PID: 208 Comm: ptp4l Not tainted 5.3.0-rc6-01445-ge950f2d4bc7f-dirty #1827
    [   41.599873] [<c0313d7c>] (unwind_backtrace) from [<c030e13c>] (show_stack+0x10/0x14)
    [   41.607584] [<c030e13c>] (show_stack) from [<c1212d50>] (dump_stack+0xd4/0x100)
    [   41.614863] [<c1212d50>] (dump_stack) from [<c037dfc8>] (___might_sleep+0x1c8/0x2b4)
    [   41.622574] [<c037dfc8>] (___might_sleep) from [<c122ea90>] (__mutex_lock+0x48/0xab8)
    [   41.630368] [<c122ea90>] (__mutex_lock) from [<c122f51c>] (mutex_lock_nested+0x1c/0x24)
    [   41.638340] [<c122f51c>] (mutex_lock_nested) from [<c0c6fe08>] (sja1105_static_config_reload+0x30/0x27c)
    [   41.647779] [<c0c6fe08>] (sja1105_static_config_reload) from [<c0c7015c>] (sja1105_hwtstamp_set+0x108/0x1cc)
    [   41.657562] [<c0c7015c>] (sja1105_hwtstamp_set) from [<c0feb650>] (dev_ifsioc+0x18c/0x330)
    [   41.665788] [<c0feb650>] (dev_ifsioc) from [<c0febbd8>] (dev_ioctl+0x320/0x6e8)
    [   41.673064] [<c0febbd8>] (dev_ioctl) from [<c0f8b1f4>] (sock_ioctl+0x334/0x5e8)
    [   41.680340] [<c0f8b1f4>] (sock_ioctl) from [<c05404a8>] (do_vfs_ioctl+0xb0/0xa10)
    [   41.687789] [<c05404a8>] (do_vfs_ioctl) from [<c0540e3c>] (ksys_ioctl+0x34/0x58)
    [   41.695151] [<c0540e3c>] (ksys_ioctl) from [<c0301000>] (ret_fast_syscall+0x0/0x28)
    [   41.702768] Exception stack(0xe8495fa8 to 0xe8495ff0)
    [   41.707796] 5fa0:                   beff4a8c 00000001 00000011 000089b0 beff4a8c beff4a80
    [   41.715933] 5fc0: beff4a8c 00000001 0000000c 00000036 b6fa98c8 004e19c1 00000001 00000000
    [   41.724069] 5fe0: 004dcedc beff4a6c 004c0738 b6e7af4c
    [   41.729860] BUG: scheduling while atomic: ptp4l/208/0x00000002
    [   41.735682] INFO: lockdep is turned off.
    
    Enabling RX timestamping will logically disturb the fastpath (processing
    of meta frames). Replace bool hwts_rx_en with a bit that is checked
    atomically from the fastpath and temporarily unset from the sleepable
    context during a change of the RX timestamping process (a destructive
    operation anyways, requires switch reset).
    If found unset, the fastpath (net/dsa/tag_sja1105.c) will just drop any
    received meta frame and not take the meta_lock at all.
    
    Fixes: a602afd200f5 ("net: dsa: sja1105: Expose PTP timestamping ioctls to userspace")
    Signed-off-by: Vladimir Oltean <olteanv@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dsa/tag_sja1105.c b/net/dsa/tag_sja1105.c
index 9c9aff3e52cf..63ef2a14c934 100644
--- a/net/dsa/tag_sja1105.c
+++ b/net/dsa/tag_sja1105.c
@@ -156,7 +156,11 @@ static struct sk_buff
 	/* Step 1: A timestampable frame was received.
 	 * Buffer it until we get its meta frame.
 	 */
-	if (is_link_local && sp->data->hwts_rx_en) {
+	if (is_link_local) {
+		if (!test_bit(SJA1105_HWTS_RX_EN, &sp->data->state))
+			/* Do normal processing. */
+			return skb;
+
 		spin_lock(&sp->data->meta_lock);
 		/* Was this a link-local frame instead of the meta
 		 * that we were expecting?
@@ -187,6 +191,12 @@ static struct sk_buff
 	} else if (is_meta) {
 		struct sk_buff *stampable_skb;
 
+		/* Drop the meta frame if we're not in the right state
+		 * to process it.
+		 */
+		if (!test_bit(SJA1105_HWTS_RX_EN, &sp->data->state))
+			return NULL;
+
 		spin_lock(&sp->data->meta_lock);
 
 		stampable_skb = sp->data->stampable_skb;

commit 5f06c63bd3f03767e763c3ba2a361299247001a3
Author: Vladimir Oltean <olteanv@gmail.com>
Date:   Sun Sep 15 05:00:01 2019 +0300

    net: dsa: sja1105: Advertise the 8 TX queues
    
    This is a preparation patch for the tc-taprio offload (and potentially
    for other future offloads such as tc-mqprio).
    
    Instead of looking directly at skb->priority during xmit, let's get the
    netdev queue and the queue-to-traffic-class mapping, and put the
    resulting traffic class into the dsa_8021q PCP field. The switch is
    configured with a 1-to-1 PCP-to-ingress-queue-to-egress-queue mapping
    (see vlan_pmap in sja1105_main.c), so the effect is that we can inject
    into a front-panel's egress traffic class through VLAN tagging from
    Linux, completely transparently.
    
    Unfortunately the switch doesn't look at the VLAN PCP in the case of
    management traffic to/from the CPU (link-local frames at
    01-80-C2-xx-xx-xx or 01-1B-19-xx-xx-xx) so we can't alter the
    transmission queue of this type of traffic on a frame-by-frame basis. It
    is only selected through the "hostprio" setting which ATM is harcoded in
    the driver to 7.
    
    Signed-off-by: Vladimir Oltean <olteanv@gmail.com>
    Reviewed-by: Florian Fainelli <f.fainelli@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dsa/tag_sja1105.c b/net/dsa/tag_sja1105.c
index 47ee88163a9d..9c9aff3e52cf 100644
--- a/net/dsa/tag_sja1105.c
+++ b/net/dsa/tag_sja1105.c
@@ -89,7 +89,8 @@ static struct sk_buff *sja1105_xmit(struct sk_buff *skb,
 	struct dsa_port *dp = dsa_slave_to_port(netdev);
 	struct dsa_switch *ds = dp->ds;
 	u16 tx_vid = dsa_8021q_tx_vid(ds, dp->index);
-	u8 pcp = skb->priority;
+	u16 queue_mapping = skb_get_queue_mapping(skb);
+	u8 pcp = netdev_txq_to_tc(netdev, queue_mapping);
 
 	/* Transmitting management traffic does not rely upon switch tagging,
 	 * but instead SPI-installed management routes. Part 2 of this

commit 93fa8587b25356382a39f1ca3a81d6c1b42ac731
Author: Vladimir Oltean <olteanv@gmail.com>
Date:   Mon Aug 5 01:38:48 2019 +0300

    net: dsa: sja1105: Fix memory leak on meta state machine error path
    
    When RX timestamping is enabled and two link-local (non-meta) frames are
    received in a row, this constitutes an error.
    
    The tagger is always caching the last link-local frame, in an attempt to
    merge it with the meta follow-up frame when that arrives. To recover
    from the above error condition, the initial cached link-local frame is
    dropped and the second frame in a row is cached (in expectance of the
    second meta frame).
    
    However, when dropping the initial link-local frame, its backing memory
    was being leaked.
    
    Fixes: f3097be21bf1 ("net: dsa: sja1105: Add a state machine for RX timestamping")
    Signed-off-by: Vladimir Oltean <olteanv@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dsa/tag_sja1105.c b/net/dsa/tag_sja1105.c
index 8fa8dda8a15b..47ee88163a9d 100644
--- a/net/dsa/tag_sja1105.c
+++ b/net/dsa/tag_sja1105.c
@@ -165,6 +165,7 @@ static struct sk_buff
 					    "Expected meta frame, is %12llx "
 					    "in the DSA master multicast filter?\n",
 					    SJA1105_META_DMAC);
+			kfree_skb(sp->data->stampable_skb);
 		}
 
 		/* Hold a reference to avoid dsa_switch_rcv

commit f163fed2764e66511fb5c489bf87e532ad7606fb
Author: Vladimir Oltean <olteanv@gmail.com>
Date:   Mon Aug 5 01:38:47 2019 +0300

    net: dsa: sja1105: Fix memory leak on meta state machine normal path
    
    After a meta frame is received, it is associated with the cached
    sp->data->stampable_skb from the DSA tagger private structure.
    
    Cached means its refcount is incremented with skb_get() in order for
    dsa_switch_rcv() to not free it when the tagger .rcv returns NULL.
    
    The mistake is that skb_unref() is not the correct function to use. It
    will correctly decrement the refcount (which will go back to zero) but
    the skb memory will not be freed.  That is the job of kfree_skb(), which
    also calls skb_unref().
    
    But it turns out that freeing the cached stampable_skb is in fact not
    necessary.  It is still a perfectly valid skb, and now it is even
    annotated with the partial RX timestamp.  So remove the skb_copy()
    altogether and simply pass the stampable_skb with a refcount of 1
    (incremented by us, decremented by dsa_switch_rcv) up the stack.
    
    Fixes: f3097be21bf1 ("net: dsa: sja1105: Add a state machine for RX timestamping")
    Signed-off-by: Vladimir Oltean <olteanv@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dsa/tag_sja1105.c b/net/dsa/tag_sja1105.c
index 26363d72d25b..8fa8dda8a15b 100644
--- a/net/dsa/tag_sja1105.c
+++ b/net/dsa/tag_sja1105.c
@@ -211,17 +211,8 @@ static struct sk_buff
 		 * for further processing up the network stack.
 		 */
 		kfree_skb(skb);
-
-		skb = skb_copy(stampable_skb, GFP_ATOMIC);
-		if (!skb) {
-			dev_err_ratelimited(dp->ds->dev,
-					    "Failed to copy stampable skb\n");
-			spin_unlock(&sp->data->meta_lock);
-			return NULL;
-		}
+		skb = stampable_skb;
 		sja1105_transfer_meta(skb, meta);
-		/* The cached copy will be freed now */
-		skb_unref(stampable_skb);
 
 		spin_unlock(&sp->data->meta_lock);
 	}

commit 008cfbaa3f9f84efead76d2cea12b4dd05cce67d
Author: Wei Yongjun <weiyongjun1@huawei.com>
Date:   Wed Jul 17 06:29:56 2019 +0000

    net: dsa: sja1105: Fix missing unlock on error in sk_buff()
    
    Add the missing unlock before return from function sk_buff()
    in the error handling case.
    
    Fixes: f3097be21bf1 ("net: dsa: sja1105: Add a state machine for RX timestamping")
    Signed-off-by: Wei Yongjun <weiyongjun1@huawei.com>
    Reviewed-by: Vladimir Oltean <olteanv@gmail.com>
    Reviewed-by: Vivien Didelot <vivien.didelot@gmail.com>
    Reviewed-by: Florian Fainelli <f.fainelli@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dsa/tag_sja1105.c b/net/dsa/tag_sja1105.c
index 1d96c9d4a8e9..26363d72d25b 100644
--- a/net/dsa/tag_sja1105.c
+++ b/net/dsa/tag_sja1105.c
@@ -216,6 +216,7 @@ static struct sk_buff
 		if (!skb) {
 			dev_err_ratelimited(dp->ds->dev,
 					    "Failed to copy stampable skb\n");
+			spin_unlock(&sp->data->meta_lock);
 			return NULL;
 		}
 		sja1105_transfer_meta(skb, meta);

commit f3097be21bf17ae8785eea009cbc424f16611d9a
Author: Vladimir Oltean <olteanv@gmail.com>
Date:   Sat Jun 8 15:04:42 2019 +0300

    net: dsa: sja1105: Add a state machine for RX timestamping
    
    Meta frame reception relies on the hardware keeping its promise that it
    will send no other traffic towards the CPU port between a link-local
    frame and a meta frame.  Otherwise there is no other way to associate
    the meta frame with the link-local frame it's holding a timestamp of.
    The receive function is made stateful, and buffers a timestampable frame
    until its meta frame arrives, then merges the two, drops the meta and
    releases the link-local frame up the stack.
    
    Signed-off-by: Vladimir Oltean <olteanv@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dsa/tag_sja1105.c b/net/dsa/tag_sja1105.c
index 5b51e96130c7..1d96c9d4a8e9 100644
--- a/net/dsa/tag_sja1105.c
+++ b/net/dsa/tag_sja1105.c
@@ -110,6 +110,124 @@ static struct sk_buff *sja1105_xmit(struct sk_buff *skb,
 			     ((pcp << VLAN_PRIO_SHIFT) | tx_vid));
 }
 
+static void sja1105_transfer_meta(struct sk_buff *skb,
+				  const struct sja1105_meta *meta)
+{
+	struct ethhdr *hdr = eth_hdr(skb);
+
+	hdr->h_dest[3] = meta->dmac_byte_3;
+	hdr->h_dest[4] = meta->dmac_byte_4;
+	SJA1105_SKB_CB(skb)->meta_tstamp = meta->tstamp;
+}
+
+/* This is a simple state machine which follows the hardware mechanism of
+ * generating RX timestamps:
+ *
+ * After each timestampable skb (all traffic for which send_meta1 and
+ * send_meta0 is true, aka all MAC-filtered link-local traffic) a meta frame
+ * containing a partial timestamp is immediately generated by the switch and
+ * sent as a follow-up to the link-local frame on the CPU port.
+ *
+ * The meta frames have no unique identifier (such as sequence number) by which
+ * one may pair them to the correct timestampable frame.
+ * Instead, the switch has internal logic that ensures no frames are sent on
+ * the CPU port between a link-local timestampable frame and its corresponding
+ * meta follow-up. It also ensures strict ordering between ports (lower ports
+ * have higher priority towards the CPU port). For this reason, a per-port
+ * data structure is not needed/desirable.
+ *
+ * This function pairs the link-local frame with its partial timestamp from the
+ * meta follow-up frame. The full timestamp will be reconstructed later in a
+ * work queue.
+ */
+static struct sk_buff
+*sja1105_rcv_meta_state_machine(struct sk_buff *skb,
+				struct sja1105_meta *meta,
+				bool is_link_local,
+				bool is_meta)
+{
+	struct sja1105_port *sp;
+	struct dsa_port *dp;
+
+	dp = dsa_slave_to_port(skb->dev);
+	sp = dp->priv;
+
+	/* Step 1: A timestampable frame was received.
+	 * Buffer it until we get its meta frame.
+	 */
+	if (is_link_local && sp->data->hwts_rx_en) {
+		spin_lock(&sp->data->meta_lock);
+		/* Was this a link-local frame instead of the meta
+		 * that we were expecting?
+		 */
+		if (sp->data->stampable_skb) {
+			dev_err_ratelimited(dp->ds->dev,
+					    "Expected meta frame, is %12llx "
+					    "in the DSA master multicast filter?\n",
+					    SJA1105_META_DMAC);
+		}
+
+		/* Hold a reference to avoid dsa_switch_rcv
+		 * from freeing the skb.
+		 */
+		sp->data->stampable_skb = skb_get(skb);
+		spin_unlock(&sp->data->meta_lock);
+
+		/* Tell DSA we got nothing */
+		return NULL;
+
+	/* Step 2: The meta frame arrived.
+	 * Time to take the stampable skb out of the closet, annotate it
+	 * with the partial timestamp, and pretend that we received it
+	 * just now (basically masquerade the buffered frame as the meta
+	 * frame, which serves no further purpose).
+	 */
+	} else if (is_meta) {
+		struct sk_buff *stampable_skb;
+
+		spin_lock(&sp->data->meta_lock);
+
+		stampable_skb = sp->data->stampable_skb;
+		sp->data->stampable_skb = NULL;
+
+		/* Was this a meta frame instead of the link-local
+		 * that we were expecting?
+		 */
+		if (!stampable_skb) {
+			dev_err_ratelimited(dp->ds->dev,
+					    "Unexpected meta frame\n");
+			spin_unlock(&sp->data->meta_lock);
+			return NULL;
+		}
+
+		if (stampable_skb->dev != skb->dev) {
+			dev_err_ratelimited(dp->ds->dev,
+					    "Meta frame on wrong port\n");
+			spin_unlock(&sp->data->meta_lock);
+			return NULL;
+		}
+
+		/* Free the meta frame and give DSA the buffered stampable_skb
+		 * for further processing up the network stack.
+		 */
+		kfree_skb(skb);
+
+		skb = skb_copy(stampable_skb, GFP_ATOMIC);
+		if (!skb) {
+			dev_err_ratelimited(dp->ds->dev,
+					    "Failed to copy stampable skb\n");
+			return NULL;
+		}
+		sja1105_transfer_meta(skb, meta);
+		/* The cached copy will be freed now */
+		skb_unref(stampable_skb);
+
+		spin_unlock(&sp->data->meta_lock);
+	}
+
+	return skb;
+}
+
 static struct sk_buff *sja1105_rcv(struct sk_buff *skb,
 				   struct net_device *netdev,
 				   struct packet_type *pt)
@@ -167,7 +285,8 @@ static struct sk_buff *sja1105_rcv(struct sk_buff *skb,
 	if (is_tagged)
 		skb = dsa_8021q_remove_header(skb);
 
-	return skb;
+	return sja1105_rcv_meta_state_machine(skb, &meta, is_link_local,
+					      is_meta);
 }
 
 static struct dsa_device_ops sja1105_netdev_ops = {

commit e53e18a6fe4d3ae04c28ca2327ef7e7656cb07ce
Author: Vladimir Oltean <olteanv@gmail.com>
Date:   Sat Jun 8 15:04:39 2019 +0300

    net: dsa: sja1105: Receive and decode meta frames
    
    This adds support in the tagger for understanding the source port and
    switch id of meta frames.  Their timestamp is also extracted but not
    used yet - this needs to be done in a state machine that modifies the
    previously received timestampable frame - will be added in a follow-up
    patch.
    
    Also take the opportunity to:
    - Remove a comment in sja1105_filter made obsolete by e8d67fa5696e
      ("net: dsa: sja1105: Don't store frame type in skb->cb")
    - Reorder the checks in sja1105_filter to optimize for the most likely
      scenario first: regular traffic.
    
    Signed-off-by: Vladimir Oltean <olteanv@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dsa/tag_sja1105.c b/net/dsa/tag_sja1105.c
index 094711ced5c0..5b51e96130c7 100644
--- a/net/dsa/tag_sja1105.c
+++ b/net/dsa/tag_sja1105.c
@@ -24,6 +24,36 @@ static inline bool sja1105_is_link_local(const struct sk_buff *skb)
 	return false;
 }
 
+struct sja1105_meta {
+	u64 tstamp;
+	u64 dmac_byte_4;
+	u64 dmac_byte_3;
+	u64 source_port;
+	u64 switch_id;
+};
+
+static void sja1105_meta_unpack(const struct sk_buff *skb,
+				struct sja1105_meta *meta)
+{
+	u8 *buf = skb_mac_header(skb) + ETH_HLEN;
+
+	/* UM10944.pdf section 4.2.17 AVB Parameters:
+	 * Structure of the meta-data follow-up frame.
+	 * It is in network byte order, so there are no quirks
+	 * while unpacking the meta frame.
+	 *
+	 * Also SJA1105 E/T only populates bits 23:0 of the timestamp
+	 * whereas P/Q/R/S does 32 bits. Since the structure is the
+	 * same and the E/T puts zeroes in the high-order byte, use
+	 * a unified unpacking command for both device series.
+	 */
+	packing(buf,     &meta->tstamp,     31, 0, 4, UNPACK, 0);
+	packing(buf + 4, &meta->dmac_byte_4, 7, 0, 1, UNPACK, 0);
+	packing(buf + 5, &meta->dmac_byte_3, 7, 0, 1, UNPACK, 0);
+	packing(buf + 6, &meta->source_port, 7, 0, 1, UNPACK, 0);
+	packing(buf + 7, &meta->switch_id,   7, 0, 1, UNPACK, 0);
+}
+
 static inline bool sja1105_is_meta_frame(const struct sk_buff *skb)
 {
 	const struct ethhdr *hdr = eth_hdr(skb);
@@ -40,14 +70,15 @@ static inline bool sja1105_is_meta_frame(const struct sk_buff *skb)
 }
 
 /* This is the first time the tagger sees the frame on RX.
- * Figure out if we can decode it, and if we can, annotate skb->cb with how we
- * plan to do that, so we don't need to check again in the rcv function.
+ * Figure out if we can decode it.
  */
 static bool sja1105_filter(const struct sk_buff *skb, struct net_device *dev)
 {
+	if (!dsa_port_is_vlan_filtering(dev->dsa_ptr))
+		return true;
 	if (sja1105_is_link_local(skb))
 		return true;
-	if (!dsa_port_is_vlan_filtering(dev->dsa_ptr))
+	if (sja1105_is_meta_frame(skb))
 		return true;
 	return false;
 }
@@ -83,16 +114,19 @@ static struct sk_buff *sja1105_rcv(struct sk_buff *skb,
 				   struct net_device *netdev,
 				   struct packet_type *pt)
 {
+	struct sja1105_meta meta = {0};
 	int source_port, switch_id;
 	struct vlan_ethhdr *hdr;
 	u16 tpid, vid, tci;
 	bool is_link_local;
 	bool is_tagged;
+	bool is_meta;
 
 	hdr = vlan_eth_hdr(skb);
 	tpid = ntohs(hdr->h_vlan_proto);
 	is_tagged = (tpid == ETH_P_SJA1105);
 	is_link_local = sja1105_is_link_local(skb);
+	is_meta = sja1105_is_meta_frame(skb);
 
 	skb->offload_fwd_mark = 1;
 
@@ -113,6 +147,10 @@ static struct sk_buff *sja1105_rcv(struct sk_buff *skb,
 		/* Clear the DMAC bytes that were mangled by the switch */
 		hdr->h_dest[3] = 0;
 		hdr->h_dest[4] = 0;
+	} else if (is_meta) {
+		sja1105_meta_unpack(skb, &meta);
+		source_port = meta.source_port;
+		switch_id = meta.switch_id;
 	} else {
 		return NULL;
 	}

commit 79fa7061397a372256b466d62a0a81690b512d5f
Author: Vladimir Oltean <olteanv@gmail.com>
Date:   Sat Jun 8 15:04:38 2019 +0300

    net: dsa: sja1105: Make sja1105_is_link_local not match meta frames
    
    Although meta frames are configured to be sent at SJA1105_META_DMAC
    (01-80-C2-00-00-0E) which is a multicast MAC address that would also be
    trapped by the switch to the CPU, were it to receive it on a front-panel
    port, meta frames are conceptually not link-local frames, they only
    carry their RX timestamps.
    
    The choice of sending meta frames at a multicast DMAC is a pragmatic
    one, to avoid installing an extra entry to the DSA master port's
    multicast MAC filter.
    
    Signed-off-by: Vladimir Oltean <olteanv@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dsa/tag_sja1105.c b/net/dsa/tag_sja1105.c
index 0beb52518d56..094711ced5c0 100644
--- a/net/dsa/tag_sja1105.c
+++ b/net/dsa/tag_sja1105.c
@@ -13,6 +13,8 @@ static inline bool sja1105_is_link_local(const struct sk_buff *skb)
 	const struct ethhdr *hdr = eth_hdr(skb);
 	u64 dmac = ether_addr_to_u64(hdr->h_dest);
 
+	if (ntohs(hdr->h_proto) == ETH_P_SJA1105_META)
+		return false;
 	if ((dmac & SJA1105_LINKLOCAL_FILTER_A_MASK) ==
 		    SJA1105_LINKLOCAL_FILTER_A)
 		return true;

commit d3f9b90bf19fad05889e4bead7dc1b336da56118
Author: Vladimir Oltean <olteanv@gmail.com>
Date:   Sat Jun 8 15:04:36 2019 +0300

    net: dsa: sja1105: Build a minimal understanding of meta frames
    
    Meta frames are sent on the CPU port by the switch if RX timestamping is
    enabled. They contain a partial timestamp of the previous frame.
    
    They are Ethernet frames with the Ethernet header constructed out of:
    
    - SJA1105_META_DMAC
    - SJA1105_META_SMAC
    - ETH_P_SJA1105_META
    
    The Ethernet payload will be decoded in a follow-up patch.
    
    Signed-off-by: Vladimir Oltean <olteanv@gmail.com>
    Reviewed-by: Florian Fainelli <f.fainelli@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dsa/tag_sja1105.c b/net/dsa/tag_sja1105.c
index cd8e0bfb5e75..0beb52518d56 100644
--- a/net/dsa/tag_sja1105.c
+++ b/net/dsa/tag_sja1105.c
@@ -22,6 +22,21 @@ static inline bool sja1105_is_link_local(const struct sk_buff *skb)
 	return false;
 }
 
+static inline bool sja1105_is_meta_frame(const struct sk_buff *skb)
+{
+	const struct ethhdr *hdr = eth_hdr(skb);
+	u64 smac = ether_addr_to_u64(hdr->h_source);
+	u64 dmac = ether_addr_to_u64(hdr->h_dest);
+
+	if (smac != SJA1105_META_SMAC)
+		return false;
+	if (dmac != SJA1105_META_DMAC)
+		return false;
+	if (ntohs(hdr->h_proto) != ETH_P_SJA1105_META)
+		return false;
+	return true;
+}
+
 /* This is the first time the tagger sees the frame on RX.
  * Figure out if we can decode it, and if we can, annotate skb->cb with how we
  * plan to do that, so we don't need to check again in the rcv function.

commit 42824463d38d273194376051d7883724aea1b0ac
Author: Vladimir Oltean <olteanv@gmail.com>
Date:   Sat Jun 8 15:04:32 2019 +0300

    net: dsa: sja1105: Limit use of incl_srcpt to bridge+vlan mode
    
    The incl_srcpt setting makes the switch mangle the destination MACs of
    multicast frames trapped to the CPU - a primitive tagging mechanism that
    works even when we cannot use the 802.1Q software features.
    
    The downside is that the two multicast MAC addresses that the switch
    traps for L2 PTP (01-80-C2-00-00-0E and 01-1B-19-00-00-00) quickly turn
    into a lot more, as the switch encodes the source port and switch id
    into bytes 3 and 4 of the MAC. The resulting range of MAC addresses
    would need to be installed manually into the DSA master port's multicast
    MAC filter, and even then, most devices might not have a large enough
    MAC filtering table.
    
    As a result, only limit use of incl_srcpt to when it's strictly
    necessary: when under a VLAN filtering bridge.  This fixes PTP in
    non-bridged mode (standalone ports). Otherwise, PTP frames, as well as
    metadata follow-up frames holding RX timestamps won't be received
    because they will be blocked by the master port's MAC filter.
    Linuxptp doesn't help, because it only requests the addition of the
    unmodified PTP MACs to the multicast filter.
    This issue is not seen in bridged mode because the master port is put in
    promiscuous mode when the slave ports are enslaved to a bridge.
    Therefore, there is no downside to having the incl_srcpt mechanism
    active there.
    
    Signed-off-by: Vladimir Oltean <olteanv@gmail.com>
    Reviewed-by: Florian Fainelli <f.fainelli@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dsa/tag_sja1105.c b/net/dsa/tag_sja1105.c
index 77eeea004e92..cd8e0bfb5e75 100644
--- a/net/dsa/tag_sja1105.c
+++ b/net/dsa/tag_sja1105.c
@@ -69,15 +69,24 @@ static struct sk_buff *sja1105_rcv(struct sk_buff *skb,
 	int source_port, switch_id;
 	struct vlan_ethhdr *hdr;
 	u16 tpid, vid, tci;
+	bool is_link_local;
 	bool is_tagged;
 
 	hdr = vlan_eth_hdr(skb);
 	tpid = ntohs(hdr->h_vlan_proto);
 	is_tagged = (tpid == ETH_P_SJA1105);
+	is_link_local = sja1105_is_link_local(skb);
 
 	skb->offload_fwd_mark = 1;
 
-	if (sja1105_is_link_local(skb)) {
+	if (is_tagged) {
+		/* Normal traffic path. */
+		tci = ntohs(hdr->h_vlan_TCI);
+		vid = tci & VLAN_VID_MASK;
+		source_port = dsa_8021q_rx_source_port(vid);
+		switch_id = dsa_8021q_rx_switch_id(vid);
+		skb->priority = (tci & VLAN_PRIO_MASK) >> VLAN_PRIO_SHIFT;
+	} else if (is_link_local) {
 		/* Management traffic path. Switch embeds the switch ID and
 		 * port ID into bytes of the destination MAC, courtesy of
 		 * the incl_srcpt options.
@@ -88,12 +97,7 @@ static struct sk_buff *sja1105_rcv(struct sk_buff *skb,
 		hdr->h_dest[3] = 0;
 		hdr->h_dest[4] = 0;
 	} else {
-		/* Normal traffic path. */
-		tci = ntohs(hdr->h_vlan_TCI);
-		vid = tci & VLAN_VID_MASK;
-		source_port = dsa_8021q_rx_source_port(vid);
-		switch_id = dsa_8021q_rx_switch_id(vid);
-		skb->priority = (tci & VLAN_PRIO_MASK) >> VLAN_PRIO_SHIFT;
+		return NULL;
 	}
 
 	skb->dev = dsa_master_find_slave(netdev, switch_id, source_port);

commit d461933638ae9fa49ad22f60a40de5b3ed414912
Author: Vladimir Oltean <olteanv@gmail.com>
Date:   Sat Jun 8 15:04:29 2019 +0300

    net: dsa: tag_8021q: Create helper function for removing VLAN header
    
    This removes the existing implementation from tag_sja1105, which was
    partially incorrect (it was not changing the MAC header offset, thereby
    leaving it to point 4 bytes earlier than it should have).
    
    This overwrites the VLAN tag by moving the Ethernet source and
    destination MACs 4 bytes to the right. Then skb->data (assumed to be
    pointing immediately after the EtherType) is temporarily pushed to the
    beginning of the new Ethernet header, the new Ethernet header offset and
    length are recorded, then skb->data is moved back to where it was.
    
    Signed-off-by: Vladimir Oltean <olteanv@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dsa/tag_sja1105.c b/net/dsa/tag_sja1105.c
index d43737e6c3fb..77eeea004e92 100644
--- a/net/dsa/tag_sja1105.c
+++ b/net/dsa/tag_sja1105.c
@@ -66,17 +66,14 @@ static struct sk_buff *sja1105_rcv(struct sk_buff *skb,
 				   struct net_device *netdev,
 				   struct packet_type *pt)
 {
-	struct ethhdr *hdr = eth_hdr(skb);
-	u64 source_port, switch_id;
-	struct sk_buff *nskb;
+	int source_port, switch_id;
+	struct vlan_ethhdr *hdr;
 	u16 tpid, vid, tci;
 	bool is_tagged;
 
-	nskb = dsa_8021q_rcv(skb, netdev, pt, &tpid, &tci);
-	is_tagged = (nskb && tpid == ETH_P_SJA1105);
-
-	skb->priority = (tci & VLAN_PRIO_MASK) >> VLAN_PRIO_SHIFT;
-	vid = tci & VLAN_VID_MASK;
+	hdr = vlan_eth_hdr(skb);
+	tpid = ntohs(hdr->h_vlan_proto);
+	is_tagged = (tpid == ETH_P_SJA1105);
 
 	skb->offload_fwd_mark = 1;
 
@@ -92,8 +89,11 @@ static struct sk_buff *sja1105_rcv(struct sk_buff *skb,
 		hdr->h_dest[4] = 0;
 	} else {
 		/* Normal traffic path. */
+		tci = ntohs(hdr->h_vlan_TCI);
+		vid = tci & VLAN_VID_MASK;
 		source_port = dsa_8021q_rx_source_port(vid);
 		switch_id = dsa_8021q_rx_switch_id(vid);
+		skb->priority = (tci & VLAN_PRIO_MASK) >> VLAN_PRIO_SHIFT;
 	}
 
 	skb->dev = dsa_master_find_slave(netdev, switch_id, source_port);
@@ -106,8 +106,7 @@ static struct sk_buff *sja1105_rcv(struct sk_buff *skb,
 	 * it there, see dsa_switch_rcv: skb_push(skb, ETH_HLEN).
 	 */
 	if (is_tagged)
-		memmove(skb->data - ETH_HLEN, skb->data - ETH_HLEN - VLAN_HLEN,
-			ETH_HLEN - VLAN_HLEN);
+		skb = dsa_8021q_remove_header(skb);
 
 	return skb;
 }

commit e8d67fa5696e2fcaf956dae36d11e6eff5246101
Author: Vladimir Oltean <olteanv@gmail.com>
Date:   Thu May 30 00:51:26 2019 +0300

    net: dsa: sja1105: Don't store frame type in skb->cb
    
    Due to a confusion I thought that eth_type_trans() was called by the
    network stack whereas it can actually be called by network drivers to
    figure out the skb protocol and next packet_type handlers.
    
    In light of the above, it is not safe to store the frame type from the
    DSA tagger's .filter callback (first entry point on RX path), since GRO
    is yet to be invoked on the received traffic.  Hence it is very likely
    that the skb->cb will actually get overwritten between eth_type_trans()
    and the actual DSA packet_type handler.
    
    Of course, what this patch fixes is the actual overwriting of the
    SJA1105_SKB_CB(skb)->type field from the GRO layer, which made all
    frames be seen as SJA1105_FRAME_TYPE_NORMAL (0).
    
    Fixes: 227d07a07ef1 ("net: dsa: sja1105: Add support for traffic through standalone ports")
    Signed-off-by: Vladimir Oltean <olteanv@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dsa/tag_sja1105.c b/net/dsa/tag_sja1105.c
index 969402c7dbf1..d43737e6c3fb 100644
--- a/net/dsa/tag_sja1105.c
+++ b/net/dsa/tag_sja1105.c
@@ -28,14 +28,10 @@ static inline bool sja1105_is_link_local(const struct sk_buff *skb)
  */
 static bool sja1105_filter(const struct sk_buff *skb, struct net_device *dev)
 {
-	if (sja1105_is_link_local(skb)) {
-		SJA1105_SKB_CB(skb)->type = SJA1105_FRAME_TYPE_LINK_LOCAL;
+	if (sja1105_is_link_local(skb))
 		return true;
-	}
-	if (!dsa_port_is_vlan_filtering(dev->dsa_ptr)) {
-		SJA1105_SKB_CB(skb)->type = SJA1105_FRAME_TYPE_NORMAL;
+	if (!dsa_port_is_vlan_filtering(dev->dsa_ptr))
 		return true;
-	}
 	return false;
 }
 
@@ -84,7 +80,7 @@ static struct sk_buff *sja1105_rcv(struct sk_buff *skb,
 
 	skb->offload_fwd_mark = 1;
 
-	if (SJA1105_SKB_CB(skb)->type == SJA1105_FRAME_TYPE_LINK_LOCAL) {
+	if (sja1105_is_link_local(skb)) {
 		/* Management traffic path. Switch embeds the switch ID and
 		 * port ID into bytes of the destination MAC, courtesy of
 		 * the incl_srcpt options.

commit 227d07a07ef126272ea2eed97fd136cd7a803d81
Author: Vladimir Oltean <olteanv@gmail.com>
Date:   Sun May 5 13:19:27 2019 +0300

    net: dsa: sja1105: Add support for traffic through standalone ports
    
    In order to support this, we are creating a make-shift switch tag out of
    a VLAN trunk configured on the CPU port. Termination of normal traffic
    on switch ports only works when not under a vlan_filtering bridge.
    Termination of management (PTP, BPDU) traffic works under all
    circumstances because it uses a different tagging mechanism
    (incl_srcpt). We are making use of the generic CONFIG_NET_DSA_TAG_8021Q
    code and leveraging it from our own CONFIG_NET_DSA_TAG_SJA1105.
    
    There are two types of traffic: regular and link-local.
    
    The link-local traffic received on the CPU port is trapped from the
    switch's regular forwarding decisions because it matched one of the two
    DMAC filters for management traffic.
    
    On transmission, the switch requires special massaging for these
    link-local frames. Due to a weird implementation of the switching IP, by
    default it drops link-local frames that originate on the CPU port.
    It needs to be told where to forward them to, through an SPI command
    ("management route") that is valid for only a single frame.
    So when we're sending link-local traffic, we are using the
    dsa_defer_xmit mechanism.
    
    Signed-off-by: Vladimir Oltean <olteanv@gmail.com>
    Reviewed-by: Florian Fainelli <f.fainelli@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dsa/tag_sja1105.c b/net/dsa/tag_sja1105.c
new file mode 100644
index 000000000000..969402c7dbf1
--- /dev/null
+++ b/net/dsa/tag_sja1105.c
@@ -0,0 +1,131 @@
+// SPDX-License-Identifier: GPL-2.0
+/* Copyright (c) 2019, Vladimir Oltean <olteanv@gmail.com>
+ */
+#include <linux/if_vlan.h>
+#include <linux/dsa/sja1105.h>
+#include <linux/dsa/8021q.h>
+#include <linux/packing.h>
+#include "dsa_priv.h"
+
+/* Similar to is_link_local_ether_addr(hdr->h_dest) but also covers PTP */
+static inline bool sja1105_is_link_local(const struct sk_buff *skb)
+{
+	const struct ethhdr *hdr = eth_hdr(skb);
+	u64 dmac = ether_addr_to_u64(hdr->h_dest);
+
+	if ((dmac & SJA1105_LINKLOCAL_FILTER_A_MASK) ==
+		    SJA1105_LINKLOCAL_FILTER_A)
+		return true;
+	if ((dmac & SJA1105_LINKLOCAL_FILTER_B_MASK) ==
+		    SJA1105_LINKLOCAL_FILTER_B)
+		return true;
+	return false;
+}
+
+/* This is the first time the tagger sees the frame on RX.
+ * Figure out if we can decode it, and if we can, annotate skb->cb with how we
+ * plan to do that, so we don't need to check again in the rcv function.
+ */
+static bool sja1105_filter(const struct sk_buff *skb, struct net_device *dev)
+{
+	if (sja1105_is_link_local(skb)) {
+		SJA1105_SKB_CB(skb)->type = SJA1105_FRAME_TYPE_LINK_LOCAL;
+		return true;
+	}
+	if (!dsa_port_is_vlan_filtering(dev->dsa_ptr)) {
+		SJA1105_SKB_CB(skb)->type = SJA1105_FRAME_TYPE_NORMAL;
+		return true;
+	}
+	return false;
+}
+
+static struct sk_buff *sja1105_xmit(struct sk_buff *skb,
+				    struct net_device *netdev)
+{
+	struct dsa_port *dp = dsa_slave_to_port(netdev);
+	struct dsa_switch *ds = dp->ds;
+	u16 tx_vid = dsa_8021q_tx_vid(ds, dp->index);
+	u8 pcp = skb->priority;
+
+	/* Transmitting management traffic does not rely upon switch tagging,
+	 * but instead SPI-installed management routes. Part 2 of this
+	 * is the .port_deferred_xmit driver callback.
+	 */
+	if (unlikely(sja1105_is_link_local(skb)))
+		return dsa_defer_xmit(skb, netdev);
+
+	/* If we are under a vlan_filtering bridge, IP termination on
+	 * switch ports based on 802.1Q tags is simply too brittle to
+	 * be passable. So just defer to the dsa_slave_notag_xmit
+	 * implementation.
+	 */
+	if (dsa_port_is_vlan_filtering(dp))
+		return skb;
+
+	return dsa_8021q_xmit(skb, netdev, ETH_P_SJA1105,
+			     ((pcp << VLAN_PRIO_SHIFT) | tx_vid));
+}
+
+static struct sk_buff *sja1105_rcv(struct sk_buff *skb,
+				   struct net_device *netdev,
+				   struct packet_type *pt)
+{
+	struct ethhdr *hdr = eth_hdr(skb);
+	u64 source_port, switch_id;
+	struct sk_buff *nskb;
+	u16 tpid, vid, tci;
+	bool is_tagged;
+
+	nskb = dsa_8021q_rcv(skb, netdev, pt, &tpid, &tci);
+	is_tagged = (nskb && tpid == ETH_P_SJA1105);
+
+	skb->priority = (tci & VLAN_PRIO_MASK) >> VLAN_PRIO_SHIFT;
+	vid = tci & VLAN_VID_MASK;
+
+	skb->offload_fwd_mark = 1;
+
+	if (SJA1105_SKB_CB(skb)->type == SJA1105_FRAME_TYPE_LINK_LOCAL) {
+		/* Management traffic path. Switch embeds the switch ID and
+		 * port ID into bytes of the destination MAC, courtesy of
+		 * the incl_srcpt options.
+		 */
+		source_port = hdr->h_dest[3];
+		switch_id = hdr->h_dest[4];
+		/* Clear the DMAC bytes that were mangled by the switch */
+		hdr->h_dest[3] = 0;
+		hdr->h_dest[4] = 0;
+	} else {
+		/* Normal traffic path. */
+		source_port = dsa_8021q_rx_source_port(vid);
+		switch_id = dsa_8021q_rx_switch_id(vid);
+	}
+
+	skb->dev = dsa_master_find_slave(netdev, switch_id, source_port);
+	if (!skb->dev) {
+		netdev_warn(netdev, "Couldn't decode source port\n");
+		return NULL;
+	}
+
+	/* Delete/overwrite fake VLAN header, DSA expects to not find
+	 * it there, see dsa_switch_rcv: skb_push(skb, ETH_HLEN).
+	 */
+	if (is_tagged)
+		memmove(skb->data - ETH_HLEN, skb->data - ETH_HLEN - VLAN_HLEN,
+			ETH_HLEN - VLAN_HLEN);
+
+	return skb;
+}
+
+static struct dsa_device_ops sja1105_netdev_ops = {
+	.name = "sja1105",
+	.proto = DSA_TAG_PROTO_SJA1105,
+	.xmit = sja1105_xmit,
+	.rcv = sja1105_rcv,
+	.filter = sja1105_filter,
+	.overhead = VLAN_HLEN,
+};
+
+MODULE_LICENSE("GPL v2");
+MODULE_ALIAS_DSA_TAG_DRIVER(DSA_TAG_PROTO_SJA1105);
+
+module_dsa_tag_driver(sja1105_netdev_ops);
