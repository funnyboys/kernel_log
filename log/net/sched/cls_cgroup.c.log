commit 2874c5fd284268364ece81a7bd936f3c8168e567
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon May 27 08:55:01 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 152
    
    Based on 1 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license as published by
      the free software foundation either version 2 of the license or at
      your option any later version
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-or-later
    
    has been chosen to replace the boilerplate/reference in 3029 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190527070032.746973796@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index 35659127e5a3..fb881144fa01 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -1,11 +1,7 @@
+// SPDX-License-Identifier: GPL-2.0-or-later
 /*
  * net/sched/cls_cgroup.c	Control Group Classifier
  *
- *		This program is free software; you can redistribute it and/or
- *		modify it under the terms of the GNU General Public License
- *		as published by the Free Software Foundation; either version
- *		2 of the License, or (at your option) any later version.
- *
  * Authors:	Thomas Graf <tgraf@suug.ch>
  */
 

commit a9e41a529681b38087c91ebc0bb91e12f510ca2d
Merge: 23bfaa594002 a3147770bea7
Author: David S. Miller <davem@davemloft.net>
Date:   Tue May 7 17:22:09 2019 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/davem/net
    
    Minor conflict with the DSA legacy code removal.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 594725db0ce11b2fd70f672d7540fa43c7f2f627
Author: Matteo Croce <mcroce@redhat.com>
Date:   Thu May 2 17:13:18 2019 +0200

    cls_cgroup: avoid panic when receiving a packet before filter set
    
    When a cgroup classifier is added, there is a small time interval in
    which tp->root is NULL. If we receive a packet in this small time slice
    a NULL pointer dereference will happen, leading to a kernel panic:
    
        # mkdir /sys/fs/cgroup/net_cls/0
        # echo 0x100001 >  /sys/fs/cgroup/net_cls/0/net_cls.classid
        # echo $$ >/sys/fs/cgroup/net_cls/0/tasks
        # ping -qfb 255.255.255.255 -I eth0 &>/dev/null &
        # tc qdisc add dev eth0 root handle 10: htb
        # while : ; do
        > tc filter add dev eth0 parent 10: protocol ip prio 10 handle 1: cgroup
        > tc filter delete dev eth0
        > done
        Unable to handle kernel NULL pointer dereference at virtual address 0000000000000028
        Mem abort info:
          ESR = 0x96000005
          Exception class = DABT (current EL), IL = 32 bits
          SET = 0, FnV = 0
          EA = 0, S1PTW = 0
        Data abort info:
          ISV = 0, ISS = 0x00000005
          CM = 0, WnR = 0
        user pgtable: 4k pages, 39-bit VAs, pgdp = 0000000098a7ff91
        [0000000000000028] pgd=0000000000000000, pud=0000000000000000
        Internal error: Oops: 96000005 [#1] SMP
        Modules linked in: sch_htb cls_cgroup algif_hash af_alg nls_iso8859_1 nls_cp437 vfat fat xhci_plat_hcd m25p80 spi_nor xhci_hcd mtd usbcore usb_common spi_orion sfp i2c_mv64xxx phy_generic mdio_i2c marvell10g i2c_core mvpp2 mvmdio phylink sbsa_gwdt ip_tables x_tables autofs4
        Process ping (pid: 5421, stack limit = 0x00000000b20b1505)
        CPU: 3 PID: 5421 Comm: ping Not tainted 5.1.0-rc6 #31
        Hardware name: Marvell 8040 MACCHIATOBin Double-shot (DT)
        pstate: 60000005 (nZCv daif -PAN -UAO)
        pc : cls_cgroup_classify+0x80/0xec [cls_cgroup]
        lr : cls_cgroup_classify+0x34/0xec [cls_cgroup]
        sp : ffffff8012e6b850
        x29: ffffff8012e6b850 x28: ffffffc423dd3c00
        x27: ffffff801093ebc0 x26: ffffffc425a85b00
        x25: 0000000020000000 x24: 0000000000000000
        x23: ffffff8012e6b910 x22: ffffffc428db4900
        x21: ffffff8012e6b910 x20: 0000000000100001
        x19: 0000000000000000 x18: 0000000000000000
        x17: 0000000000000000 x16: 0000000000000000
        x15: 0000000000000000 x14: 0000000000000000
        x13: 0000000000000000 x12: 000000000000001c
        x11: 0000000000000018 x10: ffffff8012e6b840
        x9 : 0000000000003580 x8 : 000000000000009d
        x7 : 0000000000000002 x6 : ffffff8012e6b860
        x5 : 000000007cd66ffe x4 : 000000009742a193
        x3 : ffffff800865b4d8 x2 : ffffff8012e6b910
        x1 : 0000000000000400 x0 : ffffffc42c38f300
        Call trace:
         cls_cgroup_classify+0x80/0xec [cls_cgroup]
         tcf_classify+0x78/0x138
         htb_enqueue+0x74/0x320 [sch_htb]
         __dev_queue_xmit+0x3e4/0x9d0
         dev_queue_xmit+0x24/0x30
         ip_finish_output2+0x2e4/0x4d0
         ip_finish_output+0x1d8/0x270
         ip_mc_output+0xa8/0x240
         ip_local_out+0x58/0x68
         ip_send_skb+0x2c/0x88
         ip_push_pending_frames+0x44/0x50
         raw_sendmsg+0x458/0x830
         inet_sendmsg+0x54/0xe8
         sock_sendmsg+0x34/0x50
         __sys_sendto+0xd0/0x120
         __arm64_sys_sendto+0x30/0x40
         el0_svc_common.constprop.0+0x88/0xf8
         el0_svc_handler+0x2c/0x38
         el0_svc+0x8/0xc
        Code: 39496001 360002a1 b9425c14 34000274 (79405260)
    
    Fixes: ed76f5edccc9 ("net: sched: protect filter_chain list with filter_chain_lock mutex")
    Suggested-by: Cong Wang <xiyou.wangcong@gmail.com>
    Signed-off-by: Matteo Croce <mcroce@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index 4c1567854f95..706a160142ea 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -32,6 +32,8 @@ static int cls_cgroup_classify(struct sk_buff *skb, const struct tcf_proto *tp,
 	struct cls_cgroup_head *head = rcu_dereference_bh(tp->root);
 	u32 classid = task_get_classid(skb);
 
+	if (unlikely(!head))
+		return -1;
 	if (!classid)
 		return -1;
 	if (!tcf_em_tree_match(skb, &head->ematches, NULL))

commit 8cb081746c031fb164089322e2336a0bf5b3070c
Author: Johannes Berg <johannes.berg@intel.com>
Date:   Fri Apr 26 14:07:28 2019 +0200

    netlink: make validation more configurable for future strictness
    
    We currently have two levels of strict validation:
    
     1) liberal (default)
         - undefined (type >= max) & NLA_UNSPEC attributes accepted
         - attribute length >= expected accepted
         - garbage at end of message accepted
     2) strict (opt-in)
         - NLA_UNSPEC attributes accepted
         - attribute length >= expected accepted
    
    Split out parsing strictness into four different options:
     * TRAILING     - check that there's no trailing data after parsing
                      attributes (in message or nested)
     * MAXTYPE      - reject attrs > max known type
     * UNSPEC       - reject attributes with NLA_UNSPEC policy entries
     * STRICT_ATTRS - strictly validate attribute size
    
    The default for future things should be *everything*.
    The current *_strict() is a combination of TRAILING and MAXTYPE,
    and is renamed to _deprecated_strict().
    The current regular parsing has none of this, and is renamed to
    *_parse_deprecated().
    
    Additionally it allows us to selectively set one of the new flags
    even on old policies. Notably, the UNSPEC flag could be useful in
    this case, since it can be arranged (by filling in the policy) to
    not be an incompatible userspace ABI change, but would then going
    forward prevent forgetting attribute entries. Similar can apply
    to the POLICY flag.
    
    We end up with the following renames:
     * nla_parse           -> nla_parse_deprecated
     * nla_parse_strict    -> nla_parse_deprecated_strict
     * nlmsg_parse         -> nlmsg_parse_deprecated
     * nlmsg_parse_strict  -> nlmsg_parse_deprecated_strict
     * nla_parse_nested    -> nla_parse_nested_deprecated
     * nla_validate_nested -> nla_validate_nested_deprecated
    
    Using spatch, of course:
        @@
        expression TB, MAX, HEAD, LEN, POL, EXT;
        @@
        -nla_parse(TB, MAX, HEAD, LEN, POL, EXT)
        +nla_parse_deprecated(TB, MAX, HEAD, LEN, POL, EXT)
    
        @@
        expression NLH, HDRLEN, TB, MAX, POL, EXT;
        @@
        -nlmsg_parse(NLH, HDRLEN, TB, MAX, POL, EXT)
        +nlmsg_parse_deprecated(NLH, HDRLEN, TB, MAX, POL, EXT)
    
        @@
        expression NLH, HDRLEN, TB, MAX, POL, EXT;
        @@
        -nlmsg_parse_strict(NLH, HDRLEN, TB, MAX, POL, EXT)
        +nlmsg_parse_deprecated_strict(NLH, HDRLEN, TB, MAX, POL, EXT)
    
        @@
        expression TB, MAX, NLA, POL, EXT;
        @@
        -nla_parse_nested(TB, MAX, NLA, POL, EXT)
        +nla_parse_nested_deprecated(TB, MAX, NLA, POL, EXT)
    
        @@
        expression START, MAX, POL, EXT;
        @@
        -nla_validate_nested(START, MAX, POL, EXT)
        +nla_validate_nested_deprecated(START, MAX, POL, EXT)
    
        @@
        expression NLH, HDRLEN, MAX, POL, EXT;
        @@
        -nlmsg_validate(NLH, HDRLEN, MAX, POL, EXT)
        +nlmsg_validate_deprecated(NLH, HDRLEN, MAX, POL, EXT)
    
    For this patch, don't actually add the strict, non-renamed versions
    yet so that it breaks compile if I get it wrong.
    
    Also, while at it, make nla_validate and nla_parse go down to a
    common __nla_validate_parse() function to avoid code duplication.
    
    Ultimately, this allows us to have very strict validation for every
    new caller of nla_parse()/nlmsg_parse() etc as re-introduced in the
    next patch, while existing things will continue to work as is.
    
    In effect then, this adds fully strict validation for any new command.
    
    Signed-off-by: Johannes Berg <johannes.berg@intel.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index b680dd684282..037d128c2851 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -104,8 +104,9 @@ static int cls_cgroup_change(struct net *net, struct sk_buff *in_skb,
 		goto errout;
 	new->handle = handle;
 	new->tp = tp;
-	err = nla_parse_nested(tb, TCA_CGROUP_MAX, tca[TCA_OPTIONS],
-			       cgroup_policy, NULL);
+	err = nla_parse_nested_deprecated(tb, TCA_CGROUP_MAX,
+					  tca[TCA_OPTIONS], cgroup_policy,
+					  NULL);
 	if (err < 0)
 		goto errout;
 

commit ae0be8de9a53cda3505865c11826d8ff0640237c
Author: Michal Kubecek <mkubecek@suse.cz>
Date:   Fri Apr 26 11:13:06 2019 +0200

    netlink: make nla_nest_start() add NLA_F_NESTED flag
    
    Even if the NLA_F_NESTED flag was introduced more than 11 years ago, most
    netlink based interfaces (including recently added ones) are still not
    setting it in kernel generated messages. Without the flag, message parsers
    not aware of attribute semantics (e.g. wireshark dissector or libmnl's
    mnl_nlmsg_fprintf()) cannot recognize nested attributes and won't display
    the structure of their contents.
    
    Unfortunately we cannot just add the flag everywhere as there may be
    userspace applications which check nlattr::nla_type directly rather than
    through a helper masking out the flags. Therefore the patch renames
    nla_nest_start() to nla_nest_start_noflag() and introduces nla_nest_start()
    as a wrapper adding NLA_F_NESTED. The calls which add NLA_F_NESTED manually
    are rewritten to use nla_nest_start().
    
    Except for changes in include/net/netlink.h, the patch was generated using
    this semantic patch:
    
    @@ expression E1, E2; @@
    -nla_nest_start(E1, E2)
    +nla_nest_start_noflag(E1, E2)
    
    @@ expression E1, E2; @@
    -nla_nest_start_noflag(E1, E2 | NLA_F_NESTED)
    +nla_nest_start(E1, E2)
    
    Signed-off-by: Michal Kubecek <mkubecek@suse.cz>
    Acked-by: Jiri Pirko <jiri@mellanox.com>
    Acked-by: David Ahern <dsahern@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index 4c1567854f95..b680dd684282 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -176,7 +176,7 @@ static int cls_cgroup_dump(struct net *net, struct tcf_proto *tp, void *fh,
 
 	t->tcm_handle = head->handle;
 
-	nest = nla_nest_start(skb, TCA_OPTIONS);
+	nest = nla_nest_start_noflag(skb, TCA_OPTIONS);
 	if (nest == NULL)
 		goto nla_put_failure;
 

commit 14215108a1fd7e002c0a1f9faf8fbaf41fdda50d
Author: Cong Wang <xiyou.wangcong@gmail.com>
Date:   Wed Feb 20 21:37:42 2019 -0800

    net_sched: initialize net pointer inside tcf_exts_init()
    
    For tcindex filter, it is too late to initialize the
    net pointer in tcf_exts_validate(), as tcf_exts_get_net()
    requires a non-NULL net pointer. We can just move its
    initialization into tcf_exts_init(), which just requires
    an additional parameter.
    
    This makes the code in tcindex_alloc_perfect_hash()
    prettier.
    
    Cc: Jamal Hadi Salim <jhs@mojatatu.com>
    Cc: Jiri Pirko <jiri@resnulli.us>
    Signed-off-by: Cong Wang <xiyou.wangcong@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index 02b05066b635..4c1567854f95 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -99,7 +99,7 @@ static int cls_cgroup_change(struct net *net, struct sk_buff *in_skb,
 	if (!new)
 		return -ENOBUFS;
 
-	err = tcf_exts_init(&new->exts, TCA_CGROUP_ACT, TCA_CGROUP_POLICE);
+	err = tcf_exts_init(&new->exts, net, TCA_CGROUP_ACT, TCA_CGROUP_POLICE);
 	if (err < 0)
 		goto errout;
 	new->handle = handle;

commit 8b58d12f4ae1a10037b824b1fb409cf424d6aaac
Author: Vlad Buslov <vladbu@mellanox.com>
Date:   Fri Feb 15 17:18:44 2019 +0200

    net: sched: cgroup: verify that filter is not NULL during walk
    
    Check that filter is not NULL before passing it to tcf_walker->fn()
    callback in cls_cgroup_walk(). This can happen when cls_cgroup_change()
    failed to set first filter.
    
    Fixes: ed76f5edccc9 ("net: sched: protect filter_chain list with filter_chain_lock mutex")
    Signed-off-by: Vlad Buslov <vladbu@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index 1cef3b416094..02b05066b635 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -158,6 +158,8 @@ static void cls_cgroup_walk(struct tcf_proto *tp, struct tcf_walker *arg,
 	if (arg->count < arg->skip)
 		goto skip;
 
+	if (!head)
+		return;
 	if (arg->fn(tp, head, arg) < 0) {
 		arg->stop = 1;
 		return;

commit 12db03b65c2b90752e4c37666977fd4a1b5f5824
Author: Vlad Buslov <vladbu@mellanox.com>
Date:   Mon Feb 11 10:55:45 2019 +0200

    net: sched: extend proto ops to support unlocked classifiers
    
    Add 'rtnl_held' flag to tcf proto change, delete, destroy, dump, walk
    functions to track rtnl lock status. Extend users of these function in cls
    API to propagate rtnl lock status to them. This allows classifiers to
    obtain rtnl lock when necessary and to pass rtnl lock status to extensions
    and driver offload callbacks.
    
    Add flags field to tcf proto ops. Add flag value to indicate that
    classifier doesn't require rtnl lock.
    
    Signed-off-by: Vlad Buslov <vladbu@mellanox.com>
    Acked-by: Jiri Pirko <jiri@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index 663ee1c6d606..1cef3b416094 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -78,7 +78,7 @@ static void cls_cgroup_destroy_work(struct work_struct *work)
 static int cls_cgroup_change(struct net *net, struct sk_buff *in_skb,
 			     struct tcf_proto *tp, unsigned long base,
 			     u32 handle, struct nlattr **tca,
-			     void **arg, bool ovr,
+			     void **arg, bool ovr, bool rtnl_held,
 			     struct netlink_ext_ack *extack)
 {
 	struct nlattr *tb[TCA_CGROUP_MAX + 1];
@@ -130,7 +130,7 @@ static int cls_cgroup_change(struct net *net, struct sk_buff *in_skb,
 	return err;
 }
 
-static void cls_cgroup_destroy(struct tcf_proto *tp,
+static void cls_cgroup_destroy(struct tcf_proto *tp, bool rtnl_held,
 			       struct netlink_ext_ack *extack)
 {
 	struct cls_cgroup_head *head = rtnl_dereference(tp->root);
@@ -145,12 +145,13 @@ static void cls_cgroup_destroy(struct tcf_proto *tp,
 }
 
 static int cls_cgroup_delete(struct tcf_proto *tp, void *arg, bool *last,
-			     struct netlink_ext_ack *extack)
+			     bool rtnl_held, struct netlink_ext_ack *extack)
 {
 	return -EOPNOTSUPP;
 }
 
-static void cls_cgroup_walk(struct tcf_proto *tp, struct tcf_walker *arg)
+static void cls_cgroup_walk(struct tcf_proto *tp, struct tcf_walker *arg,
+			    bool rtnl_held)
 {
 	struct cls_cgroup_head *head = rtnl_dereference(tp->root);
 
@@ -166,7 +167,7 @@ static void cls_cgroup_walk(struct tcf_proto *tp, struct tcf_walker *arg)
 }
 
 static int cls_cgroup_dump(struct net *net, struct tcf_proto *tp, void *fh,
-			   struct sk_buff *skb, struct tcmsg *t)
+			   struct sk_buff *skb, struct tcmsg *t, bool rtnl_held)
 {
 	struct cls_cgroup_head *head = rtnl_dereference(tp->root);
 	struct nlattr *nest;

commit ec6743a10996d38e0438e5f45f2347ff2f42df0a
Author: Vlad Buslov <vladbu@mellanox.com>
Date:   Mon Feb 11 10:55:43 2019 +0200

    net: sched: track rtnl lock status when validating extensions
    
    Actions API is already updated to not rely on rtnl lock for
    synchronization. However, it need to be provided with rtnl status when
    called from classifiers API in order to be able to correctly release the
    lock when loading kernel module.
    
    Extend extension validation function with 'rtnl_held' flag which is passed
    to actions API. Add new 'rtnl_held' parameter to tcf_exts_validate() in cls
    API. No classifier is currently updated to support unlocked execution, so
    pass hardcoded 'true' flag parameter value.
    
    Signed-off-by: Vlad Buslov <vladbu@mellanox.com>
    Acked-by: Jiri Pirko <jiri@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index 3bc01bdde165..663ee1c6d606 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -110,7 +110,7 @@ static int cls_cgroup_change(struct net *net, struct sk_buff *in_skb,
 		goto errout;
 
 	err = tcf_exts_validate(net, tp, tb, tca[TCA_RATE], &new->exts, ovr,
-				extack);
+				true, extack);
 	if (err < 0)
 		goto errout;
 

commit aaa908ffbee18a65529b716efb346a626e81559a
Author: Cong Wang <xiyou.wangcong@gmail.com>
Date:   Wed May 23 15:26:53 2018 -0700

    net_sched: switch to rcu_work
    
    Commit 05f0fe6b74db ("RCU, workqueue: Implement rcu_work") introduces
    new API's for dispatching work in a RCU callback. Now we can just
    switch to the new API's for tc filters. This could get rid of a lot
    of code.
    
    Cc: Tejun Heo <tj@kernel.org>
    Cc: "Paul E. McKenney" <paulmck@linux.vnet.ibm.com>
    Cc: Jamal Hadi Salim <jhs@mojatatu.com>
    Signed-off-by: Cong Wang <xiyou.wangcong@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index 762da5c0cf5e..3bc01bdde165 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -23,10 +23,7 @@ struct cls_cgroup_head {
 	struct tcf_exts		exts;
 	struct tcf_ematch_tree	ematches;
 	struct tcf_proto	*tp;
-	union {
-		struct work_struct	work;
-		struct rcu_head		rcu;
-	};
+	struct rcu_work		rwork;
 };
 
 static int cls_cgroup_classify(struct sk_buff *skb, const struct tcf_proto *tp,
@@ -70,24 +67,14 @@ static void __cls_cgroup_destroy(struct cls_cgroup_head *head)
 
 static void cls_cgroup_destroy_work(struct work_struct *work)
 {
-	struct cls_cgroup_head *head = container_of(work,
+	struct cls_cgroup_head *head = container_of(to_rcu_work(work),
 						    struct cls_cgroup_head,
-						    work);
+						    rwork);
 	rtnl_lock();
 	__cls_cgroup_destroy(head);
 	rtnl_unlock();
 }
 
-static void cls_cgroup_destroy_rcu(struct rcu_head *root)
-{
-	struct cls_cgroup_head *head = container_of(root,
-						    struct cls_cgroup_head,
-						    rcu);
-
-	INIT_WORK(&head->work, cls_cgroup_destroy_work);
-	tcf_queue_work(&head->work);
-}
-
 static int cls_cgroup_change(struct net *net, struct sk_buff *in_skb,
 			     struct tcf_proto *tp, unsigned long base,
 			     u32 handle, struct nlattr **tca,
@@ -134,7 +121,7 @@ static int cls_cgroup_change(struct net *net, struct sk_buff *in_skb,
 	rcu_assign_pointer(tp->root, new);
 	if (head) {
 		tcf_exts_get_net(&head->exts);
-		call_rcu(&head->rcu, cls_cgroup_destroy_rcu);
+		tcf_queue_work(&head->rwork, cls_cgroup_destroy_work);
 	}
 	return 0;
 errout:
@@ -151,7 +138,7 @@ static void cls_cgroup_destroy(struct tcf_proto *tp,
 	/* Head can still be NULL due to cls_cgroup_init(). */
 	if (head) {
 		if (tcf_exts_get_net(&head->exts))
-			call_rcu(&head->rcu, cls_cgroup_destroy_rcu);
+			tcf_queue_work(&head->rwork, cls_cgroup_destroy_work);
 		else
 			__cls_cgroup_destroy(head);
 	}

commit 715df5ecab0f22685930cb8bb0cc70ed8fb9279e
Author: Jakub Kicinski <jakub.kicinski@netronome.com>
Date:   Wed Jan 24 12:54:13 2018 -0800

    net: sched: propagate extack to cls->destroy callbacks
    
    Propagate extack to cls->destroy callbacks when called from
    non-error paths.  On error paths pass NULL to avoid overwriting
    the failure message.
    
    Signed-off-by: Jakub Kicinski <jakub.kicinski@netronome.com>
    Reviewed-by: Simon Horman <simon.horman@netronome.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index 1b54fbfca414..762da5c0cf5e 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -143,7 +143,8 @@ static int cls_cgroup_change(struct net *net, struct sk_buff *in_skb,
 	return err;
 }
 
-static void cls_cgroup_destroy(struct tcf_proto *tp)
+static void cls_cgroup_destroy(struct tcf_proto *tp,
+			       struct netlink_ext_ack *extack)
 {
 	struct cls_cgroup_head *head = rtnl_dereference(tp->root);
 

commit 571acf2106963d6c1c0ce1ed13e711bd296b2d25
Author: Alexander Aring <aring@mojatatu.com>
Date:   Thu Jan 18 11:20:53 2018 -0500

    net: sched: cls: add extack support for delete callback
    
    This patch adds extack support for classifier delete callback api. This
    prepares to handle extack support inside each specific classifier
    implementation.
    
    Cc: David Ahern <dsahern@gmail.com>
    Signed-off-by: Alexander Aring <aring@mojatatu.com>
    Acked-by: Jiri Pirko <jiri@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index aaafcf6965f7..1b54fbfca414 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -156,7 +156,8 @@ static void cls_cgroup_destroy(struct tcf_proto *tp)
 	}
 }
 
-static int cls_cgroup_delete(struct tcf_proto *tp, void *arg, bool *last)
+static int cls_cgroup_delete(struct tcf_proto *tp, void *arg, bool *last,
+			     struct netlink_ext_ack *extack)
 {
 	return -EOPNOTSUPP;
 }

commit 50a561900e66a03f5127edac57487079bc0b8201
Author: Alexander Aring <aring@mojatatu.com>
Date:   Thu Jan 18 11:20:52 2018 -0500

    net: sched: cls: add extack support for tcf_exts_validate
    
    The tcf_exts_validate function calls the act api change callback. For
    preparing extack support for act api, this patch adds the extack as
    parameter for this function which is common used in cls implementations.
    
    Furthermore the tcf_exts_validate will call action init callback which
    prepares the TC action subsystem for extack support.
    
    Cc: David Ahern <dsahern@gmail.com>
    Signed-off-by: Alexander Aring <aring@mojatatu.com>
    Acked-by: Jiri Pirko <jiri@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index b74af0b55820..aaafcf6965f7 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -122,7 +122,8 @@ static int cls_cgroup_change(struct net *net, struct sk_buff *in_skb,
 	if (err < 0)
 		goto errout;
 
-	err = tcf_exts_validate(net, tp, tb, tca[TCA_RATE], &new->exts, ovr);
+	err = tcf_exts_validate(net, tp, tb, tca[TCA_RATE], &new->exts, ovr,
+				extack);
 	if (err < 0)
 		goto errout;
 

commit 7306db38a67cf6b8e1ca354b1d0c0117b7b880d5
Author: Alexander Aring <aring@mojatatu.com>
Date:   Thu Jan 18 11:20:51 2018 -0500

    net: sched: cls: add extack support for change callback
    
    This patch adds extack support for classifier change callback api. This
    prepares to handle extack support inside each specific classifier
    implementation.
    
    Cc: David Ahern <dsahern@gmail.com>
    Signed-off-by: Alexander Aring <aring@mojatatu.com>
    Acked-by: Jiri Pirko <jiri@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index 309d5899265f..b74af0b55820 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -91,7 +91,8 @@ static void cls_cgroup_destroy_rcu(struct rcu_head *root)
 static int cls_cgroup_change(struct net *net, struct sk_buff *in_skb,
 			     struct tcf_proto *tp, unsigned long base,
 			     u32 handle, struct nlattr **tca,
-			     void **arg, bool ovr)
+			     void **arg, bool ovr,
+			     struct netlink_ext_ack *extack)
 {
 	struct nlattr *tb[TCA_CGROUP_MAX + 1];
 	struct cls_cgroup_head *head = rtnl_dereference(tp->root);

commit ed1481681414e4d4264ad46864d5c1da5ff6ccb1
Author: Cong Wang <xiyou.wangcong@gmail.com>
Date:   Mon Nov 6 13:47:22 2017 -0800

    cls_cgroup: use tcf_exts_get_net() before call_rcu()
    
    Hold netns refcnt before call_rcu() and release it after
    the tcf_exts_destroy() is done.
    
    Note, on ->destroy() path we have to respect the return value
    of tcf_exts_get_net(), on other paths it should always return
    true, so we don't need to care.
    
    Cc: Lucas Bates <lucasb@mojatatu.com>
    Cc: Jamal Hadi Salim <jhs@mojatatu.com>
    Cc: Jiri Pirko <jiri@resnulli.us>
    Signed-off-by: Cong Wang <xiyou.wangcong@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index a97e069bee89..309d5899265f 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -60,15 +60,21 @@ static const struct nla_policy cgroup_policy[TCA_CGROUP_MAX + 1] = {
 	[TCA_CGROUP_EMATCHES]	= { .type = NLA_NESTED },
 };
 
+static void __cls_cgroup_destroy(struct cls_cgroup_head *head)
+{
+	tcf_exts_destroy(&head->exts);
+	tcf_em_tree_destroy(&head->ematches);
+	tcf_exts_put_net(&head->exts);
+	kfree(head);
+}
+
 static void cls_cgroup_destroy_work(struct work_struct *work)
 {
 	struct cls_cgroup_head *head = container_of(work,
 						    struct cls_cgroup_head,
 						    work);
 	rtnl_lock();
-	tcf_exts_destroy(&head->exts);
-	tcf_em_tree_destroy(&head->ematches);
-	kfree(head);
+	__cls_cgroup_destroy(head);
 	rtnl_unlock();
 }
 
@@ -124,8 +130,10 @@ static int cls_cgroup_change(struct net *net, struct sk_buff *in_skb,
 		goto errout;
 
 	rcu_assign_pointer(tp->root, new);
-	if (head)
+	if (head) {
+		tcf_exts_get_net(&head->exts);
 		call_rcu(&head->rcu, cls_cgroup_destroy_rcu);
+	}
 	return 0;
 errout:
 	tcf_exts_destroy(&new->exts);
@@ -138,8 +146,12 @@ static void cls_cgroup_destroy(struct tcf_proto *tp)
 	struct cls_cgroup_head *head = rtnl_dereference(tp->root);
 
 	/* Head can still be NULL due to cls_cgroup_init(). */
-	if (head)
-		call_rcu(&head->rcu, cls_cgroup_destroy_rcu);
+	if (head) {
+		if (tcf_exts_get_net(&head->exts))
+			call_rcu(&head->rcu, cls_cgroup_destroy_rcu);
+		else
+			__cls_cgroup_destroy(head);
+	}
 }
 
 static int cls_cgroup_delete(struct tcf_proto *tp, void *arg, bool *last)

commit b1b5b04fdb6da262aef37ef83b9f2e41326720ef
Author: Cong Wang <xiyou.wangcong@gmail.com>
Date:   Thu Oct 26 18:24:31 2017 -0700

    net_sched: use tcf_queue_work() in cgroup filter
    
    Defer the tcf_exts_destroy() in RCU callback to
    tc filter workqueue and get RTNL lock.
    
    Reported-by: Chris Mi <chrism@mellanox.com>
    Cc: Daniel Borkmann <daniel@iogearbox.net>
    Cc: Jiri Pirko <jiri@resnulli.us>
    Cc: John Fastabend <john.fastabend@gmail.com>
    Cc: Jamal Hadi Salim <jhs@mojatatu.com>
    Cc: "Paul E. McKenney" <paulmck@linux.vnet.ibm.com>
    Signed-off-by: Cong Wang <xiyou.wangcong@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index d48452f87975..a97e069bee89 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -23,7 +23,10 @@ struct cls_cgroup_head {
 	struct tcf_exts		exts;
 	struct tcf_ematch_tree	ematches;
 	struct tcf_proto	*tp;
-	struct rcu_head		rcu;
+	union {
+		struct work_struct	work;
+		struct rcu_head		rcu;
+	};
 };
 
 static int cls_cgroup_classify(struct sk_buff *skb, const struct tcf_proto *tp,
@@ -57,15 +60,26 @@ static const struct nla_policy cgroup_policy[TCA_CGROUP_MAX + 1] = {
 	[TCA_CGROUP_EMATCHES]	= { .type = NLA_NESTED },
 };
 
+static void cls_cgroup_destroy_work(struct work_struct *work)
+{
+	struct cls_cgroup_head *head = container_of(work,
+						    struct cls_cgroup_head,
+						    work);
+	rtnl_lock();
+	tcf_exts_destroy(&head->exts);
+	tcf_em_tree_destroy(&head->ematches);
+	kfree(head);
+	rtnl_unlock();
+}
+
 static void cls_cgroup_destroy_rcu(struct rcu_head *root)
 {
 	struct cls_cgroup_head *head = container_of(root,
 						    struct cls_cgroup_head,
 						    rcu);
 
-	tcf_exts_destroy(&head->exts);
-	tcf_em_tree_destroy(&head->ematches);
-	kfree(head);
+	INIT_WORK(&head->work, cls_cgroup_destroy_work);
+	tcf_queue_work(&head->work);
 }
 
 static int cls_cgroup_change(struct net *net, struct sk_buff *in_skb,

commit 8113c095672f6504b23eba6edf4a57b5f7f744af
Author: WANG Cong <xiyou.wangcong@gmail.com>
Date:   Fri Aug 4 21:31:43 2017 -0700

    net_sched: use void pointer for filter handle
    
    Now we use 'unsigned long fh' as a pointer in every place,
    it is safe to convert it to a void pointer now. This gets
    rid of many casts to pointer.
    
    Cc: Jamal Hadi Salim <jhs@mojatatu.com>
    Cc: Jiri Pirko <jiri@resnulli.us>
    Signed-off-by: Cong Wang <xiyou.wangcong@gmail.com>
    Acked-by: Jamal Hadi Salim <jhs@mojatatu.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index df7a582775df..d48452f87975 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -43,9 +43,9 @@ static int cls_cgroup_classify(struct sk_buff *skb, const struct tcf_proto *tp,
 	return tcf_exts_exec(skb, &head->exts, res);
 }
 
-static unsigned long cls_cgroup_get(struct tcf_proto *tp, u32 handle)
+static void *cls_cgroup_get(struct tcf_proto *tp, u32 handle)
 {
-	return 0UL;
+	return NULL;
 }
 
 static int cls_cgroup_init(struct tcf_proto *tp)
@@ -71,7 +71,7 @@ static void cls_cgroup_destroy_rcu(struct rcu_head *root)
 static int cls_cgroup_change(struct net *net, struct sk_buff *in_skb,
 			     struct tcf_proto *tp, unsigned long base,
 			     u32 handle, struct nlattr **tca,
-			     unsigned long *arg, bool ovr)
+			     void **arg, bool ovr)
 {
 	struct nlattr *tb[TCA_CGROUP_MAX + 1];
 	struct cls_cgroup_head *head = rtnl_dereference(tp->root);
@@ -128,7 +128,7 @@ static void cls_cgroup_destroy(struct tcf_proto *tp)
 		call_rcu(&head->rcu, cls_cgroup_destroy_rcu);
 }
 
-static int cls_cgroup_delete(struct tcf_proto *tp, unsigned long arg, bool *last)
+static int cls_cgroup_delete(struct tcf_proto *tp, void *arg, bool *last)
 {
 	return -EOPNOTSUPP;
 }
@@ -140,7 +140,7 @@ static void cls_cgroup_walk(struct tcf_proto *tp, struct tcf_walker *arg)
 	if (arg->count < arg->skip)
 		goto skip;
 
-	if (arg->fn(tp, (unsigned long) head, arg) < 0) {
+	if (arg->fn(tp, head, arg) < 0) {
 		arg->stop = 1;
 		return;
 	}
@@ -148,7 +148,7 @@ static void cls_cgroup_walk(struct tcf_proto *tp, struct tcf_walker *arg)
 	arg->count++;
 }
 
-static int cls_cgroup_dump(struct net *net, struct tcf_proto *tp, unsigned long fh,
+static int cls_cgroup_dump(struct net *net, struct tcf_proto *tp, void *fh,
 			   struct sk_buff *skb, struct tcmsg *t)
 {
 	struct cls_cgroup_head *head = rtnl_dereference(tp->root);

commit 8cc6251381183191f99ecd6d49931251ebbbe27d
Author: Jiri Pirko <jiri@mellanox.com>
Date:   Fri Aug 4 14:29:11 2017 +0200

    net: sched: cls_cgroup: no need to call tcf_exts_change for newly allocated struct
    
    As the new struct just was allocated, so no need to use tcf_exts_change
    to do atomic change, and we can just fill-up the unused exts struct
    directly by tcf_exts_validate.
    
    Signed-off-by: Jiri Pirko <jiri@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index ce7d38beab95..df7a582775df 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -76,7 +76,6 @@ static int cls_cgroup_change(struct net *net, struct sk_buff *in_skb,
 	struct nlattr *tb[TCA_CGROUP_MAX + 1];
 	struct cls_cgroup_head *head = rtnl_dereference(tp->root);
 	struct cls_cgroup_head *new;
-	struct tcf_exts e;
 	int err;
 
 	if (!tca[TCA_OPTIONS])
@@ -102,22 +101,13 @@ static int cls_cgroup_change(struct net *net, struct sk_buff *in_skb,
 	if (err < 0)
 		goto errout;
 
-	err = tcf_exts_init(&e, TCA_CGROUP_ACT, TCA_CGROUP_POLICE);
+	err = tcf_exts_validate(net, tp, tb, tca[TCA_RATE], &new->exts, ovr);
 	if (err < 0)
 		goto errout;
-	err = tcf_exts_validate(net, tp, tb, tca[TCA_RATE], &e, ovr);
-	if (err < 0) {
-		tcf_exts_destroy(&e);
-		goto errout;
-	}
 
 	err = tcf_em_tree_validate(tp, tb[TCA_CGROUP_EMATCHES], &new->ematches);
-	if (err < 0) {
-		tcf_exts_destroy(&e);
+	if (err < 0)
 		goto errout;
-	}
-
-	tcf_exts_change(tp, &new->exts, &e);
 
 	rcu_assign_pointer(tp->root, new);
 	if (head)

commit 4ebc1e3cfcd8778e2150bdb799b19e85348b8efa
Author: Jiri Pirko <jiri@mellanox.com>
Date:   Fri Aug 4 14:28:57 2017 +0200

    net: sched: remove unneeded tcf_em_tree_change
    
    Since tcf_em_tree_validate could be always called on a newly created
    filter, there is no need for this change function.
    
    Signed-off-by: Jiri Pirko <jiri@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index 12ce547eea04..ce7d38beab95 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -76,7 +76,6 @@ static int cls_cgroup_change(struct net *net, struct sk_buff *in_skb,
 	struct nlattr *tb[TCA_CGROUP_MAX + 1];
 	struct cls_cgroup_head *head = rtnl_dereference(tp->root);
 	struct cls_cgroup_head *new;
-	struct tcf_ematch_tree t;
 	struct tcf_exts e;
 	int err;
 
@@ -112,14 +111,13 @@ static int cls_cgroup_change(struct net *net, struct sk_buff *in_skb,
 		goto errout;
 	}
 
-	err = tcf_em_tree_validate(tp, tb[TCA_CGROUP_EMATCHES], &t);
+	err = tcf_em_tree_validate(tp, tb[TCA_CGROUP_EMATCHES], &new->ematches);
 	if (err < 0) {
 		tcf_exts_destroy(&e);
 		goto errout;
 	}
 
 	tcf_exts_change(tp, &new->exts, &e);
-	tcf_em_tree_change(tp, &new->ematches, &t);
 
 	rcu_assign_pointer(tp->root, new);
 	if (head)

commit 763dbf6328e41de7a55851baf5ee49e367552531
Author: WANG Cong <xiyou.wangcong@gmail.com>
Date:   Wed Apr 19 14:21:21 2017 -0700

    net_sched: move the empty tp check from ->destroy() to ->delete()
    
    We could have a race condition where in ->classify() path we
    dereference tp->root and meanwhile a parallel ->destroy() makes it
    a NULL. Daniel cured this bug in commit d936377414fa
    ("net, sched: respect rcu grace period on cls destruction").
    
    This happens when ->destroy() is called for deleting a filter to
    check if we are the last one in tp, this tp is still linked and
    visible at that time. The root cause of this problem is the semantic
    of ->destroy(), it does two things (for non-force case):
    
    1) check if tp is empty
    2) if tp is empty we could really destroy it
    
    and its caller, if cares, needs to check its return value to see if it
    is really destroyed. Therefore we can't unlink tp unless we know it is
    empty.
    
    As suggested by Daniel, we could actually move the test logic to ->delete()
    so that we can safely unlink tp after ->delete() tells us the last one is
    just deleted and before ->destroy().
    
    Fixes: 1e052be69d04 ("net_sched: destroy proto tp when all filters are gone")
    Cc: Roi Dayan <roid@mellanox.com>
    Cc: Daniel Borkmann <daniel@iogearbox.net>
    Cc: John Fastabend <john.fastabend@gmail.com>
    Cc: Jamal Hadi Salim <jhs@mojatatu.com>
    Signed-off-by: Cong Wang <xiyou.wangcong@gmail.com>
    Acked-by: Daniel Borkmann <daniel@iogearbox.net>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index b5e7c1bee6c3..12ce547eea04 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -131,20 +131,16 @@ static int cls_cgroup_change(struct net *net, struct sk_buff *in_skb,
 	return err;
 }
 
-static bool cls_cgroup_destroy(struct tcf_proto *tp, bool force)
+static void cls_cgroup_destroy(struct tcf_proto *tp)
 {
 	struct cls_cgroup_head *head = rtnl_dereference(tp->root);
 
-	if (!force)
-		return false;
 	/* Head can still be NULL due to cls_cgroup_init(). */
 	if (head)
 		call_rcu(&head->rcu, cls_cgroup_destroy_rcu);
-
-	return true;
 }
 
-static int cls_cgroup_delete(struct tcf_proto *tp, unsigned long arg)
+static int cls_cgroup_delete(struct tcf_proto *tp, unsigned long arg, bool *last)
 {
 	return -EOPNOTSUPP;
 }

commit fceb6435e85298f747fee938415057af837f5a8a
Author: Johannes Berg <johannes.berg@intel.com>
Date:   Wed Apr 12 14:34:07 2017 +0200

    netlink: pass extended ACK struct to parsing functions
    
    Pass the new extended ACK reporting struct to all of the generic
    netlink parsing functions. For now, pass NULL in almost all callers
    (except for some in the core.)
    
    Signed-off-by: Johannes Berg <johannes.berg@intel.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index c1f20077837f..b5e7c1bee6c3 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -99,7 +99,7 @@ static int cls_cgroup_change(struct net *net, struct sk_buff *in_skb,
 	new->handle = handle;
 	new->tp = tp;
 	err = nla_parse_nested(tb, TCA_CGROUP_MAX, tca[TCA_OPTIONS],
-			       cgroup_policy);
+			       cgroup_policy, NULL);
 	if (err < 0)
 		goto errout;
 

commit d936377414fadbafb4d17148d222fe45ca5442d4
Author: Daniel Borkmann <daniel@iogearbox.net>
Date:   Sun Nov 27 01:18:01 2016 +0100

    net, sched: respect rcu grace period on cls destruction
    
    Roi reported a crash in flower where tp->root was NULL in ->classify()
    callbacks. Reason is that in ->destroy() tp->root is set to NULL via
    RCU_INIT_POINTER(). It's problematic for some of the classifiers, because
    this doesn't respect RCU grace period for them, and as a result, still
    outstanding readers from tc_classify() will try to blindly dereference
    a NULL tp->root.
    
    The tp->root object is strictly private to the classifier implementation
    and holds internal data the core such as tc_ctl_tfilter() doesn't know
    about. Within some classifiers, such as cls_bpf, cls_basic, etc, tp->root
    is only checked for NULL in ->get() callback, but nowhere else. This is
    misleading and seemed to be copied from old classifier code that was not
    cleaned up properly. For example, d3fa76ee6b4a ("[NET_SCHED]: cls_basic:
    fix NULL pointer dereference") moved tp->root initialization into ->init()
    routine, where before it was part of ->change(), so ->get() had to deal
    with tp->root being NULL back then, so that was indeed a valid case, after
    d3fa76ee6b4a, not really anymore. We used to set tp->root to NULL long
    ago in ->destroy(), see 47a1a1d4be29 ("pkt_sched: remove unnecessary xchg()
    in packet classifiers"); but the NULLifying was reintroduced with the
    RCUification, but it's not correct for every classifier implementation.
    
    In the cases that are fixed here with one exception of cls_cgroup, tp->root
    object is allocated and initialized inside ->init() callback, which is always
    performed at a point in time after we allocate a new tp, which means tp and
    thus tp->root was not globally visible in the tp chain yet (see tc_ctl_tfilter()).
    Also, on destruction tp->root is strictly kfree_rcu()'ed in ->destroy()
    handler, same for the tp which is kfree_rcu()'ed right when we return
    from ->destroy() in tcf_destroy(). This means, the head object's lifetime
    for such classifiers is always tied to the tp lifetime. The RCU callback
    invocation for the two kfree_rcu() could be out of order, but that's fine
    since both are independent.
    
    Dropping the RCU_INIT_POINTER(tp->root, NULL) for these classifiers here
    means that 1) we don't need a useless NULL check in fast-path and, 2) that
    outstanding readers of that tp in tc_classify() can still execute under
    respect with RCU grace period as it is actually expected.
    
    Things that haven't been touched here: cls_fw and cls_route. They each
    handle tp->root being NULL in ->classify() path for historic reasons, so
    their ->destroy() implementation can stay as is. If someone actually
    cares, they could get cleaned up at some point to avoid the test in fast
    path. cls_u32 doesn't set tp->root to NULL. For cls_rsvp, I just added a
    !head should anyone actually be using/testing it, so it at least aligns with
    cls_fw and cls_route. For cls_flower we additionally need to defer rhashtable
    destruction (to a sleepable context) after RCU grace period as concurrent
    readers might still access it. (Note that in this case we need to hold module
    reference to keep work callback address intact, since we only wait on module
    unload for all call_rcu()s to finish.)
    
    This fixes one race to bring RCU grace period guarantees back. Next step
    as worked on by Cong however is to fix 1e052be69d04 ("net_sched: destroy
    proto tp when all filters are gone") to get the order of unlinking the tp
    in tc_ctl_tfilter() for the RTM_DELTFILTER case right by moving
    RCU_INIT_POINTER() before tcf_destroy() and let the notification for
    removal be done through the prior ->delete() callback. Both are independant
    issues. Once we have that right, we can then clean tp->root up for a number
    of classifiers by not making them RCU pointers, which requires a new callback
    (->uninit) that is triggered from tp's RCU callback, where we just kfree()
    tp->root from there.
    
    Fixes: 1f947bf151e9 ("net: sched: rcu'ify cls_bpf")
    Fixes: 9888faefe132 ("net: sched: cls_basic use RCU")
    Fixes: 70da9f0bf999 ("net: sched: cls_flow use RCU")
    Fixes: 77b9900ef53a ("tc: introduce Flower classifier")
    Fixes: bf3994d2ed31 ("net/sched: introduce Match-all classifier")
    Fixes: 952313bd6258 ("net: sched: cls_cgroup use RCU")
    Reported-by: Roi Dayan <roid@mellanox.com>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Cc: Cong Wang <xiyou.wangcong@gmail.com>
    Cc: John Fastabend <john.fastabend@gmail.com>
    Cc: Roi Dayan <roid@mellanox.com>
    Cc: Jiri Pirko <jiri@mellanox.com>
    Acked-by: John Fastabend <john.r.fastabend@intel.com>
    Acked-by: Cong Wang <xiyou.wangcong@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index 85233c470035..c1f20077837f 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -137,11 +137,10 @@ static bool cls_cgroup_destroy(struct tcf_proto *tp, bool force)
 
 	if (!force)
 		return false;
-
-	if (head) {
-		RCU_INIT_POINTER(tp->root, NULL);
+	/* Head can still be NULL due to cls_cgroup_init(). */
+	if (head)
 		call_rcu(&head->rcu, cls_cgroup_destroy_rcu);
-	}
+
 	return true;
 }
 

commit b9a24bb76bf611a5268ceffe04219e6ad264559b
Author: WANG Cong <xiyou.wangcong@gmail.com>
Date:   Fri Aug 19 12:36:54 2016 -0700

    net_sched: properly handle failure case of tcf_exts_init()
    
    After commit 22dc13c837c3 ("net_sched: convert tcf_exts from list to pointer array")
    we do dynamic allocation in tcf_exts_init(), therefore we need
    to handle the ENOMEM case properly.
    
    Cc: Jamal Hadi Salim <jhs@mojatatu.com>
    Signed-off-by: Cong Wang <xiyou.wangcong@gmail.com>
    Acked-by: Jamal Hadi Salim <jhs@mojatatu.com>
    Acked-by: Jamal Hadi Salim <jhs@mojatatu.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index 4c85bd3a750c..85233c470035 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -93,7 +93,9 @@ static int cls_cgroup_change(struct net *net, struct sk_buff *in_skb,
 	if (!new)
 		return -ENOBUFS;
 
-	tcf_exts_init(&new->exts, TCA_CGROUP_ACT, TCA_CGROUP_POLICE);
+	err = tcf_exts_init(&new->exts, TCA_CGROUP_ACT, TCA_CGROUP_POLICE);
+	if (err < 0)
+		goto errout;
 	new->handle = handle;
 	new->tp = tp;
 	err = nla_parse_nested(tb, TCA_CGROUP_MAX, tca[TCA_OPTIONS],
@@ -101,10 +103,14 @@ static int cls_cgroup_change(struct net *net, struct sk_buff *in_skb,
 	if (err < 0)
 		goto errout;
 
-	tcf_exts_init(&e, TCA_CGROUP_ACT, TCA_CGROUP_POLICE);
-	err = tcf_exts_validate(net, tp, tb, tca[TCA_RATE], &e, ovr);
+	err = tcf_exts_init(&e, TCA_CGROUP_ACT, TCA_CGROUP_POLICE);
 	if (err < 0)
 		goto errout;
+	err = tcf_exts_validate(net, tp, tb, tca[TCA_RATE], &e, ovr);
+	if (err < 0) {
+		tcf_exts_destroy(&e);
+		goto errout;
+	}
 
 	err = tcf_em_tree_validate(tp, tb[TCA_CGROUP_EMATCHES], &t);
 	if (err < 0) {
@@ -120,6 +126,7 @@ static int cls_cgroup_change(struct net *net, struct sk_buff *in_skb,
 		call_rcu(&head->rcu, cls_cgroup_destroy_rcu);
 	return 0;
 errout:
+	tcf_exts_destroy(&new->exts);
 	kfree(new);
 	return err;
 }

commit b87a173e25d6bf5c26f13d329cdddf57dbd4061a
Author: Daniel Borkmann <daniel@iogearbox.net>
Date:   Wed Jul 15 14:21:41 2015 +0200

    cls_cgroup: factor out classid retrieval
    
    Split out retrieving the cgroups net_cls classid retrieval into its
    own function, so that it can be reused later on from other parts of
    the traffic control subsystem. If there's no skb->sk, then the small
    helper returns 0 as well, which in cls_cgroup terms means 'could not
    classify'.
    
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Cc: Thomas Graf <tgraf@suug.ch>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index ea611b216412..4c85bd3a750c 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -30,35 +30,16 @@ static int cls_cgroup_classify(struct sk_buff *skb, const struct tcf_proto *tp,
 			       struct tcf_result *res)
 {
 	struct cls_cgroup_head *head = rcu_dereference_bh(tp->root);
-	u32 classid;
-
-	classid = task_cls_state(current)->classid;
-
-	/*
-	 * Due to the nature of the classifier it is required to ignore all
-	 * packets originating from softirq context as accessing `current'
-	 * would lead to false results.
-	 *
-	 * This test assumes that all callers of dev_queue_xmit() explicitely
-	 * disable bh. Knowing this, it is possible to detect softirq based
-	 * calls by looking at the number of nested bh disable calls because
-	 * softirqs always disables bh.
-	 */
-	if (in_serving_softirq()) {
-		/* If there is an sk_classid we'll use that. */
-		if (!skb->sk)
-			return -1;
-		classid = skb->sk->sk_classid;
-	}
+	u32 classid = task_get_classid(skb);
 
 	if (!classid)
 		return -1;
-
 	if (!tcf_em_tree_match(skb, &head->ematches, NULL))
 		return -1;
 
 	res->classid = classid;
 	res->class = 0;
+
 	return tcf_exts_exec(skb, &head->exts, res);
 }
 

commit 1e052be69d045c8d0f82ff1116fd3e5a79661745
Author: Cong Wang <cwang@twopensource.com>
Date:   Fri Mar 6 11:47:59 2015 -0800

    net_sched: destroy proto tp when all filters are gone
    
    Kernel automatically creates a tp for each
    (kind, protocol, priority) tuple, which has handle 0,
    when we add a new filter, but it still is left there
    after we remove our own, unless we don't specify the
    handle (literally means all the filters under
    the tuple). For example this one is left:
    
      # tc filter show dev eth0
      filter parent 8001: protocol arp pref 49152 basic
    
    The user-space is hard to clean up these for kernel
    because filters like u32 are organized in a complex way.
    So kernel is responsible to remove it after all filters
    are gone.  Each type of filter has its own way to
    store the filters, so each type has to provide its
    way to check if all filters are gone.
    
    Cc: Jamal Hadi Salim <jhs@mojatatu.com>
    Signed-off-by: Cong Wang <cwang@twopensource.com>
    Signed-off-by: Cong Wang <xiyou.wangcong@gmail.com>
    Acked-by: Jamal Hadi Salim<jhs@mojatatu.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index 221697ab0247..ea611b216412 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -143,14 +143,18 @@ static int cls_cgroup_change(struct net *net, struct sk_buff *in_skb,
 	return err;
 }
 
-static void cls_cgroup_destroy(struct tcf_proto *tp)
+static bool cls_cgroup_destroy(struct tcf_proto *tp, bool force)
 {
 	struct cls_cgroup_head *head = rtnl_dereference(tp->root);
 
+	if (!force)
+		return false;
+
 	if (head) {
 		RCU_INIT_POINTER(tp->root, NULL);
 		call_rcu(&head->rcu, cls_cgroup_destroy_rcu);
 	}
+	return true;
 }
 
 static int cls_cgroup_delete(struct tcf_proto *tp, unsigned long arg)

commit 6ea3b446b9369c971bcab2a723d814d2295c77d3
Author: Jiri Pirko <jiri@resnulli.us>
Date:   Tue Dec 9 22:23:29 2014 +0100

    net: sched: cls: use nla_nest_cancel instead of nlmsg_trim
    
    To cancel nesting, this function is more convenient.
    
    Signed-off-by: Jiri Pirko <jiri@resnulli.us>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index 741bfa7debb2..221697ab0247 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -177,7 +177,6 @@ static int cls_cgroup_dump(struct net *net, struct tcf_proto *tp, unsigned long
 			   struct sk_buff *skb, struct tcmsg *t)
 {
 	struct cls_cgroup_head *head = rtnl_dereference(tp->root);
-	unsigned char *b = skb_tail_pointer(skb);
 	struct nlattr *nest;
 
 	t->tcm_handle = head->handle;
@@ -198,7 +197,7 @@ static int cls_cgroup_dump(struct net *net, struct tcf_proto *tp, unsigned long
 	return skb->len;
 
 nla_put_failure:
-	nlmsg_trim(skb, b);
+	nla_nest_cancel(skb, nest);
 	return -1;
 }
 

commit 57d743a3dec174b8f1fbf53e93ade2fea3d32bd7
Author: Jiri Pirko <jiri@resnulli.us>
Date:   Thu Dec 4 21:41:18 2014 +0100

    net: sched: cls: remove unused op put from tcf_proto_ops
    
    It is never called and implementations are void. So just remove it.
    
    Signed-off-by: Jiri Pirko <jiri@resnulli.us>
    Signed-off-by: Jamal Hadi Salim <jhs@mojatatu.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index dbee65e26b3e..741bfa7debb2 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -67,10 +67,6 @@ static unsigned long cls_cgroup_get(struct tcf_proto *tp, u32 handle)
 	return 0UL;
 }
 
-static void cls_cgroup_put(struct tcf_proto *tp, unsigned long f)
-{
-}
-
 static int cls_cgroup_init(struct tcf_proto *tp)
 {
 	return 0;
@@ -213,7 +209,6 @@ static struct tcf_proto_ops cls_cgroup_ops __read_mostly = {
 	.classify	=	cls_cgroup_classify,
 	.destroy	=	cls_cgroup_destroy,
 	.get		=	cls_cgroup_get,
-	.put		=	cls_cgroup_put,
 	.delete		=	cls_cgroup_delete,
 	.walk		=	cls_cgroup_walk,
 	.dump		=	cls_cgroup_dump,

commit 18b5427ae1654803930b97590ac5a85245861646
Author: Jiri Pirko <jiri@resnulli.us>
Date:   Tue Dec 2 18:00:36 2014 +0100

    net_sched: cls_cgroup: remove unnecessary if
    
    since head->handle == handle (checked before), just assign handle.
    
    Signed-off-by: Jiri Pirko <jiri@resnulli.us>
    Acked-by: Jamal Hadi Salim <jhs@mojatatu.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index d61a801222c1..dbee65e26b3e 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -117,11 +117,7 @@ static int cls_cgroup_change(struct net *net, struct sk_buff *in_skb,
 		return -ENOBUFS;
 
 	tcf_exts_init(&new->exts, TCA_CGROUP_ACT, TCA_CGROUP_POLICE);
-	if (head)
-		new->handle = head->handle;
-	else
-		new->handle = handle;
-
+	new->handle = handle;
 	new->tp = tp;
 	err = nla_parse_nested(tb, TCA_CGROUP_MAX, tca[TCA_OPTIONS],
 			       cgroup_policy);

commit 13990f8156862fe945a1a226850a6550c8988a33
Author: John Fastabend <john.fastabend@gmail.com>
Date:   Sun Oct 5 21:28:20 2014 -0700

    net: sched: cls_cgroup tear down exts and ematch from rcu callback
    
    It is not RCU safe to destroy the action chain while there
    is a possibility of readers accessing it. Move this code
    into the rcu callback using the same rcu callback used in the
    code patch to make a change to head.
    
    Signed-off-by: John Fastabend <john.r.fastabend@intel.com>
    Acked-by: Cong Wang <cwang@twopensource.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index 2f77a89655dc..d61a801222c1 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -156,10 +156,8 @@ static void cls_cgroup_destroy(struct tcf_proto *tp)
 	struct cls_cgroup_head *head = rtnl_dereference(tp->root);
 
 	if (head) {
-		tcf_exts_destroy(&head->exts);
-		tcf_em_tree_destroy(&head->ematches);
 		RCU_INIT_POINTER(tp->root, NULL);
-		kfree_rcu(head, rcu);
+		call_rcu(&head->rcu, cls_cgroup_destroy_rcu);
 	}
 }
 

commit 82a470f1119eb7d2e4941b915bf9cd6fd8d54494
Author: John Fastabend <john.fastabend@gmail.com>
Date:   Sun Oct 5 21:27:53 2014 -0700

    net: sched: remove tcf_proto from ematch calls
    
    This removes the tcf_proto argument from the ematch code paths that
    only need it to reference the net namespace. This allows simplifying
    qdisc code paths especially when we need to tear down the ematch
    from an RCU callback. In this case we can not guarentee that the
    tcf_proto structure is still valid.
    
    Signed-off-by: John Fastabend <john.r.fastabend@intel.com>
    Acked-by: Cong Wang <cwang@twopensource.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index 3409f168225f..2f77a89655dc 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -87,7 +87,7 @@ static void cls_cgroup_destroy_rcu(struct rcu_head *root)
 						    rcu);
 
 	tcf_exts_destroy(&head->exts);
-	tcf_em_tree_destroy(head->tp, &head->ematches);
+	tcf_em_tree_destroy(&head->ematches);
 	kfree(head);
 }
 
@@ -157,7 +157,7 @@ static void cls_cgroup_destroy(struct tcf_proto *tp)
 
 	if (head) {
 		tcf_exts_destroy(&head->exts);
-		tcf_em_tree_destroy(tp, &head->ematches);
+		tcf_em_tree_destroy(&head->ematches);
 		RCU_INIT_POINTER(tp->root, NULL);
 		kfree_rcu(head, rcu);
 	}

commit 18d0264f630e200772bf236ac5747c47e908501e
Author: WANG Cong <xiyou.wangcong@gmail.com>
Date:   Thu Sep 25 10:26:37 2014 -0700

    net_sched: remove the first parameter from tcf_exts_destroy()
    
    Cc: Jamal Hadi Salim <jhs@mojatatu.com>
    Signed-off-by: Cong Wang <xiyou.wangcong@gmail.com>
    Acked-by: Jamal Hadi Salim <hadi@mojatatu.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index 15c34d4ccd9e..3409f168225f 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -86,7 +86,7 @@ static void cls_cgroup_destroy_rcu(struct rcu_head *root)
 						    struct cls_cgroup_head,
 						    rcu);
 
-	tcf_exts_destroy(head->tp, &head->exts);
+	tcf_exts_destroy(&head->exts);
 	tcf_em_tree_destroy(head->tp, &head->ematches);
 	kfree(head);
 }
@@ -135,7 +135,7 @@ static int cls_cgroup_change(struct net *net, struct sk_buff *in_skb,
 
 	err = tcf_em_tree_validate(tp, tb[TCA_CGROUP_EMATCHES], &t);
 	if (err < 0) {
-		tcf_exts_destroy(tp, &e);
+		tcf_exts_destroy(&e);
 		goto errout;
 	}
 
@@ -156,7 +156,7 @@ static void cls_cgroup_destroy(struct tcf_proto *tp)
 	struct cls_cgroup_head *head = rtnl_dereference(tp->root);
 
 	if (head) {
-		tcf_exts_destroy(tp, &head->exts);
+		tcf_exts_destroy(&head->exts);
 		tcf_em_tree_destroy(tp, &head->ematches);
 		RCU_INIT_POINTER(tp->root, NULL);
 		kfree_rcu(head, rcu);

commit 9f6c38e70b6c7ea379394a755fe76e09996f5370
Author: John Fastabend <john.fastabend@gmail.com>
Date:   Tue Sep 16 00:33:42 2014 -0700

    net: sched: cls_cgroup need tcf_exts_init in all cases
    
    This ensures the tcf_exts_init() is called for all cases.
    
    Fixes: 952313bd62589cae216a57 ("net: sched: cls_cgroup use RCU")
    Signed-off-by: John Fastabend <john.r.fastabend@intel.com>
    Acked-by: Cong Wang <cwang@twopensource.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index 10c7ffde13e2..15c34d4ccd9e 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -116,12 +116,11 @@ static int cls_cgroup_change(struct net *net, struct sk_buff *in_skb,
 	if (!new)
 		return -ENOBUFS;
 
-	if (head) {
+	tcf_exts_init(&new->exts, TCA_CGROUP_ACT, TCA_CGROUP_POLICE);
+	if (head)
 		new->handle = head->handle;
-	} else {
-		tcf_exts_init(&new->exts, TCA_CGROUP_ACT, TCA_CGROUP_POLICE);
+	else
 		new->handle = handle;
-	}
 
 	new->tp = tp;
 	err = nla_parse_nested(tb, TCA_CGROUP_MAX, tca[TCA_OPTIONS],

commit d14cbfc88ff87e5054d67fde3ba5f4c20b773dab
Author: John Fastabend <john.fastabend@gmail.com>
Date:   Mon Sep 15 23:31:17 2014 -0700

    net: sched: cls_cgroup fix possible memory leak of 'new'
    
    tree:   git://git.kernel.org/pub/scm/linux/kernel/git/davem/net-next.git master
    head:   54996b529ab70ca1d6f40677cd2698c4f7127e87
    commit: c7953ef23042b7c4fc2be5ecdd216aacff6df5eb [625/646] net: sched: cls_cgroup use RCU
    
    net/sched/cls_cgroup.c:130 cls_cgroup_change() warn: possible memory leak of 'new'
    net/sched/cls_cgroup.c:135 cls_cgroup_change() warn: possible memory leak of 'new'
    net/sched/cls_cgroup.c:139 cls_cgroup_change() warn: possible memory leak of 'new'
    
    Fixes: c7953ef23042b7c4fc2be5ecdd216aac ("net: sched: cls_cgroup use RCU")
    Reported-by: Dan Carpenter <dan.carpenter@oracle.com>
    Signed-off-by: John Fastabend <john.r.fastabend@intel.com>
    Acked-by: Cong Wang <cwang@twopensource.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index 3b7548759998..10c7ffde13e2 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -127,16 +127,18 @@ static int cls_cgroup_change(struct net *net, struct sk_buff *in_skb,
 	err = nla_parse_nested(tb, TCA_CGROUP_MAX, tca[TCA_OPTIONS],
 			       cgroup_policy);
 	if (err < 0)
-		return err;
+		goto errout;
 
 	tcf_exts_init(&e, TCA_CGROUP_ACT, TCA_CGROUP_POLICE);
 	err = tcf_exts_validate(net, tp, tb, tca[TCA_RATE], &e, ovr);
 	if (err < 0)
-		return err;
+		goto errout;
 
 	err = tcf_em_tree_validate(tp, tb[TCA_CGROUP_EMATCHES], &t);
-	if (err < 0)
-		return err;
+	if (err < 0) {
+		tcf_exts_destroy(tp, &e);
+		goto errout;
+	}
 
 	tcf_exts_change(tp, &new->exts, &e);
 	tcf_em_tree_change(tp, &new->ematches, &t);
@@ -145,6 +147,9 @@ static int cls_cgroup_change(struct net *net, struct sk_buff *in_skb,
 	if (head)
 		call_rcu(&head->rcu, cls_cgroup_destroy_rcu);
 	return 0;
+errout:
+	kfree(new);
+	return err;
 }
 
 static void cls_cgroup_destroy(struct tcf_proto *tp)

commit 952313bd62589cae216a579bb7ebc76f8e290817
Author: John Fastabend <john.fastabend@gmail.com>
Date:   Fri Sep 12 20:06:26 2014 -0700

    net: sched: cls_cgroup use RCU
    
    Make cgroup classifier safe for RCU.
    
    Also drops the calls in the classify routine that were doing a
    rcu_read_lock()/rcu_read_unlock(). If the rcu_read_lock() isn't held
    entering this routine we have issues with deleting the classifier
    chain so remove the unnecessary rcu_read_lock()/rcu_read_unlock()
    pair noting all paths AFAIK hold rcu_read_lock.
    
    If there is a case where classify is called without the rcu read lock
    then an rcu splat will occur and we can correct it.
    
    Signed-off-by: John Fastabend <john.r.fastabend@intel.com>
    Acked-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index cacf01bd04f0..3b7548759998 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -22,17 +22,17 @@ struct cls_cgroup_head {
 	u32			handle;
 	struct tcf_exts		exts;
 	struct tcf_ematch_tree	ematches;
+	struct tcf_proto	*tp;
+	struct rcu_head		rcu;
 };
 
 static int cls_cgroup_classify(struct sk_buff *skb, const struct tcf_proto *tp,
 			       struct tcf_result *res)
 {
-	struct cls_cgroup_head *head = tp->root;
+	struct cls_cgroup_head *head = rcu_dereference_bh(tp->root);
 	u32 classid;
 
-	rcu_read_lock();
 	classid = task_cls_state(current)->classid;
-	rcu_read_unlock();
 
 	/*
 	 * Due to the nature of the classifier it is required to ignore all
@@ -80,13 +80,25 @@ static const struct nla_policy cgroup_policy[TCA_CGROUP_MAX + 1] = {
 	[TCA_CGROUP_EMATCHES]	= { .type = NLA_NESTED },
 };
 
+static void cls_cgroup_destroy_rcu(struct rcu_head *root)
+{
+	struct cls_cgroup_head *head = container_of(root,
+						    struct cls_cgroup_head,
+						    rcu);
+
+	tcf_exts_destroy(head->tp, &head->exts);
+	tcf_em_tree_destroy(head->tp, &head->ematches);
+	kfree(head);
+}
+
 static int cls_cgroup_change(struct net *net, struct sk_buff *in_skb,
 			     struct tcf_proto *tp, unsigned long base,
 			     u32 handle, struct nlattr **tca,
 			     unsigned long *arg, bool ovr)
 {
 	struct nlattr *tb[TCA_CGROUP_MAX + 1];
-	struct cls_cgroup_head *head = tp->root;
+	struct cls_cgroup_head *head = rtnl_dereference(tp->root);
+	struct cls_cgroup_head *new;
 	struct tcf_ematch_tree t;
 	struct tcf_exts e;
 	int err;
@@ -94,25 +106,24 @@ static int cls_cgroup_change(struct net *net, struct sk_buff *in_skb,
 	if (!tca[TCA_OPTIONS])
 		return -EINVAL;
 
-	if (head == NULL) {
-		if (!handle)
-			return -EINVAL;
+	if (!head && !handle)
+		return -EINVAL;
 
-		head = kzalloc(sizeof(*head), GFP_KERNEL);
-		if (head == NULL)
-			return -ENOBUFS;
+	if (head && handle != head->handle)
+		return -ENOENT;
 
-		tcf_exts_init(&head->exts, TCA_CGROUP_ACT, TCA_CGROUP_POLICE);
-		head->handle = handle;
+	new = kzalloc(sizeof(*head), GFP_KERNEL);
+	if (!new)
+		return -ENOBUFS;
 
-		tcf_tree_lock(tp);
-		tp->root = head;
-		tcf_tree_unlock(tp);
+	if (head) {
+		new->handle = head->handle;
+	} else {
+		tcf_exts_init(&new->exts, TCA_CGROUP_ACT, TCA_CGROUP_POLICE);
+		new->handle = handle;
 	}
 
-	if (handle != head->handle)
-		return -ENOENT;
-
+	new->tp = tp;
 	err = nla_parse_nested(tb, TCA_CGROUP_MAX, tca[TCA_OPTIONS],
 			       cgroup_policy);
 	if (err < 0)
@@ -127,20 +138,24 @@ static int cls_cgroup_change(struct net *net, struct sk_buff *in_skb,
 	if (err < 0)
 		return err;
 
-	tcf_exts_change(tp, &head->exts, &e);
-	tcf_em_tree_change(tp, &head->ematches, &t);
+	tcf_exts_change(tp, &new->exts, &e);
+	tcf_em_tree_change(tp, &new->ematches, &t);
 
+	rcu_assign_pointer(tp->root, new);
+	if (head)
+		call_rcu(&head->rcu, cls_cgroup_destroy_rcu);
 	return 0;
 }
 
 static void cls_cgroup_destroy(struct tcf_proto *tp)
 {
-	struct cls_cgroup_head *head = tp->root;
+	struct cls_cgroup_head *head = rtnl_dereference(tp->root);
 
 	if (head) {
 		tcf_exts_destroy(tp, &head->exts);
 		tcf_em_tree_destroy(tp, &head->ematches);
-		kfree(head);
+		RCU_INIT_POINTER(tp->root, NULL);
+		kfree_rcu(head, rcu);
 	}
 }
 
@@ -151,7 +166,7 @@ static int cls_cgroup_delete(struct tcf_proto *tp, unsigned long arg)
 
 static void cls_cgroup_walk(struct tcf_proto *tp, struct tcf_walker *arg)
 {
-	struct cls_cgroup_head *head = tp->root;
+	struct cls_cgroup_head *head = rtnl_dereference(tp->root);
 
 	if (arg->count < arg->skip)
 		goto skip;
@@ -167,7 +182,7 @@ static void cls_cgroup_walk(struct tcf_proto *tp, struct tcf_walker *arg)
 static int cls_cgroup_dump(struct net *net, struct tcf_proto *tp, unsigned long fh,
 			   struct sk_buff *skb, struct tcmsg *t)
 {
-	struct cls_cgroup_head *head = tp->root;
+	struct cls_cgroup_head *head = rtnl_dereference(tp->root);
 	unsigned char *b = skb_tail_pointer(skb);
 	struct nlattr *nest;
 

commit 2f7ef2f8790f5bf53db4fc6b2310943139285827
Author: Cong Wang <cwang@twopensource.com>
Date:   Fri Apr 25 13:54:06 2014 -0700

    sched, cls: check if we could overwrite actions when changing a filter
    
    When actions are attached to a filter, they are a part of the filter
    itself, so when changing a filter we should allow to overwrite the actions
    inside as well.
    
    In my specific case, when I tried to _append_ a new action to an existing
    filter which already has an action, I got EEXIST since kernel refused
    to overwrite the existing one in kernel.
    
    This patch checks if we are changing the filter checking NLM_F_CREATE flag
    (Sigh, filters don't use NLM_F_REPLACE...) and then passes the boolean down
    to actions. This fixes the problem above.
    
    Cc: Jamal Hadi Salim <jhs@mojatatu.com>
    Cc: David S. Miller <davem@davemloft.net>
    Signed-off-by: Cong Wang <xiyou.wangcong@gmail.com>
    Signed-off-by: Cong Wang <cwang@twopensource.com>
    Signed-off-by: Jamal Hadi Salim <jhs@mojatatu.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index 8e2158ab551c..cacf01bd04f0 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -83,7 +83,7 @@ static const struct nla_policy cgroup_policy[TCA_CGROUP_MAX + 1] = {
 static int cls_cgroup_change(struct net *net, struct sk_buff *in_skb,
 			     struct tcf_proto *tp, unsigned long base,
 			     u32 handle, struct nlattr **tca,
-			     unsigned long *arg)
+			     unsigned long *arg, bool ovr)
 {
 	struct nlattr *tb[TCA_CGROUP_MAX + 1];
 	struct cls_cgroup_head *head = tp->root;
@@ -119,7 +119,7 @@ static int cls_cgroup_change(struct net *net, struct sk_buff *in_skb,
 		return err;
 
 	tcf_exts_init(&e, TCA_CGROUP_ACT, TCA_CGROUP_POLICE);
-	err = tcf_exts_validate(net, tp, tb, tca[TCA_RATE], &e);
+	err = tcf_exts_validate(net, tp, tb, tca[TCA_RATE], &e, ovr);
 	if (err < 0)
 		return err;
 

commit 832d1d5bfaefafa5aa40282f6765c6d996fe384e
Author: WANG Cong <xiyou.wangcong@gmail.com>
Date:   Thu Jan 9 16:14:01 2014 -0800

    net_sched: add struct net pointer to tcf_proto_ops->dump
    
    It will be needed by the next patch.
    
    Cc: Jamal Hadi Salim <jhs@mojatatu.com>
    Cc: David S. Miller <davem@davemloft.net>
    Signed-off-by: Cong Wang <xiyou.wangcong@gmail.com>
    Signed-off-by: Jamal Hadi Salim <jhs@mojatatu.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index 8349fcdc50f3..8e2158ab551c 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -164,7 +164,7 @@ static void cls_cgroup_walk(struct tcf_proto *tp, struct tcf_walker *arg)
 	arg->count++;
 }
 
-static int cls_cgroup_dump(struct tcf_proto *tp, unsigned long fh,
+static int cls_cgroup_dump(struct net *net, struct tcf_proto *tp, unsigned long fh,
 			   struct sk_buff *skb, struct tcmsg *t)
 {
 	struct cls_cgroup_head *head = tp->root;

commit 855404efae0d449cc491978d54ea5d117a3cb271
Merge: a1d4b03a076d 82a37132f300
Author: David S. Miller <davem@davemloft.net>
Date:   Sun Jan 5 20:18:50 2014 -0500

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/pablo/nf-next
    
    Pablo Neira Ayuso says:
    
    ====================
    netfilter/IPVS updates for net-next
    
    The following patchset contains Netfilter updates for your net-next tree,
    they are:
    
    * Add full port randomization support. Some crazy researchers found a way
      to reconstruct the secure ephemeral ports that are allocated in random mode
      by sending off-path bursts of UDP packets to overrun the socket buffer of
      the DNS resolver to trigger retransmissions, then if the timing for the
      DNS resolution done by a client is larger than usual, then they conclude
      that the port that received the burst of UDP packets is the one that was
      opened. It seems a bit aggressive method to me but it seems to work for
      them. As a result, Daniel Borkmann and Hannes Frederic Sowa came up with a
      new NAT mode to fully randomize ports using prandom.
    
    * Add a new classifier to x_tables based on the socket net_cls set via
      cgroups. These includes two patches to prepare the field as requested by
      Zefan Li. Also from Daniel Borkmann.
    
    * Use prandom instead of get_random_bytes in several locations of the
      netfilter code, from Florian Westphal.
    
    * Allow to use the CTA_MARK_MASK in ctnetlink when mangling the conntrack
      mark, also from Florian Westphal.
    
    * Fix compilation warning due to unused variable in IPVS, from Geert
      Uytterhoeven.
    
    * Add support for UID/GID via nfnetlink_queue, from Valentina Giusti.
    
    * Add IPComp extension to x_tables, from Fan Du.
    ====================
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit fe1217c4f3f7d7cbf8efdd8dd5fdc7204a1d65a8
Author: Daniel Borkmann <dborkman@redhat.com>
Date:   Sun Dec 29 18:27:10 2013 +0100

    net: net_cls: move cgroupfs classid handling into core
    
    Zefan Li requested [1] to perform the following cleanup/refactoring:
    
    - Split cgroupfs classid handling into net core to better express a
      possible more generic use.
    
    - Disable module support for cgroupfs bits as the majority of other
      cgroupfs subsystems do not have that, and seems to be not wished
      from cgroup side. Zefan probably might want to follow-up for netprio
      later on.
    
    - By this, code can be further reduced which previously took care of
      functionality built when compiled as module.
    
    cgroupfs bits are being placed under net/core/netclassid_cgroup.c, so
    that we are consistent with {netclassid,netprio}_cgroup naming that is
    under net/core/ as suggested by Zefan.
    
    No change in functionality, but only code refactoring that is being
    done here.
    
     [1] http://patchwork.ozlabs.org/patch/304825/
    
    Suggested-by: Li Zefan <lizefan@huawei.com>
    Signed-off-by: Daniel Borkmann <dborkman@redhat.com>
    Cc: Zefan Li <lizefan@huawei.com>
    Cc: Thomas Graf <tgraf@suug.ch>
    Cc: cgroups@vger.kernel.org
    Acked-by: Li Zefan <lizefan@huawei.com>
    Signed-off-by: Pablo Neira Ayuso <pablo@netfilter.org>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index 16006c92c3fd..838fa40abad1 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -11,109 +11,13 @@
 
 #include <linux/module.h>
 #include <linux/slab.h>
-#include <linux/types.h>
-#include <linux/string.h>
-#include <linux/errno.h>
 #include <linux/skbuff.h>
-#include <linux/cgroup.h>
 #include <linux/rcupdate.h>
-#include <linux/fdtable.h>
 #include <net/rtnetlink.h>
 #include <net/pkt_cls.h>
 #include <net/sock.h>
 #include <net/cls_cgroup.h>
 
-static inline struct cgroup_cls_state *css_cls_state(struct cgroup_subsys_state *css)
-{
-	return css ? container_of(css, struct cgroup_cls_state, css) : NULL;
-}
-
-static inline struct cgroup_cls_state *task_cls_state(struct task_struct *p)
-{
-	return css_cls_state(task_css(p, net_cls_subsys_id));
-}
-
-static struct cgroup_subsys_state *
-cgrp_css_alloc(struct cgroup_subsys_state *parent_css)
-{
-	struct cgroup_cls_state *cs;
-
-	cs = kzalloc(sizeof(*cs), GFP_KERNEL);
-	if (!cs)
-		return ERR_PTR(-ENOMEM);
-	return &cs->css;
-}
-
-static int cgrp_css_online(struct cgroup_subsys_state *css)
-{
-	struct cgroup_cls_state *cs = css_cls_state(css);
-	struct cgroup_cls_state *parent = css_cls_state(css_parent(css));
-
-	if (parent)
-		cs->classid = parent->classid;
-	return 0;
-}
-
-static void cgrp_css_free(struct cgroup_subsys_state *css)
-{
-	kfree(css_cls_state(css));
-}
-
-static int update_classid(const void *v, struct file *file, unsigned n)
-{
-	int err;
-	struct socket *sock = sock_from_file(file, &err);
-	if (sock)
-		sock->sk->sk_classid = (u32)(unsigned long)v;
-	return 0;
-}
-
-static void cgrp_attach(struct cgroup_subsys_state *css,
-			struct cgroup_taskset *tset)
-{
-	struct task_struct *p;
-	struct cgroup_cls_state *cs = css_cls_state(css);
-	void *v = (void *)(unsigned long)cs->classid;
-
-	cgroup_taskset_for_each(p, css, tset) {
-		task_lock(p);
-		iterate_fd(p->files, 0, update_classid, v);
-		task_unlock(p);
-	}
-}
-
-static u64 read_classid(struct cgroup_subsys_state *css, struct cftype *cft)
-{
-	return css_cls_state(css)->classid;
-}
-
-static int write_classid(struct cgroup_subsys_state *css, struct cftype *cft,
-			 u64 value)
-{
-	css_cls_state(css)->classid = (u32) value;
-	return 0;
-}
-
-static struct cftype ss_files[] = {
-	{
-		.name = "classid",
-		.read_u64 = read_classid,
-		.write_u64 = write_classid,
-	},
-	{ }	/* terminate */
-};
-
-struct cgroup_subsys net_cls_subsys = {
-	.name		= "net_cls",
-	.css_alloc	= cgrp_css_alloc,
-	.css_online	= cgrp_css_online,
-	.css_free	= cgrp_css_free,
-	.attach		= cgrp_attach,
-	.subsys_id	= net_cls_subsys_id,
-	.base_cftypes	= ss_files,
-	.module		= THIS_MODULE,
-};
-
 struct cls_cgroup_head {
 	u32			handle;
 	struct tcf_exts		exts;
@@ -309,25 +213,12 @@ static struct tcf_proto_ops cls_cgroup_ops __read_mostly = {
 
 static int __init init_cgroup_cls(void)
 {
-	int ret;
-
-	ret = cgroup_load_subsys(&net_cls_subsys);
-	if (ret)
-		goto out;
-
-	ret = register_tcf_proto_ops(&cls_cgroup_ops);
-	if (ret)
-		cgroup_unload_subsys(&net_cls_subsys);
-
-out:
-	return ret;
+	return register_tcf_proto_ops(&cls_cgroup_ops);
 }
 
 static void __exit exit_cgroup_cls(void)
 {
 	unregister_tcf_proto_ops(&cls_cgroup_ops);
-
-	cgroup_unload_subsys(&net_cls_subsys);
 }
 
 module_init(init_cgroup_cls);

commit c1ddf295f5183a5189196a8035546842caa2055a
Author: Cong Wang <xiyou.wangcong@gmail.com>
Date:   Thu Jan 2 14:58:41 2014 -0800

    net: revert "sched classifier: make cgroup table local"
    
    This reverts commit de6fb288b1246a5c4e00c0cdbfe3a838a360b3f4.
    Otherwise we got:
    
    net/sched/cls_cgroup.c:106:29: error: static declaration of ‘net_cls_subsys’ follows non-static declaration
     static struct cgroup_subsys net_cls_subsys = {
                                 ^
    In file included from include/linux/cgroup.h:654:0,
                     from net/sched/cls_cgroup.c:18:
    include/linux/cgroup_subsys.h:35:29: note: previous declaration of ‘net_cls_subsys’ was here
     SUBSYS(net_cls)
                                 ^
    make[2]: *** [net/sched/cls_cgroup.o] Error 1
    
    Cc: Stephen Hemminger <stephen@networkplumber.org>
    Cc: David S. Miller <davem@davemloft.net>
    Signed-off-by: Cong Wang <xiyou.wangcong@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index 161a03e0c002..f9d212583ea2 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -103,7 +103,7 @@ static struct cftype ss_files[] = {
 	{ }	/* terminate */
 };
 
-static struct cgroup_subsys net_cls_subsys = {
+struct cgroup_subsys net_cls_subsys = {
 	.name		= "net_cls",
 	.css_alloc	= cgrp_css_alloc,
 	.css_online	= cgrp_css_online,

commit de6fb288b1246a5c4e00c0cdbfe3a838a360b3f4
Author: stephen hemminger <stephen@networkplumber.org>
Date:   Tue Dec 31 11:55:29 2013 -0800

    sched classifier: make cgroup table local
    
    Doesn't need to be global.
    
    Signed-off-by: Stephen Hemminger <stephen@networkplumber.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index f9d212583ea2..161a03e0c002 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -103,7 +103,7 @@ static struct cftype ss_files[] = {
 	{ }	/* terminate */
 };
 
-struct cgroup_subsys net_cls_subsys = {
+static struct cgroup_subsys net_cls_subsys = {
 	.name		= "net_cls",
 	.css_alloc	= cgrp_css_alloc,
 	.css_online	= cgrp_css_online,

commit 5da57f422d89c504a1d72dadd4e19d3dca8e974e
Author: WANG Cong <xiyou.wangcong@gmail.com>
Date:   Sun Dec 15 20:15:07 2013 -0800

    net_sched: cls: refactor out struct tcf_ext_map
    
    These information can be saved in tcf_exts, and this will
    simplify the code.
    
    Cc: Jamal Hadi Salim <jhs@mojatatu.com>
    Cc: David S. Miller <davem@davemloft.net>
    Signed-off-by: Cong Wang <xiyou.wangcong@gmail.com>
    Signed-off-by: Jamal Hadi Salim <jhs@mojatatu.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index e4fae032bcfb..f9d212583ea2 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -172,11 +172,6 @@ static int cls_cgroup_init(struct tcf_proto *tp)
 	return 0;
 }
 
-static const struct tcf_ext_map cgroup_ext_map = {
-	.action = TCA_CGROUP_ACT,
-	.police = TCA_CGROUP_POLICE,
-};
-
 static const struct nla_policy cgroup_policy[TCA_CGROUP_MAX + 1] = {
 	[TCA_CGROUP_EMATCHES]	= { .type = NLA_NESTED },
 };
@@ -203,7 +198,7 @@ static int cls_cgroup_change(struct net *net, struct sk_buff *in_skb,
 		if (head == NULL)
 			return -ENOBUFS;
 
-		tcf_exts_init(&head->exts);
+		tcf_exts_init(&head->exts, TCA_CGROUP_ACT, TCA_CGROUP_POLICE);
 		head->handle = handle;
 
 		tcf_tree_lock(tp);
@@ -219,8 +214,8 @@ static int cls_cgroup_change(struct net *net, struct sk_buff *in_skb,
 	if (err < 0)
 		return err;
 
-	err = tcf_exts_validate(net, tp, tb, tca[TCA_RATE], &e,
-				&cgroup_ext_map);
+	tcf_exts_init(&e, TCA_CGROUP_ACT, TCA_CGROUP_POLICE);
+	err = tcf_exts_validate(net, tp, tb, tca[TCA_RATE], &e);
 	if (err < 0)
 		return err;
 
@@ -278,13 +273,13 @@ static int cls_cgroup_dump(struct tcf_proto *tp, unsigned long fh,
 	if (nest == NULL)
 		goto nla_put_failure;
 
-	if (tcf_exts_dump(skb, &head->exts, &cgroup_ext_map) < 0 ||
+	if (tcf_exts_dump(skb, &head->exts) < 0 ||
 	    tcf_em_tree_dump(skb, &head->ematches, TCA_CGROUP_EMATCHES) < 0)
 		goto nla_put_failure;
 
 	nla_nest_end(skb, nest);
 
-	if (tcf_exts_dump_stats(skb, &head->exts, &cgroup_ext_map) < 0)
+	if (tcf_exts_dump_stats(skb, &head->exts) < 0)
 		goto nla_put_failure;
 
 	return skb->len;

commit 33be627159913b094bb578e83e9a7fdc66c10208
Author: WANG Cong <xiyou.wangcong@gmail.com>
Date:   Sun Dec 15 20:15:05 2013 -0800

    net_sched: act: use standard struct list_head
    
    Currently actions are chained by a singly linked list,
    therefore it is a bit hard to add and remove a specific
    entry. Convert it to struct list_head so that in the
    latter patch we can remove an action without finding
    its head.
    
    Cc: Jamal Hadi Salim <jhs@mojatatu.com>
    Cc: David S. Miller <davem@davemloft.net>
    Signed-off-by: Cong Wang <xiyou.wangcong@gmail.com>
    Signed-off-by: Jamal Hadi Salim <jhs@mojatatu.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index 16006c92c3fd..e4fae032bcfb 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -203,6 +203,7 @@ static int cls_cgroup_change(struct net *net, struct sk_buff *in_skb,
 		if (head == NULL)
 			return -ENOBUFS;
 
+		tcf_exts_init(&head->exts);
 		head->handle = handle;
 
 		tcf_tree_lock(tp);

commit ff0bfad6a2ed98c89cc91bc88ac223082eb42d4a
Author: Gao feng <gaofeng@cn.fujitsu.com>
Date:   Tue Oct 8 11:05:20 2013 +0800

    cgroup: cls: remove unnecessary task_cls_classid
    
    We can get classid through cgroup_subsys_state,
    this is directviewing and effective.
    
    Signed-off-by: Gao feng <gaofeng@cn.fujitsu.com>
    Acked-by: Neil Horman <nhorman@tuxdriver.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index 867b4a3e3980..16006c92c3fd 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -72,11 +72,11 @@ static void cgrp_attach(struct cgroup_subsys_state *css,
 			struct cgroup_taskset *tset)
 {
 	struct task_struct *p;
-	void *v;
+	struct cgroup_cls_state *cs = css_cls_state(css);
+	void *v = (void *)(unsigned long)cs->classid;
 
 	cgroup_taskset_for_each(p, css, tset) {
 		task_lock(p);
-		v = (void *)(unsigned long)task_cls_classid(p);
 		iterate_fd(p->files, 0, update_classid, v);
 		task_unlock(p);
 	}

commit d99c8727e7bbc01b70e2c57e6127bfab26b868fd
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Aug 8 20:11:27 2013 -0400

    cgroup: make cgroup_taskset deal with cgroup_subsys_state instead of cgroup
    
    cgroup is in the process of converting to css (cgroup_subsys_state)
    from cgroup as the principal subsystem interface handle.  This is
    mostly to prepare for the unified hierarchy support where css's will
    be created and destroyed dynamically but also helps cleaning up
    subsystem implementations as css is usually what they are interested
    in anyway.
    
    cgroup_taskset which is used by the subsystem attach methods is the
    last cgroup subsystem API which isn't using css as the handle.  Update
    cgroup_taskset_cur_cgroup() to cgroup_taskset_cur_css() and
    cgroup_taskset_for_each() to take @skip_css instead of @skip_cgrp.
    
    The conversions are pretty mechanical.  One exception is
    cpuset::cgroup_cs(), which lost its last user and got removed.
    
    This patch shouldn't introduce any functional changes.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Acked-by: Daniel Wagner <daniel.wagner@bmw-carit.de>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Matt Helsley <matthltc@us.ibm.com>
    Cc: Steven Rostedt <rostedt@goodmis.org>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index 8ea1184cec92..867b4a3e3980 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -74,7 +74,7 @@ static void cgrp_attach(struct cgroup_subsys_state *css,
 	struct task_struct *p;
 	void *v;
 
-	cgroup_taskset_for_each(p, css->cgroup, tset) {
+	cgroup_taskset_for_each(p, css, tset) {
 		task_lock(p);
 		v = (void *)(unsigned long)task_cls_classid(p);
 		iterate_fd(p->files, 0, update_classid, v);

commit 182446d087906de40e514573a92a97b203695f71
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Aug 8 20:11:24 2013 -0400

    cgroup: pass around cgroup_subsys_state instead of cgroup in file methods
    
    cgroup is currently in the process of transitioning to using struct
    cgroup_subsys_state * as the primary handle instead of struct cgroup.
    Please see the previous commit which converts the subsystem methods
    for rationale.
    
    This patch converts all cftype file operations to take @css instead of
    @cgroup.  cftypes for the cgroup core files don't have their subsytem
    pointer set.  These will automatically use the dummy_css added by the
    previous patch and can be converted the same way.
    
    Most subsystem conversions are straight forwards but there are some
    interesting ones.
    
    * freezer: update_if_frozen() is also converted to take @css instead
      of @cgroup for consistency.  This will make the code look simpler
      too once iterators are converted to use css.
    
    * memory/vmpressure: mem_cgroup_from_css() needs to be exported to
      vmpressure while mem_cgroup_from_cont() can be made static.
      Updated accordingly.
    
    * cpu: cgroup_tg() doesn't have any user left.  Removed.
    
    * cpuacct: cgroup_ca() doesn't have any user left.  Removed.
    
    * hugetlb: hugetlb_cgroup_form_cgroup() doesn't have any user left.
      Removed.
    
    * net_cls: cgrp_cls_state() doesn't have any user left.  Removed.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Acked-by: Michal Hocko <mhocko@suse.cz>
    Acked-by: Vivek Goyal <vgoyal@redhat.com>
    Acked-by: Aristeu Rozanski <aris@redhat.com>
    Acked-by: Daniel Wagner <daniel.wagner@bmw-carit.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Balbir Singh <bsingharora@gmail.com>
    Cc: Matt Helsley <matthltc@us.ibm.com>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Steven Rostedt <rostedt@goodmis.org>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index dc3983835893..8ea1184cec92 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -28,11 +28,6 @@ static inline struct cgroup_cls_state *css_cls_state(struct cgroup_subsys_state
 	return css ? container_of(css, struct cgroup_cls_state, css) : NULL;
 }
 
-static inline struct cgroup_cls_state *cgrp_cls_state(struct cgroup *cgrp)
-{
-	return css_cls_state(cgroup_css(cgrp, net_cls_subsys_id));
-}
-
 static inline struct cgroup_cls_state *task_cls_state(struct task_struct *p)
 {
 	return css_cls_state(task_css(p, net_cls_subsys_id));
@@ -87,14 +82,15 @@ static void cgrp_attach(struct cgroup_subsys_state *css,
 	}
 }
 
-static u64 read_classid(struct cgroup *cgrp, struct cftype *cft)
+static u64 read_classid(struct cgroup_subsys_state *css, struct cftype *cft)
 {
-	return cgrp_cls_state(cgrp)->classid;
+	return css_cls_state(css)->classid;
 }
 
-static int write_classid(struct cgroup *cgrp, struct cftype *cft, u64 value)
+static int write_classid(struct cgroup_subsys_state *css, struct cftype *cft,
+			 u64 value)
 {
-	cgrp_cls_state(cgrp)->classid = (u32) value;
+	css_cls_state(css)->classid = (u32) value;
 	return 0;
 }
 

commit eb95419b023abacb415e2a18fea899023ce7624d
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Aug 8 20:11:23 2013 -0400

    cgroup: pass around cgroup_subsys_state instead of cgroup in subsystem methods
    
    cgroup is currently in the process of transitioning to using struct
    cgroup_subsys_state * as the primary handle instead of struct cgroup *
    in subsystem implementations for the following reasons.
    
    * With unified hierarchy, subsystems will be dynamically bound and
      unbound from cgroups and thus css's (cgroup_subsys_state) may be
      created and destroyed dynamically over the lifetime of a cgroup,
      which is different from the current state where all css's are
      allocated and destroyed together with the associated cgroup.  This
      in turn means that cgroup_css() should be synchronized and may
      return NULL, making it more cumbersome to use.
    
    * Differing levels of per-subsystem granularity in the unified
      hierarchy means that the task and descendant iterators should behave
      differently depending on the specific subsystem the iteration is
      being performed for.
    
    * In majority of the cases, subsystems only care about its part in the
      cgroup hierarchy - ie. the hierarchy of css's.  Subsystem methods
      often obtain the matching css pointer from the cgroup and don't
      bother with the cgroup pointer itself.  Passing around css fits
      much better.
    
    This patch converts all cgroup_subsys methods to take @css instead of
    @cgroup.  The conversions are mostly straight-forward.  A few
    noteworthy changes are
    
    * ->css_alloc() now takes css of the parent cgroup rather than the
      pointer to the new cgroup as the css for the new cgroup doesn't
      exist yet.  Knowing the parent css is enough for all the existing
      subsystems.
    
    * In kernel/cgroup.c::offline_css(), unnecessary open coded css
      dereference is replaced with local variable access.
    
    This patch shouldn't cause any behavior differences.
    
    v2: Unnecessary explicit cgrp->subsys[] deref in css_online() replaced
        with local variable @css as suggested by Li Zefan.
    
        Rebased on top of new for-3.12 which includes for-3.11-fixes so
        that ->css_free() invocation added by da0a12caff ("cgroup: fix a
        leak when percpu_ref_init() fails") is converted too.  Suggested
        by Li Zefan.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Acked-by: Michal Hocko <mhocko@suse.cz>
    Acked-by: Vivek Goyal <vgoyal@redhat.com>
    Acked-by: Aristeu Rozanski <aris@redhat.com>
    Acked-by: Daniel Wagner <daniel.wagner@bmw-carit.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Balbir Singh <bsingharora@gmail.com>
    Cc: Matt Helsley <matthltc@us.ibm.com>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Steven Rostedt <rostedt@goodmis.org>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index 9e6b75e5efce..dc3983835893 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -38,7 +38,8 @@ static inline struct cgroup_cls_state *task_cls_state(struct task_struct *p)
 	return css_cls_state(task_css(p, net_cls_subsys_id));
 }
 
-static struct cgroup_subsys_state *cgrp_css_alloc(struct cgroup *cgrp)
+static struct cgroup_subsys_state *
+cgrp_css_alloc(struct cgroup_subsys_state *parent_css)
 {
 	struct cgroup_cls_state *cs;
 
@@ -48,19 +49,19 @@ static struct cgroup_subsys_state *cgrp_css_alloc(struct cgroup *cgrp)
 	return &cs->css;
 }
 
-static int cgrp_css_online(struct cgroup *cgrp)
+static int cgrp_css_online(struct cgroup_subsys_state *css)
 {
-	struct cgroup_cls_state *cs = cgrp_cls_state(cgrp);
-	struct cgroup_cls_state *parent = css_cls_state(css_parent(&cs->css));
+	struct cgroup_cls_state *cs = css_cls_state(css);
+	struct cgroup_cls_state *parent = css_cls_state(css_parent(css));
 
 	if (parent)
 		cs->classid = parent->classid;
 	return 0;
 }
 
-static void cgrp_css_free(struct cgroup *cgrp)
+static void cgrp_css_free(struct cgroup_subsys_state *css)
 {
-	kfree(cgrp_cls_state(cgrp));
+	kfree(css_cls_state(css));
 }
 
 static int update_classid(const void *v, struct file *file, unsigned n)
@@ -72,12 +73,13 @@ static int update_classid(const void *v, struct file *file, unsigned n)
 	return 0;
 }
 
-static void cgrp_attach(struct cgroup *cgrp, struct cgroup_taskset *tset)
+static void cgrp_attach(struct cgroup_subsys_state *css,
+			struct cgroup_taskset *tset)
 {
 	struct task_struct *p;
 	void *v;
 
-	cgroup_taskset_for_each(p, cgrp, tset) {
+	cgroup_taskset_for_each(p, css->cgroup, tset) {
 		task_lock(p);
 		v = (void *)(unsigned long)task_cls_classid(p);
 		iterate_fd(p->files, 0, update_classid, v);

commit 6387698699afd72d6304566fb6ccf84bffe07c56
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Aug 8 20:11:23 2013 -0400

    cgroup: add css_parent()
    
    Currently, controllers have to explicitly follow the cgroup hierarchy
    to find the parent of a given css.  cgroup is moving towards using
    cgroup_subsys_state as the main controller interface construct, so
    let's provide a way to climb the hierarchy using just csses.
    
    This patch implements css_parent() which, given a css, returns its
    parent.  The function is guarnateed to valid non-NULL parent css as
    long as the target css is not at the top of the hierarchy.
    
    freezer, cpuset, cpu, cpuacct, hugetlb, memory, net_cls and devices
    are converted to use css_parent() instead of accessing cgroup->parent
    directly.
    
    * __parent_ca() is dropped from cpuacct and its usage is replaced with
      parent_ca().  The only difference between the two was NULL test on
      cgroup->parent which is now embedded in css_parent() making the
      distinction moot.  Note that eventually a css->parent field will be
      added to css and the NULL check in css_parent() will go away.
    
    This patch shouldn't cause any behavior differences.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index af412ab2b477..9e6b75e5efce 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -50,9 +50,11 @@ static struct cgroup_subsys_state *cgrp_css_alloc(struct cgroup *cgrp)
 
 static int cgrp_css_online(struct cgroup *cgrp)
 {
-	if (cgrp->parent)
-		cgrp_cls_state(cgrp)->classid =
-			cgrp_cls_state(cgrp->parent)->classid;
+	struct cgroup_cls_state *cs = cgrp_cls_state(cgrp);
+	struct cgroup_cls_state *parent = css_cls_state(css_parent(&cs->css));
+
+	if (parent)
+		cs->classid = parent->classid;
 	return 0;
 }
 

commit a7c6d554aa01236ac2a9f851ab0f75704f76dfa2
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Aug 8 20:11:23 2013 -0400

    cgroup: add/update accessors which obtain subsys specific data from css
    
    css (cgroup_subsys_state) is usually embedded in a subsys specific
    data structure.  Subsystems either use container_of() directly to cast
    from css to such data structure or has an accessor function wrapping
    such cast.  As cgroup as whole is moving towards using css as the main
    interface handle, add and update such accessors to ease dealing with
    css's.
    
    All accessors explicitly handle NULL input and return NULL in those
    cases.  While this looks like an extra branch in the code, as all
    controllers specific data structures have css as the first field, the
    casting doesn't involve any offsetting and the compiler can trivially
    optimize out the branch.
    
    * blkio, freezer, cpuset, cpu, cpuacct and net_cls didn't have such
      accessor.  Added.
    
    * memory, hugetlb and devices already had one but didn't explicitly
      handle NULL input.  Updated.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index 5ee72a001df0..af412ab2b477 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -23,16 +23,19 @@
 #include <net/sock.h>
 #include <net/cls_cgroup.h>
 
+static inline struct cgroup_cls_state *css_cls_state(struct cgroup_subsys_state *css)
+{
+	return css ? container_of(css, struct cgroup_cls_state, css) : NULL;
+}
+
 static inline struct cgroup_cls_state *cgrp_cls_state(struct cgroup *cgrp)
 {
-	return container_of(cgroup_css(cgrp, net_cls_subsys_id),
-			    struct cgroup_cls_state, css);
+	return css_cls_state(cgroup_css(cgrp, net_cls_subsys_id));
 }
 
 static inline struct cgroup_cls_state *task_cls_state(struct task_struct *p)
 {
-	return container_of(task_css(p, net_cls_subsys_id),
-			    struct cgroup_cls_state, css);
+	return css_cls_state(task_css(p, net_cls_subsys_id));
 }
 
 static struct cgroup_subsys_state *cgrp_css_alloc(struct cgroup *cgrp)

commit 8af01f56a03e9cbd91a55d688fce1315021efba8
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Aug 8 20:11:22 2013 -0400

    cgroup: s/cgroup_subsys_state/cgroup_css/ s/task_subsys_state/task_css/
    
    The names of the two struct cgroup_subsys_state accessors -
    cgroup_subsys_state() and task_subsys_state() - are somewhat awkward.
    The former clashes with the type name and the latter doesn't even
    indicate it's somehow related to cgroup.
    
    We're about to revamp large portion of cgroup API, so, let's rename
    them so that they're less awkward.  Most per-controller usages of the
    accessors are localized in accessor wrappers and given the amount of
    scheduled changes, this isn't gonna add any noticeable headache.
    
    Rename cgroup_subsys_state() to cgroup_css() and task_subsys_state()
    to task_css().  This patch is pure rename.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index 3a294eb98d61..5ee72a001df0 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -25,13 +25,13 @@
 
 static inline struct cgroup_cls_state *cgrp_cls_state(struct cgroup *cgrp)
 {
-	return container_of(cgroup_subsys_state(cgrp, net_cls_subsys_id),
+	return container_of(cgroup_css(cgrp, net_cls_subsys_id),
 			    struct cgroup_cls_state, css);
 }
 
 static inline struct cgroup_cls_state *task_cls_state(struct task_struct *p)
 {
-	return container_of(task_subsys_state(p, net_cls_subsys_id),
+	return container_of(task_css(p, net_cls_subsys_id),
 			    struct cgroup_cls_state, css);
 }
 

commit c1b52739e45f5969b208ebc377f52468280af11e
Author: Benjamin LaHaise <bcrl@kvack.org>
Date:   Mon Jan 14 05:15:39 2013 +0000

    pkt_sched: namespace aware act_mirred
    
    Eric Dumazet pointed out that act_mirred needs to find the current net_ns,
    and struct net pointer is not provided in the call chain.  His original
    patch made use of current->nsproxy->net_ns to find the network namespace,
    but this fails to work correctly for userspace code that makes use of
    netlink sockets in different network namespaces.  Instead, pass the
    "struct net *" down along the call chain to where it is needed.
    
    This version removes the ifb changes as Eric has submitted that patch
    separately, but is otherwise identical to the previous version.
    
    Signed-off-by: Benjamin LaHaise <bcrl@kvack.org>
    Tested-by: Eric Dumazet <eric.dumazet@gmail.com>
    Acked-by: Jamal Hadi Salim <jhs@mojatatu.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index 6db7855b9029..3a294eb98d61 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -178,7 +178,7 @@ static const struct nla_policy cgroup_policy[TCA_CGROUP_MAX + 1] = {
 	[TCA_CGROUP_EMATCHES]	= { .type = NLA_NESTED },
 };
 
-static int cls_cgroup_change(struct sk_buff *in_skb,
+static int cls_cgroup_change(struct net *net, struct sk_buff *in_skb,
 			     struct tcf_proto *tp, unsigned long base,
 			     u32 handle, struct nlattr **tca,
 			     unsigned long *arg)
@@ -215,7 +215,8 @@ static int cls_cgroup_change(struct sk_buff *in_skb,
 	if (err < 0)
 		return err;
 
-	err = tcf_exts_validate(tp, tb, tca[TCA_RATE], &e, &cgroup_ext_map);
+	err = tcf_exts_validate(net, tp, tb, tca[TCA_RATE], &e,
+				&cgroup_ext_map);
 	if (err < 0)
 		return err;
 

commit 6be35c700f742e911ecedd07fcc43d4439922334
Merge: e37aa63e87bd 520dfe3a3645
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Dec 12 18:07:07 2012 -0800

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/davem/net-next
    
    Pull networking changes from David Miller:
    
    1) Allow to dump, monitor, and change the bridge multicast database
       using netlink.  From Cong Wang.
    
    2) RFC 5961 TCP blind data injection attack mitigation, from Eric
       Dumazet.
    
    3) Networking user namespace support from Eric W. Biederman.
    
    4) tuntap/virtio-net multiqueue support by Jason Wang.
    
    5) Support for checksum offload of encapsulated packets (basically,
       tunneled traffic can still be checksummed by HW).  From Joseph
       Gasparakis.
    
    6) Allow BPF filter access to VLAN tags, from Eric Dumazet and
       Daniel Borkmann.
    
    7) Bridge port parameters over netlink and BPDU blocking support
       from Stephen Hemminger.
    
    8) Improve data access patterns during inet socket demux by rearranging
       socket layout, from Eric Dumazet.
    
    9) TIPC protocol updates and cleanups from Ying Xue, Paul Gortmaker, and
       Jon Maloy.
    
    10) Update TCP socket hash sizing to be more in line with current day
        realities.  The existing heurstics were choosen a decade ago.
        From Eric Dumazet.
    
    11) Fix races, queue bloat, and excessive wakeups in ATM and
        associated drivers, from Krzysztof Mazur and David Woodhouse.
    
    12) Support DOVE (Distributed Overlay Virtual Ethernet) extensions
        in VXLAN driver, from David Stevens.
    
    13) Add "oops_only" mode to netconsole, from Amerigo Wang.
    
    14) Support set and query of VEB/VEPA bridge mode via PF_BRIDGE, also
        allow DCB netlink to work on namespaces other than the initial
        namespace.  From John Fastabend.
    
    15) Support PTP in the Tigon3 driver, from Matt Carlson.
    
    16) tun/vhost zero copy fixes and improvements, plus turn it on
        by default, from Michael S. Tsirkin.
    
    17) Support per-association statistics in SCTP, from Michele
        Baldessari.
    
    And many, many, driver updates, cleanups, and improvements.  Too
    numerous to mention individually.
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/davem/net-next: (1722 commits)
      net/mlx4_en: Add support for destination MAC in steering rules
      net/mlx4_en: Use generic etherdevice.h functions.
      net: ethtool: Add destination MAC address to flow steering API
      bridge: add support of adding and deleting mdb entries
      bridge: notify mdb changes via netlink
      ndisc: Unexport ndisc_{build,send}_skb().
      uapi: add missing netconf.h to export list
      pkt_sched: avoid requeues if possible
      solos-pci: fix double-free of TX skb in DMA mode
      bnx2: Fix accidental reversions.
      bna: Driver Version Updated to 3.1.2.1
      bna: Firmware update
      bna: Add RX State
      bna: Rx Page Based Allocation
      bna: TX Intr Coalescing Fix
      bna: Tx and Rx Optimizations
      bna: Code Cleanup and Enhancements
      ath9k: check pdata variable before dereferencing it
      ath5k: RX timestamp is reported at end of frame
      ath9k_htc: RX timestamp is reported at end of frame
      ...

commit 0ba18f7a5e268e095f79e32b7b47e8ce4fbabbe2
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Nov 22 07:32:46 2012 -0800

    netcls_cgroup: move config inheritance to ->css_online() and remove .broken_hierarchy marking
    
    It turns out that we'll have to live with attributes which are
    inherited at cgroup creation time but not affected by further updates
    to the parent afterwards - such attributes are already in wide use
    e.g. for cpuset.
    
    So, there's nothing to do for netcls_cgroup for hierarchy support.
    Its current behavior - inherit only during creation - is good enough.
    
    Move config inheriting from ->css_alloc() to ->css_online() for
    consistency, which doesn't change behavior at all, and remove
    .broken_hierarchy marking.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Tested-and-Acked-by: Daniel Wagner <daniel.wagner@bmw-carit.de>
    Acked-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index 8cdc18e075fb..31f06b633574 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -41,11 +41,15 @@ static struct cgroup_subsys_state *cgrp_css_alloc(struct cgroup *cgrp)
 	cs = kzalloc(sizeof(*cs), GFP_KERNEL);
 	if (!cs)
 		return ERR_PTR(-ENOMEM);
+	return &cs->css;
+}
 
+static int cgrp_css_online(struct cgroup *cgrp)
+{
 	if (cgrp->parent)
-		cs->classid = cgrp_cls_state(cgrp->parent)->classid;
-
-	return &cs->css;
+		cgrp_cls_state(cgrp)->classid =
+			cgrp_cls_state(cgrp->parent)->classid;
+	return 0;
 }
 
 static void cgrp_css_free(struct cgroup *cgrp)
@@ -76,19 +80,11 @@ static struct cftype ss_files[] = {
 struct cgroup_subsys net_cls_subsys = {
 	.name		= "net_cls",
 	.css_alloc	= cgrp_css_alloc,
+	.css_online	= cgrp_css_online,
 	.css_free	= cgrp_css_free,
 	.subsys_id	= net_cls_subsys_id,
 	.base_cftypes	= ss_files,
 	.module		= THIS_MODULE,
-
-	/*
-	 * While net_cls cgroup has the rudimentary hierarchy support of
-	 * inheriting the parent's classid on cgroup creation, it doesn't
-	 * properly propagates config changes in ancestors to their
-	 * descendents.  A child should follow the parent's configuration
-	 * but be allowed to override it.  Fix it and remove the following.
-	 */
-	.broken_hierarchy = true,
 };
 
 struct cls_cgroup_head {

commit 92fb97487a7e41b222c1417cabd1d1ab7cc3a48c
Author: Tejun Heo <tj@kernel.org>
Date:   Mon Nov 19 08:13:38 2012 -0800

    cgroup: rename ->create/post_create/pre_destroy/destroy() to ->css_alloc/online/offline/free()
    
    Rename cgroup_subsys css lifetime related callbacks to better describe
    what their roles are.  Also, update documentation.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index 2ecde225ae60..8cdc18e075fb 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -34,7 +34,7 @@ static inline struct cgroup_cls_state *task_cls_state(struct task_struct *p)
 			    struct cgroup_cls_state, css);
 }
 
-static struct cgroup_subsys_state *cgrp_create(struct cgroup *cgrp)
+static struct cgroup_subsys_state *cgrp_css_alloc(struct cgroup *cgrp)
 {
 	struct cgroup_cls_state *cs;
 
@@ -48,7 +48,7 @@ static struct cgroup_subsys_state *cgrp_create(struct cgroup *cgrp)
 	return &cs->css;
 }
 
-static void cgrp_destroy(struct cgroup *cgrp)
+static void cgrp_css_free(struct cgroup *cgrp)
 {
 	kfree(cgrp_cls_state(cgrp));
 }
@@ -75,8 +75,8 @@ static struct cftype ss_files[] = {
 
 struct cgroup_subsys net_cls_subsys = {
 	.name		= "net_cls",
-	.create		= cgrp_create,
-	.destroy	= cgrp_destroy,
+	.css_alloc	= cgrp_css_alloc,
+	.css_free	= cgrp_css_free,
 	.subsys_id	= net_cls_subsys_id,
 	.base_cftypes	= ss_files,
 	.module		= THIS_MODULE,

commit 6a328d8c6f03501657ad580f6f98bf9a42583ff7
Author: Daniel Wagner <daniel.wagner@bmw-carit.de>
Date:   Thu Oct 25 04:16:59 2012 +0000

    cgroup: net_cls: Rework update socket logic
    
    The cgroup logic part of net_cls is very similar as the one in
    net_prio. Let's stream line the net_cls logic with the net_prio one.
    
    The net_prio update logic was changed by following commit (note there
    were some changes necessary later on)
    
    commit 406a3c638ce8b17d9704052c07955490f732c2b8
    Author: John Fastabend <john.r.fastabend@intel.com>
    Date:   Fri Jul 20 10:39:25 2012 +0000
    
        net: netprio_cgroup: rework update socket logic
    
        Instead of updating the sk_cgrp_prioidx struct field on every send
        this only updates the field when a task is moved via cgroup
        infrastructure.
    
        This allows sockets that may be used by a kernel worker thread
        to be managed. For example in the iscsi case today a user can
        put iscsid in a netprio cgroup and control traffic will be sent
        with the correct sk_cgrp_prioidx value set but as soon as data
        is sent the kernel worker thread isssues a send and sk_cgrp_prioidx
        is updated with the kernel worker threads value which is the
        default case.
    
        It seems more correct to only update the field when the user
        explicitly sets it via control group infrastructure. This allows
        the users to manage sockets that may be used with other threads.
    
    Since classid is now updated when the task is moved between the
    cgroups, we don't have to call sock_update_classid() from various
    places to ensure we always using the latest classid value.
    
    [v2: Use iterate_fd() instead of open coding]
    
    Signed-off-by: Daniel Wagner <daniel.wagner@bmw-carit.de>
    Cc:  Li Zefan <lizefan@huawei.com>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: "Michael S. Tsirkin" <mst@redhat.com>
    Cc: Jamal Hadi Salim <jhs@mojatatu.com>
    Cc: Joe Perches <joe@perches.com>
    Cc: John Fastabend <john.r.fastabend@intel.com>
    Cc: Neil Horman <nhorman@tuxdriver.com>
    Cc: Stanislav Kinsbursky <skinsbursky@parallels.com>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: <netdev@vger.kernel.org>
    Cc: <cgroups@vger.kernel.org>
    Acked-by: Neil Horman <nhorman@tuxdriver.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index 2ecde225ae60..709b0fb38a18 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -17,6 +17,7 @@
 #include <linux/skbuff.h>
 #include <linux/cgroup.h>
 #include <linux/rcupdate.h>
+#include <linux/fdtable.h>
 #include <net/rtnetlink.h>
 #include <net/pkt_cls.h>
 #include <net/sock.h>
@@ -53,6 +54,28 @@ static void cgrp_destroy(struct cgroup *cgrp)
 	kfree(cgrp_cls_state(cgrp));
 }
 
+static int update_classid(const void *v, struct file *file, unsigned n)
+{
+	int err;
+	struct socket *sock = sock_from_file(file, &err);
+	if (sock)
+		sock->sk->sk_classid = (u32)(unsigned long)v;
+	return 0;
+}
+
+static void cgrp_attach(struct cgroup *cgrp, struct cgroup_taskset *tset)
+{
+	struct task_struct *p;
+	void *v;
+
+	cgroup_taskset_for_each(p, cgrp, tset) {
+		task_lock(p);
+		v = (void *)(unsigned long)task_cls_classid(p);
+		iterate_fd(p->files, 0, update_classid, v);
+		task_unlock(p);
+	}
+}
+
 static u64 read_classid(struct cgroup *cgrp, struct cftype *cft)
 {
 	return cgrp_cls_state(cgrp)->classid;
@@ -77,6 +100,7 @@ struct cgroup_subsys net_cls_subsys = {
 	.name		= "net_cls",
 	.create		= cgrp_create,
 	.destroy	= cgrp_destroy,
+	.attach		= cgrp_attach,
 	.subsys_id	= net_cls_subsys_id,
 	.base_cftypes	= ss_files,
 	.module		= THIS_MODULE,

commit 437589a74b6a590d175f86cf9f7b2efcee7765e7
Merge: 68d47a137c3b 72235465864d
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Oct 2 11:11:09 2012 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/ebiederm/user-namespace
    
    Pull user namespace changes from Eric Biederman:
     "This is a mostly modest set of changes to enable basic user namespace
      support.  This allows the code to code to compile with user namespaces
      enabled and removes the assumption there is only the initial user
      namespace.  Everything is converted except for the most complex of the
      filesystems: autofs4, 9p, afs, ceph, cifs, coda, fuse, gfs2, ncpfs,
      nfs, ocfs2 and xfs as those patches need a bit more review.
    
      The strategy is to push kuid_t and kgid_t values are far down into
      subsystems and filesystems as reasonable.  Leaving the make_kuid and
      from_kuid operations to happen at the edge of userspace, as the values
      come off the disk, and as the values come in from the network.
      Letting compile type incompatible compile errors (present when user
      namespaces are enabled) guide me to find the issues.
    
      The most tricky areas have been the places where we had an implicit
      union of uid and gid values and were storing them in an unsigned int.
      Those places were converted into explicit unions.  I made certain to
      handle those places with simple trivial patches.
    
      Out of that work I discovered we have generic interfaces for storing
      quota by projid.  I had never heard of the project identifiers before.
      Adding full user namespace support for project identifiers accounts
      for most of the code size growth in my git tree.
    
      Ultimately there will be work to relax privlige checks from
      "capable(FOO)" to "ns_capable(user_ns, FOO)" where it is safe allowing
      root in a user names to do those things that today we only forbid to
      non-root users because it will confuse suid root applications.
    
      While I was pushing kuid_t and kgid_t changes deep into the audit code
      I made a few other cleanups.  I capitalized on the fact we process
      netlink messages in the context of the message sender.  I removed
      usage of NETLINK_CRED, and started directly using current->tty.
    
      Some of these patches have also made it into maintainer trees, with no
      problems from identical code from different trees showing up in
      linux-next.
    
      After reading through all of this code I feel like I might be able to
      win a game of kernel trivial pursuit."
    
    Fix up some fairly trivial conflicts in netfilter uid/git logging code.
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/ebiederm/user-namespace: (107 commits)
      userns: Convert the ufs filesystem to use kuid/kgid where appropriate
      userns: Convert the udf filesystem to use kuid/kgid where appropriate
      userns: Convert ubifs to use kuid/kgid
      userns: Convert squashfs to use kuid/kgid where appropriate
      userns: Convert reiserfs to use kuid and kgid where appropriate
      userns: Convert jfs to use kuid/kgid where appropriate
      userns: Convert jffs2 to use kuid and kgid where appropriate
      userns: Convert hpfs to use kuid and kgid where appropriate
      userns: Convert btrfs to use kuid/kgid where appropriate
      userns: Convert bfs to use kuid/kgid where appropriate
      userns: Convert affs to use kuid/kgid wherwe appropriate
      userns: On alpha modify linux_to_osf_stat to use convert from kuids and kgids
      userns: On ia64 deal with current_uid and current_gid being kuid and kgid
      userns: On ppc convert current_uid from a kuid before printing.
      userns: Convert s390 getting uid and gid system calls to use kuid and kgid
      userns: Convert s390 hypfs to use kuid and kgid where appropriate
      userns: Convert binder ipc to use kuids
      userns: Teach security_path_chown to take kuids and kgids
      userns: Add user namespace support to IMA
      userns: Convert EVM to deal with kuids and kgids in it's hmac computation
      ...

commit 68d47a137c3bef754923bccf73fb639c9b0bbd5e
Merge: c0e8a139a5bb 8c7f6edbda01
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Oct 2 10:52:28 2012 -0700

    Merge branch 'for-3.7-hierarchy' of git://git.kernel.org/pub/scm/linux/kernel/git/tj/cgroup
    
    Pull cgroup hierarchy update from Tejun Heo:
     "Currently, different cgroup subsystems handle nested cgroups
      completely differently.  There's no consistency among subsystems and
      the behaviors often are outright broken.
    
      People at least seem to agree that the broken hierarhcy behaviors need
      to be weeded out if any progress is gonna be made on this front and
      that the fallouts from deprecating the broken behaviors should be
      acceptable especially given that the current behaviors don't make much
      sense when nested.
    
      This patch makes cgroup emit warning messages if cgroups for
      subsystems with broken hierarchy behavior are nested to prepare for
      fixing them in the future.  This was put in a separate branch because
      more related changes were expected (didn't make it this round) and the
      memory cgroup wanted to pull in this and make changes on top."
    
    * 'for-3.7-hierarchy' of git://git.kernel.org/pub/scm/linux/kernel/git/tj/cgroup:
      cgroup: mark subsystems with broken hierarchy support and whine if cgroups are nested for them

commit 8c7f6edbda01f1b1a2e60ad61f14fe38023e433b
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Sep 13 12:20:58 2012 -0700

    cgroup: mark subsystems with broken hierarchy support and whine if cgroups are nested for them
    
    Currently, cgroup hierarchy support is a mess.  cpu related subsystems
    behave correctly - configuration, accounting and control on a parent
    properly cover its children.  blkio and freezer completely ignore
    hierarchy and treat all cgroups as if they're directly under the root
    cgroup.  Others show yet different behaviors.
    
    These differing interpretations of cgroup hierarchy make using cgroup
    confusing and it impossible to co-mount controllers into the same
    hierarchy and obtain sane behavior.
    
    Eventually, we want full hierarchy support from all subsystems and
    probably a unified hierarchy.  Users using separate hierarchies
    expecting completely different behaviors depending on the mounted
    subsystem is deterimental to making any progress on this front.
    
    This patch adds cgroup_subsys.broken_hierarchy and sets it to %true
    for controllers which are lacking in hierarchy support.  The goal of
    this patch is two-fold.
    
    * Move users away from using hierarchy on currently non-hierarchical
      subsystems, so that implementing proper hierarchy support on those
      doesn't surprise them.
    
    * Keep track of which controllers are broken how and nudge the
      subsystems to implement proper hierarchy support.
    
    For now, start with a single warning message.  We can whine louder
    later on.
    
    v2: Fixed a typo spotted by Michal. Warning message updated.
    
    v3: Updated memcg part so that it doesn't generate warning in the
        cases where .use_hierarchy=false doesn't make the behavior
        different from root.use_hierarchy=true.  Fixed a typo spotted by
        Glauber.
    
    v4: Check ->broken_hierarchy after cgroup creation is complete so that
        ->create() can affect the result per Michal.  Dropped unnecessary
        memcg root handling per Michal.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Michal Hocko <mhocko@suse.cz>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Acked-by: Serge E. Hallyn <serue@us.ibm.com>
    Cc: Glauber Costa <glommer@parallels.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Paul Turner <pjt@google.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Thomas Graf <tgraf@suug.ch>
    Cc: Vivek Goyal <vgoyal@redhat.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Arnaldo Carvalho de Melo <acme@ghostprotocols.net>
    Cc: Neil Horman <nhorman@tuxdriver.com>
    Cc: Aneesh Kumar K.V <aneesh.kumar@linux.vnet.ibm.com>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index 7743ea8d1d38..907daf99ab2e 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -82,6 +82,15 @@ struct cgroup_subsys net_cls_subsys = {
 #endif
 	.base_cftypes	= ss_files,
 	.module		= THIS_MODULE,
+
+	/*
+	 * While net_cls cgroup has the rudimentary hierarchy support of
+	 * inheriting the parent's classid on cgroup creation, it doesn't
+	 * properly propagates config changes in ancestors to their
+	 * descendents.  A child should follow the parent's configuration
+	 * but be allowed to override it.  Fix it and remove the following.
+	 */
+	.broken_hierarchy = true,
 };
 
 struct cls_cgroup_head {

commit 8a8e04df4747661daaee77e98e102d99c9e09b98
Author: Daniel Wagner <daniel.wagner@bmw-carit.de>
Date:   Wed Sep 12 16:12:07 2012 +0200

    cgroup: Assign subsystem IDs during compile time
    
    WARNING: With this change it is impossible to load external built
    controllers anymore.
    
    In case where CONFIG_NETPRIO_CGROUP=m and CONFIG_NET_CLS_CGROUP=m is
    set, corresponding subsys_id should also be a constant. Up to now,
    net_prio_subsys_id and net_cls_subsys_id would be of the type int and
    the value would be assigned during runtime.
    
    By switching the macro definition IS_SUBSYS_ENABLED from IS_BUILTIN
    to IS_ENABLED, all *_subsys_id will have constant value. That means we
    need to remove all the code which assumes a value can be assigned to
    net_prio_subsys_id and net_cls_subsys_id.
    
    A close look is necessary on the RCU part which was introduces by
    following patch:
    
      commit f845172531fb7410c7fb7780b1a6e51ee6df7d52
      Author:       Herbert Xu <herbert@gondor.apana.org.au>  Mon May 24 09:12:34 2010
      Committer:    David S. Miller <davem@davemloft.net>  Mon May 24 09:12:34 2010
    
      cls_cgroup: Store classid in struct sock
    
      Tis code was added to init_cgroup_cls()
    
              /* We can't use rcu_assign_pointer because this is an int. */
              smp_wmb();
              net_cls_subsys_id = net_cls_subsys.subsys_id;
    
      respectively to exit_cgroup_cls()
    
              net_cls_subsys_id = -1;
              synchronize_rcu();
    
      and in module version of task_cls_classid()
    
              rcu_read_lock();
              id = rcu_dereference(net_cls_subsys_id);
              if (id >= 0)
                      classid = container_of(task_subsys_state(p, id),
                                             struct cgroup_cls_state, css)->classid;
              rcu_read_unlock();
    
    Without an explicit explaination why the RCU part is needed. (The
    rcu_deference was fixed by exchanging it to rcu_derefence_index_check()
    in a later commit, but that is a minor detail.)
    
    So here is my pondering why it was introduced and why it safe to
    remove it now. Note that this code was copied over to net_prio the
    reasoning holds for that subsystem too.
    
    The idea behind the RCU use for net_cls_subsys_id is to make sure we
    get a valid pointer back from task_subsys_state(). task_subsys_state()
    is just blindly accessing the subsys array and returning the
    pointer. Obviously, passing in -1 as id into task_subsys_state()
    returns an invalid value (out of lower bound).
    
    So this code makes sure that only after module is loaded and the
    subsystem registered, the id is assigned.
    
    Before unregistering the module all old readers must have left the
    critical section. This is done by assigning -1 to the id and issuing a
    synchronized_rcu(). Any new readers wont call task_subsys_state()
    anymore and therefore it is safe to unregister the subsystem.
    
    The new code relies on the same trick, but it looks at the subsys
    pointer return by task_subsys_state() (remember the id is constant
    and therefore we allways have a valid index into the subsys
    array).
    
    No precautions need to be taken during module loading
    module. Eventually, all CPUs will get a valid pointer back from
    task_subsys_state() because rebind_subsystem() which is called after
    the module init() function will assigned subsys[net_cls_subsys_id] the
    newly loaded module subsystem pointer.
    
    When the subsystem is about to be removed, rebind_subsystem() will
    called before the module exit() function. In this case,
    rebind_subsys() will assign subsys[net_cls_subsys_id] a NULL pointer
    and then it calls synchronize_rcu(). All old readers have left by then
    the critical section. Any new reader wont access the subsystem
    anymore.  At this point we are safe to unregister the subsystem. No
    synchronize_rcu() call is needed.
    
    Signed-off-by: Daniel Wagner <daniel.wagner@bmw-carit.de>
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Acked-by: Neil Horman <nhorman@tuxdriver.com>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: "Paul E. McKenney" <paulmck@linux.vnet.ibm.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Eric Dumazet <edumazet@google.com>
    Cc: Gao feng <gaofeng@cn.fujitsu.com>
    Cc: Glauber Costa <glommer@parallels.com>
    Cc: Herbert Xu <herbert@gondor.apana.org.au>
    Cc: Jamal Hadi Salim <jhs@mojatatu.com>
    Cc: John Fastabend <john.r.fastabend@intel.com>
    Cc: Kamezawa Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: netdev@vger.kernel.org
    Cc: cgroups@vger.kernel.org

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index 7743ea8d1d38..67cf90d962f4 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -77,9 +77,7 @@ struct cgroup_subsys net_cls_subsys = {
 	.name		= "net_cls",
 	.create		= cgrp_create,
 	.destroy	= cgrp_destroy,
-#ifdef CONFIG_NET_CLS_CGROUP
 	.subsys_id	= net_cls_subsys_id,
-#endif
 	.base_cftypes	= ss_files,
 	.module		= THIS_MODULE,
 };
@@ -283,12 +281,6 @@ static int __init init_cgroup_cls(void)
 	if (ret)
 		goto out;
 
-#ifndef CONFIG_NET_CLS_CGROUP
-	/* We can't use rcu_assign_pointer because this is an int. */
-	smp_wmb();
-	net_cls_subsys_id = net_cls_subsys.subsys_id;
-#endif
-
 	ret = register_tcf_proto_ops(&cls_cgroup_ops);
 	if (ret)
 		cgroup_unload_subsys(&net_cls_subsys);
@@ -301,11 +293,6 @@ static void __exit exit_cgroup_cls(void)
 {
 	unregister_tcf_proto_ops(&cls_cgroup_ops);
 
-#ifndef CONFIG_NET_CLS_CGROUP
-	net_cls_subsys_id = -1;
-	synchronize_rcu();
-#endif
-
 	cgroup_unload_subsys(&net_cls_subsys);
 }
 

commit af4c6641f5ad445fe6d0832da42406dbd9a37ce4
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Fri May 25 13:42:45 2012 -0600

    net sched: Pass the skb into change so it can access NETLINK_CB
    
    cls_flow.c plays with uids and gids.  Unless I misread that
    code it is possible for classifiers to depend on the specific uid and
    gid values.  Therefore I need to know the user namespace of the
    netlink socket that is installing the packet classifiers.  Pass
    in the rtnetlink skb so I can access the NETLINK_CB of the passed
    packet.  In particular I want access to sk_user_ns(NETLINK_CB(in_skb).ssk).
    
    Pass in not the user namespace but the incomming rtnetlink skb into
    the the classifier change routines as that is generally the more useful
    parameter.
    
    Cc: Jamal Hadi Salim <jhs@mojatatu.com>
    Acked-by: David S. Miller <davem@davemloft.net>
    Acked-by: Serge Hallyn <serge.hallyn@canonical.com>
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index 7743ea8d1d38..91de66695b4a 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -151,7 +151,8 @@ static const struct nla_policy cgroup_policy[TCA_CGROUP_MAX + 1] = {
 	[TCA_CGROUP_EMATCHES]	= { .type = NLA_NESTED },
 };
 
-static int cls_cgroup_change(struct tcf_proto *tp, unsigned long base,
+static int cls_cgroup_change(struct sk_buff *in_skb,
+			     struct tcf_proto *tp, unsigned long base,
 			     u32 handle, struct nlattr **tca,
 			     unsigned long *arg)
 {

commit 4baf6e33251b37f111e21289f8ee71fe4cce236e
Author: Tejun Heo <tj@kernel.org>
Date:   Sun Apr 1 12:09:55 2012 -0700

    cgroup: convert all non-memcg controllers to the new cftype interface
    
    Convert debug, freezer, cpuset, cpu_cgroup, cpuacct, net_prio, blkio,
    net_cls and device controllers to use the new cftype based interface.
    Termination entry is added to cftype arrays and populate callbacks are
    replaced with cgroup_subsys->base_cftypes initializations.
    
    This is functionally identical transformation.  There shouldn't be any
    visible behavior change.
    
    memcg is rather special and will be converted separately.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizf@cn.fujitsu.com>
    Cc: Paul Menage <paul@paulmenage.org>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Vivek Goyal <vgoyal@redhat.com>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index 024df8a32275..7743ea8d1d38 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -70,21 +70,17 @@ static struct cftype ss_files[] = {
 		.read_u64 = read_classid,
 		.write_u64 = write_classid,
 	},
+	{ }	/* terminate */
 };
 
-static int cgrp_populate(struct cgroup_subsys *ss, struct cgroup *cgrp)
-{
-	return cgroup_add_files(cgrp, ss, ss_files, ARRAY_SIZE(ss_files));
-}
-
 struct cgroup_subsys net_cls_subsys = {
 	.name		= "net_cls",
 	.create		= cgrp_create,
 	.destroy	= cgrp_destroy,
-	.populate	= cgrp_populate,
 #ifdef CONFIG_NET_CLS_CGROUP
 	.subsys_id	= net_cls_subsys_id,
 #endif
+	.base_cftypes	= ss_files,
 	.module		= THIS_MODULE,
 };
 

commit 676f7c8f84d15e94065841529016da5ab92e901b
Author: Tejun Heo <tj@kernel.org>
Date:   Sun Apr 1 12:09:55 2012 -0700

    cgroup: relocate cftype and cgroup_subsys definitions in controllers
    
    blk-cgroup, netprio_cgroup, cls_cgroup and tcp_memcontrol
    unnecessarily define cftype array and cgroup_subsys structures at the
    top of the file, which is unconventional and necessiates forward
    declaration of methods.
    
    This patch relocates those below the definitions of the methods and
    removes the forward declarations.  Note that forward declaration of
    tcp_files[] is added in tcp_memcontrol.c for tcp_init_cgroup().  This
    will be removed soon by another patch.
    
    This patch doesn't introduce any functional change.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizf@cn.fujitsu.com>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index 1afaa284fcd7..024df8a32275 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -22,22 +22,6 @@
 #include <net/sock.h>
 #include <net/cls_cgroup.h>
 
-static struct cgroup_subsys_state *cgrp_create(struct cgroup *cgrp);
-static void cgrp_destroy(struct cgroup *cgrp);
-static int cgrp_populate(struct cgroup_subsys *ss, struct cgroup *cgrp);
-
-struct cgroup_subsys net_cls_subsys = {
-	.name		= "net_cls",
-	.create		= cgrp_create,
-	.destroy	= cgrp_destroy,
-	.populate	= cgrp_populate,
-#ifdef CONFIG_NET_CLS_CGROUP
-	.subsys_id	= net_cls_subsys_id,
-#endif
-	.module		= THIS_MODULE,
-};
-
-
 static inline struct cgroup_cls_state *cgrp_cls_state(struct cgroup *cgrp)
 {
 	return container_of(cgroup_subsys_state(cgrp, net_cls_subsys_id),
@@ -93,6 +77,17 @@ static int cgrp_populate(struct cgroup_subsys *ss, struct cgroup *cgrp)
 	return cgroup_add_files(cgrp, ss, ss_files, ARRAY_SIZE(ss_files));
 }
 
+struct cgroup_subsys net_cls_subsys = {
+	.name		= "net_cls",
+	.create		= cgrp_create,
+	.destroy	= cgrp_destroy,
+	.populate	= cgrp_populate,
+#ifdef CONFIG_NET_CLS_CGROUP
+	.subsys_id	= net_cls_subsys_id,
+#endif
+	.module		= THIS_MODULE,
+};
+
 struct cls_cgroup_head {
 	u32			handle;
 	struct tcf_exts		exts;

commit 761b3ef50e1c2649cffbfa67a4dcb2dcdb7982ed
Author: Li Zefan <lizf@cn.fujitsu.com>
Date:   Tue Jan 31 13:47:36 2012 +0800

    cgroup: remove cgroup_subsys argument from callbacks
    
    The argument is not used at all, and it's not necessary, because
    a specific callback handler of course knows which subsys it
    belongs to.
    
    Now only ->pupulate() takes this argument, because the handlers of
    this callback always call cgroup_add_file()/cgroup_add_files().
    
    So we reduce a few lines of code, though the shrinking of object size
    is minimal.
    
     16 files changed, 113 insertions(+), 162 deletions(-)
    
       text    data     bss     dec     hex filename
    5486240  656987 7039960 13183187         c928d3 vmlinux.o.orig
    5486170  656987 7039960 13183117         c9288d vmlinux.o
    
    Signed-off-by: Li Zefan <lizf@cn.fujitsu.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index f84fdc3a7f27..1afaa284fcd7 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -22,9 +22,8 @@
 #include <net/sock.h>
 #include <net/cls_cgroup.h>
 
-static struct cgroup_subsys_state *cgrp_create(struct cgroup_subsys *ss,
-					       struct cgroup *cgrp);
-static void cgrp_destroy(struct cgroup_subsys *ss, struct cgroup *cgrp);
+static struct cgroup_subsys_state *cgrp_create(struct cgroup *cgrp);
+static void cgrp_destroy(struct cgroup *cgrp);
 static int cgrp_populate(struct cgroup_subsys *ss, struct cgroup *cgrp);
 
 struct cgroup_subsys net_cls_subsys = {
@@ -51,8 +50,7 @@ static inline struct cgroup_cls_state *task_cls_state(struct task_struct *p)
 			    struct cgroup_cls_state, css);
 }
 
-static struct cgroup_subsys_state *cgrp_create(struct cgroup_subsys *ss,
-						 struct cgroup *cgrp)
+static struct cgroup_subsys_state *cgrp_create(struct cgroup *cgrp)
 {
 	struct cgroup_cls_state *cs;
 
@@ -66,7 +64,7 @@ static struct cgroup_subsys_state *cgrp_create(struct cgroup_subsys *ss,
 	return &cs->css;
 }
 
-static void cgrp_destroy(struct cgroup_subsys *ss, struct cgroup *cgrp)
+static void cgrp_destroy(struct cgroup *cgrp)
 {
 	kfree(cgrp_cls_state(cgrp));
 }

commit dc7f9f6e8838556f226c2ebd1da7bb305cb25654
Author: Eric Dumazet <eric.dumazet@gmail.com>
Date:   Tue Jul 5 23:25:42 2011 +0000

    net: sched: constify tcf_proto and tc_action
    
    Signed-off-by: Eric Dumazet <eric.dumazet@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index 32a335194ca5..f84fdc3a7f27 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -101,7 +101,7 @@ struct cls_cgroup_head {
 	struct tcf_ematch_tree	ematches;
 };
 
-static int cls_cgroup_classify(struct sk_buff *skb, struct tcf_proto *tp,
+static int cls_cgroup_classify(struct sk_buff *skb, const struct tcf_proto *tp,
 			       struct tcf_result *res)
 {
 	struct cls_cgroup_head *head = tp->root;

commit cc7ec456f82da7f89a5b376e613b3ac4311b3e9a
Author: Eric Dumazet <eric.dumazet@gmail.com>
Date:   Wed Jan 19 19:26:56 2011 +0000

    net_sched: cleanups
    
    Cleanup net/sched code to current CodingStyle and practices.
    
    Reduce inline abuse
    
    Signed-off-by: Eric Dumazet <eric.dumazet@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index d49c40fb7e09..32a335194ca5 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -56,7 +56,8 @@ static struct cgroup_subsys_state *cgrp_create(struct cgroup_subsys *ss,
 {
 	struct cgroup_cls_state *cs;
 
-	if (!(cs = kzalloc(sizeof(*cs), GFP_KERNEL)))
+	cs = kzalloc(sizeof(*cs), GFP_KERNEL);
+	if (!cs)
 		return ERR_PTR(-ENOMEM);
 
 	if (cgrp->parent)
@@ -94,8 +95,7 @@ static int cgrp_populate(struct cgroup_subsys *ss, struct cgroup *cgrp)
 	return cgroup_add_files(cgrp, ss, ss_files, ARRAY_SIZE(ss_files));
 }
 
-struct cls_cgroup_head
-{
+struct cls_cgroup_head {
 	u32			handle;
 	struct tcf_exts		exts;
 	struct tcf_ematch_tree	ematches;
@@ -166,7 +166,7 @@ static int cls_cgroup_change(struct tcf_proto *tp, unsigned long base,
 			     u32 handle, struct nlattr **tca,
 			     unsigned long *arg)
 {
-	struct nlattr *tb[TCA_CGROUP_MAX+1];
+	struct nlattr *tb[TCA_CGROUP_MAX + 1];
 	struct cls_cgroup_head *head = tp->root;
 	struct tcf_ematch_tree t;
 	struct tcf_exts e;

commit c00b2c9e79466d61979cd21af526cc6d5d0ee04f
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Wed Nov 3 13:31:05 2010 +0000

    cls_cgroup: Fix crash on module unload
    
    Somewhere along the lines net_cls_subsys_id became a macro when
    cls_cgroup is built as a module.  Not only did it make cls_cgroup
    completely useless, it also causes it to crash on module unload.
    
    This patch fixes this by removing that macro.
    
    Thanks to Eric Dumazet for diagnosing this problem.
    
    Reported-by: Randy Dunlap <randy.dunlap@oracle.com>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
    Reviewed-by: Li Zefan <lizf@cn.fujitsu.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index 37dff78e9cb1..d49c40fb7e09 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -34,8 +34,6 @@ struct cgroup_subsys net_cls_subsys = {
 	.populate	= cgrp_populate,
 #ifdef CONFIG_NET_CLS_CGROUP
 	.subsys_id	= net_cls_subsys_id,
-#else
-#define net_cls_subsys_id net_cls_subsys.subsys_id
 #endif
 	.module		= THIS_MODULE,
 };

commit 75e1056f5c57050415b64cb761a3acc35d91f013
Author: Venkatesh Pallipadi <venki@google.com>
Date:   Mon Oct 4 17:03:16 2010 -0700

    sched: Fix softirq time accounting
    
    Peter Zijlstra found a bug in the way softirq time is accounted in
    VIRT_CPU_ACCOUNTING on this thread:
    
       http://lkml.indiana.edu/hypermail//linux/kernel/1009.2/01366.html
    
    The problem is, softirq processing uses local_bh_disable internally. There
    is no way, later in the flow, to differentiate between whether softirq is
    being processed or is it just that bh has been disabled. So, a hardirq when bh
    is disabled results in time being wrongly accounted as softirq.
    
    Looking at the code a bit more, the problem exists in !VIRT_CPU_ACCOUNTING
    as well. As account_system_time() in normal tick based accouting also uses
    softirq_count, which will be set even when not in softirq with bh disabled.
    
    Peter also suggested solution of using 2*SOFTIRQ_OFFSET as irq count
    for local_bh_{disable,enable} and using just SOFTIRQ_OFFSET while softirq
    processing. The patch below does that and adds API in_serving_softirq() which
    returns whether we are currently processing softirq or not.
    
    Also changes one of the usages of softirq_count in net/sched/cls_cgroup.c
    to in_serving_softirq.
    
    Looks like many usages of in_softirq really want in_serving_softirq. Those
    changes can be made individually on a case by case basis.
    
    Signed-off-by: Venkatesh Pallipadi <venki@google.com>
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    LKML-Reference: <1286237003-12406-2-git-send-email-venki@google.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index 78ef2c5e130b..37dff78e9cb1 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -123,7 +123,7 @@ static int cls_cgroup_classify(struct sk_buff *skb, struct tcf_proto *tp,
 	 * calls by looking at the number of nested bh disable calls because
 	 * softirqs always disables bh.
 	 */
-	if (softirq_count() != SOFTIRQ_OFFSET) {
+	if (in_serving_softirq()) {
 		/* If there is an sk_classid we'll use that. */
 		if (!skb->sk)
 			return -1;

commit f845172531fb7410c7fb7780b1a6e51ee6df7d52
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Mon May 24 00:12:34 2010 -0700

    cls_cgroup: Store classid in struct sock
    
    Up until now cls_cgroup has relied on fetching the classid out of
    the current executing thread.  This runs into trouble when a packet
    processing is delayed in which case it may execute out of another
    thread's context.
    
    Furthermore, even when a packet is not delayed we may fail to
    classify it if soft IRQs have been disabled, because this scenario
    is indistinguishable from one where a packet unrelated to the
    current thread is processed by a real soft IRQ.
    
    In fact, the current semantics is inherently broken, as a single
    skb may be constructed out of the writes of two different tasks.
    A different manifestation of this problem is when the TCP stack
    transmits in response of an incoming ACK.  This is currently
    unclassified.
    
    As we already have a concept of packet ownership for accounting
    purposes in the skb->sk pointer, this is a natural place to store
    the classid in a persistent manner.
    
    This patch adds the cls_cgroup classid in struct sock, filling up
    an existing hole on 64-bit :)
    
    The value is set at socket creation time.  So all sockets created
    via socket(2) automatically gains the ID of the thread creating it.
    Whenever another process touches the socket by either reading or
    writing to it, we will change the socket classid to that of the
    process if it has a valid (non-zero) classid.
    
    For sockets created on inbound connections through accept(2), we
    inherit the classid of the original listening socket through
    sk_clone, possibly preceding the actual accept(2) call.
    
    In order to minimise risks, I have not made this the authoritative
    classid.  For now it is only used as a backup when we execute
    with soft IRQs disabled.  Once we're completely happy with its
    semantics we can use it as the sole classid.
    
    Footnote: I have rearranged the error path on cls_group module
    creation.  If we didn't do this, then there is a window where
    someone could create a tc rule using cls_group before the cgroup
    subsystem has been registered.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index 221180384fd7..78ef2c5e130b 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -16,14 +16,11 @@
 #include <linux/errno.h>
 #include <linux/skbuff.h>
 #include <linux/cgroup.h>
+#include <linux/rcupdate.h>
 #include <net/rtnetlink.h>
 #include <net/pkt_cls.h>
-
-struct cgroup_cls_state
-{
-	struct cgroup_subsys_state css;
-	u32 classid;
-};
+#include <net/sock.h>
+#include <net/cls_cgroup.h>
 
 static struct cgroup_subsys_state *cgrp_create(struct cgroup_subsys *ss,
 					       struct cgroup *cgrp);
@@ -112,6 +109,10 @@ static int cls_cgroup_classify(struct sk_buff *skb, struct tcf_proto *tp,
 	struct cls_cgroup_head *head = tp->root;
 	u32 classid;
 
+	rcu_read_lock();
+	classid = task_cls_state(current)->classid;
+	rcu_read_unlock();
+
 	/*
 	 * Due to the nature of the classifier it is required to ignore all
 	 * packets originating from softirq context as accessing `current'
@@ -122,12 +123,12 @@ static int cls_cgroup_classify(struct sk_buff *skb, struct tcf_proto *tp,
 	 * calls by looking at the number of nested bh disable calls because
 	 * softirqs always disables bh.
 	 */
-	if (softirq_count() != SOFTIRQ_OFFSET)
-		return -1;
-
-	rcu_read_lock();
-	classid = task_cls_state(current)->classid;
-	rcu_read_unlock();
+	if (softirq_count() != SOFTIRQ_OFFSET) {
+		/* If there is an sk_classid we'll use that. */
+		if (!skb->sk)
+			return -1;
+		classid = skb->sk->sk_classid;
+	}
 
 	if (!classid)
 		return -1;
@@ -289,18 +290,35 @@ static struct tcf_proto_ops cls_cgroup_ops __read_mostly = {
 
 static int __init init_cgroup_cls(void)
 {
-	int ret = register_tcf_proto_ops(&cls_cgroup_ops);
-	if (ret)
-		return ret;
+	int ret;
+
 	ret = cgroup_load_subsys(&net_cls_subsys);
 	if (ret)
-		unregister_tcf_proto_ops(&cls_cgroup_ops);
+		goto out;
+
+#ifndef CONFIG_NET_CLS_CGROUP
+	/* We can't use rcu_assign_pointer because this is an int. */
+	smp_wmb();
+	net_cls_subsys_id = net_cls_subsys.subsys_id;
+#endif
+
+	ret = register_tcf_proto_ops(&cls_cgroup_ops);
+	if (ret)
+		cgroup_unload_subsys(&net_cls_subsys);
+
+out:
 	return ret;
 }
 
 static void __exit exit_cgroup_cls(void)
 {
 	unregister_tcf_proto_ops(&cls_cgroup_ops);
+
+#ifndef CONFIG_NET_CLS_CGROUP
+	net_cls_subsys_id = -1;
+	synchronize_rcu();
+#endif
+
 	cgroup_unload_subsys(&net_cls_subsys);
 }
 

commit 5a0e3ad6af8660be21ca98a971cd00f331318c05
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Mar 24 17:04:11 2010 +0900

    include cleanup: Update gfp.h and slab.h includes to prepare for breaking implicit slab.h inclusion from percpu.h
    
    percpu.h is included by sched.h and module.h and thus ends up being
    included when building most .c files.  percpu.h includes slab.h which
    in turn includes gfp.h making everything defined by the two files
    universally available and complicating inclusion dependencies.
    
    percpu.h -> slab.h dependency is about to be removed.  Prepare for
    this change by updating users of gfp and slab facilities include those
    headers directly instead of assuming availability.  As this conversion
    needs to touch large number of source files, the following script is
    used as the basis of conversion.
    
      http://userweb.kernel.org/~tj/misc/slabh-sweep.py
    
    The script does the followings.
    
    * Scan files for gfp and slab usages and update includes such that
      only the necessary includes are there.  ie. if only gfp is used,
      gfp.h, if slab is used, slab.h.
    
    * When the script inserts a new include, it looks at the include
      blocks and try to put the new include such that its order conforms
      to its surrounding.  It's put in the include block which contains
      core kernel includes, in the same order that the rest are ordered -
      alphabetical, Christmas tree, rev-Xmas-tree or at the end if there
      doesn't seem to be any matching order.
    
    * If the script can't find a place to put a new include (mostly
      because the file doesn't have fitting include block), it prints out
      an error message indicating which .h file needs to be added to the
      file.
    
    The conversion was done in the following steps.
    
    1. The initial automatic conversion of all .c files updated slightly
       over 4000 files, deleting around 700 includes and adding ~480 gfp.h
       and ~3000 slab.h inclusions.  The script emitted errors for ~400
       files.
    
    2. Each error was manually checked.  Some didn't need the inclusion,
       some needed manual addition while adding it to implementation .h or
       embedding .c file was more appropriate for others.  This step added
       inclusions to around 150 files.
    
    3. The script was run again and the output was compared to the edits
       from #2 to make sure no file was left behind.
    
    4. Several build tests were done and a couple of problems were fixed.
       e.g. lib/decompress_*.c used malloc/free() wrappers around slab
       APIs requiring slab.h to be added manually.
    
    5. The script was run on all .h files but without automatically
       editing them as sprinkling gfp.h and slab.h inclusions around .h
       files could easily lead to inclusion dependency hell.  Most gfp.h
       inclusion directives were ignored as stuff from gfp.h was usually
       wildly available and often used in preprocessor macros.  Each
       slab.h inclusion directive was examined and added manually as
       necessary.
    
    6. percpu.h was updated not to include slab.h.
    
    7. Build test were done on the following configurations and failures
       were fixed.  CONFIG_GCOV_KERNEL was turned off for all tests (as my
       distributed build env didn't work with gcov compiles) and a few
       more options had to be turned off depending on archs to make things
       build (like ipr on powerpc/64 which failed due to missing writeq).
    
       * x86 and x86_64 UP and SMP allmodconfig and a custom test config.
       * powerpc and powerpc64 SMP allmodconfig
       * sparc and sparc64 SMP allmodconfig
       * ia64 SMP allmodconfig
       * s390 SMP allmodconfig
       * alpha SMP allmodconfig
       * um on x86_64 SMP allmodconfig
    
    8. percpu.h modifications were reverted so that it could be applied as
       a separate patch and serve as bisection point.
    
    Given the fact that I had only a couple of failures from tests on step
    6, I'm fairly confident about the coverage of this conversion patch.
    If there is a breakage, it's likely to be something in one of the arch
    headers which should be easily discoverable easily on most builds of
    the specific arch.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Guess-its-ok-by: Christoph Lameter <cl@linux-foundation.org>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Lee Schermerhorn <Lee.Schermerhorn@hp.com>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index 7f27d2c15e08..221180384fd7 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -10,6 +10,7 @@
  */
 
 #include <linux/module.h>
+#include <linux/slab.h>
 #include <linux/types.h>
 #include <linux/string.h>
 #include <linux/errno.h>

commit 8e039d84b323c4503c4d56863faa47c783660826
Author: Ben Blum <bblum@andrew.cmu.edu>
Date:   Tue Mar 23 05:24:03 2010 +0000

    cgroups: net_cls as module
    
    Allows the net_cls cgroup subsystem to be compiled as a module
    
    This patch modifies net/sched/cls_cgroup.c to allow the net_cls subsystem
    to be optionally compiled as a module instead of builtin.  The
    cgroup_subsys struct is moved around a bit to allow the subsys_id to be
    either declared as a compile-time constant by the cgroup_subsys.h include
    in cgroup.h, or, if it's a module, initialized within the struct by
    cgroup_load_subsys.
    
    Signed-off-by: Ben Blum <bblum@andrew.cmu.edu>
    Acked-by: Li Zefan <lizf@cn.fujitsu.com>
    Cc: Paul Menage <menage@google.com>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: Lai Jiangshan <laijs@cn.fujitsu.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index e4877ca6727c..7f27d2c15e08 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -24,6 +24,25 @@ struct cgroup_cls_state
 	u32 classid;
 };
 
+static struct cgroup_subsys_state *cgrp_create(struct cgroup_subsys *ss,
+					       struct cgroup *cgrp);
+static void cgrp_destroy(struct cgroup_subsys *ss, struct cgroup *cgrp);
+static int cgrp_populate(struct cgroup_subsys *ss, struct cgroup *cgrp);
+
+struct cgroup_subsys net_cls_subsys = {
+	.name		= "net_cls",
+	.create		= cgrp_create,
+	.destroy	= cgrp_destroy,
+	.populate	= cgrp_populate,
+#ifdef CONFIG_NET_CLS_CGROUP
+	.subsys_id	= net_cls_subsys_id,
+#else
+#define net_cls_subsys_id net_cls_subsys.subsys_id
+#endif
+	.module		= THIS_MODULE,
+};
+
+
 static inline struct cgroup_cls_state *cgrp_cls_state(struct cgroup *cgrp)
 {
 	return container_of(cgroup_subsys_state(cgrp, net_cls_subsys_id),
@@ -79,14 +98,6 @@ static int cgrp_populate(struct cgroup_subsys *ss, struct cgroup *cgrp)
 	return cgroup_add_files(cgrp, ss, ss_files, ARRAY_SIZE(ss_files));
 }
 
-struct cgroup_subsys net_cls_subsys = {
-	.name		= "net_cls",
-	.create		= cgrp_create,
-	.destroy	= cgrp_destroy,
-	.populate	= cgrp_populate,
-	.subsys_id	= net_cls_subsys_id,
-};
-
 struct cls_cgroup_head
 {
 	u32			handle;
@@ -277,12 +288,19 @@ static struct tcf_proto_ops cls_cgroup_ops __read_mostly = {
 
 static int __init init_cgroup_cls(void)
 {
-	return register_tcf_proto_ops(&cls_cgroup_ops);
+	int ret = register_tcf_proto_ops(&cls_cgroup_ops);
+	if (ret)
+		return ret;
+	ret = cgroup_load_subsys(&net_cls_subsys);
+	if (ret)
+		unregister_tcf_proto_ops(&cls_cgroup_ops);
+	return ret;
 }
 
 static void __exit exit_cgroup_cls(void)
 {
 	unregister_tcf_proto_ops(&cls_cgroup_ops);
+	cgroup_unload_subsys(&net_cls_subsys);
 }
 
 module_init(init_cgroup_cls);

commit 9cbc1cb8cd46ce1f7645b9de249b2ce8460129bb
Merge: ca44d6e60f9d 45e3e1935e28
Author: David S. Miller <davem@davemloft.net>
Date:   Mon Jun 15 03:02:23 2009 -0700

    Merge branch 'master' of master.kernel.org:/pub/scm/linux/kernel/git/torvalds/linux-2.6
    
    Conflicts:
            Documentation/feature-removal-schedule.txt
            drivers/scsi/fcoe/fcoe.c
            net/core/drop_monitor.c
            net/core/net-traces.c

commit 52ea3a56a3268bc2a5a7c75e98c81463004e38ef
Author: Minoru Usui <usui@mxm.nes.nec.co.jp>
Date:   Tue Jun 9 04:03:09 2009 -0700

    cls_cgroup: Fix oops when user send improperly 'tc filter add' request
    
    I found a bug in cls_cgroup_change() in cls_cgroup.c.
    cls_cgroup_change() expected tca[TCA_OPTIONS] was set from user space properly,
    but tc in iproute2-2.6.29-1 (which I used) didn't set it.
    
    In the current source code of tc in git, it set tca[TCA_OPTIONS].
    
      git://git.kernel.org/pub/scm/linux/kernel/git/shemminger/iproute2.git
    
    If we always use a newest iproute2 in git when we use cls_cgroup,
    we don't face this oops probably.
    But I think, kernel shouldn't panic regardless of use program's behaviour.
    
    Signed-off-by: Minoru Usui <usui@mxm.nes.nec.co.jp>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index cc29b44b1500..e5becb92b3e7 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -167,6 +167,9 @@ static int cls_cgroup_change(struct tcf_proto *tp, unsigned long base,
 	struct tcf_exts e;
 	int err;
 
+	if (!tca[TCA_OPTIONS])
+		return -EINVAL;
+
 	if (head == NULL) {
 		if (!handle)
 			return -EINVAL;

commit b2f8f7525c8aa1fdd8ad8c72c832dfb571d5f768
Merge: d455e5b165a3 12186be7d2e1
Author: David S. Miller <davem@davemloft.net>
Date:   Wed Jun 3 02:43:41 2009 -0700

    Merge branch 'master' of master.kernel.org:/pub/scm/linux/kernel/git/davem/net-2.6
    
    Conflicts:
            drivers/net/forcedeth.c

commit e65fcfd63a9a62baa5708484ff8edbe56eb3e7ec
Author: Paul Menage <menage@google.com>
Date:   Tue May 26 20:47:02 2009 -0700

    cls_cgroup: read classid atomically in classifier
    
    Avoid reading the unsynchronized value cs->classid multiple times,
    since it could change concurrently from non-zero to zero; this would
    result in the classifier returning a positive result with a bogus
    (zero) classid.
    
    Signed-off-by: Paul Menage <menage@google.com>
    Reviewed-by: Li Zefan <lizf@cn.fujitsu.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index 91a3db4a76f8..cc29b44b1500 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -104,8 +104,7 @@ static int cls_cgroup_classify(struct sk_buff *skb, struct tcf_proto *tp,
 			       struct tcf_result *res)
 {
 	struct cls_cgroup_head *head = tp->root;
-	struct cgroup_cls_state *cs;
-	int ret = 0;
+	u32 classid;
 
 	/*
 	 * Due to the nature of the classifier it is required to ignore all
@@ -121,17 +120,18 @@ static int cls_cgroup_classify(struct sk_buff *skb, struct tcf_proto *tp,
 		return -1;
 
 	rcu_read_lock();
-	cs = task_cls_state(current);
-	if (cs->classid && tcf_em_tree_match(skb, &head->ematches, NULL)) {
-		res->classid = cs->classid;
-		res->class = 0;
-		ret = tcf_exts_exec(skb, &head->exts, res);
-	} else
-		ret = -1;
-
+	classid = task_cls_state(current)->classid;
 	rcu_read_unlock();
 
-	return ret;
+	if (!classid)
+		return -1;
+
+	if (!tcf_em_tree_match(skb, &head->ematches, NULL))
+		return -1;
+
+	res->classid = classid;
+	res->class = 0;
+	return tcf_exts_exec(skb, &head->exts, res);
 }
 
 static unsigned long cls_cgroup_get(struct tcf_proto *tp, u32 handle)

commit cb1c4b71f6da18fa98bab4af055f391d01bee8ba
Author: Li Zefan <lizf@cn.fujitsu.com>
Date:   Tue May 12 10:47:33 2009 +0000

    cls_cgroup: remove unneeded cgroup_lock
    
    We can remove this lock here, since we are in cgroup write handler and
    thus the cgrp is guaranteed to be valid, and no lock is needed when
    writing a u32 variable.
    
    Signed-off-by: Li Zefan <lizf@cn.fujitsuc.com>
    Acked-by: Paul Menage <menage@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index 91a3db4a76f8..1ab4542e61e0 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -62,13 +62,7 @@ static u64 read_classid(struct cgroup *cgrp, struct cftype *cft)
 
 static int write_classid(struct cgroup *cgrp, struct cftype *cft, u64 value)
 {
-	if (!cgroup_lock_live_group(cgrp))
-		return -ENODEV;
-
 	cgrp_cls_state(cgrp)->classid = (u32) value;
-
-	cgroup_unlock();
-
 	return 0;
 }
 

commit 8e8ba85417366afd2361e315c6ba5949d3eff56f
Author: Li Zefan <lizf@cn.fujitsu.com>
Date:   Mon Dec 29 19:39:03 2008 -0800

    cls_cgroup: clean up for cgroup part
    
    - It's better to use container_of() instead of casting cgroup_subsys_state *
      to cgroup_cls_state *.
    - Add helper function task_cls_state().
    - Rename net_cls_state() to cgrp_cls_state().
    
    Signed-off-by: Li Zefan <lizf@cn.fujitsu.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index 31d95b1946c6..91a3db4a76f8 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -24,10 +24,16 @@ struct cgroup_cls_state
 	u32 classid;
 };
 
-static inline struct cgroup_cls_state *net_cls_state(struct cgroup *cgrp)
+static inline struct cgroup_cls_state *cgrp_cls_state(struct cgroup *cgrp)
 {
-	return (struct cgroup_cls_state *)
-		cgroup_subsys_state(cgrp, net_cls_subsys_id);
+	return container_of(cgroup_subsys_state(cgrp, net_cls_subsys_id),
+			    struct cgroup_cls_state, css);
+}
+
+static inline struct cgroup_cls_state *task_cls_state(struct task_struct *p)
+{
+	return container_of(task_subsys_state(p, net_cls_subsys_id),
+			    struct cgroup_cls_state, css);
 }
 
 static struct cgroup_subsys_state *cgrp_create(struct cgroup_subsys *ss,
@@ -39,19 +45,19 @@ static struct cgroup_subsys_state *cgrp_create(struct cgroup_subsys *ss,
 		return ERR_PTR(-ENOMEM);
 
 	if (cgrp->parent)
-		cs->classid = net_cls_state(cgrp->parent)->classid;
+		cs->classid = cgrp_cls_state(cgrp->parent)->classid;
 
 	return &cs->css;
 }
 
 static void cgrp_destroy(struct cgroup_subsys *ss, struct cgroup *cgrp)
 {
-	kfree(net_cls_state(cgrp));
+	kfree(cgrp_cls_state(cgrp));
 }
 
 static u64 read_classid(struct cgroup *cgrp, struct cftype *cft)
 {
-	return net_cls_state(cgrp)->classid;
+	return cgrp_cls_state(cgrp)->classid;
 }
 
 static int write_classid(struct cgroup *cgrp, struct cftype *cft, u64 value)
@@ -59,7 +65,7 @@ static int write_classid(struct cgroup *cgrp, struct cftype *cft, u64 value)
 	if (!cgroup_lock_live_group(cgrp))
 		return -ENODEV;
 
-	net_cls_state(cgrp)->classid = (u32) value;
+	cgrp_cls_state(cgrp)->classid = (u32) value;
 
 	cgroup_unlock();
 
@@ -115,8 +121,7 @@ static int cls_cgroup_classify(struct sk_buff *skb, struct tcf_proto *tp,
 		return -1;
 
 	rcu_read_lock();
-	cs = (struct cgroup_cls_state *) task_subsys_state(current,
-							   net_cls_subsys_id);
+	cs = task_cls_state(current);
 	if (cs->classid && tcf_em_tree_match(skb, &head->ematches, NULL)) {
 		res->classid = cs->classid;
 		res->class = 0;

commit 2f068bf8711c35b98bf9a0172555b8390a762fc0
Author: Li Zefan <lizf@cn.fujitsu.com>
Date:   Sun Dec 28 17:57:19 2008 +0000

    cls_cgroup: fix an oops when removing a cgroup
    
    When removing a cgroup, an oops was triggered immediately. The cause
    is wrong kfree() in cgrp_destroy().
    
    Signed-off-by: Li Zefan <lizf@cn.fujitsu.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index 0d68b1975983..31d95b1946c6 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -46,7 +46,7 @@ static struct cgroup_subsys_state *cgrp_create(struct cgroup_subsys *ss,
 
 static void cgrp_destroy(struct cgroup_subsys *ss, struct cgroup *cgrp)
 {
-	kfree(ss);
+	kfree(net_cls_state(cgrp));
 }
 
 static u64 read_classid(struct cgroup *cgrp, struct cftype *cft)

commit 47a1a1d4be2910b13a8e90f75c17e253c39531ff
Author: Patrick McHardy <kaber@trash.net>
Date:   Wed Nov 19 08:03:09 2008 +0000

    pkt_sched: remove unnecessary xchg() in packet classifiers
    
    The use of xchg() hasn't been necessary since 2.2.something when proper
    locking was added to packet schedulers. In the case of classifiers they
    mostly weren't even necessary before that since they're mainly used
    to assign a NULL pointer to the filter root in the ->destroy path;
    the root is destroyed immediately after that.
    
    Signed-off-by: Patrick McHardy <kaber@trash.net>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
index 53ada2c0e41c..0d68b1975983 100644
--- a/net/sched/cls_cgroup.c
+++ b/net/sched/cls_cgroup.c
@@ -201,9 +201,7 @@ static int cls_cgroup_change(struct tcf_proto *tp, unsigned long base,
 
 static void cls_cgroup_destroy(struct tcf_proto *tp)
 {
-	struct cls_cgroup_head *head;
-
-	head = (struct cls_cgroup_head *)xchg(&tp->root, NULL);
+	struct cls_cgroup_head *head = tp->root;
 
 	if (head) {
 		tcf_exts_destroy(tp, &head->exts);

commit f400923735ecbb67cbe4a3606c9479f694754f51
Author: Thomas Graf <tgraf@suug.ch>
Date:   Fri Nov 7 22:56:00 2008 -0800

    pkt_sched: Control group classifier
    
    The classifier should cover the most common use case and will work
    without any special configuration.
    
    The principle of the classifier is to directly access the
    task_struct via get_current(). In order for this to work,
    classification requests from softirqs must be ignored. This is
    not a problem because the vast majority of packets in softirq
    context are not assigned to a task anyway. For this to work, a
    mechanism is needed to trace softirq context.
    
    This repost goes back to the method of relying on the number of
    nested bh disable calls for the sake of not adding too much
    complexity and the option to come up with something more reliable
    if actually needed.
    
    Signed-off-by: Thomas Graf <tgraf@suug.ch>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sched/cls_cgroup.c b/net/sched/cls_cgroup.c
new file mode 100644
index 000000000000..53ada2c0e41c
--- /dev/null
+++ b/net/sched/cls_cgroup.c
@@ -0,0 +1,290 @@
+/*
+ * net/sched/cls_cgroup.c	Control Group Classifier
+ *
+ *		This program is free software; you can redistribute it and/or
+ *		modify it under the terms of the GNU General Public License
+ *		as published by the Free Software Foundation; either version
+ *		2 of the License, or (at your option) any later version.
+ *
+ * Authors:	Thomas Graf <tgraf@suug.ch>
+ */
+
+#include <linux/module.h>
+#include <linux/types.h>
+#include <linux/string.h>
+#include <linux/errno.h>
+#include <linux/skbuff.h>
+#include <linux/cgroup.h>
+#include <net/rtnetlink.h>
+#include <net/pkt_cls.h>
+
+struct cgroup_cls_state
+{
+	struct cgroup_subsys_state css;
+	u32 classid;
+};
+
+static inline struct cgroup_cls_state *net_cls_state(struct cgroup *cgrp)
+{
+	return (struct cgroup_cls_state *)
+		cgroup_subsys_state(cgrp, net_cls_subsys_id);
+}
+
+static struct cgroup_subsys_state *cgrp_create(struct cgroup_subsys *ss,
+						 struct cgroup *cgrp)
+{
+	struct cgroup_cls_state *cs;
+
+	if (!(cs = kzalloc(sizeof(*cs), GFP_KERNEL)))
+		return ERR_PTR(-ENOMEM);
+
+	if (cgrp->parent)
+		cs->classid = net_cls_state(cgrp->parent)->classid;
+
+	return &cs->css;
+}
+
+static void cgrp_destroy(struct cgroup_subsys *ss, struct cgroup *cgrp)
+{
+	kfree(ss);
+}
+
+static u64 read_classid(struct cgroup *cgrp, struct cftype *cft)
+{
+	return net_cls_state(cgrp)->classid;
+}
+
+static int write_classid(struct cgroup *cgrp, struct cftype *cft, u64 value)
+{
+	if (!cgroup_lock_live_group(cgrp))
+		return -ENODEV;
+
+	net_cls_state(cgrp)->classid = (u32) value;
+
+	cgroup_unlock();
+
+	return 0;
+}
+
+static struct cftype ss_files[] = {
+	{
+		.name = "classid",
+		.read_u64 = read_classid,
+		.write_u64 = write_classid,
+	},
+};
+
+static int cgrp_populate(struct cgroup_subsys *ss, struct cgroup *cgrp)
+{
+	return cgroup_add_files(cgrp, ss, ss_files, ARRAY_SIZE(ss_files));
+}
+
+struct cgroup_subsys net_cls_subsys = {
+	.name		= "net_cls",
+	.create		= cgrp_create,
+	.destroy	= cgrp_destroy,
+	.populate	= cgrp_populate,
+	.subsys_id	= net_cls_subsys_id,
+};
+
+struct cls_cgroup_head
+{
+	u32			handle;
+	struct tcf_exts		exts;
+	struct tcf_ematch_tree	ematches;
+};
+
+static int cls_cgroup_classify(struct sk_buff *skb, struct tcf_proto *tp,
+			       struct tcf_result *res)
+{
+	struct cls_cgroup_head *head = tp->root;
+	struct cgroup_cls_state *cs;
+	int ret = 0;
+
+	/*
+	 * Due to the nature of the classifier it is required to ignore all
+	 * packets originating from softirq context as accessing `current'
+	 * would lead to false results.
+	 *
+	 * This test assumes that all callers of dev_queue_xmit() explicitely
+	 * disable bh. Knowing this, it is possible to detect softirq based
+	 * calls by looking at the number of nested bh disable calls because
+	 * softirqs always disables bh.
+	 */
+	if (softirq_count() != SOFTIRQ_OFFSET)
+		return -1;
+
+	rcu_read_lock();
+	cs = (struct cgroup_cls_state *) task_subsys_state(current,
+							   net_cls_subsys_id);
+	if (cs->classid && tcf_em_tree_match(skb, &head->ematches, NULL)) {
+		res->classid = cs->classid;
+		res->class = 0;
+		ret = tcf_exts_exec(skb, &head->exts, res);
+	} else
+		ret = -1;
+
+	rcu_read_unlock();
+
+	return ret;
+}
+
+static unsigned long cls_cgroup_get(struct tcf_proto *tp, u32 handle)
+{
+	return 0UL;
+}
+
+static void cls_cgroup_put(struct tcf_proto *tp, unsigned long f)
+{
+}
+
+static int cls_cgroup_init(struct tcf_proto *tp)
+{
+	return 0;
+}
+
+static const struct tcf_ext_map cgroup_ext_map = {
+	.action = TCA_CGROUP_ACT,
+	.police = TCA_CGROUP_POLICE,
+};
+
+static const struct nla_policy cgroup_policy[TCA_CGROUP_MAX + 1] = {
+	[TCA_CGROUP_EMATCHES]	= { .type = NLA_NESTED },
+};
+
+static int cls_cgroup_change(struct tcf_proto *tp, unsigned long base,
+			     u32 handle, struct nlattr **tca,
+			     unsigned long *arg)
+{
+	struct nlattr *tb[TCA_CGROUP_MAX+1];
+	struct cls_cgroup_head *head = tp->root;
+	struct tcf_ematch_tree t;
+	struct tcf_exts e;
+	int err;
+
+	if (head == NULL) {
+		if (!handle)
+			return -EINVAL;
+
+		head = kzalloc(sizeof(*head), GFP_KERNEL);
+		if (head == NULL)
+			return -ENOBUFS;
+
+		head->handle = handle;
+
+		tcf_tree_lock(tp);
+		tp->root = head;
+		tcf_tree_unlock(tp);
+	}
+
+	if (handle != head->handle)
+		return -ENOENT;
+
+	err = nla_parse_nested(tb, TCA_CGROUP_MAX, tca[TCA_OPTIONS],
+			       cgroup_policy);
+	if (err < 0)
+		return err;
+
+	err = tcf_exts_validate(tp, tb, tca[TCA_RATE], &e, &cgroup_ext_map);
+	if (err < 0)
+		return err;
+
+	err = tcf_em_tree_validate(tp, tb[TCA_CGROUP_EMATCHES], &t);
+	if (err < 0)
+		return err;
+
+	tcf_exts_change(tp, &head->exts, &e);
+	tcf_em_tree_change(tp, &head->ematches, &t);
+
+	return 0;
+}
+
+static void cls_cgroup_destroy(struct tcf_proto *tp)
+{
+	struct cls_cgroup_head *head;
+
+	head = (struct cls_cgroup_head *)xchg(&tp->root, NULL);
+
+	if (head) {
+		tcf_exts_destroy(tp, &head->exts);
+		tcf_em_tree_destroy(tp, &head->ematches);
+		kfree(head);
+	}
+}
+
+static int cls_cgroup_delete(struct tcf_proto *tp, unsigned long arg)
+{
+	return -EOPNOTSUPP;
+}
+
+static void cls_cgroup_walk(struct tcf_proto *tp, struct tcf_walker *arg)
+{
+	struct cls_cgroup_head *head = tp->root;
+
+	if (arg->count < arg->skip)
+		goto skip;
+
+	if (arg->fn(tp, (unsigned long) head, arg) < 0) {
+		arg->stop = 1;
+		return;
+	}
+skip:
+	arg->count++;
+}
+
+static int cls_cgroup_dump(struct tcf_proto *tp, unsigned long fh,
+			   struct sk_buff *skb, struct tcmsg *t)
+{
+	struct cls_cgroup_head *head = tp->root;
+	unsigned char *b = skb_tail_pointer(skb);
+	struct nlattr *nest;
+
+	t->tcm_handle = head->handle;
+
+	nest = nla_nest_start(skb, TCA_OPTIONS);
+	if (nest == NULL)
+		goto nla_put_failure;
+
+	if (tcf_exts_dump(skb, &head->exts, &cgroup_ext_map) < 0 ||
+	    tcf_em_tree_dump(skb, &head->ematches, TCA_CGROUP_EMATCHES) < 0)
+		goto nla_put_failure;
+
+	nla_nest_end(skb, nest);
+
+	if (tcf_exts_dump_stats(skb, &head->exts, &cgroup_ext_map) < 0)
+		goto nla_put_failure;
+
+	return skb->len;
+
+nla_put_failure:
+	nlmsg_trim(skb, b);
+	return -1;
+}
+
+static struct tcf_proto_ops cls_cgroup_ops __read_mostly = {
+	.kind		=	"cgroup",
+	.init		=	cls_cgroup_init,
+	.change		=	cls_cgroup_change,
+	.classify	=	cls_cgroup_classify,
+	.destroy	=	cls_cgroup_destroy,
+	.get		=	cls_cgroup_get,
+	.put		=	cls_cgroup_put,
+	.delete		=	cls_cgroup_delete,
+	.walk		=	cls_cgroup_walk,
+	.dump		=	cls_cgroup_dump,
+	.owner		=	THIS_MODULE,
+};
+
+static int __init init_cgroup_cls(void)
+{
+	return register_tcf_proto_ops(&cls_cgroup_ops);
+}
+
+static void __exit exit_cgroup_cls(void)
+{
+	unregister_tcf_proto_ops(&cls_cgroup_ops);
+}
+
+module_init(init_cgroup_cls);
+module_exit(exit_cgroup_cls);
+MODULE_LICENSE("GPL");
