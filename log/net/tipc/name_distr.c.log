commit f73b12812a3d1d798b7517547ccdcf864844d2cd
Author: Hoang Le <hoang.h.le@dektech.com.au>
Date:   Tue Oct 29 07:51:21 2019 +0700

    tipc: improve throughput between nodes in netns
    
    Currently, TIPC transports intra-node user data messages directly
    socket to socket, hence shortcutting all the lower layers of the
    communication stack. This gives TIPC very good intra node performance,
    both regarding throughput and latency.
    
    We now introduce a similar mechanism for TIPC data traffic across
    network namespaces located in the same kernel. On the send path, the
    call chain is as always accompanied by the sending node's network name
    space pointer. However, once we have reliably established that the
    receiving node is represented by a namespace on the same host, we just
    replace the namespace pointer with the receiving node/namespace's
    ditto, and follow the regular socket receive patch though the receiving
    node. This technique gives us a throughput similar to the node internal
    throughput, several times larger than if we let the traffic go though
    the full network stacks. As a comparison, max throughput for 64k
    messages is four times larger than TCP throughput for the same type of
    traffic.
    
    To meet any security concerns, the following should be noted.
    
    - All nodes joining a cluster are supposed to have been be certified
    and authenticated by mechanisms outside TIPC. This is no different for
    nodes/namespaces on the same host; they have to auto discover each
    other using the attached interfaces, and establish links which are
    supervised via the regular link monitoring mechanism. Hence, a kernel
    local node has no other way to join a cluster than any other node, and
    have to obey to policies set in the IP or device layers of the stack.
    
    - Only when a sender has established with 100% certainty that the peer
    node is located in a kernel local namespace does it choose to let user
    data messages, and only those, take the crossover path to the receiving
    node/namespace.
    
    - If the receiving node/namespace is removed, its namespace pointer
    is invalidated at all peer nodes, and their neighbor link monitoring
    will eventually note that this node is gone.
    
    - To ensure the "100% certainty" criteria, and prevent any possible
    spoofing, received discovery messages must contain a proof that the
    sender knows a common secret. We use the hash mix of the sending
    node/namespace for this purpose, since it can be accessed directly by
    all other namespaces in the kernel. Upon reception of a discovery
    message, the receiver checks this proof against all the local
    namespaces'hash_mix:es. If it finds a match, that, along with a
    matching node id and cluster id, this is deemed sufficient proof that
    the peer node in question is in a local namespace, and a wormhole can
    be opened.
    
    - We should also consider that TIPC is intended to be a cluster local
    IPC mechanism (just like e.g. UNIX sockets) rather than a network
    protocol, and hence we think it can justified to allow it to shortcut the
    lower protocol layers.
    
    Regarding traceability, we should notice that since commit 6c9081a3915d
    ("tipc: add loopback device tracking") it is possible to follow the node
    internal packet flow by just activating tcpdump on the loopback
    interface. This will be true even for this mechanism; by activating
    tcpdump on the involved nodes' loopback interfaces their inter-name
    space messaging can easily be tracked.
    
    v2:
    - update 'net' pointer when node left/rejoined
    v3:
    - grab read/write lock when using node ref obj
    v4:
    - clone traffics between netns to loopback
    
    Suggested-by: Jon Maloy <jon.maloy@ericsson.com>
    Acked-by: Jon Maloy <jon.maloy@ericsson.com>
    Signed-off-by: Hoang Le <hoang.h.le@dektech.com.au>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index 836e629e8f4a..5feaf3b67380 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -146,7 +146,7 @@ static void named_distribute(struct net *net, struct sk_buff_head *list,
 	struct publication *publ;
 	struct sk_buff *skb = NULL;
 	struct distr_item *item = NULL;
-	u32 msg_dsz = ((tipc_node_get_mtu(net, dnode, 0) - INT_H_SIZE) /
+	u32 msg_dsz = ((tipc_node_get_mtu(net, dnode, 0, false) - INT_H_SIZE) /
 			ITEM_SIZE) * ITEM_SIZE;
 	u32 msg_rem = msg_dsz;
 

commit aa2eaa8c272a3211dec07ce9c6c863a7e355c10e
Merge: a3d3c74da49c 1609d7604b84
Author: David S. Miller <davem@davemloft.net>
Date:   Sun Sep 15 14:17:27 2019 +0200

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net
    
    Minor overlapping changes in the btusb and ixgbe drivers.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 42dec1dbe38239cf91cc1f4df7830c66276ced37
Author: Xin Long <lucien.xin@gmail.com>
Date:   Tue Sep 3 17:53:12 2019 +0800

    tipc: add NULL pointer check before calling kfree_rcu
    
    Unlike kfree(p), kfree_rcu(p, rcu) won't do NULL pointer check. When
    tipc_nametbl_remove_publ returns NULL, the panic below happens:
    
       BUG: unable to handle kernel NULL pointer dereference at 0000000000000068
       RIP: 0010:__call_rcu+0x1d/0x290
       Call Trace:
        <IRQ>
        tipc_publ_notify+0xa9/0x170 [tipc]
        tipc_node_write_unlock+0x8d/0x100 [tipc]
        tipc_node_link_down+0xae/0x1d0 [tipc]
        tipc_node_check_dest+0x3ea/0x8f0 [tipc]
        ? tipc_disc_rcv+0x2c7/0x430 [tipc]
        tipc_disc_rcv+0x2c7/0x430 [tipc]
        ? tipc_rcv+0x6bb/0xf20 [tipc]
        tipc_rcv+0x6bb/0xf20 [tipc]
        ? ip_route_input_slow+0x9cf/0xb10
        tipc_udp_recv+0x195/0x1e0 [tipc]
        ? tipc_udp_is_known_peer+0x80/0x80 [tipc]
        udp_queue_rcv_skb+0x180/0x460
        udp_unicast_rcv_skb.isra.56+0x75/0x90
        __udp4_lib_rcv+0x4ce/0xb90
        ip_local_deliver_finish+0x11c/0x210
        ip_local_deliver+0x6b/0xe0
        ? ip_rcv_finish+0xa9/0x410
        ip_rcv+0x273/0x362
    
    Fixes: 97ede29e80ee ("tipc: convert name table read-write lock to RCU")
    Reported-by: Li Shuang <shuali@redhat.com>
    Signed-off-by: Xin Long <lucien.xin@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index 44abc8e9c990..241ed2274473 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -223,7 +223,8 @@ static void tipc_publ_purge(struct net *net, struct publication *publ, u32 addr)
 		       publ->key);
 	}
 
-	kfree_rcu(p, rcu);
+	if (p)
+		kfree_rcu(p, rcu);
 }
 
 /**

commit e654f9f53b45fde3fcc8051830b212c7a8f36148
Author: Jon Maloy <jon.maloy@ericsson.com>
Date:   Thu Aug 15 16:42:50 2019 +0200

    tipc: clean up skb list lock handling on send path
    
    The policy for handling the skb list locks on the send and receive paths
    is simple.
    
    - On the send path we never need to grab the lock on the 'xmitq' list
      when the destination is an exernal node.
    
    - On the receive path we always need to grab the lock on the 'inputq'
      list, irrespective of source node.
    
    However, when transmitting node local messages those will eventually
    end up on the receive path of a local socket, meaning that the argument
    'xmitq' in tipc_node_xmit() will become the 'Ã­nputq' argument in  the
    function tipc_sk_rcv(). This has been handled by always initializing
    the spinlock of the 'xmitq' list at message creation, just in case it
    may end up on the receive path later, and despite knowing that the lock
    in most cases never will be used.
    
    This approach is inaccurate and confusing, and has also concealed the
    fact that the stated 'no lock grabbing' policy for the send path is
    violated in some cases.
    
    We now clean up this by never initializing the lock at message creation,
    instead doing this at the moment we find that the message actually will
    enter the receive path. At the same time we fix the four locations
    where we incorrectly access the spinlock on the send/error path.
    
    This patch also reverts commit d12cffe9329f ("tipc: ensure head->lock
    is initialised") which has now become redundant.
    
    CC: Eric Dumazet <edumazet@google.com>
    Reported-by: Chris Packham <chris.packham@alliedtelesis.co.nz>
    Acked-by: Ying Xue <ying.xue@windriver.com>
    Signed-off-by: Jon Maloy <jon.maloy@ericsson.com>
    Reviewed-by: Xin Long <lucien.xin@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index 44abc8e9c990..61219f0b9677 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -190,7 +190,7 @@ void tipc_named_node_up(struct net *net, u32 dnode)
 	struct name_table *nt = tipc_name_table(net);
 	struct sk_buff_head head;
 
-	skb_queue_head_init(&head);
+	__skb_queue_head_init(&head);
 
 	read_lock_bh(&nt->cluster_scope_lock);
 	named_distribute(net, &head, dnode, &nt->cluster_scope);

commit d12cffe9329fd278555d0f9bb89af1259a2fd933
Author: Chris Packham <chris.packham@alliedtelesis.co.nz>
Date:   Fri Jul 12 10:41:15 2019 +1200

    tipc: ensure head->lock is initialised
    
    tipc_named_node_up() creates a skb list. It passes the list to
    tipc_node_xmit() which has some code paths that can call
    skb_queue_purge() which relies on the list->lock being initialised.
    
    The spin_lock is only needed if the messages end up on the receive path
    but when the list is created in tipc_named_node_up() we don't
    necessarily know if it is going to end up there.
    
    Once all the skb list users are updated in tipc it will then be possible
    to update them to use the unlocked variants of the skb list functions
    and initialise the lock when we know the message will follow the receive
    path.
    
    Signed-off-by: Chris Packham <chris.packham@alliedtelesis.co.nz>
    Acked-by: Jon Maloy <jon.maloy@ericsson.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index 61219f0b9677..44abc8e9c990 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -190,7 +190,7 @@ void tipc_named_node_up(struct net *net, u32 dnode)
 	struct name_table *nt = tipc_name_table(net);
 	struct sk_buff_head head;
 
-	__skb_queue_head_init(&head);
+	skb_queue_head_init(&head);
 
 	read_lock_bh(&nt->cluster_scope_lock);
 	named_distribute(net, &head, dnode, &nt->cluster_scope);

commit 988f3f1603d4650409db5334355cbf7b13ef50c3
Author: Jon Maloy <jon.maloy@ericsson.com>
Date:   Fri Oct 19 19:55:40 2018 +0200

    tipc: eliminate message disordering during binding table update
    
    We have seen the following race scenario:
    1) named_distribute() builds a "bulk" message, containing a PUBLISH
       item for a certain publication. This is based on the contents of
       the binding tables's 'cluster_scope' list.
    2) tipc_named_withdraw() removes the same publication from the list,
       bulds a WITHDRAW message and distributes it to all cluster nodes.
    3) tipc_named_node_up(), which was calling named_distribute(), sends
       out the bulk message built under 1)
    4) The WITHDRAW message arrives at the just detected node, finds
       no corresponding publication, and is dropped.
    5) The PUBLISH item arrives at the same node, is added to its binding
       table, and remains there forever.
    
    This arrival disordering was earlier taken care of by the backlog queue,
    originally added for a different purpose, which was removed in the
    commit referred to below, but we now need a different solution.
    In this commit, we replace the rcu lock protecting the 'cluster_scope'
    list with a regular RW lock which comprises even the sending of the
    bulk message. This both guarantees both the list integrity and the
    message sending order. We will later add a commit which cleans up
    this code further.
    
    Note that this commit needs recently added commit d3092b2efca1 ("tipc:
    fix unsafe rcu locking when accessing publication list") to apply
    cleanly.
    
    Fixes: 37922ea4a310 ("tipc: permit overlapping service ranges in name table")
    Reported-by: Tuong Lien Tong <tuong.t.lien@dektech.com.au>
    Acked-by: Ying Xue <ying.xue@windriver.com>
    Signed-off-by: Jon Maloy <jon.maloy@ericsson.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index 3cfeb9df64b0..61219f0b9677 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -94,8 +94,9 @@ struct sk_buff *tipc_named_publish(struct net *net, struct publication *publ)
 		list_add_tail_rcu(&publ->binding_node, &nt->node_scope);
 		return NULL;
 	}
-	list_add_tail_rcu(&publ->binding_node, &nt->cluster_scope);
-
+	write_lock_bh(&nt->cluster_scope_lock);
+	list_add_tail(&publ->binding_node, &nt->cluster_scope);
+	write_unlock_bh(&nt->cluster_scope_lock);
 	skb = named_prepare_buf(net, PUBLICATION, ITEM_SIZE, 0);
 	if (!skb) {
 		pr_warn("Publication distribution failure\n");
@@ -112,11 +113,13 @@ struct sk_buff *tipc_named_publish(struct net *net, struct publication *publ)
  */
 struct sk_buff *tipc_named_withdraw(struct net *net, struct publication *publ)
 {
+	struct name_table *nt = tipc_name_table(net);
 	struct sk_buff *buf;
 	struct distr_item *item;
 
-	list_del_rcu(&publ->binding_node);
-
+	write_lock_bh(&nt->cluster_scope_lock);
+	list_del(&publ->binding_node);
+	write_unlock_bh(&nt->cluster_scope_lock);
 	if (publ->scope == TIPC_NODE_SCOPE)
 		return NULL;
 
@@ -147,7 +150,7 @@ static void named_distribute(struct net *net, struct sk_buff_head *list,
 			ITEM_SIZE) * ITEM_SIZE;
 	u32 msg_rem = msg_dsz;
 
-	list_for_each_entry_rcu(publ, pls, binding_node) {
+	list_for_each_entry(publ, pls, binding_node) {
 		/* Prepare next buffer: */
 		if (!skb) {
 			skb = named_prepare_buf(net, PUBLICATION, msg_rem,
@@ -189,11 +192,10 @@ void tipc_named_node_up(struct net *net, u32 dnode)
 
 	__skb_queue_head_init(&head);
 
-	rcu_read_lock();
+	read_lock_bh(&nt->cluster_scope_lock);
 	named_distribute(net, &head, dnode, &nt->cluster_scope);
-	rcu_read_unlock();
-
 	tipc_node_xmit(net, &head, dnode, 0);
+	read_unlock_bh(&nt->cluster_scope_lock);
 }
 
 /**

commit d3092b2efca1cd1d492d0b08499a2066c5ca8cec
Author: Tung Nguyen <tung.q.nguyen@dektech.com.au>
Date:   Fri Oct 12 22:46:55 2018 +0200

    tipc: fix unsafe rcu locking when accessing publication list
    
    The binding table's 'cluster_scope' list is rcu protected to handle
    races between threads changing the list and those traversing the list at
    the same moment. We have now found that the function named_distribute()
    uses the regular list_for_each() macro to traverse the said list.
    Likewise, the function tipc_named_withdraw() is removing items from the
    same list using the regular list_del() call. When these two functions
    execute in parallel we see occasional crashes.
    
    This commit fixes this by adding the missing _rcu() suffixes.
    
    Signed-off-by: Tung Nguyen <tung.q.nguyen@dektech.com.au>
    Signed-off-by: Jon Maloy <jon.maloy@ericsson.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index 51b4b96f89db..3cfeb9df64b0 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -115,7 +115,7 @@ struct sk_buff *tipc_named_withdraw(struct net *net, struct publication *publ)
 	struct sk_buff *buf;
 	struct distr_item *item;
 
-	list_del(&publ->binding_node);
+	list_del_rcu(&publ->binding_node);
 
 	if (publ->scope == TIPC_NODE_SCOPE)
 		return NULL;
@@ -147,7 +147,7 @@ static void named_distribute(struct net *net, struct sk_buff_head *list,
 			ITEM_SIZE) * ITEM_SIZE;
 	u32 msg_rem = msg_dsz;
 
-	list_for_each_entry(publ, pls, binding_node) {
+	list_for_each_entry_rcu(publ, pls, binding_node) {
 		/* Prepare next buffer: */
 		if (!skb) {
 			skb = named_prepare_buf(net, PUBLICATION, msg_rem,

commit 37922ea4a3105176357c8d565a9d982c4a08714a
Author: Jon Maloy <jon.maloy@ericsson.com>
Date:   Thu Mar 29 23:20:43 2018 +0200

    tipc: permit overlapping service ranges in name table
    
    With the new RB tree structure for service ranges it becomes possible to
    solve an old problem; - we can now allow overlapping service ranges in
    the table.
    
    When inserting a new service range to the tree, we use 'lower' as primary
    key, and when necessary 'upper' as secondary key.
    
    Since there may now be multiple service ranges matching an indicated
    'lower' value, we must also add the 'upper' value to the functions
    used for removing publications, so that the correct, corresponding
    range item can be found.
    
    These changes guarantee that a well-formed publication/withdrawal item
    from a peer node never will be rejected, and make it possible to
    eliminate the problematic backlog functionality we currently have for
    handling such cases.
    
    Signed-off-by: Jon Maloy <jon.maloy@ericsson.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index 8240a85b0d0c..51b4b96f89db 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -204,12 +204,12 @@ void tipc_named_node_up(struct net *net, u32 dnode)
  */
 static void tipc_publ_purge(struct net *net, struct publication *publ, u32 addr)
 {
-	struct tipc_net *tn = net_generic(net, tipc_net_id);
+	struct tipc_net *tn = tipc_net(net);
 	struct publication *p;
 
 	spin_lock_bh(&tn->nametbl_lock);
-	p = tipc_nametbl_remove_publ(net, publ->type, publ->lower,
-				     publ->node, publ->port, publ->key);
+	p = tipc_nametbl_remove_publ(net, publ->type, publ->lower, publ->upper,
+				     publ->node, publ->key);
 	if (p)
 		tipc_node_unsubscribe(net, &p->binding_node, addr);
 	spin_unlock_bh(&tn->nametbl_lock);
@@ -261,81 +261,37 @@ void tipc_publ_notify(struct net *net, struct list_head *nsub_list, u32 addr)
 static bool tipc_update_nametbl(struct net *net, struct distr_item *i,
 				u32 node, u32 dtype)
 {
-	struct publication *publ = NULL;
+	struct publication *p = NULL;
+	u32 lower = ntohl(i->lower);
+	u32 upper = ntohl(i->upper);
+	u32 type = ntohl(i->type);
+	u32 port = ntohl(i->port);
+	u32 key = ntohl(i->key);
 
 	if (dtype == PUBLICATION) {
-		publ = tipc_nametbl_insert_publ(net, ntohl(i->type),
-						ntohl(i->lower),
-						ntohl(i->upper),
-						TIPC_CLUSTER_SCOPE, node,
-						ntohl(i->port), ntohl(i->key));
-		if (publ) {
-			tipc_node_subscribe(net, &publ->binding_node, node);
+		p = tipc_nametbl_insert_publ(net, type, lower, upper,
+					     TIPC_CLUSTER_SCOPE, node,
+					     port, key);
+		if (p) {
+			tipc_node_subscribe(net, &p->binding_node, node);
 			return true;
 		}
 	} else if (dtype == WITHDRAWAL) {
-		publ = tipc_nametbl_remove_publ(net, ntohl(i->type),
-						ntohl(i->lower),
-						node, ntohl(i->port),
-						ntohl(i->key));
-		if (publ) {
-			tipc_node_unsubscribe(net, &publ->binding_node, node);
-			kfree_rcu(publ, rcu);
+		p = tipc_nametbl_remove_publ(net, type, lower,
+					     upper, node, key);
+		if (p) {
+			tipc_node_unsubscribe(net, &p->binding_node, node);
+			kfree_rcu(p, rcu);
 			return true;
 		}
+		pr_warn_ratelimited("Failed to remove binding %u,%u from %x\n",
+				    type, lower, node);
 	} else {
 		pr_warn("Unrecognized name table message received\n");
 	}
 	return false;
 }
 
-/**
- * tipc_named_add_backlog - add a failed name table update to the backlog
- *
- */
-static void tipc_named_add_backlog(struct net *net, struct distr_item *i,
-				   u32 type, u32 node)
-{
-	struct distr_queue_item *e;
-	struct tipc_net *tn = net_generic(net, tipc_net_id);
-	unsigned long now = get_jiffies_64();
-
-	e = kzalloc(sizeof(*e), GFP_ATOMIC);
-	if (!e)
-		return;
-	e->dtype = type;
-	e->node = node;
-	e->expires = now + msecs_to_jiffies(sysctl_tipc_named_timeout);
-	memcpy(e, i, sizeof(*i));
-	list_add_tail(&e->next, &tn->dist_queue);
-}
-
-/**
- * tipc_named_process_backlog - try to process any pending name table updates
- * from the network.
- */
-void tipc_named_process_backlog(struct net *net)
-{
-	struct distr_queue_item *e, *tmp;
-	struct tipc_net *tn = net_generic(net, tipc_net_id);
-	unsigned long now = get_jiffies_64();
-
-	list_for_each_entry_safe(e, tmp, &tn->dist_queue, next) {
-		if (time_after(e->expires, now)) {
-			if (!tipc_update_nametbl(net, &e->i, e->node, e->dtype))
-				continue;
-		} else {
-			pr_warn_ratelimited("Dropping name table update (%d) of {%u, %u, %u} from %x key=%u\n",
-					    e->dtype, ntohl(e->i.type),
-					    ntohl(e->i.lower),
-					    ntohl(e->i.upper),
-					    e->node, ntohl(e->i.key));
-		}
-		list_del(&e->next);
-		kfree(e);
-	}
-}
-
 /**
  * tipc_named_rcv - process name table update messages sent by another node
  */
@@ -358,12 +314,10 @@ void tipc_named_rcv(struct net *net, struct sk_buff_head *inputq)
 		count = msg_data_sz(msg) / ITEM_SIZE;
 		node = msg_orignode(msg);
 		while (count--) {
-			if (!tipc_update_nametbl(net, item, node, mtype))
-				tipc_named_add_backlog(net, item, mtype, node);
+			tipc_update_nametbl(net, item, node, mtype);
 			item++;
 		}
 		kfree_skb(skb);
-		tipc_named_process_backlog(net);
 	}
 	spin_unlock_bh(&tn->nametbl_lock);
 }

commit d50ccc2d3909fc1b4d40e4af16b026f05dc68707
Author: Jon Maloy <jon.maloy@ericsson.com>
Date:   Thu Mar 22 20:42:50 2018 +0100

    tipc: add 128-bit node identifier
    
    We add a 128-bit node identity, as an alternative to the currently used
    32-bit node address.
    
    For the sake of compatibility and to minimize message header changes
    we retain the existing 32-bit address field. When not set explicitly by
    the user, this field will be filled with a hash value generated from the
    much longer node identity, and be used as a shorthand value for the
    latter.
    
    We permit either the address or the identity to be set by configuration,
    but not both, so when the address value is set by a legacy user the
    corresponding 128-bit node identity is generated based on the that value.
    
    Acked-by: Ying Xue <ying.xue@windriver.com>
    Signed-off-by: Jon Maloy <jon.maloy@ericsson.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index 7e571f4f47bc..8240a85b0d0c 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -318,7 +318,6 @@ void tipc_named_process_backlog(struct net *net)
 {
 	struct distr_queue_item *e, *tmp;
 	struct tipc_net *tn = net_generic(net, tipc_net_id);
-	char addr[16];
 	unsigned long now = get_jiffies_64();
 
 	list_for_each_entry_safe(e, tmp, &tn->dist_queue, next) {
@@ -326,12 +325,11 @@ void tipc_named_process_backlog(struct net *net)
 			if (!tipc_update_nametbl(net, &e->i, e->node, e->dtype))
 				continue;
 		} else {
-			tipc_addr_string_fill(addr, e->node);
-			pr_warn_ratelimited("Dropping name table update (%d) of {%u, %u, %u} from %s key=%u\n",
+			pr_warn_ratelimited("Dropping name table update (%d) of {%u, %u, %u} from %x key=%u\n",
 					    e->dtype, ntohl(e->i.type),
 					    ntohl(e->i.lower),
 					    ntohl(e->i.upper),
-					    addr, ntohl(e->i.key));
+					    e->node, ntohl(e->i.key));
 		}
 		list_del(&e->next);
 		kfree(e);

commit 23fd3eace088ab1872ee59c19191a119ec779ac9
Author: Jon Maloy <jon.maloy@ericsson.com>
Date:   Thu Mar 22 20:42:49 2018 +0100

    tipc: remove direct accesses to own_addr field in struct tipc_net
    
    As a preparation to changing the addressing structure of TIPC we replace
    all direct accesses to the tipc_net::own_addr field with the function
    dedicated for this, tipc_own_addr().
    
    There are no changes to program logics in this commit.
    
    Acked-by: Ying Xue <ying.xue@windriver.com>
    Signed-off-by: Jon Maloy <jon.maloy@ericsson.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index 28d095a7d8bb..7e571f4f47bc 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -68,14 +68,14 @@ static void publ_to_item(struct distr_item *i, struct publication *p)
 static struct sk_buff *named_prepare_buf(struct net *net, u32 type, u32 size,
 					 u32 dest)
 {
-	struct tipc_net *tn = net_generic(net, tipc_net_id);
 	struct sk_buff *buf = tipc_buf_acquire(INT_H_SIZE + size, GFP_ATOMIC);
+	u32 self = tipc_own_addr(net);
 	struct tipc_msg *msg;
 
 	if (buf != NULL) {
 		msg = buf_msg(buf);
-		tipc_msg_init(tn->own_addr, msg, NAME_DISTRIBUTOR, type,
-			      INT_H_SIZE, dest);
+		tipc_msg_init(self, msg, NAME_DISTRIBUTOR,
+			      type, INT_H_SIZE, dest);
 		msg_set_size(msg, INT_H_SIZE + size);
 	}
 	return buf;
@@ -382,13 +382,14 @@ void tipc_named_reinit(struct net *net)
 	struct name_table *nt = tipc_name_table(net);
 	struct tipc_net *tn = tipc_net(net);
 	struct publication *publ;
+	u32 self = tipc_own_addr(net);
 
 	spin_lock_bh(&tn->nametbl_lock);
 
 	list_for_each_entry_rcu(publ, &nt->node_scope, binding_node)
-		publ->node = tn->own_addr;
+		publ->node = self;
 	list_for_each_entry_rcu(publ, &nt->cluster_scope, binding_node)
-		publ->node = tn->own_addr;
+		publ->node = self;
 
 	spin_unlock_bh(&tn->nametbl_lock);
 }

commit e50e73e10757ac86fcb1aaa986055049e060727a
Author: Jon Maloy <jon.maloy@ericsson.com>
Date:   Thu Mar 15 16:48:55 2018 +0100

    tipc: some name changes
    
    We rename some lists and fields in struct publication both to make
    the naming more consistent and to better reflect their roles. We
    also update the descriptions of those lists.
    
    node_list -> local_publ
    cluster_list -> all_publ
    pport_list -> binding_sock
    ref -> port
    
    There are no functional changes in this commit.
    
    Acked-by: Ying Xue <ying.xue@windriver.com>
    Signed-off-by: Jon Maloy <jon.maloy@ericsson.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index 4c54fb37875a..28d095a7d8bb 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -56,7 +56,7 @@ static void publ_to_item(struct distr_item *i, struct publication *p)
 	i->type = htonl(p->type);
 	i->lower = htonl(p->lower);
 	i->upper = htonl(p->upper);
-	i->ref = htonl(p->ref);
+	i->port = htonl(p->port);
 	i->key = htonl(p->key);
 }
 
@@ -209,15 +209,15 @@ static void tipc_publ_purge(struct net *net, struct publication *publ, u32 addr)
 
 	spin_lock_bh(&tn->nametbl_lock);
 	p = tipc_nametbl_remove_publ(net, publ->type, publ->lower,
-				     publ->node, publ->ref, publ->key);
+				     publ->node, publ->port, publ->key);
 	if (p)
 		tipc_node_unsubscribe(net, &p->binding_node, addr);
 	spin_unlock_bh(&tn->nametbl_lock);
 
 	if (p != publ) {
 		pr_err("Unable to remove publication from failed node\n"
-		       " (type=%u, lower=%u, node=0x%x, ref=%u, key=%u)\n",
-		       publ->type, publ->lower, publ->node, publ->ref,
+		       " (type=%u, lower=%u, node=0x%x, port=%u, key=%u)\n",
+		       publ->type, publ->lower, publ->node, publ->port,
 		       publ->key);
 	}
 
@@ -268,7 +268,7 @@ static bool tipc_update_nametbl(struct net *net, struct distr_item *i,
 						ntohl(i->lower),
 						ntohl(i->upper),
 						TIPC_CLUSTER_SCOPE, node,
-						ntohl(i->ref), ntohl(i->key));
+						ntohl(i->port), ntohl(i->key));
 		if (publ) {
 			tipc_node_subscribe(net, &publ->binding_node, node);
 			return true;
@@ -276,7 +276,7 @@ static bool tipc_update_nametbl(struct net *net, struct distr_item *i,
 	} else if (dtype == WITHDRAWAL) {
 		publ = tipc_nametbl_remove_publ(net, ntohl(i->type),
 						ntohl(i->lower),
-						node, ntohl(i->ref),
+						node, ntohl(i->port),
 						ntohl(i->key));
 		if (publ) {
 			tipc_node_unsubscribe(net, &publ->binding_node, node);

commit 935439cc48ef24f0e50396be3684a0f27e609363
Author: Jon Maloy <jon.maloy@ericsson.com>
Date:   Thu Mar 15 16:48:54 2018 +0100

    tipc: merge two lists in struct publication
    
    The size of struct publication can be reduced further. Membership in
    lists 'nodesub_list' and 'local_list' is mutually exlusive, in that
    remote publications use the former and local publications the latter.
    We replace the two lists with one single, named 'binding_node' which
    reflects what it really is.
    
    Acked-by: Ying Xue <ying.xue@windriver.com>
    Signed-off-by: Jon Maloy <jon.maloy@ericsson.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index 11ce20505550..4c54fb37875a 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -91,10 +91,10 @@ struct sk_buff *tipc_named_publish(struct net *net, struct publication *publ)
 	struct sk_buff *skb;
 
 	if (publ->scope == TIPC_NODE_SCOPE) {
-		list_add_tail_rcu(&publ->local_list, &nt->node_scope);
+		list_add_tail_rcu(&publ->binding_node, &nt->node_scope);
 		return NULL;
 	}
-	list_add_tail_rcu(&publ->local_list, &nt->cluster_scope);
+	list_add_tail_rcu(&publ->binding_node, &nt->cluster_scope);
 
 	skb = named_prepare_buf(net, PUBLICATION, ITEM_SIZE, 0);
 	if (!skb) {
@@ -115,7 +115,7 @@ struct sk_buff *tipc_named_withdraw(struct net *net, struct publication *publ)
 	struct sk_buff *buf;
 	struct distr_item *item;
 
-	list_del(&publ->local_list);
+	list_del(&publ->binding_node);
 
 	if (publ->scope == TIPC_NODE_SCOPE)
 		return NULL;
@@ -147,7 +147,7 @@ static void named_distribute(struct net *net, struct sk_buff_head *list,
 			ITEM_SIZE) * ITEM_SIZE;
 	u32 msg_rem = msg_dsz;
 
-	list_for_each_entry(publ, pls, local_list) {
+	list_for_each_entry(publ, pls, binding_node) {
 		/* Prepare next buffer: */
 		if (!skb) {
 			skb = named_prepare_buf(net, PUBLICATION, msg_rem,
@@ -211,7 +211,7 @@ static void tipc_publ_purge(struct net *net, struct publication *publ, u32 addr)
 	p = tipc_nametbl_remove_publ(net, publ->type, publ->lower,
 				     publ->node, publ->ref, publ->key);
 	if (p)
-		tipc_node_unsubscribe(net, &p->nodesub_list, addr);
+		tipc_node_unsubscribe(net, &p->binding_node, addr);
 	spin_unlock_bh(&tn->nametbl_lock);
 
 	if (p != publ) {
@@ -246,7 +246,7 @@ void tipc_publ_notify(struct net *net, struct list_head *nsub_list, u32 addr)
 {
 	struct publication *publ, *tmp;
 
-	list_for_each_entry_safe(publ, tmp, nsub_list, nodesub_list)
+	list_for_each_entry_safe(publ, tmp, nsub_list, binding_node)
 		tipc_publ_purge(net, publ, addr);
 	tipc_dist_queue_purge(net, addr);
 }
@@ -270,7 +270,7 @@ static bool tipc_update_nametbl(struct net *net, struct distr_item *i,
 						TIPC_CLUSTER_SCOPE, node,
 						ntohl(i->ref), ntohl(i->key));
 		if (publ) {
-			tipc_node_subscribe(net, &publ->nodesub_list, node);
+			tipc_node_subscribe(net, &publ->binding_node, node);
 			return true;
 		}
 	} else if (dtype == WITHDRAWAL) {
@@ -279,7 +279,7 @@ static bool tipc_update_nametbl(struct net *net, struct distr_item *i,
 						node, ntohl(i->ref),
 						ntohl(i->key));
 		if (publ) {
-			tipc_node_unsubscribe(net, &publ->nodesub_list, node);
+			tipc_node_unsubscribe(net, &publ->binding_node, node);
 			kfree_rcu(publ, rcu);
 			return true;
 		}
@@ -385,9 +385,9 @@ void tipc_named_reinit(struct net *net)
 
 	spin_lock_bh(&tn->nametbl_lock);
 
-	list_for_each_entry_rcu(publ, &nt->node_scope, local_list)
+	list_for_each_entry_rcu(publ, &nt->node_scope, binding_node)
 		publ->node = tn->own_addr;
-	list_for_each_entry_rcu(publ, &nt->cluster_scope, local_list)
+	list_for_each_entry_rcu(publ, &nt->cluster_scope, binding_node)
 		publ->node = tn->own_addr;
 
 	spin_unlock_bh(&tn->nametbl_lock);

commit 64a52b26d5633d6efc35cdf1e0c627cc4189e55a
Author: Jon Maloy <jon.maloy@ericsson.com>
Date:   Thu Mar 15 16:48:52 2018 +0100

    tipc: remove zone publication list in name table
    
    As a consequence of the previous commit we nan now eliminate zone scope
    related lists in the name table. We start with name_table::publ_list[3],
    which can now be replaced with two lists, one for node scope publications
    and one for cluster scope publications.
    
    Acked-by: Ying Xue <ying.xue@windriver.com>
    Signed-off-by: Jon Maloy <jon.maloy@ericsson.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index 23f8899e0f8c..11ce20505550 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -86,25 +86,25 @@ static struct sk_buff *named_prepare_buf(struct net *net, u32 type, u32 size,
  */
 struct sk_buff *tipc_named_publish(struct net *net, struct publication *publ)
 {
-	struct tipc_net *tn = net_generic(net, tipc_net_id);
-	struct sk_buff *buf;
+	struct name_table *nt = tipc_name_table(net);
 	struct distr_item *item;
+	struct sk_buff *skb;
 
-	list_add_tail_rcu(&publ->local_list,
-			  &tn->nametbl->publ_list[publ->scope]);
-
-	if (publ->scope == TIPC_NODE_SCOPE)
+	if (publ->scope == TIPC_NODE_SCOPE) {
+		list_add_tail_rcu(&publ->local_list, &nt->node_scope);
 		return NULL;
+	}
+	list_add_tail_rcu(&publ->local_list, &nt->cluster_scope);
 
-	buf = named_prepare_buf(net, PUBLICATION, ITEM_SIZE, 0);
-	if (!buf) {
+	skb = named_prepare_buf(net, PUBLICATION, ITEM_SIZE, 0);
+	if (!skb) {
 		pr_warn("Publication distribution failure\n");
 		return NULL;
 	}
 
-	item = (struct distr_item *)msg_data(buf_msg(buf));
+	item = (struct distr_item *)msg_data(buf_msg(skb));
 	publ_to_item(item, publ);
-	return buf;
+	return skb;
 }
 
 /**
@@ -184,16 +184,13 @@ static void named_distribute(struct net *net, struct sk_buff_head *list,
  */
 void tipc_named_node_up(struct net *net, u32 dnode)
 {
-	struct tipc_net *tn = net_generic(net, tipc_net_id);
+	struct name_table *nt = tipc_name_table(net);
 	struct sk_buff_head head;
 
 	__skb_queue_head_init(&head);
 
 	rcu_read_lock();
-	named_distribute(net, &head, dnode,
-			 &tn->nametbl->publ_list[TIPC_CLUSTER_SCOPE]);
-	named_distribute(net, &head, dnode,
-			 &tn->nametbl->publ_list[TIPC_ZONE_SCOPE]);
+	named_distribute(net, &head, dnode, &nt->cluster_scope);
 	rcu_read_unlock();
 
 	tipc_node_xmit(net, &head, dnode, 0);
@@ -382,16 +379,16 @@ void tipc_named_rcv(struct net *net, struct sk_buff_head *inputq)
  */
 void tipc_named_reinit(struct net *net)
 {
-	struct tipc_net *tn = net_generic(net, tipc_net_id);
+	struct name_table *nt = tipc_name_table(net);
+	struct tipc_net *tn = tipc_net(net);
 	struct publication *publ;
-	int scope;
 
 	spin_lock_bh(&tn->nametbl_lock);
 
-	for (scope = TIPC_ZONE_SCOPE; scope <= TIPC_NODE_SCOPE; scope++)
-		list_for_each_entry_rcu(publ, &tn->nametbl->publ_list[scope],
-					local_list)
-			publ->node = tn->own_addr;
+	list_for_each_entry_rcu(publ, &nt->node_scope, local_list)
+		publ->node = tn->own_addr;
+	list_for_each_entry_rcu(publ, &nt->cluster_scope, local_list)
+		publ->node = tn->own_addr;
 
 	spin_unlock_bh(&tn->nametbl_lock);
 }

commit 57d5f64d83ab5b5a5118b1597386dd76eaf4340d
Author: Parthasarathy Bhuvaragan <parthasarathy.bhuvaragan@ericsson.com>
Date:   Fri Jan 13 15:46:25 2017 +0100

    tipc: allocate user memory with GFP_KERNEL flag
    
    Until now, we allocate memory always with GFP_ATOMIC flag.
    When the system is under memory pressure and a user tries to send,
    the send fails due to low memory. However, the user application
    can wait for free memory if we allocate it using GFP_KERNEL flag.
    
    In this commit, we use allocate memory with GFP_KERNEL for all user
    allocation.
    
    Reported-by: Rune Torgersen <runet@innovsys.com>
    Acked-by: Jon Maloy <jon.maloy@ericsson.com>
    Signed-off-by: Parthasarathy Bhuvaragan <parthasarathy.bhuvaragan@ericsson.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index c1cfd92de17a..23f8899e0f8c 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -69,7 +69,7 @@ static struct sk_buff *named_prepare_buf(struct net *net, u32 type, u32 size,
 					 u32 dest)
 {
 	struct tipc_net *tn = net_generic(net, tipc_net_id);
-	struct sk_buff *buf = tipc_buf_acquire(INT_H_SIZE + size);
+	struct sk_buff *buf = tipc_buf_acquire(INT_H_SIZE + size, GFP_ATOMIC);
 	struct tipc_msg *msg;
 
 	if (buf != NULL) {

commit 06bd2b1ed04ca9fdbc767859885944a1e8b86b40
Author: Jon Paul Maloy <jon.maloy@ericsson.com>
Date:   Thu Oct 27 18:51:55 2016 -0400

    tipc: fix broadcast link synchronization problem
    
    In commit 2d18ac4ba745 ("tipc: extend broadcast link initialization
    criteria") we tried to fix a problem with the initial synchronization
    of broadcast link acknowledge values. Unfortunately that solution is
    not sufficient to solve the issue.
    
    We have seen it happen that LINK_PROTOCOL/STATE packets with a valid
    non-zero unicast acknowledge number may bypass BCAST_PROTOCOL
    initialization, NAME_DISTRIBUTOR and other STATE packets with invalid
    broadcast acknowledge numbers, leading to premature opening of the
    broadcast link. When the bypassed packets finally arrive, they are
    inadvertently accepted, and the already correctly initialized
    acknowledge number in the broadcast receive link is overwritten by
    the invalid (zero) value of the said packets. After this the broadcast
    link goes stale.
    
    We now fix this by marking the packets where we know the acknowledge
    value is or may be invalid, and then ignoring the acks from those.
    
    To this purpose, we claim an unused bit in the header to indicate that
    the value is invalid. We set the bit to 1 in the initial BCAST_PROTOCOL
    synchronization packet and all initial ("bulk") NAME_DISTRIBUTOR
    packets, plus those LINK_PROTOCOL packets sent out before the broadcast
    links are fully synchronized.
    
    This minor protocol update is fully backwards compatible.
    
    Reported-by: John Thompson <thompa.atl@gmail.com>
    Tested-by: John Thompson <thompa.atl@gmail.com>
    Signed-off-by: Jon Maloy <jon.maloy@ericsson.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index a04fe9be1c60..c1cfd92de17a 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -156,6 +156,7 @@ static void named_distribute(struct net *net, struct sk_buff_head *list,
 				pr_warn("Bulk publication failure\n");
 				return;
 			}
+			msg_set_bc_ack_invalid(buf_msg(skb), true);
 			item = (struct distr_item *)msg_data(buf_msg(skb));
 		}
 

commit d2f394dc4816b7bd1b44981d83509f18f19c53f0
Author: Parthasarathy Bhuvaragan <parthasarathy.bhuvaragan@ericsson.com>
Date:   Thu Sep 1 16:22:16 2016 +0200

    tipc: fix random link resets while adding a second bearer
    
    In a dual bearer configuration, if the second tipc link becomes
    active while the first link still has pending nametable "bulk"
    updates, it randomly leads to reset of the second link.
    
    When a link is established, the function named_distribute(),
    fills the skb based on node mtu (allows room for TUNNEL_PROTOCOL)
    with NAME_DISTRIBUTOR message for each PUBLICATION.
    However, the function named_distribute() allocates the buffer by
    increasing the node mtu by INT_H_SIZE (to insert NAME_DISTRIBUTOR).
    This consumes the space allocated for TUNNEL_PROTOCOL.
    
    When establishing the second link, the link shall tunnel all the
    messages in the first link queue including the "bulk" update.
    As size of the NAME_DISTRIBUTOR messages while tunnelling, exceeds
    the link mtu the transmission fails (-EMSGSIZE).
    
    Thus, the synch point based on the message count of the tunnel
    packets is never reached leading to link timeout.
    
    In this commit, we adjust the size of name distributor message so that
    they can be tunnelled.
    
    Reviewed-by: Jon Maloy <jon.maloy@ericsson.com>
    Signed-off-by: Parthasarathy Bhuvaragan <parthasarathy.bhuvaragan@ericsson.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index 6b626a64b517..a04fe9be1c60 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -62,6 +62,8 @@ static void publ_to_item(struct distr_item *i, struct publication *p)
 
 /**
  * named_prepare_buf - allocate & initialize a publication message
+ *
+ * The buffer returned is of size INT_H_SIZE + payload size
  */
 static struct sk_buff *named_prepare_buf(struct net *net, u32 type, u32 size,
 					 u32 dest)
@@ -141,9 +143,9 @@ static void named_distribute(struct net *net, struct sk_buff_head *list,
 	struct publication *publ;
 	struct sk_buff *skb = NULL;
 	struct distr_item *item = NULL;
-	uint msg_dsz = (tipc_node_get_mtu(net, dnode, 0) / ITEM_SIZE) *
-			ITEM_SIZE;
-	uint msg_rem = msg_dsz;
+	u32 msg_dsz = ((tipc_node_get_mtu(net, dnode, 0) - INT_H_SIZE) /
+			ITEM_SIZE) * ITEM_SIZE;
+	u32 msg_rem = msg_dsz;
 
 	list_for_each_entry(publ, pls, local_list) {
 		/* Prepare next buffer: */

commit ddb1d33969ef52687ad00f75eecf87029f62e382
Author: Erik Hugne <erik.hugne@gmail.com>
Date:   Thu Apr 7 10:40:44 2016 -0400

    tipc: purge deferred updates from dead nodes
    
    If a peer node becomes unavailable, in addition to removing the
    nametable entries from this node we also need to purge all deferred
    updates associated with this node.
    
    Signed-off-by: Erik Hugne <erik.hugne@gmail.com>
    Signed-off-by: Jon Maloy <jon.maloy@ericsson.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index 4f4f5810f223..6b626a64b517 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -224,12 +224,31 @@ static void tipc_publ_purge(struct net *net, struct publication *publ, u32 addr)
 	kfree_rcu(p, rcu);
 }
 
+/**
+ * tipc_dist_queue_purge - remove deferred updates from a node that went down
+ */
+static void tipc_dist_queue_purge(struct net *net, u32 addr)
+{
+	struct tipc_net *tn = net_generic(net, tipc_net_id);
+	struct distr_queue_item *e, *tmp;
+
+	spin_lock_bh(&tn->nametbl_lock);
+	list_for_each_entry_safe(e, tmp, &tn->dist_queue, next) {
+		if (e->node != addr)
+			continue;
+		list_del(&e->next);
+		kfree(e);
+	}
+	spin_unlock_bh(&tn->nametbl_lock);
+}
+
 void tipc_publ_notify(struct net *net, struct list_head *nsub_list, u32 addr)
 {
 	struct publication *publ, *tmp;
 
 	list_for_each_entry_safe(publ, tmp, nsub_list, nodesub_list)
 		tipc_publ_purge(net, publ, addr);
+	tipc_dist_queue_purge(net, addr);
 }
 
 /**

commit 541726abe7daca64390c2ec34e6a203145f1686d
Author: Erik Hugne <erik.hugne@gmail.com>
Date:   Thu Apr 7 10:40:43 2016 -0400

    tipc: make dist queue pernet
    
    Nametable updates received from the network that cannot be applied
    immediately are placed on a defer queue. This queue is global to the
    TIPC module, which might cause problems when using TIPC in containers.
    To prevent nametable updates from escaping into the wrong namespace,
    we make the queue pernet instead.
    
    Signed-off-by: Erik Hugne <erik.hugne@gmail.com>
    Signed-off-by: Jon Maloy <jon.maloy@ericsson.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index ebe9d0ff6e9e..4f4f5810f223 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -40,11 +40,6 @@
 
 int sysctl_tipc_named_timeout __read_mostly = 2000;
 
-/**
- * struct tipc_dist_queue - queue holding deferred name table updates
- */
-static struct list_head tipc_dist_queue = LIST_HEAD_INIT(tipc_dist_queue);
-
 struct distr_queue_item {
 	struct distr_item i;
 	u32 dtype;
@@ -279,9 +274,11 @@ static bool tipc_update_nametbl(struct net *net, struct distr_item *i,
  * tipc_named_add_backlog - add a failed name table update to the backlog
  *
  */
-static void tipc_named_add_backlog(struct distr_item *i, u32 type, u32 node)
+static void tipc_named_add_backlog(struct net *net, struct distr_item *i,
+				   u32 type, u32 node)
 {
 	struct distr_queue_item *e;
+	struct tipc_net *tn = net_generic(net, tipc_net_id);
 	unsigned long now = get_jiffies_64();
 
 	e = kzalloc(sizeof(*e), GFP_ATOMIC);
@@ -291,7 +288,7 @@ static void tipc_named_add_backlog(struct distr_item *i, u32 type, u32 node)
 	e->node = node;
 	e->expires = now + msecs_to_jiffies(sysctl_tipc_named_timeout);
 	memcpy(e, i, sizeof(*i));
-	list_add_tail(&e->next, &tipc_dist_queue);
+	list_add_tail(&e->next, &tn->dist_queue);
 }
 
 /**
@@ -301,10 +298,11 @@ static void tipc_named_add_backlog(struct distr_item *i, u32 type, u32 node)
 void tipc_named_process_backlog(struct net *net)
 {
 	struct distr_queue_item *e, *tmp;
+	struct tipc_net *tn = net_generic(net, tipc_net_id);
 	char addr[16];
 	unsigned long now = get_jiffies_64();
 
-	list_for_each_entry_safe(e, tmp, &tipc_dist_queue, next) {
+	list_for_each_entry_safe(e, tmp, &tn->dist_queue, next) {
 		if (time_after(e->expires, now)) {
 			if (!tipc_update_nametbl(net, &e->i, e->node, e->dtype))
 				continue;
@@ -344,7 +342,7 @@ void tipc_named_rcv(struct net *net, struct sk_buff_head *inputq)
 		node = msg_orignode(msg);
 		while (count--) {
 			if (!tipc_update_nametbl(net, item, node, mtype))
-				tipc_named_add_backlog(item, mtype, node);
+				tipc_named_add_backlog(net, item, mtype, node);
 			item++;
 		}
 		kfree_skb(skb);

commit 1d7e1c2595bd20c5274a8e49d89cf0cf483759de
Author: Jon Paul Maloy <jon.maloy@ericsson.com>
Date:   Thu Nov 19 14:30:42 2015 -0500

    tipc: reduce code dependency between binding table and node layer
    
    The file name_distr.c currently contains three functions,
    named_cluster_distribute(), tipc_publ_subcscribe() and
    tipc_publ_unsubscribe() that all directly access fields in
    struct tipc_node. We want to eliminate such dependencies, so
    we move those functions to the file node.c and rename them to
    tipc_node_broadcast(), tipc_node_subscribe() and tipc_node_unsubscribe()
    respectively.
    
    Reviewed-by: Ying Xue <ying.xue@windriver.com>
    Signed-off-by: Jon Maloy <jon.maloy@ericsson.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index f51c8bdbea1c..ebe9d0ff6e9e 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -84,31 +84,6 @@ static struct sk_buff *named_prepare_buf(struct net *net, u32 type, u32 size,
 	return buf;
 }
 
-void named_cluster_distribute(struct net *net, struct sk_buff *skb)
-{
-	struct tipc_net *tn = net_generic(net, tipc_net_id);
-	struct sk_buff *oskb;
-	struct tipc_node *node;
-	u32 dnode;
-
-	rcu_read_lock();
-	list_for_each_entry_rcu(node, &tn->node_list, list) {
-		dnode = node->addr;
-		if (in_own_node(net, dnode))
-			continue;
-		if (!tipc_node_is_up(node))
-			continue;
-		oskb = pskb_copy(skb, GFP_ATOMIC);
-		if (!oskb)
-			break;
-		msg_set_destnode(buf_msg(oskb), dnode);
-		tipc_node_xmit_skb(net, oskb, dnode, 0);
-	}
-	rcu_read_unlock();
-
-	kfree_skb(skb);
-}
-
 /**
  * tipc_named_publish - tell other nodes about a new publication by this node
  */
@@ -226,42 +201,6 @@ void tipc_named_node_up(struct net *net, u32 dnode)
 	tipc_node_xmit(net, &head, dnode, 0);
 }
 
-static void tipc_publ_subscribe(struct net *net, struct publication *publ,
-				u32 addr)
-{
-	struct tipc_node *node;
-
-	if (in_own_node(net, addr))
-		return;
-
-	node = tipc_node_find(net, addr);
-	if (!node) {
-		pr_warn("Node subscription rejected, unknown node 0x%x\n",
-			addr);
-		return;
-	}
-
-	tipc_node_lock(node);
-	list_add_tail(&publ->nodesub_list, &node->publ_list);
-	tipc_node_unlock(node);
-	tipc_node_put(node);
-}
-
-static void tipc_publ_unsubscribe(struct net *net, struct publication *publ,
-				  u32 addr)
-{
-	struct tipc_node *node;
-
-	node = tipc_node_find(net, addr);
-	if (!node)
-		return;
-
-	tipc_node_lock(node);
-	list_del_init(&publ->nodesub_list);
-	tipc_node_unlock(node);
-	tipc_node_put(node);
-}
-
 /**
  * tipc_publ_purge - remove publication associated with a failed node
  *
@@ -277,7 +216,7 @@ static void tipc_publ_purge(struct net *net, struct publication *publ, u32 addr)
 	p = tipc_nametbl_remove_publ(net, publ->type, publ->lower,
 				     publ->node, publ->ref, publ->key);
 	if (p)
-		tipc_publ_unsubscribe(net, p, addr);
+		tipc_node_unsubscribe(net, &p->nodesub_list, addr);
 	spin_unlock_bh(&tn->nametbl_lock);
 
 	if (p != publ) {
@@ -317,7 +256,7 @@ static bool tipc_update_nametbl(struct net *net, struct distr_item *i,
 						TIPC_CLUSTER_SCOPE, node,
 						ntohl(i->ref), ntohl(i->key));
 		if (publ) {
-			tipc_publ_subscribe(net, publ, node);
+			tipc_node_subscribe(net, &publ->nodesub_list, node);
 			return true;
 		}
 	} else if (dtype == WITHDRAWAL) {
@@ -326,7 +265,7 @@ static bool tipc_update_nametbl(struct net *net, struct distr_item *i,
 						node, ntohl(i->ref),
 						ntohl(i->key));
 		if (publ) {
-			tipc_publ_unsubscribe(net, publ, node);
+			tipc_node_unsubscribe(net, &publ->nodesub_list, node);
 			kfree_rcu(publ, rcu);
 			return true;
 		}

commit c7cad0d6f70cd4ce8644ffe528a4df1cdc2e77f5
Author: Jon Paul Maloy <jon.maloy@ericsson.com>
Date:   Thu Nov 19 14:30:40 2015 -0500

    tipc: move linearization of buffers to generic code
    
    In commit 5cbb28a4bf65c7e4 ("tipc: linearize arriving NAME_DISTR
    and LINK_PROTO buffers") we added linearization of NAME_DISTRIBUTOR,
    LINK_PROTOCOL/RESET and LINK_PROTOCOL/ACTIVATE to the function
    tipc_udp_recv(). The location of the change was selected in order
    to make the commit easily appliable to 'net' and 'stable'.
    
    We now move this linearization to where it should be done, in the
    functions tipc_named_rcv() and tipc_link_proto_rcv() respectively.
    
    Reviewed-by: Ying Xue <ying.xue@windriver.com>
    Signed-off-by: Jon Maloy <jon.maloy@ericsson.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index c07612bab95c..f51c8bdbea1c 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -397,6 +397,7 @@ void tipc_named_rcv(struct net *net, struct sk_buff_head *inputq)
 
 	spin_lock_bh(&tn->nametbl_lock);
 	for (skb = skb_dequeue(inputq); skb; skb = skb_dequeue(inputq)) {
+		skb_linearize(skb);
 		msg = buf_msg(skb);
 		mtype = msg_type(msg);
 		item = (struct distr_item *)msg_data(msg);

commit c49a0a84391bcc313b3dc2a9ceee6de684e07655
Author: Jon Paul Maloy <jon.maloy@ericsson.com>
Date:   Thu Oct 22 08:51:47 2015 -0400

    tipc: ensure binding table initial distribution is sent via first link
    
    Correct synchronization of the broadcast link at first contact between
    two nodes is dependent on the assumption that the binding table "bulk"
    update passes via the same link as the initial broadcast syncronization
    message, i.e., via the first link that is established.
    
    This is not guaranteed in the current implementation. If two link
    come up very close to each other in time, the "bulk" may quite well
    pass via the second link, and hence void the guarantee of a correct
    initial synchronization before the broadcast link is opened.
    
    This commit makes two small changes to strengthen this guarantee.
    
    1) We let the second established link occupy slot 1 of the
       "active_links" array, while the first link will retain slot 0.
       (This is in reality a cosmetic change, we could just as well keep
        the current, opposite order)
    
    2) We let the name distributor always use link selector/slot 0 when
       it sends it binding table updates.
    
    The extra traffic bias on the first link caused by this change should
    be negligible, since binding table updates constitutes a very small
    fraction of the total traffic.
    
    Signed-off-by: Jon Maloy <jon.maloy@ericsson.com>
    Reviewed-by: Ying Xue <ying.xue@windriver.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index e6018b7eb197..c07612bab95c 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -102,7 +102,7 @@ void named_cluster_distribute(struct net *net, struct sk_buff *skb)
 		if (!oskb)
 			break;
 		msg_set_destnode(buf_msg(oskb), dnode);
-		tipc_node_xmit_skb(net, oskb, dnode, dnode);
+		tipc_node_xmit_skb(net, oskb, dnode, 0);
 	}
 	rcu_read_unlock();
 
@@ -223,7 +223,7 @@ void tipc_named_node_up(struct net *net, u32 dnode)
 			 &tn->nametbl->publ_list[TIPC_ZONE_SCOPE]);
 	rcu_read_unlock();
 
-	tipc_node_xmit(net, &head, dnode, dnode);
+	tipc_node_xmit(net, &head, dnode, 0);
 }
 
 static void tipc_publ_subscribe(struct net *net, struct publication *publ,

commit af9b028e270fda6fb812d70d17d902297df1ceb5
Author: Jon Paul Maloy <jon.maloy@ericsson.com>
Date:   Thu Jul 16 16:54:24 2015 -0400

    tipc: make media xmit call outside node spinlock context
    
    Currently, message sending is performed through a deep call chain,
    where the node spinlock is grabbed and held during a significant
    part of the transmission time. This is clearly detrimental to
    overall throughput performance; it would be better if we could send
    the message after the spinlock has been released.
    
    In this commit, we do instead let the call revert on the stack after
    the buffer chain has been added to the transmission queue, whereafter
    clones of the buffers are transmitted to the device layer outside the
    spinlock scope.
    
    As a further step in our effort to separate the roles of the node
    and link entities we also move the function tipc_link_xmit() to
    node.c, and rename it to tipc_node_xmit().
    
    Reviewed-by: Ying Xue <ying.xue@windriver.com>
    Signed-off-by: Jon Maloy <jon.maloy@ericsson.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index 3a1539e96294..e6018b7eb197 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -102,7 +102,7 @@ void named_cluster_distribute(struct net *net, struct sk_buff *skb)
 		if (!oskb)
 			break;
 		msg_set_destnode(buf_msg(oskb), dnode);
-		tipc_link_xmit_skb(net, oskb, dnode, dnode);
+		tipc_node_xmit_skb(net, oskb, dnode, dnode);
 	}
 	rcu_read_unlock();
 
@@ -223,7 +223,7 @@ void tipc_named_node_up(struct net *net, u32 dnode)
 			 &tn->nametbl->publ_list[TIPC_ZONE_SCOPE]);
 	rcu_read_unlock();
 
-	tipc_link_xmit(net, &head, dnode, dnode);
+	tipc_node_xmit(net, &head, dnode, dnode);
 }
 
 static void tipc_publ_subscribe(struct net *net, struct publication *publ,

commit 9d13ec65ede775f896c3da1cfa35283afe2f796c
Author: Jon Paul Maloy <jon.maloy@ericsson.com>
Date:   Thu Jul 16 16:54:19 2015 -0400

    tipc: introduce link entry structure to struct tipc_node
    
    struct 'tipc_node' currently contains two arrays for link attributes,
    one for the link pointers, and one for the usable link MTUs.
    
    We now group those into a new struct 'tipc_link_entry', and intoduce
    one single array consisting of such enties. Apart from being a cosmetic
    improvement, this is a starting point for the strict master-slave
    relation between node and link that we will introduce in the following
    commits.
    
    Reviewed-by: Ying Xue <ying.xue@windriver.com>
    Signed-off-by: Jon Maloy <jon.maloy@ericsson.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index 41e7b7e4dda0..3a1539e96294 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -96,7 +96,7 @@ void named_cluster_distribute(struct net *net, struct sk_buff *skb)
 		dnode = node->addr;
 		if (in_own_node(net, dnode))
 			continue;
-		if (!tipc_node_active_links(node))
+		if (!tipc_node_is_up(node))
 			continue;
 		oskb = pskb_copy(skb, GFP_ATOMIC);
 		if (!oskb)

commit 8a0f6ebe8494c5c6ccfe12264385b64c280e3241
Author: Ying Xue <ying.xue@windriver.com>
Date:   Thu Mar 26 18:10:24 2015 +0800

    tipc: involve reference counter for node structure
    
    TIPC node hash node table is protected with rcu lock on read side.
    tipc_node_find() is used to look for a node object with node address
    through iterating the hash node table. As the entire process of what
    tipc_node_find() traverses the table is guarded with rcu read lock,
    it's safe for us. However, when callers use the node object returned
    by tipc_node_find(), there is no rcu read lock applied. Therefore,
    this is absolutely unsafe for callers of tipc_node_find().
    
    Now we introduce a reference counter for node structure. Before
    tipc_node_find() returns node object to its caller, it first increases
    the reference counter. Accordingly, after its caller used it up,
    it decreases the counter again. This can prevent a node being used by
    one thread from being freed by another thread.
    
    Reviewed-by: Erik Hugne <erik.hugne@ericsson.com>
    Reviewed-by: Jon Maloy <jon.maloy@ericson.com>
    Signed-off-by: Ying Xue <ying.xue@windriver.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index 506aaa565da7..41e7b7e4dda0 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -244,6 +244,7 @@ static void tipc_publ_subscribe(struct net *net, struct publication *publ,
 	tipc_node_lock(node);
 	list_add_tail(&publ->nodesub_list, &node->publ_list);
 	tipc_node_unlock(node);
+	tipc_node_put(node);
 }
 
 static void tipc_publ_unsubscribe(struct net *net, struct publication *publ,
@@ -258,6 +259,7 @@ static void tipc_publ_unsubscribe(struct net *net, struct publication *publ,
 	tipc_node_lock(node);
 	list_del_init(&publ->nodesub_list);
 	tipc_node_unlock(node);
+	tipc_node_put(node);
 }
 
 /**

commit 3622c36f37640078c9a706b71e02e6334c85f9e9
Author: Erik Hugne <erik.hugne@ericsson.com>
Date:   Fri Feb 27 08:56:54 2015 +0100

    tipc: only create header copy for name distr messages
    
    The TIPC name distributor pushes topology updates to the cluster
    neighbors. Currently this is done in a unicast manner, and the
    skb holding the update is cloned for each cluster member. This
    is unnecessary, as we only modify the destnode field in the header
    so we change it to do pskb_copy instead.
    
    Signed-off-by: Erik Hugne <erik.hugne@ericsson.com>
    Reviewed-by: Jon Maloy <jon.maloy@ericsson.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index fcb07915aaac..506aaa565da7 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -98,7 +98,7 @@ void named_cluster_distribute(struct net *net, struct sk_buff *skb)
 			continue;
 		if (!tipc_node_active_links(node))
 			continue;
-		oskb = skb_copy(skb, GFP_ATOMIC);
+		oskb = pskb_copy(skb, GFP_ATOMIC);
 		if (!oskb)
 			break;
 		msg_set_destnode(buf_msg(oskb), dnode);

commit c637c1035534867b85b78b453c38c495b58e2c5a
Author: Jon Paul Maloy <jon.maloy@ericsson.com>
Date:   Thu Feb 5 08:36:41 2015 -0500

    tipc: resolve race problem at unicast message reception
    
    TIPC handles message cardinality and sequencing at the link layer,
    before passing messages upwards to the destination sockets. During the
    upcall from link to socket no locks are held. It is therefore possible,
    and we see it happen occasionally, that messages arriving in different
    threads and delivered in sequence still bypass each other before they
    reach the destination socket. This must not happen, since it violates
    the sequentiality guarantee.
    
    We solve this by adding a new input buffer queue to the link structure.
    Arriving messages are added safely to the tail of that queue by the
    link, while the head of the queue is consumed, also safely, by the
    receiving socket. Sequentiality is secured per socket by only allowing
    buffers to be dequeued inside the socket lock. Since there may be multiple
    simultaneous readers of the queue, we use a 'filter' parameter to reduce
    the risk that they peek the same buffer from the queue, hence also
    reducing the risk of contention on the receiving socket locks.
    
    This solves the sequentiality problem, and seems to cause no measurable
    performance degradation.
    
    A nice side effect of this change is that lock handling in the functions
    tipc_rcv() and tipc_bcast_rcv() now becomes uniform, something that
    will enable future simplifications of those functions.
    
    Reviewed-by: Ying Xue <ying.xue@windriver.com>
    Signed-off-by: Jon Maloy <jon.maloy@ericsson.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index dd8564cd9dbb..fcb07915aaac 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -381,25 +381,34 @@ void tipc_named_process_backlog(struct net *net)
 }
 
 /**
- * tipc_named_rcv - process name table update message sent by another node
+ * tipc_named_rcv - process name table update messages sent by another node
  */
-void tipc_named_rcv(struct net *net, struct sk_buff *buf)
+void tipc_named_rcv(struct net *net, struct sk_buff_head *inputq)
 {
 	struct tipc_net *tn = net_generic(net, tipc_net_id);
-	struct tipc_msg *msg = buf_msg(buf);
-	struct distr_item *item = (struct distr_item *)msg_data(msg);
-	u32 count = msg_data_sz(msg) / ITEM_SIZE;
-	u32 node = msg_orignode(msg);
+	struct tipc_msg *msg;
+	struct distr_item *item;
+	uint count;
+	u32 node;
+	struct sk_buff *skb;
+	int mtype;
 
 	spin_lock_bh(&tn->nametbl_lock);
-	while (count--) {
-		if (!tipc_update_nametbl(net, item, node, msg_type(msg)))
-			tipc_named_add_backlog(item, msg_type(msg), node);
-		item++;
+	for (skb = skb_dequeue(inputq); skb; skb = skb_dequeue(inputq)) {
+		msg = buf_msg(skb);
+		mtype = msg_type(msg);
+		item = (struct distr_item *)msg_data(msg);
+		count = msg_data_sz(msg) / ITEM_SIZE;
+		node = msg_orignode(msg);
+		while (count--) {
+			if (!tipc_update_nametbl(net, item, node, mtype))
+				tipc_named_add_backlog(item, mtype, node);
+			item++;
+		}
+		kfree_skb(skb);
+		tipc_named_process_backlog(net);
 	}
-	tipc_named_process_backlog(net);
 	spin_unlock_bh(&tn->nametbl_lock);
-	kfree_skb(buf);
 }
 
 /**

commit c5898636c440da91d58f10beac00f073e68378df
Author: Jon Paul Maloy <jon.maloy@ericsson.com>
Date:   Thu Feb 5 08:36:36 2015 -0500

    tipc: reduce usage of context info in socket and link
    
    The most common usage of namespace information is when we fetch the
    own node addess from the net structure. This leads to a lot of
    passing around of a parameter of type 'struct net *' between
    functions just to make them able to obtain this address.
    
    However, in many cases this is unnecessary. The own node address
    is readily available as a member of both struct tipc_sock and
    tipc_link, and can be fetched from there instead.
    The fact that the vast majority of functions in socket.c and link.c
    anyway are maintaining a pointer to their respective base structures
    makes this option even more compelling.
    
    In this commit, we introduce the inline functions tsk_own_node()
    and link_own_node() to make it easy for functions to fetch the node
    address from those structs instead of having to pass along and
    dereference the namespace struct.
    
    In particular, we make calls to the msg_xx() functions in msg.{h,c}
    context independent by directly passing them the own node address
    as parameter when needed. Those functions should be regarded as
    leaves in the code dependency tree, and it is hence desirable to
    keep them namspace unaware.
    
    Apart from a potential positive effect on cache behavior, these
    changes make it easier to introduce the changes that will follow
    later in this series.
    
    Reviewed-by: Ying Xue <ying.xue@windriver.com>
    Signed-off-by: Jon Maloy <jon.maloy@ericsson.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index 7f31cd4badc4..dd8564cd9dbb 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -71,13 +71,14 @@ static void publ_to_item(struct distr_item *i, struct publication *p)
 static struct sk_buff *named_prepare_buf(struct net *net, u32 type, u32 size,
 					 u32 dest)
 {
+	struct tipc_net *tn = net_generic(net, tipc_net_id);
 	struct sk_buff *buf = tipc_buf_acquire(INT_H_SIZE + size);
 	struct tipc_msg *msg;
 
 	if (buf != NULL) {
 		msg = buf_msg(buf);
-		tipc_msg_init(net, msg, NAME_DISTRIBUTOR, type, INT_H_SIZE,
-			      dest);
+		tipc_msg_init(tn->own_addr, msg, NAME_DISTRIBUTOR, type,
+			      INT_H_SIZE, dest);
 		msg_set_size(msg, INT_H_SIZE + size);
 	}
 	return buf;

commit 347475395434abb2b61bf59c2952470f37072567
Author: Ying Xue <ying.xue@windriver.com>
Date:   Fri Jan 9 15:27:10 2015 +0800

    tipc: make tipc node address support net namespace
    
    If net namespace is supported in tipc, each namespace will be treated
    as a separate tipc node. Therefore, every namespace must own its
    private tipc node address. This means the "tipc_own_addr" global
    variable of node address must be moved to tipc_net structure to
    satisfy the requirement. It's turned out that users also can assign
    node address for every namespace.
    
    Signed-off-by: Ying Xue <ying.xue@windriver.com>
    Tested-by: Tero Aho <Tero.Aho@coriant.com>
    Reviewed-by: Jon Maloy <jon.maloy@ericsson.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index ba421321d15d..7f31cd4badc4 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -68,14 +68,16 @@ static void publ_to_item(struct distr_item *i, struct publication *p)
 /**
  * named_prepare_buf - allocate & initialize a publication message
  */
-static struct sk_buff *named_prepare_buf(u32 type, u32 size, u32 dest)
+static struct sk_buff *named_prepare_buf(struct net *net, u32 type, u32 size,
+					 u32 dest)
 {
 	struct sk_buff *buf = tipc_buf_acquire(INT_H_SIZE + size);
 	struct tipc_msg *msg;
 
 	if (buf != NULL) {
 		msg = buf_msg(buf);
-		tipc_msg_init(msg, NAME_DISTRIBUTOR, type, INT_H_SIZE, dest);
+		tipc_msg_init(net, msg, NAME_DISTRIBUTOR, type, INT_H_SIZE,
+			      dest);
 		msg_set_size(msg, INT_H_SIZE + size);
 	}
 	return buf;
@@ -91,7 +93,7 @@ void named_cluster_distribute(struct net *net, struct sk_buff *skb)
 	rcu_read_lock();
 	list_for_each_entry_rcu(node, &tn->node_list, list) {
 		dnode = node->addr;
-		if (in_own_node(dnode))
+		if (in_own_node(net, dnode))
 			continue;
 		if (!tipc_node_active_links(node))
 			continue;
@@ -121,7 +123,7 @@ struct sk_buff *tipc_named_publish(struct net *net, struct publication *publ)
 	if (publ->scope == TIPC_NODE_SCOPE)
 		return NULL;
 
-	buf = named_prepare_buf(PUBLICATION, ITEM_SIZE, 0);
+	buf = named_prepare_buf(net, PUBLICATION, ITEM_SIZE, 0);
 	if (!buf) {
 		pr_warn("Publication distribution failure\n");
 		return NULL;
@@ -135,7 +137,7 @@ struct sk_buff *tipc_named_publish(struct net *net, struct publication *publ)
 /**
  * tipc_named_withdraw - tell other nodes about a withdrawn publication by this node
  */
-struct sk_buff *tipc_named_withdraw(struct publication *publ)
+struct sk_buff *tipc_named_withdraw(struct net *net, struct publication *publ)
 {
 	struct sk_buff *buf;
 	struct distr_item *item;
@@ -145,7 +147,7 @@ struct sk_buff *tipc_named_withdraw(struct publication *publ)
 	if (publ->scope == TIPC_NODE_SCOPE)
 		return NULL;
 
-	buf = named_prepare_buf(WITHDRAWAL, ITEM_SIZE, 0);
+	buf = named_prepare_buf(net, WITHDRAWAL, ITEM_SIZE, 0);
 	if (!buf) {
 		pr_warn("Withdrawal distribution failure\n");
 		return NULL;
@@ -175,7 +177,8 @@ static void named_distribute(struct net *net, struct sk_buff_head *list,
 	list_for_each_entry(publ, pls, local_list) {
 		/* Prepare next buffer: */
 		if (!skb) {
-			skb = named_prepare_buf(PUBLICATION, msg_rem, dnode);
+			skb = named_prepare_buf(net, PUBLICATION, msg_rem,
+						dnode);
 			if (!skb) {
 				pr_warn("Bulk publication failure\n");
 				return;
@@ -227,7 +230,7 @@ static void tipc_publ_subscribe(struct net *net, struct publication *publ,
 {
 	struct tipc_node *node;
 
-	if (in_own_node(addr))
+	if (in_own_node(net, addr))
 		return;
 
 	node = tipc_node_find(net, addr);
@@ -416,7 +419,7 @@ void tipc_named_reinit(struct net *net)
 	for (scope = TIPC_ZONE_SCOPE; scope <= TIPC_NODE_SCOPE; scope++)
 		list_for_each_entry_rcu(publ, &tn->nametbl->publ_list[scope],
 					local_list)
-			publ->node = tipc_own_addr;
+			publ->node = tn->own_addr;
 
 	spin_unlock_bh(&tn->nametbl_lock);
 }

commit 4ac1c8d0ee9faf3a4be185cc4db1381fa0d81280
Author: Ying Xue <ying.xue@windriver.com>
Date:   Fri Jan 9 15:27:09 2015 +0800

    tipc: name tipc name table support net namespace
    
    TIPC name table is used to store the mapping relationship between
    TIPC service name and socket port ID. When tipc supports namespace,
    it allows users to publish service names only owned by a certain
    namespace. Therefore, every namespace must have its private name
    table to prevent service names published to one namespace from being
    contaminated by other service names in another namespace. Therefore,
    The name table global variable (ie, nametbl) and its lock must be
    moved to tipc_net structure, and a parameter of namespace must be
    added for necessary functions so that they can obtain name table
    variable defined in tipc_net structure.
    
    Signed-off-by: Ying Xue <ying.xue@windriver.com>
    Tested-by: Tero Aho <Tero.Aho@coriant.com>
    Reviewed-by: Jon Maloy <jon.maloy@ericsson.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index d40df588263e..ba421321d15d 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -109,13 +109,14 @@ void named_cluster_distribute(struct net *net, struct sk_buff *skb)
 /**
  * tipc_named_publish - tell other nodes about a new publication by this node
  */
-struct sk_buff *tipc_named_publish(struct publication *publ)
+struct sk_buff *tipc_named_publish(struct net *net, struct publication *publ)
 {
+	struct tipc_net *tn = net_generic(net, tipc_net_id);
 	struct sk_buff *buf;
 	struct distr_item *item;
 
 	list_add_tail_rcu(&publ->local_list,
-			  &tipc_nametbl->publ_list[publ->scope]);
+			  &tn->nametbl->publ_list[publ->scope]);
 
 	if (publ->scope == TIPC_NODE_SCOPE)
 		return NULL;
@@ -206,15 +207,16 @@ static void named_distribute(struct net *net, struct sk_buff_head *list,
  */
 void tipc_named_node_up(struct net *net, u32 dnode)
 {
+	struct tipc_net *tn = net_generic(net, tipc_net_id);
 	struct sk_buff_head head;
 
 	__skb_queue_head_init(&head);
 
 	rcu_read_lock();
 	named_distribute(net, &head, dnode,
-			 &tipc_nametbl->publ_list[TIPC_CLUSTER_SCOPE]);
+			 &tn->nametbl->publ_list[TIPC_CLUSTER_SCOPE]);
 	named_distribute(net, &head, dnode,
-			 &tipc_nametbl->publ_list[TIPC_ZONE_SCOPE]);
+			 &tn->nametbl->publ_list[TIPC_ZONE_SCOPE]);
 	rcu_read_unlock();
 
 	tipc_link_xmit(net, &head, dnode, dnode);
@@ -262,14 +264,15 @@ static void tipc_publ_unsubscribe(struct net *net, struct publication *publ,
  */
 static void tipc_publ_purge(struct net *net, struct publication *publ, u32 addr)
 {
+	struct tipc_net *tn = net_generic(net, tipc_net_id);
 	struct publication *p;
 
-	spin_lock_bh(&tipc_nametbl_lock);
-	p = tipc_nametbl_remove_publ(publ->type, publ->lower,
+	spin_lock_bh(&tn->nametbl_lock);
+	p = tipc_nametbl_remove_publ(net, publ->type, publ->lower,
 				     publ->node, publ->ref, publ->key);
 	if (p)
 		tipc_publ_unsubscribe(net, p, addr);
-	spin_unlock_bh(&tipc_nametbl_lock);
+	spin_unlock_bh(&tn->nametbl_lock);
 
 	if (p != publ) {
 		pr_err("Unable to remove publication from failed node\n"
@@ -302,7 +305,8 @@ static bool tipc_update_nametbl(struct net *net, struct distr_item *i,
 	struct publication *publ = NULL;
 
 	if (dtype == PUBLICATION) {
-		publ = tipc_nametbl_insert_publ(ntohl(i->type), ntohl(i->lower),
+		publ = tipc_nametbl_insert_publ(net, ntohl(i->type),
+						ntohl(i->lower),
 						ntohl(i->upper),
 						TIPC_CLUSTER_SCOPE, node,
 						ntohl(i->ref), ntohl(i->key));
@@ -311,7 +315,8 @@ static bool tipc_update_nametbl(struct net *net, struct distr_item *i,
 			return true;
 		}
 	} else if (dtype == WITHDRAWAL) {
-		publ = tipc_nametbl_remove_publ(ntohl(i->type), ntohl(i->lower),
+		publ = tipc_nametbl_remove_publ(net, ntohl(i->type),
+						ntohl(i->lower),
 						node, ntohl(i->ref),
 						ntohl(i->key));
 		if (publ) {
@@ -376,19 +381,20 @@ void tipc_named_process_backlog(struct net *net)
  */
 void tipc_named_rcv(struct net *net, struct sk_buff *buf)
 {
+	struct tipc_net *tn = net_generic(net, tipc_net_id);
 	struct tipc_msg *msg = buf_msg(buf);
 	struct distr_item *item = (struct distr_item *)msg_data(msg);
 	u32 count = msg_data_sz(msg) / ITEM_SIZE;
 	u32 node = msg_orignode(msg);
 
-	spin_lock_bh(&tipc_nametbl_lock);
+	spin_lock_bh(&tn->nametbl_lock);
 	while (count--) {
 		if (!tipc_update_nametbl(net, item, node, msg_type(msg)))
 			tipc_named_add_backlog(item, msg_type(msg), node);
 		item++;
 	}
 	tipc_named_process_backlog(net);
-	spin_unlock_bh(&tipc_nametbl_lock);
+	spin_unlock_bh(&tn->nametbl_lock);
 	kfree_skb(buf);
 }
 
@@ -399,17 +405,18 @@ void tipc_named_rcv(struct net *net, struct sk_buff *buf)
  * All name table entries published by this node are updated to reflect
  * the node's new network address.
  */
-void tipc_named_reinit(void)
+void tipc_named_reinit(struct net *net)
 {
+	struct tipc_net *tn = net_generic(net, tipc_net_id);
 	struct publication *publ;
 	int scope;
 
-	spin_lock_bh(&tipc_nametbl_lock);
+	spin_lock_bh(&tn->nametbl_lock);
 
 	for (scope = TIPC_ZONE_SCOPE; scope <= TIPC_NODE_SCOPE; scope++)
-		list_for_each_entry_rcu(publ, &tipc_nametbl->publ_list[scope],
+		list_for_each_entry_rcu(publ, &tn->nametbl->publ_list[scope],
 					local_list)
 			publ->node = tipc_own_addr;
 
-	spin_unlock_bh(&tipc_nametbl_lock);
+	spin_unlock_bh(&tn->nametbl_lock);
 }

commit f2f9800d4955a96d92896841d8ba9b04201deaa1
Author: Ying Xue <ying.xue@windriver.com>
Date:   Fri Jan 9 15:27:05 2015 +0800

    tipc: make tipc node table aware of net namespace
    
    Global variables associated with node table are below:
    - node table list (node_htable)
    - node hash table list (tipc_node_list)
    - node table lock (node_list_lock)
    - node number counter (tipc_num_nodes)
    - node link number counter (tipc_num_links)
    
    To make node table support namespace, above global variables must be
    moved to tipc_net structure in order to keep secret for different
    namespaces. As a consequence, these variables are allocated and
    initialized when namespace is created, and deallocated when namespace
    is destroyed. After the change, functions associated with these
    variables have to utilize a namespace pointer to access them. So
    adding namespace pointer as a parameter of these functions is the
    major change made in the commit.
    
    Signed-off-by: Ying Xue <ying.xue@windriver.com>
    Tested-by: Tero Aho <Tero.Aho@coriant.com>
    Reviewed-by: Jon Maloy <jon.maloy@ericsson.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index ba6083dca95b..d40df588263e 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -81,14 +81,15 @@ static struct sk_buff *named_prepare_buf(u32 type, u32 size, u32 dest)
 	return buf;
 }
 
-void named_cluster_distribute(struct sk_buff *skb)
+void named_cluster_distribute(struct net *net, struct sk_buff *skb)
 {
+	struct tipc_net *tn = net_generic(net, tipc_net_id);
 	struct sk_buff *oskb;
 	struct tipc_node *node;
 	u32 dnode;
 
 	rcu_read_lock();
-	list_for_each_entry_rcu(node, &tipc_node_list, list) {
+	list_for_each_entry_rcu(node, &tn->node_list, list) {
 		dnode = node->addr;
 		if (in_own_node(dnode))
 			continue;
@@ -98,7 +99,7 @@ void named_cluster_distribute(struct sk_buff *skb)
 		if (!oskb)
 			break;
 		msg_set_destnode(buf_msg(oskb), dnode);
-		tipc_link_xmit_skb(oskb, dnode, dnode);
+		tipc_link_xmit_skb(net, oskb, dnode, dnode);
 	}
 	rcu_read_unlock();
 
@@ -160,13 +161,14 @@ struct sk_buff *tipc_named_withdraw(struct publication *publ)
  * @dnode: node to be updated
  * @pls: linked list of publication items to be packed into buffer chain
  */
-static void named_distribute(struct sk_buff_head *list, u32 dnode,
-			     struct list_head *pls)
+static void named_distribute(struct net *net, struct sk_buff_head *list,
+			     u32 dnode, struct list_head *pls)
 {
 	struct publication *publ;
 	struct sk_buff *skb = NULL;
 	struct distr_item *item = NULL;
-	uint msg_dsz = (tipc_node_get_mtu(dnode, 0) / ITEM_SIZE) * ITEM_SIZE;
+	uint msg_dsz = (tipc_node_get_mtu(net, dnode, 0) / ITEM_SIZE) *
+			ITEM_SIZE;
 	uint msg_rem = msg_dsz;
 
 	list_for_each_entry(publ, pls, local_list) {
@@ -202,30 +204,31 @@ static void named_distribute(struct sk_buff_head *list, u32 dnode,
 /**
  * tipc_named_node_up - tell specified node about all publications by this node
  */
-void tipc_named_node_up(u32 dnode)
+void tipc_named_node_up(struct net *net, u32 dnode)
 {
 	struct sk_buff_head head;
 
 	__skb_queue_head_init(&head);
 
 	rcu_read_lock();
-	named_distribute(&head, dnode,
+	named_distribute(net, &head, dnode,
 			 &tipc_nametbl->publ_list[TIPC_CLUSTER_SCOPE]);
-	named_distribute(&head, dnode,
+	named_distribute(net, &head, dnode,
 			 &tipc_nametbl->publ_list[TIPC_ZONE_SCOPE]);
 	rcu_read_unlock();
 
-	tipc_link_xmit(&head, dnode, dnode);
+	tipc_link_xmit(net, &head, dnode, dnode);
 }
 
-static void tipc_publ_subscribe(struct publication *publ, u32 addr)
+static void tipc_publ_subscribe(struct net *net, struct publication *publ,
+				u32 addr)
 {
 	struct tipc_node *node;
 
 	if (in_own_node(addr))
 		return;
 
-	node = tipc_node_find(addr);
+	node = tipc_node_find(net, addr);
 	if (!node) {
 		pr_warn("Node subscription rejected, unknown node 0x%x\n",
 			addr);
@@ -237,11 +240,12 @@ static void tipc_publ_subscribe(struct publication *publ, u32 addr)
 	tipc_node_unlock(node);
 }
 
-static void tipc_publ_unsubscribe(struct publication *publ, u32 addr)
+static void tipc_publ_unsubscribe(struct net *net, struct publication *publ,
+				  u32 addr)
 {
 	struct tipc_node *node;
 
-	node = tipc_node_find(addr);
+	node = tipc_node_find(net, addr);
 	if (!node)
 		return;
 
@@ -256,7 +260,7 @@ static void tipc_publ_unsubscribe(struct publication *publ, u32 addr)
  * Invoked for each publication issued by a newly failed node.
  * Removes publication structure from name table & deletes it.
  */
-static void tipc_publ_purge(struct publication *publ, u32 addr)
+static void tipc_publ_purge(struct net *net, struct publication *publ, u32 addr)
 {
 	struct publication *p;
 
@@ -264,7 +268,7 @@ static void tipc_publ_purge(struct publication *publ, u32 addr)
 	p = tipc_nametbl_remove_publ(publ->type, publ->lower,
 				     publ->node, publ->ref, publ->key);
 	if (p)
-		tipc_publ_unsubscribe(p, addr);
+		tipc_publ_unsubscribe(net, p, addr);
 	spin_unlock_bh(&tipc_nametbl_lock);
 
 	if (p != publ) {
@@ -277,12 +281,12 @@ static void tipc_publ_purge(struct publication *publ, u32 addr)
 	kfree_rcu(p, rcu);
 }
 
-void tipc_publ_notify(struct list_head *nsub_list, u32 addr)
+void tipc_publ_notify(struct net *net, struct list_head *nsub_list, u32 addr)
 {
 	struct publication *publ, *tmp;
 
 	list_for_each_entry_safe(publ, tmp, nsub_list, nodesub_list)
-		tipc_publ_purge(publ, addr);
+		tipc_publ_purge(net, publ, addr);
 }
 
 /**
@@ -292,7 +296,8 @@ void tipc_publ_notify(struct list_head *nsub_list, u32 addr)
  * tipc_nametbl_lock must be held.
  * Returns the publication item if successful, otherwise NULL.
  */
-static bool tipc_update_nametbl(struct distr_item *i, u32 node, u32 dtype)
+static bool tipc_update_nametbl(struct net *net, struct distr_item *i,
+				u32 node, u32 dtype)
 {
 	struct publication *publ = NULL;
 
@@ -302,7 +307,7 @@ static bool tipc_update_nametbl(struct distr_item *i, u32 node, u32 dtype)
 						TIPC_CLUSTER_SCOPE, node,
 						ntohl(i->ref), ntohl(i->key));
 		if (publ) {
-			tipc_publ_subscribe(publ, node);
+			tipc_publ_subscribe(net, publ, node);
 			return true;
 		}
 	} else if (dtype == WITHDRAWAL) {
@@ -310,7 +315,7 @@ static bool tipc_update_nametbl(struct distr_item *i, u32 node, u32 dtype)
 						node, ntohl(i->ref),
 						ntohl(i->key));
 		if (publ) {
-			tipc_publ_unsubscribe(publ, node);
+			tipc_publ_unsubscribe(net, publ, node);
 			kfree_rcu(publ, rcu);
 			return true;
 		}
@@ -343,7 +348,7 @@ static void tipc_named_add_backlog(struct distr_item *i, u32 type, u32 node)
  * tipc_named_process_backlog - try to process any pending name table updates
  * from the network.
  */
-void tipc_named_process_backlog(void)
+void tipc_named_process_backlog(struct net *net)
 {
 	struct distr_queue_item *e, *tmp;
 	char addr[16];
@@ -351,7 +356,7 @@ void tipc_named_process_backlog(void)
 
 	list_for_each_entry_safe(e, tmp, &tipc_dist_queue, next) {
 		if (time_after(e->expires, now)) {
-			if (!tipc_update_nametbl(&e->i, e->node, e->dtype))
+			if (!tipc_update_nametbl(net, &e->i, e->node, e->dtype))
 				continue;
 		} else {
 			tipc_addr_string_fill(addr, e->node);
@@ -369,7 +374,7 @@ void tipc_named_process_backlog(void)
 /**
  * tipc_named_rcv - process name table update message sent by another node
  */
-void tipc_named_rcv(struct sk_buff *buf)
+void tipc_named_rcv(struct net *net, struct sk_buff *buf)
 {
 	struct tipc_msg *msg = buf_msg(buf);
 	struct distr_item *item = (struct distr_item *)msg_data(msg);
@@ -378,11 +383,11 @@ void tipc_named_rcv(struct sk_buff *buf)
 
 	spin_lock_bh(&tipc_nametbl_lock);
 	while (count--) {
-		if (!tipc_update_nametbl(item, node, msg_type(msg)))
+		if (!tipc_update_nametbl(net, item, node, msg_type(msg)))
 			tipc_named_add_backlog(item, msg_type(msg), node);
 		item++;
 	}
-	tipc_named_process_backlog();
+	tipc_named_process_backlog(net);
 	spin_unlock_bh(&tipc_nametbl_lock);
 	kfree_skb(buf);
 }

commit 97ede29e80eead50d8bd533cf163401b88c027be
Author: Ying Xue <ying.xue@windriver.com>
Date:   Tue Dec 2 15:00:30 2014 +0800

    tipc: convert name table read-write lock to RCU
    
    Convert tipc name table read-write lock to RCU. After this change,
    a new spin lock is used to protect name table on write side while
    RCU is applied on read side.
    
    Signed-off-by: Ying Xue <ying.xue@windriver.com>
    Reviewed-by: Erik Hugne <erik.hugne@ericsson.com>
    Reviewed-by: Jon Maloy <jon.maloy@ericsson.com>
    Tested-by: Erik Hugne <erik.hugne@ericsson.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index ed00929f16c8..ba6083dca95b 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -113,8 +113,8 @@ struct sk_buff *tipc_named_publish(struct publication *publ)
 	struct sk_buff *buf;
 	struct distr_item *item;
 
-	list_add_tail(&publ->local_list,
-		      &tipc_nametbl->publ_list[publ->scope]);
+	list_add_tail_rcu(&publ->local_list,
+			  &tipc_nametbl->publ_list[publ->scope]);
 
 	if (publ->scope == TIPC_NODE_SCOPE)
 		return NULL;
@@ -208,12 +208,12 @@ void tipc_named_node_up(u32 dnode)
 
 	__skb_queue_head_init(&head);
 
-	read_lock_bh(&tipc_nametbl_lock);
+	rcu_read_lock();
 	named_distribute(&head, dnode,
 			 &tipc_nametbl->publ_list[TIPC_CLUSTER_SCOPE]);
 	named_distribute(&head, dnode,
 			 &tipc_nametbl->publ_list[TIPC_ZONE_SCOPE]);
-	read_unlock_bh(&tipc_nametbl_lock);
+	rcu_read_unlock();
 
 	tipc_link_xmit(&head, dnode, dnode);
 }
@@ -260,12 +260,12 @@ static void tipc_publ_purge(struct publication *publ, u32 addr)
 {
 	struct publication *p;
 
-	write_lock_bh(&tipc_nametbl_lock);
+	spin_lock_bh(&tipc_nametbl_lock);
 	p = tipc_nametbl_remove_publ(publ->type, publ->lower,
 				     publ->node, publ->ref, publ->key);
 	if (p)
 		tipc_publ_unsubscribe(p, addr);
-	write_unlock_bh(&tipc_nametbl_lock);
+	spin_unlock_bh(&tipc_nametbl_lock);
 
 	if (p != publ) {
 		pr_err("Unable to remove publication from failed node\n"
@@ -274,7 +274,7 @@ static void tipc_publ_purge(struct publication *publ, u32 addr)
 		       publ->key);
 	}
 
-	kfree(p);
+	kfree_rcu(p, rcu);
 }
 
 void tipc_publ_notify(struct list_head *nsub_list, u32 addr)
@@ -311,7 +311,7 @@ static bool tipc_update_nametbl(struct distr_item *i, u32 node, u32 dtype)
 						ntohl(i->key));
 		if (publ) {
 			tipc_publ_unsubscribe(publ, node);
-			kfree(publ);
+			kfree_rcu(publ, rcu);
 			return true;
 		}
 	} else {
@@ -376,14 +376,14 @@ void tipc_named_rcv(struct sk_buff *buf)
 	u32 count = msg_data_sz(msg) / ITEM_SIZE;
 	u32 node = msg_orignode(msg);
 
-	write_lock_bh(&tipc_nametbl_lock);
+	spin_lock_bh(&tipc_nametbl_lock);
 	while (count--) {
 		if (!tipc_update_nametbl(item, node, msg_type(msg)))
 			tipc_named_add_backlog(item, msg_type(msg), node);
 		item++;
 	}
 	tipc_named_process_backlog();
-	write_unlock_bh(&tipc_nametbl_lock);
+	spin_unlock_bh(&tipc_nametbl_lock);
 	kfree_skb(buf);
 }
 
@@ -399,12 +399,12 @@ void tipc_named_reinit(void)
 	struct publication *publ;
 	int scope;
 
-	write_lock_bh(&tipc_nametbl_lock);
+	spin_lock_bh(&tipc_nametbl_lock);
 
 	for (scope = TIPC_ZONE_SCOPE; scope <= TIPC_NODE_SCOPE; scope++)
-		list_for_each_entry(publ, &tipc_nametbl->publ_list[scope],
-				    local_list)
+		list_for_each_entry_rcu(publ, &tipc_nametbl->publ_list[scope],
+					local_list)
 			publ->node = tipc_own_addr;
 
-	write_unlock_bh(&tipc_nametbl_lock);
+	spin_unlock_bh(&tipc_nametbl_lock);
 }

commit 993bfe5daf34c645a51348facdc7c28c55f488fe
Author: Ying Xue <ying.xue@windriver.com>
Date:   Tue Dec 2 15:00:24 2014 +0800

    tipc: make name table allocated dynamically
    
    Name table locking policy is going to be adjusted from read-write
    lock protection to RCU lock protection in the future commits. But
    its essential precondition is to convert the allocation way of name
    table from static to dynamic mode.
    
    Signed-off-by: Ying Xue <ying.xue@windriver.com>
    Reviewed-by: Erik Hugne <erik.hugne@ericsson.com>
    Reviewed-by: Jon Maloy <jon.maloy@ericsson.com>
    Tested-by: Erik Hugne <erik.hugne@ericsson.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index 628cd85b647e..ed00929f16c8 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -38,34 +38,6 @@
 #include "link.h"
 #include "name_distr.h"
 
-/**
- * struct publ_list - list of publications made by this node
- * @list: circular list of publications
- */
-struct publ_list {
-	struct list_head list;
-};
-
-static struct publ_list publ_zone = {
-	.list = LIST_HEAD_INIT(publ_zone.list),
-};
-
-static struct publ_list publ_cluster = {
-	.list = LIST_HEAD_INIT(publ_cluster.list),
-};
-
-static struct publ_list publ_node = {
-	.list = LIST_HEAD_INIT(publ_node.list),
-};
-
-static struct publ_list *publ_lists[] = {
-	NULL,
-	&publ_zone,	/* publ_lists[TIPC_ZONE_SCOPE]		*/
-	&publ_cluster,	/* publ_lists[TIPC_CLUSTER_SCOPE]	*/
-	&publ_node	/* publ_lists[TIPC_NODE_SCOPE]		*/
-};
-
-
 int sysctl_tipc_named_timeout __read_mostly = 2000;
 
 /**
@@ -141,7 +113,8 @@ struct sk_buff *tipc_named_publish(struct publication *publ)
 	struct sk_buff *buf;
 	struct distr_item *item;
 
-	list_add_tail(&publ->local_list, &publ_lists[publ->scope]->list);
+	list_add_tail(&publ->local_list,
+		      &tipc_nametbl->publ_list[publ->scope]);
 
 	if (publ->scope == TIPC_NODE_SCOPE)
 		return NULL;
@@ -188,7 +161,7 @@ struct sk_buff *tipc_named_withdraw(struct publication *publ)
  * @pls: linked list of publication items to be packed into buffer chain
  */
 static void named_distribute(struct sk_buff_head *list, u32 dnode,
-			     struct publ_list *pls)
+			     struct list_head *pls)
 {
 	struct publication *publ;
 	struct sk_buff *skb = NULL;
@@ -196,7 +169,7 @@ static void named_distribute(struct sk_buff_head *list, u32 dnode,
 	uint msg_dsz = (tipc_node_get_mtu(dnode, 0) / ITEM_SIZE) * ITEM_SIZE;
 	uint msg_rem = msg_dsz;
 
-	list_for_each_entry(publ, &pls->list, local_list) {
+	list_for_each_entry(publ, pls, local_list) {
 		/* Prepare next buffer: */
 		if (!skb) {
 			skb = named_prepare_buf(PUBLICATION, msg_rem, dnode);
@@ -236,8 +209,10 @@ void tipc_named_node_up(u32 dnode)
 	__skb_queue_head_init(&head);
 
 	read_lock_bh(&tipc_nametbl_lock);
-	named_distribute(&head, dnode, &publ_cluster);
-	named_distribute(&head, dnode, &publ_zone);
+	named_distribute(&head, dnode,
+			 &tipc_nametbl->publ_list[TIPC_CLUSTER_SCOPE]);
+	named_distribute(&head, dnode,
+			 &tipc_nametbl->publ_list[TIPC_ZONE_SCOPE]);
 	read_unlock_bh(&tipc_nametbl_lock);
 
 	tipc_link_xmit(&head, dnode, dnode);
@@ -427,7 +402,8 @@ void tipc_named_reinit(void)
 	write_lock_bh(&tipc_nametbl_lock);
 
 	for (scope = TIPC_ZONE_SCOPE; scope <= TIPC_NODE_SCOPE; scope++)
-		list_for_each_entry(publ, &publ_lists[scope]->list, local_list)
+		list_for_each_entry(publ, &tipc_nametbl->publ_list[scope],
+				    local_list)
 			publ->node = tipc_own_addr;
 
 	write_unlock_bh(&tipc_nametbl_lock);

commit 1b61e70ad13e1c907f143c3b0a1694df640639c0
Author: Ying Xue <ying.xue@windriver.com>
Date:   Tue Dec 2 15:00:23 2014 +0800

    tipc: remove size variable from publ_list struct
    
    The size variable is introduced in publ_list struct to help us exactly
    calculate SKB buffer sizes needed by publications when all publications
    in name table are delivered in bulk in named_distribute(). But if
    publication SKB buffer size is assumed to MTU, the size variable in
    publ_list struct can be completely eliminated at the cost of wasting
    a bit memory space for last SKB.
    
    Signed-off-by: Ying Xue <ying.xue@windriver.com>
    Signed-off-by: Tero Aho <tero.aho@coriant.com>
    Reviewed-by: Erik Hugne <erik.hugne@ericsson.com>
    Reviewed-by: Jon Maloy <jon.maloy@ericsson.com>
    Tested-by: Erik Hugne <erik.hugne@ericsson.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index 56248db75274..628cd85b647e 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -41,26 +41,21 @@
 /**
  * struct publ_list - list of publications made by this node
  * @list: circular list of publications
- * @list_size: number of entries in list
  */
 struct publ_list {
 	struct list_head list;
-	u32 size;
 };
 
 static struct publ_list publ_zone = {
 	.list = LIST_HEAD_INIT(publ_zone.list),
-	.size = 0,
 };
 
 static struct publ_list publ_cluster = {
 	.list = LIST_HEAD_INIT(publ_cluster.list),
-	.size = 0,
 };
 
 static struct publ_list publ_node = {
 	.list = LIST_HEAD_INIT(publ_node.list),
-	.size = 0,
 };
 
 static struct publ_list *publ_lists[] = {
@@ -147,7 +142,6 @@ struct sk_buff *tipc_named_publish(struct publication *publ)
 	struct distr_item *item;
 
 	list_add_tail(&publ->local_list, &publ_lists[publ->scope]->list);
-	publ_lists[publ->scope]->size++;
 
 	if (publ->scope == TIPC_NODE_SCOPE)
 		return NULL;
@@ -172,7 +166,6 @@ struct sk_buff *tipc_named_withdraw(struct publication *publ)
 	struct distr_item *item;
 
 	list_del(&publ->local_list);
-	publ_lists[publ->scope]->size--;
 
 	if (publ->scope == TIPC_NODE_SCOPE)
 		return NULL;
@@ -200,16 +193,12 @@ static void named_distribute(struct sk_buff_head *list, u32 dnode,
 	struct publication *publ;
 	struct sk_buff *skb = NULL;
 	struct distr_item *item = NULL;
-	uint dsz = pls->size * ITEM_SIZE;
 	uint msg_dsz = (tipc_node_get_mtu(dnode, 0) / ITEM_SIZE) * ITEM_SIZE;
-	uint rem = dsz;
-	uint msg_rem = 0;
+	uint msg_rem = msg_dsz;
 
 	list_for_each_entry(publ, &pls->list, local_list) {
 		/* Prepare next buffer: */
 		if (!skb) {
-			msg_rem = min_t(uint, rem, msg_dsz);
-			rem -= msg_rem;
 			skb = named_prepare_buf(PUBLICATION, msg_rem, dnode);
 			if (!skb) {
 				pr_warn("Bulk publication failure\n");
@@ -227,8 +216,14 @@ static void named_distribute(struct sk_buff_head *list, u32 dnode,
 		if (!msg_rem) {
 			__skb_queue_tail(list, skb);
 			skb = NULL;
+			msg_rem = msg_dsz;
 		}
 	}
+	if (skb) {
+		msg_set_size(buf_msg(skb), INT_H_SIZE + (msg_dsz - msg_rem));
+		skb_trim(skb, INT_H_SIZE + (msg_dsz - msg_rem));
+		__skb_queue_tail(list, skb);
+	}
 }
 
 /**

commit a6ca109443842e7251c68451f8137ae68ae6d8a6
Author: Ying Xue <ying.xue@windriver.com>
Date:   Wed Nov 26 11:41:55 2014 +0800

    tipc: use generic SKB list APIs to manage TIPC outgoing packet chains
    
    Use standard SKB list APIs associated with struct sk_buff_head to
    manage socket outgoing packet chain and name table outgoing packet
    chain, having relevant code simpler and more readable.
    
    Signed-off-by: Ying Xue <ying.xue@windriver.com>
    Reviewed-by: Jon Maloy <jon.maloy@ericsson.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index 6c2638d3c659..56248db75274 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -114,9 +114,9 @@ static struct sk_buff *named_prepare_buf(u32 type, u32 size, u32 dest)
 	return buf;
 }
 
-void named_cluster_distribute(struct sk_buff *buf)
+void named_cluster_distribute(struct sk_buff *skb)
 {
-	struct sk_buff *obuf;
+	struct sk_buff *oskb;
 	struct tipc_node *node;
 	u32 dnode;
 
@@ -127,15 +127,15 @@ void named_cluster_distribute(struct sk_buff *buf)
 			continue;
 		if (!tipc_node_active_links(node))
 			continue;
-		obuf = skb_copy(buf, GFP_ATOMIC);
-		if (!obuf)
+		oskb = skb_copy(skb, GFP_ATOMIC);
+		if (!oskb)
 			break;
-		msg_set_destnode(buf_msg(obuf), dnode);
-		tipc_link_xmit(obuf, dnode, dnode);
+		msg_set_destnode(buf_msg(oskb), dnode);
+		tipc_link_xmit_skb(oskb, dnode, dnode);
 	}
 	rcu_read_unlock();
 
-	kfree_skb(buf);
+	kfree_skb(skb);
 }
 
 /**
@@ -190,15 +190,15 @@ struct sk_buff *tipc_named_withdraw(struct publication *publ)
 
 /**
  * named_distribute - prepare name info for bulk distribution to another node
- * @msg_list: list of messages (buffers) to be returned from this function
+ * @list: list of messages (buffers) to be returned from this function
  * @dnode: node to be updated
  * @pls: linked list of publication items to be packed into buffer chain
  */
-static void named_distribute(struct list_head *msg_list, u32 dnode,
+static void named_distribute(struct sk_buff_head *list, u32 dnode,
 			     struct publ_list *pls)
 {
 	struct publication *publ;
-	struct sk_buff *buf = NULL;
+	struct sk_buff *skb = NULL;
 	struct distr_item *item = NULL;
 	uint dsz = pls->size * ITEM_SIZE;
 	uint msg_dsz = (tipc_node_get_mtu(dnode, 0) / ITEM_SIZE) * ITEM_SIZE;
@@ -207,15 +207,15 @@ static void named_distribute(struct list_head *msg_list, u32 dnode,
 
 	list_for_each_entry(publ, &pls->list, local_list) {
 		/* Prepare next buffer: */
-		if (!buf) {
+		if (!skb) {
 			msg_rem = min_t(uint, rem, msg_dsz);
 			rem -= msg_rem;
-			buf = named_prepare_buf(PUBLICATION, msg_rem, dnode);
-			if (!buf) {
+			skb = named_prepare_buf(PUBLICATION, msg_rem, dnode);
+			if (!skb) {
 				pr_warn("Bulk publication failure\n");
 				return;
 			}
-			item = (struct distr_item *)msg_data(buf_msg(buf));
+			item = (struct distr_item *)msg_data(buf_msg(skb));
 		}
 
 		/* Pack publication into message: */
@@ -225,8 +225,8 @@ static void named_distribute(struct list_head *msg_list, u32 dnode,
 
 		/* Append full buffer to list: */
 		if (!msg_rem) {
-			list_add_tail((struct list_head *)buf, msg_list);
-			buf = NULL;
+			__skb_queue_tail(list, skb);
+			skb = NULL;
 		}
 	}
 }
@@ -236,18 +236,16 @@ static void named_distribute(struct list_head *msg_list, u32 dnode,
  */
 void tipc_named_node_up(u32 dnode)
 {
-	LIST_HEAD(msg_list);
-	struct sk_buff *buf_chain;
+	struct sk_buff_head head;
+
+	__skb_queue_head_init(&head);
 
 	read_lock_bh(&tipc_nametbl_lock);
-	named_distribute(&msg_list, dnode, &publ_cluster);
-	named_distribute(&msg_list, dnode, &publ_zone);
+	named_distribute(&head, dnode, &publ_cluster);
+	named_distribute(&head, dnode, &publ_zone);
 	read_unlock_bh(&tipc_nametbl_lock);
 
-	/* Convert circular list to linear list and send: */
-	buf_chain = (struct sk_buff *)msg_list.next;
-	((struct sk_buff *)msg_list.prev)->next = NULL;
-	tipc_link_xmit(buf_chain, dnode, dnode);
+	tipc_link_xmit(&head, dnode, dnode);
 }
 
 static void tipc_publ_subscribe(struct publication *publ, u32 addr)

commit a8f48af587b0f257c49dce5b49a62554a4b8627e
Author: Ying Xue <ying.xue@windriver.com>
Date:   Wed Nov 26 11:41:45 2014 +0800

    tipc: remove node subscription infrastructure
    
    The node subscribe infrastructure represents a virtual base class, so
    its users, such as struct tipc_port and struct publication, can derive
    its implemented functionalities. However, after the removal of struct
    tipc_port, struct publication is left as its only single user now. So
    defining an abstract infrastructure for one user becomes no longer
    reasonable. If corresponding new functions associated with the
    infrastructure are moved to name_table.c file, the node subscription
    infrastructure can be removed as well.
    
    Signed-off-by: Ying Xue <ying.xue@windriver.com>
    Reviewed-by: Jon Maloy <jon.maloy@ericsson.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index 376d2bb51d8d..6c2638d3c659 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -250,13 +250,45 @@ void tipc_named_node_up(u32 dnode)
 	tipc_link_xmit(buf_chain, dnode, dnode);
 }
 
+static void tipc_publ_subscribe(struct publication *publ, u32 addr)
+{
+	struct tipc_node *node;
+
+	if (in_own_node(addr))
+		return;
+
+	node = tipc_node_find(addr);
+	if (!node) {
+		pr_warn("Node subscription rejected, unknown node 0x%x\n",
+			addr);
+		return;
+	}
+
+	tipc_node_lock(node);
+	list_add_tail(&publ->nodesub_list, &node->publ_list);
+	tipc_node_unlock(node);
+}
+
+static void tipc_publ_unsubscribe(struct publication *publ, u32 addr)
+{
+	struct tipc_node *node;
+
+	node = tipc_node_find(addr);
+	if (!node)
+		return;
+
+	tipc_node_lock(node);
+	list_del_init(&publ->nodesub_list);
+	tipc_node_unlock(node);
+}
+
 /**
- * named_purge_publ - remove publication associated with a failed node
+ * tipc_publ_purge - remove publication associated with a failed node
  *
  * Invoked for each publication issued by a newly failed node.
  * Removes publication structure from name table & deletes it.
  */
-static void named_purge_publ(struct publication *publ)
+static void tipc_publ_purge(struct publication *publ, u32 addr)
 {
 	struct publication *p;
 
@@ -264,7 +296,7 @@ static void named_purge_publ(struct publication *publ)
 	p = tipc_nametbl_remove_publ(publ->type, publ->lower,
 				     publ->node, publ->ref, publ->key);
 	if (p)
-		tipc_nodesub_unsubscribe(&p->subscr);
+		tipc_publ_unsubscribe(p, addr);
 	write_unlock_bh(&tipc_nametbl_lock);
 
 	if (p != publ) {
@@ -277,6 +309,14 @@ static void named_purge_publ(struct publication *publ)
 	kfree(p);
 }
 
+void tipc_publ_notify(struct list_head *nsub_list, u32 addr)
+{
+	struct publication *publ, *tmp;
+
+	list_for_each_entry_safe(publ, tmp, nsub_list, nodesub_list)
+		tipc_publ_purge(publ, addr);
+}
+
 /**
  * tipc_update_nametbl - try to process a nametable update and notify
  *			 subscribers
@@ -294,9 +334,7 @@ static bool tipc_update_nametbl(struct distr_item *i, u32 node, u32 dtype)
 						TIPC_CLUSTER_SCOPE, node,
 						ntohl(i->ref), ntohl(i->key));
 		if (publ) {
-			tipc_nodesub_subscribe(&publ->subscr, node, publ,
-					       (net_ev_handler)
-					       named_purge_publ);
+			tipc_publ_subscribe(publ, node);
 			return true;
 		}
 	} else if (dtype == WITHDRAWAL) {
@@ -304,7 +342,7 @@ static bool tipc_update_nametbl(struct distr_item *i, u32 node, u32 dtype)
 						node, ntohl(i->ref),
 						ntohl(i->key));
 		if (publ) {
-			tipc_nodesub_unsubscribe(&publ->subscr);
+			tipc_publ_unsubscribe(publ, node);
 			kfree(publ);
 			return true;
 		}

commit 0fc4dffad13e81deb3bf72e74cac292172df5285
Author: Erik Hugne <erik.hugne@ericsson.com>
Date:   Wed Sep 10 14:02:50 2014 +0200

    tipc: fix sparse warnings
    
    This fixes the following sparse warnings:
    sparse: symbol 'tipc_update_nametbl' was not declared. Should it be static?
    Also, the function is changed to return bool upon success, rather than a
    potentially freed pointer.
    
    Signed-off-by: Erik Hugne <erik.hugne@ericsson.com>
    Reported-by: Dan Carpenter <dan.carpenter@oracle.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index 780ef710a849..376d2bb51d8d 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -284,8 +284,7 @@ static void named_purge_publ(struct publication *publ)
  * tipc_nametbl_lock must be held.
  * Returns the publication item if successful, otherwise NULL.
  */
-struct publication *tipc_update_nametbl(struct distr_item *i, u32 node,
-					u32 dtype)
+static bool tipc_update_nametbl(struct distr_item *i, u32 node, u32 dtype)
 {
 	struct publication *publ = NULL;
 
@@ -298,6 +297,7 @@ struct publication *tipc_update_nametbl(struct distr_item *i, u32 node,
 			tipc_nodesub_subscribe(&publ->subscr, node, publ,
 					       (net_ev_handler)
 					       named_purge_publ);
+			return true;
 		}
 	} else if (dtype == WITHDRAWAL) {
 		publ = tipc_nametbl_remove_publ(ntohl(i->type), ntohl(i->lower),
@@ -306,11 +306,12 @@ struct publication *tipc_update_nametbl(struct distr_item *i, u32 node,
 		if (publ) {
 			tipc_nodesub_unsubscribe(&publ->subscr);
 			kfree(publ);
+			return true;
 		}
 	} else {
 		pr_warn("Unrecognized name table message received\n");
 	}
-	return publ;
+	return false;
 }
 
 /**

commit a5325ae5b8bff051933a754db7727fc9823e6414
Author: Erik Hugne <erik.hugne@ericsson.com>
Date:   Thu Aug 28 09:08:47 2014 +0200

    tipc: add name distributor resiliency queue
    
    TIPC name table updates are distributed asynchronously in a cluster,
    entailing a risk of certain race conditions. E.g., if two nodes
    simultaneously issue conflicting (overlapping) publications, this may
    not be detected until both publications have reached a third node, in
    which case one of the publications will be silently dropped on that
    node. Hence, we end up with an inconsistent name table.
    
    In most cases this conflict is just a temporary race, e.g., one
    node is issuing a publication under the assumption that a previous,
    conflicting, publication has already been withdrawn by the other node.
    However, because of the (rtt related) distributed update delay, this
    may not yet hold true on all nodes. The symptom of this failure is a
    syslog message: "tipc: Cannot publish {%u,%u,%u}, overlap error".
    
    In this commit we add a resiliency queue at the receiving end of
    the name table distributor. When insertion of an arriving publication
    fails, we retain it in this queue for a short amount of time, assuming
    that another update will arrive very soon and clear the conflict. If so
    happens, we insert the publication, otherwise we drop it.
    
    The (configurable) retention value defaults to 2000 ms. Knowing from
    experience that the situation described above is extremely rare, there
    is no risk that the queue will accumulate any large number of items.
    
    Signed-off-by: Erik Hugne <erik.hugne@ericsson.com>
    Signed-off-by: Jon Maloy <jon.maloy@ericsson.com>
    Acked-by: Ying Xue <ying.xue@windriver.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index 0591f33b8384..780ef710a849 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -1,7 +1,7 @@
 /*
  * net/tipc/name_distr.c: TIPC name distribution code
  *
- * Copyright (c) 2000-2006, Ericsson AB
+ * Copyright (c) 2000-2006, 2014, Ericsson AB
  * Copyright (c) 2005, 2010-2011, Wind River Systems
  * All rights reserved.
  *
@@ -71,6 +71,21 @@ static struct publ_list *publ_lists[] = {
 };
 
 
+int sysctl_tipc_named_timeout __read_mostly = 2000;
+
+/**
+ * struct tipc_dist_queue - queue holding deferred name table updates
+ */
+static struct list_head tipc_dist_queue = LIST_HEAD_INIT(tipc_dist_queue);
+
+struct distr_queue_item {
+	struct distr_item i;
+	u32 dtype;
+	u32 node;
+	unsigned long expires;
+	struct list_head next;
+};
+
 /**
  * publ_to_item - add publication info to a publication message
  */
@@ -298,6 +313,52 @@ struct publication *tipc_update_nametbl(struct distr_item *i, u32 node,
 	return publ;
 }
 
+/**
+ * tipc_named_add_backlog - add a failed name table update to the backlog
+ *
+ */
+static void tipc_named_add_backlog(struct distr_item *i, u32 type, u32 node)
+{
+	struct distr_queue_item *e;
+	unsigned long now = get_jiffies_64();
+
+	e = kzalloc(sizeof(*e), GFP_ATOMIC);
+	if (!e)
+		return;
+	e->dtype = type;
+	e->node = node;
+	e->expires = now + msecs_to_jiffies(sysctl_tipc_named_timeout);
+	memcpy(e, i, sizeof(*i));
+	list_add_tail(&e->next, &tipc_dist_queue);
+}
+
+/**
+ * tipc_named_process_backlog - try to process any pending name table updates
+ * from the network.
+ */
+void tipc_named_process_backlog(void)
+{
+	struct distr_queue_item *e, *tmp;
+	char addr[16];
+	unsigned long now = get_jiffies_64();
+
+	list_for_each_entry_safe(e, tmp, &tipc_dist_queue, next) {
+		if (time_after(e->expires, now)) {
+			if (!tipc_update_nametbl(&e->i, e->node, e->dtype))
+				continue;
+		} else {
+			tipc_addr_string_fill(addr, e->node);
+			pr_warn_ratelimited("Dropping name table update (%d) of {%u, %u, %u} from %s key=%u\n",
+					    e->dtype, ntohl(e->i.type),
+					    ntohl(e->i.lower),
+					    ntohl(e->i.upper),
+					    addr, ntohl(e->i.key));
+		}
+		list_del(&e->next);
+		kfree(e);
+	}
+}
+
 /**
  * tipc_named_rcv - process name table update message sent by another node
  */
@@ -306,13 +367,15 @@ void tipc_named_rcv(struct sk_buff *buf)
 	struct tipc_msg *msg = buf_msg(buf);
 	struct distr_item *item = (struct distr_item *)msg_data(msg);
 	u32 count = msg_data_sz(msg) / ITEM_SIZE;
+	u32 node = msg_orignode(msg);
 
 	write_lock_bh(&tipc_nametbl_lock);
 	while (count--) {
-		tipc_update_nametbl(item, msg_orignode(msg),
-				    msg_type(msg));
+		if (!tipc_update_nametbl(item, node, msg_type(msg)))
+			tipc_named_add_backlog(item, msg_type(msg), node);
 		item++;
 	}
+	tipc_named_process_backlog();
 	write_unlock_bh(&tipc_nametbl_lock);
 	kfree_skb(buf);
 }

commit f4ad8a4b8b9f490a15c3239e0d6ac99e7e438d34
Author: Erik Hugne <erik.hugne@ericsson.com>
Date:   Thu Aug 28 09:08:46 2014 +0200

    tipc: refactor name table updates out of named packet receive routine
    
    We need to perform the same actions when processing deferred name
    table updates, so this functionality is moved to a separate
    function.
    
    Signed-off-by: Erik Hugne <erik.hugne@ericsson.com>
    Signed-off-by: Jon Maloy <jon.maloy@ericsson.com>
    Acked-by: Ying Xue <ying.xue@windriver.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index dcc15bcd5692..0591f33b8384 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -262,53 +262,55 @@ static void named_purge_publ(struct publication *publ)
 	kfree(p);
 }
 
+/**
+ * tipc_update_nametbl - try to process a nametable update and notify
+ *			 subscribers
+ *
+ * tipc_nametbl_lock must be held.
+ * Returns the publication item if successful, otherwise NULL.
+ */
+struct publication *tipc_update_nametbl(struct distr_item *i, u32 node,
+					u32 dtype)
+{
+	struct publication *publ = NULL;
+
+	if (dtype == PUBLICATION) {
+		publ = tipc_nametbl_insert_publ(ntohl(i->type), ntohl(i->lower),
+						ntohl(i->upper),
+						TIPC_CLUSTER_SCOPE, node,
+						ntohl(i->ref), ntohl(i->key));
+		if (publ) {
+			tipc_nodesub_subscribe(&publ->subscr, node, publ,
+					       (net_ev_handler)
+					       named_purge_publ);
+		}
+	} else if (dtype == WITHDRAWAL) {
+		publ = tipc_nametbl_remove_publ(ntohl(i->type), ntohl(i->lower),
+						node, ntohl(i->ref),
+						ntohl(i->key));
+		if (publ) {
+			tipc_nodesub_unsubscribe(&publ->subscr);
+			kfree(publ);
+		}
+	} else {
+		pr_warn("Unrecognized name table message received\n");
+	}
+	return publ;
+}
+
 /**
  * tipc_named_rcv - process name table update message sent by another node
  */
 void tipc_named_rcv(struct sk_buff *buf)
 {
-	struct publication *publ;
 	struct tipc_msg *msg = buf_msg(buf);
 	struct distr_item *item = (struct distr_item *)msg_data(msg);
 	u32 count = msg_data_sz(msg) / ITEM_SIZE;
 
 	write_lock_bh(&tipc_nametbl_lock);
 	while (count--) {
-		if (msg_type(msg) == PUBLICATION) {
-			publ = tipc_nametbl_insert_publ(ntohl(item->type),
-							ntohl(item->lower),
-							ntohl(item->upper),
-							TIPC_CLUSTER_SCOPE,
-							msg_orignode(msg),
-							ntohl(item->ref),
-							ntohl(item->key));
-			if (publ) {
-				tipc_nodesub_subscribe(&publ->subscr,
-						       msg_orignode(msg),
-						       publ,
-						       (net_ev_handler)
-						       named_purge_publ);
-			}
-		} else if (msg_type(msg) == WITHDRAWAL) {
-			publ = tipc_nametbl_remove_publ(ntohl(item->type),
-							ntohl(item->lower),
-							msg_orignode(msg),
-							ntohl(item->ref),
-							ntohl(item->key));
-
-			if (publ) {
-				tipc_nodesub_unsubscribe(&publ->subscr);
-				kfree(publ);
-			} else {
-				pr_err("Unable to remove publication by node 0x%x\n"
-				       " (type=%u, lower=%u, ref=%u, key=%u)\n",
-				       msg_orignode(msg), ntohl(item->type),
-				       ntohl(item->lower), ntohl(item->ref),
-				       ntohl(item->key));
-			}
-		} else {
-			pr_warn("Unrecognized name table message received\n");
-		}
+		tipc_update_nametbl(item, msg_orignode(msg),
+				    msg_type(msg));
 		item++;
 	}
 	write_unlock_bh(&tipc_nametbl_lock);

commit 9fbfb8b120bd4fe89cd70d6c8841e6e1cfab2609
Author: Jon Paul Maloy <jon.maloy@ericsson.com>
Date:   Wed Jul 16 20:41:03 2014 -0400

    tipc: rename temporarily named functions
    
    After the previous commit, we can now give the functions with temporary
    names, such as tipc_link_xmit2(), tipc_msg_build2() etc., their proper
    names.
    
    There are no functional changes in this commit.
    
    Signed-off-by: Jon Maloy <jon.maloy@ericsson.com>
    Reviewed-by: Erik Hugne <erik.hugne@ericsson.com>
    Reviewed-by: Ying Xue <ying.xue@windriver.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index d16f9475fa76..dcc15bcd5692 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -116,7 +116,7 @@ void named_cluster_distribute(struct sk_buff *buf)
 		if (!obuf)
 			break;
 		msg_set_destnode(buf_msg(obuf), dnode);
-		tipc_link_xmit2(obuf, dnode, dnode);
+		tipc_link_xmit(obuf, dnode, dnode);
 	}
 	rcu_read_unlock();
 
@@ -232,7 +232,7 @@ void tipc_named_node_up(u32 dnode)
 	/* Convert circular list to linear list and send: */
 	buf_chain = (struct sk_buff *)msg_list.next;
 	((struct sk_buff *)msg_list.prev)->next = NULL;
-	tipc_link_xmit2(buf_chain, dnode, dnode);
+	tipc_link_xmit(buf_chain, dnode, dnode);
 }
 
 /**

commit dbdf6d24ad37d63938f29a2d134a1a9f6e9e673c
Author: Jon Paul Maloy <jon.maloy@ericsson.com>
Date:   Wed Jul 16 20:40:58 2014 -0400

    tipc: make name table distributor use new send function
    
    In a previous commit series ("tipc: new unicast transmission code")
    we introduced a new message sending function, tipc_link_xmit2(),
    and moved the unicast data users over to use that function. We now
    let the internal name table distributor do the same.
    
    The interaction between the name distributor and the node/link
    layer also becomes significantly simpler, so we can eliminate
    the function tipc_link_names_xmit().
    
    Signed-off-by: Jon Maloy <jon.maloy@ericsson.com>
    Reviewed-by: Erik Hugne <erik.hugne@ericsson.com>
    Reviewed-by: Ying Xue <ying.xue@windriver.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index 8ce730984aa1..d16f9475fa76 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -101,24 +101,22 @@ static struct sk_buff *named_prepare_buf(u32 type, u32 size, u32 dest)
 
 void named_cluster_distribute(struct sk_buff *buf)
 {
-	struct sk_buff *buf_copy;
-	struct tipc_node *n_ptr;
-	struct tipc_link *l_ptr;
+	struct sk_buff *obuf;
+	struct tipc_node *node;
+	u32 dnode;
 
 	rcu_read_lock();
-	list_for_each_entry_rcu(n_ptr, &tipc_node_list, list) {
-		tipc_node_lock(n_ptr);
-		l_ptr = n_ptr->active_links[n_ptr->addr & 1];
-		if (l_ptr) {
-			buf_copy = skb_copy(buf, GFP_ATOMIC);
-			if (!buf_copy) {
-				tipc_node_unlock(n_ptr);
-				break;
-			}
-			msg_set_destnode(buf_msg(buf_copy), n_ptr->addr);
-			__tipc_link_xmit(l_ptr, buf_copy);
-		}
-		tipc_node_unlock(n_ptr);
+	list_for_each_entry_rcu(node, &tipc_node_list, list) {
+		dnode = node->addr;
+		if (in_own_node(dnode))
+			continue;
+		if (!tipc_node_active_links(node))
+			continue;
+		obuf = skb_copy(buf, GFP_ATOMIC);
+		if (!obuf)
+			break;
+		msg_set_destnode(buf_msg(obuf), dnode);
+		tipc_link_xmit2(obuf, dnode, dnode);
 	}
 	rcu_read_unlock();
 
@@ -175,34 +173,44 @@ struct sk_buff *tipc_named_withdraw(struct publication *publ)
 	return buf;
 }
 
-/*
+/**
  * named_distribute - prepare name info for bulk distribution to another node
+ * @msg_list: list of messages (buffers) to be returned from this function
+ * @dnode: node to be updated
+ * @pls: linked list of publication items to be packed into buffer chain
  */
-static void named_distribute(struct list_head *message_list, u32 node,
-			     struct publ_list *pls, u32 max_item_buf)
+static void named_distribute(struct list_head *msg_list, u32 dnode,
+			     struct publ_list *pls)
 {
 	struct publication *publ;
 	struct sk_buff *buf = NULL;
 	struct distr_item *item = NULL;
-	u32 left = 0;
-	u32 rest = pls->size * ITEM_SIZE;
+	uint dsz = pls->size * ITEM_SIZE;
+	uint msg_dsz = (tipc_node_get_mtu(dnode, 0) / ITEM_SIZE) * ITEM_SIZE;
+	uint rem = dsz;
+	uint msg_rem = 0;
 
 	list_for_each_entry(publ, &pls->list, local_list) {
+		/* Prepare next buffer: */
 		if (!buf) {
-			left = (rest <= max_item_buf) ? rest : max_item_buf;
-			rest -= left;
-			buf = named_prepare_buf(PUBLICATION, left, node);
+			msg_rem = min_t(uint, rem, msg_dsz);
+			rem -= msg_rem;
+			buf = named_prepare_buf(PUBLICATION, msg_rem, dnode);
 			if (!buf) {
 				pr_warn("Bulk publication failure\n");
 				return;
 			}
 			item = (struct distr_item *)msg_data(buf_msg(buf));
 		}
+
+		/* Pack publication into message: */
 		publ_to_item(item, publ);
 		item++;
-		left -= ITEM_SIZE;
-		if (!left) {
-			list_add_tail((struct list_head *)buf, message_list);
+		msg_rem -= ITEM_SIZE;
+
+		/* Append full buffer to list: */
+		if (!msg_rem) {
+			list_add_tail((struct list_head *)buf, msg_list);
 			buf = NULL;
 		}
 	}
@@ -211,16 +219,20 @@ static void named_distribute(struct list_head *message_list, u32 node,
 /**
  * tipc_named_node_up - tell specified node about all publications by this node
  */
-void tipc_named_node_up(u32 max_item_buf, u32 node)
+void tipc_named_node_up(u32 dnode)
 {
-	LIST_HEAD(message_list);
+	LIST_HEAD(msg_list);
+	struct sk_buff *buf_chain;
 
 	read_lock_bh(&tipc_nametbl_lock);
-	named_distribute(&message_list, node, &publ_cluster, max_item_buf);
-	named_distribute(&message_list, node, &publ_zone, max_item_buf);
+	named_distribute(&msg_list, dnode, &publ_cluster);
+	named_distribute(&msg_list, dnode, &publ_zone);
 	read_unlock_bh(&tipc_nametbl_lock);
 
-	tipc_link_names_xmit(&message_list, node);
+	/* Convert circular list to linear list and send: */
+	buf_chain = (struct sk_buff *)msg_list.next;
+	((struct sk_buff *)msg_list.prev)->next = NULL;
+	tipc_link_xmit2(buf_chain, dnode, dnode);
 }
 
 /**

commit ca0c42732c512a12fabe677594840f31861dd31a
Author: Ying Xue <ying.xue@windriver.com>
Date:   Mon May 5 08:56:14 2014 +0800

    tipc: avoid to asynchronously deliver name tables to peer node
    
    Postpone the actions of delivering name tables until after node
    lock is released, avoiding to do it under asynchronous context.
    
    Signed-off-by: Ying Xue <ying.xue@windriver.com>
    Reviewed-by: Erik Hugne <erik.hugne@ericsson.com>
    Reviewed-by: Jon Maloy <jon.maloy@ericsson.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index 8465263246c3..8ce730984aa1 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -38,34 +38,6 @@
 #include "link.h"
 #include "name_distr.h"
 
-#define ITEM_SIZE sizeof(struct distr_item)
-
-/**
- * struct distr_item - publication info distributed to other nodes
- * @type: name sequence type
- * @lower: name sequence lower bound
- * @upper: name sequence upper bound
- * @ref: publishing port reference
- * @key: publication key
- *
- * ===> All fields are stored in network byte order. <===
- *
- * First 3 fields identify (name or) name sequence being published.
- * Reference field uniquely identifies port that published name sequence.
- * Key field uniquely identifies publication, in the event a port has
- * multiple publications of the same name sequence.
- *
- * Note: There is no field that identifies the publishing node because it is
- * the same for all items contained within a publication message.
- */
-struct distr_item {
-	__be32 type;
-	__be32 lower;
-	__be32 upper;
-	__be32 ref;
-	__be32 key;
-};
-
 /**
  * struct publ_list - list of publications made by this node
  * @list: circular list of publications
@@ -239,29 +211,9 @@ static void named_distribute(struct list_head *message_list, u32 node,
 /**
  * tipc_named_node_up - tell specified node about all publications by this node
  */
-void tipc_named_node_up(unsigned long nodearg)
+void tipc_named_node_up(u32 max_item_buf, u32 node)
 {
-	struct tipc_node *n_ptr;
-	struct tipc_link *l_ptr;
-	struct list_head message_list;
-	u32 node = (u32)nodearg;
-	u32 max_item_buf = 0;
-
-	/* compute maximum amount of publication data to send per message */
-	n_ptr = tipc_node_find(node);
-	if (n_ptr) {
-		tipc_node_lock(n_ptr);
-		l_ptr = n_ptr->active_links[0];
-		if (l_ptr)
-			max_item_buf = ((l_ptr->max_pkt - INT_H_SIZE) /
-				ITEM_SIZE) * ITEM_SIZE;
-		tipc_node_unlock(n_ptr);
-	}
-	if (!max_item_buf)
-		return;
-
-	/* create list of publication messages, then send them as a unit */
-	INIT_LIST_HEAD(&message_list);
+	LIST_HEAD(message_list);
 
 	read_lock_bh(&tipc_nametbl_lock);
 	named_distribute(&message_list, node, &publ_cluster, max_item_buf);

commit 5356f3d7d48af72eb2a14b643d5563f068c44fe0
Author: Ying Xue <ying.xue@windriver.com>
Date:   Mon May 5 08:56:09 2014 +0800

    tipc: always use tipc_node_lock() to hold node lock
    
    Although we obtain node lock with tipc_node_lock() in most time, there
    are still places where we directly use native spin lock interface
    to grab node lock. But as we will do more jobs in the future when node
    lock is released, we should ensure that tipc_node_lock() is always
    called when node lock is taken.
    
    Signed-off-by: Ying Xue <ying.xue@windriver.com>
    Reviewed-by: Erik Hugne <erik.hugne@ericsson.com>
    Reviewed-by: Jon Maloy <jon.maloy@ericsson.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index 974a73f3d876..8465263246c3 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -135,18 +135,18 @@ void named_cluster_distribute(struct sk_buff *buf)
 
 	rcu_read_lock();
 	list_for_each_entry_rcu(n_ptr, &tipc_node_list, list) {
-		spin_lock_bh(&n_ptr->lock);
+		tipc_node_lock(n_ptr);
 		l_ptr = n_ptr->active_links[n_ptr->addr & 1];
 		if (l_ptr) {
 			buf_copy = skb_copy(buf, GFP_ATOMIC);
 			if (!buf_copy) {
-				spin_unlock_bh(&n_ptr->lock);
+				tipc_node_unlock(n_ptr);
 				break;
 			}
 			msg_set_destnode(buf_msg(buf_copy), n_ptr->addr);
 			__tipc_link_xmit(l_ptr, buf_copy);
 		}
-		spin_unlock_bh(&n_ptr->lock);
+		tipc_node_unlock(n_ptr);
 	}
 	rcu_read_unlock();
 

commit eab8c045732635e3833a5d58b17c6da08ff71f9e
Author: Ying Xue <ying.xue@windriver.com>
Date:   Mon Apr 28 18:00:10 2014 +0800

    tipc: move the delivery of named messages out of nametbl lock
    
    Commit a89778d8baf19cd7e728d81121a294a06cedaad1 ("tipc: add support
    for link state subscriptions") introduced below possible deadlock
    scenario:
    
           CPU0                          CPU1
    T0:   tipc_publish()                 link_timeout()
    T1:   tipc_nametbl_publish()         [grab node lock]*
    T2:   [grab nametbl write lock]*     link_state_event()
    T3:   named_cluster_distribute()     link_activate()
    T4:   [grab node lock]*              tipc_node_link_up()
    T5:                                  tipc_nametbl_publish()
    T6:                                  [grab nametble write lock]*
    
    The opposite order of holding nametbl write lock and node lock on
    above two different paths may result in a deadlock. If we move the
    the delivery of named messages via link out of name nametbl lock,
    the reverse order of holding locks will be eliminated, as a result,
    the deadlock will be killed as well.
    
    Signed-off-by: Ying Xue <ying.xue@windriver.com>
    Reviewed-by: Erik Hugne <erik.hugne@ericsson.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index 36a72822601c..974a73f3d876 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -127,7 +127,7 @@ static struct sk_buff *named_prepare_buf(u32 type, u32 size, u32 dest)
 	return buf;
 }
 
-static void named_cluster_distribute(struct sk_buff *buf)
+void named_cluster_distribute(struct sk_buff *buf)
 {
 	struct sk_buff *buf_copy;
 	struct tipc_node *n_ptr;
@@ -156,7 +156,7 @@ static void named_cluster_distribute(struct sk_buff *buf)
 /**
  * tipc_named_publish - tell other nodes about a new publication by this node
  */
-void tipc_named_publish(struct publication *publ)
+struct sk_buff *tipc_named_publish(struct publication *publ)
 {
 	struct sk_buff *buf;
 	struct distr_item *item;
@@ -165,23 +165,23 @@ void tipc_named_publish(struct publication *publ)
 	publ_lists[publ->scope]->size++;
 
 	if (publ->scope == TIPC_NODE_SCOPE)
-		return;
+		return NULL;
 
 	buf = named_prepare_buf(PUBLICATION, ITEM_SIZE, 0);
 	if (!buf) {
 		pr_warn("Publication distribution failure\n");
-		return;
+		return NULL;
 	}
 
 	item = (struct distr_item *)msg_data(buf_msg(buf));
 	publ_to_item(item, publ);
-	named_cluster_distribute(buf);
+	return buf;
 }
 
 /**
  * tipc_named_withdraw - tell other nodes about a withdrawn publication by this node
  */
-void tipc_named_withdraw(struct publication *publ)
+struct sk_buff *tipc_named_withdraw(struct publication *publ)
 {
 	struct sk_buff *buf;
 	struct distr_item *item;
@@ -190,17 +190,17 @@ void tipc_named_withdraw(struct publication *publ)
 	publ_lists[publ->scope]->size--;
 
 	if (publ->scope == TIPC_NODE_SCOPE)
-		return;
+		return NULL;
 
 	buf = named_prepare_buf(WITHDRAWAL, ITEM_SIZE, 0);
 	if (!buf) {
 		pr_warn("Withdrawal distribution failure\n");
-		return;
+		return NULL;
 	}
 
 	item = (struct distr_item *)msg_data(buf_msg(buf));
 	publ_to_item(item, publ);
-	named_cluster_distribute(buf);
+	return buf;
 }
 
 /*

commit 7216cd949c9bd56a4ccd952c624ab68f8c9aa0a4
Author: Ying Xue <ying.xue@windriver.com>
Date:   Mon Apr 21 10:55:48 2014 +0800

    tipc: purge tipc_net_lock lock
    
    Now tipc routing hierarchy comprises the structures 'node', 'link'and
    'bearer'. The whole hierarchy is protected by a big read/write lock,
    tipc_net_lock, to ensure that nothing is added or removed while code
    is accessing any of these structures. Obviously the locking policy
    makes node, link and bearer components closely bound together so that
    their relationship becomes unnecessarily complex. In the worst case,
    such locking policy not only has a negative influence on performance,
    but also it's prone to lead to deadlock occasionally.
    
    In order o decouple the complex relationship between bearer and node
    as well as link, the locking policy is adjusted as follows:
    
    - Bearer level
      RTNL lock is used on update side, and RCU is used on read side.
      Meanwhile, all bearer instances including broadcast bearer are
      saved into bearer_list array.
    
    - Node and link level
      All node instances are saved into two tipc_node_list and node_htable
      lists. The two lists are protected by node_list_lock on write side,
      and they are guarded with RCU lock on read side. All members in node
      structure including link instances are protected by node spin lock.
    
    - The relationship between bearer and node
      When link accesses bearer, it first needs to find the bearer with
      its bearer identity from the bearer_list array. When bearer accesses
      node, it can iterate the node_htable hash list with the node
      address to find the corresponding node.
    
    In the new locking policy, every component has its private locking
    solution and the relationship between bearer and node is very simple,
    that is, they can find each other with node address or bearer identity
    from node_htable hash list or bearer_list array.
    
    Until now above all changes have been done, so tipc_net_lock can be
    removed safely.
    
    Signed-off-by: Ying Xue <ying.xue@windriver.com>
    Reviewed-by: Jon Maloy <jon.maloy@ericsson.com>
    Reviewed-by: Erik Hugne <erik.hugne@ericsson.com>
    Tested-by: Erik Hugne <erik.hugne@ericsson.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index aff8041dc157..36a72822601c 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -248,7 +248,6 @@ void tipc_named_node_up(unsigned long nodearg)
 	u32 max_item_buf = 0;
 
 	/* compute maximum amount of publication data to send per message */
-	read_lock_bh(&tipc_net_lock);
 	n_ptr = tipc_node_find(node);
 	if (n_ptr) {
 		tipc_node_lock(n_ptr);
@@ -258,7 +257,6 @@ void tipc_named_node_up(unsigned long nodearg)
 				ITEM_SIZE) * ITEM_SIZE;
 		tipc_node_unlock(n_ptr);
 	}
-	read_unlock_bh(&tipc_net_lock);
 	if (!max_item_buf)
 		return;
 

commit 6c7a762e70637a256229f9dc9ca793908e8bd01b
Author: Ying Xue <ying.xue@windriver.com>
Date:   Thu Mar 27 12:54:37 2014 +0800

    tipc: tipc: convert node list and node hlist to RCU lists
    
    Convert tipc_node_list list and node_htable hash list to RCU lists.
    On read side, the two lists are protected with RCU read lock, and
    on update side, node_list_lock is applied to them.
    
    Signed-off-by: Ying Xue <ying.xue@windriver.com>
    Reviewed-by: Erik Hugne <erik.hugne@ericsson.com>
    Reviewed-by: Jon Maloy <jon.maloy@ericsson.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index c5904d196cd3..aff8041dc157 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -133,8 +133,8 @@ static void named_cluster_distribute(struct sk_buff *buf)
 	struct tipc_node *n_ptr;
 	struct tipc_link *l_ptr;
 
-	read_lock_bh(&tipc_net_lock);
-	list_for_each_entry(n_ptr, &tipc_node_list, list) {
+	rcu_read_lock();
+	list_for_each_entry_rcu(n_ptr, &tipc_node_list, list) {
 		spin_lock_bh(&n_ptr->lock);
 		l_ptr = n_ptr->active_links[n_ptr->addr & 1];
 		if (l_ptr) {
@@ -148,7 +148,7 @@ static void named_cluster_distribute(struct sk_buff *buf)
 		}
 		spin_unlock_bh(&n_ptr->lock);
 	}
-	read_unlock_bh(&tipc_net_lock);
+	rcu_read_unlock();
 
 	kfree_skb(buf);
 }

commit 78dfb789b69f161703ef322a0c2e3e61c7f7573a
Author: Ying Xue <ying.xue@windriver.com>
Date:   Thu Mar 27 12:54:32 2014 +0800

    tipc: acquire necessary locks in named_cluster_distribute routine
    
    The 'tipc_node_list' is guarded by tipc_net_lock and 'links' array
    defined in 'tipc_node' structure is protected by node lock as well.
    Without acquiring the two locks in named_cluster_distribute() a fatal
    oops may happen in case that a destroyed link might be got and then
    accessed. Therefore, above mentioned two locks must be held in
    named_cluster_distribute() to prevent the issue from happening
    accidentally.
    
    As 'links' array in node struct must be protected by node lock,
    we have to move the code of selecting an active link from
    tipc_link_xmit() to named_cluster_distribute() and then call
    __tipc_link_xmit() with the selected link to deliver name messages.
    
    Signed-off-by: Ying Xue <ying.xue@windriver.com>
    Reviewed-by: Erik Hugne <erik.hugne@ericsson.com>
    Reviewed-by: Jon Maloy <jon.maloy@ericsson.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index 893c49a3d98a..c5904d196cd3 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -131,16 +131,24 @@ static void named_cluster_distribute(struct sk_buff *buf)
 {
 	struct sk_buff *buf_copy;
 	struct tipc_node *n_ptr;
+	struct tipc_link *l_ptr;
 
+	read_lock_bh(&tipc_net_lock);
 	list_for_each_entry(n_ptr, &tipc_node_list, list) {
-		if (tipc_node_active_links(n_ptr)) {
+		spin_lock_bh(&n_ptr->lock);
+		l_ptr = n_ptr->active_links[n_ptr->addr & 1];
+		if (l_ptr) {
 			buf_copy = skb_copy(buf, GFP_ATOMIC);
-			if (!buf_copy)
+			if (!buf_copy) {
+				spin_unlock_bh(&n_ptr->lock);
 				break;
+			}
 			msg_set_destnode(buf_msg(buf_copy), n_ptr->addr);
-			tipc_link_xmit(buf_copy, n_ptr->addr, n_ptr->addr);
+			__tipc_link_xmit(l_ptr, buf_copy);
 		}
+		spin_unlock_bh(&n_ptr->lock);
 	}
+	read_unlock_bh(&tipc_net_lock);
 
 	kfree_skb(buf);
 }

commit 247f0f3c3176c55b46cb9a20011d3d6757634815
Author: Ying Xue <ying.xue@windriver.com>
Date:   Tue Feb 18 16:06:46 2014 +0800

    tipc: align tipc function names with common naming practice in the network
    
    Rename the following functions, which are shorter and more in line
    with common naming practice in the network subsystem.
    
    tipc_bclink_send_msg->tipc_bclink_xmit
    tipc_bclink_recv_pkt->tipc_bclink_rcv
    tipc_disc_recv_msg->tipc_disc_rcv
    tipc_link_send_proto_msg->tipc_link_proto_xmit
    link_recv_proto_msg->tipc_link_proto_rcv
    link_send_sections_long->tipc_link_iovec_long_xmit
    tipc_link_send_sections_fast->tipc_link_iovec_xmit_fast
    tipc_link_send_sync->tipc_link_sync_xmit
    tipc_link_recv_sync->tipc_link_sync_rcv
    tipc_link_send_buf->__tipc_link_xmit
    tipc_link_send->tipc_link_xmit
    tipc_link_send_names->tipc_link_names_xmit
    tipc_named_recv->tipc_named_rcv
    tipc_link_recv_bundle->tipc_link_bundle_rcv
    tipc_link_dup_send_queue->tipc_link_dup_queue_xmit
    link_send_long_buf->tipc_link_frag_xmit
    
    tipc_multicast->tipc_port_mcast_xmit
    tipc_port_recv_mcast->tipc_port_mcast_rcv
    tipc_port_reject_sections->tipc_port_iovec_reject
    tipc_port_recv_proto_msg->tipc_port_proto_rcv
    tipc_connect->tipc_port_connect
    __tipc_connect->__tipc_port_connect
    __tipc_disconnect->__tipc_port_disconnect
    tipc_disconnect->tipc_port_disconnect
    tipc_shutdown->tipc_port_shutdown
    tipc_port_recv_msg->tipc_port_rcv
    tipc_port_recv_sections->tipc_port_iovec_rcv
    
    release->tipc_release
    accept->tipc_accept
    bind->tipc_bind
    get_name->tipc_getname
    poll->tipc_poll
    send_msg->tipc_sendmsg
    send_packet->tipc_send_packet
    send_stream->tipc_send_stream
    recv_msg->tipc_recvmsg
    recv_stream->tipc_recv_stream
    connect->tipc_connect
    listen->tipc_listen
    shutdown->tipc_shutdown
    setsockopt->tipc_setsockopt
    getsockopt->tipc_getsockopt
    
    Above changes have no impact on current users of the functions.
    
    Signed-off-by: Ying Xue <ying.xue@windriver.com>
    Reviewed-by: Jon Maloy <jon.maloy@ericsson.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index e0d08055754e..893c49a3d98a 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -138,7 +138,7 @@ static void named_cluster_distribute(struct sk_buff *buf)
 			if (!buf_copy)
 				break;
 			msg_set_destnode(buf_msg(buf_copy), n_ptr->addr);
-			tipc_link_send(buf_copy, n_ptr->addr, n_ptr->addr);
+			tipc_link_xmit(buf_copy, n_ptr->addr, n_ptr->addr);
 		}
 	}
 
@@ -262,7 +262,7 @@ void tipc_named_node_up(unsigned long nodearg)
 	named_distribute(&message_list, node, &publ_zone, max_item_buf);
 	read_unlock_bh(&tipc_nametbl_lock);
 
-	tipc_link_send_names(&message_list, node);
+	tipc_link_names_xmit(&message_list, node);
 }
 
 /**
@@ -293,9 +293,9 @@ static void named_purge_publ(struct publication *publ)
 }
 
 /**
- * tipc_named_recv - process name table update message sent by another node
+ * tipc_named_rcv - process name table update message sent by another node
  */
-void tipc_named_recv(struct sk_buff *buf)
+void tipc_named_rcv(struct sk_buff *buf)
 {
 	struct publication *publ;
 	struct tipc_msg *msg = buf_msg(buf);

commit 4cb7d55ab4c4726c5d966d5a19e7b304345e74ca
Author: Ying Xue <ying.xue@windriver.com>
Date:   Fri Nov 16 13:51:32 2012 +0800

    tipc: eliminate an unnecessary cast of node variable
    
    As the variable:node is currently defined to u32 type, it is
    unnecessary to cast its type to u32 again when using it.
    
    Signed-off-by: Ying Xue <ying.xue@windriver.com>
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index 55d3928dfd67..e0d08055754e 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -262,7 +262,7 @@ void tipc_named_node_up(unsigned long nodearg)
 	named_distribute(&message_list, node, &publ_zone, max_item_buf);
 	read_unlock_bh(&tipc_nametbl_lock);
 
-	tipc_link_send_names(&message_list, (u32)node);
+	tipc_link_send_names(&message_list, node);
 }
 
 /**

commit 2cf8aa19fe8bec578b707daa383ebff80e3f81a1
Author: Erik Hugne <erik.hugne@ericsson.com>
Date:   Fri Jun 29 00:16:37 2012 -0400

    tipc: use standard printk shortcut macros (pr_err etc.)
    
    All messages should go directly to the kernel log.  The TIPC
    specific error, warning, info and debug trace macro's are
    removed and all references replaced with pr_err, pr_warn,
    pr_info and pr_debug.
    
    Commonly used sub-strings are explicitly declared as a const
    char to reduce .text size.
    
    Note that this means the debug messages (changed to pr_debug),
    are now enabled through dynamic debugging, instead of a TIPC
    specific Kconfig option (TIPC_DEBUG).  The latter will be
    phased out completely
    
    Signed-off-by: Erik Hugne <erik.hugne@ericsson.com>
    Signed-off-by: Jon Maloy <jon.maloy@ericsson.com>
    [PG: use pr_fmt as suggested by Joe Perches <joe@perches.com>]
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index 158318e67b08..55d3928dfd67 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -161,7 +161,7 @@ void tipc_named_publish(struct publication *publ)
 
 	buf = named_prepare_buf(PUBLICATION, ITEM_SIZE, 0);
 	if (!buf) {
-		warn("Publication distribution failure\n");
+		pr_warn("Publication distribution failure\n");
 		return;
 	}
 
@@ -186,7 +186,7 @@ void tipc_named_withdraw(struct publication *publ)
 
 	buf = named_prepare_buf(WITHDRAWAL, ITEM_SIZE, 0);
 	if (!buf) {
-		warn("Withdrawal distribution failure\n");
+		pr_warn("Withdrawal distribution failure\n");
 		return;
 	}
 
@@ -213,7 +213,7 @@ static void named_distribute(struct list_head *message_list, u32 node,
 			rest -= left;
 			buf = named_prepare_buf(PUBLICATION, left, node);
 			if (!buf) {
-				warn("Bulk publication failure\n");
+				pr_warn("Bulk publication failure\n");
 				return;
 			}
 			item = (struct distr_item *)msg_data(buf_msg(buf));
@@ -283,9 +283,10 @@ static void named_purge_publ(struct publication *publ)
 	write_unlock_bh(&tipc_nametbl_lock);
 
 	if (p != publ) {
-		err("Unable to remove publication from failed node\n"
-		    "(type=%u, lower=%u, node=0x%x, ref=%u, key=%u)\n",
-		    publ->type, publ->lower, publ->node, publ->ref, publ->key);
+		pr_err("Unable to remove publication from failed node\n"
+		       " (type=%u, lower=%u, node=0x%x, ref=%u, key=%u)\n",
+		       publ->type, publ->lower, publ->node, publ->ref,
+		       publ->key);
 	}
 
 	kfree(p);
@@ -329,14 +330,14 @@ void tipc_named_recv(struct sk_buff *buf)
 				tipc_nodesub_unsubscribe(&publ->subscr);
 				kfree(publ);
 			} else {
-				err("Unable to remove publication by node 0x%x\n"
-				    "(type=%u, lower=%u, ref=%u, key=%u)\n",
-				    msg_orignode(msg),
-				    ntohl(item->type), ntohl(item->lower),
-				    ntohl(item->ref), ntohl(item->key));
+				pr_err("Unable to remove publication by node 0x%x\n"
+				       " (type=%u, lower=%u, ref=%u, key=%u)\n",
+				       msg_orignode(msg), ntohl(item->type),
+				       ntohl(item->lower), ntohl(item->ref),
+				       ntohl(item->key));
 			}
 		} else {
-			warn("Unrecognized name table message received\n");
+			pr_warn("Unrecognized name table message received\n");
 		}
 		item++;
 	}

commit 617d3c7a50b3dc15f558d60013047aede79dc055
Author: Paul Gortmaker <paul.gortmaker@windriver.com>
Date:   Mon Apr 30 15:29:02 2012 -0400

    tipc: compress out gratuitous extra carriage returns
    
    Some of the comment blocks are floating in limbo between two
    functions, or between blocks of code.  Delete the extra line
    feeds between any comment and its associated following block
    of code, to be consistent with the majority of the rest of
    the kernel.  Also delete trailing newlines at EOF and fix
    a couple trivial typos in existing comments.
    
    This is a 100% cosmetic change with no runtime impact.  We get
    rid of over 500 lines of non-code, and being blank line deletes,
    they won't even show up as noise in git blame.
    
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index 211c1723a190..158318e67b08 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -58,7 +58,6 @@
  * Note: There is no field that identifies the publishing node because it is
  * the same for all items contained within a publication message.
  */
-
 struct distr_item {
 	__be32 type;
 	__be32 lower;
@@ -103,7 +102,6 @@ static struct publ_list *publ_lists[] = {
 /**
  * publ_to_item - add publication info to a publication message
  */
-
 static void publ_to_item(struct distr_item *i, struct publication *p)
 {
 	i->type = htonl(p->type);
@@ -116,7 +114,6 @@ static void publ_to_item(struct distr_item *i, struct publication *p)
 /**
  * named_prepare_buf - allocate & initialize a publication message
  */
-
 static struct sk_buff *named_prepare_buf(u32 type, u32 size, u32 dest)
 {
 	struct sk_buff *buf = tipc_buf_acquire(INT_H_SIZE + size);
@@ -151,7 +148,6 @@ static void named_cluster_distribute(struct sk_buff *buf)
 /**
  * tipc_named_publish - tell other nodes about a new publication by this node
  */
-
 void tipc_named_publish(struct publication *publ)
 {
 	struct sk_buff *buf;
@@ -177,7 +173,6 @@ void tipc_named_publish(struct publication *publ)
 /**
  * tipc_named_withdraw - tell other nodes about a withdrawn publication by this node
  */
-
 void tipc_named_withdraw(struct publication *publ)
 {
 	struct sk_buff *buf;
@@ -236,7 +231,6 @@ static void named_distribute(struct list_head *message_list, u32 node,
 /**
  * tipc_named_node_up - tell specified node about all publications by this node
  */
-
 void tipc_named_node_up(unsigned long nodearg)
 {
 	struct tipc_node *n_ptr;
@@ -246,7 +240,6 @@ void tipc_named_node_up(unsigned long nodearg)
 	u32 max_item_buf = 0;
 
 	/* compute maximum amount of publication data to send per message */
-
 	read_lock_bh(&tipc_net_lock);
 	n_ptr = tipc_node_find(node);
 	if (n_ptr) {
@@ -262,7 +255,6 @@ void tipc_named_node_up(unsigned long nodearg)
 		return;
 
 	/* create list of publication messages, then send them as a unit */
-
 	INIT_LIST_HEAD(&message_list);
 
 	read_lock_bh(&tipc_nametbl_lock);
@@ -279,7 +271,6 @@ void tipc_named_node_up(unsigned long nodearg)
  * Invoked for each publication issued by a newly failed node.
  * Removes publication structure from name table & deletes it.
  */
-
 static void named_purge_publ(struct publication *publ)
 {
 	struct publication *p;
@@ -303,7 +294,6 @@ static void named_purge_publ(struct publication *publ)
 /**
  * tipc_named_recv - process name table update message sent by another node
  */
-
 void tipc_named_recv(struct sk_buff *buf)
 {
 	struct publication *publ;
@@ -361,7 +351,6 @@ void tipc_named_recv(struct sk_buff *buf)
  * All name table entries published by this node are updated to reflect
  * the node's new network address.
  */
-
 void tipc_named_reinit(void)
 {
 	struct publication *publ;

commit 1110b8d33a54d1b91131e2a70ef0c3c26425b800
Author: Allan Stephens <allan.stephens@windriver.com>
Date:   Tue Apr 17 17:57:52 2012 -0400

    tipc: Update node-scope publications when network address is assigned
    
    Ensures that node-scope name publications that exist prior to the
    configuration of a node's network address are properly re-initialized
    with that address when it is assigned. TIPC's node-scope publications
    are now tracked using a publications list like the lists used for
    cluster-scope and zone-scope publications so they can be easily updated
    when required.
    
    The inclusion of node scope name publications in a conventional publication
    list means that they must now also be withdrawn, just like cluster and zone
    scope publications are currently withdrawn.  So some conditional tests on
    scope ==/!= TIPC_NODE_SCOPE are inserted/removed accordingly.
    
    Signed-off-by: Allan Stephens <allan.stephens@windriver.com>
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index 8751ea53dfde..211c1723a190 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -160,6 +160,9 @@ void tipc_named_publish(struct publication *publ)
 	list_add_tail(&publ->local_list, &publ_lists[publ->scope]->list);
 	publ_lists[publ->scope]->size++;
 
+	if (publ->scope == TIPC_NODE_SCOPE)
+		return;
+
 	buf = named_prepare_buf(PUBLICATION, ITEM_SIZE, 0);
 	if (!buf) {
 		warn("Publication distribution failure\n");
@@ -183,6 +186,9 @@ void tipc_named_withdraw(struct publication *publ)
 	list_del(&publ->local_list);
 	publ_lists[publ->scope]->size--;
 
+	if (publ->scope == TIPC_NODE_SCOPE)
+		return;
+
 	buf = named_prepare_buf(WITHDRAWAL, ITEM_SIZE, 0);
 	if (!buf) {
 		warn("Withdrawal distribution failure\n");
@@ -349,11 +355,11 @@ void tipc_named_recv(struct sk_buff *buf)
 }
 
 /**
- * tipc_named_reinit - re-initialize local publication list
+ * tipc_named_reinit - re-initialize local publications
  *
  * This routine is called whenever TIPC networking is enabled.
- * All existing publications by this node that have "cluster" or "zone" scope
- * are updated to reflect the node's new network address.
+ * All name table entries published by this node are updated to reflect
+ * the node's new network address.
  */
 
 void tipc_named_reinit(void)
@@ -363,7 +369,7 @@ void tipc_named_reinit(void)
 
 	write_lock_bh(&tipc_nametbl_lock);
 
-	for (scope = TIPC_ZONE_SCOPE; scope <= TIPC_CLUSTER_SCOPE; scope++)
+	for (scope = TIPC_ZONE_SCOPE; scope <= TIPC_NODE_SCOPE; scope++)
 		list_for_each_entry(publ, &publ_lists[scope]->list, local_list)
 			publ->node = tipc_own_addr;
 

commit a909804f7c6cb83b7365ed23e9fd4c1267ee9ef0
Author: Allan Stephens <allan.stephens@windriver.com>
Date:   Tue Apr 17 17:57:52 2012 -0400

    tipc: Separate cluster-scope and zone-scope names into distinct lists
    
    Utilizes distinct lists to track zone-scope and cluster-scope names
    published by a node. For now, TIPC continues to process the entries
    in both lists in the same way; however, an upcoming patch will utilize
    the existence of the lists to prevent the sending of cluster-scope names
    to nodes that are not part of the local cluster.
    
    To achieve this, an array of publication lists is introduced, so
    that they can be iterated over and accessed via publ->scope as
    an index where convenient.
    
    Signed-off-by: Allan Stephens <allan.stephens@windriver.com>
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index 3be0eb9509df..8751ea53dfde 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -77,11 +77,29 @@ struct publ_list {
 	u32 size;
 };
 
+static struct publ_list publ_zone = {
+	.list = LIST_HEAD_INIT(publ_zone.list),
+	.size = 0,
+};
+
 static struct publ_list publ_cluster = {
 	.list = LIST_HEAD_INIT(publ_cluster.list),
 	.size = 0,
 };
 
+static struct publ_list publ_node = {
+	.list = LIST_HEAD_INIT(publ_node.list),
+	.size = 0,
+};
+
+static struct publ_list *publ_lists[] = {
+	NULL,
+	&publ_zone,	/* publ_lists[TIPC_ZONE_SCOPE]		*/
+	&publ_cluster,	/* publ_lists[TIPC_CLUSTER_SCOPE]	*/
+	&publ_node	/* publ_lists[TIPC_NODE_SCOPE]		*/
+};
+
+
 /**
  * publ_to_item - add publication info to a publication message
  */
@@ -139,8 +157,8 @@ void tipc_named_publish(struct publication *publ)
 	struct sk_buff *buf;
 	struct distr_item *item;
 
-	list_add_tail(&publ->local_list, &publ_cluster.list);
-	publ_cluster.size++;
+	list_add_tail(&publ->local_list, &publ_lists[publ->scope]->list);
+	publ_lists[publ->scope]->size++;
 
 	buf = named_prepare_buf(PUBLICATION, ITEM_SIZE, 0);
 	if (!buf) {
@@ -163,7 +181,7 @@ void tipc_named_withdraw(struct publication *publ)
 	struct distr_item *item;
 
 	list_del(&publ->local_list);
-	publ_cluster.size--;
+	publ_lists[publ->scope]->size--;
 
 	buf = named_prepare_buf(WITHDRAWAL, ITEM_SIZE, 0);
 	if (!buf) {
@@ -243,6 +261,7 @@ void tipc_named_node_up(unsigned long nodearg)
 
 	read_lock_bh(&tipc_nametbl_lock);
 	named_distribute(&message_list, node, &publ_cluster, max_item_buf);
+	named_distribute(&message_list, node, &publ_zone, max_item_buf);
 	read_unlock_bh(&tipc_nametbl_lock);
 
 	tipc_link_send_names(&message_list, (u32)node);
@@ -340,11 +359,13 @@ void tipc_named_recv(struct sk_buff *buf)
 void tipc_named_reinit(void)
 {
 	struct publication *publ;
+	int scope;
 
 	write_lock_bh(&tipc_nametbl_lock);
 
-	list_for_each_entry(publ, &publ_cluster.list, local_list)
-		publ->node = tipc_own_addr;
+	for (scope = TIPC_ZONE_SCOPE; scope <= TIPC_CLUSTER_SCOPE; scope++)
+		list_for_each_entry(publ, &publ_lists[scope]->list, local_list)
+			publ->node = tipc_own_addr;
 
 	write_unlock_bh(&tipc_nametbl_lock);
 }

commit e11aa059715e2bacd4e62d57be5557dda697af8e
Author: Allan Stephens <allan.stephens@windriver.com>
Date:   Tue Apr 17 17:57:52 2012 -0400

    tipc: Factor out name publication code to a separate function
    
    This is done so that it can be reused with differing publication
    lists, instead of being hard coded to the cluster publicaton list.
    
    Signed-off-by: Allan Stephens <allan.stephens@windriver.com>
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index 870a001131c6..3be0eb9509df 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -176,6 +176,39 @@ void tipc_named_withdraw(struct publication *publ)
 	named_cluster_distribute(buf);
 }
 
+/*
+ * named_distribute - prepare name info for bulk distribution to another node
+ */
+static void named_distribute(struct list_head *message_list, u32 node,
+			     struct publ_list *pls, u32 max_item_buf)
+{
+	struct publication *publ;
+	struct sk_buff *buf = NULL;
+	struct distr_item *item = NULL;
+	u32 left = 0;
+	u32 rest = pls->size * ITEM_SIZE;
+
+	list_for_each_entry(publ, &pls->list, local_list) {
+		if (!buf) {
+			left = (rest <= max_item_buf) ? rest : max_item_buf;
+			rest -= left;
+			buf = named_prepare_buf(PUBLICATION, left, node);
+			if (!buf) {
+				warn("Bulk publication failure\n");
+				return;
+			}
+			item = (struct distr_item *)msg_data(buf_msg(buf));
+		}
+		publ_to_item(item, publ);
+		item++;
+		left -= ITEM_SIZE;
+		if (!left) {
+			list_add_tail((struct list_head *)buf, message_list);
+			buf = NULL;
+		}
+	}
+}
+
 /**
  * tipc_named_node_up - tell specified node about all publications by this node
  */
@@ -184,13 +217,8 @@ void tipc_named_node_up(unsigned long nodearg)
 {
 	struct tipc_node *n_ptr;
 	struct tipc_link *l_ptr;
-	struct publication *publ;
-	struct distr_item *item = NULL;
-	struct sk_buff *buf = NULL;
 	struct list_head message_list;
 	u32 node = (u32)nodearg;
-	u32 left = 0;
-	u32 rest;
 	u32 max_item_buf = 0;
 
 	/* compute maximum amount of publication data to send per message */
@@ -214,28 +242,7 @@ void tipc_named_node_up(unsigned long nodearg)
 	INIT_LIST_HEAD(&message_list);
 
 	read_lock_bh(&tipc_nametbl_lock);
-	rest = publ_cluster.size * ITEM_SIZE;
-
-	list_for_each_entry(publ, &publ_cluster.list, local_list) {
-		if (!buf) {
-			left = (rest <= max_item_buf) ? rest : max_item_buf;
-			rest -= left;
-			buf = named_prepare_buf(PUBLICATION, left, node);
-			if (!buf) {
-				warn("Bulk publication distribution failure\n");
-				goto exit;
-			}
-			item = (struct distr_item *)msg_data(buf_msg(buf));
-		}
-		publ_to_item(item, publ);
-		item++;
-		left -= ITEM_SIZE;
-		if (!left) {
-			list_add_tail((struct list_head *)buf, &message_list);
-			buf = NULL;
-		}
-	}
-exit:
+	named_distribute(&message_list, node, &publ_cluster, max_item_buf);
 	read_unlock_bh(&tipc_nametbl_lock);
 
 	tipc_link_send_names(&message_list, (u32)node);

commit 3f8375fee30cbf7fb0bd67f044e3406daa16fa3e
Author: Allan Stephens <allan.stephens@windriver.com>
Date:   Tue Apr 17 17:57:52 2012 -0400

    tipc: introduce publication lists struct
    
    There is currently a single list that is containing both cluster-scope and
    zone-scope publications, and the list count is a separate free floating
    variable.  Create a struct to bind the count to the list, and to pave
    the way for factoring out the publications into zone/cluster/node scope.
    
    The current "publ_root" most matches what will be the cluster scope
    list, so it is named accordingly in this commit.
    
    Signed-off-by: Allan Stephens <allan.stephens@windriver.com>
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index d57da6159616..870a001131c6 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -68,12 +68,19 @@ struct distr_item {
 };
 
 /**
- * List of externally visible publications by this node --
- * that is, all publications having scope > TIPC_NODE_SCOPE.
+ * struct publ_list - list of publications made by this node
+ * @list: circular list of publications
+ * @list_size: number of entries in list
  */
+struct publ_list {
+	struct list_head list;
+	u32 size;
+};
 
-static LIST_HEAD(publ_root);
-static u32 publ_cnt;
+static struct publ_list publ_cluster = {
+	.list = LIST_HEAD_INIT(publ_cluster.list),
+	.size = 0,
+};
 
 /**
  * publ_to_item - add publication info to a publication message
@@ -132,8 +139,8 @@ void tipc_named_publish(struct publication *publ)
 	struct sk_buff *buf;
 	struct distr_item *item;
 
-	list_add_tail(&publ->local_list, &publ_root);
-	publ_cnt++;
+	list_add_tail(&publ->local_list, &publ_cluster.list);
+	publ_cluster.size++;
 
 	buf = named_prepare_buf(PUBLICATION, ITEM_SIZE, 0);
 	if (!buf) {
@@ -156,7 +163,7 @@ void tipc_named_withdraw(struct publication *publ)
 	struct distr_item *item;
 
 	list_del(&publ->local_list);
-	publ_cnt--;
+	publ_cluster.size--;
 
 	buf = named_prepare_buf(WITHDRAWAL, ITEM_SIZE, 0);
 	if (!buf) {
@@ -207,9 +214,9 @@ void tipc_named_node_up(unsigned long nodearg)
 	INIT_LIST_HEAD(&message_list);
 
 	read_lock_bh(&tipc_nametbl_lock);
-	rest = publ_cnt * ITEM_SIZE;
+	rest = publ_cluster.size * ITEM_SIZE;
 
-	list_for_each_entry(publ, &publ_root, local_list) {
+	list_for_each_entry(publ, &publ_cluster.list, local_list) {
 		if (!buf) {
 			left = (rest <= max_item_buf) ? rest : max_item_buf;
 			rest -= left;
@@ -329,7 +336,7 @@ void tipc_named_reinit(void)
 
 	write_lock_bh(&tipc_nametbl_lock);
 
-	list_for_each_entry(publ, &publ_root, local_list)
+	list_for_each_entry(publ, &publ_cluster.list, local_list)
 		publ->node = tipc_own_addr;
 
 	write_unlock_bh(&tipc_nametbl_lock);

commit 5f6d9123f1c7ef7297b0da1620988fe16c738e75
Author: Allan Stephens <allan.stephens@windriver.com>
Date:   Fri Nov 4 13:24:29 2011 -0400

    tipc: Eliminate trivial buffer manipulation helper routines
    
    Gets rid of two inlined routines that simply call existing sk_buff
    manipulation routines, since there is no longer any extra processing
    done by the helper routines.
    
    Note that these changes are essentially cosmetic in nature, and have
    no impact on the actual operation of TIPC.
    
    Signed-off-by: Allan Stephens <allan.stephens@windriver.com>
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index acecfda82f37..d57da6159616 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -120,7 +120,7 @@ static void named_cluster_distribute(struct sk_buff *buf)
 		}
 	}
 
-	buf_discard(buf);
+	kfree_skb(buf);
 }
 
 /**
@@ -312,7 +312,7 @@ void tipc_named_recv(struct sk_buff *buf)
 		item++;
 	}
 	write_unlock_bh(&tipc_nametbl_lock);
-	buf_discard(buf);
+	kfree_skb(buf);
 }
 
 /**

commit 3175bd9add570f3b5c06877369897b334556a2ff
Author: Allan Stephens <allan.stephens@windriver.com>
Date:   Fri Oct 28 12:03:00 2011 -0400

    tipc: Eliminate alteration of publication key during name table purging
    
    Removes code that alters the publication key of a name table entry
    that is being forcibly purged from TIPC's name table after contact
    with the publishing node has been lost.
    
    Current TIPC ensures that all defunct names are purged before
    re-establishing contact with a failed node.  There used to be a risk
    that the publication might be accidentally deleted because it might be
    re-added to the name table before the purge operation was completed.
    But now there is no longer a need to ensure that the new key is different
    than the old one.
    
    Signed-off-by: Allan Stephens <allan.stephens@windriver.com>
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index 98ebb37f1808..acecfda82f37 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -239,9 +239,6 @@ void tipc_named_node_up(unsigned long nodearg)
  *
  * Invoked for each publication issued by a newly failed node.
  * Removes publication structure from name table & deletes it.
- * In rare cases the link may have come back up again when this
- * function is called, and we have two items representing the same
- * publication. Nudge this item's key to distinguish it from the other.
  */
 
 static void named_purge_publ(struct publication *publ)
@@ -249,7 +246,6 @@ static void named_purge_publ(struct publication *publ)
 	struct publication *p;
 
 	write_lock_bh(&tipc_nametbl_lock);
-	publ->key += 1222345;
 	p = tipc_nametbl_remove_publ(publ->type, publ->lower,
 				     publ->node, publ->ref, publ->key);
 	if (p)

commit a18c4bc3ea3c23f658655b1eee4f62cb71d51efd
Author: Paul Gortmaker <paul.gortmaker@windriver.com>
Date:   Thu Dec 29 20:58:42 2011 -0500

    tipc: rename struct link* to struct tipc_link*
    
    This converts the following:
    
            struct link             ->      struct tipc_link
            struct link_req         ->      struct tipc_link_req
            struct link_name        ->      struct tipc_link_name
    
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index be8306f9139e..98ebb37f1808 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -176,7 +176,7 @@ void tipc_named_withdraw(struct publication *publ)
 void tipc_named_node_up(unsigned long nodearg)
 {
 	struct tipc_node *n_ptr;
-	struct link *l_ptr;
+	struct tipc_link *l_ptr;
 	struct publication *publ;
 	struct distr_item *item = NULL;
 	struct sk_buff *buf = NULL;

commit 945af1c39df00a1e5873e38145432ba752ec49a0
Author: Allan Stephens <allan.stephens@windriver.com>
Date:   Fri Oct 14 14:42:25 2011 -0400

    tipc: Eliminate useless check when network address is assigned
    
    Gets rid of an unnecessary check in the routine that updates the port id
    of a node's name publications when the node is assigned a network address,
    since the routine is only invoked if the new address is different from
    the existing one.
    
    Signed-off-by: Allan Stephens <allan.stephens@windriver.com>
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index b7ca1bd7b151..be8306f9139e 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -322,10 +322,9 @@ void tipc_named_recv(struct sk_buff *buf)
 /**
  * tipc_named_reinit - re-initialize local publication list
  *
- * This routine is called whenever TIPC networking is (re)enabled.
+ * This routine is called whenever TIPC networking is enabled.
  * All existing publications by this node that have "cluster" or "zone" scope
- * are updated to reflect the node's current network address.
- * (If the node's address is unchanged, the update loop terminates immediately.)
+ * are updated to reflect the node's new network address.
  */
 
 void tipc_named_reinit(void)
@@ -333,10 +332,9 @@ void tipc_named_reinit(void)
 	struct publication *publ;
 
 	write_lock_bh(&tipc_nametbl_lock);
-	list_for_each_entry(publ, &publ_root, local_list) {
-		if (publ->node == tipc_own_addr)
-			break;
+
+	list_for_each_entry(publ, &publ_root, local_list)
 		publ->node = tipc_own_addr;
-	}
+
 	write_unlock_bh(&tipc_nametbl_lock);
 }

commit 9aa88c2a509e11e6efc466c88b386e0e01bef731
Author: Allan Stephens <allan.stephens@windriver.com>
Date:   Tue May 31 13:38:02 2011 -0400

    tipc: Enhance sending of bulk name table messages
    
    Modifies the initial transfer of name table entries to a new neighboring
    node so that the messages are enqueued as a unit, rather than individually.
    
    The revised algorithm now locates the link carrying the message only once,
    and eliminates unnecessary checks for link congestion, message fragmentation,
    and message bundling that are not required when sending these messages.
    
    Signed-off-by: Allan Stephens <allan.stephens@windriver.com>
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index 97546f07938c..b7ca1bd7b151 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -180,6 +180,7 @@ void tipc_named_node_up(unsigned long nodearg)
 	struct publication *publ;
 	struct distr_item *item = NULL;
 	struct sk_buff *buf = NULL;
+	struct list_head message_list;
 	u32 node = (u32)nodearg;
 	u32 left = 0;
 	u32 rest;
@@ -201,6 +202,10 @@ void tipc_named_node_up(unsigned long nodearg)
 	if (!max_item_buf)
 		return;
 
+	/* create list of publication messages, then send them as a unit */
+
+	INIT_LIST_HEAD(&message_list);
+
 	read_lock_bh(&tipc_nametbl_lock);
 	rest = publ_cnt * ITEM_SIZE;
 
@@ -219,13 +224,14 @@ void tipc_named_node_up(unsigned long nodearg)
 		item++;
 		left -= ITEM_SIZE;
 		if (!left) {
-			msg_set_link_selector(buf_msg(buf), node);
-			tipc_link_send(buf, node, node);
+			list_add_tail((struct list_head *)buf, &message_list);
 			buf = NULL;
 		}
 	}
 exit:
 	read_unlock_bh(&tipc_nametbl_lock);
+
+	tipc_link_send_names(&message_list, (u32)node);
 }
 
 /**

commit 1c553bb52eb4c58333a843c0a5888d2329909f62
Author: Paul Gortmaker <paul.gortmaker@windriver.com>
Date:   Fri Sep 2 13:45:34 2011 -0400

    tipc: relocate/coalesce node cast in tipc_named_node_up
    
    Functions like this are called using unsigned longs from
    function pointers.  In this case, the function is passed in
    a node which is normally internally treated as a u32 by TIPC.
    
    Rather than add more casts into this function in the future
    for each added use of node within, move the cast to a single
    place on a local.
    
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index 21bc0281ec89..97546f07938c 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -173,13 +173,14 @@ void tipc_named_withdraw(struct publication *publ)
  * tipc_named_node_up - tell specified node about all publications by this node
  */
 
-void tipc_named_node_up(unsigned long node)
+void tipc_named_node_up(unsigned long nodearg)
 {
 	struct tipc_node *n_ptr;
 	struct link *l_ptr;
 	struct publication *publ;
 	struct distr_item *item = NULL;
 	struct sk_buff *buf = NULL;
+	u32 node = (u32)nodearg;
 	u32 left = 0;
 	u32 rest;
 	u32 max_item_buf = 0;
@@ -187,7 +188,7 @@ void tipc_named_node_up(unsigned long node)
 	/* compute maximum amount of publication data to send per message */
 
 	read_lock_bh(&tipc_net_lock);
-	n_ptr = tipc_node_find((u32)node);
+	n_ptr = tipc_node_find(node);
 	if (n_ptr) {
 		tipc_node_lock(n_ptr);
 		l_ptr = n_ptr->active_links[0];

commit 149ce37c8de72c64fc4f66c1b4cf7a0fb66b7ee9
Author: Allan Stephens <allan.stephens@windriver.com>
Date:   Tue May 31 11:05:02 2011 -0400

    tipc: Prevent fragmented messages during initial name table exchange
    
    Reduces the maximum size of messages sent during the initial exchange
    of name table information between two nodes to be no larger than the
    MTU of the first link established between the nodes. This ensures that
    messages will never need to be fragmented, which would add unnecessary
    overhead to the name table synchronization mechanism.
    
    Signed-off-by: Allan Stephens <allan.stephens@windriver.com>
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index cd356e504332..21bc0281ec89 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -175,16 +175,32 @@ void tipc_named_withdraw(struct publication *publ)
 
 void tipc_named_node_up(unsigned long node)
 {
+	struct tipc_node *n_ptr;
+	struct link *l_ptr;
 	struct publication *publ;
 	struct distr_item *item = NULL;
 	struct sk_buff *buf = NULL;
 	u32 left = 0;
 	u32 rest;
-	u32 max_item_buf;
+	u32 max_item_buf = 0;
+
+	/* compute maximum amount of publication data to send per message */
+
+	read_lock_bh(&tipc_net_lock);
+	n_ptr = tipc_node_find((u32)node);
+	if (n_ptr) {
+		tipc_node_lock(n_ptr);
+		l_ptr = n_ptr->active_links[0];
+		if (l_ptr)
+			max_item_buf = ((l_ptr->max_pkt - INT_H_SIZE) /
+				ITEM_SIZE) * ITEM_SIZE;
+		tipc_node_unlock(n_ptr);
+	}
+	read_unlock_bh(&tipc_net_lock);
+	if (!max_item_buf)
+		return;
 
 	read_lock_bh(&tipc_nametbl_lock);
-	max_item_buf = TIPC_MAX_USER_MSG_SIZE / ITEM_SIZE;
-	max_item_buf *= ITEM_SIZE;
 	rest = publ_cnt * ITEM_SIZE;
 
 	list_for_each_entry(publ, &publ_root, local_list) {

commit 741d9eb7b8f352071f56aacb77f5245b4e2a4fbe
Author: Allan Stephens <allan.stephens@windriver.com>
Date:   Tue May 31 15:03:18 2011 -0400

    tipc: Cleanup of message header size terminology
    
    Performs cosmetic cleanup of the symbolic names used to specify TIPC
    payload message header sizes. The revised names now more accurately
    reflect the payload messages in which they can appear. In addition,
    several places where these payload message symbol names were being used
    to create non-payload messages have been updated to use the proper
    internal message symbolic name.
    
    No functional changes are introduced by this rework.
    
    Signed-off-by: Allan Stephens <allan.stephens@windriver.com>
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index 80025a1b3bfd..cd356e504332 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -94,13 +94,13 @@ static void publ_to_item(struct distr_item *i, struct publication *p)
 
 static struct sk_buff *named_prepare_buf(u32 type, u32 size, u32 dest)
 {
-	struct sk_buff *buf = tipc_buf_acquire(LONG_H_SIZE + size);
+	struct sk_buff *buf = tipc_buf_acquire(INT_H_SIZE + size);
 	struct tipc_msg *msg;
 
 	if (buf != NULL) {
 		msg = buf_msg(buf);
-		tipc_msg_init(msg, NAME_DISTRIBUTOR, type, LONG_H_SIZE, dest);
-		msg_set_size(msg, LONG_H_SIZE + size);
+		tipc_msg_init(msg, NAME_DISTRIBUTOR, type, INT_H_SIZE, dest);
+		msg_set_size(msg, INT_H_SIZE + size);
 	}
 	return buf;
 }

commit 25985edcedea6396277003854657b5f3cb31a628
Author: Lucas De Marchi <lucas.demarchi@profusion.mobi>
Date:   Wed Mar 30 22:57:33 2011 -0300

    Fix common misspellings
    
    Fixes generated by 'codespell' and manually reviewed.
    
    Signed-off-by: Lucas De Marchi <lucas.demarchi@profusion.mobi>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index c9fa6dfcf287..80025a1b3bfd 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -160,7 +160,7 @@ void tipc_named_withdraw(struct publication *publ)
 
 	buf = named_prepare_buf(WITHDRAWAL, ITEM_SIZE, 0);
 	if (!buf) {
-		warn("Withdrawl distribution failure\n");
+		warn("Withdrawal distribution failure\n");
 		return;
 	}
 

commit 8f19afb2dbc885befef2a4e7931dfcb51702a212
Author: Paul Gortmaker <paul.gortmaker@windriver.com>
Date:   Mon Feb 28 11:36:21 2011 -0400

    tipc: cosmetic - function names are not to be full sentences
    
    Function names like "tipc_node_has_redundant_links" are unweildy
    and result in long lines even for simple lines.  The "has" doesn't
    contribute any value add, so dropping that is a slight step in the
    right direction.   This is a cosmetic change, basic result of:
    
    for i in `grep -l tipc_node_has_ *` ; do sed -i s/tipc_node_has_/tipc_node_/ $i ; done
    
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index 1b70d5d051d0..c9fa6dfcf287 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -111,7 +111,7 @@ static void named_cluster_distribute(struct sk_buff *buf)
 	struct tipc_node *n_ptr;
 
 	list_for_each_entry(n_ptr, &tipc_node_list, list) {
-		if (tipc_node_has_active_links(n_ptr)) {
+		if (tipc_node_active_links(n_ptr)) {
 			buf_copy = skb_copy(buf, GFP_ATOMIC);
 			if (!buf_copy)
 				break;

commit 672d99e19a12b703c9e2d71ead8fb8b8a85a3886
Author: Allan Stephens <allan.stephens@windriver.com>
Date:   Fri Feb 25 18:42:52 2011 -0500

    tipc: Convert node object array to a hash table
    
    Replaces the dynamically allocated array of pointers to the cluster's
    node objects with a static hash table. Hash collisions are resolved
    using chaining, with a typical hash chain having only a single node,
    to avoid degrading performance during processing of incoming packets.
    The conversion to a hash table reduces the memory requirements for
    TIPC's node table to approximately the same size it had prior to
    the previous commit.
    
    In addition to the hash table itself, TIPC now also maintains a
    linked list for the node objects, sorted by ascending network address.
    This list allows TIPC to continue sending responses to user space
    applications that request node and link information in sorted order.
    The list also improves performance when name table update messages are
    sent by making it easier to identify the nodes that must be notified.
    
    Signed-off-by: Allan Stephens <allan.stephens@windriver.com>
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index f2086f684b34..1b70d5d051d0 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -109,11 +109,9 @@ static void named_cluster_distribute(struct sk_buff *buf)
 {
 	struct sk_buff *buf_copy;
 	struct tipc_node *n_ptr;
-	u32 n_num;
 
-	for (n_num = 1; n_num <= tipc_highest_node; n_num++) {
-		n_ptr = tipc_nodes[n_num];
-		if (n_ptr && tipc_node_has_active_links(n_ptr)) {
+	list_for_each_entry(n_ptr, &tipc_node_list, list) {
+		if (tipc_node_has_active_links(n_ptr)) {
 			buf_copy = skb_copy(buf, GFP_ATOMIC);
 			if (!buf_copy)
 				break;

commit d1bcb11544109114d72965afea7805cc3e16a83a
Author: Allan Stephens <allan.stephens@windriver.com>
Date:   Fri Feb 25 10:01:58 2011 -0500

    tipc: Split up unified structure of network-related variables
    
    Converts the fields of the global "tipc_net" structure into individual
    variables.  Since the struct was never referenced as a complete unit,
    its existence was pointless.  This will facilitate upcoming changes to
    TIPC's node table and simpify upcoming relocation of the variables so
    they are only visible to the files that actually use them.
    
    This change is essentially cosmetic in nature, and doesn't affect the
    operation of TIPC.
    
    Signed-off-by: Allan Stephens <allan.stephens@windriver.com>
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index d58dae78b551..f2086f684b34 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -111,8 +111,8 @@ static void named_cluster_distribute(struct sk_buff *buf)
 	struct tipc_node *n_ptr;
 	u32 n_num;
 
-	for (n_num = 1; n_num <= tipc_net.highest_node; n_num++) {
-		n_ptr = tipc_net.nodes[n_num];
+	for (n_num = 1; n_num <= tipc_highest_node; n_num++) {
+		n_ptr = tipc_nodes[n_num];
 		if (n_ptr && tipc_node_has_active_links(n_ptr)) {
 			buf_copy = skb_copy(buf, GFP_ATOMIC);
 			if (!buf_copy)

commit f1379173326de4c745c4f610501486e4f3bd9248
Author: Allan Stephens <Allan.Stephens@windriver.com>
Date:   Wed Feb 23 14:13:41 2011 -0500

    tipc: Cosmetic changes to node subscription code
    
    Relocates the code that notifies users of node subscriptions so that
    it is adjacent to the rest of the routines that implement TIPC's node
    subscription capability. Renames the name table routine that is
    invoked by a node subscription to better reflect its purpose and to
    be consistent with other, similar name table routines.
    
    These changes are cosmetic in nature, and do not alter the behavior
    of TIPC.
    
    Signed-off-by: Allan Stephens <Allan.Stephens@windriver.com>
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index 1d4a18aa9ccc..d58dae78b551 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -214,7 +214,7 @@ void tipc_named_node_up(unsigned long node)
 }
 
 /**
- * node_is_down - remove publication associated with a failed node
+ * named_purge_publ - remove publication associated with a failed node
  *
  * Invoked for each publication issued by a newly failed node.
  * Removes publication structure from name table & deletes it.
@@ -223,7 +223,7 @@ void tipc_named_node_up(unsigned long node)
  * publication. Nudge this item's key to distinguish it from the other.
  */
 
-static void node_is_down(struct publication *publ)
+static void named_purge_publ(struct publication *publ)
 {
 	struct publication *p;
 
@@ -269,7 +269,8 @@ void tipc_named_recv(struct sk_buff *buf)
 				tipc_nodesub_subscribe(&publ->subscr,
 						       msg_orignode(msg),
 						       publ,
-						       (net_ev_handler)node_is_down);
+						       (net_ev_handler)
+						       named_purge_publ);
 			}
 		} else if (msg_type(msg) == WITHDRAWAL) {
 			publ = tipc_nametbl_remove_publ(ntohl(item->type),

commit 431697eb60d2d36614096aff12bd1b826a9f9bc1
Author: Allan Stephens <Allan.Stephens@windriver.com>
Date:   Wed Feb 23 13:51:15 2011 -0500

    tipc: Prevent null pointer error when removing a node subscription
    
    Prevents a null pointer dereference from occurring if a node subscription
    is triggered at the same time that the subscribing port or publication is
    terminating the subscription. The problem arises if the triggering routine
    asynchronously activates and deregisters the node subscription while
    deregistration is already underway -- the deregistration routine may find
    that the pointer it has just verified to be non-NULL is now NULL.
    To avoid this race condition the triggering routine now simply marks the
    node subscription as defunct (to prevent it from re-activating)
    instead of deregistering it. The subscription is now both deregistered
    and destroyed only when the subscribing port or publication code terminates
    the node subscription.
    
    Signed-off-by: Allan Stephens <Allan.Stephens@windriver.com>
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index 483c226c9581..1d4a18aa9ccc 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -2,7 +2,7 @@
  * net/tipc/name_distr.c: TIPC name distribution code
  *
  * Copyright (c) 2000-2006, Ericsson AB
- * Copyright (c) 2005, Wind River Systems
+ * Copyright (c) 2005, 2010-2011, Wind River Systems
  * All rights reserved.
  *
  * Redistribution and use in source and binary forms, with or without
@@ -221,7 +221,6 @@ void tipc_named_node_up(unsigned long node)
  * In rare cases the link may have come back up again when this
  * function is called, and we have two items representing the same
  * publication. Nudge this item's key to distinguish it from the other.
- * (Note: Publication's node subscription is already unsubscribed.)
  */
 
 static void node_is_down(struct publication *publ)
@@ -232,6 +231,8 @@ static void node_is_down(struct publication *publ)
 	publ->key += 1222345;
 	p = tipc_nametbl_remove_publ(publ->type, publ->lower,
 				     publ->node, publ->ref, publ->key);
+	if (p)
+		tipc_nodesub_unsubscribe(&p->subscr);
 	write_unlock_bh(&tipc_nametbl_lock);
 
 	if (p != publ) {

commit e3ec9c7d5eea9adf2c604c623c987360cc700b88
Author: Allan Stephens <Allan.Stephens@windriver.com>
Date:   Fri Dec 31 18:59:34 2010 +0000

    tipc: remove zeroing assignments to static global variables
    
    Cleans up TIPC's source code to eliminate the needless initialization
    of static variables to zero.
    
    These changes are purely cosmetic and do not alter the operation of TIPC
    in any way.
    
    Signed-off-by: Allan Stephens <Allan.Stephens@windriver.com>
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index a6c989fd4988..483c226c9581 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -73,7 +73,7 @@ struct distr_item {
  */
 
 static LIST_HEAD(publ_root);
-static u32 publ_cnt = 0;
+static u32 publ_cnt;
 
 /**
  * publ_to_item - add publication info to a publication message

commit e83504f72456809cdbdbc91700d3ba6370c9da1c
Author: Allan Stephens <Allan.Stephens@windriver.com>
Date:   Fri Dec 31 18:59:30 2010 +0000

    tipc: remove pointless check for NULL prior to kfree
    
    It is acceptable to call kfree() with NULL, so these checks are not
    serving any useful purpose.
    
    Signed-off-by: Allan Stephens <Allan.Stephens@windriver.com>
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index 376a30b9fd72..a6c989fd4988 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -240,9 +240,7 @@ static void node_is_down(struct publication *publ)
 		    publ->type, publ->lower, publ->node, publ->ref, publ->key);
 	}
 
-	if (p) {
-		kfree(p);
-	}
+	kfree(p);
 }
 
 /**

commit 886ef52a8ce6930a9d0c58267d5b5038ac3e8d30
Author: Allan Stephens <Allan.Stephens@windriver.com>
Date:   Fri Dec 31 18:59:29 2010 +0000

    tipc: remove redundant #includes
    
    Eliminates a number of #include statements that no longer serve any
    useful purpose.
    
    Signed-off-by: Allan Stephens <Allan.Stephens@windriver.com>
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index 0dd648ec0809..376a30b9fd72 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -35,7 +35,6 @@
  */
 
 #include "core.h"
-#include "addr.h"
 #include "link.h"
 #include "name_distr.h"
 

commit b29f14284989b3d0b3a5ce268b5b1fc4df9c5795
Author: Allan Stephens <Allan.Stephens@windriver.com>
Date:   Fri Dec 31 18:59:25 2010 +0000

    tipc: remove calls to dbg() and msg_dbg()
    
    Eliminates obsolete calls to two of TIPC's main debugging macros, as well
    as a pair of associated debugging routines that are no longer required.
    
    Signed-off-by: Allan Stephens <Allan.Stephens@windriver.com>
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index c4583fe888d8..0dd648ec0809 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -87,7 +87,6 @@ static void publ_to_item(struct distr_item *i, struct publication *p)
 	i->upper = htonl(p->upper);
 	i->ref = htonl(p->ref);
 	i->key = htonl(p->key);
-	dbg("publ_to_item: %u, %u, %u\n", p->type, p->lower, p->upper);
 }
 
 /**
@@ -147,7 +146,6 @@ void tipc_named_publish(struct publication *publ)
 
 	item = (struct distr_item *)msg_data(buf_msg(buf));
 	publ_to_item(item, publ);
-	dbg("tipc_named_publish: broadcasting publish msg\n");
 	named_cluster_distribute(buf);
 }
 
@@ -171,7 +169,6 @@ void tipc_named_withdraw(struct publication *publ)
 
 	item = (struct distr_item *)msg_data(buf_msg(buf));
 	publ_to_item(item, publ);
-	dbg("tipc_named_withdraw: broadcasting withdraw msg\n");
 	named_cluster_distribute(buf);
 }
 
@@ -209,9 +206,6 @@ void tipc_named_node_up(unsigned long node)
 		left -= ITEM_SIZE;
 		if (!left) {
 			msg_set_link_selector(buf_msg(buf), node);
-			dbg("tipc_named_node_up: sending publish msg to "
-			    "<%u.%u.%u>\n", tipc_zone(node),
-			    tipc_cluster(node), tipc_node(node));
 			tipc_link_send(buf, node, node);
 			buf = NULL;
 		}
@@ -236,8 +230,6 @@ static void node_is_down(struct publication *publ)
 	struct publication *p;
 
 	write_lock_bh(&tipc_nametbl_lock);
-	dbg("node_is_down: withdrawing %u, %u, %u\n",
-	    publ->type, publ->lower, publ->upper);
 	publ->key += 1222345;
 	p = tipc_nametbl_remove_publ(publ->type, publ->lower,
 				     publ->node, publ->ref, publ->key);
@@ -268,9 +260,6 @@ void tipc_named_recv(struct sk_buff *buf)
 	write_lock_bh(&tipc_nametbl_lock);
 	while (count--) {
 		if (msg_type(msg) == PUBLICATION) {
-			dbg("tipc_named_recv: got publication for %u, %u, %u\n",
-			    ntohl(item->type), ntohl(item->lower),
-			    ntohl(item->upper));
 			publ = tipc_nametbl_insert_publ(ntohl(item->type),
 							ntohl(item->lower),
 							ntohl(item->upper),
@@ -285,9 +274,6 @@ void tipc_named_recv(struct sk_buff *buf)
 						       (net_ev_handler)node_is_down);
 			}
 		} else if (msg_type(msg) == WITHDRAWAL) {
-			dbg("tipc_named_recv: got withdrawl for %u, %u, %u\n",
-			    ntohl(item->type), ntohl(item->lower),
-			    ntohl(item->upper));
 			publ = tipc_nametbl_remove_publ(ntohl(item->type),
 							ntohl(item->lower),
 							msg_orignode(msg),

commit 8f92df6ad49da958d97e171762d0a97a3dc738f1
Author: Allan Stephens <Allan.Stephens@windriver.com>
Date:   Fri Dec 31 18:59:19 2010 +0000

    tipc: Remove prototype code for supporting multiple clusters
    
    Eliminates routines, data structures, and files that were intended
    to allow TIPC to support a network containing multiple clusters.
    Currently, TIPC supports only networks consisting of a single cluster
    within a single zone, so this code is unnecessary.
    
    Signed-off-by: Allan Stephens <Allan.Stephens@windriver.com>
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index 10ff48be3c01..c4583fe888d8 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -35,7 +35,7 @@
  */
 
 #include "core.h"
-#include "cluster.h"
+#include "addr.h"
 #include "link.h"
 #include "name_distr.h"
 
@@ -107,6 +107,26 @@ static struct sk_buff *named_prepare_buf(u32 type, u32 size, u32 dest)
 	return buf;
 }
 
+static void named_cluster_distribute(struct sk_buff *buf)
+{
+	struct sk_buff *buf_copy;
+	struct tipc_node *n_ptr;
+	u32 n_num;
+
+	for (n_num = 1; n_num <= tipc_net.highest_node; n_num++) {
+		n_ptr = tipc_net.nodes[n_num];
+		if (n_ptr && tipc_node_has_active_links(n_ptr)) {
+			buf_copy = skb_copy(buf, GFP_ATOMIC);
+			if (!buf_copy)
+				break;
+			msg_set_destnode(buf_msg(buf_copy), n_ptr->addr);
+			tipc_link_send(buf_copy, n_ptr->addr, n_ptr->addr);
+		}
+	}
+
+	buf_discard(buf);
+}
+
 /**
  * tipc_named_publish - tell other nodes about a new publication by this node
  */
@@ -127,8 +147,8 @@ void tipc_named_publish(struct publication *publ)
 
 	item = (struct distr_item *)msg_data(buf_msg(buf));
 	publ_to_item(item, publ);
-	dbg("tipc_named_withdraw: broadcasting publish msg\n");
-	tipc_cltr_broadcast(buf);
+	dbg("tipc_named_publish: broadcasting publish msg\n");
+	named_cluster_distribute(buf);
 }
 
 /**
@@ -152,7 +172,7 @@ void tipc_named_withdraw(struct publication *publ)
 	item = (struct distr_item *)msg_data(buf_msg(buf));
 	publ_to_item(item, publ);
 	dbg("tipc_named_withdraw: broadcasting withdraw msg\n");
-	tipc_cltr_broadcast(buf);
+	named_cluster_distribute(buf);
 }
 
 /**

commit c80262829769419e19527f972672e8df0480235a
Author: Allan Stephens <allan.stephens@windriver.com>
Date:   Tue Nov 30 12:00:54 2010 +0000

    tipc: Remove obsolete inclusions of header files
    
    Gets rid of #include statements that are no longer required as a
    result of the merging of obsolete native API header file content
    into other TIPC include files.
    
    Signed-off-by: Allan Stephens <Allan.Stephens@windriver.com>
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index 7b907171f879..10ff48be3c01 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -36,9 +36,7 @@
 
 #include "core.h"
 #include "cluster.h"
-#include "dbg.h"
 #include "link.h"
-#include "msg.h"
 #include "name_distr.h"
 
 #define ITEM_SIZE sizeof(struct distr_item)

commit 31e3c3f6f1f9b154981a0e6620df700463db30ee
Author: stephen hemminger <shemminger@vyatta.com>
Date:   Wed Oct 13 13:20:35 2010 +0000

    tipc: cleanup function namespace
    
    Do some cleanups of TIPC based on make namespacecheck
      1. Don't export unused symbols
      2. Eliminate dead code
      3. Make functions and variables local
      4. Rename buf_acquire to tipc_buf_acquire since it is used in several files
    
    Compile tested only.
    This make break out of tree kernel modules that depend on TIPC routines.
    
    Signed-off-by: Stephen Hemminger <shemminger@vyatta.com>
    Acked-by: Jon Maloy <jon.maloy@ericsson.com>
    Acked-by: Paul Gortmaker <paul.gortmaker@windriver.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index 6ac3c543250b..7b907171f879 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -98,7 +98,7 @@ static void publ_to_item(struct distr_item *i, struct publication *p)
 
 static struct sk_buff *named_prepare_buf(u32 type, u32 size, u32 dest)
 {
-	struct sk_buff *buf = buf_acquire(LONG_H_SIZE + size);
+	struct sk_buff *buf = tipc_buf_acquire(LONG_H_SIZE + size);
 	struct tipc_msg *msg;
 
 	if (buf != NULL) {

commit c68ca7b72017f8f52e7aed0d2a6ecfaede133b6b
Author: Allan Stephens <allan.stephens@windriver.com>
Date:   Tue May 11 14:30:12 2010 +0000

    tipc: add tipc_ prefix to fcns targeted for un-inlining
    
    These functions have enough code in them such that they
    seem like sensible targets for un-inlining.  Prior to doing
    that, this adds the tipc_ prefix to the functions, so that
    in the event of a panic dump or similar, the subsystem from
    which the functions come from is immediately clear.
    
    Signed-off-by: Allan Stephens <allan.stephens@windriver.com>
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index 10a69894e2fd..6ac3c543250b 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -103,7 +103,7 @@ static struct sk_buff *named_prepare_buf(u32 type, u32 size, u32 dest)
 
 	if (buf != NULL) {
 		msg = buf_msg(buf);
-		msg_init(msg, NAME_DISTRIBUTOR, type, LONG_H_SIZE, dest);
+		tipc_msg_init(msg, NAME_DISTRIBUTOR, type, LONG_H_SIZE, dest);
 		msg_set_size(msg, LONG_H_SIZE + size);
 	}
 	return buf;

commit 757152175666681d54d370500e41a756cfedd4fc
Author: Allan Stephens <allan.stephens@windriver.com>
Date:   Wed Jun 4 17:37:34 2008 -0700

    tipc: Optimize message initialization routine
    
    This patch eliminates the rarely-used "error code" argument
    when initializing a TIPC message header, since the default
    value of zero is the desired result in most cases; the few
    exceptional cases now set the error code explicitly.
    
    Signed-off-by: Allan Stephens <allan.stephens@windriver.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index aecba5cd87d6..10a69894e2fd 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -103,8 +103,7 @@ static struct sk_buff *named_prepare_buf(u32 type, u32 size, u32 dest)
 
 	if (buf != NULL) {
 		msg = buf_msg(buf);
-		msg_init(msg, NAME_DISTRIBUTOR, type, TIPC_OK,
-			 LONG_H_SIZE, dest);
+		msg_init(msg, NAME_DISTRIBUTOR, type, LONG_H_SIZE, dest);
 		msg_set_size(msg, LONG_H_SIZE + size);
 	}
 	return buf;

commit 40dbfae440abe6860167f12e0296bd7a1a599839
Author: Allan Stephens <allan.stephens@windriver.com>
Date:   Mon May 5 01:21:54 2008 -0700

    tipc: Fix null pointer dereference in debug code
    
    This patch eliminates an obsolete use of the DBG_OUTPUT print
    buffer which could lead to a null pointer crash in tipc_printf()
    if TIPC's debugging capabilities are configured.
    
    Signed-off-by: Allan Stephens <allan.stephens@windriver.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index 39fd1619febf..aecba5cd87d6 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -41,9 +41,6 @@
 #include "msg.h"
 #include "name_distr.h"
 
-#undef  DBG_OUTPUT
-#define DBG_OUTPUT NULL
-
 #define ITEM_SIZE sizeof(struct distr_item)
 
 /**

commit c43072852649d8382b81237ce51195bcec36f24a
Author: YOSHIFUJI Hideaki <yoshfuji@linux-ipv6.org>
Date:   Fri Feb 9 23:25:21 2007 +0900

    [NET] TIPC: Fix whitespace errors.
    
    Signed-off-by: YOSHIFUJI Hideaki <yoshfuji@linux-ipv6.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index 7bf87cb26ef3..39fd1619febf 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -1,6 +1,6 @@
 /*
  * net/tipc/name_distr.c: TIPC name distribution code
- * 
+ *
  * Copyright (c) 2000-2006, Ericsson AB
  * Copyright (c) 2005, Wind River Systems
  * All rights reserved.
@@ -53,15 +53,15 @@
  * @upper: name sequence upper bound
  * @ref: publishing port reference
  * @key: publication key
- * 
+ *
  * ===> All fields are stored in network byte order. <===
- * 
+ *
  * First 3 fields identify (name or) name sequence being published.
  * Reference field uniquely identifies port that published name sequence.
  * Key field uniquely identifies publication, in the event a port has
  * multiple publications of the same name sequence.
- * 
- * Note: There is no field that identifies the publishing node because it is 
+ *
+ * Note: There is no field that identifies the publishing node because it is
  * the same for all items contained within a publication message.
  */
 
@@ -74,12 +74,12 @@ struct distr_item {
 };
 
 /**
- * List of externally visible publications by this node -- 
+ * List of externally visible publications by this node --
  * that is, all publications having scope > TIPC_NODE_SCOPE.
  */
 
 static LIST_HEAD(publ_root);
-static u32 publ_cnt = 0;		
+static u32 publ_cnt = 0;
 
 /**
  * publ_to_item - add publication info to a publication message
@@ -101,12 +101,12 @@ static void publ_to_item(struct distr_item *i, struct publication *p)
 
 static struct sk_buff *named_prepare_buf(u32 type, u32 size, u32 dest)
 {
-	struct sk_buff *buf = buf_acquire(LONG_H_SIZE + size);  
+	struct sk_buff *buf = buf_acquire(LONG_H_SIZE + size);
 	struct tipc_msg *msg;
 
 	if (buf != NULL) {
 		msg = buf_msg(buf);
-		msg_init(msg, NAME_DISTRIBUTOR, type, TIPC_OK, 
+		msg_init(msg, NAME_DISTRIBUTOR, type, TIPC_OK,
 			 LONG_H_SIZE, dest);
 		msg_set_size(msg, LONG_H_SIZE + size);
 	}
@@ -174,7 +174,7 @@ void tipc_named_node_up(unsigned long node)
 	u32 rest;
 	u32 max_item_buf;
 
-	read_lock_bh(&tipc_nametbl_lock); 
+	read_lock_bh(&tipc_nametbl_lock);
 	max_item_buf = TIPC_MAX_USER_MSG_SIZE / ITEM_SIZE;
 	max_item_buf *= ITEM_SIZE;
 	rest = publ_cnt * ITEM_SIZE;
@@ -183,7 +183,7 @@ void tipc_named_node_up(unsigned long node)
 		if (!buf) {
 			left = (rest <= max_item_buf) ? rest : max_item_buf;
 			rest -= left;
-			buf = named_prepare_buf(PUBLICATION, left, node);       
+			buf = named_prepare_buf(PUBLICATION, left, node);
 			if (!buf) {
 				warn("Bulk publication distribution failure\n");
 				goto exit;
@@ -196,20 +196,20 @@ void tipc_named_node_up(unsigned long node)
 		if (!left) {
 			msg_set_link_selector(buf_msg(buf), node);
 			dbg("tipc_named_node_up: sending publish msg to "
-			    "<%u.%u.%u>\n", tipc_zone(node), 
+			    "<%u.%u.%u>\n", tipc_zone(node),
 			    tipc_cluster(node), tipc_node(node));
 			tipc_link_send(buf, node, node);
 			buf = NULL;
 		}
 	}
 exit:
-	read_unlock_bh(&tipc_nametbl_lock); 
+	read_unlock_bh(&tipc_nametbl_lock);
 }
 
 /**
  * node_is_down - remove publication associated with a failed node
- * 
- * Invoked for each publication issued by a newly failed node.  
+ *
+ * Invoked for each publication issued by a newly failed node.
  * Removes publication structure from name table & deletes it.
  * In rare cases the link may have come back up again when this
  * function is called, and we have two items representing the same
@@ -221,15 +221,15 @@ static void node_is_down(struct publication *publ)
 {
 	struct publication *p;
 
-        write_lock_bh(&tipc_nametbl_lock);
-	dbg("node_is_down: withdrawing %u, %u, %u\n", 
+	write_lock_bh(&tipc_nametbl_lock);
+	dbg("node_is_down: withdrawing %u, %u, %u\n",
 	    publ->type, publ->lower, publ->upper);
-        publ->key += 1222345;
-	p = tipc_nametbl_remove_publ(publ->type, publ->lower, 
+	publ->key += 1222345;
+	p = tipc_nametbl_remove_publ(publ->type, publ->lower,
 				     publ->node, publ->ref, publ->key);
 	write_unlock_bh(&tipc_nametbl_lock);
 
-        if (p != publ) {
+	if (p != publ) {
 		err("Unable to remove publication from failed node\n"
 		    "(type=%u, lower=%u, node=0x%x, ref=%u, key=%u)\n",
 		    publ->type, publ->lower, publ->node, publ->ref, publ->key);
@@ -251,27 +251,27 @@ void tipc_named_recv(struct sk_buff *buf)
 	struct distr_item *item = (struct distr_item *)msg_data(msg);
 	u32 count = msg_data_sz(msg) / ITEM_SIZE;
 
-	write_lock_bh(&tipc_nametbl_lock); 
+	write_lock_bh(&tipc_nametbl_lock);
 	while (count--) {
 		if (msg_type(msg) == PUBLICATION) {
-			dbg("tipc_named_recv: got publication for %u, %u, %u\n", 
+			dbg("tipc_named_recv: got publication for %u, %u, %u\n",
 			    ntohl(item->type), ntohl(item->lower),
 			    ntohl(item->upper));
-			publ = tipc_nametbl_insert_publ(ntohl(item->type), 
+			publ = tipc_nametbl_insert_publ(ntohl(item->type),
 							ntohl(item->lower),
 							ntohl(item->upper),
 							TIPC_CLUSTER_SCOPE,
-							msg_orignode(msg), 
+							msg_orignode(msg),
 							ntohl(item->ref),
 							ntohl(item->key));
 			if (publ) {
-				tipc_nodesub_subscribe(&publ->subscr, 
-						       msg_orignode(msg), 
+				tipc_nodesub_subscribe(&publ->subscr,
+						       msg_orignode(msg),
 						       publ,
 						       (net_ev_handler)node_is_down);
 			}
 		} else if (msg_type(msg) == WITHDRAWAL) {
-			dbg("tipc_named_recv: got withdrawl for %u, %u, %u\n", 
+			dbg("tipc_named_recv: got withdrawl for %u, %u, %u\n",
 			    ntohl(item->type), ntohl(item->lower),
 			    ntohl(item->upper));
 			publ = tipc_nametbl_remove_publ(ntohl(item->type),
@@ -282,7 +282,7 @@ void tipc_named_recv(struct sk_buff *buf)
 
 			if (publ) {
 				tipc_nodesub_unsubscribe(&publ->subscr);
-        			kfree(publ);
+				kfree(publ);
 			} else {
 				err("Unable to remove publication by node 0x%x\n"
 				    "(type=%u, lower=%u, ref=%u, key=%u)\n",
@@ -295,13 +295,13 @@ void tipc_named_recv(struct sk_buff *buf)
 		}
 		item++;
 	}
-	write_unlock_bh(&tipc_nametbl_lock); 
+	write_unlock_bh(&tipc_nametbl_lock);
 	buf_discard(buf);
 }
 
 /**
  * tipc_named_reinit - re-initialize local publication list
- * 
+ *
  * This routine is called whenever TIPC networking is (re)enabled.
  * All existing publications by this node that have "cluster" or "zone" scope
  * are updated to reflect the node's current network address.
@@ -312,11 +312,11 @@ void tipc_named_reinit(void)
 {
 	struct publication *publ;
 
-	write_lock_bh(&tipc_nametbl_lock); 
+	write_lock_bh(&tipc_nametbl_lock);
 	list_for_each_entry(publ, &publ_root, local_list) {
 		if (publ->node == tipc_own_addr)
 			break;
 		publ->node = tipc_own_addr;
 	}
-	write_unlock_bh(&tipc_nametbl_lock); 
+	write_unlock_bh(&tipc_nametbl_lock);
 }

commit 3e6c8cd5669c1202fe806ce3e13d701f20a71c7e
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Wed Nov 8 00:19:09 2006 -0800

    [TIPC]: endianness annotations
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index 03bd659c43ca..7bf87cb26ef3 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -66,11 +66,11 @@
  */
 
 struct distr_item {
-	u32 type;
-	u32 lower;
-	u32 upper;
-	u32 ref;
-	u32 key;
+	__be32 type;
+	__be32 lower;
+	__be32 upper;
+	__be32 ref;
+	__be32 key;
 };
 
 /**

commit 08c31f7167b1bdc30cd0960b45d6f3076eb1f179
Author: Allan Stephens <allan.stephens@windriver.com>
Date:   Mon Oct 16 21:56:04 2006 -0700

    [TIPC]: Name publication events now delivered in chronological order
    
    This patch tivially re-orders the entries in TIPC's list of local
    publications so that applications will receive publication events
    in the order they were published.
    
    Signed-off-by: Allan Stephens <allan.stephens@windriver.com>
    Signed-off-by: Per Liden <per.liden@ericsson.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index f0b063bcc2a9..03bd659c43ca 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -122,7 +122,7 @@ void tipc_named_publish(struct publication *publ)
 	struct sk_buff *buf;
 	struct distr_item *item;
 
-	list_add(&publ->local_list, &publ_root);
+	list_add_tail(&publ->local_list, &publ_root);
 	publ_cnt++;
 
 	buf = named_prepare_buf(PUBLICATION, ITEM_SIZE, 0);

commit a10bd924a421e0e5d5bb9640735b9317b8e473b5
Author: Allan Stephens <allan.stephens@windriver.com>
Date:   Sun Jun 25 23:52:17 2006 -0700

    [TIPC]: Enhanced & cleaned up system messages; fixed 2 obscure memory leaks.
    
    Signed-off-by: Allan Stephens <allan.stephens@windriver.com>
    Signed-off-by: Per Liden <per.liden@ericsson.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index 5718ecb91d33..f0b063bcc2a9 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -127,7 +127,7 @@ void tipc_named_publish(struct publication *publ)
 
 	buf = named_prepare_buf(PUBLICATION, ITEM_SIZE, 0);
 	if (!buf) {
-		warn("Memory squeeze; failed to distribute publication\n");
+		warn("Publication distribution failure\n");
 		return;
 	}
 
@@ -151,7 +151,7 @@ void tipc_named_withdraw(struct publication *publ)
 
 	buf = named_prepare_buf(WITHDRAWAL, ITEM_SIZE, 0);
 	if (!buf) {
-		warn("Memory squeeze; failed to distribute withdrawal\n");
+		warn("Withdrawl distribution failure\n");
 		return;
 	}
 
@@ -184,8 +184,8 @@ void tipc_named_node_up(unsigned long node)
 			left = (rest <= max_item_buf) ? rest : max_item_buf;
 			rest -= left;
 			buf = named_prepare_buf(PUBLICATION, left, node);       
-			if (buf == NULL) {
-				warn("Memory Squeeze; could not send publication\n");
+			if (!buf) {
+				warn("Bulk publication distribution failure\n");
 				goto exit;
 			}
 			item = (struct distr_item *)msg_data(buf_msg(buf));
@@ -291,7 +291,7 @@ void tipc_named_recv(struct sk_buff *buf)
 				    ntohl(item->ref), ntohl(item->key));
 			}
 		} else {
-			warn("tipc_named_recv: unknown msg\n");
+			warn("Unrecognized name table message received\n");
 		}
 		item++;
 	}

commit f131072c3da84e70a0f65d71b3a3f6611c6a22bc
Author: Allan Stephens <allan.stephens@windriver.com>
Date:   Sun Jun 25 23:51:37 2006 -0700

    [TIPC]: First phase of assert() cleanup
    
    This also contains enhancements to simplify comparisons in name table
    publication removal algorithm and to simplify name table sanity checking
    when shutting down TIPC.
    
    Signed-off-by: Allan Stephens <allan.stephens@windriver.com>
    Signed-off-by: Per Liden <per.liden@ericsson.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index a3bbc891f959..5718ecb91d33 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -174,7 +174,6 @@ void tipc_named_node_up(unsigned long node)
 	u32 rest;
 	u32 max_item_buf;
 
-	assert(in_own_cluster(node));
 	read_lock_bh(&tipc_nametbl_lock); 
 	max_item_buf = TIPC_MAX_USER_MSG_SIZE / ITEM_SIZE;
 	max_item_buf *= ITEM_SIZE;
@@ -221,15 +220,24 @@ void tipc_named_node_up(unsigned long node)
 static void node_is_down(struct publication *publ)
 {
 	struct publication *p;
+
         write_lock_bh(&tipc_nametbl_lock);
 	dbg("node_is_down: withdrawing %u, %u, %u\n", 
 	    publ->type, publ->lower, publ->upper);
         publ->key += 1222345;
 	p = tipc_nametbl_remove_publ(publ->type, publ->lower, 
 				     publ->node, publ->ref, publ->key);
-        assert(p == publ);
 	write_unlock_bh(&tipc_nametbl_lock);
-	kfree(publ);
+
+        if (p != publ) {
+		err("Unable to remove publication from failed node\n"
+		    "(type=%u, lower=%u, node=0x%x, ref=%u, key=%u)\n",
+		    publ->type, publ->lower, publ->node, publ->ref, publ->key);
+	}
+
+	if (p) {
+		kfree(p);
+	}
 }
 
 /**
@@ -275,6 +283,12 @@ void tipc_named_recv(struct sk_buff *buf)
 			if (publ) {
 				tipc_nodesub_unsubscribe(&publ->subscr);
         			kfree(publ);
+			} else {
+				err("Unable to remove publication by node 0x%x\n"
+				    "(type=%u, lower=%u, ref=%u, key=%u)\n",
+				    msg_orignode(msg),
+				    ntohl(item->type), ntohl(item->lower),
+				    ntohl(item->ref), ntohl(item->key));
 			}
 		} else {
 			warn("tipc_named_recv: unknown msg\n");

commit 63903ca6af3d9424a0c2b176f927fa7e7ab2ae8e
Author: Jesper Juhl <jesper.juhl@gmail.com>
Date:   Tue Apr 18 14:51:44 2006 -0700

    [NET]: Remove redundant NULL checks before [kv]free
    
    Redundant NULL check before kfree removal
    from net/
    
    Signed-off-by: Jesper Juhl <jesper.juhl@gmail.com>
    Acked-by: James Morris <jmorris@namei.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index 953307a9df1d..a3bbc891f959 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -229,8 +229,7 @@ static void node_is_down(struct publication *publ)
 				     publ->node, publ->ref, publ->key);
         assert(p == publ);
 	write_unlock_bh(&tipc_nametbl_lock);
-	if (publ)
-		kfree(publ);
+	kfree(publ);
 }
 
 /**

commit 1fc54d8f49c1270c584803437fb7c0ac543588c1
Author: Sam Ravnborg <sam@ravnborg.org>
Date:   Mon Mar 20 22:36:47 2006 -0800

    [TIPC]: Fix simple sparse warnings
    
    Tried to run the new tipc stack through sparse.
    Following patch fixes all cases where 0 was used
    as replacement of NULL.
    Use NULL to document this is a pointer and to silence sparse.
    
    This brough sparse warning count down with 127 to 24 warnings.
    
    Signed-off-by: Sam Ravnborg <sam@ravnborg.org>
    Signed-off-by: Per Liden <per.liden@ericsson.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index 830f90999041..953307a9df1d 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -168,8 +168,8 @@ void tipc_named_withdraw(struct publication *publ)
 void tipc_named_node_up(unsigned long node)
 {
 	struct publication *publ;
-	struct distr_item *item = 0;
-	struct sk_buff *buf = 0;
+	struct distr_item *item = NULL;
+	struct sk_buff *buf = NULL;
 	u32 left = 0;
 	u32 rest;
 	u32 max_item_buf;
@@ -200,7 +200,7 @@ void tipc_named_node_up(unsigned long node)
 			    "<%u.%u.%u>\n", tipc_zone(node), 
 			    tipc_cluster(node), tipc_node(node));
 			tipc_link_send(buf, node, node);
-			buf = 0;
+			buf = NULL;
 		}
 	}
 exit:

commit 4323add67792ced172d0d93b8b2e6187023115f1
Author: Per Liden <per.liden@ericsson.com>
Date:   Wed Jan 18 00:38:21 2006 +0100

    [TIPC] Avoid polluting the global namespace
    
    This patch adds a tipc_ prefix to all externally visible symbols.
    
    Signed-off-by: Per Liden <per.liden@ericsson.com>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index 41cbaf1a4a73..830f90999041 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -114,10 +114,10 @@ static struct sk_buff *named_prepare_buf(u32 type, u32 size, u32 dest)
 }
 
 /**
- * named_publish - tell other nodes about a new publication by this node
+ * tipc_named_publish - tell other nodes about a new publication by this node
  */
 
-void named_publish(struct publication *publ)
+void tipc_named_publish(struct publication *publ)
 {
 	struct sk_buff *buf;
 	struct distr_item *item;
@@ -133,15 +133,15 @@ void named_publish(struct publication *publ)
 
 	item = (struct distr_item *)msg_data(buf_msg(buf));
 	publ_to_item(item, publ);
-	dbg("named_withdraw: broadcasting publish msg\n");
-	cluster_broadcast(buf);
+	dbg("tipc_named_withdraw: broadcasting publish msg\n");
+	tipc_cltr_broadcast(buf);
 }
 
 /**
- * named_withdraw - tell other nodes about a withdrawn publication by this node
+ * tipc_named_withdraw - tell other nodes about a withdrawn publication by this node
  */
 
-void named_withdraw(struct publication *publ)
+void tipc_named_withdraw(struct publication *publ)
 {
 	struct sk_buff *buf;
 	struct distr_item *item;
@@ -157,15 +157,15 @@ void named_withdraw(struct publication *publ)
 
 	item = (struct distr_item *)msg_data(buf_msg(buf));
 	publ_to_item(item, publ);
-	dbg("named_withdraw: broadcasting withdraw msg\n");
-	cluster_broadcast(buf);
+	dbg("tipc_named_withdraw: broadcasting withdraw msg\n");
+	tipc_cltr_broadcast(buf);
 }
 
 /**
- * named_node_up - tell specified node about all publications by this node
+ * tipc_named_node_up - tell specified node about all publications by this node
  */
 
-void named_node_up(unsigned long node)
+void tipc_named_node_up(unsigned long node)
 {
 	struct publication *publ;
 	struct distr_item *item = 0;
@@ -175,7 +175,7 @@ void named_node_up(unsigned long node)
 	u32 max_item_buf;
 
 	assert(in_own_cluster(node));
-	read_lock_bh(&nametbl_lock); 
+	read_lock_bh(&tipc_nametbl_lock); 
 	max_item_buf = TIPC_MAX_USER_MSG_SIZE / ITEM_SIZE;
 	max_item_buf *= ITEM_SIZE;
 	rest = publ_cnt * ITEM_SIZE;
@@ -196,15 +196,15 @@ void named_node_up(unsigned long node)
 		left -= ITEM_SIZE;
 		if (!left) {
 			msg_set_link_selector(buf_msg(buf), node);
-			dbg("named_node_up: sending publish msg to "
+			dbg("tipc_named_node_up: sending publish msg to "
 			    "<%u.%u.%u>\n", tipc_zone(node), 
 			    tipc_cluster(node), tipc_node(node));
-			link_send(buf, node, node);
+			tipc_link_send(buf, node, node);
 			buf = 0;
 		}
 	}
 exit:
-	read_unlock_bh(&nametbl_lock); 
+	read_unlock_bh(&tipc_nametbl_lock); 
 }
 
 /**
@@ -221,73 +221,73 @@ void named_node_up(unsigned long node)
 static void node_is_down(struct publication *publ)
 {
 	struct publication *p;
-        write_lock_bh(&nametbl_lock);
+        write_lock_bh(&tipc_nametbl_lock);
 	dbg("node_is_down: withdrawing %u, %u, %u\n", 
 	    publ->type, publ->lower, publ->upper);
         publ->key += 1222345;
-	p = nametbl_remove_publ(publ->type, publ->lower, 
-				publ->node, publ->ref, publ->key);
+	p = tipc_nametbl_remove_publ(publ->type, publ->lower, 
+				     publ->node, publ->ref, publ->key);
         assert(p == publ);
-	write_unlock_bh(&nametbl_lock);
+	write_unlock_bh(&tipc_nametbl_lock);
 	if (publ)
 		kfree(publ);
 }
 
 /**
- * named_recv - process name table update message sent by another node
+ * tipc_named_recv - process name table update message sent by another node
  */
 
-void named_recv(struct sk_buff *buf)
+void tipc_named_recv(struct sk_buff *buf)
 {
 	struct publication *publ;
 	struct tipc_msg *msg = buf_msg(buf);
 	struct distr_item *item = (struct distr_item *)msg_data(msg);
 	u32 count = msg_data_sz(msg) / ITEM_SIZE;
 
-	write_lock_bh(&nametbl_lock); 
+	write_lock_bh(&tipc_nametbl_lock); 
 	while (count--) {
 		if (msg_type(msg) == PUBLICATION) {
-			dbg("named_recv: got publication for %u, %u, %u\n", 
+			dbg("tipc_named_recv: got publication for %u, %u, %u\n", 
 			    ntohl(item->type), ntohl(item->lower),
 			    ntohl(item->upper));
-			publ = nametbl_insert_publ(ntohl(item->type), 
-						   ntohl(item->lower),
-						   ntohl(item->upper),
-						   TIPC_CLUSTER_SCOPE,
-						   msg_orignode(msg), 
-						   ntohl(item->ref),
-						   ntohl(item->key));
+			publ = tipc_nametbl_insert_publ(ntohl(item->type), 
+							ntohl(item->lower),
+							ntohl(item->upper),
+							TIPC_CLUSTER_SCOPE,
+							msg_orignode(msg), 
+							ntohl(item->ref),
+							ntohl(item->key));
 			if (publ) {
-				nodesub_subscribe(&publ->subscr, 
-						  msg_orignode(msg), 
-						  publ,
-						  (net_ev_handler)node_is_down);
+				tipc_nodesub_subscribe(&publ->subscr, 
+						       msg_orignode(msg), 
+						       publ,
+						       (net_ev_handler)node_is_down);
 			}
 		} else if (msg_type(msg) == WITHDRAWAL) {
-			dbg("named_recv: got withdrawl for %u, %u, %u\n", 
+			dbg("tipc_named_recv: got withdrawl for %u, %u, %u\n", 
 			    ntohl(item->type), ntohl(item->lower),
 			    ntohl(item->upper));
-			publ = nametbl_remove_publ(ntohl(item->type),
-						   ntohl(item->lower),
-						   msg_orignode(msg),
-						   ntohl(item->ref),
-						   ntohl(item->key));
+			publ = tipc_nametbl_remove_publ(ntohl(item->type),
+							ntohl(item->lower),
+							msg_orignode(msg),
+							ntohl(item->ref),
+							ntohl(item->key));
 
 			if (publ) {
-				nodesub_unsubscribe(&publ->subscr);
+				tipc_nodesub_unsubscribe(&publ->subscr);
         			kfree(publ);
 			}
 		} else {
-			warn("named_recv: unknown msg\n");
+			warn("tipc_named_recv: unknown msg\n");
 		}
 		item++;
 	}
-	write_unlock_bh(&nametbl_lock); 
+	write_unlock_bh(&tipc_nametbl_lock); 
 	buf_discard(buf);
 }
 
 /**
- * named_reinit - re-initialize local publication list
+ * tipc_named_reinit - re-initialize local publication list
  * 
  * This routine is called whenever TIPC networking is (re)enabled.
  * All existing publications by this node that have "cluster" or "zone" scope
@@ -295,15 +295,15 @@ void named_recv(struct sk_buff *buf)
  * (If the node's address is unchanged, the update loop terminates immediately.)
  */
 
-void named_reinit(void)
+void tipc_named_reinit(void)
 {
 	struct publication *publ;
 
-	write_lock_bh(&nametbl_lock); 
+	write_lock_bh(&tipc_nametbl_lock); 
 	list_for_each_entry(publ, &publ_root, local_list) {
 		if (publ->node == tipc_own_addr)
 			break;
 		publ->node = tipc_own_addr;
 	}
-	write_unlock_bh(&nametbl_lock); 
+	write_unlock_bh(&tipc_nametbl_lock); 
 }

commit 593a5f22d8035b1396a958b6bbde9f13c0f09549
Author: Per Liden <per.liden@nospam.ericsson.com>
Date:   Wed Jan 11 19:14:19 2006 +0100

    [TIPC] More updates of file headers
    
    Updated copyright notice to include the year the file was
    actually created. Information about file creation dates
    was extracted from the files in the old CVS repository
    at tipc.sourceforge.net.
    
    Signed-off-by: Per Liden <per.liden@nospam.ericsson.com>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index 93ac2b25220e..41cbaf1a4a73 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -1,7 +1,7 @@
 /*
  * net/tipc/name_distr.c: TIPC name distribution code
  * 
- * Copyright (c) 2003-2006, Ericsson AB
+ * Copyright (c) 2000-2006, Ericsson AB
  * Copyright (c) 2005, Wind River Systems
  * All rights reserved.
  *

commit 9da1c8b694f8e72a16f259614caaae50cbcdaf10
Author: Per Liden <per.liden@nospam.ericsson.com>
Date:   Wed Jan 11 18:40:41 2006 +0100

    [TIPC] Update of file headers
    
    The copyright statements from different parts of Ericsson
    have been merged into one.
    
    Signed-off-by: Per Liden <per.liden@nospam.ericsson.com>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index 31448272a13a..93ac2b25220e 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -1,9 +1,8 @@
 /*
  * net/tipc/name_distr.c: TIPC name distribution code
  * 
- * Copyright (c) 2003-2005, Ericsson Research Canada
+ * Copyright (c) 2003-2006, Ericsson AB
  * Copyright (c) 2005, Wind River Systems
- * Copyright (c) 2005-2006, Ericsson AB
  * All rights reserved.
  *
  * Redistribution and use in source and binary forms, with or without

commit 9ea1fd3c1a15c620d1e3d0aa269d34b705477003
Author: Per Liden <per.liden@nospam.ericsson.com>
Date:   Wed Jan 11 13:30:43 2006 +0100

    [TIPC] License header update
    
    The license header in each file now more clearly state that this
    code is licensed under a dual BSD/GPL. Before this was only
    evident if you looked at the MODULE_LICENSE line in core.c.
    
    Signed-off-by: Per Liden <per.liden@nospam.ericsson.com>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
index 5e0604cb3aeb..31448272a13a 100644
--- a/net/tipc/name_distr.c
+++ b/net/tipc/name_distr.c
@@ -6,28 +6,32 @@
  * Copyright (c) 2005-2006, Ericsson AB
  * All rights reserved.
  *
- * Redistribution and use in source and binary forms, with or without 
+ * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
- * Redistributions of source code must retain the above copyright notice, this 
- * list of conditions and the following disclaimer.
- * Redistributions in binary form must reproduce the above copyright notice, 
- * this list of conditions and the following disclaimer in the documentation 
- * and/or other materials provided with the distribution.
- * Neither the names of the copyright holders nor the names of its 
- * contributors may be used to endorse or promote products derived from this 
- * software without specific prior written permission.
+ * 1. Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ * 3. Neither the names of the copyright holders nor the names of its
+ *    contributors may be used to endorse or promote products derived from
+ *    this software without specific prior written permission.
  *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" 
- * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE 
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE 
- * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE 
- * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR 
- * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF 
- * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS 
- * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN 
- * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) 
- * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE 
+ * Alternatively, this software may be distributed under the terms of the
+ * GNU General Public License ("GPL") version 2 as published by the Free
+ * Software Foundation.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE
+ * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+ * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+ * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
  * POSSIBILITY OF SUCH DAMAGE.
  */
 

commit b97bf3fd8f6a16966d4f18983b2c40993ff937d4
Author: Per Liden <per.liden@nospam.ericsson.com>
Date:   Mon Jan 2 19:04:38 2006 +0100

    [TIPC] Initial merge
    
    TIPC (Transparent Inter Process Communication) is a protocol designed for
    intra cluster communication. For more information see
    http://tipc.sourceforge.net
    
    Signed-off-by: Per Liden <per.liden@nospam.ericsson.com>

diff --git a/net/tipc/name_distr.c b/net/tipc/name_distr.c
new file mode 100644
index 000000000000..5e0604cb3aeb
--- /dev/null
+++ b/net/tipc/name_distr.c
@@ -0,0 +1,306 @@
+/*
+ * net/tipc/name_distr.c: TIPC name distribution code
+ * 
+ * Copyright (c) 2003-2005, Ericsson Research Canada
+ * Copyright (c) 2005, Wind River Systems
+ * Copyright (c) 2005-2006, Ericsson AB
+ * All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without 
+ * modification, are permitted provided that the following conditions are met:
+ *
+ * Redistributions of source code must retain the above copyright notice, this 
+ * list of conditions and the following disclaimer.
+ * Redistributions in binary form must reproduce the above copyright notice, 
+ * this list of conditions and the following disclaimer in the documentation 
+ * and/or other materials provided with the distribution.
+ * Neither the names of the copyright holders nor the names of its 
+ * contributors may be used to endorse or promote products derived from this 
+ * software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" 
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE 
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE 
+ * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE 
+ * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR 
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF 
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS 
+ * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN 
+ * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) 
+ * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE 
+ * POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include "core.h"
+#include "cluster.h"
+#include "dbg.h"
+#include "link.h"
+#include "msg.h"
+#include "name_distr.h"
+
+#undef  DBG_OUTPUT
+#define DBG_OUTPUT NULL
+
+#define ITEM_SIZE sizeof(struct distr_item)
+
+/**
+ * struct distr_item - publication info distributed to other nodes
+ * @type: name sequence type
+ * @lower: name sequence lower bound
+ * @upper: name sequence upper bound
+ * @ref: publishing port reference
+ * @key: publication key
+ * 
+ * ===> All fields are stored in network byte order. <===
+ * 
+ * First 3 fields identify (name or) name sequence being published.
+ * Reference field uniquely identifies port that published name sequence.
+ * Key field uniquely identifies publication, in the event a port has
+ * multiple publications of the same name sequence.
+ * 
+ * Note: There is no field that identifies the publishing node because it is 
+ * the same for all items contained within a publication message.
+ */
+
+struct distr_item {
+	u32 type;
+	u32 lower;
+	u32 upper;
+	u32 ref;
+	u32 key;
+};
+
+/**
+ * List of externally visible publications by this node -- 
+ * that is, all publications having scope > TIPC_NODE_SCOPE.
+ */
+
+static LIST_HEAD(publ_root);
+static u32 publ_cnt = 0;		
+
+/**
+ * publ_to_item - add publication info to a publication message
+ */
+
+static void publ_to_item(struct distr_item *i, struct publication *p)
+{
+	i->type = htonl(p->type);
+	i->lower = htonl(p->lower);
+	i->upper = htonl(p->upper);
+	i->ref = htonl(p->ref);
+	i->key = htonl(p->key);
+	dbg("publ_to_item: %u, %u, %u\n", p->type, p->lower, p->upper);
+}
+
+/**
+ * named_prepare_buf - allocate & initialize a publication message
+ */
+
+static struct sk_buff *named_prepare_buf(u32 type, u32 size, u32 dest)
+{
+	struct sk_buff *buf = buf_acquire(LONG_H_SIZE + size);  
+	struct tipc_msg *msg;
+
+	if (buf != NULL) {
+		msg = buf_msg(buf);
+		msg_init(msg, NAME_DISTRIBUTOR, type, TIPC_OK, 
+			 LONG_H_SIZE, dest);
+		msg_set_size(msg, LONG_H_SIZE + size);
+	}
+	return buf;
+}
+
+/**
+ * named_publish - tell other nodes about a new publication by this node
+ */
+
+void named_publish(struct publication *publ)
+{
+	struct sk_buff *buf;
+	struct distr_item *item;
+
+	list_add(&publ->local_list, &publ_root);
+	publ_cnt++;
+
+	buf = named_prepare_buf(PUBLICATION, ITEM_SIZE, 0);
+	if (!buf) {
+		warn("Memory squeeze; failed to distribute publication\n");
+		return;
+	}
+
+	item = (struct distr_item *)msg_data(buf_msg(buf));
+	publ_to_item(item, publ);
+	dbg("named_withdraw: broadcasting publish msg\n");
+	cluster_broadcast(buf);
+}
+
+/**
+ * named_withdraw - tell other nodes about a withdrawn publication by this node
+ */
+
+void named_withdraw(struct publication *publ)
+{
+	struct sk_buff *buf;
+	struct distr_item *item;
+
+	list_del(&publ->local_list);
+	publ_cnt--;
+
+	buf = named_prepare_buf(WITHDRAWAL, ITEM_SIZE, 0);
+	if (!buf) {
+		warn("Memory squeeze; failed to distribute withdrawal\n");
+		return;
+	}
+
+	item = (struct distr_item *)msg_data(buf_msg(buf));
+	publ_to_item(item, publ);
+	dbg("named_withdraw: broadcasting withdraw msg\n");
+	cluster_broadcast(buf);
+}
+
+/**
+ * named_node_up - tell specified node about all publications by this node
+ */
+
+void named_node_up(unsigned long node)
+{
+	struct publication *publ;
+	struct distr_item *item = 0;
+	struct sk_buff *buf = 0;
+	u32 left = 0;
+	u32 rest;
+	u32 max_item_buf;
+
+	assert(in_own_cluster(node));
+	read_lock_bh(&nametbl_lock); 
+	max_item_buf = TIPC_MAX_USER_MSG_SIZE / ITEM_SIZE;
+	max_item_buf *= ITEM_SIZE;
+	rest = publ_cnt * ITEM_SIZE;
+
+	list_for_each_entry(publ, &publ_root, local_list) {
+		if (!buf) {
+			left = (rest <= max_item_buf) ? rest : max_item_buf;
+			rest -= left;
+			buf = named_prepare_buf(PUBLICATION, left, node);       
+			if (buf == NULL) {
+				warn("Memory Squeeze; could not send publication\n");
+				goto exit;
+			}
+			item = (struct distr_item *)msg_data(buf_msg(buf));
+		}
+		publ_to_item(item, publ);
+		item++;
+		left -= ITEM_SIZE;
+		if (!left) {
+			msg_set_link_selector(buf_msg(buf), node);
+			dbg("named_node_up: sending publish msg to "
+			    "<%u.%u.%u>\n", tipc_zone(node), 
+			    tipc_cluster(node), tipc_node(node));
+			link_send(buf, node, node);
+			buf = 0;
+		}
+	}
+exit:
+	read_unlock_bh(&nametbl_lock); 
+}
+
+/**
+ * node_is_down - remove publication associated with a failed node
+ * 
+ * Invoked for each publication issued by a newly failed node.  
+ * Removes publication structure from name table & deletes it.
+ * In rare cases the link may have come back up again when this
+ * function is called, and we have two items representing the same
+ * publication. Nudge this item's key to distinguish it from the other.
+ * (Note: Publication's node subscription is already unsubscribed.)
+ */
+
+static void node_is_down(struct publication *publ)
+{
+	struct publication *p;
+        write_lock_bh(&nametbl_lock);
+	dbg("node_is_down: withdrawing %u, %u, %u\n", 
+	    publ->type, publ->lower, publ->upper);
+        publ->key += 1222345;
+	p = nametbl_remove_publ(publ->type, publ->lower, 
+				publ->node, publ->ref, publ->key);
+        assert(p == publ);
+	write_unlock_bh(&nametbl_lock);
+	if (publ)
+		kfree(publ);
+}
+
+/**
+ * named_recv - process name table update message sent by another node
+ */
+
+void named_recv(struct sk_buff *buf)
+{
+	struct publication *publ;
+	struct tipc_msg *msg = buf_msg(buf);
+	struct distr_item *item = (struct distr_item *)msg_data(msg);
+	u32 count = msg_data_sz(msg) / ITEM_SIZE;
+
+	write_lock_bh(&nametbl_lock); 
+	while (count--) {
+		if (msg_type(msg) == PUBLICATION) {
+			dbg("named_recv: got publication for %u, %u, %u\n", 
+			    ntohl(item->type), ntohl(item->lower),
+			    ntohl(item->upper));
+			publ = nametbl_insert_publ(ntohl(item->type), 
+						   ntohl(item->lower),
+						   ntohl(item->upper),
+						   TIPC_CLUSTER_SCOPE,
+						   msg_orignode(msg), 
+						   ntohl(item->ref),
+						   ntohl(item->key));
+			if (publ) {
+				nodesub_subscribe(&publ->subscr, 
+						  msg_orignode(msg), 
+						  publ,
+						  (net_ev_handler)node_is_down);
+			}
+		} else if (msg_type(msg) == WITHDRAWAL) {
+			dbg("named_recv: got withdrawl for %u, %u, %u\n", 
+			    ntohl(item->type), ntohl(item->lower),
+			    ntohl(item->upper));
+			publ = nametbl_remove_publ(ntohl(item->type),
+						   ntohl(item->lower),
+						   msg_orignode(msg),
+						   ntohl(item->ref),
+						   ntohl(item->key));
+
+			if (publ) {
+				nodesub_unsubscribe(&publ->subscr);
+        			kfree(publ);
+			}
+		} else {
+			warn("named_recv: unknown msg\n");
+		}
+		item++;
+	}
+	write_unlock_bh(&nametbl_lock); 
+	buf_discard(buf);
+}
+
+/**
+ * named_reinit - re-initialize local publication list
+ * 
+ * This routine is called whenever TIPC networking is (re)enabled.
+ * All existing publications by this node that have "cluster" or "zone" scope
+ * are updated to reflect the node's current network address.
+ * (If the node's address is unchanged, the update loop terminates immediately.)
+ */
+
+void named_reinit(void)
+{
+	struct publication *publ;
+
+	write_lock_bh(&nametbl_lock); 
+	list_for_each_entry(publ, &publ_root, local_list) {
+		if (publ->node == tipc_own_addr)
+			break;
+		publ->node = tipc_own_addr;
+	}
+	write_unlock_bh(&nametbl_lock); 
+}
