commit 31d518f35e1a80268a24a855be9477eb458540ad
Merge: 9e860947d8d7 738d2902773e
Author: David S. Miller <davem@davemloft.net>
Date:   Tue Dec 31 13:37:13 2019 -0800

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net
    
    Simple overlapping changes in bpf land wrt. bpf_helper_defs.h
    handling.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit bd085ef678b2cc8c38c105673dfe8ff8f5ec0c57
Author: Hangbin Liu <liuhangbin@gmail.com>
Date:   Sun Dec 22 10:51:09 2019 +0800

    net: add bool confirm_neigh parameter for dst_ops.update_pmtu
    
    The MTU update code is supposed to be invoked in response to real
    networking events that update the PMTU. In IPv6 PMTU update function
    __ip6_rt_update_pmtu() we called dst_confirm_neigh() to update neighbor
    confirmed time.
    
    But for tunnel code, it will call pmtu before xmit, like:
      - tnl_update_pmtu()
        - skb_dst_update_pmtu()
          - ip6_rt_update_pmtu()
            - __ip6_rt_update_pmtu()
              - dst_confirm_neigh()
    
    If the tunnel remote dst mac address changed and we still do the neigh
    confirm, we will not be able to update neigh cache and ping6 remote
    will failed.
    
    So for this ip_tunnel_xmit() case, _EVEN_ if the MTU is changed, we
    should not be invoking dst_confirm_neigh() as we have no evidence
    of successful two-way communication at this point.
    
    On the other hand it is also important to keep the neigh reachability fresh
    for TCP flows, so we cannot remove this dst_confirm_neigh() call.
    
    To fix the issue, we have to add a new bool parameter for dst_ops.update_pmtu
    to choose whether we should do neigh update or not. I will add the parameter
    in this patch and set all the callers to true to comply with the previous
    way, and fix the tunnel code one by one on later patches.
    
    v5: No change.
    v4: No change.
    v3: Do not remove dst_confirm_neigh, but add a new bool parameter in
        dst_ops.update_pmtu to control whether we should do neighbor confirm.
        Also split the big patch to small ones for each area.
    v2: Remove dst_confirm_neigh in __ip6_rt_update_pmtu.
    
    Suggested-by: David Miller <davem@davemloft.net>
    Reviewed-by: Guillaume Nault <gnault@redhat.com>
    Acked-by: David Ahern <dsahern@gmail.com>
    Signed-off-by: Hangbin Liu <liuhangbin@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index 7235a6032671..3bbe1a58ec87 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -263,7 +263,7 @@ bool sctp_transport_update_pmtu(struct sctp_transport *t, u32 pmtu)
 
 		pf->af->from_sk(&addr, sk);
 		pf->to_sk_daddr(&t->ipaddr, sk);
-		dst->ops->update_pmtu(dst, sk, NULL, pmtu);
+		dst->ops->update_pmtu(dst, sk, NULL, pmtu, true);
 		pf->to_sk_daddr(&addr, sk);
 
 		dst = sctp_transport_dst_check(t);

commit 4e7696d90b51a1a73ce0e8174f3aff58b914619c
Author: Xin Long <lucien.xin@gmail.com>
Date:   Mon Dec 9 13:45:18 2019 +0800

    sctp: get netns from asoc and ep base
    
    Commit 312434617cb1 ("sctp: cache netns in sctp_ep_common") set netns
    in asoc and ep base since they're created, and it will never change.
    It's a better way to get netns from asoc and ep base, comparing to
    calling sock_net().
    
    This patch is to replace them.
    
    v1->v2:
      - no change.
    
    Suggested-by: Marcelo Ricardo Leitner <marcelo.leitner@gmail.com>
    Signed-off-by: Xin Long <lucien.xin@gmail.com>
    Acked-by: Neil Horman <nhorman@tuxdriver.com>
    Acked-by: Marcelo Ricardo Leitner <marcelo.leitner@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index 7235a6032671..f4de064598f8 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -334,7 +334,7 @@ void sctp_transport_update_rto(struct sctp_transport *tp, __u32 rtt)
 		pr_debug("%s: rto_pending not set on transport %p!\n", __func__, tp);
 
 	if (tp->rttvar || tp->srtt) {
-		struct net *net = sock_net(tp->asoc->base.sk);
+		struct net *net = tp->asoc->base.net;
 		/* 6.3.1 C3) When a new RTT measurement R' is made, set
 		 * RTTVAR <- (1 - RTO.Beta) * RTTVAR + RTO.Beta * |SRTT - R'|
 		 * SRTT <- (1 - RTO.Alpha) * SRTT + RTO.Alpha * R'

commit 4c31bc6b1e2ee9c21608506431783dfa525b9989
Author: Xin Long <lucien.xin@gmail.com>
Date:   Tue Jul 30 20:38:19 2019 +0800

    sctp: only copy the available addr data in sctp_transport_init
    
    'addr' passed to sctp_transport_init is not always a whole size
    of union sctp_addr, like the path:
    
      sctp_sendmsg() ->
      sctp_sendmsg_new_asoc() ->
      sctp_assoc_add_peer() ->
      sctp_transport_new() -> sctp_transport_init()
    
    In the next patches, we will also pass the address length of data
    only to sctp_assoc_add_peer().
    
    So sctp_transport_init() should copy the only available data from
    addr to peer->ipaddr, instead of 'peer->ipaddr = *addr' which may
    cause slab-out-of-bounds.
    
    Signed-off-by: Xin Long <lucien.xin@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index e2f8e369cd08..7235a6032671 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -43,8 +43,8 @@ static struct sctp_transport *sctp_transport_init(struct net *net,
 						  gfp_t gfp)
 {
 	/* Copy in the address.  */
-	peer->ipaddr = *addr;
 	peer->af_specific = sctp_get_af_specific(addr->sa.sa_family);
+	memcpy(&peer->ipaddr, addr, peer->af_specific->sockaddr_len);
 	memset(&peer->saddr, 0, sizeof(union sctp_addr));
 
 	peer->sack_generation = 0;

commit 47505b8bcfcffffe878ea1fee412922f3bfd7262
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu May 23 11:14:41 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 104
    
    Based on 1 normalized pattern(s):
    
      this sctp implementation is free software you can redistribute it
      and or modify it under the terms of the gnu general public license
      as published by the free software foundation either version 2 or at
      your option any later version this sctp implementation is
      distributed in the hope that it will be useful but without any
      warranty without even the implied warranty of merchantability or
      fitness for a particular purpose see the gnu general public license
      for more details you should have received a copy of the gnu general
      public license along with gnu cc see the file copying if not see
      http www gnu org licenses
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-or-later
    
    has been chosen to replace the boilerplate/reference in 42 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Richard Fontana <rfontana@redhat.com>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190523091649.683323110@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index ad158d311ffa..e2f8e369cd08 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -1,3 +1,4 @@
+// SPDX-License-Identifier: GPL-2.0-or-later
 /* SCTP kernel implementation
  * Copyright (c) 1999-2000 Cisco, Inc.
  * Copyright (c) 1999-2001 Motorola, Inc.
@@ -11,22 +12,6 @@
  * a remote transport address.  For local transport addresses, we just use
  * union sctp_addr.
  *
- * This SCTP implementation is free software;
- * you can redistribute it and/or modify it under the terms of
- * the GNU General Public License as published by
- * the Free Software Foundation; either version 2, or (at your option)
- * any later version.
- *
- * This SCTP implementation is distributed in the hope that it
- * will be useful, but WITHOUT ANY WARRANTY; without even the implied
- *                 ************************
- * warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
- * See the GNU General Public License for more details.
- *
- * You should have received a copy of the GNU General Public License
- * along with GNU CC; see the file COPYING.  If not, see
- * <http://www.gnu.org/licenses/>.
- *
  * Please send any bug reports or fixes you make to the
  * email address(es):
  *    lksctp developers <linux-sctp@vger.kernel.org>

commit d1f20c03f48102e52eb98b8651d129b83134cae4
Author: Maciej Kwiecien <maciej.kwiecien@nokia.com>
Date:   Fri Feb 22 09:45:26 2019 +0100

    sctp: don't compare hb_timer expire date before starting it
    
    hb_timer might not start at all for a particular transport because its
    start is conditional. In a result a node is not sending heartbeats.
    
    Function sctp_transport_reset_hb_timer has two roles:
        - initial start of hb_timer for a given transport,
        - update expire date of hb_timer for a given transport.
    The function is optimized to update timer's expire only if it is before
    a new calculated one but this comparison is invalid for a timer which
    has not yet started. Such a timer has expire == 0 and if a new expire
    value is bigger than (MAX_JIFFIES / 2 + 2) then "time_before" macro will
    fail and timer will not start resulting in no heartbeat packets send by
    the node.
    
    This was found when association was initialized within first 5 mins
    after system boot due to jiffies init value which is near to MAX_JIFFIES.
    
    Test kernel version: 4.9.154 (ARCH=arm)
    hb_timer.expire = 0;                //initialized, not started timer
    new_expire = MAX_JIFFIES / 2 + 2;   //or more
    time_before(hb_timer.expire, new_expire) == false
    
    Fixes: ba6f5e33bdbb ("sctp: avoid refreshing heartbeat timer too often")
    Reported-by: Marcin Stojek <marcin.stojek@nokia.com>
    Tested-by: Marcin Stojek <marcin.stojek@nokia.com>
    Signed-off-by: Maciej Kwiecien <maciej.kwiecien@nokia.com>
    Reviewed-by: Alexander Sverdlin <alexander.sverdlin@nokia.com>
    Acked-by: Marcelo Ricardo Leitner <marcelo.leitner@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index 033696e6f74f..ad158d311ffa 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -207,7 +207,8 @@ void sctp_transport_reset_hb_timer(struct sctp_transport *transport)
 
 	/* When a data chunk is sent, reset the heartbeat interval.  */
 	expires = jiffies + sctp_transport_timeout(transport);
-	if (time_before(transport->hb_timer.expires, expires) &&
+	if ((time_before(transport->hb_timer.expires, expires) ||
+	     !timer_pending(&transport->hb_timer)) &&
 	    !mod_timer(&transport->hb_timer,
 		       expires + prandom_u32_max(transport->rto)))
 		sctp_transport_hold(transport);

commit d7ab5cdce54da631f0c8c11e506c974536a3581e
Author: Xin Long <lucien.xin@gmail.com>
Date:   Thu Sep 20 17:27:28 2018 +0800

    sctp: update dst pmtu with the correct daddr
    
    When processing pmtu update from an icmp packet, it calls .update_pmtu
    with sk instead of skb in sctp_transport_update_pmtu.
    
    However for sctp, the daddr in the transport might be different from
    inet_sock->inet_daddr or sk->sk_v6_daddr, which is used to update or
    create the route cache. The incorrect daddr will cause a different
    route cache created for the path.
    
    So before calling .update_pmtu, inet_sock->inet_daddr/sk->sk_v6_daddr
    should be updated with the daddr in the transport, and update it back
    after it's done.
    
    The issue has existed since route exceptions introduction.
    
    Fixes: 4895c771c7f0 ("ipv4: Add FIB nexthop exceptions.")
    Reported-by: ian.periam@dialogic.com
    Signed-off-by: Xin Long <lucien.xin@gmail.com>
    Acked-by: Marcelo Ricardo Leitner <marcelo.leitner@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index 12cac85da994..033696e6f74f 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -260,6 +260,7 @@ void sctp_transport_pmtu(struct sctp_transport *transport, struct sock *sk)
 bool sctp_transport_update_pmtu(struct sctp_transport *t, u32 pmtu)
 {
 	struct dst_entry *dst = sctp_transport_dst_check(t);
+	struct sock *sk = t->asoc->base.sk;
 	bool change = true;
 
 	if (unlikely(pmtu < SCTP_DEFAULT_MINSEGMENT)) {
@@ -271,12 +272,19 @@ bool sctp_transport_update_pmtu(struct sctp_transport *t, u32 pmtu)
 	pmtu = SCTP_TRUNC4(pmtu);
 
 	if (dst) {
-		dst->ops->update_pmtu(dst, t->asoc->base.sk, NULL, pmtu);
+		struct sctp_pf *pf = sctp_get_pf_specific(dst->ops->family);
+		union sctp_addr addr;
+
+		pf->af->from_sk(&addr, sk);
+		pf->to_sk_daddr(&t->ipaddr, sk);
+		dst->ops->update_pmtu(dst, sk, NULL, pmtu);
+		pf->to_sk_daddr(&addr, sk);
+
 		dst = sctp_transport_dst_check(t);
 	}
 
 	if (!dst) {
-		t->af_specific->get_dst(t, &t->saddr, &t->fl, t->asoc->base.sk);
+		t->af_specific->get_dst(t, &t->saddr, &t->fl, sk);
 		dst = t->dst;
 	}
 

commit a65925475571953da12a9bc2082aec29d4e2c0e7
Author: Xin Long <lucien.xin@gmail.com>
Date:   Tue Jul 3 16:30:47 2018 +0800

    sctp: fix the issue that pathmtu may be set lower than MINSEGMENT
    
    After commit b6c5734db070 ("sctp: fix the handling of ICMP Frag Needed
    for too small MTUs"), sctp_transport_update_pmtu would refetch pathmtu
    from the dst and set it to transport's pathmtu without any check.
    
    The new pathmtu may be lower than MINSEGMENT if the dst is obsolete and
    updated by .get_dst() in sctp_transport_update_pmtu. In this case, it
    could have a smaller MTU as well, and thus we should validate it
    against MINSEGMENT instead.
    
    Syzbot reported a warning in sctp_mtu_payload caused by this.
    
    This patch refetches the pathmtu by calling sctp_dst_mtu where it does
    the check against MINSEGMENT.
    
    v1->v2:
      - refetch the pathmtu by calling sctp_dst_mtu instead as Marcelo's
        suggestion.
    
    Fixes: b6c5734db070 ("sctp: fix the handling of ICMP Frag Needed for too small MTUs")
    Reported-by: syzbot+f0d9d7cba052f9344b03@syzkaller.appspotmail.com
    Suggested-by: Marcelo Ricardo Leitner <marcelo.leitner@gmail.com>
    Signed-off-by: Xin Long <lucien.xin@gmail.com>
    Acked-by: Marcelo Ricardo Leitner <marcelo.leitner@gmail.com>
    Acked-by: Neil Horman <nhorman@tuxdriver.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index 445b7ef61677..12cac85da994 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -282,7 +282,7 @@ bool sctp_transport_update_pmtu(struct sctp_transport *t, u32 pmtu)
 
 	if (dst) {
 		/* Re-fetch, as under layers may have a higher minimum size */
-		pmtu = SCTP_TRUNC4(dst_mtu(dst));
+		pmtu = sctp_dst_mtu(dst);
 		change = t->pathmtu != pmtu;
 	}
 	t->pathmtu = pmtu;

commit 1d88ba1ebb2763aa86172cd7ca05dedbeccc0d35
Author: Xin Long <lucien.xin@gmail.com>
Date:   Tue Jun 5 12:16:58 2018 +0800

    sctp: not allow transport timeout value less than HZ/5 for hb_timer
    
    syzbot reported a rcu_sched self-detected stall on CPU which is caused
    by too small value set on rto_min with SCTP_RTOINFO sockopt. With this
    value, hb_timer will get stuck there, as in its timer handler it starts
    this timer again with this value, then goes to the timer handler again.
    
    This problem is there since very beginning, and thanks to Eric for the
    reproducer shared from a syzbot mail.
    
    This patch fixes it by not allowing sctp_transport_timeout to return a
    smaller value than HZ/5 for hb_timer, which is based on TCP's min rto.
    
    Note that it doesn't fix this issue by limiting rto_min, as some users
    are still using small rto and no proper value was found for it yet.
    
    Reported-by: syzbot+3dcd59a1f907245f891f@syzkaller.appspotmail.com
    Suggested-by: Marcelo Ricardo Leitner <marcelo.leitner@gmail.com>
    Signed-off-by: Xin Long <lucien.xin@gmail.com>
    Acked-by: Neil Horman <nhorman@tuxdriver.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index 4a95e260b674..445b7ef61677 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -637,7 +637,7 @@ unsigned long sctp_transport_timeout(struct sctp_transport *trans)
 	    trans->state != SCTP_PF)
 		timeout += trans->hbinterval;
 
-	return timeout;
+	return max_t(unsigned long, timeout, HZ / 5);
 }
 
 /* Reset transport variables to their initial values */

commit 6e91b578bf3f9e19c250835cba97a4be38ffcb31
Author: Marcelo Ricardo Leitner <marcelo.leitner@gmail.com>
Date:   Thu Apr 26 16:58:59 2018 -0300

    sctp: re-use sctp_transport_pmtu in sctp_transport_route
    
    sctp_transport_route currently is very similar to sctp_transport_pmtu plus
    a few other bits.
    
    This patch reuses sctp_transport_pmtu in sctp_transport_route and removes
    the duplicated code.
    
    Also, as all calls to sctp_transport_route were forcing the dst release
    before calling it, let's just include such release too.
    
    Signed-off-by: Marcelo Ricardo Leitner <marcelo.leitner@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index ed73a9d91b83..4a95e260b674 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -242,6 +242,15 @@ void sctp_transport_pmtu(struct sctp_transport *transport, struct sock *sk)
 						&transport->fl, sk);
 	}
 
+	if (transport->param_flags & SPP_PMTUD_DISABLE) {
+		struct sctp_association *asoc = transport->asoc;
+
+		if (!transport->pathmtu && asoc && asoc->pathmtu)
+			transport->pathmtu = asoc->pathmtu;
+		if (transport->pathmtu)
+			return;
+	}
+
 	if (transport->dst)
 		transport->pathmtu = sctp_dst_mtu(transport->dst);
 	else
@@ -290,6 +299,7 @@ void sctp_transport_route(struct sctp_transport *transport,
 	struct sctp_association *asoc = transport->asoc;
 	struct sctp_af *af = transport->af_specific;
 
+	sctp_transport_dst_release(transport);
 	af->get_dst(transport, saddr, &transport->fl, sctp_opt2sk(opt));
 
 	if (saddr)
@@ -297,25 +307,14 @@ void sctp_transport_route(struct sctp_transport *transport,
 	else
 		af->get_saddr(opt, transport, &transport->fl);
 
-	if ((transport->param_flags & SPP_PMTUD_DISABLE) && transport->pathmtu) {
-		return;
-	}
-	if (transport->dst) {
-		transport->pathmtu = SCTP_TRUNC4(dst_mtu(transport->dst));
+	sctp_transport_pmtu(transport, sctp_opt2sk(opt));
 
-		/* Initialize sk->sk_rcv_saddr, if the transport is the
-		 * association's active path for getsockname().
-		 */
-		if (asoc && (!asoc->peer.primary_path ||
-			     (transport == asoc->peer.active_path)))
-			opt->pf->to_sk_saddr(&transport->saddr,
-					     asoc->base.sk);
-	} else if ((transport->param_flags & SPP_PMTUD_DISABLE) &&
-		   asoc && asoc->pathmtu) {
-		transport->pathmtu = asoc->pathmtu;
-	} else {
-		transport->pathmtu = SCTP_DEFAULT_MAXSEGMENT;
-	}
+	/* Initialize sk->sk_rcv_saddr, if the transport is the
+	 * association's active path for getsockname().
+	 */
+	if (transport->dst && asoc &&
+	    (!asoc->peer.primary_path || transport == asoc->peer.active_path))
+		opt->pf->to_sk_saddr(&transport->saddr, asoc->base.sk);
 }
 
 /* Hold a reference to a transport.  */

commit 6ff0f871c20ec1769a481edca86f23c76b2b06d3
Author: Marcelo Ricardo Leitner <marcelo.leitner@gmail.com>
Date:   Thu Apr 26 16:58:57 2018 -0300

    sctp: introduce sctp_dst_mtu
    
    Which makes sure that the MTU respects the minimum value of
    SCTP_DEFAULT_MINSEGMENT and that it is correctly aligned.
    
    Signed-off-by: Marcelo Ricardo Leitner <marcelo.leitner@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index c5fc3aed08a1..ed73a9d91b83 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -242,9 +242,9 @@ void sctp_transport_pmtu(struct sctp_transport *transport, struct sock *sk)
 						&transport->fl, sk);
 	}
 
-	if (transport->dst) {
-		transport->pathmtu = SCTP_TRUNC4(dst_mtu(transport->dst));
-	} else
+	if (transport->dst)
+		transport->pathmtu = sctp_dst_mtu(transport->dst);
+	else
 		transport->pathmtu = SCTP_DEFAULT_MAXSEGMENT;
 }
 

commit 800e00c12733fe2ed565206dcdb515fa2f705b9f
Author: Marcelo Ricardo Leitner <marcelo.leitner@gmail.com>
Date:   Thu Apr 26 16:58:51 2018 -0300

    sctp: move transport pathmtu calc away of sctp_assoc_add_peer
    
    There was only one case that sctp_assoc_add_peer couldn't handle, which
    is when SPP_PMTUD_DISABLE is set and pathmtu not initialized.
    So add this situation to sctp_transport_route and reuse what was
    already in there.
    
    Signed-off-by: Marcelo Ricardo Leitner <marcelo.leitner@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index 47f82bd794d9..c5fc3aed08a1 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -307,11 +307,15 @@ void sctp_transport_route(struct sctp_transport *transport,
 		 * association's active path for getsockname().
 		 */
 		if (asoc && (!asoc->peer.primary_path ||
-				(transport == asoc->peer.active_path)))
+			     (transport == asoc->peer.active_path)))
 			opt->pf->to_sk_saddr(&transport->saddr,
 					     asoc->base.sk);
-	} else
+	} else if ((transport->param_flags & SPP_PMTUD_DISABLE) &&
+		   asoc && asoc->pathmtu) {
+		transport->pathmtu = asoc->pathmtu;
+	} else {
 		transport->pathmtu = SCTP_DEFAULT_MAXSEGMENT;
+	}
 }
 
 /* Hold a reference to a transport.  */

commit b6c5734db07079c9410147b32407f2366d584e6c
Author: Marcelo Ricardo Leitner <marcelo.leitner@gmail.com>
Date:   Fri Jan 5 11:17:18 2018 -0200

    sctp: fix the handling of ICMP Frag Needed for too small MTUs
    
    syzbot reported a hang involving SCTP, on which it kept flooding dmesg
    with the message:
    [  246.742374] sctp: sctp_transport_update_pmtu: Reported pmtu 508 too
    low, using default minimum of 512
    
    That happened because whenever SCTP hits an ICMP Frag Needed, it tries
    to adjust to the new MTU and triggers an immediate retransmission. But
    it didn't consider the fact that MTUs smaller than the SCTP minimum MTU
    allowed (512) would not cause the PMTU to change, and issued the
    retransmission anyway (thus leading to another ICMP Frag Needed, and so
    on).
    
    As IPv4 (ip_rt_min_pmtu=556) and IPv6 (IPV6_MIN_MTU=1280) minimum MTU
    are higher than that, sctp_transport_update_pmtu() is changed to
    re-fetch the PMTU that got set after our request, and with that, detect
    if there was an actual change or not.
    
    The fix, thus, skips the immediate retransmission if the received ICMP
    resulted in no change, in the hope that SCTP will select another path.
    
    Note: The value being used for the minimum MTU (512,
    SCTP_DEFAULT_MINSEGMENT) is not right and instead it should be (576,
    SCTP_MIN_PMTU), but such change belongs to another patch.
    
    Changes from v1:
    - do not disable PMTU discovery, in the light of commit
    06ad391919b2 ("[SCTP] Don't disable PMTU discovery when mtu is small")
    and as suggested by Xin Long.
    - changed the way to break the rtx loop by detecting if the icmp
      resulted in a change or not
    Changes from v2:
    none
    
    See-also: https://lkml.org/lkml/2017/12/22/811
    Reported-by: syzbot <syzkaller@googlegroups.com>
    Signed-off-by: Marcelo Ricardo Leitner <marcelo.leitner@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index 1e5a22430cf5..47f82bd794d9 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -248,28 +248,37 @@ void sctp_transport_pmtu(struct sctp_transport *transport, struct sock *sk)
 		transport->pathmtu = SCTP_DEFAULT_MAXSEGMENT;
 }
 
-void sctp_transport_update_pmtu(struct sctp_transport *t, u32 pmtu)
+bool sctp_transport_update_pmtu(struct sctp_transport *t, u32 pmtu)
 {
 	struct dst_entry *dst = sctp_transport_dst_check(t);
+	bool change = true;
 
 	if (unlikely(pmtu < SCTP_DEFAULT_MINSEGMENT)) {
-		pr_warn("%s: Reported pmtu %d too low, using default minimum of %d\n",
-			__func__, pmtu, SCTP_DEFAULT_MINSEGMENT);
-		/* Use default minimum segment size and disable
-		 * pmtu discovery on this transport.
-		 */
-		t->pathmtu = SCTP_DEFAULT_MINSEGMENT;
-	} else {
-		t->pathmtu = pmtu;
+		pr_warn_ratelimited("%s: Reported pmtu %d too low, using default minimum of %d\n",
+				    __func__, pmtu, SCTP_DEFAULT_MINSEGMENT);
+		/* Use default minimum segment instead */
+		pmtu = SCTP_DEFAULT_MINSEGMENT;
 	}
+	pmtu = SCTP_TRUNC4(pmtu);
 
 	if (dst) {
 		dst->ops->update_pmtu(dst, t->asoc->base.sk, NULL, pmtu);
 		dst = sctp_transport_dst_check(t);
 	}
 
-	if (!dst)
+	if (!dst) {
 		t->af_specific->get_dst(t, &t->saddr, &t->fl, t->asoc->base.sk);
+		dst = t->dst;
+	}
+
+	if (dst) {
+		/* Re-fetch, as under layers may have a higher minimum size */
+		pmtu = SCTP_TRUNC4(dst_mtu(dst));
+		change = t->pathmtu != pmtu;
+	}
+	t->pathmtu = pmtu;
+
+	return change;
 }
 
 /* Caches the dst entry and source address for a transport's destination

commit 9c3b57518363577d4e2ea1964ef4fa03e100beaa
Author: Kees Cook <keescook@chromium.org>
Date:   Tue Oct 24 01:45:31 2017 -0700

    net: sctp: Convert timers to use timer_setup()
    
    In preparation for unconditionally passing the struct timer_list pointer to
    all timer callbacks, switch to using the new timer_setup() and from_timer()
    to pass the timer pointer explicitly.
    
    Cc: Vlad Yasevich <vyasevich@gmail.com>
    Cc: Neil Horman <nhorman@tuxdriver.com>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: linux-sctp@vger.kernel.org
    Cc: netdev@vger.kernel.org
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index 2d9bd3776bc8..1e5a22430cf5 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -87,14 +87,11 @@ static struct sctp_transport *sctp_transport_init(struct net *net,
 	INIT_LIST_HEAD(&peer->send_ready);
 	INIT_LIST_HEAD(&peer->transports);
 
-	setup_timer(&peer->T3_rtx_timer, sctp_generate_t3_rtx_event,
-		    (unsigned long)peer);
-	setup_timer(&peer->hb_timer, sctp_generate_heartbeat_event,
-		    (unsigned long)peer);
-	setup_timer(&peer->reconf_timer, sctp_generate_reconf_event,
-		    (unsigned long)peer);
-	setup_timer(&peer->proto_unreach_timer,
-		    sctp_generate_proto_unreach_event, (unsigned long)peer);
+	timer_setup(&peer->T3_rtx_timer, sctp_generate_t3_rtx_event, 0);
+	timer_setup(&peer->hb_timer, sctp_generate_heartbeat_event, 0);
+	timer_setup(&peer->reconf_timer, sctp_generate_reconf_event, 0);
+	timer_setup(&peer->proto_unreach_timer,
+		    sctp_generate_proto_unreach_event, 0);
 
 	/* Initialize the 64-bit random nonce sent with heartbeat. */
 	get_random_bytes(&peer->hb_nonce, sizeof(peer->hb_nonce));

commit 233e7936c84b7d7dd90c10e2ba27abb5ab42956f
Author: Xin Long <lucien.xin@gmail.com>
Date:   Sat Aug 5 19:59:51 2017 +0800

    sctp: remove the typedef sctp_lower_cwnd_t
    
    This patch is to remove the typedef sctp_lower_cwnd_t, and
    replace with enum sctp_lower_cwnd in the places where it's
    using this typedef.
    
    Signed-off-by: Xin Long <lucien.xin@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index 80a97c8501a7..2d9bd3776bc8 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -490,7 +490,7 @@ void sctp_transport_raise_cwnd(struct sctp_transport *transport,
  * detected.
  */
 void sctp_transport_lower_cwnd(struct sctp_transport *transport,
-			       sctp_lower_cwnd_t reason)
+			       enum sctp_lower_cwnd reason)
 {
 	struct sctp_association *asoc = transport->asoc;
 

commit a4b2b58efd44db68358e1a6b71cf205c795d7ada
Author: Reshetova, Elena <elena.reshetova@intel.com>
Date:   Tue Jul 4 15:53:27 2017 +0300

    net, sctp: convert sctp_transport.refcnt from atomic_t to refcount_t
    
    refcount_t type and corresponding API should be
    used instead of atomic_t when the variable is used as
    a reference counter. This allows to avoid accidental
    refcounter overflows that might lead to use-after-free
    situations.
    
    Signed-off-by: Elena Reshetova <elena.reshetova@intel.com>
    Signed-off-by: Hans Liljestrand <ishkamiel@gmail.com>
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: David Windsor <dwindsor@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index 7cdd6bcddbc5..80a97c8501a7 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -99,7 +99,7 @@ static struct sctp_transport *sctp_transport_init(struct net *net,
 	/* Initialize the 64-bit random nonce sent with heartbeat. */
 	get_random_bytes(&peer->hb_nonce, sizeof(peer->hb_nonce));
 
-	atomic_set(&peer->refcnt, 1);
+	refcount_set(&peer->refcnt, 1);
 
 	return peer;
 }
@@ -172,7 +172,7 @@ static void sctp_transport_destroy_rcu(struct rcu_head *head)
  */
 static void sctp_transport_destroy(struct sctp_transport *transport)
 {
-	if (unlikely(atomic_read(&transport->refcnt))) {
+	if (unlikely(refcount_read(&transport->refcnt))) {
 		WARN(1, "Attempt to destroy undead transport %p!\n", transport);
 		return;
 	}
@@ -311,7 +311,7 @@ void sctp_transport_route(struct sctp_transport *transport,
 /* Hold a reference to a transport.  */
 int sctp_transport_hold(struct sctp_transport *transport)
 {
-	return atomic_add_unless(&transport->refcnt, 1, 0);
+	return refcount_inc_not_zero(&transport->refcnt);
 }
 
 /* Release a reference to a transport and clean up
@@ -319,7 +319,7 @@ int sctp_transport_hold(struct sctp_transport *transport)
  */
 void sctp_transport_put(struct sctp_transport *transport)
 {
-	if (atomic_dec_and_test(&transport->refcnt))
+	if (refcount_dec_and_test(&transport->refcnt))
 		sctp_transport_destroy(transport);
 }
 

commit a02d036c027e9070ca27c156f59eb445d5405480
Author: Marcelo Ricardo Leitner <marcelo.leitner@gmail.com>
Date:   Fri Jun 23 19:59:36 2017 -0300

    sctp: adjust ssthresh when transport is idle
    
    RFC 4960 Errata 3.27 identifies that ssthresh should be adjusted to cwnd
    because otherwise it could cause the transport to lock into congestion
    avoidance phase specially if ssthresh was previously reduced by some
    packet drop, leading to poor performance.
    
    The Errata says to adjust ssthresh to cwnd only once, though the same
    goal is achieved by updating it every time we update cwnd too. The
    caveat is that we could take longer to get back up to speed but that
    should be compensated by the fact that we don't adjust on RTO basis (as
    RFC says) but based on Heartbeats, which are usually way longer.
    
    See-also: https://tools.ietf.org/html/draft-ietf-tsvwg-rfc4960-errata-01#section-3.27
    Signed-off-by: Marcelo Ricardo Leitner <marcelo.leitner@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index e3ebf04ddbd0..7cdd6bcddbc5 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -569,6 +569,8 @@ void sctp_transport_lower_cwnd(struct sctp_transport *transport,
 		 */
 		transport->cwnd = max(transport->cwnd/2,
 					 4*asoc->pathmtu);
+		/* RFC 4960 Errata 3.27.2: also adjust sshthresh */
+		transport->ssthresh = transport->cwnd;
 		break;
 	}
 

commit 4ccbd0b0b9b8b09d87c7e7b0f868eda2bed03189
Author: Marcelo Ricardo Leitner <marcelo.leitner@gmail.com>
Date:   Fri Jun 23 19:59:35 2017 -0300

    sctp: adjust cwnd increase in Congestion Avoidance phase
    
    RFC4960 Errata 3.26 identified that at the same time RFC4960 states that
    cwnd should never grow more than 1*MTU per RTT, Section 7.2.2 was
    underspecified and as described could allow increasing cwnd more than
    that.
    
    This patch updates it so partial_bytes_acked is maxed to cwnd if
    flight_size doesn't reach cwnd, protecting it from such case.
    
    See-also: https://tools.ietf.org/html/draft-ietf-tsvwg-rfc4960-errata-01#section-3.26
    Signed-off-by: Marcelo Ricardo Leitner <marcelo.leitner@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index 9d3589451a96..e3ebf04ddbd0 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -405,13 +405,6 @@ void sctp_transport_raise_cwnd(struct sctp_transport *transport,
 	    TSN_lte(asoc->fast_recovery_exit, sack_ctsn))
 		asoc->fast_recovery = 0;
 
-	/* The appropriate cwnd increase algorithm is performed if, and only
-	 * if the congestion window is being fully utilized.
-	 * Note that RFC4960 Errata 3.22 removed the other condition.
-	 */
-	if (flight_size < cwnd)
-		return;
-
 	ssthresh = transport->ssthresh;
 	pba = transport->partial_bytes_acked;
 	pmtu = transport->asoc->pathmtu;
@@ -434,6 +427,14 @@ void sctp_transport_raise_cwnd(struct sctp_transport *transport,
 		if (asoc->fast_recovery)
 			return;
 
+		/* The appropriate cwnd increase algorithm is performed
+		 * if, and only if the congestion window is being fully
+		 * utilized.  Note that RFC4960 Errata 3.22 removed the
+		 * other condition on ctsn moving.
+		 */
+		if (flight_size < cwnd)
+			return;
+
 		if (bytes_acked > pmtu)
 			cwnd += pmtu;
 		else
@@ -451,6 +452,13 @@ void sctp_transport_raise_cwnd(struct sctp_transport *transport,
 		 * acknowledged by the new Cumulative TSN Ack and by Gap
 		 * Ack Blocks. (updated by RFC4960 Errata 3.22)
 		 *
+		 * When partial_bytes_acked is greater than cwnd and
+		 * before the arrival of the SACK the sender had less
+		 * bytes of data outstanding than cwnd (i.e., before
+		 * arrival of the SACK, flightsize was less than cwnd),
+		 * reset partial_bytes_acked to cwnd. (RFC 4960 Errata
+		 * 3.26)
+		 *
 		 * When partial_bytes_acked is equal to or greater than
 		 * cwnd and before the arrival of the SACK the sender
 		 * had cwnd or more bytes of data outstanding (i.e.,
@@ -460,7 +468,9 @@ void sctp_transport_raise_cwnd(struct sctp_transport *transport,
 		 * increased by MTU. (RFC 4960 Errata 3.12)
 		 */
 		pba += bytes_acked;
-		if (pba >= cwnd) {
+		if (pba > cwnd && flight_size < cwnd)
+			pba = cwnd;
+		if (pba >= cwnd && flight_size >= cwnd) {
 			pba = pba - cwnd;
 			cwnd += pmtu;
 		}

commit e56f777af82ebbdf8302164b040128d890f100d8
Author: Marcelo Ricardo Leitner <marcelo.leitner@gmail.com>
Date:   Fri Jun 23 19:59:34 2017 -0300

    sctp: allow increasing cwnd regardless of ctsn moving or not
    
    As per RFC4960 Errata 3.22, this condition is not needed anymore as it
    could cause the partial_bytes_acked to not consider the TSNs acked in
    the Gap Ack Blocks although they were received by the peer successfully.
    
    This patch thus drops the check for new Cumulative TSN Ack Point,
    leaving just the flight_size < cwnd one.
    
    See-also: https://tools.ietf.org/html/draft-ietf-tsvwg-rfc4960-errata-01#section-3.22
    Signed-off-by: Marcelo Ricardo Leitner <marcelo.leitner@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index 04b6dd1a07de..9d3589451a96 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -406,11 +406,10 @@ void sctp_transport_raise_cwnd(struct sctp_transport *transport,
 		asoc->fast_recovery = 0;
 
 	/* The appropriate cwnd increase algorithm is performed if, and only
-	 * if the cumulative TSN whould advanced and the congestion window is
-	 * being fully utilized.
+	 * if the congestion window is being fully utilized.
+	 * Note that RFC4960 Errata 3.22 removed the other condition.
 	 */
-	if (TSN_lte(sack_ctsn, transport->asoc->ctsn_ack_point) ||
-	    (flight_size < cwnd))
+	if (flight_size < cwnd)
 		return;
 
 	ssthresh = transport->ssthresh;
@@ -446,11 +445,11 @@ void sctp_transport_raise_cwnd(struct sctp_transport *transport,
 			 flight_size, pba);
 	} else {
 		/* RFC 2960 7.2.2 Whenever cwnd is greater than ssthresh,
-		 * upon each SACK arrival that advances the Cumulative TSN Ack
-		 * Point, increase partial_bytes_acked by the total number of
-		 * bytes of all new chunks acknowledged in that SACK including
-		 * chunks acknowledged by the new Cumulative TSN Ack and by
-		 * Gap Ack Blocks.
+		 * upon each SACK arrival, increase partial_bytes_acked
+		 * by the total number of bytes of all new chunks
+		 * acknowledged in that SACK including chunks
+		 * acknowledged by the new Cumulative TSN Ack and by Gap
+		 * Ack Blocks. (updated by RFC4960 Errata 3.22)
 		 *
 		 * When partial_bytes_acked is equal to or greater than
 		 * cwnd and before the arrival of the SACK the sender

commit d0b53f40977446fdf2460b14d4544d1375a3138d
Author: Marcelo Ricardo Leitner <marcelo.leitner@gmail.com>
Date:   Fri Jun 23 19:59:33 2017 -0300

    sctp: update order of adjustments of partial_bytes_acked and cwnd
    
    RFC4960 Errata 3.12 says RFC4960 is unclear about the order of
    adjustments applied to partial_bytes_acked and cwnd in the congestion
    avoidance phase, and that the actual order should be:
    partial_bytes_acked is reset to (partial_bytes_acked - cwnd). Next, cwnd
    is increased by MTU.
    
    We were first increasing cwnd, and then subtracting the new value pba,
    which leads to a different result as pba is smaller than what it should
    and could cause cwnd to not grow as much.
    
    See-also: https://tools.ietf.org/html/draft-ietf-tsvwg-rfc4960-errata-01#section-3.12
    Signed-off-by: Marcelo Ricardo Leitner <marcelo.leitner@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index 721eeebfcd8a..04b6dd1a07de 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -452,17 +452,18 @@ void sctp_transport_raise_cwnd(struct sctp_transport *transport,
 		 * chunks acknowledged by the new Cumulative TSN Ack and by
 		 * Gap Ack Blocks.
 		 *
-		 * When partial_bytes_acked is equal to or greater than cwnd
-		 * and before the arrival of the SACK the sender had cwnd or
-		 * more bytes of data outstanding (i.e., before arrival of the
-		 * SACK, flightsize was greater than or equal to cwnd),
-		 * increase cwnd by MTU, and reset partial_bytes_acked to
-		 * (partial_bytes_acked - cwnd).
+		 * When partial_bytes_acked is equal to or greater than
+		 * cwnd and before the arrival of the SACK the sender
+		 * had cwnd or more bytes of data outstanding (i.e.,
+		 * before arrival of the SACK, flightsize was greater
+		 * than or equal to cwnd), partial_bytes_acked is reset
+		 * to (partial_bytes_acked - cwnd). Next, cwnd is
+		 * increased by MTU. (RFC 4960 Errata 3.12)
 		 */
 		pba += bytes_acked;
 		if (pba >= cwnd) {
+			pba = pba - cwnd;
 			cwnd += pmtu;
-			pba = ((cwnd < pba) ? (pba - cwnd) : 0);
 		}
 
 		pr_debug("%s: congestion avoidance: transport:%p, "

commit 3ebfdf082184d04f6e73b30cd9446613dc7f8c02
Author: Xin Long <lucien.xin@gmail.com>
Date:   Tue Apr 4 13:39:55 2017 +0800

    sctp: get sock from transport in sctp_transport_update_pmtu
    
    This patch is almost to revert commit 02f3d4ce9e81 ("sctp: Adjust PMTU
    updates to accomodate route invalidation."). As t->asoc can't be NULL
    in sctp_transport_update_pmtu, it could get sk from asoc, and no need
    to pass sk into that function.
    
    It is also to remove some duplicated codes from that function.
    
    Signed-off-by: Xin Long <lucien.xin@gmail.com>
    Acked-by: Marcelo Ricardo Leitner <marcelo.leitner@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index 3379668af368..721eeebfcd8a 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -251,14 +251,13 @@ void sctp_transport_pmtu(struct sctp_transport *transport, struct sock *sk)
 		transport->pathmtu = SCTP_DEFAULT_MAXSEGMENT;
 }
 
-void sctp_transport_update_pmtu(struct sock *sk, struct sctp_transport *t, u32 pmtu)
+void sctp_transport_update_pmtu(struct sctp_transport *t, u32 pmtu)
 {
-	struct dst_entry *dst;
+	struct dst_entry *dst = sctp_transport_dst_check(t);
 
 	if (unlikely(pmtu < SCTP_DEFAULT_MINSEGMENT)) {
 		pr_warn("%s: Reported pmtu %d too low, using default minimum of %d\n",
-			__func__, pmtu,
-			SCTP_DEFAULT_MINSEGMENT);
+			__func__, pmtu, SCTP_DEFAULT_MINSEGMENT);
 		/* Use default minimum segment size and disable
 		 * pmtu discovery on this transport.
 		 */
@@ -267,17 +266,13 @@ void sctp_transport_update_pmtu(struct sock *sk, struct sctp_transport *t, u32 p
 		t->pathmtu = pmtu;
 	}
 
-	dst = sctp_transport_dst_check(t);
-	if (!dst)
-		t->af_specific->get_dst(t, &t->saddr, &t->fl, sk);
-
 	if (dst) {
-		dst->ops->update_pmtu(dst, sk, NULL, pmtu);
-
+		dst->ops->update_pmtu(dst, t->asoc->base.sk, NULL, pmtu);
 		dst = sctp_transport_dst_check(t);
-		if (!dst)
-			t->af_specific->get_dst(t, &t->saddr, &t->fl, sk);
 	}
+
+	if (!dst)
+		t->af_specific->get_dst(t, &t->saddr, &t->fl, t->asoc->base.sk);
 }
 
 /* Caches the dst entry and source address for a transport's destination

commit b564d62e67560423965c43d60249a09d8e70a27a
Author: Masahiro Yamada <yamada.masahiro@socionext.com>
Date:   Mon Feb 27 14:29:06 2017 -0800

    scripts/spelling.txt: add "varible" pattern and fix typo instances
    
    Fix typos and add the following to the scripts/spelling.txt:
    
      varible||variable
    
    While we are here, tidy up the comment blocks that fit in a single line
    for drivers/net/ethernet/intel/i40e/i40e_virtchnl_pf.c and
    net/sctp/transport.c.
    
    Link: http://lkml.kernel.org/r/1481573103-11329-11-git-send-email-yamada.masahiro@socionext.com
    Signed-off-by: Masahiro Yamada <yamada.masahiro@socionext.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index 5b63ceb3bf37..3379668af368 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -643,9 +643,7 @@ void sctp_transport_reset(struct sctp_transport *t)
 	t->srtt = 0;
 	t->rttvar = 0;
 
-	/* Reset these additional varibles so that we have a clean
-	 * slate.
-	 */
+	/* Reset these additional variables so that we have a clean slate. */
 	t->partial_bytes_acked = 0;
 	t->flight_size = 0;
 	t->error_count = 0;

commit c86a773c78025f5b825bacd7b846f4fa60dc0317
Author: Julian Anastasov <ja@ssi.bg>
Date:   Mon Feb 6 23:14:13 2017 +0200

    sctp: add dst_pending_confirm flag
    
    Add new transport flag to allow sockets to confirm neighbour.
    When same struct dst_entry can be used for many different
    neighbours we can not use it for pending confirmations.
    The flag is propagated from transport to every packet.
    It is reset when cached dst is reset.
    
    Reported-by: YueHaibing <yuehaibing@huawei.com>
    Fixes: 5110effee8fd ("net: Do delayed neigh confirmation.")
    Fixes: f2bb4bedf35d ("ipv4: Cache output routes in fib_info nexthops.")
    Signed-off-by: Julian Anastasov <ja@ssi.bg>
    Acked-by: Eric Dumazet <edumazet@google.com>
    Acked-by: Neil Horman <nhorman@tuxdriver.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index baa1ac00d7b5..5b63ceb3bf37 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -240,7 +240,7 @@ void sctp_transport_pmtu(struct sctp_transport *transport, struct sock *sk)
 {
 	/* If we don't have a fresh route, look one up */
 	if (!transport->dst || transport->dst->obsolete) {
-		dst_release(transport->dst);
+		sctp_transport_dst_release(transport);
 		transport->af_specific->get_dst(transport, &transport->saddr,
 						&transport->fl, sk);
 	}
@@ -672,3 +672,17 @@ void sctp_transport_immediate_rtx(struct sctp_transport *t)
 			sctp_transport_hold(t);
 	}
 }
+
+/* Drop dst */
+void sctp_transport_dst_release(struct sctp_transport *t)
+{
+	dst_release(t->dst);
+	t->dst = NULL;
+	t->dst_pending_confirm = 0;
+}
+
+/* Schedule neighbour confirm */
+void sctp_transport_dst_confirm(struct sctp_transport *t)
+{
+	t->dst_pending_confirm = 1;
+}

commit 7b9438de0cd4b46a6914416bfede6cf839cd9e68
Author: Xin Long <lucien.xin@gmail.com>
Date:   Wed Jan 18 00:44:43 2017 +0800

    sctp: add stream reconf timer
    
    This patch is to add a per transport timer based on sctp timer frame
    for stream reconf chunk retransmission. It would start after sending
    a reconf request chunk, and stop after receiving the response chunk.
    
    If the timer expires, besides retransmitting the reconf request chunk,
    it would also do the same thing with data RTO timer. like to increase
    the appropriate error counts, and perform threshold management, possibly
    destroying the asoc if sctp retransmission thresholds are exceeded, just
    as section 5.1.1 describes.
    
    This patch is also to add asoc strreset_chunk, it is used to save the
    reconf request chunk, so that it can be retransmitted, and to check if
    the response is really for this request by comparing the information
    inside with the response chunk as well.
    
    Signed-off-by: Xin Long <lucien.xin@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index a1652ab63918..baa1ac00d7b5 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -88,9 +88,11 @@ static struct sctp_transport *sctp_transport_init(struct net *net,
 	INIT_LIST_HEAD(&peer->transports);
 
 	setup_timer(&peer->T3_rtx_timer, sctp_generate_t3_rtx_event,
-			(unsigned long)peer);
+		    (unsigned long)peer);
 	setup_timer(&peer->hb_timer, sctp_generate_heartbeat_event,
-			(unsigned long)peer);
+		    (unsigned long)peer);
+	setup_timer(&peer->reconf_timer, sctp_generate_reconf_event,
+		    (unsigned long)peer);
 	setup_timer(&peer->proto_unreach_timer,
 		    sctp_generate_proto_unreach_event, (unsigned long)peer);
 
@@ -144,6 +146,9 @@ void sctp_transport_free(struct sctp_transport *transport)
 	if (del_timer(&transport->T3_rtx_timer))
 		sctp_transport_put(transport);
 
+	if (del_timer(&transport->reconf_timer))
+		sctp_transport_put(transport);
+
 	/* Delete the ICMP proto unreachable timer if it's active. */
 	if (del_timer(&transport->proto_unreach_timer))
 		sctp_association_put(transport->asoc);
@@ -211,6 +216,14 @@ void sctp_transport_reset_hb_timer(struct sctp_transport *transport)
 		sctp_transport_hold(transport);
 }
 
+void sctp_transport_reset_reconf_timer(struct sctp_transport *transport)
+{
+	if (!timer_pending(&transport->reconf_timer))
+		if (!mod_timer(&transport->reconf_timer,
+			       jiffies + transport->rto))
+			sctp_transport_hold(transport);
+}
+
 /* This transport has been assigned to an association.
  * Initialize fields from the association or from the sock itself.
  * Register the reference count in the association.

commit 8b0e195314fabd58a331c4f7b6db75a1565535d7
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sun Dec 25 12:30:41 2016 +0100

    ktime: Cleanup ktime_set() usage
    
    ktime_set(S,N) was required for the timespec storage type and is still
    useful for situations where a Seconds and Nanoseconds part of a time value
    needs to be converted. For anything where the Seconds argument is 0, this
    is pointless and can be replaced with a simple assignment.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index ce54dce13ddb..a1652ab63918 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -72,7 +72,7 @@ static struct sctp_transport *sctp_transport_init(struct net *net,
 	 */
 	peer->rto = msecs_to_jiffies(net->sctp.rto_initial);
 
-	peer->last_time_heard = ktime_set(0, 0);
+	peer->last_time_heard = 0;
 	peer->last_time_ecne_reduced = jiffies;
 
 	peer->param_flags = SPP_HB_DISABLE |

commit e2f036a97271cf5811ee754bf321a29a814577f9
Author: Marcelo Ricardo Leitner <marcelo.leitner@gmail.com>
Date:   Wed Sep 21 08:45:55 2016 -0300

    sctp: rename WORD_TRUNC/ROUND macros
    
    To something more meaningful these days, specially because this is
    working on packet headers or lengths and which are not tied to any CPU
    arch but to the protocol itself.
    
    So, WORD_TRUNC becomes SCTP_TRUNC4 and WORD_ROUND becomes SCTP_PAD4.
    
    Reported-by: David Laight <David.Laight@ACULAB.COM>
    Reported-by: David Miller <davem@davemloft.net>
    Signed-off-by: Marcelo Ricardo Leitner <marcelo.leitner@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index 81b86678be4d..ce54dce13ddb 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -233,7 +233,7 @@ void sctp_transport_pmtu(struct sctp_transport *transport, struct sock *sk)
 	}
 
 	if (transport->dst) {
-		transport->pathmtu = WORD_TRUNC(dst_mtu(transport->dst));
+		transport->pathmtu = SCTP_TRUNC4(dst_mtu(transport->dst));
 	} else
 		transport->pathmtu = SCTP_DEFAULT_MAXSEGMENT;
 }
@@ -287,7 +287,7 @@ void sctp_transport_route(struct sctp_transport *transport,
 		return;
 	}
 	if (transport->dst) {
-		transport->pathmtu = WORD_TRUNC(dst_mtu(transport->dst));
+		transport->pathmtu = SCTP_TRUNC4(dst_mtu(transport->dst));
 
 		/* Initialize sk->sk_rcv_saddr, if the transport is the
 		 * association's active path for getsockname().

commit ba6f5e33bdbb9ed2014b778fbbaecf20060ca989
Author: Marcelo Ricardo Leitner <marcelo.leitner@gmail.com>
Date:   Wed Apr 6 15:15:19 2016 -0300

    sctp: avoid refreshing heartbeat timer too often
    
    Currently on high rate SCTP streams the heartbeat timer refresh can
    consume quite a lot of resources as timer updates are costly and it
    contains a random factor, which a) is also costly and b) invalidates
    mod_timer() optimization for not editing a timer to the same value.
    It may even cause the timer to be slightly advanced, for no good reason.
    
    As suggested by David Laight this patch now removes this timer update
    from hot path by leaving the timer on and re-evaluating upon its
    expiration if the heartbeat is still needed or not, similarly to what is
    done for TCP. If it's not needed anymore the timer is re-scheduled to
    the new timeout, considering the time already elapsed.
    
    For this, we now record the last tx timestamp per transport, updated in
    the same spots as hb timer was restarted on tx. Also split up
    sctp_transport_reset_timers into sctp_transport_reset_t3_rtx and
    sctp_transport_reset_hb_timer, so we can re-arm T3 without re-arming the
    heartbeat one.
    
    On loopback with MTU of 65535 and data chunks with 1636, so that we
    have a considerable amount of chunks without stressing system calls,
    netperf -t SCTP_STREAM -l 30, perf looked like this before:
    
    Samples: 103K of event 'cpu-clock', Event count (approx.): 25833000000
      Overhead  Command  Shared Object      Symbol
    +    6,15%  netperf  [kernel.vmlinux]   [k] copy_user_enhanced_fast_string
    -    5,43%  netperf  [kernel.vmlinux]   [k] _raw_write_unlock_irqrestore
       - _raw_write_unlock_irqrestore
          - 96,54% _raw_spin_unlock_irqrestore
             - 36,14% mod_timer
                + 97,24% sctp_transport_reset_timers
                + 2,76% sctp_do_sm
             + 33,65% __wake_up_sync_key
             + 28,77% sctp_ulpq_tail_event
             + 1,40% del_timer
          - 1,84% mod_timer
             + 99,03% sctp_transport_reset_timers
             + 0,97% sctp_do_sm
          + 1,50% sctp_ulpq_tail_event
    
    And after this patch, now with netperf -l 60:
    
    Samples: 230K of event 'cpu-clock', Event count (approx.): 57707250000
      Overhead  Command  Shared Object      Symbol
    +    5,65%  netperf  [kernel.vmlinux]   [k] memcpy_erms
    +    5,59%  netperf  [kernel.vmlinux]   [k] copy_user_enhanced_fast_string
    -    5,05%  netperf  [kernel.vmlinux]   [k] _raw_spin_unlock_irqrestore
       - _raw_spin_unlock_irqrestore
          + 49,89% __wake_up_sync_key
          + 45,68% sctp_ulpq_tail_event
          - 2,85% mod_timer
             + 76,51% sctp_transport_reset_t3_rtx
             + 23,49% sctp_do_sm
          + 1,55% del_timer
    +    2,50%  netperf  [sctp]             [k] sctp_datamsg_from_user
    +    2,26%  netperf  [sctp]             [k] sctp_sendmsg
    
    Throughput-wise, from 6800mbps without the patch to 7050mbps with it,
    ~3.7%.
    
    Signed-off-by: Marcelo Ricardo Leitner <marcelo.leitner@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index 9b6b48c7524e..81b86678be4d 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -183,7 +183,7 @@ static void sctp_transport_destroy(struct sctp_transport *transport)
 /* Start T3_rtx timer if it is not already running and update the heartbeat
  * timer.  This routine is called every time a DATA chunk is sent.
  */
-void sctp_transport_reset_timers(struct sctp_transport *transport)
+void sctp_transport_reset_t3_rtx(struct sctp_transport *transport)
 {
 	/* RFC 2960 6.3.2 Retransmission Timer Rules
 	 *
@@ -197,11 +197,18 @@ void sctp_transport_reset_timers(struct sctp_transport *transport)
 		if (!mod_timer(&transport->T3_rtx_timer,
 			       jiffies + transport->rto))
 			sctp_transport_hold(transport);
+}
+
+void sctp_transport_reset_hb_timer(struct sctp_transport *transport)
+{
+	unsigned long expires;
 
 	/* When a data chunk is sent, reset the heartbeat interval.  */
-	if (!mod_timer(&transport->hb_timer,
-		       sctp_transport_timeout(transport)))
-	    sctp_transport_hold(transport);
+	expires = jiffies + sctp_transport_timeout(transport);
+	if (time_before(transport->hb_timer.expires, expires) &&
+	    !mod_timer(&transport->hb_timer,
+		       expires + prandom_u32_max(transport->rto)))
+		sctp_transport_hold(transport);
 }
 
 /* This transport has been assigned to an association.
@@ -595,13 +602,13 @@ void sctp_transport_burst_reset(struct sctp_transport *t)
 unsigned long sctp_transport_timeout(struct sctp_transport *trans)
 {
 	/* RTO + timer slack +/- 50% of RTO */
-	unsigned long timeout = (trans->rto >> 1) + prandom_u32_max(trans->rto);
+	unsigned long timeout = trans->rto >> 1;
 
 	if (trans->state != SCTP_UNCONFIRMED &&
 	    trans->state != SCTP_PF)
 		timeout += trans->hbinterval;
 
-	return timeout + jiffies;
+	return timeout;
 }
 
 /* Reset transport variables to their initial values */

commit 3822a5ff4bc32043fa9c7b6d6f125bcdca6da39c
Author: Marcelo Ricardo Leitner <marcelo.leitner@gmail.com>
Date:   Sat Mar 19 12:17:20 2016 -0300

    sctp: align MTU to a word
    
    SCTP is a protocol that is aligned to a word (4 bytes). Thus using bare
    MTU can sometimes return values that are not aligned, like for loopback,
    which is 65536 but ipv4_mtu() limits that to 65535. This mis-alignment
    will cause the last non-aligned bytes to never be used and can cause
    issues with congestion control.
    
    So it's better to just consider a lower MTU and keep congestion control
    calcs saner as they are based on PMTU.
    
    Same applies to icmp frag needed messages, which is also fixed by this
    patch.
    
    One other effect of this is the inability to send MTU-sized packet
    without queueing or fragmentation and without hitting Nagle. As the
    check performed at sctp_packet_can_append_data():
    
    if (chunk->skb->len + q->out_qlen >= transport->pathmtu - packet->overhead)
            /* Enough data queued to fill a packet */
            return SCTP_XMIT_OK;
    
    with the above example of MTU, if there are no other messages queued,
    one cannot send a packet that just fits one packet (65532 bytes) and
    without causing DATA chunk fragmentation or a delay.
    
    v2:
     - Added WORD_TRUNC macro
    
    Signed-off-by: Marcelo Ricardo Leitner <marcelo.leitner@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index d517153891a6..9b6b48c7524e 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -226,7 +226,7 @@ void sctp_transport_pmtu(struct sctp_transport *transport, struct sock *sk)
 	}
 
 	if (transport->dst) {
-		transport->pathmtu = dst_mtu(transport->dst);
+		transport->pathmtu = WORD_TRUNC(dst_mtu(transport->dst));
 	} else
 		transport->pathmtu = SCTP_DEFAULT_MAXSEGMENT;
 }
@@ -280,7 +280,7 @@ void sctp_transport_route(struct sctp_transport *transport,
 		return;
 	}
 	if (transport->dst) {
-		transport->pathmtu = dst_mtu(transport->dst);
+		transport->pathmtu = WORD_TRUNC(dst_mtu(transport->dst));
 
 		/* Initialize sk->sk_rcv_saddr, if the transport is the
 		 * association's active path for getsockname().

commit 39d2adebf137de5f900843f69f5e500932e31047
Author: Xin Long <lucien.xin@gmail.com>
Date:   Thu Mar 10 15:31:57 2016 +0800

    sctp: fix the transports round robin issue when init is retransmitted
    
    prior to this patch, at the beginning if we have two paths in one assoc,
    they may have the same params other than the last_time_heard, it will try
    the paths like this:
    
    1st cycle
      try trans1 fail.
      then trans2 is selected.(cause it's last_time_heard is after trans1).
    
    2nd cycle:
      try  trans2 fail
      then trans2 is selected.(cause it's last_time_heard is after trans1).
    
    3rd cycle:
      try  trans2 fail
      then trans2 is selected.(cause it's last_time_heard is after trans1).
    
    ....
    
    trans1 will never have change to be selected, which is not what we expect.
    we should keeping round robin all the paths if they are just added at the
    beginning.
    
    So at first every tranport's last_time_heard should be initialized 0, so
    that we ensure they have the same value at the beginning, only by this,
    all the transports could get equal chance to be selected.
    
    Then for sctp_trans_elect_best, it should return the trans_next one when
    *trans == *trans_next, so that we can try next if it fails,  but now it
    always return trans. so we can fix it by exchanging these two params when
    we calls sctp_trans_elect_tie().
    
    Fixes: 4c47af4d5eb2 ('net: sctp: rework multihoming retransmission path selection to rfc4960')
    Signed-off-by: Xin Long <lucien.xin@gmail.com>
    Acked-by: Daniel Borkmann <daniel@iogearbox.net>
    Acked-by: Marcelo Ricardo Leitner <marcelo.leitner@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index a431c14044a4..d517153891a6 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -72,7 +72,7 @@ static struct sctp_transport *sctp_transport_init(struct net *net,
 	 */
 	peer->rto = msecs_to_jiffies(net->sctp.rto_initial);
 
-	peer->last_time_heard = ktime_get();
+	peer->last_time_heard = ktime_set(0, 0);
 	peer->last_time_ecne_reduced = jiffies;
 
 	peer->param_flags = SPP_HB_DISABLE |

commit 47faa1e4c50ec26e6e75dcd1ce53f064bd45f729
Author: Xin Long <lucien.xin@gmail.com>
Date:   Fri Jan 22 01:49:09 2016 +0800

    sctp: remove the dead field of sctp_transport
    
    After we use refcnt to check if transport is alive, the dead can be
    removed from sctp_transport.
    
    The traversal of transport_addr_list in procfs dump is using
    list_for_each_entry_rcu, no need to check if it has been freed.
    
    sctp_generate_t3_rtx_event and sctp_generate_heartbeat_event is
    protected by sock lock, it's not necessary to check dead, either.
    also, the timers are cancelled when sctp_transport_free() is
    called, that it doesn't wait for refcnt to reach 0 to cancel them.
    
    Signed-off-by: Xin Long <lucien.xin@gmail.com>
    Signed-off-by: Marcelo Ricardo Leitner <marcelo.leitner@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index 69f3799570a7..a431c14044a4 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -132,8 +132,6 @@ struct sctp_transport *sctp_transport_new(struct net *net,
  */
 void sctp_transport_free(struct sctp_transport *transport)
 {
-	transport->dead = 1;
-
 	/* Try to delete the heartbeat timer.  */
 	if (del_timer(&transport->hb_timer))
 		sctp_transport_put(transport);
@@ -169,7 +167,7 @@ static void sctp_transport_destroy_rcu(struct rcu_head *head)
  */
 static void sctp_transport_destroy(struct sctp_transport *transport)
 {
-	if (unlikely(!transport->dead)) {
+	if (unlikely(atomic_read(&transport->refcnt))) {
 		WARN(1, "Attempt to destroy undead transport %p!\n", transport);
 		return;
 	}

commit 1eed677933b816978abc4e3e18ecae5f254cb9be
Author: Xin Long <lucien.xin@gmail.com>
Date:   Fri Jan 22 01:49:07 2016 +0800

    sctp: fix the transport dead race check by using atomic_add_unless on refcnt
    
    Now when __sctp_lookup_association is running in BH, it will try to
    check if t->dead is set, but meanwhile other CPUs may be freeing this
    transport and this assoc and if it happens that
    __sctp_lookup_association checked t->dead a bit too early, it may think
    that the association is still good while it was already freed.
    
    So we fix this race by using atomic_add_unless in sctp_transport_hold.
    After we get one transport from hashtable, we will hold it only when
    this transport's refcnt is not 0, so that we can make sure t->asoc
    cannot be freed before we hold the asoc again.
    
    Note that sctp association is not freed using RCU so we can't use
    atomic_add_unless() with it as it may just be too late for that either.
    
    Fixes: 4f0087812648 ("sctp: apply rhashtable api to send/recv path")
    Reported-by: Vlad Yasevich <vyasevich@gmail.com>
    Signed-off-by: Xin Long <lucien.xin@gmail.com>
    Signed-off-by: Marcelo Ricardo Leitner <marcelo.leitner@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index aab9e3f29755..69f3799570a7 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -296,9 +296,9 @@ void sctp_transport_route(struct sctp_transport *transport,
 }
 
 /* Hold a reference to a transport.  */
-void sctp_transport_hold(struct sctp_transport *transport)
+int sctp_transport_hold(struct sctp_transport *transport)
 {
-	atomic_inc(&transport->refcnt);
+	return atomic_add_unless(&transport->refcnt, 1, 0);
 }
 
 /* Release a reference to a transport and clean up

commit 79211c8ed19c055ca105502c8733800d442a0ae6
Author: Andrew Morton <akpm@linux-foundation.org>
Date:   Mon Nov 9 14:58:13 2015 -0800

    remove abs64()
    
    Switch everything to the new and more capable implementation of abs().
    Mainly to give the new abs() a bit of a workout.
    
    Cc: Michal Nazarewicz <mina86@mina86.com>
    Cc: John Stultz <john.stultz@linaro.org>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Masami Hiramatsu <masami.hiramatsu.pt@hitachi.com>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index a0a431824f63..aab9e3f29755 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -331,7 +331,7 @@ void sctp_transport_update_rto(struct sctp_transport *tp, __u32 rtt)
 		 * 1/8, rto_alpha would be expressed as 3.
 		 */
 		tp->rttvar = tp->rttvar - (tp->rttvar >> net->sctp.rto_beta)
-			+ (((__u32)abs64((__s64)tp->srtt - (__s64)rtt)) >> net->sctp.rto_beta);
+			+ (((__u32)abs((__s64)tp->srtt - (__s64)rtt)) >> net->sctp.rto_beta);
 		tp->srtt = tp->srtt - (tp->srtt >> net->sctp.rto_alpha)
 			+ (rtt >> net->sctp.rto_alpha);
 	} else {

commit 299ee123e19889d511092347f5fc14db0f10e3a6
Author: Jason Gunthorpe <jgunthorpe@obsidianresearch.com>
Date:   Wed Jul 30 12:40:53 2014 -0600

    sctp: Fixup v4mapped behaviour to comply with Sock API
    
    The SCTP socket extensions API document describes the v4mapping option as
    follows:
    
    8.1.15.  Set/Clear IPv4 Mapped Addresses (SCTP_I_WANT_MAPPED_V4_ADDR)
    
       This socket option is a Boolean flag which turns on or off the
       mapping of IPv4 addresses.  If this option is turned on, then IPv4
       addresses will be mapped to V6 representation.  If this option is
       turned off, then no mapping will be done of V4 addresses and a user
       will receive both PF_INET6 and PF_INET type addresses on the socket.
       See [RFC3542] for more details on mapped V6 addresses.
    
    This description isn't really in line with what the code does though.
    
    Introduce addr_to_user (renamed addr_v4map), which should be called
    before any sockaddr is passed back to user space. The new function
    places the sockaddr into the correct format depending on the
    SCTP_I_WANT_MAPPED_V4_ADDR option.
    
    Audit all places that touched v4mapped and either sanely construct
    a v4 or v6 address then call addr_to_user, or drop the
    unnecessary v4mapped check entirely.
    
    Audit all places that call addr_to_user and verify they are on a sycall
    return path.
    
    Add a custom getname that formats the address properly.
    
    Several bugs are addressed:
     - SCTP_I_WANT_MAPPED_V4_ADDR=0 often returned garbage for
       addresses to user space
     - The addr_len returned from recvmsg was not correct when
       returning AF_INET on a v6 socket
     - flowlabel and scope_id were not zerod when promoting
       a v4 to v6
     - Some syscalls like bind and connect behaved differently
       depending on v4mapped
    
    Tested bind, getpeername, getsockname, connect, and recvmsg for proper
    behaviour in v4mapped = 1 and 0 cases.
    
    Signed-off-by: Neil Horman <nhorman@tuxdriver.com>
    Tested-by: Jason Gunthorpe <jgunthorpe@obsidianresearch.com>
    Signed-off-by: Jason Gunthorpe <jgunthorpe@obsidianresearch.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index b10e047bbd15..a0a431824f63 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -289,8 +289,8 @@ void sctp_transport_route(struct sctp_transport *transport,
 		 */
 		if (asoc && (!asoc->peer.primary_path ||
 				(transport == asoc->peer.active_path)))
-			opt->pf->af->to_sk_saddr(&transport->saddr,
-						 asoc->base.sk);
+			opt->pf->to_sk_saddr(&transport->saddr,
+					     asoc->base.sk);
 	} else
 		transport->pathmtu = SCTP_DEFAULT_MAXSEGMENT;
 }

commit 8f61059a96c2a29c1cc5a39dfe23d06ef5b4b065
Author: Daniel Borkmann <dborkman@redhat.com>
Date:   Mon Jun 30 13:52:08 2014 +0200

    net: sctp: improve timer slack calculation for transport HBs
    
    RFC4960, section 8.3 says:
    
      On an idle destination address that is allowed to heartbeat,
      it is recommended that a HEARTBEAT chunk is sent once per RTO
      of that destination address plus the protocol parameter
      'HB.interval', with jittering of +/- 50% of the RTO value,
      and exponential backoff of the RTO if the previous HEARTBEAT
      is unanswered.
    
    Currently, we calculate jitter via sctp_jitter() function first,
    and then add its result to the current RTO for the new timeout:
    
      TMO = RTO + (RAND() % RTO) - (RTO / 2)
                  `------------------------^-=> sctp_jitter()
    
    Instead, we can just simplify all this by directly calculating:
    
      TMO = (RTO / 2) + (RAND() % RTO)
    
    With the help of prandom_u32_max(), we don't need to open code
    our own global PRNG, but can instead just make use of the per
    CPU implementation of prandom with better quality numbers. Also,
    we can now spare us the conditional for divide by zero check
    since no div or mod operation needs to be used. Note that
    prandom_u32_max() won't emit the same result as a mod operation,
    but we really don't care here as we only want to have a random
    number scaled into RTO interval.
    
    Note, exponential RTO backoff is handeled elsewhere, namely in
    sctp_do_8_2_transport_strike().
    
    Signed-off-by: Daniel Borkmann <dborkman@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index 7dd672fa651f..b10e047bbd15 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -594,15 +594,16 @@ void sctp_transport_burst_reset(struct sctp_transport *t)
 }
 
 /* What is the next timeout value for this transport? */
-unsigned long sctp_transport_timeout(struct sctp_transport *t)
+unsigned long sctp_transport_timeout(struct sctp_transport *trans)
 {
-	unsigned long timeout;
-	timeout = t->rto + sctp_jitter(t->rto);
-	if ((t->state != SCTP_UNCONFIRMED) &&
-	    (t->state != SCTP_PF))
-		timeout += t->hbinterval;
-	timeout += jiffies;
-	return timeout;
+	/* RTO + timer slack +/- 50% of RTO */
+	unsigned long timeout = (trans->rto >> 1) + prandom_u32_max(trans->rto);
+
+	if (trans->state != SCTP_UNCONFIRMED &&
+	    trans->state != SCTP_PF)
+		timeout += trans->hbinterval;
+
+	return timeout + jiffies;
 }
 
 /* Reset transport variables to their initial values */

commit e575235fc6026bb75e166ff68f84118c62d73f94
Author: Daniel Borkmann <dborkman@redhat.com>
Date:   Wed Jun 11 18:19:30 2014 +0200

    net: sctp: migrate most recently used transport to ktime
    
    Be more precise in transport path selection and use ktime
    helpers instead of jiffies to compare and pick the better
    primary and secondary recently used transports. This also
    avoids any side-effects during a possible roll-over, and
    could lead to better path decision-making.
    
    Signed-off-by: Daniel Borkmann <dborkman@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index 1d348d15b33d..7dd672fa651f 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -72,7 +72,7 @@ static struct sctp_transport *sctp_transport_init(struct net *net,
 	 */
 	peer->rto = msecs_to_jiffies(net->sctp.rto_initial);
 
-	peer->last_time_heard = jiffies;
+	peer->last_time_heard = ktime_get();
 	peer->last_time_ecne_reduced = jiffies;
 
 	peer->param_flags = SPP_HB_DISABLE |

commit 2045ceaed4d54e6e698874d008be727ee5b2a01c
Author: stephen hemminger <stephen@networkplumber.org>
Date:   Wed Feb 12 20:51:22 2014 -0800

    net: remove unnecessary return's
    
    One of my pet coding style peeves is the practice of
    adding extra return; at the end of function.
    Kill several instances of this in network code.
    
    I suppose some coccinelle wizardy could do this automatically.
    
    Signed-off-by: Stephen Hemminger <stephen@networkplumber.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index d0810dc5f079..1d348d15b33d 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -652,5 +652,4 @@ void sctp_transport_immediate_rtx(struct sctp_transport *t)
 		if (!mod_timer(&t->T3_rtx_timer, jiffies + t->rto))
 			sctp_transport_hold(t);
 	}
-	return;
 }

commit 34f9f437104b86f6ddfa2770e2cd852846385dc3
Merge: 95dc19299f74 66e56cd46b93
Author: David S. Miller <davem@davemloft.net>
Date:   Mon Dec 9 20:20:14 2013 -0500

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/davem/net
    
    Merge 'net' into 'net-next' to get the AF_PACKET bug fix that
    Daniel's direct transmit changes depend upon.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 4b2f13a25133b115eb56771bd4a8e71a82aea968
Author: Jeff Kirsher <jeffrey.t.kirsher@intel.com>
Date:   Fri Dec 6 06:28:48 2013 -0800

    sctp: Fix FSF address in file headers
    
    Several files refer to an old address for the Free Software Foundation
    in the file header comment.  Resolve by replacing the address with
    the URL <http://www.gnu.org/licenses/> so that we do not have to keep
    updating the header comments anytime the address changes.
    
    CC: Vlad Yasevich <vyasevich@gmail.com>
    CC: Neil Horman <nhorman@tuxdriver.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index e332efb124cc..1d4f3ac29baf 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -24,9 +24,8 @@
  * See the GNU General Public License for more details.
  *
  * You should have received a copy of the GNU General Public License
- * along with GNU CC; see the file COPYING.  If not, write to
- * the Free Software Foundation, 59 Temple Place - Suite 330,
- * Boston, MA 02111-1307, USA.
+ * along with GNU CC; see the file COPYING.  If not, see
+ * <http://www.gnu.org/licenses/>.
  *
  * Please send any bug reports or fixes you make to the
  * email address(es):

commit 78ac814f120da17053b3d52aa215c7c547c5e77d
Author: wangweidong <wangweidong1@huawei.com>
Date:   Wed Dec 4 17:32:39 2013 +0800

    sctp: disable max_burst when the max_burst is 0
    
    As Michael pointed out that when max_burst is 0, it just disable
    max_burst. It declared in rfc6458#section-8.1.24. so add the check
    in sctp_transport_burst_limited, when it 0, just do nothing.
    
    Reviewed-by: Daniel Borkmann <dborkman@redhat.com>
    Suggested-by: Vlad Yasevich <vyasevich@gmail.com>
    Suggested-by: Michael Tuexen <Michael.Tuexen@lurchi.franken.de>
    Signed-off-by: Wang Weidong <wangweidong1@huawei.com>
    Acked-by: Neil Horman <nhorman@tuxdriver.com>
    Acked-by: Vlad Yasevich <vyasevich@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index e332efb124cc..efc46ffed1fd 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -573,7 +573,7 @@ void sctp_transport_burst_limited(struct sctp_transport *t)
 	u32 old_cwnd = t->cwnd;
 	u32 max_burst_bytes;
 
-	if (t->burst_limited)
+	if (t->burst_limited || asoc->max_burst == 0)
 		return;
 
 	max_burst_bytes = t->flight_size + (asoc->max_burst * asoc->pathmtu);

commit 2ff1cf12c9fe70e75e600404e6a4274b19d293ed
Merge: 16b304f3404f 0f7dd1aa8f95
Author: David S. Miller <davem@davemloft.net>
Date:   Fri Aug 16 15:37:26 2013 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/davem/net

commit 771085d6bf3c52de29fc213e5bad07a82e57c23e
Author: Daniel Borkmann <dborkman@redhat.com>
Date:   Fri Aug 9 16:25:21 2013 +0200

    net: sctp: sctp_transport_destroy{, _rcu}: fix potential pointer corruption
    
    Probably this one is quite unlikely to be triggered, but it's more safe
    to do the call_rcu() at the end after we have dropped the reference on
    the asoc and freed sctp packet chunks. The reason why is because in
    sctp_transport_destroy_rcu() the transport is being kfree()'d, and if
    we're unlucky enough we could run into corrupted pointers. Probably
    that's more of theoretical nature, but it's safer to have this simple fix.
    
    Introduced by commit 8c98653f ("sctp: sctp_close: fix release of bindings
    for deferred call_rcu's"). I also did the 8c98653f regression test and
    it's fine that way.
    
    Signed-off-by: Daniel Borkmann <dborkman@redhat.com>
    Acked-by: Vlad Yasevich <vyasevich@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index bdbbc3fd7c14..8fdd16046d66 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -181,12 +181,12 @@ static void sctp_transport_destroy(struct sctp_transport *transport)
 		return;
 	}
 
-	call_rcu(&transport->rcu, sctp_transport_destroy_rcu);
-
 	sctp_packet_free(&transport->packet);
 
 	if (transport->asoc)
 		sctp_association_put(transport->asoc);
+
+	call_rcu(&transport->rcu, sctp_transport_destroy_rcu);
 }
 
 /* Start T3_rtx timer if it is not already running and update the heartbeat

commit 477143e3fece3dc12629bb1ebd7b47e8e6e72b2b
Author: Daniel Borkmann <dborkman@redhat.com>
Date:   Tue Aug 6 21:18:13 2013 +0200

    net: sctp: trivial: update bug report in header comment
    
    With the restructuring of the lksctp.org site, we only allow bug
    reports through the SCTP mailing list linux-sctp@vger.kernel.org,
    not via SF, as SF is only used for web hosting and nothing more.
    While at it, also remove the obvious statement that bugs will be
    fixed and incooperated into the kernel.
    
    Signed-off-by: Daniel Borkmann <dborkman@redhat.com>
    Acked-by: Vlad Yasevich <vyasevich@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index 9602c52aa617..6836ead5c957 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -32,9 +32,6 @@
  * email address(es):
  *    lksctp developers <linux-sctp@vger.kernel.org>
  *
- * Or submit a bug report through the following website:
- *    http://www.sf.net/projects/lksctp
- *
  * Written or modified by:
  *    La Monte H.P. Yarroll <piggy@acm.org>
  *    Karl Knutson          <karl@athena.chicago.il.us>
@@ -43,9 +40,6 @@
  *    Hui Huang             <hui.huang@nokia.com>
  *    Sridhar Samudrala	    <sri@us.ibm.com>
  *    Ardelle Fan	    <ardelle.fan@intel.com>
- *
- * Any bugs reported given to us we will try to fix... any fixes shared will
- * be incorporated into the next SCTP release.
  */
 
 #define pr_fmt(fmt) KBUILD_MODNAME ": " fmt

commit 91705c61b52029ab5da67a15a23eef08667bf40e
Author: Daniel Borkmann <dborkman@redhat.com>
Date:   Tue Jul 23 14:51:47 2013 +0200

    net: sctp: trivial: update mailing list address
    
    The SCTP mailing list address to send patches or questions
    to is linux-sctp@vger.kernel.org and not
    lksctp-developers@lists.sourceforge.net anymore. Therefore,
    update all occurences.
    
    Signed-off-by: Daniel Borkmann <dborkman@redhat.com>
    Acked-by: Neil Horman <nhorman@tuxdriver.com>
    Acked-by: Vlad Yasevich <vyasevich@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index bdbbc3fd7c14..9602c52aa617 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -30,7 +30,7 @@
  *
  * Please send any bug reports or fixes you make to the
  * email address(es):
- *    lksctp developers <lksctp-developers@lists.sourceforge.net>
+ *    lksctp developers <linux-sctp@vger.kernel.org>
  *
  * Or submit a bug report through the following website:
  *    http://www.sf.net/projects/lksctp

commit bb33381d0c97cdee25f2cdab540b6e2bd16fa03b
Author: Daniel Borkmann <dborkman@redhat.com>
Date:   Fri Jun 28 19:49:40 2013 +0200

    net: sctp: rework debugging framework to use pr_debug and friends
    
    We should get rid of all own SCTP debug printk macros and use the ones
    that the kernel offers anyway instead. This makes the code more readable
    and conform to the kernel code, and offers all the features of dynamic
    debbuging that pr_debug() et al has, such as only turning on/off portions
    of debug messages at runtime through debugfs. The runtime cost of having
    CONFIG_DYNAMIC_DEBUG enabled, but none of the debug statements printing,
    is negligible [1]. If kernel debugging is completly turned off, then these
    statements will also compile into "empty" functions.
    
    While we're at it, we also need to change the Kconfig option as it /now/
    only refers to the ifdef'ed code portions in outqueue.c that enable further
    debugging/tracing of SCTP transaction fields. Also, since SCTP_ASSERT code
    was enabled with this Kconfig option and has now been removed, we
    transform those code parts into WARNs resp. where appropriate BUG_ONs so
    that those bugs can be more easily detected as probably not many people
    have SCTP debugging permanently turned on.
    
    To turn on all SCTP debugging, the following steps are needed:
    
     # mount -t debugfs none /sys/kernel/debug
     # echo -n 'module sctp +p' > /sys/kernel/debug/dynamic_debug/control
    
    This can be done more fine-grained on a per file, per line basis and others
    as described in [2].
    
     [1] https://www.kernel.org/doc/ols/2009/ols2009-pages-39-46.pdf
     [2] Documentation/dynamic-debug-howto.txt
    
    Signed-off-by: Daniel Borkmann <dborkman@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index 5d3c71bbd197..bdbbc3fd7c14 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -176,7 +176,10 @@ static void sctp_transport_destroy_rcu(struct rcu_head *head)
  */
 static void sctp_transport_destroy(struct sctp_transport *transport)
 {
-	SCTP_ASSERT(transport->dead, "Transport is not dead", return);
+	if (unlikely(!transport->dead)) {
+		WARN(1, "Attempt to destroy undead transport %p!\n", transport);
+		return;
+	}
 
 	call_rcu(&transport->rcu, sctp_transport_destroy_rcu);
 
@@ -317,11 +320,9 @@ void sctp_transport_put(struct sctp_transport *transport)
 /* Update transport's RTO based on the newly calculated RTT. */
 void sctp_transport_update_rto(struct sctp_transport *tp, __u32 rtt)
 {
-	/* Check for valid transport.  */
-	SCTP_ASSERT(tp, "NULL transport", return);
-
-	/* We should not be doing any RTO updates unless rto_pending is set.  */
-	SCTP_ASSERT(tp->rto_pending, "rto_pending not set", return);
+	if (unlikely(!tp->rto_pending))
+		/* We should not be doing any RTO updates unless rto_pending is set.  */
+		pr_debug("%s: rto_pending not set on transport %p!\n", __func__, tp);
 
 	if (tp->rttvar || tp->srtt) {
 		struct net *net = sock_net(tp->asoc->base.sk);
@@ -377,9 +378,8 @@ void sctp_transport_update_rto(struct sctp_transport *tp, __u32 rtt)
 	 */
 	tp->rto_pending = 0;
 
-	SCTP_DEBUG_PRINTK("%s: transport: %p, rtt: %d, srtt: %d "
-			  "rttvar: %d, rto: %ld\n", __func__,
-			  tp, rtt, tp->srtt, tp->rttvar, tp->rto);
+	pr_debug("%s: transport:%p, rtt:%d, srtt:%d rttvar:%d, rto:%ld\n",
+		 __func__, tp, rtt, tp->srtt, tp->rttvar, tp->rto);
 }
 
 /* This routine updates the transport's cwnd and partial_bytes_acked
@@ -433,12 +433,11 @@ void sctp_transport_raise_cwnd(struct sctp_transport *transport,
 			cwnd += pmtu;
 		else
 			cwnd += bytes_acked;
-		SCTP_DEBUG_PRINTK("%s: SLOW START: transport: %p, "
-				  "bytes_acked: %d, cwnd: %d, ssthresh: %d, "
-				  "flight_size: %d, pba: %d\n",
-				  __func__,
-				  transport, bytes_acked, cwnd,
-				  ssthresh, flight_size, pba);
+
+		pr_debug("%s: slow start: transport:%p, bytes_acked:%d, "
+			 "cwnd:%d, ssthresh:%d, flight_size:%d, pba:%d\n",
+			 __func__, transport, bytes_acked, cwnd, ssthresh,
+			 flight_size, pba);
 	} else {
 		/* RFC 2960 7.2.2 Whenever cwnd is greater than ssthresh,
 		 * upon each SACK arrival that advances the Cumulative TSN Ack
@@ -459,12 +458,12 @@ void sctp_transport_raise_cwnd(struct sctp_transport *transport,
 			cwnd += pmtu;
 			pba = ((cwnd < pba) ? (pba - cwnd) : 0);
 		}
-		SCTP_DEBUG_PRINTK("%s: CONGESTION AVOIDANCE: "
-				  "transport: %p, bytes_acked: %d, cwnd: %d, "
-				  "ssthresh: %d, flight_size: %d, pba: %d\n",
-				  __func__,
-				  transport, bytes_acked, cwnd,
-				  ssthresh, flight_size, pba);
+
+		pr_debug("%s: congestion avoidance: transport:%p, "
+			 "bytes_acked:%d, cwnd:%d, ssthresh:%d, "
+			 "flight_size:%d, pba:%d\n", __func__,
+			 transport, bytes_acked, cwnd, ssthresh,
+			 flight_size, pba);
 	}
 
 	transport->cwnd = cwnd;
@@ -558,10 +557,10 @@ void sctp_transport_lower_cwnd(struct sctp_transport *transport,
 	}
 
 	transport->partial_bytes_acked = 0;
-	SCTP_DEBUG_PRINTK("%s: transport: %p reason: %d cwnd: "
-			  "%d ssthresh: %d\n", __func__,
-			  transport, reason,
-			  transport->cwnd, transport->ssthresh);
+
+	pr_debug("%s: transport:%p, reason:%d, cwnd:%d, ssthresh:%d\n",
+		 __func__, transport, reason, transport->cwnd,
+		 transport->ssthresh);
 }
 
 /* Apply Max.Burst limit to the congestion window:

commit 939cfa75a0cea97aa60cb88e3722baefdceb4e72
Author: Daniel Borkmann <dborkman@redhat.com>
Date:   Mon Jun 17 11:40:04 2013 +0200

    net: sctp: get rid of t_new macro for kzalloc
    
    t_new rather obfuscates things where everyone else is using actual
    function names instead of that macro, so replace it with kzalloc,
    which is the function t_new wraps.
    
    Signed-off-by: Daniel Borkmann <dborkman@redhat.com>
    Acked-by: Vlad Yasevich <vyasevich@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index 098f1d5f769e..5d3c71bbd197 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -116,7 +116,7 @@ struct sctp_transport *sctp_transport_new(struct net *net,
 {
 	struct sctp_transport *transport;
 
-	transport = t_new(struct sctp_transport, gfp);
+	transport = kzalloc(sizeof(*transport), gfp);
 	if (!transport)
 		goto fail;
 

commit 8fa5df6d210a09241876b74d156c57d833dd057b
Author: Daniel Borkmann <dborkman@redhat.com>
Date:   Tue Apr 16 11:07:15 2013 +0000

    net: sctp: sctp_transport: remove unused variable
    
    sctp_transport's member 'malloced' is set to 1, never evaluated
    and the structure is kfreed anyway. So just remove it.
    
    Signed-off-by: Daniel Borkmann <dborkman@redhat.com>
    Acked-by: Neil Horman <nhorman@tuxdriver.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index fafd2a461ba0..098f1d5f769e 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -123,7 +123,6 @@ struct sctp_transport *sctp_transport_new(struct net *net,
 	if (!sctp_transport_init(net, transport, addr, gfp))
 		goto fail_init;
 
-	transport->malloced = 1;
 	SCTP_DBG_OBJCNT_INC(transport);
 
 	return transport;

commit 25cc4ae913a46bcc11b03c37bec59568f2122a36
Author: Ying Xue <ying.xue@windriver.com>
Date:   Sun Feb 3 20:32:57 2013 +0000

    net: remove redundant check for timer pending state before del_timer
    
    As in del_timer() there has already placed a timer_pending() function
    to check whether the timer to be deleted is pending or not, it's
    unnecessary to check timer pending state again before del_timer() is
    called.
    
    Signed-off-by: Ying Xue <ying.xue@windriver.com>
    Cc: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index ca5331cc1ed2..fafd2a461ba0 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -151,13 +151,11 @@ void sctp_transport_free(struct sctp_transport *transport)
 	 * structure hang around in memory since we know
 	 * the tranport is going away.
 	 */
-	if (timer_pending(&transport->T3_rtx_timer) &&
-	    del_timer(&transport->T3_rtx_timer))
+	if (del_timer(&transport->T3_rtx_timer))
 		sctp_transport_put(transport);
 
 	/* Delete the ICMP proto unreachable timer if it's active. */
-	if (timer_pending(&transport->proto_unreach_timer) &&
-	    del_timer(&transport->proto_unreach_timer))
+	if (del_timer(&transport->proto_unreach_timer))
 		sctp_association_put(transport->asoc);
 
 	sctp_transport_put(transport);
@@ -655,10 +653,9 @@ void sctp_transport_reset(struct sctp_transport *t)
 void sctp_transport_immediate_rtx(struct sctp_transport *t)
 {
 	/* Stop pending T3_rtx_timer */
-	if (timer_pending(&t->T3_rtx_timer)) {
-		(void)del_timer(&t->T3_rtx_timer);
+	if (del_timer(&t->T3_rtx_timer))
 		sctp_transport_put(t);
-	}
+
 	sctp_retransmit(&t->asoc->outqueue, t, SCTP_RTXR_T3_RTX);
 	if (!timer_pending(&t->T3_rtx_timer)) {
 		if (!mod_timer(&t->T3_rtx_timer, jiffies + t->rto))

commit 8c98653f05534acd1cb07ea4929702a3659177d1
Author: Daniel Borkmann <dborkman@redhat.com>
Date:   Fri Feb 1 04:37:43 2013 +0000

    sctp: sctp_close: fix release of bindings for deferred call_rcu's
    
    It seems due to RCU usage, i.e. within SCTP's address binding list,
    a, say, ``behavioral change'' was introduced which does actually
    not conform to the RFC anymore. In particular consider the following
    (fictional) scenario to demonstrate this:
    
      do:
        Two SOCK_SEQPACKET-style sockets are opened (S1, S2)
        S1 is bound to 127.0.0.1, port 1024 [server]
        S2 is bound to 127.0.0.1, port 1025 [client]
        listen(2) is invoked on S1
        From S2 we call one sendmsg(2) with msg.msg_name and
           msg.msg_namelen parameters set to the server's
           address
        S1, S2 are closed
        goto do
    
    The first pass of this loop passes successful, while the second round
    fails during binding of S1 (address still in use). What is happening?
    In the first round, the initial handshake is being done, and, at the
    time close(2) is called on S1, a non-graceful shutdown is performed via
    ABORT since in S1's receive queue an unprocessed packet is present,
    thus stating an error condition. This can be considered as a correct
    behavior.
    
    During close also all bound addresses are freed, thus nothing *must*
    be active anymore. In reference to RFC2960:
    
      After checking the Verification Tag, the receiving endpoint shall
      remove the association from its record, and shall report the
      termination to its upper layer. (9.1 Abort of an Association)
    
    Also, no half-open states are supported, thus after an ungraceful
    shutdown, we leave nothing behind. However, this seems not to be
    happening though. In a real-world scenario, this is exactly where
    it breaks the lksctp-tools functional test suite, *for instance*:
    
      ./test_sockopt
      test_sockopt.c  1 PASS : getsockopt(SCTP_STATUS) on a socket with no assoc
      test_sockopt.c  2 PASS : getsockopt(SCTP_STATUS)
      test_sockopt.c  3 PASS : getsockopt(SCTP_STATUS) with invalid associd
      test_sockopt.c  4 PASS : getsockopt(SCTP_STATUS) with NULL associd
      test_sockopt.c  5 BROK : bind: Address already in use
    
    The underlying problem is that sctp_endpoint_destroy() hasn't been
    triggered yet while the next bind attempt is being done. It will be
    triggered eventually (but too late) by sctp_transport_destroy_rcu()
    after one RCU grace period:
    
      sctp_transport_destroy()
        sctp_transport_destroy_rcu() ----.
          sctp_association_put() [*]  <--+--> sctp_packet_free()
            sctp_association_destroy()          [...]
              sctp_endpoint_put()                 skb->destructor
                sctp_endpoint_destroy()             sctp_wfree()
                  sctp_bind_addr_free()               sctp_association_put() [*]
    
    Thus, we move out the condition with sctp_association_put() as well as
    the sctp_packet_free() invocation and the issue can be solved. We also
    better free the SCTP chunks first before putting the ref of the association.
    
    With this patch, the example above (which simulates a similar scenario
    as in the implementation of this test case) and therefore also the test
    suite run successfully through. Tested by myself.
    
    Cc: Vlad Yasevich <vyasevich@gmail.com>
    Signed-off-by: Daniel Borkmann <dborkman@redhat.com>
    Acked-by: Vlad Yasevich <vyasevich@gmail.com>
    Acked-by: Neil Horman <nhorman@tuxdriver.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index 4e45bb68aef0..ca5331cc1ed2 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -168,10 +168,6 @@ static void sctp_transport_destroy_rcu(struct rcu_head *head)
 	struct sctp_transport *transport;
 
 	transport = container_of(head, struct sctp_transport, rcu);
-	if (transport->asoc)
-		sctp_association_put(transport->asoc);
-
-	sctp_packet_free(&transport->packet);
 
 	dst_release(transport->dst);
 	kfree(transport);
@@ -186,6 +182,11 @@ static void sctp_transport_destroy(struct sctp_transport *transport)
 	SCTP_ASSERT(transport->dead, "Transport is not dead", return);
 
 	call_rcu(&transport->rcu, sctp_transport_destroy_rcu);
+
+	sctp_packet_free(&transport->packet);
+
+	if (transport->asoc)
+		sctp_association_put(transport->asoc);
 }
 
 /* Start T3_rtx timer if it is not already running and update the heartbeat

commit 45122ca26ced7fae41049326a3797a73f961db2e
Author: Thomas Graf <tgraf@suug.ch>
Date:   Thu Dec 6 09:25:05 2012 +0000

    sctp: Add RCU protection to assoc->transport_addr_list
    
    peer.transport_addr_list is currently only protected by sk_sock
    which is inpractical to acquire for procfs dumping purposes.
    
    This patch adds RCU protection allowing for the procfs readers to
    enter RCU read-side critical sections.
    
    Modification of the list continues to be serialized via sk_lock.
    
    V2: Use list_del_rcu() in sctp_association_free() to be safe
        Skip transports marked dead when dumping for procfs
    
    Cc: Vlad Yasevich <vyasevich@gmail.com>
    Cc: Neil Horman <nhorman@tuxdriver.com>
    Signed-off-by: Thomas Graf <tgraf@suug.ch>
    Acked-by: Vlad Yasevich <vyasevich@gmail.com>
    Acked-by: Neil Horman <nhorman@tuxdriver.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index 310f11eb2206..4e45bb68aef0 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -163,13 +163,11 @@ void sctp_transport_free(struct sctp_transport *transport)
 	sctp_transport_put(transport);
 }
 
-/* Destroy the transport data structure.
- * Assumes there are no more users of this structure.
- */
-static void sctp_transport_destroy(struct sctp_transport *transport)
+static void sctp_transport_destroy_rcu(struct rcu_head *head)
 {
-	SCTP_ASSERT(transport->dead, "Transport is not dead", return);
+	struct sctp_transport *transport;
 
+	transport = container_of(head, struct sctp_transport, rcu);
 	if (transport->asoc)
 		sctp_association_put(transport->asoc);
 
@@ -180,6 +178,16 @@ static void sctp_transport_destroy(struct sctp_transport *transport)
 	SCTP_DBG_OBJCNT_DEC(transport);
 }
 
+/* Destroy the transport data structure.
+ * Assumes there are no more users of this structure.
+ */
+static void sctp_transport_destroy(struct sctp_transport *transport)
+{
+	SCTP_ASSERT(transport->dead, "Transport is not dead", return);
+
+	call_rcu(&transport->rcu, sctp_transport_destroy_rcu);
+}
+
 /* Start T3_rtx timer if it is not already running and update the heartbeat
  * timer.  This routine is called every time a DATA chunk is sent.
  */

commit 196d67593439b03088913227093e374235596e33
Author: Michele Baldessari <michele@acksyn.org>
Date:   Sat Dec 1 04:49:42 2012 +0000

    sctp: Add support to per-association statistics via a new SCTP_GET_ASSOC_STATS call
    
    The current SCTP stack is lacking a mechanism to have per association
    statistics. This is an implementation modeled after OpenSolaris'
    SCTP_GET_ASSOC_STATS.
    
    Userspace part will follow on lksctp if/when there is a general ACK on
    this.
    V4:
    - Move ipackets++ before q->immediate.func() for consistency reasons
    - Move sctp_max_rto() at the end of sctp_transport_update_rto() to avoid
      returning bogus RTO values
    - return asoc->rto_min when max_obs_rto value has not changed
    
    V3:
    - Increase ictrlchunks in sctp_assoc_bh_rcv() as well
    - Move ipackets++ to sctp_inq_push()
    - return 0 when no rto updates took place since the last call
    
    V2:
    - Implement partial retrieval of stat struct to cope for future expansion
    - Kill the rtxpackets counter as it cannot be precise anyway
    - Rename outseqtsns to outofseqtsns to make it clearer that these are out
      of sequence unexpected TSNs
    - Move asoc->ipackets++ under a lock to avoid potential miscounts
    - Fold asoc->opackets++ into the already existing asoc check
    - Kill unneeded (q->asoc) test when increasing rtxchunks
    - Do not count octrlchunks if sending failed (SCTP_XMIT_OK != 0)
    - Don't count SHUTDOWNs as SACKs
    - Move SCTP_GET_ASSOC_STATS to the private space API
    - Adjust the len check in sctp_getsockopt_assoc_stats() to allow for
      future struct growth
    - Move association statistics in their own struct
    - Update idupchunks when we send a SACK with dup TSNs
    - return min_rto in max_rto when RTO has not changed. Also return the
      transport when max_rto last changed.
    
    Signed-off: Michele Baldessari <michele@acksyn.org>
    Acked-by: Vlad Yasevich <vyasevich@gmail.com>
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index 206cf5238fd3..310f11eb2206 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -363,6 +363,7 @@ void sctp_transport_update_rto(struct sctp_transport *tp, __u32 rtt)
 	if (tp->rto > tp->asoc->rto_max)
 		tp->rto = tp->asoc->rto_max;
 
+	sctp_max_rto(tp->asoc, tp);
 	tp->rtt = rtt;
 
 	/* Reset rto_pending so that a new RTT measurement is started when a
@@ -620,6 +621,7 @@ void sctp_transport_reset(struct sctp_transport *t)
 	t->burst_limited = 0;
 	t->ssthresh = asoc->peer.i.a_rwnd;
 	t->rto = asoc->rto_initial;
+	sctp_max_rto(asoc, t);
 	t->rtt = 0;
 	t->srtt = 0;
 	t->rttvar = 0;

commit 92d64c261e77cb2a6117887617e2a629fea6b67c
Author: Schoch Christian <e0326715@student.tuwien.ac.at>
Date:   Wed Nov 28 05:18:29 2012 +0000

    sctp: Error in calculation of RTTvar
    
    The calculation of RTTVAR involves the subtraction of two unsigned
    numbers which
    may causes rollover and results in very high values of RTTVAR when RTT > SRTT.
    With this patch it is possible to set RTOmin = 1 to get the minimum of RTO at
    4 times the clock granularity.
    
    Change Notes:
    
    v2)
            *Replaced abs() by abs64() and long by __s64, changed patch
    description.
    
    Signed-off-by: Christian Schoch <e0326715@student.tuwien.ac.at>
    CC: Vlad Yasevich <vyasevich@gmail.com>
    CC: Sridhar Samudrala <sri@us.ibm.com>
    CC: Neil Horman <nhorman@tuxdriver.com>
    CC: linux-sctp@vger.kernel.org
    Acked-by: Vlad Yasevich <vyasevich@gmail.com>
    Acked-by: Neil Horman <nhorman@tuxdriver.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index 953c21e4af97..206cf5238fd3 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -331,7 +331,7 @@ void sctp_transport_update_rto(struct sctp_transport *tp, __u32 rtt)
 		 * 1/8, rto_alpha would be expressed as 3.
 		 */
 		tp->rttvar = tp->rttvar - (tp->rttvar >> net->sctp.rto_beta)
-			+ ((abs(tp->srtt - rtt)) >> net->sctp.rto_beta);
+			+ (((__u32)abs64((__s64)tp->srtt - (__s64)rtt)) >> net->sctp.rto_beta);
 		tp->srtt = tp->srtt - (tp->srtt >> net->sctp.rto_alpha)
 			+ (rtt >> net->sctp.rto_alpha);
 	} else {

commit e1fc3b14f9a90d9591016749289f2c3d7b35fbf4
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Tue Aug 7 07:29:57 2012 +0000

    sctp: Make sysctl tunables per net
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index aada963c9d6b..953c21e4af97 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -77,7 +77,7 @@ static struct sctp_transport *sctp_transport_init(struct net *net,
 	 * given destination transport address, set RTO to the protocol
 	 * parameter 'RTO.Initial'.
 	 */
-	peer->rto = msecs_to_jiffies(sctp_rto_initial);
+	peer->rto = msecs_to_jiffies(net->sctp.rto_initial);
 
 	peer->last_time_heard = jiffies;
 	peer->last_time_ecne_reduced = jiffies;
@@ -87,8 +87,8 @@ static struct sctp_transport *sctp_transport_init(struct net *net,
 			    SPP_SACKDELAY_ENABLE;
 
 	/* Initialize the default path max_retrans.  */
-	peer->pathmaxrxt  = sctp_max_retrans_path;
-	peer->pf_retrans  = sctp_pf_retrans;
+	peer->pathmaxrxt  = net->sctp.max_retrans_path;
+	peer->pf_retrans  = net->sctp.pf_retrans;
 
 	INIT_LIST_HEAD(&peer->transmitted);
 	INIT_LIST_HEAD(&peer->send_ready);
@@ -318,6 +318,7 @@ void sctp_transport_update_rto(struct sctp_transport *tp, __u32 rtt)
 	SCTP_ASSERT(tp->rto_pending, "rto_pending not set", return);
 
 	if (tp->rttvar || tp->srtt) {
+		struct net *net = sock_net(tp->asoc->base.sk);
 		/* 6.3.1 C3) When a new RTT measurement R' is made, set
 		 * RTTVAR <- (1 - RTO.Beta) * RTTVAR + RTO.Beta * |SRTT - R'|
 		 * SRTT <- (1 - RTO.Alpha) * SRTT + RTO.Alpha * R'
@@ -329,10 +330,10 @@ void sctp_transport_update_rto(struct sctp_transport *tp, __u32 rtt)
 		 * For example, assuming the default value of RTO.Alpha of
 		 * 1/8, rto_alpha would be expressed as 3.
 		 */
-		tp->rttvar = tp->rttvar - (tp->rttvar >> sctp_rto_beta)
-			+ ((abs(tp->srtt - rtt)) >> sctp_rto_beta);
-		tp->srtt = tp->srtt - (tp->srtt >> sctp_rto_alpha)
-			+ (rtt >> sctp_rto_alpha);
+		tp->rttvar = tp->rttvar - (tp->rttvar >> net->sctp.rto_beta)
+			+ ((abs(tp->srtt - rtt)) >> net->sctp.rto_beta);
+		tp->srtt = tp->srtt - (tp->srtt >> net->sctp.rto_alpha)
+			+ (rtt >> net->sctp.rto_alpha);
 	} else {
 		/* 6.3.1 C2) When the first RTT measurement R is made, set
 		 * SRTT <- R, RTTVAR <- R/2.

commit 89bf3450cb9b041b1bb4bcc5e7cbdeab4545b1c1
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Tue Aug 7 07:26:14 2012 +0000

    sctp: Push struct net down into sctp_transport_init
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index c97472b248a2..aada963c9d6b 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -59,7 +59,8 @@
 /* 1st Level Abstractions.  */
 
 /* Initialize a new transport from provided memory.  */
-static struct sctp_transport *sctp_transport_init(struct sctp_transport *peer,
+static struct sctp_transport *sctp_transport_init(struct net *net,
+						  struct sctp_transport *peer,
 						  const union sctp_addr *addr,
 						  gfp_t gfp)
 {
@@ -109,7 +110,8 @@ static struct sctp_transport *sctp_transport_init(struct sctp_transport *peer,
 }
 
 /* Allocate and initialize a new transport.  */
-struct sctp_transport *sctp_transport_new(const union sctp_addr *addr,
+struct sctp_transport *sctp_transport_new(struct net *net,
+					  const union sctp_addr *addr,
 					  gfp_t gfp)
 {
 	struct sctp_transport *transport;
@@ -118,7 +120,7 @@ struct sctp_transport *sctp_transport_new(const union sctp_addr *addr,
 	if (!transport)
 		goto fail;
 
-	if (!sctp_transport_init(transport, addr, gfp))
+	if (!sctp_transport_init(net, transport, addr, gfp))
 		goto fail_init;
 
 	transport->malloced = 1;

commit 5e9965c15ba88319500284e590733f4a4629a288
Merge: 3ba97381343b 2860583fe840
Author: David S. Miller <davem@davemloft.net>
Date:   Sun Jul 22 17:04:15 2012 -0700

    Merge branch 'kill_rtcache'
    
    The ipv4 routing cache is non-deterministic, performance wise, and is
    subject to reasonably easy to launch denial of service attacks.
    
    The routing cache works great for well behaved traffic, and the world
    was a much friendlier place when the tradeoffs that led to the routing
    cache's design were considered.
    
    What it boils down to is that the performance of the routing cache is
    a product of the traffic patterns seen by a system rather than being a
    product of the contents of the routing tables.  The former of which is
    controllable by external entitites.
    
    Even for "well behaved" legitimate traffic, high volume sites can see
    hit rates in the routing cache of only ~%10.
    
    The general flow of this patch series is that first the routing cache
    is removed.  We build a completely new rtable entry every lookup
    request.
    
    Next we make some simplifications due to the fact that removing the
    routing cache causes several members of struct rtable to become no
    longer necessary.
    
    Then we need to make some amends such that we can legally cache
    pre-constructed routes in the FIB nexthops.  Firstly, we need to
    invalidate routes which are hit with nexthop exceptions.  Secondly we
    have to change the semantics of rt->rt_gateway such that zero means
    that the destination is on-link and non-zero otherwise.
    
    Now that the preparations are ready, we start caching precomputed
    routes in the FIB nexthops.  Output and input routes need different
    kinds of care when determining if we can legally do such caching or
    not.  The details are in the commit log messages for those changes.
    
    The patch series then winds down with some more struct rtable
    simplifications and other tidy ups that remove unnecessary overhead.
    
    On a SPARC-T3 output route lookups are ~876 cycles.  Input route
    lookups are ~1169 cycles with rpfilter disabled, and about ~1468
    cycles with rpfilter enabled.
    
    These measurements were taken with the kbench_mod test module in the
    net_test_tools GIT tree:
    
    git://git.kernel.org/pub/scm/linux/kernel/git/davem/net_test_tools.git
    
    That GIT tree also includes a udpflood tester tool and stresses
    route lookups on packet output.
    
    For example, on the same SPARC-T3 system we can run:
    
            time ./udpflood -l 10000000 10.2.2.11
    
    with routing cache:
    real    1m21.955s       user    0m6.530s        sys     1m15.390s
    
    without routing cache:
    real    1m31.678s       user    0m6.520s        sys     1m25.140s
    
    Performance undoubtedly can easily be improved further.
    
    For example fib_table_lookup() performs a lot of excessive
    computations with all the masking and shifting, some of it
    conditionalized to deal with edge cases.
    
    Also, Eric's no-ref optimization for input route lookups can be
    re-instated for the FIB nexthop caching code path.  I would be really
    pleased if someone would work on that.
    
    In fact anyone suitable motivated can just fire up perf on the loading
    of the test net_test_tools benchmark kernel module.  I spend much of
    my time going:
    
    bash# perf record insmod ./kbench_mod.ko dst=172.30.42.22 src=74.128.0.1 iif=2
    bash# perf report
    
    Thanks to helpful feedback from Joe Perches, Eric Dumazet, Ben
    Hutchings, and others.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 5aa93bcf66f4af094d6f11096e81d5501a0b4ba5
Author: Neil Horman <nhorman@tuxdriver.com>
Date:   Sat Jul 21 07:56:07 2012 +0000

    sctp: Implement quick failover draft from tsvwg
    
    I've seen several attempts recently made to do quick failover of sctp transports
    by reducing various retransmit timers and counters.  While its possible to
    implement a faster failover on multihomed sctp associations, its not
    particularly robust, in that it can lead to unneeded retransmits, as well as
    false connection failures due to intermittent latency on a network.
    
    Instead, lets implement the new ietf quick failover draft found here:
    http://tools.ietf.org/html/draft-nishida-tsvwg-sctp-failover-05
    
    This will let the sctp stack identify transports that have had a small number of
    errors, and avoid using them quickly until their reliability can be
    re-established.  I've tested this out on two virt guests connected via multiple
    isolated virt networks and believe its in compliance with the above draft and
    works well.
    
    Signed-off-by: Neil Horman <nhorman@tuxdriver.com>
    CC: Vlad Yasevich <vyasevich@gmail.com>
    CC: Sridhar Samudrala <sri@us.ibm.com>
    CC: "David S. Miller" <davem@davemloft.net>
    CC: linux-sctp@vger.kernel.org
    CC: joe@perches.com
    Acked-by: Vlad Yasevich <vyasevich@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index a6b7ee9ce28a..d1c652ed2f3d 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -87,6 +87,7 @@ static struct sctp_transport *sctp_transport_init(struct sctp_transport *peer,
 
 	/* Initialize the default path max_retrans.  */
 	peer->pathmaxrxt  = sctp_max_retrans_path;
+	peer->pf_retrans  = sctp_pf_retrans;
 
 	INIT_LIST_HEAD(&peer->transmitted);
 	INIT_LIST_HEAD(&peer->send_ready);
@@ -595,7 +596,8 @@ unsigned long sctp_transport_timeout(struct sctp_transport *t)
 {
 	unsigned long timeout;
 	timeout = t->rto + sctp_jitter(t->rto);
-	if (t->state != SCTP_UNCONFIRMED)
+	if ((t->state != SCTP_UNCONFIRMED) &&
+	    (t->state != SCTP_PF))
 		timeout += t->hbinterval;
 	timeout += jiffies;
 	return timeout;

commit f5b0a8743601a4477419171f5046bd07d1c080a0
Author: David S. Miller <davem@davemloft.net>
Date:   Thu Jul 19 12:31:33 2012 -0700

    net: Document dst->obsolete better.
    
    Add a big comment explaining how the field works, and use defines
    instead of magic constants for the values assigned to it.
    
    Suggested by Joe Perches.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index a6b7ee9ce28a..ec3a12b9b802 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -216,7 +216,7 @@ void sctp_transport_set_owner(struct sctp_transport *transport,
 void sctp_transport_pmtu(struct sctp_transport *transport, struct sock *sk)
 {
 	/* If we don't have a fresh route, look one up */
-	if (!transport->dst || transport->dst->obsolete > 1) {
+	if (!transport->dst || transport->dst->obsolete) {
 		dst_release(transport->dst);
 		transport->af_specific->get_dst(transport, &transport->saddr,
 						&transport->fl, sk);

commit 6700c2709c08d74ae2c3c29b84a30da012dbc7f1
Author: David S. Miller <davem@davemloft.net>
Date:   Tue Jul 17 03:29:28 2012 -0700

    net: Pass optional SKB and SK arguments to dst_ops->{update_pmtu,redirect}()
    
    This will be used so that we can compose a full flow key.
    
    Even though we have a route in this context, we need more.  In the
    future the routes will be without destination address, source address,
    etc. keying.  One ipv4 route will cover entire subnets, etc.
    
    In this environment we have to have a way to possess persistent storage
    for redirects and PMTU information.  This persistent storage will exist
    in the FIB tables, and that's why we'll need to be able to rebuild a
    full lookup flow key here.  Using that flow key will do a fib_lookup()
    and create/update the persistent entry.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index e69e1a2175a4..a6b7ee9ce28a 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -249,7 +249,7 @@ void sctp_transport_update_pmtu(struct sock *sk, struct sctp_transport *t, u32 p
 		t->af_specific->get_dst(t, &t->saddr, &t->fl, sk);
 
 	if (dst) {
-		dst->ops->update_pmtu(dst, pmtu);
+		dst->ops->update_pmtu(dst, sk, NULL, pmtu);
 
 		dst = sctp_transport_dst_check(t);
 		if (!dst)

commit 02f3d4ce9e81434a365f4643020b0402f6fe3332
Author: David S. Miller <davem@davemloft.net>
Date:   Mon Jul 16 03:57:14 2012 -0700

    sctp: Adjust PMTU updates to accomodate route invalidation.
    
    This adjusts the call to dst_ops->update_pmtu() so that we can
    transparently handle the fact that, in the future, the dst itself can
    be invalidated by the PMTU update (when we have non-host routes cached
    in sockets).
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index 1dcceb6e0ce6..e69e1a2175a4 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -228,7 +228,7 @@ void sctp_transport_pmtu(struct sctp_transport *transport, struct sock *sk)
 		transport->pathmtu = SCTP_DEFAULT_MAXSEGMENT;
 }
 
-void sctp_transport_update_pmtu(struct sctp_transport *t, u32 pmtu)
+void sctp_transport_update_pmtu(struct sock *sk, struct sctp_transport *t, u32 pmtu)
 {
 	struct dst_entry *dst;
 
@@ -245,8 +245,16 @@ void sctp_transport_update_pmtu(struct sctp_transport *t, u32 pmtu)
 	}
 
 	dst = sctp_transport_dst_check(t);
-	if (dst)
+	if (!dst)
+		t->af_specific->get_dst(t, &t->saddr, &t->fl, sk);
+
+	if (dst) {
 		dst->ops->update_pmtu(dst, pmtu);
+
+		dst = sctp_transport_dst_check(t);
+		if (!dst)
+			t->af_specific->get_dst(t, &t->saddr, &t->fl, sk);
+	}
 }
 
 /* Caches the dst entry and source address for a transport's destination

commit 4244854d22bf8f782698c5224b9191c8d2d42610
Author: Neil Horman <nhorman@tuxdriver.com>
Date:   Sat Jun 30 03:04:26 2012 +0000

    sctp: be more restrictive in transport selection on bundled sacks
    
    It was noticed recently that when we send data on a transport, its possible that
    we might bundle a sack that arrived on a different transport.  While this isn't
    a major problem, it does go against the SHOULD requirement in section 6.4 of RFC
    2960:
    
     An endpoint SHOULD transmit reply chunks (e.g., SACK, HEARTBEAT ACK,
       etc.) to the same destination transport address from which it
       received the DATA or control chunk to which it is replying.  This
       rule should also be followed if the endpoint is bundling DATA chunks
       together with the reply chunk.
    
    This patch seeks to correct that.  It restricts the bundling of sack operations
    to only those transports which have moved the ctsn of the association forward
    since the last sack.  By doing this we guarantee that we only bundle outbound
    saks on a transport that has received a chunk since the last sack.  This brings
    us into stricter compliance with the RFC.
    
    Vlad had initially suggested that we strictly allow only sack bundling on the
    transport that last moved the ctsn forward.  While this makes sense, I was
    concerned that doing so prevented us from bundling in the case where we had
    received chunks that moved the ctsn on multiple transports.  In those cases, the
    RFC allows us to select any of the transports having received chunks to bundle
    the sack on.  so I've modified the approach to allow for that, by adding a state
    variable to each transport that tracks weather it has moved the ctsn since the
    last sack.  This I think keeps our behavior (and performance), close enough to
    our current profile that I think we can do this without a sysctl knob to
    enable/disable it.
    
    Signed-off-by: Neil Horman <nhorman@tuxdriver.com>
    CC: Vlad Yaseivch <vyasevich@gmail.com>
    CC: David S. Miller <davem@davemloft.net>
    CC: linux-sctp@vger.kernel.org
    Reported-by: Michele Baldessari <michele@redhat.com>
    Reported-by: sorin serban <sserban@redhat.com>
    Acked-by: Vlad Yasevich <vyasevich@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index b026ba0c6992..1dcceb6e0ce6 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -68,6 +68,8 @@ static struct sctp_transport *sctp_transport_init(struct sctp_transport *peer,
 	peer->af_specific = sctp_get_af_specific(addr->sa.sa_family);
 	memset(&peer->saddr, 0, sizeof(union sctp_addr));
 
+	peer->sack_generation = 0;
+
 	/* From 6.3.1 RTO Calculation:
 	 *
 	 * C1) Until an RTT measurement has been made for a packet sent to the

commit e0268868ba064980488fc8c194db3d8e9fb2959c
Author: Nicolas Dichtel <nicolas.dichtel@6wind.com>
Date:   Fri May 4 05:24:54 2012 +0000

    sctp: check cached dst before using it
    
    dst_check() will take care of SA (and obsolete field), hence
    IPsec rekeying scenario is taken into account.
    
    Signed-off-by: Nicolas Dichtel <nicolas.dichtel@6wind.com>
    Acked-by: Vlad Yaseivch <vyasevich@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index 3889330b7b04..b026ba0c6992 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -226,23 +226,6 @@ void sctp_transport_pmtu(struct sctp_transport *transport, struct sock *sk)
 		transport->pathmtu = SCTP_DEFAULT_MAXSEGMENT;
 }
 
-/* this is a complete rip-off from __sk_dst_check
- * the cookie is always 0 since this is how it's used in the
- * pmtu code
- */
-static struct dst_entry *sctp_transport_dst_check(struct sctp_transport *t)
-{
-	struct dst_entry *dst = t->dst;
-
-	if (dst && dst->obsolete && dst->ops->check(dst, 0) == NULL) {
-		dst_release(t->dst);
-		t->dst = NULL;
-		return NULL;
-	}
-
-	return dst;
-}
-
 void sctp_transport_update_pmtu(struct sctp_transport *t, u32 pmtu)
 {
 	struct dst_entry *dst;

commit ddc4bbee6ef1ed20314be3888dd39ceefe233e79
Author: Michio Honda <micchie@sfc.wide.ad.jp>
Date:   Fri Jun 17 11:03:23 2011 +0900

    sctp: fasthandoff with ASCONF at mobile-node
    
    Fast retransmission after changing the last address
    with ASCONF negotiation
    
    Signed-off-by: Michio Honda <micchie@sfc.wide.ad.jp>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index 394c57ca2f54..3889330b7b04 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -641,3 +641,19 @@ void sctp_transport_reset(struct sctp_transport *t)
 	t->cacc.next_tsn_at_change = 0;
 	t->cacc.cacc_saw_newack = 0;
 }
+
+/* Schedule retransmission on the given transport */
+void sctp_transport_immediate_rtx(struct sctp_transport *t)
+{
+	/* Stop pending T3_rtx_timer */
+	if (timer_pending(&t->T3_rtx_timer)) {
+		(void)del_timer(&t->T3_rtx_timer);
+		sctp_transport_put(t);
+	}
+	sctp_retransmit(&t->asoc->outqueue, t, SCTP_RTXR_T3_RTX);
+	if (!timer_pending(&t->T3_rtx_timer)) {
+		if (!mod_timer(&t->T3_rtx_timer, jiffies + t->rto))
+			sctp_transport_hold(t);
+	}
+	return;
+}

commit 8663c938ceb72f47941c95ff0ea491ebbdd68f26
Author: David S. Miller <davem@davemloft.net>
Date:   Fri May 6 16:32:47 2011 -0700

    sctp: Store a flowi in transports to provide persistent keying.
    
    Several future simplifications are possible now because of this.
    
    For example, the sctp_addr unions can simply refer directly to
    the flowi information.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index d8595dd1a8a7..394c57ca2f54 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -213,13 +213,11 @@ void sctp_transport_set_owner(struct sctp_transport *transport,
 /* Initialize the pmtu of a transport. */
 void sctp_transport_pmtu(struct sctp_transport *transport, struct sock *sk)
 {
-	struct flowi fl;
-
 	/* If we don't have a fresh route, look one up */
 	if (!transport->dst || transport->dst->obsolete > 1) {
 		dst_release(transport->dst);
 		transport->af_specific->get_dst(transport, &transport->saddr,
-					      &fl, sk);
+						&transport->fl, sk);
 	}
 
 	if (transport->dst) {
@@ -274,14 +272,13 @@ void sctp_transport_route(struct sctp_transport *transport,
 {
 	struct sctp_association *asoc = transport->asoc;
 	struct sctp_af *af = transport->af_specific;
-	struct flowi fl;
 
-	af->get_dst(transport, saddr, &fl, sctp_opt2sk(opt));
+	af->get_dst(transport, saddr, &transport->fl, sctp_opt2sk(opt));
 
 	if (saddr)
 		memcpy(&transport->saddr, saddr, sizeof(union sctp_addr));
 	else
-		af->get_saddr(opt, transport, &fl);
+		af->get_saddr(opt, transport, &transport->fl);
 
 	if ((transport->param_flags & SPP_PMTUD_DISABLE) && transport->pathmtu) {
 		return;

commit da0420bee24a1ba54e55a61e95b1a53205d7e62d
Author: Vlad Yasevich <vladislav.yasevich@hp.com>
Date:   Tue Apr 26 21:54:17 2011 +0000

    sctp: clean up route lookup calls
    
    Change the call to take the transport parameter and set the
    cached 'dst' appropriately inside the get_dst() function calls.
    
    This will allow us in the future  to clean up source address
    storage as well.
    
    Signed-off-by: Vlad Yasevich <vladislav.yasevich@hp.com>
    Signed-off-by: Wei Yongjun <yjwei@cn.fujitsu.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index 1fbb920f8dfb..d8595dd1a8a7 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -213,17 +213,17 @@ void sctp_transport_set_owner(struct sctp_transport *transport,
 /* Initialize the pmtu of a transport. */
 void sctp_transport_pmtu(struct sctp_transport *transport, struct sock *sk)
 {
-	struct dst_entry *dst;
 	struct flowi fl;
 
-	dst = transport->af_specific->get_dst(transport->asoc,
-					      &transport->ipaddr,
-					      &transport->saddr,
+	/* If we don't have a fresh route, look one up */
+	if (!transport->dst || transport->dst->obsolete > 1) {
+		dst_release(transport->dst);
+		transport->af_specific->get_dst(transport, &transport->saddr,
 					      &fl, sk);
+	}
 
-	if (dst) {
-		transport->pathmtu = dst_mtu(dst);
-		dst_release(dst);
+	if (transport->dst) {
+		transport->pathmtu = dst_mtu(transport->dst);
 	} else
 		transport->pathmtu = SCTP_DEFAULT_MAXSEGMENT;
 }
@@ -274,12 +274,9 @@ void sctp_transport_route(struct sctp_transport *transport,
 {
 	struct sctp_association *asoc = transport->asoc;
 	struct sctp_af *af = transport->af_specific;
-	union sctp_addr *daddr = &transport->ipaddr;
-	struct dst_entry *dst;
 	struct flowi fl;
 
-	dst = af->get_dst(asoc, daddr, saddr, &fl, sctp_opt2sk(opt));
-	transport->dst = dst;
+	af->get_dst(transport, saddr, &fl, sctp_opt2sk(opt));
 
 	if (saddr)
 		memcpy(&transport->saddr, saddr, sizeof(union sctp_addr));
@@ -289,8 +286,8 @@ void sctp_transport_route(struct sctp_transport *transport,
 	if ((transport->param_flags & SPP_PMTUD_DISABLE) && transport->pathmtu) {
 		return;
 	}
-	if (dst) {
-		transport->pathmtu = dst_mtu(dst);
+	if (transport->dst) {
+		transport->pathmtu = dst_mtu(transport->dst);
 
 		/* Initialize sk->sk_rcv_saddr, if the transport is the
 		 * association's active path for getsockname().

commit af1384703f8a4ff3d245925d6596ef1c5c6e469e
Author: Vlad Yasevich <vladislav.yasevich@hp.com>
Date:   Tue Apr 26 21:53:20 2011 +0000

    sctp: remove useless arguments from get_saddr() call
    
    There is no point in passing a destination address to
    a get_saddr() call.
    
    Signed-off-by: Vlad Yasevich <vladislav.yasevich@hp.com>
    Signed-off-by: Wei Yongjun <yjwei@cn.fujitsu.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index 2544b9b21f86..1fbb920f8dfb 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -284,7 +284,7 @@ void sctp_transport_route(struct sctp_transport *transport,
 	if (saddr)
 		memcpy(&transport->saddr, saddr, sizeof(union sctp_addr));
 	else
-		af->get_saddr(opt, transport, daddr, &fl);
+		af->get_saddr(opt, transport, &fl);
 
 	if ((transport->param_flags & SPP_PMTUD_DISABLE) && transport->pathmtu) {
 		return;

commit 9914ae3ca770389a3bec3114d0a07532a7f235dd
Author: Vlad Yasevich <vladislav.yasevich@hp.com>
Date:   Tue Apr 26 21:51:31 2011 +0000

    sctp: cache the ipv6 source after route lookup
    
    The ipv6 routing lookup does give us a source address,
    but instead of filling it into the dst, it's stored in
    the flowi.  We can use that instead of going through the
    entire source address selection again.
    Also the useless ->dst_saddr member of sctp_pf is removed.
    And sctp_v6_dst_saddr() is removed, instead by introduce
    sctp_v6_to_addr(), which can be reused to cleanup some dup
    code.
    
    Signed-off-by: Vlad Yasevich <vladislav.yasevich@hp.com>
    Signed-off-by: Wei Yongjun <yjwei@cn.fujitsu.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index d3ae493d234a..2544b9b21f86 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -211,11 +211,15 @@ void sctp_transport_set_owner(struct sctp_transport *transport,
 }
 
 /* Initialize the pmtu of a transport. */
-void sctp_transport_pmtu(struct sctp_transport *transport)
+void sctp_transport_pmtu(struct sctp_transport *transport, struct sock *sk)
 {
 	struct dst_entry *dst;
+	struct flowi fl;
 
-	dst = transport->af_specific->get_dst(NULL, &transport->ipaddr, NULL);
+	dst = transport->af_specific->get_dst(transport->asoc,
+					      &transport->ipaddr,
+					      &transport->saddr,
+					      &fl, sk);
 
 	if (dst) {
 		transport->pathmtu = dst_mtu(dst);
@@ -272,15 +276,16 @@ void sctp_transport_route(struct sctp_transport *transport,
 	struct sctp_af *af = transport->af_specific;
 	union sctp_addr *daddr = &transport->ipaddr;
 	struct dst_entry *dst;
+	struct flowi fl;
 
-	dst = af->get_dst(asoc, daddr, saddr);
+	dst = af->get_dst(asoc, daddr, saddr, &fl, sctp_opt2sk(opt));
+	transport->dst = dst;
 
 	if (saddr)
 		memcpy(&transport->saddr, saddr, sizeof(union sctp_addr));
 	else
-		af->get_saddr(opt, asoc, dst, daddr, &transport->saddr);
+		af->get_saddr(opt, transport, daddr, &fl);
 
-	transport->dst = dst;
 	if ((transport->param_flags & SPP_PMTUD_DISABLE) && transport->pathmtu) {
 		return;
 	}

commit 145ce502e44b57c074c72cfdc855557e19026999
Author: Joe Perches <joe@perches.com>
Date:   Tue Aug 24 13:21:08 2010 +0000

    net/sctp: Use pr_fmt and pr_<level>
    
    Change SCTP_DEBUG_PRINTK and SCTP_DEBUG_PRINTK_IPADDR to
    use do { print } while (0) guards.
    Add SCTP_DEBUG_PRINTK_CONT to fix errors in log when
    lines were continued.
    Add #define pr_fmt(fmt) KBUILD_MODNAME ": " fmt
    Add a missing newline in "Failed bind hash alloc"
    
    Signed-off-by: Joe Perches <joe@perches.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index 132046cb82fc..d3ae493d234a 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -48,6 +48,8 @@
  * be incorporated into the next SCTP release.
  */
 
+#define pr_fmt(fmt) KBUILD_MODNAME ": " fmt
+
 #include <linux/slab.h>
 #include <linux/types.h>
 #include <linux/random.h>
@@ -244,10 +246,9 @@ void sctp_transport_update_pmtu(struct sctp_transport *t, u32 pmtu)
 	struct dst_entry *dst;
 
 	if (unlikely(pmtu < SCTP_DEFAULT_MINSEGMENT)) {
-		printk(KERN_WARNING "%s: Reported pmtu %d too low, "
-		       "using default minimum of %d\n",
-		       __func__, pmtu,
-		       SCTP_DEFAULT_MINSEGMENT);
+		pr_warn("%s: Reported pmtu %d too low, using default minimum of %d\n",
+			__func__, pmtu,
+			SCTP_DEFAULT_MINSEGMENT);
 		/* Use default minimum segment size and disable
 		 * pmtu discovery on this transport.
 		 */

commit 6811d58fc148c393f80a9f5a9db49d7e75cdc546
Merge: c4949f074332 c02db8c6290b
Author: David S. Miller <davem@davemloft.net>
Date:   Sun May 16 22:26:58 2010 -0700

    Merge branch 'master' of master.kernel.org:/pub/scm/linux/kernel/git/davem/net-2.6
    
    Conflicts:
            include/linux/if_link.h

commit 55fa0cfd7c3ac2ae34cac7dca2e3fbcfe661e6c3
Author: Wei Yongjun <yjwei@cn.fujitsu.com>
Date:   Sun May 9 16:56:07 2010 +0000

    sctp: delete active ICMP proto unreachable timer when free transport
    
    transport may be free before ICMP proto unreachable timer expire, so
    we should delete active ICMP proto unreachable timer when transport
    is going away.
    
    Signed-off-by: Wei Yongjun <yjwei@cn.fujitsu.com>
    Acked-by: Vlad Yasevich <vladislav.yasevich@hp.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index 4a368038d46f..165d54e07fcd 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -173,6 +173,10 @@ void sctp_transport_free(struct sctp_transport *transport)
 	    del_timer(&transport->T3_rtx_timer))
 		sctp_transport_put(transport);
 
+	/* Delete the ICMP proto unreachable timer if it's active. */
+	if (timer_pending(&transport->proto_unreach_timer) &&
+	    del_timer(&transport->proto_unreach_timer))
+		sctp_association_put(transport->asoc);
 
 	sctp_transport_put(transport);
 }

commit 278554bd6579206921f5d8a523649a7a57f8850d
Merge: 5a147e8bf982 cea0d767c296
Author: David S. Miller <davem@davemloft.net>
Date:   Wed May 12 00:05:35 2010 -0700

    Merge branch 'master' of master.kernel.org:/pub/scm/linux/kernel/git/davem/net-2.6
    
    Conflicts:
            Documentation/feature-removal-schedule.txt
            drivers/net/wireless/ath/ar9170/usb.c
            drivers/scsi/iscsi_tcp.c
            net/ipv4/ipmr.c

commit 50b5d6ad63821cea324a5a7a19854d4de1a0a819
Author: Vlad Yasevich <vladislav.yasevich@hp.com>
Date:   Thu May 6 00:56:07 2010 -0700

    sctp: Fix a race between ICMP protocol unreachable and connect()
    
    ICMP protocol unreachable handling completely disregarded
    the fact that the user may have locked the socket.  It proceeded
    to destroy the association, even though the user may have
    held the lock and had a ref on the association.  This resulted
    in the following:
    
    Attempt to release alive inet socket f6afcc00
    
    =========================
    [ BUG: held lock freed! ]
    -------------------------
    somenu/2672 is freeing memory f6afcc00-f6afcfff, with a lock still held
    there!
     (sk_lock-AF_INET){+.+.+.}, at: [<c122098a>] sctp_connect+0x13/0x4c
    1 lock held by somenu/2672:
     #0:  (sk_lock-AF_INET){+.+.+.}, at: [<c122098a>] sctp_connect+0x13/0x4c
    
    stack backtrace:
    Pid: 2672, comm: somenu Not tainted 2.6.32-telco #55
    Call Trace:
     [<c1232266>] ? printk+0xf/0x11
     [<c1038553>] debug_check_no_locks_freed+0xce/0xff
     [<c10620b4>] kmem_cache_free+0x21/0x66
     [<c1185f25>] __sk_free+0x9d/0xab
     [<c1185f9c>] sk_free+0x1c/0x1e
     [<c1216e38>] sctp_association_put+0x32/0x89
     [<c1220865>] __sctp_connect+0x36d/0x3f4
     [<c122098a>] ? sctp_connect+0x13/0x4c
     [<c102d073>] ? autoremove_wake_function+0x0/0x33
     [<c12209a8>] sctp_connect+0x31/0x4c
     [<c11d1e80>] inet_dgram_connect+0x4b/0x55
     [<c11834fa>] sys_connect+0x54/0x71
     [<c103a3a2>] ? lock_release_non_nested+0x88/0x239
     [<c1054026>] ? might_fault+0x42/0x7c
     [<c1054026>] ? might_fault+0x42/0x7c
     [<c11847ab>] sys_socketcall+0x6d/0x178
     [<c10da994>] ? trace_hardirqs_on_thunk+0xc/0x10
     [<c1002959>] syscall_call+0x7/0xb
    
    This was because the sctp_wait_for_connect() would aqcure the socket
    lock and then proceed to release the last reference count on the
    association, thus cause the fully destruction path to finish freeing
    the socket.
    
    The simplest solution is to start a very short timer in case the socket
    is owned by user.  When the timer expires, we can do some verification
    and be able to do the release properly.
    
    Signed-off-by: Vlad Yasevich <vladislav.yasevich@hp.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index be4d63d5a5cc..4a368038d46f 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -108,6 +108,8 @@ static struct sctp_transport *sctp_transport_init(struct sctp_transport *peer,
 			(unsigned long)peer);
 	setup_timer(&peer->hb_timer, sctp_generate_heartbeat_event,
 			(unsigned long)peer);
+	setup_timer(&peer->proto_unreach_timer,
+		    sctp_generate_proto_unreach_event, (unsigned long)peer);
 
 	/* Initialize the 64-bit random nonce sent with heartbeat. */
 	get_random_bytes(&peer->hb_nonce, sizeof(peer->hb_nonce));

commit cf9b4812e18aab6f86ff998bd7425a9e823269c3
Author: Vlad Yasevich <vladislav.yasevich@hp.com>
Date:   Fri Apr 30 22:41:10 2010 -0400

    sctp: fast recovery algorithm is per association.
    
    SCTP fast recovery algorithm really applies per association
    and impacts all transports.
    
    Signed-off-by: Vlad Yasevich <vladislav.yasevich@hp.com>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index 854228bf3f34..fccf4947aff1 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -378,15 +378,16 @@ void sctp_transport_update_rto(struct sctp_transport *tp, __u32 rtt)
 void sctp_transport_raise_cwnd(struct sctp_transport *transport,
 			       __u32 sack_ctsn, __u32 bytes_acked)
 {
+	struct sctp_association *asoc = transport->asoc;
 	__u32 cwnd, ssthresh, flight_size, pba, pmtu;
 
 	cwnd = transport->cwnd;
 	flight_size = transport->flight_size;
 
 	/* See if we need to exit Fast Recovery first */
-	if (transport->fast_recovery &&
-	    TSN_lte(transport->fast_recovery_exit, sack_ctsn))
-		transport->fast_recovery = 0;
+	if (asoc->fast_recovery &&
+	    TSN_lte(asoc->fast_recovery_exit, sack_ctsn))
+		asoc->fast_recovery = 0;
 
 	/* The appropriate cwnd increase algorithm is performed if, and only
 	 * if the cumulative TSN whould advanced and the congestion window is
@@ -415,7 +416,7 @@ void sctp_transport_raise_cwnd(struct sctp_transport *transport,
 		 *    2) the destination's path MTU.  This upper bound protects
 		 *    against the ACK-Splitting attack outlined in [SAVAGE99].
 		 */
-		if (transport->fast_recovery)
+		if (asoc->fast_recovery)
 			return;
 
 		if (bytes_acked > pmtu)
@@ -466,6 +467,8 @@ void sctp_transport_raise_cwnd(struct sctp_transport *transport,
 void sctp_transport_lower_cwnd(struct sctp_transport *transport,
 			       sctp_lower_cwnd_t reason)
 {
+	struct sctp_association *asoc = transport->asoc;
+
 	switch (reason) {
 	case SCTP_LOWER_CWND_T3_RTX:
 		/* RFC 2960 Section 7.2.3, sctpimpguide
@@ -476,11 +479,11 @@ void sctp_transport_lower_cwnd(struct sctp_transport *transport,
 		 *      partial_bytes_acked = 0
 		 */
 		transport->ssthresh = max(transport->cwnd/2,
-					  4*transport->asoc->pathmtu);
-		transport->cwnd = transport->asoc->pathmtu;
+					  4*asoc->pathmtu);
+		transport->cwnd = asoc->pathmtu;
 
-		/* T3-rtx also clears fast recovery on the transport */
-		transport->fast_recovery = 0;
+		/* T3-rtx also clears fast recovery */
+		asoc->fast_recovery = 0;
 		break;
 
 	case SCTP_LOWER_CWND_FAST_RTX:
@@ -496,15 +499,15 @@ void sctp_transport_lower_cwnd(struct sctp_transport *transport,
 		 *      cwnd = ssthresh
 		 *      partial_bytes_acked = 0
 		 */
-		if (transport->fast_recovery)
+		if (asoc->fast_recovery)
 			return;
 
 		/* Mark Fast recovery */
-		transport->fast_recovery = 1;
-		transport->fast_recovery_exit = transport->asoc->next_tsn - 1;
+		asoc->fast_recovery = 1;
+		asoc->fast_recovery_exit = asoc->next_tsn - 1;
 
 		transport->ssthresh = max(transport->cwnd/2,
-					  4*transport->asoc->pathmtu);
+					  4*asoc->pathmtu);
 		transport->cwnd = transport->ssthresh;
 		break;
 
@@ -524,7 +527,7 @@ void sctp_transport_lower_cwnd(struct sctp_transport *transport,
 		if (time_after(jiffies, transport->last_time_ecne_reduced +
 					transport->rtt)) {
 			transport->ssthresh = max(transport->cwnd/2,
-						  4*transport->asoc->pathmtu);
+						  4*asoc->pathmtu);
 			transport->cwnd = transport->ssthresh;
 			transport->last_time_ecne_reduced = jiffies;
 		}
@@ -540,7 +543,7 @@ void sctp_transport_lower_cwnd(struct sctp_transport *transport,
 		 * interval.
 		 */
 		transport->cwnd = max(transport->cwnd/2,
-					 4*transport->asoc->pathmtu);
+					 4*asoc->pathmtu);
 		break;
 	}
 
@@ -625,7 +628,6 @@ void sctp_transport_reset(struct sctp_transport *t)
 	t->error_count = 0;
 	t->rto_pending = 0;
 	t->hb_sent = 0;
-	t->fast_recovery = 0;
 
 	/* Initialize the state information for SFR-CACC */
 	t->cacc.changeover_active = 0;

commit b2cf9b6bd93af1cc047d3356f1c6cc9367fe3731
Author: Vlad Yasevich <vladislav.yasevich@hp.com>
Date:   Fri Apr 30 22:41:10 2010 -0400

    sctp: update transport initializations
    
    Right now, sctp transports are not fully initialized and when
    adding any new fields, they have to be explicitely initialized.
    This is prone to mistakes.  So we switch to calling kzalloc()
    which makes things much simpler.
    
    Signed-off-by: Vlad Yasevich <vladislav.yasevich@hp.com>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index 0ebb97fc98e0..854228bf3f34 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -64,9 +64,6 @@ static struct sctp_transport *sctp_transport_init(struct sctp_transport *peer,
 	/* Copy in the address.  */
 	peer->ipaddr = *addr;
 	peer->af_specific = sctp_get_af_specific(addr->sa.sa_family);
-	peer->asoc = NULL;
-
-	peer->dst = NULL;
 	memset(&peer->saddr, 0, sizeof(union sctp_addr));
 
 	/* From 6.3.1 RTO Calculation:
@@ -76,34 +73,21 @@ static struct sctp_transport *sctp_transport_init(struct sctp_transport *peer,
 	 * parameter 'RTO.Initial'.
 	 */
 	peer->rto = msecs_to_jiffies(sctp_rto_initial);
-	peer->rtt = 0;
-	peer->rttvar = 0;
-	peer->srtt = 0;
-	peer->rto_pending = 0;
-	peer->hb_sent = 0;
-	peer->fast_recovery = 0;
 
 	peer->last_time_heard = jiffies;
 	peer->last_time_ecne_reduced = jiffies;
 
-	peer->init_sent_count = 0;
-
 	peer->param_flags = SPP_HB_DISABLE |
 			    SPP_PMTUD_ENABLE |
 			    SPP_SACKDELAY_ENABLE;
-	peer->hbinterval  = 0;
 
 	/* Initialize the default path max_retrans.  */
 	peer->pathmaxrxt  = sctp_max_retrans_path;
-	peer->error_count = 0;
 
 	INIT_LIST_HEAD(&peer->transmitted);
 	INIT_LIST_HEAD(&peer->send_ready);
 	INIT_LIST_HEAD(&peer->transports);
 
-	peer->T3_rtx_timer.expires = 0;
-	peer->hb_timer.expires = 0;
-
 	setup_timer(&peer->T3_rtx_timer, sctp_generate_t3_rtx_event,
 			(unsigned long)peer);
 	setup_timer(&peer->hb_timer, sctp_generate_heartbeat_event,
@@ -113,15 +97,6 @@ static struct sctp_transport *sctp_transport_init(struct sctp_transport *peer,
 	get_random_bytes(&peer->hb_nonce, sizeof(peer->hb_nonce));
 
 	atomic_set(&peer->refcnt, 1);
-	peer->dead = 0;
-
-	peer->malloced = 0;
-
-	/* Initialize the state information for SFR-CACC */
-	peer->cacc.changeover_active = 0;
-	peer->cacc.cycling_changeover = 0;
-	peer->cacc.next_tsn_at_change = 0;
-	peer->cacc.cacc_saw_newack = 0;
 
 	return peer;
 }

commit d9efc2231b28bc199f9de4dd594248b7341188e5
Author: Vlad Yasevich <vladislav.yasevich@hp.com>
Date:   Fri Apr 30 22:41:09 2010 -0400

    sctp: Do not force T3 timer on fast retransmissions.
    
    We don't need to force the T3 timer any more and it's
    actually wrong to do as it causes too long of a delay.
    The timer will be started if one is not running, but if
    one is running, we leave it alone.
    
    Signed-off-by: Vlad Yasevich <vladislav.yasevich@hp.com>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index be4d63d5a5cc..0ebb97fc98e0 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -195,7 +195,7 @@ static void sctp_transport_destroy(struct sctp_transport *transport)
 /* Start T3_rtx timer if it is not already running and update the heartbeat
  * timer.  This routine is called every time a DATA chunk is sent.
  */
-void sctp_transport_reset_timers(struct sctp_transport *transport, int force)
+void sctp_transport_reset_timers(struct sctp_transport *transport)
 {
 	/* RFC 2960 6.3.2 Retransmission Timer Rules
 	 *
@@ -205,7 +205,7 @@ void sctp_transport_reset_timers(struct sctp_transport *transport, int force)
 	 * address.
 	 */
 
-	if (force || !timer_pending(&transport->T3_rtx_timer))
+	if (!timer_pending(&transport->T3_rtx_timer))
 		if (!mod_timer(&transport->T3_rtx_timer,
 			       jiffies + transport->rto))
 			sctp_transport_hold(transport);

commit 5a0e3ad6af8660be21ca98a971cd00f331318c05
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Mar 24 17:04:11 2010 +0900

    include cleanup: Update gfp.h and slab.h includes to prepare for breaking implicit slab.h inclusion from percpu.h
    
    percpu.h is included by sched.h and module.h and thus ends up being
    included when building most .c files.  percpu.h includes slab.h which
    in turn includes gfp.h making everything defined by the two files
    universally available and complicating inclusion dependencies.
    
    percpu.h -> slab.h dependency is about to be removed.  Prepare for
    this change by updating users of gfp and slab facilities include those
    headers directly instead of assuming availability.  As this conversion
    needs to touch large number of source files, the following script is
    used as the basis of conversion.
    
      http://userweb.kernel.org/~tj/misc/slabh-sweep.py
    
    The script does the followings.
    
    * Scan files for gfp and slab usages and update includes such that
      only the necessary includes are there.  ie. if only gfp is used,
      gfp.h, if slab is used, slab.h.
    
    * When the script inserts a new include, it looks at the include
      blocks and try to put the new include such that its order conforms
      to its surrounding.  It's put in the include block which contains
      core kernel includes, in the same order that the rest are ordered -
      alphabetical, Christmas tree, rev-Xmas-tree or at the end if there
      doesn't seem to be any matching order.
    
    * If the script can't find a place to put a new include (mostly
      because the file doesn't have fitting include block), it prints out
      an error message indicating which .h file needs to be added to the
      file.
    
    The conversion was done in the following steps.
    
    1. The initial automatic conversion of all .c files updated slightly
       over 4000 files, deleting around 700 includes and adding ~480 gfp.h
       and ~3000 slab.h inclusions.  The script emitted errors for ~400
       files.
    
    2. Each error was manually checked.  Some didn't need the inclusion,
       some needed manual addition while adding it to implementation .h or
       embedding .c file was more appropriate for others.  This step added
       inclusions to around 150 files.
    
    3. The script was run again and the output was compared to the edits
       from #2 to make sure no file was left behind.
    
    4. Several build tests were done and a couple of problems were fixed.
       e.g. lib/decompress_*.c used malloc/free() wrappers around slab
       APIs requiring slab.h to be added manually.
    
    5. The script was run on all .h files but without automatically
       editing them as sprinkling gfp.h and slab.h inclusions around .h
       files could easily lead to inclusion dependency hell.  Most gfp.h
       inclusion directives were ignored as stuff from gfp.h was usually
       wildly available and often used in preprocessor macros.  Each
       slab.h inclusion directive was examined and added manually as
       necessary.
    
    6. percpu.h was updated not to include slab.h.
    
    7. Build test were done on the following configurations and failures
       were fixed.  CONFIG_GCOV_KERNEL was turned off for all tests (as my
       distributed build env didn't work with gcov compiles) and a few
       more options had to be turned off depending on archs to make things
       build (like ipr on powerpc/64 which failed due to missing writeq).
    
       * x86 and x86_64 UP and SMP allmodconfig and a custom test config.
       * powerpc and powerpc64 SMP allmodconfig
       * sparc and sparc64 SMP allmodconfig
       * ia64 SMP allmodconfig
       * s390 SMP allmodconfig
       * alpha SMP allmodconfig
       * um on x86_64 SMP allmodconfig
    
    8. percpu.h modifications were reverted so that it could be applied as
       a separate patch and serve as bisection point.
    
    Given the fact that I had only a couple of failures from tests on step
    6, I'm fairly confident about the coverage of this conversion patch.
    If there is a breakage, it's likely to be something in one of the arch
    headers which should be easily discoverable easily on most builds of
    the specific arch.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Guess-its-ok-by: Christoph Lameter <cl@linux-foundation.org>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Lee Schermerhorn <Lee.Schermerhorn@hp.com>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index b827d21dbe54..be4d63d5a5cc 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -48,6 +48,7 @@
  * be incorporated into the next SCTP release.
  */
 
+#include <linux/slab.h>
 #include <linux/types.h>
 #include <linux/random.h>
 #include <net/sctp/sctp.h>

commit 9b963e5d0e01461099a40117b05480f24b63381f
Merge: 3b8626ba01a8 5fdd4baef619
Author: David S. Miller <davem@davemloft.net>
Date:   Sun Nov 29 00:57:15 2009 -0800

    Merge branch 'master' of master.kernel.org:/pub/scm/linux/kernel/git/davem/net-2.6
    
    Conflicts:
            drivers/ieee802154/fakehard.c
            drivers/net/e1000e/ich8lan.c
            drivers/net/e1000e/phy.c
            drivers/net/netxen/netxen_nic_init.c
            drivers/net/wireless/ath/ath9k/main.c

commit 5fdd4baef6195a1f2960e901c8877e2105f832ca
Author: Andrei Pelinescu-Onciul <andrei@iptel.org>
Date:   Sun Nov 29 00:14:02 2009 -0800

    sctp: on T3_RTX retransmit all the in-flight chunks
    
    When retransmitting due to T3 timeout, retransmit all the
    in-flight chunks for the corresponding  transport/path, including
    chunks sent less then 1 rto ago.
    This is the correct behaviour according to rfc4960 section 6.3.3
    E3 and
    "Note: Any DATA chunks that were sent to the address for which the
     T3-rtx timer expired but did not fit in one MTU (rule E3 above)
     should be marked for retransmission and sent as soon as cwnd
     allows (normally, when a SACK arrives). ".
    
    This fixes problems when more then one path is present and the T3
    retransmission of the first chunk that timeouts stops the T3 timer
    for the initial active path, leaving all the other in-flight
    chunks waiting forever or until a new chunk is transmitted on the
    same path and timeouts (and this will happen only if the cwnd
    allows sending new chunks, but since cwnd was dropped to MTU by
    the timeout => it will wait until the first heartbeat).
    
    Example: 10 packets in flight, sent at 0.1 s intervals on the
    primary path. The primary path is down and the first packet
    timeouts. The first packet is retransmitted on another path, the
    T3 timer for the primary path is stopped and cwnd is set to MTU.
    All the other 9 in-flight packets will not be retransmitted
    (unless more new packets are sent on the primary path which depend
    on cwnd allowing it, and even in this case the 9 packets will be
    retransmitted only after a new packet timeouts which even in the
    best case would be more then RTO).
    
    This commit reverts d0ce92910bc04e107b2f3f2048f07e94f570035d and
    also removes the now unused transport->last_rto, introduced in
     b6157d8e03e1e780660a328f7183bcbfa4a93a19.
    
    p.s  The problem is not only when multiple paths are there.  It
    can happen in a single homed environment.  If the application
    stops sending data, it possible to have a hung association.
    
    Signed-off-by: Andrei Pelinescu-Onciul <andrei@iptel.org>
    Signed-off-by: Vlad Yasevich <vladislav.yasevich@hp.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index 3b141bb32faf..37a1184d789f 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -74,7 +74,7 @@ static struct sctp_transport *sctp_transport_init(struct sctp_transport *peer,
 	 * given destination transport address, set RTO to the protocol
 	 * parameter 'RTO.Initial'.
 	 */
-	peer->last_rto = peer->rto = msecs_to_jiffies(sctp_rto_initial);
+	peer->rto = msecs_to_jiffies(sctp_rto_initial);
 	peer->rtt = 0;
 	peer->rttvar = 0;
 	peer->srtt = 0;
@@ -386,7 +386,6 @@ void sctp_transport_update_rto(struct sctp_transport *tp, __u32 rtt)
 		tp->rto = tp->asoc->rto_max;
 
 	tp->rtt = rtt;
-	tp->last_rto = tp->rto;
 
 	/* Reset rto_pending so that a new RTT measurement is started when a
 	 * new data chunk is sent.
@@ -602,7 +601,7 @@ void sctp_transport_reset(struct sctp_transport *t)
 	 */
 	t->cwnd = min(4*asoc->pathmtu, max_t(__u32, 2*asoc->pathmtu, 4380));
 	t->ssthresh = asoc->peer.i.a_rwnd;
-	t->last_rto = t->rto = asoc->rto_initial;
+	t->rto = asoc->rto_initial;
 	t->rtt = 0;
 	t->srtt = 0;
 	t->rttvar = 0;

commit 46d5a808558181e03a4760d2188cc9879445738a
Author: Vlad Yasevich <vladislav.yasevich@hp.com>
Date:   Mon Nov 23 15:54:00 2009 -0500

    sctp: Update max.burst implementation
    
    Current implementation of max.burst ends up limiting new
    data during cwnd decay period.  The decay is happening becuase
    the connection is idle and we are allowed to fill the congestion
    window.  The point of max.burst is to limit micro-bursts in response
    to large acks.  This still happens, as max.burst is still applied
    to each transmit opportunity.  It will also apply if a very large
    send is made (greater then allowed by burst).
    
    Tested-by: Florian Niederbacher <florian.niederbacher@student.uibk.ac.at>
    Signed-off-by: Vlad Yasevich <vladislav.yasevich@hp.com>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index 2df29cbdaf5a..9a6cb22d129f 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -576,6 +576,43 @@ void sctp_transport_lower_cwnd(struct sctp_transport *transport,
 			  transport->cwnd, transport->ssthresh);
 }
 
+/* Apply Max.Burst limit to the congestion window:
+ * sctpimpguide-05 2.14.2
+ * D) When the time comes for the sender to
+ * transmit new DATA chunks, the protocol parameter Max.Burst MUST
+ * first be applied to limit how many new DATA chunks may be sent.
+ * The limit is applied by adjusting cwnd as follows:
+ * 	if ((flightsize+ Max.Burst * MTU) < cwnd)
+ * 		cwnd = flightsize + Max.Burst * MTU
+ */
+
+void sctp_transport_burst_limited(struct sctp_transport *t)
+{
+	struct sctp_association *asoc = t->asoc;
+	u32 old_cwnd = t->cwnd;
+	u32 max_burst_bytes;
+
+	if (t->burst_limited)
+		return;
+
+	max_burst_bytes = t->flight_size + (asoc->max_burst * asoc->pathmtu);
+	if (max_burst_bytes < old_cwnd) {
+		t->cwnd = max_burst_bytes;
+		t->burst_limited = old_cwnd;
+	}
+}
+
+/* Restore the old cwnd congestion window, after the burst had it's
+ * desired effect.
+ */
+void sctp_transport_burst_reset(struct sctp_transport *t)
+{
+	if (t->burst_limited) {
+		t->cwnd = t->burst_limited;
+		t->burst_limited = 0;
+	}
+}
+
 /* What is the next timeout value for this transport? */
 unsigned long sctp_transport_timeout(struct sctp_transport *t)
 {
@@ -598,6 +635,7 @@ void sctp_transport_reset(struct sctp_transport *t)
 	 * (see Section 6.2.1)
 	 */
 	t->cwnd = min(4*asoc->pathmtu, max_t(__u32, 2*asoc->pathmtu, 4380));
+	t->burst_limited = 0;
 	t->ssthresh = asoc->peer.i.a_rwnd;
 	t->last_rto = t->rto = asoc->rto_initial;
 	t->rtt = 0;

commit 245cba7e55929dc2b10b7d915bfba0168eeeed17
Author: Vlad Yasevich <vladislav.yasevich@hp.com>
Date:   Mon Nov 23 15:53:58 2009 -0500

    sctp: Remove useless last_time_used variable
    
    The transport last_time_used variable is rather useless.
    It was only used when determining if CWND needs to be updated
    due to idle transport.  However, idle transport detection was
    based on a Heartbeat timer and last_time_used was not incremented
    when sending Heartbeats.  As a result the check for cwnd reduction
    was always true.  We can get rid of the variable and just base
    our cwnd manipulation on the HB timer (like the code comment sais).
    We also have to call into the cwnd manipulation function regardless
    of whether HBs are enabled or not.  That way we will detect idle
    transports if the user has disabled Heartbeats.
    
    Signed-off-by: Vlad Yasevich <vladislav.yasevich@hp.com>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index 3b141bb32faf..2df29cbdaf5a 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -83,7 +83,6 @@ static struct sctp_transport *sctp_transport_init(struct sctp_transport *peer,
 	peer->fast_recovery = 0;
 
 	peer->last_time_heard = jiffies;
-	peer->last_time_used = jiffies;
 	peer->last_time_ecne_reduced = jiffies;
 
 	peer->init_sent_count = 0;
@@ -565,10 +564,8 @@ void sctp_transport_lower_cwnd(struct sctp_transport *transport,
 		 * to be done every RTO interval, we do it every hearbeat
 		 * interval.
 		 */
-		if (time_after(jiffies, transport->last_time_used +
-					transport->rto))
-			transport->cwnd = max(transport->cwnd/2,
-						 4*transport->asoc->pathmtu);
+		transport->cwnd = max(transport->cwnd/2,
+					 4*transport->asoc->pathmtu);
 		break;
 	}
 

commit a78102e74e782914039cd8a6939532649825a2e3
Author: Vlad Yasevich <vladislav.yasevich@hp.com>
Date:   Wed Nov 11 11:54:37 2009 +0000

    sctp: Set socket source address when additing first transport
    
    Recent commits
            sctp: Get rid of an extra routing lookup when adding a transport
    and
            sctp: Set source addresses on the association before adding transports
    
    changed when routes are added to the sctp transports.  As such,
    we didn't set the socket source address correctly when adding the first
    transport.  The first transport is always the primary/active one, so
    when adding it, set the socket source address.  This was causing
    regression failures in SCTP tests.
    
    Signed-off-by: Vlad Yasevich <vladislav.yasevich@hp.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index c256e4839316..3b141bb32faf 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -308,7 +308,8 @@ void sctp_transport_route(struct sctp_transport *transport,
 		/* Initialize sk->sk_rcv_saddr, if the transport is the
 		 * association's active path for getsockname().
 		 */
-		if (asoc && (transport == asoc->peer.active_path))
+		if (asoc && (!asoc->peer.primary_path ||
+				(transport == asoc->peer.active_path)))
 			opt->pf->af->to_sk_saddr(&transport->saddr,
 						 asoc->base.sk);
 	} else

commit 33ce828131ca6655b48bd2070dadd80f816dfe0d
Author: Vlad Yasevich <vladislav.yasevich@hp.com>
Date:   Fri Sep 4 18:20:58 2009 -0400

    sctp: Clear fast_recovery on the transport when T3 timer expires.
    
    If T3 timer expires, we are retransmitting data due to timeout any
    any fast recovery is null and void.  We can clear the fast recovery
    flag.
    
    Signed-off-by: Vlad Yasevich <vladislav.yasevich@hp.com>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index e5dde45c79d3..c256e4839316 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -503,6 +503,9 @@ void sctp_transport_lower_cwnd(struct sctp_transport *transport,
 		transport->ssthresh = max(transport->cwnd/2,
 					  4*transport->asoc->pathmtu);
 		transport->cwnd = transport->asoc->pathmtu;
+
+		/* T3-rtx also clears fast recovery on the transport */
+		transport->fast_recovery = 0;
 		break;
 
 	case SCTP_LOWER_CWND_FAST_RTX:

commit f61f6f82c90cbaa85270f26b89e3309a8c6e2e88
Author: Wei Yongjun <yjwei@cn.fujitsu.com>
Date:   Mon Mar 2 09:46:13 2009 +0000

    sctp: use time_before or time_after for comparing jiffies
    
    The functions time_before or time_after are more robust
    for comparing jiffies against other values.
    
    Signed-off-by: Wei Yongjun <yjwei@cn.fujitsu.com>
    Signed-off-by: Vlad Yasevich <vladislav.yasevich@hp.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index 5c29b14ee9af..e5dde45c79d3 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -543,8 +543,8 @@ void sctp_transport_lower_cwnd(struct sctp_transport *transport,
 		 * congestion indications more than once every window of
 		 * data (or more loosely more than once every round-trip time).
 		 */
-		if ((jiffies - transport->last_time_ecne_reduced) >
-		    transport->rtt) {
+		if (time_after(jiffies, transport->last_time_ecne_reduced +
+					transport->rtt)) {
 			transport->ssthresh = max(transport->cwnd/2,
 						  4*transport->asoc->pathmtu);
 			transport->cwnd = transport->ssthresh;
@@ -561,7 +561,8 @@ void sctp_transport_lower_cwnd(struct sctp_transport *transport,
 		 * to be done every RTO interval, we do it every hearbeat
 		 * interval.
 		 */
-		if ((jiffies - transport->last_time_used) > transport->rto)
+		if (time_after(jiffies, transport->last_time_used +
+					transport->rto))
 			transport->cwnd = max(transport->cwnd/2,
 						 4*transport->asoc->pathmtu);
 		break;

commit faee47cdbfe8d74a1573c2f81ea6dbb08d735be6
Author: Vlad Yasevich <vladislav.yasevich@hp.com>
Date:   Fri Feb 13 08:33:43 2009 +0000

    sctp: Fix the RTO-doubling on idle-link heartbeats
    
    SCTP incorrectly doubles rto ever time a Hearbeat chunk
    is generated.   However RFC 4960 states:
    
       On an idle destination address that is allowed to heartbeat, it is
       recommended that a HEARTBEAT chunk is sent once per RTO of that
       destination address plus the protocol parameter 'HB.interval', with
       jittering of +/- 50% of the RTO value, and exponential backoff of the
       RTO if the previous HEARTBEAT is unanswered.
    
    Essentially, of if the heartbean is unacknowledged, do we double the RTO.
    
    Signed-off-by: Vlad Yasevich <vladislav.yasevich@hp.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index e745c118f239..5c29b14ee9af 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -79,6 +79,7 @@ static struct sctp_transport *sctp_transport_init(struct sctp_transport *peer,
 	peer->rttvar = 0;
 	peer->srtt = 0;
 	peer->rto_pending = 0;
+	peer->hb_sent = 0;
 	peer->fast_recovery = 0;
 
 	peer->last_time_heard = jiffies;
@@ -608,6 +609,7 @@ void sctp_transport_reset(struct sctp_transport *t)
 	t->flight_size = 0;
 	t->error_count = 0;
 	t->rto_pending = 0;
+	t->hb_sent = 0;
 	t->fast_recovery = 0;
 
 	/* Initialize the state information for SFR-CACC */

commit 6d0ccbac688207ca0616ab5094932af4db4747b3
Author: Florian Westphal <fw@strlen.de>
Date:   Fri Jul 18 23:04:39 2008 -0700

    sctp: Prevent uninitialized memory access
    
    valgrind reports uninizialized memory accesses when running
    sctp inside the network simulation cradle simulator:
    
     Conditional jump or move depends on uninitialised value(s)
        at 0x570E34A: sctp_assoc_sync_pmtu (associola.c:1324)
        by 0x57427DA: sctp_packet_transmit (output.c:403)
        by 0x5710EFF: sctp_outq_flush (outqueue.c:824)
        by 0x5710B88: sctp_outq_uncork (outqueue.c:701)
        by 0x5745262: sctp_cmd_interpreter (sm_sideeffect.c:1548)
        by 0x57444B7: sctp_side_effects (sm_sideeffect.c:976)
        by 0x5744460: sctp_do_sm (sm_sideeffect.c:945)
        by 0x572157D: sctp_primitive_ASSOCIATE (primitive.c:94)
        by 0x5725C04: __sctp_connect (socket.c:1094)
        by 0x57297DC: sctp_connect (socket.c:3297)
    
     Conditional jump or move depends on uninitialised value(s)
        at 0x575D3A5: mod_timer (timer.c:630)
        by 0x5752B78: sctp_cmd_hb_timers_start (sm_sideeffect.c:555)
        by 0x5754133: sctp_cmd_interpreter (sm_sideeffect.c:1448)
        by 0x5753607: sctp_side_effects (sm_sideeffect.c:976)
        by 0x57535B0: sctp_do_sm (sm_sideeffect.c:945)
        by 0x571E9AE: sctp_endpoint_bh_rcv (endpointola.c:474)
        by 0x573347F: sctp_inq_push (inqueue.c:104)
        by 0x572EF93: sctp_rcv (input.c:256)
        by 0x5689623: ip_local_deliver_finish (ip_input.c:230)
        by 0x5689759: ip_local_deliver (ip_input.c:268)
        by 0x5689CAC: ip_rcv_finish (dst.h:246)
    
    #1 is due to "if (t->pmtu_pending)".
    8a4794914f9cf2681235ec2311e189fe307c28c7 "[SCTP] Flag a pmtu change request"
    suggests it should be initialized to 0.
    
    #2 is the heartbeat timer 'expires' value, which is uninizialised, but
    test by mod_timer().
    T3_rtx_timer seems to be affected by the same problem, so initialize it, too.
    
    Signed-off-by: Florian Westphal <fw@strlen.de>
    Signed-off-by: Vlad Yasevich <vladislav.yasevich@hp.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index 3f34f61221ec..e745c118f239 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -100,6 +100,9 @@ static struct sctp_transport *sctp_transport_init(struct sctp_transport *peer,
 	INIT_LIST_HEAD(&peer->send_ready);
 	INIT_LIST_HEAD(&peer->transports);
 
+	peer->T3_rtx_timer.expires = 0;
+	peer->hb_timer.expires = 0;
+
 	setup_timer(&peer->T3_rtx_timer, sctp_generate_t3_rtx_event,
 			(unsigned long)peer);
 	setup_timer(&peer->hb_timer, sctp_generate_heartbeat_event,

commit 62aeaff5ccd96462b7077046357a6d7886175a57
Author: Vlad Yasevich <vladislav.yasevich@hp.com>
Date:   Wed Jun 4 12:39:11 2008 -0700

    sctp: Start T3-RTX timer when fast retransmitting lowest TSN
    
    When we are trying to fast retransmit the lowest outstanding TSN, we
    need to restart the T3-RTX timer, so that subsequent timeouts will
    correctly tag all the packets necessary for retransmissions.
    
    Signed-off-by: Vlad Yasevich <vladislav.yasevich@hp.com>
    Tested-by: Wei Yongjun <yjwei@cn.fujitsu.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index 9647fb277221..3f34f61221ec 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -191,7 +191,7 @@ static void sctp_transport_destroy(struct sctp_transport *transport)
 /* Start T3_rtx timer if it is not already running and update the heartbeat
  * timer.  This routine is called every time a DATA chunk is sent.
  */
-void sctp_transport_reset_timers(struct sctp_transport *transport)
+void sctp_transport_reset_timers(struct sctp_transport *transport, int force)
 {
 	/* RFC 2960 6.3.2 Retransmission Timer Rules
 	 *
@@ -201,7 +201,7 @@ void sctp_transport_reset_timers(struct sctp_transport *transport)
 	 * address.
 	 */
 
-	if (!timer_pending(&transport->T3_rtx_timer))
+	if (force || !timer_pending(&transport->T3_rtx_timer))
 		if (!mod_timer(&transport->T3_rtx_timer,
 			       jiffies + transport->rto))
 			sctp_transport_hold(transport);

commit a6465234814efda9ed1dccdba852953f7508e827
Author: Vlad Yasevich <vladislav.yasevich@hp.com>
Date:   Wed Jun 4 12:38:43 2008 -0700

    sctp: Correctly implement Fast Recovery cwnd manipulations.
    
    Correctly keep track of Fast Recovery state and do not reduce
    congestion window multiple times during sucht state.
    
    Signed-off-by: Vlad Yasevich <vladislav.yasevich@hp.com>
    Tested-by: Wei Yongjun <yjwei@cn.fujitsu.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index 62082e7b7972..9647fb277221 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -79,6 +79,7 @@ static struct sctp_transport *sctp_transport_init(struct sctp_transport *peer,
 	peer->rttvar = 0;
 	peer->srtt = 0;
 	peer->rto_pending = 0;
+	peer->fast_recovery = 0;
 
 	peer->last_time_heard = jiffies;
 	peer->last_time_used = jiffies;
@@ -403,11 +404,16 @@ void sctp_transport_raise_cwnd(struct sctp_transport *transport,
 	cwnd = transport->cwnd;
 	flight_size = transport->flight_size;
 
+	/* See if we need to exit Fast Recovery first */
+	if (transport->fast_recovery &&
+	    TSN_lte(transport->fast_recovery_exit, sack_ctsn))
+		transport->fast_recovery = 0;
+
 	/* The appropriate cwnd increase algorithm is performed if, and only
-	 * if the cumulative TSN has advanced and the congestion window is
+	 * if the cumulative TSN whould advanced and the congestion window is
 	 * being fully utilized.
 	 */
-	if ((transport->asoc->ctsn_ack_point >= sack_ctsn) ||
+	if (TSN_lte(sack_ctsn, transport->asoc->ctsn_ack_point) ||
 	    (flight_size < cwnd))
 		return;
 
@@ -416,17 +422,23 @@ void sctp_transport_raise_cwnd(struct sctp_transport *transport,
 	pmtu = transport->asoc->pathmtu;
 
 	if (cwnd <= ssthresh) {
-		/* RFC 2960 7.2.1, sctpimpguide-05 2.14.2 When cwnd is less
-		 * than or equal to ssthresh an SCTP endpoint MUST use the
-		 * slow start algorithm to increase cwnd only if the current
-		 * congestion window is being fully utilized and an incoming
-		 * SACK advances the Cumulative TSN Ack Point. Only when these
-		 * two conditions are met can the cwnd be increased otherwise
-		 * the cwnd MUST not be increased. If these conditions are met
-		 * then cwnd MUST be increased by at most the lesser of
-		 * 1) the total size of the previously outstanding DATA
-		 * chunk(s) acknowledged, and 2) the destination's path MTU.
+		/* RFC 4960 7.2.1
+		 * o  When cwnd is less than or equal to ssthresh, an SCTP
+		 *    endpoint MUST use the slow-start algorithm to increase
+		 *    cwnd only if the current congestion window is being fully
+		 *    utilized, an incoming SACK advances the Cumulative TSN
+		 *    Ack Point, and the data sender is not in Fast Recovery.
+		 *    Only when these three conditions are met can the cwnd be
+		 *    increased; otherwise, the cwnd MUST not be increased.
+		 *    If these conditions are met, then cwnd MUST be increased
+		 *    by, at most, the lesser of 1) the total size of the
+		 *    previously outstanding DATA chunk(s) acknowledged, and
+		 *    2) the destination's path MTU.  This upper bound protects
+		 *    against the ACK-Splitting attack outlined in [SAVAGE99].
 		 */
+		if (transport->fast_recovery)
+			return;
+
 		if (bytes_acked > pmtu)
 			cwnd += pmtu;
 		else
@@ -502,6 +514,13 @@ void sctp_transport_lower_cwnd(struct sctp_transport *transport,
 		 *      cwnd = ssthresh
 		 *      partial_bytes_acked = 0
 		 */
+		if (transport->fast_recovery)
+			return;
+
+		/* Mark Fast recovery */
+		transport->fast_recovery = 1;
+		transport->fast_recovery_exit = transport->asoc->next_tsn - 1;
+
 		transport->ssthresh = max(transport->cwnd/2,
 					  4*transport->asoc->pathmtu);
 		transport->cwnd = transport->ssthresh;
@@ -586,6 +605,7 @@ void sctp_transport_reset(struct sctp_transport *t)
 	t->flight_size = 0;
 	t->error_count = 0;
 	t->rto_pending = 0;
+	t->fast_recovery = 0;
 
 	/* Initialize the state information for SFR-CACC */
 	t->cacc.changeover_active = 0;

commit e51171019bb0e1f9fb57c25bd2e38ce652eaea27
Author: YOSHIFUJI Hideaki <yoshfuji@linux-ipv6.org>
Date:   Thu May 29 19:55:05 2008 +0900

    [SCTP]: Fix NULL dereference of asoc.
    
    Commit 7cbca67c073263c179f605bdbbdc565ab29d801d ("[IPV6]: Support
    Source Address Selection API (RFC5014)") introduced NULL dereference
    of asoc to sctp_v6_get_saddr in net/sctp/ipv6.c.
    Pointed out by Johann Felix Soden <johfel@users.sourceforge.net>.
    
    Signed-off-by: YOSHIFUJI Hideaki <yoshfuji@linux-ipv6.org>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index f4938f6c5abe..62082e7b7972 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -291,7 +291,7 @@ void sctp_transport_route(struct sctp_transport *transport,
 	if (saddr)
 		memcpy(&transport->saddr, saddr, sizeof(union sctp_addr));
 	else
-		af->get_saddr(asoc, dst, daddr, &transport->saddr);
+		af->get_saddr(opt, asoc, dst, daddr, &transport->saddr);
 
 	transport->dst = dst;
 	if ((transport->param_flags & SPP_PMTUD_DISABLE) && transport->pathmtu) {

commit 0dc47877a3de00ceadea0005189656ae8dc52669
Author: Harvey Harrison <harvey.harrison@gmail.com>
Date:   Wed Mar 5 20:47:47 2008 -0800

    net: replace remaining __FUNCTION__ occurrences
    
    __FUNCTION__ is gcc-specific, use __func__
    
    Signed-off-by: Harvey Harrison <harvey.harrison@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index d9f8af852b56..f4938f6c5abe 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -260,7 +260,7 @@ void sctp_transport_update_pmtu(struct sctp_transport *t, u32 pmtu)
 	if (unlikely(pmtu < SCTP_DEFAULT_MINSEGMENT)) {
 		printk(KERN_WARNING "%s: Reported pmtu %d too low, "
 		       "using default minimum of %d\n",
-		       __FUNCTION__, pmtu,
+		       __func__, pmtu,
 		       SCTP_DEFAULT_MINSEGMENT);
 		/* Use default minimum segment size and disable
 		 * pmtu discovery on this transport.
@@ -388,7 +388,7 @@ void sctp_transport_update_rto(struct sctp_transport *tp, __u32 rtt)
 	tp->rto_pending = 0;
 
 	SCTP_DEBUG_PRINTK("%s: transport: %p, rtt: %d, srtt: %d "
-			  "rttvar: %d, rto: %ld\n", __FUNCTION__,
+			  "rttvar: %d, rto: %ld\n", __func__,
 			  tp, rtt, tp->srtt, tp->rttvar, tp->rto);
 }
 
@@ -434,7 +434,7 @@ void sctp_transport_raise_cwnd(struct sctp_transport *transport,
 		SCTP_DEBUG_PRINTK("%s: SLOW START: transport: %p, "
 				  "bytes_acked: %d, cwnd: %d, ssthresh: %d, "
 				  "flight_size: %d, pba: %d\n",
-				  __FUNCTION__,
+				  __func__,
 				  transport, bytes_acked, cwnd,
 				  ssthresh, flight_size, pba);
 	} else {
@@ -460,7 +460,7 @@ void sctp_transport_raise_cwnd(struct sctp_transport *transport,
 		SCTP_DEBUG_PRINTK("%s: CONGESTION AVOIDANCE: "
 				  "transport: %p, bytes_acked: %d, cwnd: %d, "
 				  "ssthresh: %d, flight_size: %d, pba: %d\n",
-				  __FUNCTION__,
+				  __func__,
 				  transport, bytes_acked, cwnd,
 				  ssthresh, flight_size, pba);
 	}
@@ -546,7 +546,7 @@ void sctp_transport_lower_cwnd(struct sctp_transport *transport,
 
 	transport->partial_bytes_acked = 0;
 	SCTP_DEBUG_PRINTK("%s: transport: %p reason: %d cwnd: "
-			  "%d ssthresh: %d\n", __FUNCTION__,
+			  "%d ssthresh: %d\n", __func__,
 			  transport, reason,
 			  transport->cwnd, transport->ssthresh);
 }

commit 60c778b25972e095df8981dd41e99d161e8738f9
Author: Vlad Yasevich <vladislav.yasevich@hp.com>
Date:   Fri Jan 11 09:57:09 2008 -0500

    [SCTP]: Stop claiming that this is a "reference implementation"
    
    I was notified by Randy Stewart that lksctp claims to be
    "the reference implementation".  First of all, "the
    refrence implementation" was the original implementation
    of SCTP in usersapce written ty Randy and a few others.
    Second, after looking at the definiton of 'reference implementation',
    we don't really meet the requirements.
    
    Signed-off-by: Vlad Yasevich <vladislav.yasevich@hp.com>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index dfa109341aeb..d9f8af852b56 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -1,23 +1,23 @@
-/* SCTP kernel reference Implementation
+/* SCTP kernel implementation
  * Copyright (c) 1999-2000 Cisco, Inc.
  * Copyright (c) 1999-2001 Motorola, Inc.
  * Copyright (c) 2001-2003 International Business Machines Corp.
  * Copyright (c) 2001 Intel Corp.
  * Copyright (c) 2001 La Monte H.P. Yarroll
  *
- * This file is part of the SCTP kernel reference Implementation
+ * This file is part of the SCTP kernel implementation
  *
  * This module provides the abstraction for an SCTP tranport representing
  * a remote transport address.  For local transport addresses, we just use
  * union sctp_addr.
  *
- * The SCTP reference implementation is free software;
+ * This SCTP implementation is free software;
  * you can redistribute it and/or modify it under the terms of
  * the GNU General Public License as published by
  * the Free Software Foundation; either version 2, or (at your option)
  * any later version.
  *
- * The SCTP reference implementation is distributed in the hope that it
+ * This SCTP implementation is distributed in the hope that it
  * will be useful, but WITHOUT ANY WARRANTY; without even the implied
  *                 ************************
  * warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.

commit b24b8a247ff65c01b252025926fe564209fae4fc
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Wed Jan 23 21:20:07 2008 -0800

    [NET]: Convert init_timer into setup_timer
    
    Many-many code in the kernel initialized the timer->function
    and  timer->data together with calling init_timer(timer). There
    is already a helper for this. Use it for networking code.
    
    The patch is HUGE, but makes the code 130 lines shorter
    (98 insertions(+), 228 deletions(-)).
    
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Acked-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index d55ce83a020b..dfa109341aeb 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -99,15 +99,10 @@ static struct sctp_transport *sctp_transport_init(struct sctp_transport *peer,
 	INIT_LIST_HEAD(&peer->send_ready);
 	INIT_LIST_HEAD(&peer->transports);
 
-	/* Set up the retransmission timer.  */
-	init_timer(&peer->T3_rtx_timer);
-	peer->T3_rtx_timer.function = sctp_generate_t3_rtx_event;
-	peer->T3_rtx_timer.data = (unsigned long)peer;
-
-	/* Set up the heartbeat timer. */
-	init_timer(&peer->hb_timer);
-	peer->hb_timer.function = sctp_generate_heartbeat_event;
-	peer->hb_timer.data = (unsigned long)peer;
+	setup_timer(&peer->T3_rtx_timer, sctp_generate_t3_rtx_event,
+			(unsigned long)peer);
+	setup_timer(&peer->hb_timer, sctp_generate_heartbeat_event,
+			(unsigned long)peer);
 
 	/* Initialize the 64-bit random nonce sent with heartbeat. */
 	get_random_bytes(&peer->hb_nonce, sizeof(peer->hb_nonce));

commit b6157d8e03e1e780660a328f7183bcbfa4a93a19
Author: Vlad Yasevich <vladislav.yasevich@hp.com>
Date:   Wed Oct 24 15:59:16 2007 -0400

    SCTP: Fix difference cases of retransmit.
    
    Commit d0ce92910bc04e107b2f3f2048f07e94f570035d broke several retransmit
    cases including fast retransmit.  The reason is that we should
    only delay by rto while doing retranmists as a result of a timeout.
    Retransmit as a result of path mtu discover, fast retransmit, or
    other evernts that should trigger immidiate retransmissions got broken.
    
    Also, since rto is doubled prior to marking of packets elegable for
    retransmission, we never marked correct chunks anyway.
    
    The fix is provide a reason for a given retransmission so that we
    can mark chunks appropriately and to save the old rto value to do
    comparisons against.
    
    All regressions tests passed with this code.
    
    Spotted by Wei Yongjun <yjwei@cn.fujitsu.com>
    
    Signed-off-by: Vlad Yasevich <vladislav.yasevich@hp.com>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index 5f467c914f80..d55ce83a020b 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -74,8 +74,8 @@ static struct sctp_transport *sctp_transport_init(struct sctp_transport *peer,
 	 * given destination transport address, set RTO to the protocol
 	 * parameter 'RTO.Initial'.
 	 */
+	peer->last_rto = peer->rto = msecs_to_jiffies(sctp_rto_initial);
 	peer->rtt = 0;
-	peer->rto = msecs_to_jiffies(sctp_rto_initial);
 	peer->rttvar = 0;
 	peer->srtt = 0;
 	peer->rto_pending = 0;
@@ -385,6 +385,7 @@ void sctp_transport_update_rto(struct sctp_transport *tp, __u32 rtt)
 		tp->rto = tp->asoc->rto_max;
 
 	tp->rtt = rtt;
+	tp->last_rto = tp->rto;
 
 	/* Reset rto_pending so that a new RTT measurement is started when a
 	 * new data chunk is sent.
@@ -578,7 +579,7 @@ void sctp_transport_reset(struct sctp_transport *t)
 	 */
 	t->cwnd = min(4*asoc->pathmtu, max_t(__u32, 2*asoc->pathmtu, 4380));
 	t->ssthresh = asoc->peer.i.a_rwnd;
-	t->rto = asoc->rto_initial;
+	t->last_rto = t->rto = asoc->rto_initial;
 	t->rtt = 0;
 	t->srtt = 0;
 	t->rttvar = 0;

commit 06ad391919b2078ec2e012f0593014b88e7a6c4e
Author: Vlad Yasevich <vladislav.yasevich@hp.com>
Date:   Tue Jun 12 15:26:22 2007 -0400

    [SCTP] Don't disable PMTU discovery when mtu is small
    
    Right now, when we receive a mtu estimate smaller then minim
    threshold in the ICMP message, we disable the path mtu discovery
    on the transport.  This leads to the never increasing sctp fragmentation
    point even when the real path mtu has increased.
    
    Signed-off-by: Vlad Yasevich <vladislav.yasevich@hp.com>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index e14c271cf28b..5f467c914f80 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -271,8 +271,6 @@ void sctp_transport_update_pmtu(struct sctp_transport *t, u32 pmtu)
 		 * pmtu discovery on this transport.
 		 */
 		t->pathmtu = SCTP_DEFAULT_MINSEGMENT;
-		t->param_flags = (t->param_flags & ~SPP_PMTUD) |
-			SPP_PMTUD_DISABLE;
 	} else {
 		t->pathmtu = pmtu;
 	}

commit c910b47e1811b3f8b184108c48de3d7af3e2999b
Author: Vlad Yasevich <vladislav.yasevich@hp.com>
Date:   Thu Jun 7 13:47:03 2007 -0400

    [SCTP] Update pmtu handling to be similar to tcp
    
    Introduce new function sctp_transport_update_pmtu that updates
    the transports and destination caches view of the path mtu.
    
    Signed-off-by: Vlad Yasevich <vladislav.yasevich@hp.com>
    Acked-by: Sridhar Samudrala <sri@us.ibm.com>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index 961df275d5b9..e14c271cf28b 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -241,6 +241,47 @@ void sctp_transport_pmtu(struct sctp_transport *transport)
 		transport->pathmtu = SCTP_DEFAULT_MAXSEGMENT;
 }
 
+/* this is a complete rip-off from __sk_dst_check
+ * the cookie is always 0 since this is how it's used in the
+ * pmtu code
+ */
+static struct dst_entry *sctp_transport_dst_check(struct sctp_transport *t)
+{
+	struct dst_entry *dst = t->dst;
+
+	if (dst && dst->obsolete && dst->ops->check(dst, 0) == NULL) {
+		dst_release(t->dst);
+		t->dst = NULL;
+		return NULL;
+	}
+
+	return dst;
+}
+
+void sctp_transport_update_pmtu(struct sctp_transport *t, u32 pmtu)
+{
+	struct dst_entry *dst;
+
+	if (unlikely(pmtu < SCTP_DEFAULT_MINSEGMENT)) {
+		printk(KERN_WARNING "%s: Reported pmtu %d too low, "
+		       "using default minimum of %d\n",
+		       __FUNCTION__, pmtu,
+		       SCTP_DEFAULT_MINSEGMENT);
+		/* Use default minimum segment size and disable
+		 * pmtu discovery on this transport.
+		 */
+		t->pathmtu = SCTP_DEFAULT_MINSEGMENT;
+		t->param_flags = (t->param_flags & ~SPP_PMTUD) |
+			SPP_PMTUD_DISABLE;
+	} else {
+		t->pathmtu = pmtu;
+	}
+
+	dst = sctp_transport_dst_check(t);
+	if (dst)
+		dst->ops->update_pmtu(dst, pmtu);
+}
+
 /* Caches the dst entry and source address for a transport's destination
  * address.
  */

commit 3ff50b7997fe06cd5d276b229967bb52d6b3b6c1
Author: Stephen Hemminger <shemminger@linux-foundation.org>
Date:   Fri Apr 20 17:09:22 2007 -0700

    [NET]: cleanup extra semicolons
    
    Spring cleaning time...
    
    There seems to be a lot of places in the network code that have
    extra bogus semicolons after conditionals.  Most commonly is a
    bogus semicolon after: switch() { }
    
    Signed-off-by: Stephen Hemminger <shemminger@linux-foundation.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index 4d8c2ab864fc..961df275d5b9 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -507,7 +507,7 @@ void sctp_transport_lower_cwnd(struct sctp_transport *transport,
 			transport->cwnd = max(transport->cwnd/2,
 						 4*transport->asoc->pathmtu);
 		break;
-	};
+	}
 
 	transport->partial_bytes_acked = 0;
 	SCTP_DEBUG_PRINTK("%s: transport: %p reason: %d cwnd: "

commit 289f42492c0958871b6045050474c752ec99704f
Author: Vlad Yasevich <vladislav.yasevich@hp.com>
Date:   Thu Mar 22 12:26:25 2007 -0700

    [SCTP]: Correctly reset ssthresh when restarting association
    
    Reset ssthresh to the correct value (peer's a_rwnd) when restarting
    association.
    
    Signed-off-by: Vlad Yasevich <vladislav.yasevich@hp.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index c4699f5c409d..4d8c2ab864fc 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -538,7 +538,7 @@ void sctp_transport_reset(struct sctp_transport *t)
 	 * (see Section 6.2.1)
 	 */
 	t->cwnd = min(4*asoc->pathmtu, max_t(__u32, 2*asoc->pathmtu, 4380));
-	t->ssthresh = SCTP_DEFAULT_MAXWINDOW;
+	t->ssthresh = asoc->peer.i.a_rwnd;
 	t->rto = asoc->rto_initial;
 	t->rtt = 0;
 	t->srtt = 0;

commit 749bf9215ed1a8b6edb4bb03693c2b62c6b9c2a4
Author: Vlad Yasevich <vladislav.yasevich@hp.com>
Date:   Mon Mar 19 17:02:30 2007 -0700

    [SCTP]: Reset some transport and association variables on restart
    
    If the association has been restarted, we need to reset the
    transport congestion variables as well as accumulated error
    counts and CACC variables.  If we do not, the association
    will use the wrong values and may terminate prematurely.
    
    This was found with a scenario where the peer restarted
    the association when lksctp was in the last HB timeout for
    its association.  The restart happened, but the error counts
    have not been reset and when the timeout occurred, a newly
    restarted association was terminated due to excessive
    retransmits.
    
    Signed-off-by: Vlad Yasevich <vladislav.yasevich@hp.com>
    Signed-off-by: Sridhar Samudrala <sri@us.ibm.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index a596f5308cb1..c4699f5c409d 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -526,3 +526,35 @@ unsigned long sctp_transport_timeout(struct sctp_transport *t)
 	timeout += jiffies;
 	return timeout;
 }
+
+/* Reset transport variables to their initial values */
+void sctp_transport_reset(struct sctp_transport *t)
+{
+	struct sctp_association *asoc = t->asoc;
+
+	/* RFC 2960 (bis), Section 5.2.4
+	 * All the congestion control parameters (e.g., cwnd, ssthresh)
+	 * related to this peer MUST be reset to their initial values
+	 * (see Section 6.2.1)
+	 */
+	t->cwnd = min(4*asoc->pathmtu, max_t(__u32, 2*asoc->pathmtu, 4380));
+	t->ssthresh = SCTP_DEFAULT_MAXWINDOW;
+	t->rto = asoc->rto_initial;
+	t->rtt = 0;
+	t->srtt = 0;
+	t->rttvar = 0;
+
+	/* Reset these additional varibles so that we have a clean
+	 * slate.
+	 */
+	t->partial_bytes_acked = 0;
+	t->flight_size = 0;
+	t->error_count = 0;
+	t->rto_pending = 0;
+
+	/* Initialize the state information for SFR-CACC */
+	t->cacc.changeover_active = 0;
+	t->cacc.cycling_changeover = 0;
+	t->cacc.next_tsn_at_change = 0;
+	t->cacc.cacc_saw_newack = 0;
+}

commit d808ad9ab8b1109239027c248c4652503b9d3029
Author: YOSHIFUJI Hideaki <yoshfuji@linux-ipv6.org>
Date:   Fri Feb 9 23:25:18 2007 +0900

    [NET] SCTP: Fix whitespace errors.
    
    Signed-off-by: YOSHIFUJI Hideaki <yoshfuji@linux-ipv6.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index 3e5936a5f671..a596f5308cb1 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -130,9 +130,9 @@ static struct sctp_transport *sctp_transport_init(struct sctp_transport *peer,
 struct sctp_transport *sctp_transport_new(const union sctp_addr *addr,
 					  gfp_t gfp)
 {
-        struct sctp_transport *transport;
+	struct sctp_transport *transport;
 
-        transport = t_new(struct sctp_transport, gfp);
+	transport = t_new(struct sctp_transport, gfp);
 	if (!transport)
 		goto fail;
 
@@ -185,7 +185,7 @@ static void sctp_transport_destroy(struct sctp_transport *transport)
 	if (transport->asoc)
 		sctp_association_put(transport->asoc);
 
-        sctp_packet_free(&transport->packet);
+	sctp_packet_free(&transport->packet);
 
 	dst_release(transport->dst);
 	kfree(transport);
@@ -268,7 +268,7 @@ void sctp_transport_route(struct sctp_transport *transport,
 
 		/* Initialize sk->sk_rcv_saddr, if the transport is the
 		 * association's active path for getsockname().
-		 */ 
+		 */
 		if (asoc && (transport == asoc->peer.active_path))
 			opt->pf->af->to_sk_saddr(&transport->saddr,
 						 asoc->base.sk);
@@ -459,8 +459,8 @@ void sctp_transport_lower_cwnd(struct sctp_transport *transport,
 		 * destination address(es) to which the missing DATA chunks
 		 * were last sent, according to the formula described in
 		 * Section 7.2.3.
-	 	 *
-	 	 * RFC 2960 7.2.3, sctpimpguide Upon detection of packet
+		 *
+		 * RFC 2960 7.2.3, sctpimpguide Upon detection of packet
 		 * losses from SACK (see Section 7.2.4), An endpoint
 		 * should do the following:
 		 *      ssthresh = max(cwnd/2, 4*MTU)
@@ -488,7 +488,7 @@ void sctp_transport_lower_cwnd(struct sctp_transport *transport,
 		if ((jiffies - transport->last_time_ecne_reduced) >
 		    transport->rtt) {
 			transport->ssthresh = max(transport->cwnd/2,
-					  	  4*transport->asoc->pathmtu);
+						  4*transport->asoc->pathmtu);
 			transport->cwnd = transport->ssthresh;
 			transport->last_time_ecne_reduced = jiffies;
 		}

commit 3fd091e73b81f131e1567c4d4a1ec042940bf2f7
Author: Vladislav Yasevich <vladislav.yasevich@hp.com>
Date:   Tue Aug 22 13:29:17 2006 -0700

    [SCTP]: Remove multiple levels of msecs to jiffies conversions.
    
    The SCTP sysctl entries are displayed in milliseconds, but stored
    internally in jiffies. This results in multiple levels of msecs to
    jiffies conversion and as a result produces a truncation error. This
    patch makes things consistent in that we store and display defaults
    in milliseconds and only convert once for use by association.
    This patch also adds some sane min/max values so that we don't go off
    the deep end.
    
    Signed-off-by: Vladislav Yasevich <vladislav.yasevich@hp.com>
    Signed-off-by: Sridhar Samudrala <sri@us.ibm.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index 2763aa93de1a..3e5936a5f671 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -75,7 +75,7 @@ static struct sctp_transport *sctp_transport_init(struct sctp_transport *peer,
 	 * parameter 'RTO.Initial'.
 	 */
 	peer->rtt = 0;
-	peer->rto = sctp_rto_initial;
+	peer->rto = msecs_to_jiffies(sctp_rto_initial);
 	peer->rttvar = 0;
 	peer->srtt = 0;
 	peer->rto_pending = 0;

commit ad8fec1720e000ba2384de6408076a60fc92a981
Author: Sridhar Samudrala <sri@us.ibm.com>
Date:   Fri Jul 21 14:48:50 2006 -0700

    [SCTP]: Verify all the paths to a peer via heartbeat before using them.
    
    This patch implements Path Initialization procedure as described in
    Sec 2.36 of RFC4460.
    
    Signed-off-by: Sridhar Samudrala <sri@us.ibm.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index 160f62ad1cc5..2763aa93de1a 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -49,6 +49,7 @@
  */
 
 #include <linux/types.h>
+#include <linux/random.h>
 #include <net/sctp/sctp.h>
 #include <net/sctp/sm.h>
 
@@ -85,7 +86,6 @@ static struct sctp_transport *sctp_transport_init(struct sctp_transport *peer,
 
 	peer->init_sent_count = 0;
 
-	peer->state = SCTP_ACTIVE;
 	peer->param_flags = SPP_HB_DISABLE |
 			    SPP_PMTUD_ENABLE |
 			    SPP_SACKDELAY_ENABLE;
@@ -109,6 +109,9 @@ static struct sctp_transport *sctp_transport_init(struct sctp_transport *peer,
 	peer->hb_timer.function = sctp_generate_heartbeat_event;
 	peer->hb_timer.data = (unsigned long)peer;
 
+	/* Initialize the 64-bit random nonce sent with heartbeat. */
+	get_random_bytes(&peer->hb_nonce, sizeof(peer->hb_nonce));
+
 	atomic_set(&peer->refcnt, 1);
 	peer->dead = 0;
 
@@ -517,7 +520,9 @@ void sctp_transport_lower_cwnd(struct sctp_transport *transport,
 unsigned long sctp_transport_timeout(struct sctp_transport *t)
 {
 	unsigned long timeout;
-	timeout = t->hbinterval + t->rto + sctp_jitter(t->rto);
+	timeout = t->rto + sctp_jitter(t->rto);
+	if (t->state != SCTP_UNCONFIRMED)
+		timeout += t->hbinterval;
 	timeout += jiffies;
 	return timeout;
 }

commit 8116ffad4180b39d7a755345c1fde09da83930c0
Author: Vlad Yasevich <vladislav.yasevich@hp.com>
Date:   Tue Jan 17 11:55:17 2006 -0800

    [SCTP]: Fix bad sysctl formatting of SCTP timeout values on 64-bit m/cs.
    
    Change all the structure members that hold jiffies to be of type
    unsigned long.  This also corrects bad sysctl formating on 64 bit
    architectures.
    
    Signed-off-by: Vlad Yasevich <vladislav.yasevich@hp.com>
    Signed-off-by: Sridhar Samudrala <sri@us.ibm.com>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index 68d73e2dd155..160f62ad1cc5 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -350,7 +350,7 @@ void sctp_transport_update_rto(struct sctp_transport *tp, __u32 rtt)
 	tp->rto_pending = 0;
 
 	SCTP_DEBUG_PRINTK("%s: transport: %p, rtt: %d, srtt: %d "
-			  "rttvar: %d, rto: %d\n", __FUNCTION__,
+			  "rttvar: %d, rto: %ld\n", __FUNCTION__,
 			  tp, rtt, tp->srtt, tp->rttvar, tp->rto);
 }
 

commit 52ccb8e90c0ace233b8b740f2fc5de0dbd706b27
Author: Frank Filz <ffilz@us.ibm.com>
Date:   Thu Dec 22 11:36:46 2005 -0800

    [SCTP]: Update SCTP_PEER_ADDR_PARAMS socket option to the latest api draft.
    
    This patch adds support to set/get heartbeat interval, maximum number of
    retransmissions, pathmtu, sackdelay time for a particular transport/
    association/socket as per the latest SCTP sockets api draft11.
    
    Signed-off-by: Frank Filz <ffilz@us.ibm.com>
    Signed-off-by: Sridhar Samudrala <sri@us.ibm.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index 268ddaf2dc0f..68d73e2dd155 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -86,10 +86,13 @@ static struct sctp_transport *sctp_transport_init(struct sctp_transport *peer,
 	peer->init_sent_count = 0;
 
 	peer->state = SCTP_ACTIVE;
-	peer->hb_allowed = 0;
+	peer->param_flags = SPP_HB_DISABLE |
+			    SPP_PMTUD_ENABLE |
+			    SPP_SACKDELAY_ENABLE;
+	peer->hbinterval  = 0;
 
 	/* Initialize the default path max_retrans.  */
-	peer->max_retrans = sctp_max_retrans_path;
+	peer->pathmaxrxt  = sctp_max_retrans_path;
 	peer->error_count = 0;
 
 	INIT_LIST_HEAD(&peer->transmitted);
@@ -229,10 +232,10 @@ void sctp_transport_pmtu(struct sctp_transport *transport)
 	dst = transport->af_specific->get_dst(NULL, &transport->ipaddr, NULL);
 
 	if (dst) {
-		transport->pmtu = dst_mtu(dst);
+		transport->pathmtu = dst_mtu(dst);
 		dst_release(dst);
 	} else
-		transport->pmtu = SCTP_DEFAULT_MAXSEGMENT;
+		transport->pathmtu = SCTP_DEFAULT_MAXSEGMENT;
 }
 
 /* Caches the dst entry and source address for a transport's destination
@@ -254,8 +257,11 @@ void sctp_transport_route(struct sctp_transport *transport,
 		af->get_saddr(asoc, dst, daddr, &transport->saddr);
 
 	transport->dst = dst;
+	if ((transport->param_flags & SPP_PMTUD_DISABLE) && transport->pathmtu) {
+		return;
+	}
 	if (dst) {
-		transport->pmtu = dst_mtu(dst);
+		transport->pathmtu = dst_mtu(dst);
 
 		/* Initialize sk->sk_rcv_saddr, if the transport is the
 		 * association's active path for getsockname().
@@ -264,7 +270,7 @@ void sctp_transport_route(struct sctp_transport *transport,
 			opt->pf->af->to_sk_saddr(&transport->saddr,
 						 asoc->base.sk);
 	} else
-		transport->pmtu = SCTP_DEFAULT_MAXSEGMENT;
+		transport->pathmtu = SCTP_DEFAULT_MAXSEGMENT;
 }
 
 /* Hold a reference to a transport.  */
@@ -369,7 +375,7 @@ void sctp_transport_raise_cwnd(struct sctp_transport *transport,
 
 	ssthresh = transport->ssthresh;
 	pba = transport->partial_bytes_acked;
-	pmtu = transport->asoc->pmtu;
+	pmtu = transport->asoc->pathmtu;
 
 	if (cwnd <= ssthresh) {
 		/* RFC 2960 7.2.1, sctpimpguide-05 2.14.2 When cwnd is less
@@ -441,8 +447,8 @@ void sctp_transport_lower_cwnd(struct sctp_transport *transport,
 		 *      partial_bytes_acked = 0
 		 */
 		transport->ssthresh = max(transport->cwnd/2,
-					  4*transport->asoc->pmtu);
-		transport->cwnd = transport->asoc->pmtu;
+					  4*transport->asoc->pathmtu);
+		transport->cwnd = transport->asoc->pathmtu;
 		break;
 
 	case SCTP_LOWER_CWND_FAST_RTX:
@@ -459,7 +465,7 @@ void sctp_transport_lower_cwnd(struct sctp_transport *transport,
 		 *      partial_bytes_acked = 0
 		 */
 		transport->ssthresh = max(transport->cwnd/2,
-					  4*transport->asoc->pmtu);
+					  4*transport->asoc->pathmtu);
 		transport->cwnd = transport->ssthresh;
 		break;
 
@@ -479,7 +485,7 @@ void sctp_transport_lower_cwnd(struct sctp_transport *transport,
 		if ((jiffies - transport->last_time_ecne_reduced) >
 		    transport->rtt) {
 			transport->ssthresh = max(transport->cwnd/2,
-					  	  4*transport->asoc->pmtu);
+					  	  4*transport->asoc->pathmtu);
 			transport->cwnd = transport->ssthresh;
 			transport->last_time_ecne_reduced = jiffies;
 		}
@@ -496,7 +502,7 @@ void sctp_transport_lower_cwnd(struct sctp_transport *transport,
 		 */
 		if ((jiffies - transport->last_time_used) > transport->rto)
 			transport->cwnd = max(transport->cwnd/2,
-						 4*transport->asoc->pmtu);
+						 4*transport->asoc->pathmtu);
 		break;
 	};
 
@@ -511,7 +517,7 @@ void sctp_transport_lower_cwnd(struct sctp_transport *transport,
 unsigned long sctp_transport_timeout(struct sctp_transport *t)
 {
 	unsigned long timeout;
-	timeout = t->hb_interval + t->rto + sctp_jitter(t->rto);
+	timeout = t->hbinterval + t->rto + sctp_jitter(t->rto);
 	timeout += jiffies;
 	return timeout;
 }

commit bf031fff1fac77775b2cd2c72ad8b017f4c0af13
Author: Neil Horman <nhorman@tuxdriver.com>
Date:   Fri Dec 2 20:32:29 2005 -0800

    [SCTP]: Fix getsockname for sctp when an ipv6 socket accepts a connection from
    an ipv4 socket.
    
    Signed-off-by: Neil Horman <nhorman@tuxdriver.com>
    Signed-off-by: Sridhar Samudrala <sri@us.ibm.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index 6bc27200e6ca..268ddaf2dc0f 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -261,7 +261,8 @@ void sctp_transport_route(struct sctp_transport *transport,
 		 * association's active path for getsockname().
 		 */ 
 		if (asoc && (transport == asoc->peer.active_path))
-			af->to_sk_saddr(&transport->saddr, asoc->base.sk);
+			opt->pf->af->to_sk_saddr(&transport->saddr,
+						 asoc->base.sk);
 	} else
 		transport->pmtu = SCTP_DEFAULT_MAXSEGMENT;
 }

commit dd0fc66fb33cd610bc1a5db8a5e232d34879b4d7
Author: Al Viro <viro@ftp.linux.org.uk>
Date:   Fri Oct 7 07:46:04 2005 +0100

    [PATCH] gfp flags annotations - part 1
    
     - added typedef unsigned int __nocast gfp_t;
    
     - replaced __nocast uses for gfp flags with gfp_t - it gives exactly
       the same warnings as far as sparse is concerned, doesn't change
       generated code (from gcc point of view we replaced unsigned int with
       typedef) and documents what's going on far better.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index d2f04ebe5081..6bc27200e6ca 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -57,7 +57,7 @@
 /* Initialize a new transport from provided memory.  */
 static struct sctp_transport *sctp_transport_init(struct sctp_transport *peer,
 						  const union sctp_addr *addr,
-						  unsigned int __nocast gfp)
+						  gfp_t gfp)
 {
 	/* Copy in the address.  */
 	peer->ipaddr = *addr;
@@ -122,7 +122,7 @@ static struct sctp_transport *sctp_transport_init(struct sctp_transport *peer,
 
 /* Allocate and initialize a new transport.  */
 struct sctp_transport *sctp_transport_new(const union sctp_addr *addr,
-					  unsigned int __nocast gfp)
+					  gfp_t gfp)
 {
         struct sctp_transport *transport;
 

commit 3182cd84f0e132558bbe106c070405ae49f1f0e3
Author: Alexey Dobriyan <adobriyan@gmail.com>
Date:   Mon Jul 11 20:57:47 2005 -0700

    [SCTP]: __nocast annotations
    
    Signed-off-by: Alexey Dobriyan <adobriyan@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index a63b69179607..d2f04ebe5081 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -57,7 +57,7 @@
 /* Initialize a new transport from provided memory.  */
 static struct sctp_transport *sctp_transport_init(struct sctp_transport *peer,
 						  const union sctp_addr *addr,
-						  int gfp)
+						  unsigned int __nocast gfp)
 {
 	/* Copy in the address.  */
 	peer->ipaddr = *addr;
@@ -121,7 +121,8 @@ static struct sctp_transport *sctp_transport_init(struct sctp_transport *peer,
 }
 
 /* Allocate and initialize a new transport.  */
-struct sctp_transport *sctp_transport_new(const union sctp_addr *addr, int gfp)
+struct sctp_transport *sctp_transport_new(const union sctp_addr *addr,
+					  unsigned int __nocast gfp)
 {
         struct sctp_transport *transport;
 

commit 2f85a42964dd43fed3a339701db046bee5a8b903
Author: Vlad Yasevich <vladislav.yasevich@hp.com>
Date:   Tue Jun 28 13:24:23 2005 -0700

    [SCTP] Make init & delayed sack timeouts configurable by user.
    
    Signed-off-by: Vlad Yasevich <vladislav.yasevich@hp.com>
    Signed-off-by: Sridhar Samudrala <sri@us.ibm.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index 0ec0fde6e6c5..a63b69179607 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -103,7 +103,6 @@ static struct sctp_transport *sctp_transport_init(struct sctp_transport *peer,
 
 	/* Set up the heartbeat timer. */
 	init_timer(&peer->hb_timer);
-	peer->hb_interval = SCTP_DEFAULT_TIMEOUT_HEARTBEAT;
 	peer->hb_timer.function = sctp_generate_heartbeat_event;
 	peer->hb_timer.data = (unsigned long)peer;
 

commit 3f7a87d2fa9b42f7aade43914f060df68cc89cc7
Author: Frank Filz <ffilzlnx@us.ibm.com>
Date:   Mon Jun 20 13:14:57 2005 -0700

    [SCTP] sctp_connectx() API support
    
    Implements sctp_connectx() as defined in the SCTP sockets API draft by
    tunneling the request through a setsockopt().
    
    Signed-off-by: Frank Filz <ffilzlnx@us.ibm.com>
    Signed-off-by: Sridhar Samudrala <sri@us.ibm.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
index f30882e1e96a..0ec0fde6e6c5 100644
--- a/net/sctp/transport.c
+++ b/net/sctp/transport.c
@@ -83,7 +83,9 @@ static struct sctp_transport *sctp_transport_init(struct sctp_transport *peer,
 	peer->last_time_used = jiffies;
 	peer->last_time_ecne_reduced = jiffies;
 
-	peer->active = SCTP_ACTIVE;
+	peer->init_sent_count = 0;
+
+	peer->state = SCTP_ACTIVE;
 	peer->hb_allowed = 0;
 
 	/* Initialize the default path max_retrans.  */

commit 1da177e4c3f41524e886b7f1b8a0c1fc7321cac2
Author: Linus Torvalds <torvalds@ppc970.osdl.org>
Date:   Sat Apr 16 15:20:36 2005 -0700

    Linux-2.6.12-rc2
    
    Initial git repository build. I'm not bothering with the full history,
    even though we have it. We can create a separate "historical" git
    archive of that later if we want to, and in the meantime it's about
    3.2GB when imported into git - space that would just make the early
    git days unnecessarily complicated, when we don't have a lot of good
    infrastructure for it.
    
    Let it rip!

diff --git a/net/sctp/transport.c b/net/sctp/transport.c
new file mode 100644
index 000000000000..f30882e1e96a
--- /dev/null
+++ b/net/sctp/transport.c
@@ -0,0 +1,514 @@
+/* SCTP kernel reference Implementation
+ * Copyright (c) 1999-2000 Cisco, Inc.
+ * Copyright (c) 1999-2001 Motorola, Inc.
+ * Copyright (c) 2001-2003 International Business Machines Corp.
+ * Copyright (c) 2001 Intel Corp.
+ * Copyright (c) 2001 La Monte H.P. Yarroll
+ *
+ * This file is part of the SCTP kernel reference Implementation
+ *
+ * This module provides the abstraction for an SCTP tranport representing
+ * a remote transport address.  For local transport addresses, we just use
+ * union sctp_addr.
+ *
+ * The SCTP reference implementation is free software;
+ * you can redistribute it and/or modify it under the terms of
+ * the GNU General Public License as published by
+ * the Free Software Foundation; either version 2, or (at your option)
+ * any later version.
+ *
+ * The SCTP reference implementation is distributed in the hope that it
+ * will be useful, but WITHOUT ANY WARRANTY; without even the implied
+ *                 ************************
+ * warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
+ * See the GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with GNU CC; see the file COPYING.  If not, write to
+ * the Free Software Foundation, 59 Temple Place - Suite 330,
+ * Boston, MA 02111-1307, USA.
+ *
+ * Please send any bug reports or fixes you make to the
+ * email address(es):
+ *    lksctp developers <lksctp-developers@lists.sourceforge.net>
+ *
+ * Or submit a bug report through the following website:
+ *    http://www.sf.net/projects/lksctp
+ *
+ * Written or modified by:
+ *    La Monte H.P. Yarroll <piggy@acm.org>
+ *    Karl Knutson          <karl@athena.chicago.il.us>
+ *    Jon Grimm             <jgrimm@us.ibm.com>
+ *    Xingang Guo           <xingang.guo@intel.com>
+ *    Hui Huang             <hui.huang@nokia.com>
+ *    Sridhar Samudrala	    <sri@us.ibm.com>
+ *    Ardelle Fan	    <ardelle.fan@intel.com>
+ *
+ * Any bugs reported given to us we will try to fix... any fixes shared will
+ * be incorporated into the next SCTP release.
+ */
+
+#include <linux/types.h>
+#include <net/sctp/sctp.h>
+#include <net/sctp/sm.h>
+
+/* 1st Level Abstractions.  */
+
+/* Initialize a new transport from provided memory.  */
+static struct sctp_transport *sctp_transport_init(struct sctp_transport *peer,
+						  const union sctp_addr *addr,
+						  int gfp)
+{
+	/* Copy in the address.  */
+	peer->ipaddr = *addr;
+	peer->af_specific = sctp_get_af_specific(addr->sa.sa_family);
+	peer->asoc = NULL;
+
+	peer->dst = NULL;
+	memset(&peer->saddr, 0, sizeof(union sctp_addr));
+
+	/* From 6.3.1 RTO Calculation:
+	 *
+	 * C1) Until an RTT measurement has been made for a packet sent to the
+	 * given destination transport address, set RTO to the protocol
+	 * parameter 'RTO.Initial'.
+	 */
+	peer->rtt = 0;
+	peer->rto = sctp_rto_initial;
+	peer->rttvar = 0;
+	peer->srtt = 0;
+	peer->rto_pending = 0;
+
+	peer->last_time_heard = jiffies;
+	peer->last_time_used = jiffies;
+	peer->last_time_ecne_reduced = jiffies;
+
+	peer->active = SCTP_ACTIVE;
+	peer->hb_allowed = 0;
+
+	/* Initialize the default path max_retrans.  */
+	peer->max_retrans = sctp_max_retrans_path;
+	peer->error_count = 0;
+
+	INIT_LIST_HEAD(&peer->transmitted);
+	INIT_LIST_HEAD(&peer->send_ready);
+	INIT_LIST_HEAD(&peer->transports);
+
+	/* Set up the retransmission timer.  */
+	init_timer(&peer->T3_rtx_timer);
+	peer->T3_rtx_timer.function = sctp_generate_t3_rtx_event;
+	peer->T3_rtx_timer.data = (unsigned long)peer;
+
+	/* Set up the heartbeat timer. */
+	init_timer(&peer->hb_timer);
+	peer->hb_interval = SCTP_DEFAULT_TIMEOUT_HEARTBEAT;
+	peer->hb_timer.function = sctp_generate_heartbeat_event;
+	peer->hb_timer.data = (unsigned long)peer;
+
+	atomic_set(&peer->refcnt, 1);
+	peer->dead = 0;
+
+	peer->malloced = 0;
+
+	/* Initialize the state information for SFR-CACC */
+	peer->cacc.changeover_active = 0;
+	peer->cacc.cycling_changeover = 0;
+	peer->cacc.next_tsn_at_change = 0;
+	peer->cacc.cacc_saw_newack = 0;
+
+	return peer;
+}
+
+/* Allocate and initialize a new transport.  */
+struct sctp_transport *sctp_transport_new(const union sctp_addr *addr, int gfp)
+{
+        struct sctp_transport *transport;
+
+        transport = t_new(struct sctp_transport, gfp);
+	if (!transport)
+		goto fail;
+
+	if (!sctp_transport_init(transport, addr, gfp))
+		goto fail_init;
+
+	transport->malloced = 1;
+	SCTP_DBG_OBJCNT_INC(transport);
+
+	return transport;
+
+fail_init:
+	kfree(transport);
+
+fail:
+	return NULL;
+}
+
+/* This transport is no longer needed.  Free up if possible, or
+ * delay until it last reference count.
+ */
+void sctp_transport_free(struct sctp_transport *transport)
+{
+	transport->dead = 1;
+
+	/* Try to delete the heartbeat timer.  */
+	if (del_timer(&transport->hb_timer))
+		sctp_transport_put(transport);
+
+	/* Delete the T3_rtx timer if it's active.
+	 * There is no point in not doing this now and letting
+	 * structure hang around in memory since we know
+	 * the tranport is going away.
+	 */
+	if (timer_pending(&transport->T3_rtx_timer) &&
+	    del_timer(&transport->T3_rtx_timer))
+		sctp_transport_put(transport);
+
+
+	sctp_transport_put(transport);
+}
+
+/* Destroy the transport data structure.
+ * Assumes there are no more users of this structure.
+ */
+static void sctp_transport_destroy(struct sctp_transport *transport)
+{
+	SCTP_ASSERT(transport->dead, "Transport is not dead", return);
+
+	if (transport->asoc)
+		sctp_association_put(transport->asoc);
+
+        sctp_packet_free(&transport->packet);
+
+	dst_release(transport->dst);
+	kfree(transport);
+	SCTP_DBG_OBJCNT_DEC(transport);
+}
+
+/* Start T3_rtx timer if it is not already running and update the heartbeat
+ * timer.  This routine is called every time a DATA chunk is sent.
+ */
+void sctp_transport_reset_timers(struct sctp_transport *transport)
+{
+	/* RFC 2960 6.3.2 Retransmission Timer Rules
+	 *
+	 * R1) Every time a DATA chunk is sent to any address(including a
+	 * retransmission), if the T3-rtx timer of that address is not running
+	 * start it running so that it will expire after the RTO of that
+	 * address.
+	 */
+
+	if (!timer_pending(&transport->T3_rtx_timer))
+		if (!mod_timer(&transport->T3_rtx_timer,
+			       jiffies + transport->rto))
+			sctp_transport_hold(transport);
+
+	/* When a data chunk is sent, reset the heartbeat interval.  */
+	if (!mod_timer(&transport->hb_timer,
+		       sctp_transport_timeout(transport)))
+	    sctp_transport_hold(transport);
+}
+
+/* This transport has been assigned to an association.
+ * Initialize fields from the association or from the sock itself.
+ * Register the reference count in the association.
+ */
+void sctp_transport_set_owner(struct sctp_transport *transport,
+			      struct sctp_association *asoc)
+{
+	transport->asoc = asoc;
+	sctp_association_hold(asoc);
+}
+
+/* Initialize the pmtu of a transport. */
+void sctp_transport_pmtu(struct sctp_transport *transport)
+{
+	struct dst_entry *dst;
+
+	dst = transport->af_specific->get_dst(NULL, &transport->ipaddr, NULL);
+
+	if (dst) {
+		transport->pmtu = dst_mtu(dst);
+		dst_release(dst);
+	} else
+		transport->pmtu = SCTP_DEFAULT_MAXSEGMENT;
+}
+
+/* Caches the dst entry and source address for a transport's destination
+ * address.
+ */
+void sctp_transport_route(struct sctp_transport *transport,
+			  union sctp_addr *saddr, struct sctp_sock *opt)
+{
+	struct sctp_association *asoc = transport->asoc;
+	struct sctp_af *af = transport->af_specific;
+	union sctp_addr *daddr = &transport->ipaddr;
+	struct dst_entry *dst;
+
+	dst = af->get_dst(asoc, daddr, saddr);
+
+	if (saddr)
+		memcpy(&transport->saddr, saddr, sizeof(union sctp_addr));
+	else
+		af->get_saddr(asoc, dst, daddr, &transport->saddr);
+
+	transport->dst = dst;
+	if (dst) {
+		transport->pmtu = dst_mtu(dst);
+
+		/* Initialize sk->sk_rcv_saddr, if the transport is the
+		 * association's active path for getsockname().
+		 */ 
+		if (asoc && (transport == asoc->peer.active_path))
+			af->to_sk_saddr(&transport->saddr, asoc->base.sk);
+	} else
+		transport->pmtu = SCTP_DEFAULT_MAXSEGMENT;
+}
+
+/* Hold a reference to a transport.  */
+void sctp_transport_hold(struct sctp_transport *transport)
+{
+	atomic_inc(&transport->refcnt);
+}
+
+/* Release a reference to a transport and clean up
+ * if there are no more references.
+ */
+void sctp_transport_put(struct sctp_transport *transport)
+{
+	if (atomic_dec_and_test(&transport->refcnt))
+		sctp_transport_destroy(transport);
+}
+
+/* Update transport's RTO based on the newly calculated RTT. */
+void sctp_transport_update_rto(struct sctp_transport *tp, __u32 rtt)
+{
+	/* Check for valid transport.  */
+	SCTP_ASSERT(tp, "NULL transport", return);
+
+	/* We should not be doing any RTO updates unless rto_pending is set.  */
+	SCTP_ASSERT(tp->rto_pending, "rto_pending not set", return);
+
+	if (tp->rttvar || tp->srtt) {
+		/* 6.3.1 C3) When a new RTT measurement R' is made, set
+		 * RTTVAR <- (1 - RTO.Beta) * RTTVAR + RTO.Beta * |SRTT - R'|
+		 * SRTT <- (1 - RTO.Alpha) * SRTT + RTO.Alpha * R'
+		 */
+
+		/* Note:  The above algorithm has been rewritten to
+		 * express rto_beta and rto_alpha as inverse powers
+		 * of two.
+		 * For example, assuming the default value of RTO.Alpha of
+		 * 1/8, rto_alpha would be expressed as 3.
+		 */
+		tp->rttvar = tp->rttvar - (tp->rttvar >> sctp_rto_beta)
+			+ ((abs(tp->srtt - rtt)) >> sctp_rto_beta);
+		tp->srtt = tp->srtt - (tp->srtt >> sctp_rto_alpha)
+			+ (rtt >> sctp_rto_alpha);
+	} else {
+		/* 6.3.1 C2) When the first RTT measurement R is made, set
+		 * SRTT <- R, RTTVAR <- R/2.
+		 */
+		tp->srtt = rtt;
+		tp->rttvar = rtt >> 1;
+	}
+
+	/* 6.3.1 G1) Whenever RTTVAR is computed, if RTTVAR = 0, then
+	 * adjust RTTVAR <- G, where G is the CLOCK GRANULARITY.
+	 */
+	if (tp->rttvar == 0)
+		tp->rttvar = SCTP_CLOCK_GRANULARITY;
+
+	/* 6.3.1 C3) After the computation, update RTO <- SRTT + 4 * RTTVAR. */
+	tp->rto = tp->srtt + (tp->rttvar << 2);
+
+	/* 6.3.1 C6) Whenever RTO is computed, if it is less than RTO.Min
+	 * seconds then it is rounded up to RTO.Min seconds.
+	 */
+	if (tp->rto < tp->asoc->rto_min)
+		tp->rto = tp->asoc->rto_min;
+
+	/* 6.3.1 C7) A maximum value may be placed on RTO provided it is
+	 * at least RTO.max seconds.
+	 */
+	if (tp->rto > tp->asoc->rto_max)
+		tp->rto = tp->asoc->rto_max;
+
+	tp->rtt = rtt;
+
+	/* Reset rto_pending so that a new RTT measurement is started when a
+	 * new data chunk is sent.
+	 */
+	tp->rto_pending = 0;
+
+	SCTP_DEBUG_PRINTK("%s: transport: %p, rtt: %d, srtt: %d "
+			  "rttvar: %d, rto: %d\n", __FUNCTION__,
+			  tp, rtt, tp->srtt, tp->rttvar, tp->rto);
+}
+
+/* This routine updates the transport's cwnd and partial_bytes_acked
+ * parameters based on the bytes acked in the received SACK.
+ */
+void sctp_transport_raise_cwnd(struct sctp_transport *transport,
+			       __u32 sack_ctsn, __u32 bytes_acked)
+{
+	__u32 cwnd, ssthresh, flight_size, pba, pmtu;
+
+	cwnd = transport->cwnd;
+	flight_size = transport->flight_size;
+
+	/* The appropriate cwnd increase algorithm is performed if, and only
+	 * if the cumulative TSN has advanced and the congestion window is
+	 * being fully utilized.
+	 */
+	if ((transport->asoc->ctsn_ack_point >= sack_ctsn) ||
+	    (flight_size < cwnd))
+		return;
+
+	ssthresh = transport->ssthresh;
+	pba = transport->partial_bytes_acked;
+	pmtu = transport->asoc->pmtu;
+
+	if (cwnd <= ssthresh) {
+		/* RFC 2960 7.2.1, sctpimpguide-05 2.14.2 When cwnd is less
+		 * than or equal to ssthresh an SCTP endpoint MUST use the
+		 * slow start algorithm to increase cwnd only if the current
+		 * congestion window is being fully utilized and an incoming
+		 * SACK advances the Cumulative TSN Ack Point. Only when these
+		 * two conditions are met can the cwnd be increased otherwise
+		 * the cwnd MUST not be increased. If these conditions are met
+		 * then cwnd MUST be increased by at most the lesser of
+		 * 1) the total size of the previously outstanding DATA
+		 * chunk(s) acknowledged, and 2) the destination's path MTU.
+		 */
+		if (bytes_acked > pmtu)
+			cwnd += pmtu;
+		else
+			cwnd += bytes_acked;
+		SCTP_DEBUG_PRINTK("%s: SLOW START: transport: %p, "
+				  "bytes_acked: %d, cwnd: %d, ssthresh: %d, "
+				  "flight_size: %d, pba: %d\n",
+				  __FUNCTION__,
+				  transport, bytes_acked, cwnd,
+				  ssthresh, flight_size, pba);
+	} else {
+		/* RFC 2960 7.2.2 Whenever cwnd is greater than ssthresh,
+		 * upon each SACK arrival that advances the Cumulative TSN Ack
+		 * Point, increase partial_bytes_acked by the total number of
+		 * bytes of all new chunks acknowledged in that SACK including
+		 * chunks acknowledged by the new Cumulative TSN Ack and by
+		 * Gap Ack Blocks.
+		 *
+		 * When partial_bytes_acked is equal to or greater than cwnd
+		 * and before the arrival of the SACK the sender had cwnd or
+		 * more bytes of data outstanding (i.e., before arrival of the
+		 * SACK, flightsize was greater than or equal to cwnd),
+		 * increase cwnd by MTU, and reset partial_bytes_acked to
+		 * (partial_bytes_acked - cwnd).
+		 */
+		pba += bytes_acked;
+		if (pba >= cwnd) {
+			cwnd += pmtu;
+			pba = ((cwnd < pba) ? (pba - cwnd) : 0);
+		}
+		SCTP_DEBUG_PRINTK("%s: CONGESTION AVOIDANCE: "
+				  "transport: %p, bytes_acked: %d, cwnd: %d, "
+				  "ssthresh: %d, flight_size: %d, pba: %d\n",
+				  __FUNCTION__,
+				  transport, bytes_acked, cwnd,
+				  ssthresh, flight_size, pba);
+	}
+
+	transport->cwnd = cwnd;
+	transport->partial_bytes_acked = pba;
+}
+
+/* This routine is used to lower the transport's cwnd when congestion is
+ * detected.
+ */
+void sctp_transport_lower_cwnd(struct sctp_transport *transport,
+			       sctp_lower_cwnd_t reason)
+{
+	switch (reason) {
+	case SCTP_LOWER_CWND_T3_RTX:
+		/* RFC 2960 Section 7.2.3, sctpimpguide
+		 * When the T3-rtx timer expires on an address, SCTP should
+		 * perform slow start by:
+		 *      ssthresh = max(cwnd/2, 4*MTU)
+		 *      cwnd = 1*MTU
+		 *      partial_bytes_acked = 0
+		 */
+		transport->ssthresh = max(transport->cwnd/2,
+					  4*transport->asoc->pmtu);
+		transport->cwnd = transport->asoc->pmtu;
+		break;
+
+	case SCTP_LOWER_CWND_FAST_RTX:
+		/* RFC 2960 7.2.4 Adjust the ssthresh and cwnd of the
+		 * destination address(es) to which the missing DATA chunks
+		 * were last sent, according to the formula described in
+		 * Section 7.2.3.
+	 	 *
+	 	 * RFC 2960 7.2.3, sctpimpguide Upon detection of packet
+		 * losses from SACK (see Section 7.2.4), An endpoint
+		 * should do the following:
+		 *      ssthresh = max(cwnd/2, 4*MTU)
+		 *      cwnd = ssthresh
+		 *      partial_bytes_acked = 0
+		 */
+		transport->ssthresh = max(transport->cwnd/2,
+					  4*transport->asoc->pmtu);
+		transport->cwnd = transport->ssthresh;
+		break;
+
+	case SCTP_LOWER_CWND_ECNE:
+		/* RFC 2481 Section 6.1.2.
+		 * If the sender receives an ECN-Echo ACK packet
+		 * then the sender knows that congestion was encountered in the
+		 * network on the path from the sender to the receiver. The
+		 * indication of congestion should be treated just as a
+		 * congestion loss in non-ECN Capable TCP. That is, the TCP
+		 * source halves the congestion window "cwnd" and reduces the
+		 * slow start threshold "ssthresh".
+		 * A critical condition is that TCP does not react to
+		 * congestion indications more than once every window of
+		 * data (or more loosely more than once every round-trip time).
+		 */
+		if ((jiffies - transport->last_time_ecne_reduced) >
+		    transport->rtt) {
+			transport->ssthresh = max(transport->cwnd/2,
+					  	  4*transport->asoc->pmtu);
+			transport->cwnd = transport->ssthresh;
+			transport->last_time_ecne_reduced = jiffies;
+		}
+		break;
+
+	case SCTP_LOWER_CWND_INACTIVE:
+		/* RFC 2960 Section 7.2.1, sctpimpguide
+		 * When the endpoint does not transmit data on a given
+		 * transport address, the cwnd of the transport address
+		 * should be adjusted to max(cwnd/2, 4*MTU) per RTO.
+		 * NOTE: Although the draft recommends that this check needs
+		 * to be done every RTO interval, we do it every hearbeat
+		 * interval.
+		 */
+		if ((jiffies - transport->last_time_used) > transport->rto)
+			transport->cwnd = max(transport->cwnd/2,
+						 4*transport->asoc->pmtu);
+		break;
+	};
+
+	transport->partial_bytes_acked = 0;
+	SCTP_DEBUG_PRINTK("%s: transport: %p reason: %d cwnd: "
+			  "%d ssthresh: %d\n", __FUNCTION__,
+			  transport, reason,
+			  transport->cwnd, transport->ssthresh);
+}
+
+/* What is the next timeout value for this transport? */
+unsigned long sctp_transport_timeout(struct sctp_transport *t)
+{
+	unsigned long timeout;
+	timeout = t->hb_interval + t->rto + sctp_jitter(t->rto);
+	timeout += jiffies;
+	return timeout;
+}
