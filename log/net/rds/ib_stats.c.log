commit 05a82481a3024b94db00b8c816bb3d526b5209e0
Author: Gerd Rausch <gerd.rausch@oracle.com>
Date:   Thu Sep 12 13:49:41 2019 -0700

    net/rds: Fix 'ib_evt_handler_call' element in 'rds_ib_stat_names'
    
    All entries in 'rds_ib_stat_names' are stringified versions
    of the corresponding "struct rds_ib_statistics" element
    without the "s_"-prefix.
    
    Fix entry 'ib_evt_handler_call' to do the same.
    
    Fixes: f4f943c958a2 ("RDS: IB: ack more receive completions to improve performance")
    Signed-off-by: Gerd Rausch <gerd.rausch@oracle.com>
    Acked-by: Santosh Shilimkar <santosh.shilimkar@oracle.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/rds/ib_stats.c b/net/rds/ib_stats.c
index 9252ad126335..ac46d8961b61 100644
--- a/net/rds/ib_stats.c
+++ b/net/rds/ib_stats.c
@@ -42,7 +42,7 @@ DEFINE_PER_CPU_SHARED_ALIGNED(struct rds_ib_statistics, rds_ib_stats);
 static const char *const rds_ib_stat_names[] = {
 	"ib_connect_raced",
 	"ib_listen_closed_stale",
-	"s_ib_evt_handler_call",
+	"ib_evt_handler_call",
 	"ib_tasklet_call",
 	"ib_tx_cq_event",
 	"ib_tx_ring_full",

commit 09b2b8f52895addd9bf28dc5ac98ff5cc750cf9a
Author: Santosh Shilimkar <santosh.shilimkar@oracle.com>
Date:   Sat Jul 9 17:14:02 2016 -0700

    RDS: IB: add few useful cache stasts
    
    Tracks the ib receive cache total, incoming and frag allocations.
    
    Signed-off-by: Santosh Shilimkar <santosh.shilimkar@oracle.com>

diff --git a/net/rds/ib_stats.c b/net/rds/ib_stats.c
index 7e78dca1f252..9252ad126335 100644
--- a/net/rds/ib_stats.c
+++ b/net/rds/ib_stats.c
@@ -55,6 +55,8 @@ static const char *const rds_ib_stat_names[] = {
 	"ib_rx_refill_from_cq",
 	"ib_rx_refill_from_thread",
 	"ib_rx_alloc_limit",
+	"ib_rx_total_frags",
+	"ib_rx_total_incs",
 	"ib_rx_credit_updates",
 	"ib_ack_sent",
 	"ib_ack_send_failure",

commit db42753adb638b63572583162bb08ea193947309
Author: santosh.shilimkar@oracle.com <santosh.shilimkar@oracle.com>
Date:   Tue Mar 1 15:20:51 2016 -0800

    RDS: IB: add mr reused stats
    
    Add MR reuse statistics to RDS IB transport.
    
    Signed-off-by: Santosh Shilimkar <ssantosh@kernel.org>
    Signed-off-by: Santosh Shilimkar <santosh.shilimkar@oracle.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/rds/ib_stats.c b/net/rds/ib_stats.c
index d77e04473056..7e78dca1f252 100644
--- a/net/rds/ib_stats.c
+++ b/net/rds/ib_stats.c
@@ -73,6 +73,8 @@ static const char *const rds_ib_stat_names[] = {
 	"ib_rdma_mr_1m_pool_flush",
 	"ib_rdma_mr_1m_pool_wait",
 	"ib_rdma_mr_1m_pool_depleted",
+	"ib_rdma_mr_8k_reused",
+	"ib_rdma_mr_1m_reused",
 	"ib_atomic_cswp",
 	"ib_atomic_fadd",
 };

commit 06766513232d1619ac84e87b1d839d3fcc23a540
Author: Santosh Shilimkar <santosh.shilimkar@oracle.com>
Date:   Thu Sep 10 21:20:57 2015 -0700

    RDS: IB: split mr pool to improve 8K messages performance
    
    8K message sizes are pretty important usecase for RDS current
    workloads so we make provison to have 8K mrs available from the pool.
    Based on number of SG's in the RDS message, we pick a pool to use.
    
    Also to make sure that we don't under utlise mrs when say 8k messages
    are dominating which could lead to 8k pull being exhausted, we fall-back
    to 1m pool till 8k pool recovers for use.
    
    This helps to at least push ~55 kB/s bidirectional data which
    is a nice improvement.
    
    Signed-off-by: Santosh Shilimkar <ssantosh@kernel.org>
    Signed-off-by: Santosh Shilimkar <santosh.shilimkar@oracle.com>

diff --git a/net/rds/ib_stats.c b/net/rds/ib_stats.c
index 8c8b84f7bfbb..d77e04473056 100644
--- a/net/rds/ib_stats.c
+++ b/net/rds/ib_stats.c
@@ -61,12 +61,18 @@ static const char *const rds_ib_stat_names[] = {
 	"ib_ack_send_delayed",
 	"ib_ack_send_piggybacked",
 	"ib_ack_received",
-	"ib_rdma_mr_alloc",
-	"ib_rdma_mr_free",
-	"ib_rdma_mr_used",
-	"ib_rdma_mr_pool_flush",
-	"ib_rdma_mr_pool_wait",
-	"ib_rdma_mr_pool_depleted",
+	"ib_rdma_mr_8k_alloc",
+	"ib_rdma_mr_8k_free",
+	"ib_rdma_mr_8k_used",
+	"ib_rdma_mr_8k_pool_flush",
+	"ib_rdma_mr_8k_pool_wait",
+	"ib_rdma_mr_8k_pool_depleted",
+	"ib_rdma_mr_1m_alloc",
+	"ib_rdma_mr_1m_free",
+	"ib_rdma_mr_1m_used",
+	"ib_rdma_mr_1m_pool_flush",
+	"ib_rdma_mr_1m_pool_wait",
+	"ib_rdma_mr_1m_pool_depleted",
 	"ib_atomic_cswp",
 	"ib_atomic_fadd",
 };

commit 0c28c04500cf956c82d542c199f5bddabd590af3
Author: Santosh Shilimkar <santosh.shilimkar@oracle.com>
Date:   Sun Sep 6 02:18:51 2015 -0400

    RDS: IB: split send completion handling and do batch ack
    
    Similar to what we did with receive CQ completion handling, we split
    the transmit completion handler so that it lets us implement batched
    work completion handling.
    
    We re-use the cq_poll routine and makes use of RDS_IB_SEND_OP to
    identify the send vs receive completion event handler invocation.
    
    Signed-off-by: Santosh Shilimkar <ssantosh@kernel.org>
    Signed-off-by: Santosh Shilimkar <santosh.shilimkar@oracle.com>

diff --git a/net/rds/ib_stats.c b/net/rds/ib_stats.c
index bdf6115ef6e1..8c8b84f7bfbb 100644
--- a/net/rds/ib_stats.c
+++ b/net/rds/ib_stats.c
@@ -43,7 +43,6 @@ static const char *const rds_ib_stat_names[] = {
 	"ib_connect_raced",
 	"ib_listen_closed_stale",
 	"s_ib_evt_handler_call",
-	"ib_tx_cq_call",
 	"ib_tasklet_call",
 	"ib_tx_cq_event",
 	"ib_tx_ring_full",

commit f4f943c958a2869b0601092857c1cf0e485d3ce8
Author: Santosh Shilimkar <santosh.shilimkar@oracle.com>
Date:   Sun Sep 6 02:18:51 2015 -0400

    RDS: IB: ack more receive completions to improve performance
    
    For better performance, we split the receive completion IRQ handler. That
    lets us acknowledge several WCE events in one call. We also limit the WC
    to max 32 to avoid latency. Acknowledging several completions in one call
    instead of several calls each time will provide better performance since
    less mutual exclusion locks are being performed.
    
    In next patch, send completion is also split which re-uses the poll_cq()
    and hence the code is moved to ib_cm.c
    
    Signed-off-by: Santosh Shilimkar <ssantosh@kernel.org>
    Signed-off-by: Santosh Shilimkar <santosh.shilimkar@oracle.com>

diff --git a/net/rds/ib_stats.c b/net/rds/ib_stats.c
index 2d5965d6e97c..bdf6115ef6e1 100644
--- a/net/rds/ib_stats.c
+++ b/net/rds/ib_stats.c
@@ -42,14 +42,15 @@ DEFINE_PER_CPU_SHARED_ALIGNED(struct rds_ib_statistics, rds_ib_stats);
 static const char *const rds_ib_stat_names[] = {
 	"ib_connect_raced",
 	"ib_listen_closed_stale",
+	"s_ib_evt_handler_call",
 	"ib_tx_cq_call",
+	"ib_tasklet_call",
 	"ib_tx_cq_event",
 	"ib_tx_ring_full",
 	"ib_tx_throttle",
 	"ib_tx_sg_mapping_failure",
 	"ib_tx_stalled",
 	"ib_tx_credit_updates",
-	"ib_rx_cq_call",
 	"ib_rx_cq_event",
 	"ib_rx_ring_empty",
 	"ib_rx_refill_from_cq",

commit 51e2cba8b5936c13b40f0fa11aa4e84683dbc751
Author: Andy Grover <andy.grover@oracle.com>
Date:   Mon Mar 29 17:47:30 2010 -0700

    RDS: Move atomic stats from general to ib-specific area
    
    Signed-off-by: Andy Grover <andy.grover@oracle.com>

diff --git a/net/rds/ib_stats.c b/net/rds/ib_stats.c
index d2c904dd6fbc..2d5965d6e97c 100644
--- a/net/rds/ib_stats.c
+++ b/net/rds/ib_stats.c
@@ -67,6 +67,8 @@ static const char *const rds_ib_stat_names[] = {
 	"ib_rdma_mr_pool_flush",
 	"ib_rdma_mr_pool_wait",
 	"ib_rdma_mr_pool_depleted",
+	"ib_atomic_cswp",
+	"ib_atomic_fadd",
 };
 
 unsigned int rds_ib_stats_info_copy(struct rds_info_iterator *iter,

commit ada3fa15057205b7d3f727bba5cd26b5912e350f
Merge: 2f82af08fcc7 5579fd7e6aed
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Sep 15 09:39:44 2009 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tj/percpu
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tj/percpu: (46 commits)
      powerpc64: convert to dynamic percpu allocator
      sparc64: use embedding percpu first chunk allocator
      percpu: kill lpage first chunk allocator
      x86,percpu: use embedding for 64bit NUMA and page for 32bit NUMA
      percpu: update embedding first chunk allocator to handle sparse units
      percpu: use group information to allocate vmap areas sparsely
      vmalloc: implement pcpu_get_vm_areas()
      vmalloc: separate out insert_vmalloc_vm()
      percpu: add chunk->base_addr
      percpu: add pcpu_unit_offsets[]
      percpu: introduce pcpu_alloc_info and pcpu_group_info
      percpu: move pcpu_lpage_build_unit_map() and pcpul_lpage_dump_cfg() upward
      percpu: add @align to pcpu_fc_alloc_fn_t
      percpu: make @dyn_size mandatory for pcpu_setup_first_chunk()
      percpu: drop @static_size from first chunk allocators
      percpu: generalize first chunk allocator selection
      percpu: build first chunk allocators selectively
      percpu: rename 4k first chunk allocator to page
      percpu: improve boot messages
      percpu: fix pcpu_reclaim() locking
      ...
    
    Fix trivial conflict as by Tejun Heo in kernel/sched.c

commit 36cbd3dcc10384f813ec0814255f576c84f2bcd4
Author: Jan Engelhardt <jengelh@medozas.de>
Date:   Wed Aug 5 10:42:58 2009 -0700

    net: mark read-only arrays as const
    
    String literals are constant, and usually, we can also tag the array
    of pointers const too, moving it to the .rodata section.
    
    Signed-off-by: Jan Engelhardt <jengelh@medozas.de>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/rds/ib_stats.c b/net/rds/ib_stats.c
index 02e3e3d50d4a..8d8488306fe4 100644
--- a/net/rds/ib_stats.c
+++ b/net/rds/ib_stats.c
@@ -39,7 +39,7 @@
 
 DEFINE_PER_CPU(struct rds_ib_statistics, rds_ib_stats) ____cacheline_aligned;
 
-static char *rds_ib_stat_names[] = {
+static const char *const rds_ib_stat_names[] = {
 	"ib_connect_raced",
 	"ib_listen_closed_stale",
 	"ib_tx_cq_call",

commit b9bf3121af348d9255f1c917830fe8c2df52efcb
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Jun 24 15:13:47 2009 +0900

    percpu: use DEFINE_PER_CPU_SHARED_ALIGNED()
    
    There are a few places where ___cacheline_aligned* is used with
    DEFINE_PER_CPU().  Use DEFINE_PER_CPU_SHARED_ALIGNED() instead.
    
    DEFINE_PER_CPU_SHARED_ALIGNED() applies alignment only on SMPs.  While
    all other converted places used _in_smp variant or only get compiled
    for SMP, net/rds used unconditional ____cacheline_aligned.  I don't
    see any reason these data structures should be aligned on UP and thus
    converted together.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Mike Frysinger <vapier@gentoo.org>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Andy Grover <andy.grover@oracle.com>

diff --git a/net/rds/ib_stats.c b/net/rds/ib_stats.c
index 02e3e3d50d4a..301ae51ae409 100644
--- a/net/rds/ib_stats.c
+++ b/net/rds/ib_stats.c
@@ -37,7 +37,7 @@
 #include "rds.h"
 #include "ib.h"
 
-DEFINE_PER_CPU(struct rds_ib_statistics, rds_ib_stats) ____cacheline_aligned;
+DEFINE_PER_CPU_SHARED_ALIGNED(struct rds_ib_statistics, rds_ib_stats);
 
 static char *rds_ib_stat_names[] = {
 	"ib_connect_raced",

commit e6babe4cc4ce48577d743cc0de19a214f2527956
Author: Andy Grover <andy.grover@oracle.com>
Date:   Tue Feb 24 15:30:35 2009 +0000

    RDS/IB: Stats and sysctls
    
    IB-specific stats and sysctls.
    
    Signed-off-by: Andy Grover <andy.grover@oracle.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/rds/ib_stats.c b/net/rds/ib_stats.c
new file mode 100644
index 000000000000..02e3e3d50d4a
--- /dev/null
+++ b/net/rds/ib_stats.c
@@ -0,0 +1,95 @@
+/*
+ * Copyright (c) 2006 Oracle.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ *
+ */
+#include <linux/percpu.h>
+#include <linux/seq_file.h>
+#include <linux/proc_fs.h>
+
+#include "rds.h"
+#include "ib.h"
+
+DEFINE_PER_CPU(struct rds_ib_statistics, rds_ib_stats) ____cacheline_aligned;
+
+static char *rds_ib_stat_names[] = {
+	"ib_connect_raced",
+	"ib_listen_closed_stale",
+	"ib_tx_cq_call",
+	"ib_tx_cq_event",
+	"ib_tx_ring_full",
+	"ib_tx_throttle",
+	"ib_tx_sg_mapping_failure",
+	"ib_tx_stalled",
+	"ib_tx_credit_updates",
+	"ib_rx_cq_call",
+	"ib_rx_cq_event",
+	"ib_rx_ring_empty",
+	"ib_rx_refill_from_cq",
+	"ib_rx_refill_from_thread",
+	"ib_rx_alloc_limit",
+	"ib_rx_credit_updates",
+	"ib_ack_sent",
+	"ib_ack_send_failure",
+	"ib_ack_send_delayed",
+	"ib_ack_send_piggybacked",
+	"ib_ack_received",
+	"ib_rdma_mr_alloc",
+	"ib_rdma_mr_free",
+	"ib_rdma_mr_used",
+	"ib_rdma_mr_pool_flush",
+	"ib_rdma_mr_pool_wait",
+	"ib_rdma_mr_pool_depleted",
+};
+
+unsigned int rds_ib_stats_info_copy(struct rds_info_iterator *iter,
+				    unsigned int avail)
+{
+	struct rds_ib_statistics stats = {0, };
+	uint64_t *src;
+	uint64_t *sum;
+	size_t i;
+	int cpu;
+
+	if (avail < ARRAY_SIZE(rds_ib_stat_names))
+		goto out;
+
+	for_each_online_cpu(cpu) {
+		src = (uint64_t *)&(per_cpu(rds_ib_stats, cpu));
+		sum = (uint64_t *)&stats;
+		for (i = 0; i < sizeof(stats) / sizeof(uint64_t); i++)
+			*(sum++) += *(src++);
+	}
+
+	rds_stats_info_copy(iter, (uint64_t *)&stats, rds_ib_stat_names,
+			    ARRAY_SIZE(rds_ib_stat_names));
+out:
+	return ARRAY_SIZE(rds_ib_stat_names);
+}
