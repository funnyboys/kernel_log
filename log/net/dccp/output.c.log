commit 2874c5fd284268364ece81a7bd936f3c8168e567
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon May 27 08:55:01 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 152
    
    Based on 1 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license as published by
      the free software foundation either version 2 of the license or at
      your option any later version
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-or-later
    
    has been chosen to replace the boilerplate/reference in 3029 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190527070032.746973796@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index 91a15b3c4915..6433187a5cc4 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -1,13 +1,9 @@
+// SPDX-License-Identifier: GPL-2.0-or-later
 /*
  *  net/dccp/output.c
  *
  *  An implementation of the DCCP protocol
  *  Arnaldo Carvalho de Melo <acme@conectiva.com.br>
- *
- *	This program is free software; you can redistribute it and/or
- *	modify it under the terms of the GNU General Public License
- *	as published by the Free Software Foundation; either version
- *	2 of the License, or (at your option) any later version.
  */
 
 #include <linux/dccp.h>

commit 174cd4b1e5fbd0d74c68cf3a74f5bd4923485512
Author: Ingo Molnar <mingo@kernel.org>
Date:   Thu Feb 2 19:15:33 2017 +0100

    sched/headers: Prepare to move signal wakeup & sigpending methods from <linux/sched.h> into <linux/sched/signal.h>
    
    Fix up affected files that include this signal functionality via sched.h.
    
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index b66c84db0766..91a15b3c4915 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -14,6 +14,7 @@
 #include <linux/kernel.h>
 #include <linux/skbuff.h>
 #include <linux/slab.h>
+#include <linux/sched/signal.h>
 
 #include <net/inet_sock.h>
 #include <net/sock.h>

commit 1ce0bf50ae2233c7115a18c0c623662d177b434c
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Thu Nov 26 13:55:39 2015 +0800

    net: Generalise wq_has_sleeper helper
    
    The memory barrier in the helper wq_has_sleeper is needed by just
    about every user of waitqueue_active.  This patch generalises it
    by making it take a wait_queue_head_t directly.  The existing
    helper is renamed to skwq_has_sleeper.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index 4ce912e691d0..b66c84db0766 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -201,7 +201,7 @@ void dccp_write_space(struct sock *sk)
 
 	rcu_read_lock();
 	wq = rcu_dereference(sk->sk_wq);
-	if (wq_has_sleeper(wq))
+	if (skwq_has_sleeper(wq))
 		wake_up_interruptible(&wq->wait);
 	/* Should agree with poll, otherwise some programs break */
 	if (sock_writeable(sk))

commit 802885fc0400d0166a6b65d1844b61696aecbb10
Author: Eric Dumazet <edumazet@google.com>
Date:   Fri Sep 25 07:39:22 2015 -0700

    dccp: constify dccp_make_response() socket argument
    
    Like tcp_make_synack() the only time we might change the socket is
    when calling sock_wmalloc(), which is using atomic operation to
    update sk->sk_wmem_alloc
    
    Also use MAX_DCCP_HEADER as both IPv4/IPv6 use this value for max_header.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index 0248e8a3460c..4ce912e691d0 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -390,7 +390,7 @@ int dccp_retransmit_skb(struct sock *sk)
 	return dccp_transmit_skb(sk, skb_clone(sk->sk_send_head, GFP_ATOMIC));
 }
 
-struct sk_buff *dccp_make_response(struct sock *sk, struct dst_entry *dst,
+struct sk_buff *dccp_make_response(const struct sock *sk, struct dst_entry *dst,
 				   struct request_sock *req)
 {
 	struct dccp_hdr *dh;
@@ -398,13 +398,18 @@ struct sk_buff *dccp_make_response(struct sock *sk, struct dst_entry *dst,
 	const u32 dccp_header_size = sizeof(struct dccp_hdr) +
 				     sizeof(struct dccp_hdr_ext) +
 				     sizeof(struct dccp_hdr_response);
-	struct sk_buff *skb = sock_wmalloc(sk, sk->sk_prot->max_header, 1,
-					   GFP_ATOMIC);
-	if (skb == NULL)
+	struct sk_buff *skb;
+
+	/* sk is marked const to clearly express we dont hold socket lock.
+	 * sock_wmalloc() will atomically change sk->sk_wmem_alloc,
+	 * it is safe to promote sk to non const.
+	 */
+	skb = sock_wmalloc((struct sock *)sk, MAX_DCCP_HEADER, 1,
+			   GFP_ATOMIC);
+	if (!skb)
 		return NULL;
 
-	/* Reserve space for headers. */
-	skb_reserve(skb, sk->sk_prot->max_header);
+	skb_reserve(skb, MAX_DCCP_HEADER);
 
 	skb_dst_set(skb, dst_clone(dst));
 

commit b0270e91014dabfceaf37f5b40ad51bbf21a1302
Author: Eric Dumazet <edumazet@google.com>
Date:   Tue Apr 15 12:58:34 2014 -0400

    ipv4: add a sock pointer to ip_queue_xmit()
    
    ip_queue_xmit() assumes the skb it has to transmit is attached to an
    inet socket. Commit 31c70d5956fc ("l2tp: keep original skb ownership")
    changed l2tp to not change skb ownership and thus broke this assumption.
    
    One fix is to add a new 'struct sock *sk' parameter to ip_queue_xmit(),
    so that we do not assume skb->sk points to the socket used by l2tp
    tunnel.
    
    Fixes: 31c70d5956fc ("l2tp: keep original skb ownership")
    Reported-by: Zhan Jianyu <nasa4836@gmail.com>
    Tested-by: Zhan Jianyu <nasa4836@gmail.com>
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index 8876078859da..0248e8a3460c 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -138,7 +138,7 @@ static int dccp_transmit_skb(struct sock *sk, struct sk_buff *skb)
 
 		DCCP_INC_STATS(DCCP_MIB_OUTSEGS);
 
-		err = icsk->icsk_af_ops->queue_xmit(skb, &inet->cork.fl);
+		err = icsk->icsk_af_ops->queue_xmit(sk, skb, &inet->cork.fl);
 		return net_xmit_eval(err);
 	}
 	return -ENOBUFS;

commit b44084c2c822f99dd3f2334b288b7e463d222662
Author: Eric Dumazet <edumazet@google.com>
Date:   Thu Oct 10 00:04:37 2013 -0700

    inet: rename ir_loc_port to ir_num
    
    In commit 634fb979e8f ("inet: includes a sock_common in request_sock")
    I forgot that the two ports in sock_common do not have same byte order :
    
    skc_dport is __be16 (network order), but skc_num is __u16 (host order)
    
    So sparse complains because ir_loc_port (mapped into skc_num) is
    considered as __u16 while it should be __be16
    
    Let rename ir_loc_port to ireq->ir_num (analogy with inet->inet_num),
    and perform appropriate htons/ntohs conversions.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: Wu Fengguang <fengguang.wu@intel.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index 9bf195d1b87a..8876078859da 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -424,7 +424,7 @@ struct sk_buff *dccp_make_response(struct sock *sk, struct dst_entry *dst,
 	/* Build and checksum header */
 	dh = dccp_zeroed_hdr(skb, dccp_header_size);
 
-	dh->dccph_sport	= inet_rsk(req)->ir_loc_port;
+	dh->dccph_sport	= htons(inet_rsk(req)->ir_num);
 	dh->dccph_dport	= inet_rsk(req)->ir_rmt_port;
 	dh->dccph_doff	= (dccp_header_size +
 			   DCCP_SKB_CB(skb)->dccpd_opt_len) / 4;

commit 634fb979e8f3a70f04c1f2f519d0cd1142eb5c1a
Author: Eric Dumazet <edumazet@google.com>
Date:   Wed Oct 9 15:21:29 2013 -0700

    inet: includes a sock_common in request_sock
    
    TCP listener refactoring, part 5 :
    
    We want to be able to insert request sockets (SYN_RECV) into main
    ehash table instead of the per listener hash table to allow RCU
    lookups and remove listener lock contention.
    
    This patch includes the needed struct sock_common in front
    of struct request_sock
    
    This means there is no more inet6_request_sock IPv6 specific
    structure.
    
    Following inet_request_sock fields were renamed as they became
    macros to reference fields from struct sock_common.
    Prefix ir_ was chosen to avoid name collisions.
    
    loc_port   -> ir_loc_port
    loc_addr   -> ir_loc_addr
    rmt_addr   -> ir_rmt_addr
    rmt_port   -> ir_rmt_port
    iif        -> ir_iif
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index d17fc90a74b6..9bf195d1b87a 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -424,8 +424,8 @@ struct sk_buff *dccp_make_response(struct sock *sk, struct dst_entry *dst,
 	/* Build and checksum header */
 	dh = dccp_zeroed_hdr(skb, dccp_header_size);
 
-	dh->dccph_sport	= inet_rsk(req)->loc_port;
-	dh->dccph_dport	= inet_rsk(req)->rmt_port;
+	dh->dccph_sport	= inet_rsk(req)->ir_loc_port;
+	dh->dccph_dport	= inet_rsk(req)->ir_rmt_port;
 	dh->dccph_doff	= (dccp_header_size +
 			   DCCP_SKB_CB(skb)->dccpd_opt_len) / 4;
 	dh->dccph_type	= DCCP_PKT_RESPONSE;

commit 2c53040f018b6c36a46eec75b9b937aaa5f78e6d
Author: Ben Hutchings <bhutchings@solarflare.com>
Date:   Tue Jul 10 10:55:09 2012 +0000

    net: Fix (nearly-)kernel-doc comments for various functions
    
    Fix incorrect start markers, wrapped summary lines, missing section
    breaks, incorrect separators, and some name mismatches.
    
    Signed-off-by: Ben Hutchings <bhutchings@solarflare.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index 787367308797..d17fc90a74b6 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -214,6 +214,7 @@ void dccp_write_space(struct sock *sk)
  * dccp_wait_for_ccid  -  Await CCID send permission
  * @sk:    socket to wait for
  * @delay: timeout in jiffies
+ *
  * This is used by CCIDs which need to delay the send time in process context.
  */
 static int dccp_wait_for_ccid(struct sock *sk, unsigned long delay)

commit f541fb7e20c848f947ca65fbf169efe69400c942
Author: Samuel Jero <sj323707@ohio.edu>
Date:   Sun Feb 26 18:22:02 2012 -0700

    dccp: fix bug in sequence number validation during connection setup
    
    This fixes a bug in the sequence number validation during the initial handshake.
    
    The code did not treat the initial sequence numbers ISS and ISR as read-only and
    did not keep state for GSR and GSS as required by the specification. This causes
    problems with retransmissions during the initial handshake, causing the
    budding connection to be reset.
    
    This patch now treats ISS/ISR as read-only and tracks GSS/GSR as required.
    
    Signed-off-by: Samuel Jero <sj323707@ohio.edu>
    Signed-off-by: Gerrit Renker <gerrit@erg.abdn.ac.uk>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index dede3edb8849..787367308797 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -408,10 +408,10 @@ struct sk_buff *dccp_make_response(struct sock *sk, struct dst_entry *dst,
 	skb_dst_set(skb, dst_clone(dst));
 
 	dreq = dccp_rsk(req);
-	if (inet_rsk(req)->acked)	/* increase ISS upon retransmission */
-		dccp_inc_seqno(&dreq->dreq_iss);
+	if (inet_rsk(req)->acked)	/* increase GSS upon retransmission */
+		dccp_inc_seqno(&dreq->dreq_gss);
 	DCCP_SKB_CB(skb)->dccpd_type = DCCP_PKT_RESPONSE;
-	DCCP_SKB_CB(skb)->dccpd_seq  = dreq->dreq_iss;
+	DCCP_SKB_CB(skb)->dccpd_seq  = dreq->dreq_gss;
 
 	/* Resolve feature dependencies resulting from choice of CCID */
 	if (dccp_feat_server_ccid_dependencies(dreq))
@@ -429,8 +429,8 @@ struct sk_buff *dccp_make_response(struct sock *sk, struct dst_entry *dst,
 			   DCCP_SKB_CB(skb)->dccpd_opt_len) / 4;
 	dh->dccph_type	= DCCP_PKT_RESPONSE;
 	dh->dccph_x	= 1;
-	dccp_hdr_set_seq(dh, dreq->dreq_iss);
-	dccp_hdr_set_ack(dccp_hdr_ack_bits(skb), dreq->dreq_isr);
+	dccp_hdr_set_seq(dh, dreq->dreq_gss);
+	dccp_hdr_set_ack(dccp_hdr_ack_bits(skb), dreq->dreq_gsr);
 	dccp_hdr_response(skb)->dccph_resp_service = dreq->dreq_service;
 
 	dccp_csum_outgoing(skb);

commit 8695e80193fed35f27c06f462bd5b76132fd5697
Author: Gerrit Renker <gerrit@erg.abdn.ac.uk>
Date:   Sun Jul 3 09:51:29 2011 -0600

    dccp: combine the functionality of enqeueing and cloning
    
    Realising the following call pattern,
     * first dccp_entail() is called to enqueue a new skb and
     * then skb_clone() is called to transmit a clone of that skb,
    this patch integrates both into the same function.
    
    Signed-off-by: Gerrit Renker <gerrit@erg.abdn.ac.uk>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index fab108e51e5a..dede3edb8849 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -27,11 +27,13 @@ static inline void dccp_event_ack_sent(struct sock *sk)
 	inet_csk_clear_xmit_timer(sk, ICSK_TIME_DACK);
 }
 
-static void dccp_skb_entail(struct sock *sk, struct sk_buff *skb)
+/* enqueue @skb on sk_send_head for retransmission, return clone to send now */
+static struct sk_buff *dccp_skb_entail(struct sock *sk, struct sk_buff *skb)
 {
 	skb_set_owner_w(skb, sk);
 	WARN_ON(sk->sk_send_head);
 	sk->sk_send_head = skb;
+	return skb_clone(sk->sk_send_head, gfp_any());
 }
 
 /*
@@ -552,8 +554,7 @@ int dccp_connect(struct sock *sk)
 
 	DCCP_SKB_CB(skb)->dccpd_type = DCCP_PKT_REQUEST;
 
-	dccp_skb_entail(sk, skb);
-	dccp_transmit_skb(sk, skb_clone(skb, GFP_KERNEL));
+	dccp_transmit_skb(sk, dccp_skb_entail(sk, skb));
 	DCCP_INC_STATS(DCCP_MIB_ACTIVEOPENS);
 
 	/* Timer for repeating the REQUEST until an answer. */
@@ -678,8 +679,7 @@ void dccp_send_close(struct sock *sk, const int active)
 		DCCP_SKB_CB(skb)->dccpd_type = DCCP_PKT_CLOSE;
 
 	if (active) {
-		dccp_skb_entail(sk, skb);
-		dccp_transmit_skb(sk, skb_clone(skb, prio));
+		skb = dccp_skb_entail(sk, skb);
 		/*
 		 * Retransmission timer for active-close: RFC 4340, 8.3 requires
 		 * to retransmit the Close/CloseReq until the CLOSING/CLOSEREQ
@@ -692,6 +692,6 @@ void dccp_send_close(struct sock *sk, const int active)
 		 */
 		inet_csk_reset_xmit_timer(sk, ICSK_TIME_RETRANS,
 					  DCCP_TIMEOUT_INIT, DCCP_RTO_MAX);
-	} else
-		dccp_transmit_skb(sk, skb);
+	}
+	dccp_transmit_skb(sk, skb);
 }

commit d9d8da805dcb503ef8ee49918a94d49085060f23
Author: David S. Miller <davem@davemloft.net>
Date:   Fri May 6 22:23:20 2011 -0700

    inet: Pass flowi to ->queue_xmit().
    
    This allows us to acquire the exact route keying information from the
    protocol, however that might be managed.
    
    It handles all of the possibilities, from the simplest case of storing
    the key in inet->cork.fl to the more complex setup SCTP has where
    individual transports determine the flow.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index 136d41cbcd02..fab108e51e5a 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -43,7 +43,7 @@ static void dccp_skb_entail(struct sock *sk, struct sk_buff *skb)
 static int dccp_transmit_skb(struct sock *sk, struct sk_buff *skb)
 {
 	if (likely(skb != NULL)) {
-		const struct inet_sock *inet = inet_sk(sk);
+		struct inet_sock *inet = inet_sk(sk);
 		const struct inet_connection_sock *icsk = inet_csk(sk);
 		struct dccp_sock *dp = dccp_sk(sk);
 		struct dccp_skb_cb *dcb = DCCP_SKB_CB(skb);
@@ -136,7 +136,7 @@ static int dccp_transmit_skb(struct sock *sk, struct sk_buff *skb)
 
 		DCCP_INC_STATS(DCCP_MIB_OUTSEGS);
 
-		err = icsk->icsk_af_ops->queue_xmit(skb);
+		err = icsk->icsk_af_ops->queue_xmit(skb, &inet->cork.fl);
 		return net_xmit_eval(err);
 	}
 	return -ENOBUFS;

commit 25985edcedea6396277003854657b5f3cb31a628
Author: Lucas De Marchi <lucas.demarchi@profusion.mobi>
Date:   Wed Mar 30 22:57:33 2011 -0300

    Fix common misspellings
    
    Fixes generated by 'codespell' and manually reviewed.
    
    Signed-off-by: Lucas De Marchi <lucas.demarchi@profusion.mobi>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index 784d30210543..136d41cbcd02 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -143,7 +143,7 @@ static int dccp_transmit_skb(struct sock *sk, struct sk_buff *skb)
 }
 
 /**
- * dccp_determine_ccmps  -  Find out about CCID-specfic packet-size limits
+ * dccp_determine_ccmps  -  Find out about CCID-specific packet-size limits
  * We only consider the HC-sender CCID for setting the CCMPS (RFC 4340, 14.),
  * since the RX CCID is restricted to feedback packets (Acks), which are small
  * in comparison with the data traffic. A value of 0 means "no current CCMPS".

commit 871a2c16c21b988688b4ab1a78eadd969765c0a3
Author: Tomasz Grobelny <tomasz@grobelny.oswiecenia.net>
Date:   Sat Dec 4 13:38:01 2010 +0100

    dccp: Policy-based packet dequeueing infrastructure
    
    This patch adds a generic infrastructure for policy-based dequeueing of
    TX packets and provides two policies:
     * a simple FIFO policy (which is the default) and
     * a priority based policy (set via socket options).
    Both policies honour the tx_qlen sysctl for the maximum size of the write
    queue (can be overridden via socket options).
    
    The priority policy uses skb->priority internally to assign an u32 priority
    identifier, using the same ranking as SO_PRIORITY. The skb->priority field
    is set to 0 when the packet leaves DCCP. The priority is supplied as ancillary
    data using cmsg(3), the patch also provides the requisite parsing routines.
    
    Signed-off-by: Tomasz Grobelny <tomasz@grobelny.oswiecenia.net>
    Signed-off-by: Gerrit Renker <gerrit@erg.abdn.ac.uk>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index d96dd9d362ae..784d30210543 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -242,7 +242,7 @@ static void dccp_xmit_packet(struct sock *sk)
 {
 	int err, len;
 	struct dccp_sock *dp = dccp_sk(sk);
-	struct sk_buff *skb = skb_dequeue(&sk->sk_write_queue);
+	struct sk_buff *skb = dccp_qpolicy_pop(sk);
 
 	if (unlikely(skb == NULL))
 		return;
@@ -345,7 +345,7 @@ void dccp_write_xmit(struct sock *sk)
 	struct dccp_sock *dp = dccp_sk(sk);
 	struct sk_buff *skb;
 
-	while ((skb = skb_peek(&sk->sk_write_queue))) {
+	while ((skb = dccp_qpolicy_top(sk))) {
 		int rc = ccid_hc_tx_send_packet(dp->dccps_hc_tx_ccid, sk, skb);
 
 		switch (ccid_packet_dequeue_eval(rc)) {
@@ -359,8 +359,7 @@ void dccp_write_xmit(struct sock *sk)
 			dccp_xmit_packet(sk);
 			break;
 		case CCID_PACKET_ERR:
-			skb_dequeue(&sk->sk_write_queue);
-			kfree_skb(skb);
+			dccp_qpolicy_drop(sk, skb);
 			dccp_pr_debug("packet discarded due to err=%d\n", rc);
 		}
 	}

commit d83447f0944e73d690218d79c07762ffa4ceb9e4
Author: Gerrit Renker <gerrit@erg.abdn.ac.uk>
Date:   Sun Nov 14 17:25:46 2010 +0100

    dccp ccid-2: Schedule Sync as out-of-band mechanism
    
    The problem with Ack Vectors is that
      i) their length is variable and can in principle grow quite large,
     ii) it is hard to predict exactly how large they will be.
    
    Due to the second point it seems not a good idea to reduce the MPS; in
    particular when on average there is enough room for the Ack Vector and an
    increase in length is momentarily due to some burst loss, after which the
    Ack Vector returns to its normal/average length.
    
    The solution taken by this patch is to subtract a minimum-expected Ack Vector
    length from the MPS, and to defer any larger Ack Vectors onto a separate
    Sync - but only if indeed there is no space left on the skb.
    
    This patch provides the infrastructure to schedule Sync-packets for transporting
    (urgent) out-of-band data. Its signalling is quicker than scheduling an Ack, since
    it does not need to wait for new application data.
    
    Signed-off-by: Gerrit Renker <gerrit@erg.abdn.ac.uk>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index 45b91853f5ae..d96dd9d362ae 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -283,6 +283,15 @@ static void dccp_xmit_packet(struct sock *sk)
 	 * any local drop will eventually be reported via receiver feedback.
 	 */
 	ccid_hc_tx_packet_sent(dp->dccps_hc_tx_ccid, sk, len);
+
+	/*
+	 * If the CCID needs to transfer additional header options out-of-band
+	 * (e.g. Ack Vectors or feature-negotiation options), it activates this
+	 * flag to schedule a Sync. The Sync will automatically incorporate all
+	 * currently pending header options, thus clearing the backlog.
+	 */
+	if (dp->dccps_sync_scheduled)
+		dccp_send_sync(sk, dp->dccps_gsr, DCCP_PKT_SYNC);
 }
 
 /**
@@ -636,6 +645,12 @@ void dccp_send_sync(struct sock *sk, const u64 ackno,
 	DCCP_SKB_CB(skb)->dccpd_type = pkt_type;
 	DCCP_SKB_CB(skb)->dccpd_ack_seq = ackno;
 
+	/*
+	 * Clear the flag in case the Sync was scheduled for out-of-band data,
+	 * such as carrying a long Ack Vector.
+	 */
+	dccp_sk(sk)->dccps_sync_scheduled = 0;
+
 	dccp_transmit_skb(sk, skb);
 }
 

commit b1fcf55eea541af9efa5d39f5a0d1aec8ceca55d
Author: Gerrit Renker <gerrit@erg.abdn.ac.uk>
Date:   Wed Oct 27 19:16:27 2010 +0000

    dccp: Refine the wait-for-ccid mechanism
    
    This extends the existing wait-for-ccid routine so that it may be used with
    different types of CCID, addressing the following problems:
    
     1) The queue-drain mechanism only works with rate-based CCIDs. If CCID-2 for
        example has a full TX queue and becomes network-limited just as the
        application wants to close, then waiting for CCID-2 to become unblocked
        could lead to an indefinite  delay (i.e., application "hangs").
     2) Since each TX CCID in turn uses a feedback mechanism, there may be changes
        in its sending policy while the queue is being drained. This can lead to
        further delays during which the application will not be able to terminate.
     3) The minimum wait time for CCID-3/4 can be expected to be the queue length
        times the current inter-packet delay. For example if tx_qlen=100 and a delay
        of 15 ms is used for each packet, then the application would have to wait
        for a minimum of 1.5 seconds before being allowed to exit.
     4) There is no way for the user/application to control this behaviour. It would
        be good to use the timeout argument of dccp_close() as an upper bound. Then
        the maximum time that an application is willing to wait for its CCIDs to can
        be set via the SO_LINGER option.
    
    These problems are addressed by giving the CCID a grace period of up to the
    `timeout' value.
    
    The wait-for-ccid function is, as before, used when the application
     (a) has read all the data in its receive buffer and
     (b) if SO_LINGER was set with a non-zero linger time, or
     (c) the socket is either in the OPEN (active close) or in the PASSIVE_CLOSEREQ
         state (client application closes after receiving CloseReq).
    
    In addition, there is a catch-all case of __skb_queue_purge() after waiting for
    the CCID. This is necessary since the write queue may still have data when
     (a) the host has been passively-closed,
     (b) abnormal termination (unread data, zero linger time),
     (c) wait-for-ccid could not finish within the given time limit.
    
    Signed-off-by: Gerrit Renker <gerrit@erg.abdn.ac.uk>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index 11418a9a389d..45b91853f5ae 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -209,49 +209,29 @@ void dccp_write_space(struct sock *sk)
 }
 
 /**
- * dccp_wait_for_ccid - Wait for ccid to tell us we can send a packet
+ * dccp_wait_for_ccid  -  Await CCID send permission
  * @sk:    socket to wait for
- * @skb:   current skb to pass on for waiting
- * @delay: sleep timeout in milliseconds (> 0)
- * This function is called by default when the socket is closed, and
- * when a non-zero linger time is set on the socket. For consistency
+ * @delay: timeout in jiffies
+ * This is used by CCIDs which need to delay the send time in process context.
  */
-static int dccp_wait_for_ccid(struct sock *sk, struct sk_buff *skb, int delay)
+static int dccp_wait_for_ccid(struct sock *sk, unsigned long delay)
 {
-	struct dccp_sock *dp = dccp_sk(sk);
 	DEFINE_WAIT(wait);
-	unsigned long jiffdelay;
-	int rc;
-
-	do {
-		dccp_pr_debug("delayed send by %d msec\n", delay);
-		jiffdelay = msecs_to_jiffies(delay);
-
-		prepare_to_wait(sk_sleep(sk), &wait, TASK_INTERRUPTIBLE);
+	long remaining;
 
-		sk->sk_write_pending++;
-		release_sock(sk);
-		schedule_timeout(jiffdelay);
-		lock_sock(sk);
-		sk->sk_write_pending--;
+	prepare_to_wait(sk_sleep(sk), &wait, TASK_INTERRUPTIBLE);
+	sk->sk_write_pending++;
+	release_sock(sk);
 
-		if (sk->sk_err)
-			goto do_error;
-		if (signal_pending(current))
-			goto do_interrupted;
+	remaining = schedule_timeout(delay);
 
-		rc = ccid_hc_tx_send_packet(dp->dccps_hc_tx_ccid, sk, skb);
-	} while ((delay = rc) > 0);
-out:
+	lock_sock(sk);
+	sk->sk_write_pending--;
 	finish_wait(sk_sleep(sk), &wait);
-	return rc;
-
-do_error:
-	rc = -EPIPE;
-	goto out;
-do_interrupted:
-	rc = -EINTR;
-	goto out;
+
+	if (signal_pending(current) || sk->sk_err)
+		return -1;
+	return remaining;
 }
 
 /**
@@ -305,7 +285,53 @@ static void dccp_xmit_packet(struct sock *sk)
 	ccid_hc_tx_packet_sent(dp->dccps_hc_tx_ccid, sk, len);
 }
 
-void dccp_write_xmit(struct sock *sk, int block)
+/**
+ * dccp_flush_write_queue  -  Drain queue at end of connection
+ * Since dccp_sendmsg queues packets without waiting for them to be sent, it may
+ * happen that the TX queue is not empty at the end of a connection. We give the
+ * HC-sender CCID a grace period of up to @time_budget jiffies. If this function
+ * returns with a non-empty write queue, it will be purged later.
+ */
+void dccp_flush_write_queue(struct sock *sk, long *time_budget)
+{
+	struct dccp_sock *dp = dccp_sk(sk);
+	struct sk_buff *skb;
+	long delay, rc;
+
+	while (*time_budget > 0 && (skb = skb_peek(&sk->sk_write_queue))) {
+		rc = ccid_hc_tx_send_packet(dp->dccps_hc_tx_ccid, sk, skb);
+
+		switch (ccid_packet_dequeue_eval(rc)) {
+		case CCID_PACKET_WILL_DEQUEUE_LATER:
+			/*
+			 * If the CCID determines when to send, the next sending
+			 * time is unknown or the CCID may not even send again
+			 * (e.g. remote host crashes or lost Ack packets).
+			 */
+			DCCP_WARN("CCID did not manage to send all packets\n");
+			return;
+		case CCID_PACKET_DELAY:
+			delay = msecs_to_jiffies(rc);
+			if (delay > *time_budget)
+				return;
+			rc = dccp_wait_for_ccid(sk, delay);
+			if (rc < 0)
+				return;
+			*time_budget -= (delay - rc);
+			/* check again if we can send now */
+			break;
+		case CCID_PACKET_SEND_AT_ONCE:
+			dccp_xmit_packet(sk);
+			break;
+		case CCID_PACKET_ERR:
+			skb_dequeue(&sk->sk_write_queue);
+			kfree_skb(skb);
+			dccp_pr_debug("packet discarded due to err=%ld\n", rc);
+		}
+	}
+}
+
+void dccp_write_xmit(struct sock *sk)
 {
 	struct dccp_sock *dp = dccp_sk(sk);
 	struct sk_buff *skb;
@@ -317,19 +343,9 @@ void dccp_write_xmit(struct sock *sk, int block)
 		case CCID_PACKET_WILL_DEQUEUE_LATER:
 			return;
 		case CCID_PACKET_DELAY:
-			if (!block) {
-				sk_reset_timer(sk, &dp->dccps_xmit_timer,
-						msecs_to_jiffies(rc)+jiffies);
-				return;
-			}
-			rc = dccp_wait_for_ccid(sk, skb, rc);
-			if (rc && rc != -EINTR) {
-				DCCP_BUG("err=%d after dccp_wait_for_ccid", rc);
-				skb_dequeue(&sk->sk_write_queue);
-				kfree_skb(skb);
-				break;
-			}
-			/* fall through */
+			sk_reset_timer(sk, &dp->dccps_xmit_timer,
+				       jiffies + msecs_to_jiffies(rc));
+			return;
 		case CCID_PACKET_SEND_AT_ONCE:
 			dccp_xmit_packet(sk);
 			break;
@@ -648,7 +664,6 @@ void dccp_send_close(struct sock *sk, const int active)
 		DCCP_SKB_CB(skb)->dccpd_type = DCCP_PKT_CLOSE;
 
 	if (active) {
-		dccp_write_xmit(sk, 1);
 		dccp_skb_entail(sk, skb);
 		dccp_transmit_skb(sk, skb_clone(skb, prio));
 		/*

commit dc841e30eaea9f9f83c9ab1ee0b3ef9e5c95ce8a
Author: Gerrit Renker <gerrit@erg.abdn.ac.uk>
Date:   Wed Oct 27 19:16:26 2010 +0000

    dccp: Extend CCID packet dequeueing interface
    
    This extends the packet dequeuing interface of dccp_write_xmit() to allow
     1. CCIDs to take care of timing when the next packet may be sent;
     2. delayed sending (as before, with an inter-packet gap up to 65.535 seconds).
    
    The main purpose is to take CCID-2 out of its polling mode (when it is network-
    limited, it tries every millisecond to send, without interruption).
    
    The mode of operation for (2) is as follows:
     * new packet is enqueued via dccp_sendmsg() => dccp_write_xmit(),
     * ccid_hc_tx_send_packet() detects that it may not send (e.g. window full),
     * it signals this condition via `CCID_PACKET_WILL_DEQUEUE_LATER',
     * dccp_write_xmit() returns without further action;
     * after some time the wait-condition for CCID becomes true,
     * that CCID schedules the tasklet,
     * tasklet function calls ccid_hc_tx_send_packet() via dccp_write_xmit(),
     * since the wait-condition is now true, ccid_hc_tx_packet() returns "send now",
     * packet is sent, and possibly more (since dccp_write_xmit() loops).
    
    Code reuse: the taskled function calls dccp_write_xmit(), the timer function
                reduces to a wrapper around the same code.
    
    Signed-off-by: Gerrit Renker <gerrit@erg.abdn.ac.uk>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index a988fe9ffcba..11418a9a389d 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -254,63 +254,89 @@ static int dccp_wait_for_ccid(struct sock *sk, struct sk_buff *skb, int delay)
 	goto out;
 }
 
+/**
+ * dccp_xmit_packet  -  Send data packet under control of CCID
+ * Transmits next-queued payload and informs CCID to account for the packet.
+ */
+static void dccp_xmit_packet(struct sock *sk)
+{
+	int err, len;
+	struct dccp_sock *dp = dccp_sk(sk);
+	struct sk_buff *skb = skb_dequeue(&sk->sk_write_queue);
+
+	if (unlikely(skb == NULL))
+		return;
+	len = skb->len;
+
+	if (sk->sk_state == DCCP_PARTOPEN) {
+		const u32 cur_mps = dp->dccps_mss_cache - DCCP_FEATNEG_OVERHEAD;
+		/*
+		 * See 8.1.5 - Handshake Completion.
+		 *
+		 * For robustness we resend Confirm options until the client has
+		 * entered OPEN. During the initial feature negotiation, the MPS
+		 * is smaller than usual, reduced by the Change/Confirm options.
+		 */
+		if (!list_empty(&dp->dccps_featneg) && len > cur_mps) {
+			DCCP_WARN("Payload too large (%d) for featneg.\n", len);
+			dccp_send_ack(sk);
+			dccp_feat_list_purge(&dp->dccps_featneg);
+		}
+
+		inet_csk_schedule_ack(sk);
+		inet_csk_reset_xmit_timer(sk, ICSK_TIME_DACK,
+					      inet_csk(sk)->icsk_rto,
+					      DCCP_RTO_MAX);
+		DCCP_SKB_CB(skb)->dccpd_type = DCCP_PKT_DATAACK;
+	} else if (dccp_ack_pending(sk)) {
+		DCCP_SKB_CB(skb)->dccpd_type = DCCP_PKT_DATAACK;
+	} else {
+		DCCP_SKB_CB(skb)->dccpd_type = DCCP_PKT_DATA;
+	}
+
+	err = dccp_transmit_skb(sk, skb);
+	if (err)
+		dccp_pr_debug("transmit_skb() returned err=%d\n", err);
+	/*
+	 * Register this one as sent even if an error occurred. To the remote
+	 * end a local packet drop is indistinguishable from network loss, i.e.
+	 * any local drop will eventually be reported via receiver feedback.
+	 */
+	ccid_hc_tx_packet_sent(dp->dccps_hc_tx_ccid, sk, len);
+}
+
 void dccp_write_xmit(struct sock *sk, int block)
 {
 	struct dccp_sock *dp = dccp_sk(sk);
 	struct sk_buff *skb;
 
 	while ((skb = skb_peek(&sk->sk_write_queue))) {
-		int err = ccid_hc_tx_send_packet(dp->dccps_hc_tx_ccid, sk, skb);
+		int rc = ccid_hc_tx_send_packet(dp->dccps_hc_tx_ccid, sk, skb);
 
-		if (err > 0) {
+		switch (ccid_packet_dequeue_eval(rc)) {
+		case CCID_PACKET_WILL_DEQUEUE_LATER:
+			return;
+		case CCID_PACKET_DELAY:
 			if (!block) {
 				sk_reset_timer(sk, &dp->dccps_xmit_timer,
-						msecs_to_jiffies(err)+jiffies);
+						msecs_to_jiffies(rc)+jiffies);
+				return;
+			}
+			rc = dccp_wait_for_ccid(sk, skb, rc);
+			if (rc && rc != -EINTR) {
+				DCCP_BUG("err=%d after dccp_wait_for_ccid", rc);
+				skb_dequeue(&sk->sk_write_queue);
+				kfree_skb(skb);
 				break;
-			} else
-				err = dccp_wait_for_ccid(sk, skb, err);
-			if (err && err != -EINTR)
-				DCCP_BUG("err=%d after dccp_wait_for_ccid", err);
-		}
-
-		skb_dequeue(&sk->sk_write_queue);
-		if (err == 0) {
-			struct dccp_skb_cb *dcb = DCCP_SKB_CB(skb);
-			const int len = skb->len;
-
-			if (sk->sk_state == DCCP_PARTOPEN) {
-				const u32 cur_mps = dp->dccps_mss_cache - DCCP_FEATNEG_OVERHEAD;
-				/*
-				 * See 8.1.5 - Handshake Completion.
-				 *
-				 * For robustness we resend Confirm options until the client has
-				 * entered OPEN. During the initial feature negotiation, the MPS
-				 * is smaller than usual, reduced by the Change/Confirm options.
-				 */
-				if (!list_empty(&dp->dccps_featneg) && len > cur_mps) {
-					DCCP_WARN("Payload too large (%d) for featneg.\n", len);
-					dccp_send_ack(sk);
-					dccp_feat_list_purge(&dp->dccps_featneg);
-				}
-
-				inet_csk_schedule_ack(sk);
-				inet_csk_reset_xmit_timer(sk, ICSK_TIME_DACK,
-						  inet_csk(sk)->icsk_rto,
-						  DCCP_RTO_MAX);
-				dcb->dccpd_type = DCCP_PKT_DATAACK;
-			} else if (dccp_ack_pending(sk))
-				dcb->dccpd_type = DCCP_PKT_DATAACK;
-			else
-				dcb->dccpd_type = DCCP_PKT_DATA;
-
-			err = dccp_transmit_skb(sk, skb);
-			ccid_hc_tx_packet_sent(dp->dccps_hc_tx_ccid, sk, len);
-			if (err)
-				DCCP_BUG("err=%d after ccid_hc_tx_packet_sent",
-					 err);
-		} else {
-			dccp_pr_debug("packet discarded due to err=%d\n", err);
+			}
+			/* fall through */
+		case CCID_PACKET_SEND_AT_ONCE:
+			dccp_xmit_packet(sk);
+			break;
+		case CCID_PACKET_ERR:
+			skb_dequeue(&sk->sk_write_queue);
 			kfree_skb(skb);
+			dccp_pr_debug("packet discarded due to err=%d\n", rc);
 		}
 	}
 }

commit baf9e782e1dc4991edecfa3b8700cf8739c40259
Author: Gerrit Renker <gerrit@erg.abdn.ac.uk>
Date:   Mon Oct 11 20:37:38 2010 +0200

    dccp: remove unused argument in CCID tx function
    
    This removes the argument `more' from ccid_hc_tx_packet_sent, since it was
    nowhere used in the entire code.
    
    (Btw, this argument was not even used in the original KAME code where the
     function initially came from; compare the variable moreToSend in the
     freebsd61-dccp-kame-28.08.2006.patch kept by Emmanuel Lochin.)
    
    Signed-off-by: Gerrit Renker <gerrit@erg.abdn.ac.uk>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index 6993a9338cf7..a988fe9ffcba 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -304,7 +304,7 @@ void dccp_write_xmit(struct sock *sk, int block)
 				dcb->dccpd_type = DCCP_PKT_DATA;
 
 			err = dccp_transmit_skb(sk, skb);
-			ccid_hc_tx_packet_sent(dp->dccps_hc_tx_ccid, sk, 0, len);
+			ccid_hc_tx_packet_sent(dp->dccps_hc_tx_ccid, sk, len);
 			if (err)
 				DCCP_BUG("err=%d after ccid_hc_tx_packet_sent",
 					 err);

commit 93344af44c0f649582bf1e3b5ecc45b3d19e98c2
Author: Gerrit Renker <gerrit@erg.abdn.ac.uk>
Date:   Mon Oct 11 20:36:33 2010 +0200

    dccp: merge now-reduced connect_init() function
    
    After moving the assignment of GAR/ISS from dccp_connect_init() to
    dccp_transmit_skb(), the former function becomes very small, so that
    a merger with dccp_connect() suggests itself.
    
    Signed-off-by: Gerrit Renker <gerrit@erg.abdn.ac.uk>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index aadbdb58758b..6993a9338cf7 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -474,8 +474,9 @@ int dccp_send_reset(struct sock *sk, enum dccp_reset_codes code)
 /*
  * Do all connect socket setups that can be done AF independent.
  */
-static inline void dccp_connect_init(struct sock *sk)
+int dccp_connect(struct sock *sk)
 {
+	struct sk_buff *skb;
 	struct dccp_sock *dp = dccp_sk(sk);
 	struct dst_entry *dst = __sk_dst_get(sk);
 	struct inet_connection_sock *icsk = inet_csk(sk);
@@ -485,22 +486,12 @@ static inline void dccp_connect_init(struct sock *sk)
 
 	dccp_sync_mss(sk, dst_mtu(dst));
 
-	/* Initialise GAR as per 8.5; AWL/AWH are set in dccp_transmit_skb() */
-	dp->dccps_gar = dp->dccps_iss;
-
-	icsk->icsk_retransmits = 0;
-}
-
-int dccp_connect(struct sock *sk)
-{
-	struct sk_buff *skb;
-	struct inet_connection_sock *icsk = inet_csk(sk);
-
 	/* do not connect if feature negotiation setup fails */
 	if (dccp_feat_finalise_settings(dccp_sk(sk)))
 		return -EPROTO;
 
-	dccp_connect_init(sk);
+	/* Initialise GAR as per 8.5; AWL/AWH are set in dccp_transmit_skb() */
+	dp->dccps_gar = dp->dccps_iss;
 
 	skb = alloc_skb(sk->sk_prot->max_header, sk->sk_allocation);
 	if (unlikely(skb == NULL))
@@ -516,6 +507,7 @@ int dccp_connect(struct sock *sk)
 	DCCP_INC_STATS(DCCP_MIB_ACTIVEOPENS);
 
 	/* Timer for repeating the REQUEST until an answer. */
+	icsk->icsk_retransmits = 0;
 	inet_csk_reset_xmit_timer(sk, ICSK_TIME_RETRANS,
 				  icsk->icsk_rto, DCCP_RTO_MAX);
 	return 0;

commit 43815482370c510c569fd18edb57afcb0fa8cab6
Author: Eric Dumazet <eric.dumazet@gmail.com>
Date:   Thu Apr 29 11:01:49 2010 +0000

    net: sock_def_readable() and friends RCU conversion
    
    sk_callback_lock rwlock actually protects sk->sk_sleep pointer, so we
    need two atomic operations (and associated dirtying) per incoming
    packet.
    
    RCU conversion is pretty much needed :
    
    1) Add a new structure, called "struct socket_wq" to hold all fields
    that will need rcu_read_lock() protection (currently: a
    wait_queue_head_t and a struct fasync_struct pointer).
    
    [Future patch will add a list anchor for wakeup coalescing]
    
    2) Attach one of such structure to each "struct socket" created in
    sock_alloc_inode().
    
    3) Respect RCU grace period when freeing a "struct socket_wq"
    
    4) Change sk_sleep pointer in "struct sock" by sk_wq, pointer to "struct
    socket_wq"
    
    5) Change sk_sleep() function to use new sk->sk_wq instead of
    sk->sk_sleep
    
    6) Change sk_has_sleeper() to wq_has_sleeper() that must be used inside
    a rcu_read_lock() section.
    
    7) Change all sk_has_sleeper() callers to :
      - Use rcu_read_lock() instead of read_lock(&sk->sk_callback_lock)
      - Use wq_has_sleeper() to eventually wakeup tasks.
      - Use rcu_read_unlock() instead of read_unlock(&sk->sk_callback_lock)
    
    8) sock_wake_async() is modified to use rcu protection as well.
    
    9) Exceptions :
      macvtap, drivers/net/tun.c, af_unix use integrated "struct socket_wq"
    instead of dynamically allocated ones. They dont need rcu freeing.
    
    Some cleanups or followups are probably needed, (possible
    sk_callback_lock conversion to a spinlock for example...).
    
    Signed-off-by: Eric Dumazet <eric.dumazet@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index 2d3dcb39851f..aadbdb58758b 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -195,15 +195,17 @@ EXPORT_SYMBOL_GPL(dccp_sync_mss);
 
 void dccp_write_space(struct sock *sk)
 {
-	read_lock(&sk->sk_callback_lock);
+	struct socket_wq *wq;
 
-	if (sk_has_sleeper(sk))
-		wake_up_interruptible(sk_sleep(sk));
+	rcu_read_lock();
+	wq = rcu_dereference(sk->sk_wq);
+	if (wq_has_sleeper(wq))
+		wake_up_interruptible(&wq->wait);
 	/* Should agree with poll, otherwise some programs break */
 	if (sock_writeable(sk))
 		sk_wake_async(sk, SOCK_WAKE_SPACE, POLL_OUT);
 
-	read_unlock(&sk->sk_callback_lock);
+	rcu_read_unlock();
 }
 
 /**

commit aa395145165cb06a0d0885221bbe0ce4a564391d
Author: Eric Dumazet <eric.dumazet@gmail.com>
Date:   Tue Apr 20 13:03:51 2010 +0000

    net: sk_sleep() helper
    
    Define a new function to return the waitqueue of a "struct sock".
    
    static inline wait_queue_head_t *sk_sleep(struct sock *sk)
    {
            return sk->sk_sleep;
    }
    
    Change all read occurrences of sk_sleep by a call to this function.
    
    Needed for a future RCU conversion. sk_sleep wont be a field directly
    available.
    
    Signed-off-by: Eric Dumazet <eric.dumazet@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index e98b65e9569f..2d3dcb39851f 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -198,7 +198,7 @@ void dccp_write_space(struct sock *sk)
 	read_lock(&sk->sk_callback_lock);
 
 	if (sk_has_sleeper(sk))
-		wake_up_interruptible(sk->sk_sleep);
+		wake_up_interruptible(sk_sleep(sk));
 	/* Should agree with poll, otherwise some programs break */
 	if (sock_writeable(sk))
 		sk_wake_async(sk, SOCK_WAKE_SPACE, POLL_OUT);
@@ -225,7 +225,7 @@ static int dccp_wait_for_ccid(struct sock *sk, struct sk_buff *skb, int delay)
 		dccp_pr_debug("delayed send by %d msec\n", delay);
 		jiffdelay = msecs_to_jiffies(delay);
 
-		prepare_to_wait(sk->sk_sleep, &wait, TASK_INTERRUPTIBLE);
+		prepare_to_wait(sk_sleep(sk), &wait, TASK_INTERRUPTIBLE);
 
 		sk->sk_write_pending++;
 		release_sock(sk);
@@ -241,7 +241,7 @@ static int dccp_wait_for_ccid(struct sock *sk, struct sk_buff *skb, int delay)
 		rc = ccid_hc_tx_send_packet(dp->dccps_hc_tx_ccid, sk, skb);
 	} while ((delay = rc) > 0);
 out:
-	finish_wait(sk->sk_sleep, &wait);
+	finish_wait(sk_sleep(sk), &wait);
 	return rc;
 
 do_error:

commit 4e15ed4d930297c127d280ca1d0c785be870def4
Author: Shan Wei <shanwei@cn.fujitsu.com>
Date:   Thu Apr 15 16:43:08 2010 +0000

    net: replace ipfragok with skb->local_df
    
    As Herbert Xu said: we should be able to simply replace ipfragok
    with skb->local_df. commit f88037(sctp: Drop ipfargok in sctp_xmit function)
    has droped ipfragok and set local_df value properly.
    
    The patch kills the ipfragok parameter of .queue_xmit().
    
    Signed-off-by: Shan Wei <shanwei@cn.fujitsu.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index b8d98e3c052a..e98b65e9569f 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -136,7 +136,7 @@ static int dccp_transmit_skb(struct sock *sk, struct sk_buff *skb)
 
 		DCCP_INC_STATS(DCCP_MIB_OUTSEGS);
 
-		err = icsk->icsk_af_ops->queue_xmit(skb, 0);
+		err = icsk->icsk_af_ops->queue_xmit(skb);
 		return net_xmit_eval(err);
 	}
 	return -ENOBUFS;

commit bb29624614c2afe2873ee8ee97cf09df42701694
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Sun Apr 11 02:15:55 2010 +0000

    inet: Remove unused send_check length argument
    
    inet: Remove unused send_check length argument
    
    This patch removes the unused length argument from the send_check
    function in struct inet_connection_sock_af_ops.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
    Tested-by: Yinghai <yinghai.lu@oracle.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index fc3f436440b4..b8d98e3c052a 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -129,7 +129,7 @@ static int dccp_transmit_skb(struct sock *sk, struct sk_buff *skb)
 			break;
 		}
 
-		icsk->icsk_af_ops->send_check(sk, 0, skb);
+		icsk->icsk_af_ops->send_check(sk, skb);
 
 		if (set_ack)
 			dccp_event_ack_sent(sk);

commit 5a0e3ad6af8660be21ca98a971cd00f331318c05
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Mar 24 17:04:11 2010 +0900

    include cleanup: Update gfp.h and slab.h includes to prepare for breaking implicit slab.h inclusion from percpu.h
    
    percpu.h is included by sched.h and module.h and thus ends up being
    included when building most .c files.  percpu.h includes slab.h which
    in turn includes gfp.h making everything defined by the two files
    universally available and complicating inclusion dependencies.
    
    percpu.h -> slab.h dependency is about to be removed.  Prepare for
    this change by updating users of gfp and slab facilities include those
    headers directly instead of assuming availability.  As this conversion
    needs to touch large number of source files, the following script is
    used as the basis of conversion.
    
      http://userweb.kernel.org/~tj/misc/slabh-sweep.py
    
    The script does the followings.
    
    * Scan files for gfp and slab usages and update includes such that
      only the necessary includes are there.  ie. if only gfp is used,
      gfp.h, if slab is used, slab.h.
    
    * When the script inserts a new include, it looks at the include
      blocks and try to put the new include such that its order conforms
      to its surrounding.  It's put in the include block which contains
      core kernel includes, in the same order that the rest are ordered -
      alphabetical, Christmas tree, rev-Xmas-tree or at the end if there
      doesn't seem to be any matching order.
    
    * If the script can't find a place to put a new include (mostly
      because the file doesn't have fitting include block), it prints out
      an error message indicating which .h file needs to be added to the
      file.
    
    The conversion was done in the following steps.
    
    1. The initial automatic conversion of all .c files updated slightly
       over 4000 files, deleting around 700 includes and adding ~480 gfp.h
       and ~3000 slab.h inclusions.  The script emitted errors for ~400
       files.
    
    2. Each error was manually checked.  Some didn't need the inclusion,
       some needed manual addition while adding it to implementation .h or
       embedding .c file was more appropriate for others.  This step added
       inclusions to around 150 files.
    
    3. The script was run again and the output was compared to the edits
       from #2 to make sure no file was left behind.
    
    4. Several build tests were done and a couple of problems were fixed.
       e.g. lib/decompress_*.c used malloc/free() wrappers around slab
       APIs requiring slab.h to be added manually.
    
    5. The script was run on all .h files but without automatically
       editing them as sprinkling gfp.h and slab.h inclusions around .h
       files could easily lead to inclusion dependency hell.  Most gfp.h
       inclusion directives were ignored as stuff from gfp.h was usually
       wildly available and often used in preprocessor macros.  Each
       slab.h inclusion directive was examined and added manually as
       necessary.
    
    6. percpu.h was updated not to include slab.h.
    
    7. Build test were done on the following configurations and failures
       were fixed.  CONFIG_GCOV_KERNEL was turned off for all tests (as my
       distributed build env didn't work with gcov compiles) and a few
       more options had to be turned off depending on archs to make things
       build (like ipr on powerpc/64 which failed due to missing writeq).
    
       * x86 and x86_64 UP and SMP allmodconfig and a custom test config.
       * powerpc and powerpc64 SMP allmodconfig
       * sparc and sparc64 SMP allmodconfig
       * ia64 SMP allmodconfig
       * s390 SMP allmodconfig
       * alpha SMP allmodconfig
       * um on x86_64 SMP allmodconfig
    
    8. percpu.h modifications were reverted so that it could be applied as
       a separate patch and serve as bisection point.
    
    Given the fact that I had only a couple of failures from tests on step
    6, I'm fairly confident about the coverage of this conversion patch.
    If there is a breakage, it's likely to be something in one of the arch
    headers which should be easily discoverable easily on most builds of
    the specific arch.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Guess-its-ok-by: Christoph Lameter <cl@linux-foundation.org>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Lee Schermerhorn <Lee.Schermerhorn@hp.com>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index d6bb753bf6ad..fc3f436440b4 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -13,6 +13,7 @@
 #include <linux/dccp.h>
 #include <linux/kernel.h>
 #include <linux/skbuff.h>
+#include <linux/slab.h>
 
 #include <net/inet_sock.h>
 #include <net/sock.h>

commit c720c7e8383aff1cb219bddf474ed89d850336e3
Author: Eric Dumazet <eric.dumazet@gmail.com>
Date:   Thu Oct 15 06:30:45 2009 +0000

    inet: rename some inet_sock fields
    
    In order to have better cache layouts of struct sock (separate zones
    for rx/tx paths), we need this preliminary patch.
    
    Goal is to transfert fields used at lookup time in the first
    read-mostly cache line (inside struct sock_common) and move sk_refcnt
    to a separate cache line (only written by rx path)
    
    This patch adds inet_ prefix to daddr, rcv_saddr, dport, num, saddr,
    sport and id fields. This allows a future patch to define these
    fields as macros, like sk_refcnt, without name clashes.
    
    Signed-off-by: Eric Dumazet <eric.dumazet@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index c96119fda688..d6bb753bf6ad 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -99,8 +99,8 @@ static int dccp_transmit_skb(struct sock *sk, struct sk_buff *skb)
 		/* Build DCCP header and checksum it. */
 		dh = dccp_zeroed_hdr(skb, dccp_header_size);
 		dh->dccph_type	= dcb->dccpd_type;
-		dh->dccph_sport	= inet->sport;
-		dh->dccph_dport	= inet->dport;
+		dh->dccph_sport	= inet->inet_sport;
+		dh->dccph_dport	= inet->inet_dport;
 		dh->dccph_doff	= (dccp_header_size + dcb->dccpd_opt_len) / 4;
 		dh->dccph_ccval	= dcb->dccpd_ccval;
 		dh->dccph_cscov = dp->dccps_pcslen;

commit a57de0b4336e48db2811a2030bb68dba8dd09d88
Author: Jiri Olsa <jolsa@redhat.com>
Date:   Wed Jul 8 12:09:13 2009 +0000

    net: adding memory barrier to the poll and receive callbacks
    
    Adding memory barrier after the poll_wait function, paired with
    receive callbacks. Adding fuctions sock_poll_wait and sk_has_sleeper
    to wrap the memory barrier.
    
    Without the memory barrier, following race can happen.
    The race fires, when following code paths meet, and the tp->rcv_nxt
    and __add_wait_queue updates stay in CPU caches.
    
    CPU1                         CPU2
    
    sys_select                   receive packet
      ...                        ...
      __add_wait_queue           update tp->rcv_nxt
      ...                        ...
      tp->rcv_nxt check          sock_def_readable
      ...                        {
      schedule                      ...
                                    if (sk->sk_sleep && waitqueue_active(sk->sk_sleep))
                                            wake_up_interruptible(sk->sk_sleep)
                                    ...
                                 }
    
    If there was no cache the code would work ok, since the wait_queue and
    rcv_nxt are opposit to each other.
    
    Meaning that once tp->rcv_nxt is updated by CPU2, the CPU1 either already
    passed the tp->rcv_nxt check and sleeps, or will get the new value for
    tp->rcv_nxt and will return with new data mask.
    In both cases the process (CPU1) is being added to the wait queue, so the
    waitqueue_active (CPU2) call cannot miss and will wake up CPU1.
    
    The bad case is when the __add_wait_queue changes done by CPU1 stay in its
    cache, and so does the tp->rcv_nxt update on CPU2 side.  The CPU1 will then
    endup calling schedule and sleep forever if there are no more data on the
    socket.
    
    Calls to poll_wait in following modules were ommited:
            net/bluetooth/af_bluetooth.c
            net/irda/af_irda.c
            net/irda/irnet/irnet_ppp.c
            net/mac80211/rc80211_pid_debugfs.c
            net/phonet/socket.c
            net/rds/af_rds.c
            net/rfkill/core.c
            net/sunrpc/cache.c
            net/sunrpc/rpc_pipe.c
            net/tipc/socket.c
    
    Signed-off-by: Jiri Olsa <jolsa@redhat.com>
    Signed-off-by: Eric Dumazet <eric.dumazet@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index c0e88c16d088..c96119fda688 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -196,7 +196,7 @@ void dccp_write_space(struct sock *sk)
 {
 	read_lock(&sk->sk_callback_lock);
 
-	if (sk->sk_sleep && waitqueue_active(sk->sk_sleep))
+	if (sk_has_sleeper(sk))
 		wake_up_interruptible(sk->sk_sleep);
 	/* Should agree with poll, otherwise some programs break */
 	if (sock_writeable(sk))

commit adf30907d63893e4208dfe3f5c88ae12bc2f25d5
Author: Eric Dumazet <eric.dumazet@gmail.com>
Date:   Tue Jun 2 05:19:30 2009 +0000

    net: skb->dst accessors
    
    Define three accessors to get/set dst attached to a skb
    
    struct dst_entry *skb_dst(const struct sk_buff *skb)
    
    void skb_dst_set(struct sk_buff *skb, struct dst_entry *dst)
    
    void skb_dst_drop(struct sk_buff *skb)
    This one should replace occurrences of :
    dst_release(skb->dst)
    skb->dst = NULL;
    
    Delete skb->dst field
    
    Signed-off-by: Eric Dumazet <eric.dumazet@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index 36bcc00654d3..c0e88c16d088 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -350,7 +350,7 @@ struct sk_buff *dccp_make_response(struct sock *sk, struct dst_entry *dst,
 	/* Reserve space for headers. */
 	skb_reserve(skb, sk->sk_prot->max_header);
 
-	skb->dst = dst_clone(dst);
+	skb_dst_set(skb, dst_clone(dst));
 
 	dreq = dccp_rsk(req);
 	if (inet_rsk(req)->acked)	/* increase ISS upon retransmission */

commit 86739fb96e8c8269fc5b3d300c959bede272a6f6
Author: Gerrit Renker <gerrit@erg.abdn.ac.uk>
Date:   Fri Feb 27 22:38:29 2009 +0000

    dccp: Do not let initial option overhead shrink the MPS
    
    This fixes a problem caused by the overlap of the connection-setup and
    established-state phases of DCCP connections.
    
    During connection setup, the client retransmits Confirm Feature-Negotiation
    options until a response from the server signals that it can move from the
    half-established PARTOPEN into the OPEN state, whereupon the connection is
    fully established on both ends (RFC 4340, 8.1.5).
    
    However, since the client may already send data while it is in the PARTOPEN
    state, consequences arise for the Maximum Packet Size: the problem is that the
    initial option overhead is much higher than for the subsequent established
    phase, as it involves potentially many variable-length list-type options
    (server-priority options, RFC 4340, 6.4).
    
    Applying the standard MPS is insufficient here: especially with larger
    payloads this can lead to annoying, counter-intuitive EMSGSIZE errors.
    
    On the other hand, reducing the MPS available for the established phase by
    the added initial overhead is highly wasteful and inefficient.
    
    The solution chosen therefore is a two-phase strategy:
    
       If the payload length of the DataAck in PARTOPEN is too large, an Ack is sent
       to carry the options, and the feature-negotiation list is then flushed.
    
       This means that the server gets two Acks for one Response. If both Acks get
       lost, it is probably better to restart the connection anyway and devising yet
       another special-case does not seem worth the extra complexity.
    
    The result is a higher utilisation of the available packet space for the data
    transmission phase (established state) of a connection.
    
    The patch (over-)estimates the initial overhead to be 32*4 bytes -- commonly
    seen values were around 90 bytes for initial feature-negotiation options.
    
    It uses sizeof(u32) to mean "aligned units of 4 bytes".
    For consistency, another use of 4-byte alignment is adapted.
    
    Signed-off-by: Gerrit Renker <gerrit@erg.abdn.ac.uk>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index 27c79bcc6a1e..36bcc00654d3 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -276,7 +276,20 @@ void dccp_write_xmit(struct sock *sk, int block)
 			const int len = skb->len;
 
 			if (sk->sk_state == DCCP_PARTOPEN) {
-				/* See 8.1.5.  Handshake Completion */
+				const u32 cur_mps = dp->dccps_mss_cache - DCCP_FEATNEG_OVERHEAD;
+				/*
+				 * See 8.1.5 - Handshake Completion.
+				 *
+				 * For robustness we resend Confirm options until the client has
+				 * entered OPEN. During the initial feature negotiation, the MPS
+				 * is smaller than usual, reduced by the Change/Confirm options.
+				 */
+				if (!list_empty(&dp->dccps_featneg) && len > cur_mps) {
+					DCCP_WARN("Payload too large (%d) for featneg.\n", len);
+					dccp_send_ack(sk);
+					dccp_feat_list_purge(&dp->dccps_featneg);
+				}
+
 				inet_csk_schedule_ack(sk);
 				inet_csk_reset_xmit_timer(sk, ICSK_TIME_DACK,
 						  inet_csk(sk)->icsk_rto,

commit 361a5c1dd0bd7bb2b90e7fe9127b366d3566522e
Author: Gerrit Renker <gerrit@erg.abdn.ac.uk>
Date:   Fri Feb 27 22:38:28 2009 +0000

    dccp: Minimise header option overhead in setting the MPS
    
    This patch resolves a long-standing FIXME to dynamically update the Maximum
    Packet Size depending on actual options usage.
    
    It uses the flags set by the feature-negotiation infrastructure to compute
    the required header option size.
    
    Most options are fixed-size, a notable exception are Ack Vectors (required
    currently only by CCID-2). These can have any length between 3 and 1020
    bytes. As a result of testing, 16 bytes (2 bytes for type/length plus 14 Ack
    Vector cells) have been found to be sufficient for loss-free situations.
    
    There are currently no CCID-specific header options which may appear on data
    packets, thus it is not necessary to define a corresponding CCID field as
    suggested in the old comment.
    
    Further changes:
    ----------------
     Adjusted the type of 'cur_mps' to match the unsigned return type of the
     function.
    
    Signed-off-by: Gerrit Renker <gerrit@erg.abdn.ac.uk>
    Acked-by: Ian McDonald <ian.mcdonald@jandi.co.nz>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index 22a618af4893..27c79bcc6a1e 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -161,21 +161,27 @@ unsigned int dccp_sync_mss(struct sock *sk, u32 pmtu)
 	struct inet_connection_sock *icsk = inet_csk(sk);
 	struct dccp_sock *dp = dccp_sk(sk);
 	u32 ccmps = dccp_determine_ccmps(dp);
-	int cur_mps = ccmps ? min(pmtu, ccmps) : pmtu;
+	u32 cur_mps = ccmps ? min(pmtu, ccmps) : pmtu;
 
 	/* Account for header lengths and IPv4/v6 option overhead */
 	cur_mps -= (icsk->icsk_af_ops->net_header_len + icsk->icsk_ext_hdr_len +
 		    sizeof(struct dccp_hdr) + sizeof(struct dccp_hdr_ext));
 
 	/*
-	 * FIXME: this should come from the CCID infrastructure, where, say,
-	 * TFRC will say it wants TIMESTAMPS, ELAPSED time, etc, for now lets
-	 * put a rough estimate for NDP + TIMESTAMP + TIMESTAMP_ECHO + ELAPSED
-	 * TIME + TFRC_OPT_LOSS_EVENT_RATE + TFRC_OPT_RECEIVE_RATE + padding to
-	 * make it a multiple of 4
+	 * Leave enough headroom for common DCCP header options.
+	 * This only considers options which may appear on DCCP-Data packets, as
+	 * per table 3 in RFC 4340, 5.8. When running out of space for other
+	 * options (eg. Ack Vector which can take up to 255 bytes), it is better
+	 * to schedule a separate Ack. Thus we leave headroom for the following:
+	 *  - 1 byte for Slow Receiver (11.6)
+	 *  - 6 bytes for Timestamp (13.1)
+	 *  - 10 bytes for Timestamp Echo (13.3)
+	 *  - 8 bytes for NDP count (7.7, when activated)
+	 *  - 6 bytes for Data Checksum (9.3)
+	 *  - %DCCPAV_MIN_OPTLEN bytes for Ack Vector size (11.4, when enabled)
 	 */
-
-	cur_mps -= roundup(5 + 6 + 10 + 6 + 6 + 6, 4);
+	cur_mps -= roundup(1 + 6 + 10 + dp->dccps_send_ndp_count * 8 + 6 +
+			   (dp->dccps_hc_rx_ackvec ? DCCPAV_MIN_OPTLEN : 0), 4);
 
 	/* And store cached results */
 	icsk->icsk_pmtu_cookie = pmtu;

commit 61c1d052a3c7d5acba3bd535aaffa5bb5d085181
Author: Ilpo Jrvinen <ilpo.jarvinen@helsinki.fi>
Date:   Fri Dec 5 22:39:49 2008 -0800

    dccp: use roundup instead of opencoding
    
    Signed-off-by: Ilpo Jrvinen <ilpo.jarvinen@helsinki.fi>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index fea30cdc0bee..22a618af4893 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -175,7 +175,7 @@ unsigned int dccp_sync_mss(struct sock *sk, u32 pmtu)
 	 * make it a multiple of 4
 	 */
 
-	cur_mps -= ((5 + 6 + 10 + 6 + 6 + 6 + 3) / 4) * 4;
+	cur_mps -= roundup(5 + 6 + 10 + 6 + 6 + 6, 4);
 
 	/* And store cached results */
 	icsk->icsk_pmtu_cookie = pmtu;

commit 0c1168398ecbfacbb27203b281bde20ec9f78017
Author: Gerrit Renker <gerrit@erg.abdn.ac.uk>
Date:   Sun Nov 16 22:49:52 2008 -0800

    dccp: Mechanism to resolve CCID dependencies
    
    This adds a hook to resolve features whose value depends on the choice of
    CCID. It is done at the server since it can only be done after the CCID
    values have been negotiated; i.e. the client will add its CCID preference
    list on the Change options sent in the Request, which will be reconciled
    with the local preference list of the server.
    
    The concept is documented on
    http://www.erg.abdn.ac.uk/users/gerrit/dccp/notes/feature_negotiation/\
                                    implementation_notes.html#ccid_dependencies
    
    Signed-off-by: Gerrit Renker <gerrit@erg.abdn.ac.uk>
    Acked-by: Ian McDonald <ian.mcdonald@jandi.co.nz>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index 92f3f6f2ef51..fea30cdc0bee 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -339,10 +339,12 @@ struct sk_buff *dccp_make_response(struct sock *sk, struct dst_entry *dst,
 	DCCP_SKB_CB(skb)->dccpd_type = DCCP_PKT_RESPONSE;
 	DCCP_SKB_CB(skb)->dccpd_seq  = dreq->dreq_iss;
 
-	if (dccp_insert_options_rsk(dreq, skb)) {
-		kfree_skb(skb);
-		return NULL;
-	}
+	/* Resolve feature dependencies resulting from choice of CCID */
+	if (dccp_feat_server_ccid_dependencies(dreq))
+		goto response_failed;
+
+	if (dccp_insert_options_rsk(dreq, skb))
+		goto response_failed;
 
 	/* Build and checksum header */
 	dh = dccp_zeroed_hdr(skb, dccp_header_size);
@@ -363,6 +365,9 @@ struct sk_buff *dccp_make_response(struct sock *sk, struct dst_entry *dst,
 	inet_rsk(req)->acked = 1;
 	DCCP_INC_STATS(DCCP_MIB_OUTSEGS);
 	return skb;
+response_failed:
+	kfree_skb(skb);
+	return NULL;
 }
 
 EXPORT_SYMBOL_GPL(dccp_make_response);

commit 9eca0a47dee201a73967026985b5f0a79a46bd36
Author: Gerrit Renker <gerrit@erg.abdn.ac.uk>
Date:   Wed Nov 12 00:48:44 2008 -0800

    dccp: Resolve dependencies of features on choice of CCID
    
    This provides a missing link in the code chain, as several features implicitly
    depend and/or rely on the choice of CCID. Most notably, this is the Send Ack Vector
    feature, but also Ack Ratio and Send Loss Event Rate (also taken care of).
    
    For Send Ack Vector, the situation is as follows:
     * since CCID2 mandates the use of Ack Vectors, there is no point in allowing
       endpoints which use CCID2 to disable Ack Vector features such a connection;
    
     * a peer with a TX CCID of CCID2 will always expect Ack Vectors, and a peer
       with a RX CCID of CCID2 must always send Ack Vectors (RFC 4341, sec. 4);
    
     * for all other CCIDs, the use of (Send) Ack Vector is optional and thus
       negotiable. However, this implies that the code negotiating the use of Ack
       Vectors also supports it (i.e. is able to supply and to either parse or
       ignore received Ack Vectors). Since this is not the case (CCID-3 has no Ack
       Vector support), the use of Ack Vectors is here disabled, with a comment
       in the source code.
    
    An analogous consideration arises for the Send Loss Event Rate feature,
    since the CCID-3 implementation does not support the loss interval options
    of RFC 4342. To make such use explicit, corresponding feature-negotiation
    options are inserted which signal the use of the loss event rate option,
    as it is used by the CCID3 code.
    
    Lastly, the values of the Ack Ratio feature are matched to the choice of CCID.
    
    The patch implements this as a function which is called after the user has
    made all other registrations for changing default values of features.
    
    The table is variable-length, the reserved (and hence for feature-negotiation
    invalid, confirmed by considering section 19.4 of RFC 4340) feature number `0'
    is used to mark the end of the table.
    
    Signed-off-by: Gerrit Renker <gerrit@erg.abdn.ac.uk>
    Acked-by: Ian McDonald <ian.mcdonald@jandi.co.nz>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index 809d803d5006..92f3f6f2ef51 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -469,6 +469,10 @@ int dccp_connect(struct sock *sk)
 	struct sk_buff *skb;
 	struct inet_connection_sock *icsk = inet_csk(sk);
 
+	/* do not connect if feature negotiation setup fails */
+	if (dccp_feat_finalise_settings(dccp_sk(sk)))
+		return -EPROTO;
+
 	dccp_connect_init(sk);
 
 	skb = alloc_skb(sk->sk_prot->max_header, sk->sk_allocation);

commit 944f750227fa0beb2b440709687415621e2533a4
Author: Gerrit Renker <gerrit@erg.abdn.ac.uk>
Date:   Sun Oct 19 23:36:47 2008 -0700

    dccp: Port redirection support for DCCP
    
    Commit a3116ac5c216fc3c145906a46df9ce542ff7dcf2 from 1st October ("tcp: Port
    redirection support for TCP") broke DCCP skb lookup by changing inet_csk_clone,
    which is used by DCCP to generate the child socket after the handshake.
    
    This patch updates DCCP to use 'loc_port' instead of 'sport', which fixes the
    problem, and thus inheriting port redirection support via the new interface.
    
    Signed-off-by: Gerrit Renker <gerrit@erg.abdn.ac.uk>
    Signed-off-by: KOVACS Krisztian <hidden@sch.bme.hu>
    Acked-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index d06945c7d3df..809d803d5006 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -347,7 +347,7 @@ struct sk_buff *dccp_make_response(struct sock *sk, struct dst_entry *dst,
 	/* Build and checksum header */
 	dh = dccp_zeroed_hdr(skb, dccp_header_size);
 
-	dh->dccph_sport	= inet_sk(sk)->sport;
+	dh->dccph_sport	= inet_rsk(req)->loc_port;
 	dh->dccph_dport	= inet_rsk(req)->rmt_port;
 	dh->dccph_doff	= (dccp_header_size +
 			   DCCP_SKB_CB(skb)->dccpd_opt_len) / 4;

commit 73f18fdbca3f92b90aeaee16f5175fe30496e218
Author: Gerrit Renker <gerrit@erg.abdn.ac.uk>
Date:   Sat Jul 26 11:59:10 2008 +0100

    dccp: Bug-Fix - AWL was never updated
    
    The AWL lower Ack validity window advances in proportion to GSS, the greatest
    sequence number sent. Updating AWL other than at connection setup (in the
    DCCP-Request sent by dccp_v{4,6}_connect()) was missing in the DCCP code.
    
    This bug lead to syslog messages such as
    
     "kernel: dccp_check_seqno: DCCP: Step 6 failed for DATAACK packet, [...]
      P.ackno exists or LAWL(82947089) <= P.ackno(82948208)
                                       <= S.AWH(82948728), sending SYNC..."
    
    The difference between AWL/AWH here is 1639 packets, while the expected value
    (the Sequence Window) would have been 100 (the default).  A closer look showed
    that LAWL = AWL = 82947089 equalled the ISS on the Response.
    
    The patch now updates AWL with each increase of GSS.
    
    
    Further changes:
    ----------------
    The patch also enforces more stringent checks on the ISS sequence number:
    
     * AWL is initialised to ISS at connection setup and remains at this value;
     * AWH is then always set to GSS (via dccp_update_gss());
     * so on the first Request: AWL =      AWH = ISS,
       and on the n-th Request: AWL = ISS, AWH = ISS + n.
    
    As a consequence, only Response packets that refer to Requests sent by this
    host will pass, all others are discarded. This is the intention and in effect
    implements the initial adjustments for AWL as specified in RFC 4340, 7.5.1.
    
    Signed-off-by: Gerrit Renker <gerrit@erg.abdn.ac.uk>
    Acked-by: Ian McDonald <ian.mcdonald@jandi.co.nz>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index d19d48195013..d06945c7d3df 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -53,8 +53,11 @@ static int dccp_transmit_skb(struct sock *sk, struct sk_buff *skb)
 					  dccp_packet_hdr_len(dcb->dccpd_type);
 		int err, set_ack = 1;
 		u64 ackno = dp->dccps_gsr;
-
-		dccp_inc_seqno(&dp->dccps_gss);
+		/*
+		 * Increment GSS here already in case the option code needs it.
+		 * Update GSS for real only if option processing below succeeds.
+		 */
+		dcb->dccpd_seq = ADD48(dp->dccps_gss, 1);
 
 		switch (dcb->dccpd_type) {
 		case DCCP_PKT_DATA:
@@ -66,6 +69,9 @@ static int dccp_transmit_skb(struct sock *sk, struct sk_buff *skb)
 
 		case DCCP_PKT_REQUEST:
 			set_ack = 0;
+			/* Use ISS on the first (non-retransmitted) Request. */
+			if (icsk->icsk_retransmits == 0)
+				dcb->dccpd_seq = dp->dccps_iss;
 			/* fall through */
 
 		case DCCP_PKT_SYNC:
@@ -84,8 +90,6 @@ static int dccp_transmit_skb(struct sock *sk, struct sk_buff *skb)
 			break;
 		}
 
-		dcb->dccpd_seq = dp->dccps_gss;
-
 		if (dccp_insert_options(sk, skb)) {
 			kfree_skb(skb);
 			return -EPROTO;
@@ -103,7 +107,7 @@ static int dccp_transmit_skb(struct sock *sk, struct sk_buff *skb)
 		/* XXX For now we're using only 48 bits sequence numbers */
 		dh->dccph_x	= 1;
 
-		dp->dccps_awh = dp->dccps_gss;
+		dccp_update_gss(sk, dcb->dccpd_seq);
 		dccp_hdr_set_seq(dh, dp->dccps_gss);
 		if (set_ack)
 			dccp_hdr_set_ack(dccp_hdr_ack_bits(skb), ackno);
@@ -112,6 +116,11 @@ static int dccp_transmit_skb(struct sock *sk, struct sk_buff *skb)
 		case DCCP_PKT_REQUEST:
 			dccp_hdr_request(skb)->dccph_req_service =
 							dp->dccps_service;
+			/*
+			 * Limit Ack window to ISS <= P.ackno <= GSS, so that
+			 * only Responses to Requests we sent are considered.
+			 */
+			dp->dccps_awl = dp->dccps_iss;
 			break;
 		case DCCP_PKT_RESET:
 			dccp_hdr_reset(skb)->dccph_reset_code =
@@ -449,19 +458,7 @@ static inline void dccp_connect_init(struct sock *sk)
 
 	dccp_sync_mss(sk, dst_mtu(dst));
 
-	/*
-	 * SWL and AWL are initially adjusted so that they are not less than
-	 * the initial Sequence Numbers received and sent, respectively:
-	 *	SWL := max(GSR + 1 - floor(W/4), ISR),
-	 *	AWL := max(GSS - W' + 1, ISS).
-	 * These adjustments MUST be applied only at the beginning of the
-	 * connection.
-	 */
-	dccp_update_gss(sk, dp->dccps_iss);
-	dccp_set_seqno(&dp->dccps_awl, max48(dp->dccps_awl, dp->dccps_iss));
-
-	/* S.GAR - greatest valid acknowledgement number received on a non-Sync;
-	 *         initialized to S.ISS (sec. 8.5)                            */
+	/* Initialise GAR as per 8.5; AWL/AWH are set in dccp_transmit_skb() */
 	dp->dccps_gar = dp->dccps_iss;
 
 	icsk->icsk_retransmits = 0;

commit 59435444a13ed52d3444c5df26b73d3086bcd57b
Author: Gerrit Renker <gerrit@erg.abdn.ac.uk>
Date:   Sat Jul 26 11:59:09 2008 +0100

    dccp: Allow to distinguish original and retransmitted packets
    
    This patch allows the sender to distinguish original and retransmitted packets,
    which is in particular needed for the retransmission of DCCP-Requests:
     * the first Request uses ISS (generated in net/dccp/ip*.c), and sets GSS = ISS;
     * all retransmitted Requests use GSS' = GSS + 1, so that the n-th retransmitted
       Request has sequence number ISS + n (mod 48).
    
    To add generic support, the patch reorganises existing code so that:
     * icsk_retransmits == 0     for the original packet and
     * icsk_retransmits = n > 0  for the n-th retransmitted packet
    at the time dccp_transmit_skb() is called, via dccp_retransmit_skb().
    
    Thanks to Wei Yongjun for pointing this problem out.
    
    Further changes:
    ----------------
     * removed the `skb' argument from dccp_retransmit_skb(), since sk_send_head
       is used for all retransmissions (the exception is client-Acks in PARTOPEN
       state, but these do not use sk_send_head);
     * since sk_send_head always contains the original skb (via dccp_entail()),
       skb_cloned() never evaluated to true and thus pskb_copy() was never used.
    
    Signed-off-by: Gerrit Renker <gerrit@erg.abdn.ac.uk>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index fe20068c5d8e..d19d48195013 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -284,14 +284,26 @@ void dccp_write_xmit(struct sock *sk, int block)
 	}
 }
 
-int dccp_retransmit_skb(struct sock *sk, struct sk_buff *skb)
+/**
+ * dccp_retransmit_skb  -  Retransmit Request, Close, or CloseReq packets
+ * There are only four retransmittable packet types in DCCP:
+ * - Request  in client-REQUEST  state (sec. 8.1.1),
+ * - CloseReq in server-CLOSEREQ state (sec. 8.3),
+ * - Close    in   node-CLOSING  state (sec. 8.3),
+ * - Acks in client-PARTOPEN state (sec. 8.1.5, handled by dccp_delack_timer()).
+ * This function expects sk->sk_send_head to contain the original skb.
+ */
+int dccp_retransmit_skb(struct sock *sk)
 {
+	WARN_ON(sk->sk_send_head == NULL);
+
 	if (inet_csk(sk)->icsk_af_ops->rebuild_header(sk) != 0)
 		return -EHOSTUNREACH; /* Routing failure or similar. */
 
-	return dccp_transmit_skb(sk, (skb_cloned(skb) ?
-				      pskb_copy(skb, GFP_ATOMIC):
-				      skb_clone(skb, GFP_ATOMIC)));
+	/* this count is used to distinguish original and retransmitted skb */
+	inet_csk(sk)->icsk_retransmits++;
+
+	return dccp_transmit_skb(sk, skb_clone(sk->sk_send_head, GFP_ATOMIC));
 }
 
 struct sk_buff *dccp_make_response(struct sock *sk, struct dst_entry *dst,

commit 1e2f0e5e8376f2a0ada8760fc9d3104e1a81382b
Author: Gerrit Renker <gerrit@erg.abdn.ac.uk>
Date:   Wed Jun 11 11:19:09 2008 +0100

    dccp: Fix sparse warnings
    
    This patch fixes the following sparse warnings:
     * nested min(max()) expression:
       net/dccp/ccids/ccid3.c:91:21: warning: symbol '__x' shadows an earlier one
       net/dccp/ccids/ccid3.c:91:21: warning: symbol '__y' shadows an earlier one
    
     * Declaration of function prototypes in .c instead of .h file, resulting in
       "should it be static?" warnings.
    
     * Declared "struct dccpw" static (local to dccp_probe).
    
     * Disabled dccp_delayed_ack() - not fully removed due to RFC 4340, 11.3
       ("Receivers SHOULD implement delayed acknowledgement timers ...").
    
     * Used a different local variable name to avoid
       net/dccp/ackvec.c:293:13: warning: symbol 'state' shadows an earlier one
       net/dccp/ackvec.c:238:33: originally declared here
    
     * Removed unused functions `dccp_ackvector_print' and `dccp_ackvec_print'.
    
    Signed-off-by: Gerrit Renker <gerrit@erg.abdn.ac.uk>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index 1f8a9b64c083..fe20068c5d8e 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -508,6 +508,7 @@ void dccp_send_ack(struct sock *sk)
 
 EXPORT_SYMBOL_GPL(dccp_send_ack);
 
+#if 0
 /* FIXME: Is this still necessary (11.3) - currently nowhere used by DCCP. */
 void dccp_send_delayed_ack(struct sock *sk)
 {
@@ -538,6 +539,7 @@ void dccp_send_delayed_ack(struct sock *sk)
 	icsk->icsk_ack.timeout = timeout;
 	sk_reset_timer(sk, &icsk->icsk_delack_timer, timeout);
 }
+#endif
 
 void dccp_send_sync(struct sock *sk, const u64 ackno,
 		    const enum dccp_pkt_type pkt_type)

commit df39e8ba56a788733d369068c7319e04b1da3cd5
Merge: f5572855ec49 159d83363b62
Author: David S. Miller <davem@davemloft.net>
Date:   Mon Apr 14 02:30:23 2008 -0700

    Merge branch 'master' of master.kernel.org:/pub/scm/linux/kernel/git/davem/net-2.6
    
    Conflicts:
    
            drivers/net/ehea/ehea_main.c
            drivers/net/wireless/iwlwifi/Kconfig
            drivers/net/wireless/rt2x00/rt61pci.c
            net/ipv4/inet_timewait_sock.c
            net/ipv6/raw.c
            net/mac80211/ieee80211_sta.c

commit 028b027524b162eef90839a92ba4b8bddf23e06c
Author: Patrick McHardy <kaber@trash.net>
Date:   Sat Apr 12 18:35:41 2008 -0700

    [DCCP]: Fix skb->cb conflicts with IP
    
    dev_queue_xmit() and the other IP output functions expect to get a skb
    with clear or properly initialized skb->cb. Unlike TCP and UDP, the
    dccp_skb_cb doesn't contain a struct inet_skb_parm at the beginning,
    so the DCCP-specific data is interpreted by the IP output functions.
    This can cause false negatives for the conditional POST_ROUTING hook
    invocation, making the packet bypass the hook.
    
    Add a inet_skb_parm/inet6_skb_parm union to the beginning of
    dccp_skb_cb to avoid clashes. Also add a BUILD_BUG_ON to make
    sure it fits in the cb.
    
    [ Combined with patch from Gerrit Renker to remove two now unnecessary
      memsets of IPCB(skb)->opt ]
    
    Signed-off-by: Patrick McHardy <kaber@trash.net>
    Acked-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index 3b763db3d863..3d7d628d870d 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -126,7 +126,6 @@ static int dccp_transmit_skb(struct sock *sk, struct sk_buff *skb)
 
 		DCCP_INC_STATS(DCCP_MIB_OUTSEGS);
 
-		memset(&(IPCB(skb)->opt), 0, sizeof(IPCB(skb)->opt));
 		err = icsk->icsk_af_ops->queue_xmit(skb, 0);
 		return net_xmit_eval(err);
 	}

commit 7630f026810a63464e47391ab1e03674c33eb1b8
Author: Denis V. Lunev <den@openvz.org>
Date:   Thu Apr 3 14:20:52 2008 -0700

    [DCCP]: Replace socket with sock for reset sending.
    
    Replace dccp_v(4|6)_ctl_socket with sock to unify a code with TCP/ICMP.
    
    Signed-off-by: Denis V. Lunev <den@openvz.org>
    Acked-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index 3b763db3d863..f32a84ef757b 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -348,7 +348,7 @@ struct sk_buff *dccp_make_response(struct sock *sk, struct dst_entry *dst,
 EXPORT_SYMBOL_GPL(dccp_make_response);
 
 /* answer offending packet in @rcv_skb with Reset from control socket @ctl */
-struct sk_buff *dccp_ctl_make_reset(struct socket *ctl, struct sk_buff *rcv_skb)
+struct sk_buff *dccp_ctl_make_reset(struct sock *sk, struct sk_buff *rcv_skb)
 {
 	struct dccp_hdr *rxdh = dccp_hdr(rcv_skb), *dh;
 	struct dccp_skb_cb *dcb = DCCP_SKB_CB(rcv_skb);
@@ -358,11 +358,11 @@ struct sk_buff *dccp_ctl_make_reset(struct socket *ctl, struct sk_buff *rcv_skb)
 	struct dccp_hdr_reset *dhr;
 	struct sk_buff *skb;
 
-	skb = alloc_skb(ctl->sk->sk_prot->max_header, GFP_ATOMIC);
+	skb = alloc_skb(sk->sk_prot->max_header, GFP_ATOMIC);
 	if (skb == NULL)
 		return NULL;
 
-	skb_reserve(skb, ctl->sk->sk_prot->max_header);
+	skb_reserve(skb, sk->sk_prot->max_header);
 
 	/* Swap the send and the receive. */
 	dh = dccp_zeroed_hdr(skb, dccp_hdr_reset_len);

commit 6179983ad30c43313e153b35af52bd9ebd7745c3
Author: Gerrit Renker <gerrit@erg.abdn.ac.uk>
Date:   Thu Dec 13 23:37:55 2007 -0200

    [DCCP]: Introducing CCMPS
    
    This introduces a CCMPS field for setting a CCID-specific upper bound on the application payload
    size, as is defined in RFC 4340, section 14.
    
    Only the TX CCID is considered in setting this limit, since the RX CCID generates comparatively
    small (DCCP-Ack) feedback packets. The CCMPS field includes network and transport layer header
    lengths. The only current CCMPS customer is CCID4 (via RFC 4828).
    
    A wrapper is used to allow querying the CCMPS even at times where the CCID modules may not have
    been fully negotiated yet.
    
    In dccp_sync_mss() the variable `mss_now' has been renamed into `cur_mps', to reflect that we are
    dealing with an MPS, but not an MSS.
    Since the DCCP code closely follows the TCP code, the identifiers `dccp_sync_mss' and
    `dccps_mss_cache' have been kept, as they have direct TCP counterparts.
    
    Signed-off-by: Gerrit Renker <gerrit@erg.abdn.ac.uk>
    Signed-off-by: Ian McDonald <ian.mcdonald@jandi.co.nz>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index 5589a5e581f4..3b763db3d863 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -133,15 +133,31 @@ static int dccp_transmit_skb(struct sock *sk, struct sk_buff *skb)
 	return -ENOBUFS;
 }
 
+/**
+ * dccp_determine_ccmps  -  Find out about CCID-specfic packet-size limits
+ * We only consider the HC-sender CCID for setting the CCMPS (RFC 4340, 14.),
+ * since the RX CCID is restricted to feedback packets (Acks), which are small
+ * in comparison with the data traffic. A value of 0 means "no current CCMPS".
+ */
+static u32 dccp_determine_ccmps(const struct dccp_sock *dp)
+{
+	const struct ccid *tx_ccid = dp->dccps_hc_tx_ccid;
+
+	if (tx_ccid == NULL || tx_ccid->ccid_ops == NULL)
+		return 0;
+	return tx_ccid->ccid_ops->ccid_ccmps;
+}
+
 unsigned int dccp_sync_mss(struct sock *sk, u32 pmtu)
 {
 	struct inet_connection_sock *icsk = inet_csk(sk);
 	struct dccp_sock *dp = dccp_sk(sk);
-	int mss_now = (pmtu - icsk->icsk_af_ops->net_header_len -
-		       sizeof(struct dccp_hdr) - sizeof(struct dccp_hdr_ext));
+	u32 ccmps = dccp_determine_ccmps(dp);
+	int cur_mps = ccmps ? min(pmtu, ccmps) : pmtu;
 
-	/* Now subtract optional transport overhead */
-	mss_now -= icsk->icsk_ext_hdr_len;
+	/* Account for header lengths and IPv4/v6 option overhead */
+	cur_mps -= (icsk->icsk_af_ops->net_header_len + icsk->icsk_ext_hdr_len +
+		    sizeof(struct dccp_hdr) + sizeof(struct dccp_hdr_ext));
 
 	/*
 	 * FIXME: this should come from the CCID infrastructure, where, say,
@@ -151,13 +167,13 @@ unsigned int dccp_sync_mss(struct sock *sk, u32 pmtu)
 	 * make it a multiple of 4
 	 */
 
-	mss_now -= ((5 + 6 + 10 + 6 + 6 + 6 + 3) / 4) * 4;
+	cur_mps -= ((5 + 6 + 10 + 6 + 6 + 6 + 3) / 4) * 4;
 
 	/* And store cached results */
 	icsk->icsk_pmtu_cookie = pmtu;
-	dp->dccps_mss_cache = mss_now;
+	dp->dccps_mss_cache = cur_mps;
 
-	return mss_now;
+	return cur_mps;
 }
 
 EXPORT_SYMBOL_GPL(dccp_sync_mss);

commit af3b867e2f6b72422bc7aacb1f1e26f47a9649bc
Author: Gerrit Renker <gerrit@erg.abdn.ac.uk>
Date:   Thu Dec 13 12:38:11 2007 -0200

    [DCCP]: Support inserting options during the 3-way handshake
    
    This provides a separate routine to insert options during the initial handshake.
    The main purpose is to conduct feature negotiation, for the moment the only user
    is the timestamp echo needed for the (CCID3) handshake RTT sample.
    
    Padding of options has been put into a small separate routine, to be shared among
    the two functions. This could also be used as a generic routine to finish inserting
    options.
    
    Also removed an `XXX' comment since its content was obvious.
    
    Signed-off-by: Gerrit Renker <gerrit@erg.abdn.ac.uk>
    Signed-off-by: Ian McDonald <ian.mcdonald@jandi.co.nz>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index b2e17910930d..5589a5e581f4 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -303,7 +303,7 @@ struct sk_buff *dccp_make_response(struct sock *sk, struct dst_entry *dst,
 	DCCP_SKB_CB(skb)->dccpd_type = DCCP_PKT_RESPONSE;
 	DCCP_SKB_CB(skb)->dccpd_seq  = dreq->dreq_iss;
 
-	if (dccp_insert_options(sk, skb)) {
+	if (dccp_insert_options_rsk(dreq, skb)) {
 		kfree_skb(skb);
 		return NULL;
 	}

commit b8599d20708fa3bde1e414689f3474560c2d990b
Author: Gerrit Renker <gerrit@erg.abdn.ac.uk>
Date:   Thu Dec 13 12:25:01 2007 -0200

    [DCCP]: Support for server holding timewait state
    
    This adds a socket option and signalling support for the case where the server
    holds timewait state on closing the connection, as described in RFC 4340, 8.3.
    
    Since holding timewait state at the server is the non-usual case, it is enabled
    via a socket option. Documentation for this socket option has been added.
    
    The setsockopt statement has been made resilient against different possible cases
    of expressing boolean `true' values using a suggestion by Ian McDonald.
    
    Signed-off-by: Gerrit Renker <gerrit@erg.abdn.ac.uk>
    Signed-off-by: Ian McDonald <ian.mcdonald@jandi.co.nz>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index e97584aa4898..b2e17910930d 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -567,8 +567,10 @@ void dccp_send_close(struct sock *sk, const int active)
 
 	/* Reserve space for headers and prepare control bits. */
 	skb_reserve(skb, sk->sk_prot->max_header);
-	DCCP_SKB_CB(skb)->dccpd_type = dp->dccps_role == DCCP_ROLE_CLIENT ?
-					DCCP_PKT_CLOSE : DCCP_PKT_CLOSEREQ;
+	if (dp->dccps_role == DCCP_ROLE_SERVER && !dp->dccps_server_timewait)
+		DCCP_SKB_CB(skb)->dccpd_type = DCCP_PKT_CLOSEREQ;
+	else
+		DCCP_SKB_CB(skb)->dccpd_type = DCCP_PKT_CLOSE;
 
 	if (active) {
 		dccp_write_xmit(sk, 1);

commit 92d31920b84f258badf206eea8aaf5ac677ac535
Author: Gerrit Renker <gerrit@erg.abdn.ac.uk>
Date:   Thu Dec 13 12:02:43 2007 -0200

    [DCCP]: Shift the retransmit timer for active-close into output.c
    
    When performing active close, RFC 4340, 8.3. requires to retransmit the
    Close/CloseReq with a backoff-retransmit timer starting at intially 2 RTTs.
    
    This patch shifts the existing code for active-close retransmit timer
    into output.c, so that the retransmit timer is started when the first
    Close/CloseReq is sent. Previously, the timer was started when, after
    releasing the socket in dccp_close(), the actively-closing side had not yet
    reached the CLOSED/TIMEWAIT state.
    
    The patch further reduces the initial timeout from 3 seconds to the required
    2 RTTs, where - in absence of a known RTT - the fallback value specified in
    RFC 4340, 3.4 is used.
    
    Signed-off-by: Gerrit Renker <gerrit@erg.abdn.ac.uk>
    Signed-off-by: Ian McDonald <ian.mcdonald@jandi.co.nz>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index 7caa7f57bb7e..e97584aa4898 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -574,7 +574,18 @@ void dccp_send_close(struct sock *sk, const int active)
 		dccp_write_xmit(sk, 1);
 		dccp_skb_entail(sk, skb);
 		dccp_transmit_skb(sk, skb_clone(skb, prio));
-		/* FIXME do we need a retransmit timer here? */
+		/*
+		 * Retransmission timer for active-close: RFC 4340, 8.3 requires
+		 * to retransmit the Close/CloseReq until the CLOSING/CLOSEREQ
+		 * state can be left. The initial timeout is 2 RTTs.
+		 * Since RTT measurement is done by the CCIDs, there is no easy
+		 * way to get an RTT sample. The fallback RTT from RFC 4340, 3.4
+		 * is too low (200ms); we use a high value to avoid unnecessary
+		 * retransmissions when the link RTT is > 0.2 seconds.
+		 * FIXME: Let main module sample RTTs and use that instead.
+		 */
+		inet_csk_reset_xmit_timer(sk, ICSK_TIME_RETRANS,
+					  DCCP_TIMEOUT_INIT, DCCP_RTO_MAX);
 	} else
 		dccp_transmit_skb(sk, skb);
 }

commit f53dc67c5e7babafe239b93a11678b0e05bead51
Author: Gerrit Renker <gerrit@erg.abdn.ac.uk>
Date:   Wed Nov 28 08:35:08 2007 +0000

    [DCCP]: Use AF-independent rebuild_header routine
    
    This fixes a nasty bug: dccp_send_reset() is called by both DCCPv4 and DCCPv6, but uses
    inet_sk_rebuild_header() in each case. This leads to unpredictable and weird behaviour:
    under some conditions, DCCPv6 Resets were sent, in other not.
    
    The fix is to use the AF-independent rebuild_header routine.
    
    Signed-off-by: Gerrit Renker <gerrit@erg.abdn.ac.uk>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index 33ce737ef3a8..7caa7f57bb7e 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -391,7 +391,7 @@ int dccp_send_reset(struct sock *sk, enum dccp_reset_codes code)
 	 * FIXME: what if rebuild_header fails?
 	 * Should we be doing a rebuild_header here?
 	 */
-	int err = inet_sk_rebuild_header(sk);
+	int err = inet_csk(sk)->icsk_af_ops->rebuild_header(sk);
 
 	if (err != 0)
 		return err;

commit 8d8ad9d7c4bfe79bc91b7fc419ecfb9dcdfe6a51
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Mon Nov 26 20:10:50 2007 +0800

    [NET]: Name magic constants in sock_wake_async()
    
    The sock_wake_async() performs a bit different actions
    depending on "how" argument. Unfortunately this argument
    ony has numerical magic values.
    
    I propose to give names to their constants to help people
    reading this function callers understand what's going on
    without looking into this function all the time.
    
    I suppose this is 2.6.25 material, but if it's not (or the
    naming seems poor/bad/awful), I can rework it against the
    current net-2.6 tree.
    
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index f49544618f20..33ce737ef3a8 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -170,7 +170,7 @@ void dccp_write_space(struct sock *sk)
 		wake_up_interruptible(sk->sk_sleep);
 	/* Should agree with poll, otherwise some programs break */
 	if (sock_writeable(sk))
-		sk_wake_async(sk, 2, POLL_OUT);
+		sk_wake_async(sk, SOCK_WAKE_SPACE, POLL_OUT);
 
 	read_unlock(&sk->sk_callback_lock);
 }

commit bc8498721dfe3f7d537f4f75302be7dbe9c7b939
Author: Gerrit Renker <gerrit@erg.abdn.ac.uk>
Date:   Thu Oct 4 14:38:49 2007 -0700

    [DCCP]: Wait for CCID
    
    This performs a minor optimisation: when ccid_hc_tx_send_packet
    returns a value greater zero, then the same call previously was done
    again at the begin of the while loop in dccp_wait_for_ccid.
    
    This patch exploits the available information and schedule-timeouts
    directly instead.
    
    Documentation also added.
    
    Signed-off-by: Gerrit Renker <gerrit@erg.abdn.ac.uk>
    Signed-off-by: Ian McDonald <ian.mcdonald@jandi.co.nz>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index 6a334ed5e9d6..f49544618f20 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -177,34 +177,38 @@ void dccp_write_space(struct sock *sk)
 
 /**
  * dccp_wait_for_ccid - Wait for ccid to tell us we can send a packet
- * @sk: socket to wait for
+ * @sk:    socket to wait for
+ * @skb:   current skb to pass on for waiting
+ * @delay: sleep timeout in milliseconds (> 0)
+ * This function is called by default when the socket is closed, and
+ * when a non-zero linger time is set on the socket. For consistency
  */
-static int dccp_wait_for_ccid(struct sock *sk, struct sk_buff *skb)
+static int dccp_wait_for_ccid(struct sock *sk, struct sk_buff *skb, int delay)
 {
 	struct dccp_sock *dp = dccp_sk(sk);
 	DEFINE_WAIT(wait);
-	unsigned long delay;
+	unsigned long jiffdelay;
 	int rc;
 
-	while (1) {
+	do {
+		dccp_pr_debug("delayed send by %d msec\n", delay);
+		jiffdelay = msecs_to_jiffies(delay);
+
 		prepare_to_wait(sk->sk_sleep, &wait, TASK_INTERRUPTIBLE);
 
+		sk->sk_write_pending++;
+		release_sock(sk);
+		schedule_timeout(jiffdelay);
+		lock_sock(sk);
+		sk->sk_write_pending--;
+
 		if (sk->sk_err)
 			goto do_error;
 		if (signal_pending(current))
 			goto do_interrupted;
 
 		rc = ccid_hc_tx_send_packet(dp->dccps_hc_tx_ccid, sk, skb);
-		if (rc <= 0)
-			break;
-		dccp_pr_debug("delayed send by %d msec\n", rc);
-		delay = msecs_to_jiffies(rc);
-		sk->sk_write_pending++;
-		release_sock(sk);
-		schedule_timeout(delay);
-		lock_sock(sk);
-		sk->sk_write_pending--;
-	}
+	} while ((delay = rc) > 0);
 out:
 	finish_wait(sk->sk_sleep, &wait);
 	return rc;
@@ -231,7 +235,7 @@ void dccp_write_xmit(struct sock *sk, int block)
 						msecs_to_jiffies(err)+jiffies);
 				break;
 			} else
-				err = dccp_wait_for_ccid(sk, skb);
+				err = dccp_wait_for_ccid(sk, skb, err);
 			if (err && err != -EINTR)
 				DCCP_BUG("err=%d after dccp_wait_for_ccid", err);
 		}

commit e356d37a096a990ea1a74c44c15640122e56110b
Author: Gerrit Renker <gerrit@erg.abdn.ac.uk>
Date:   Wed Sep 26 14:35:19 2007 -0300

    [DCCP]: Factor out common code for generating Resets
    
    This factors code common to dccp_v{4,6}_ctl_send_reset into a separate function,
    and adds support for filling in the Data 1 ... Data 3 fields from RFC 4340, 5.6.
    
    It is useful to have this separate, since the following Reset codes will always
    be generated from the control socket rather than via dccp_send_reset:
     * Code 3, "No Connection", cf. 8.3.1;
     * Code 4, "Packet Error" (identification for Data 1 added);
     * Code 5, "Option Error" (identification for Data 1..3 added, will be used later);
     * Code 6, "Mandatory Error" (same as Option Error);
     * Code 7, "Connection Refused" (what on Earth is the difference to "No Connection"?);
     * Code 8, "Bad Service Code";
     * Code 9, "Too Busy";
     * Code 10, "Bad Init Cookie" (not used).
    
    Code 0 is not recommended by the RFC, the following codes would be used in
    dccp_send_reset() instead, since they all relate to an established DCCP connection:
     * Code 1, "Closed";
     * Code 2, "Aborted";
     * Code 11, "Aggression Penalty" (12.3).
    
    Signed-off-by: Gerrit Renker <gerrit@erg.abdn.ac.uk>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@ghostprotocols.net>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index f4bde2056204..6a334ed5e9d6 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -327,6 +327,58 @@ struct sk_buff *dccp_make_response(struct sock *sk, struct dst_entry *dst,
 
 EXPORT_SYMBOL_GPL(dccp_make_response);
 
+/* answer offending packet in @rcv_skb with Reset from control socket @ctl */
+struct sk_buff *dccp_ctl_make_reset(struct socket *ctl, struct sk_buff *rcv_skb)
+{
+	struct dccp_hdr *rxdh = dccp_hdr(rcv_skb), *dh;
+	struct dccp_skb_cb *dcb = DCCP_SKB_CB(rcv_skb);
+	const u32 dccp_hdr_reset_len = sizeof(struct dccp_hdr) +
+				       sizeof(struct dccp_hdr_ext) +
+				       sizeof(struct dccp_hdr_reset);
+	struct dccp_hdr_reset *dhr;
+	struct sk_buff *skb;
+
+	skb = alloc_skb(ctl->sk->sk_prot->max_header, GFP_ATOMIC);
+	if (skb == NULL)
+		return NULL;
+
+	skb_reserve(skb, ctl->sk->sk_prot->max_header);
+
+	/* Swap the send and the receive. */
+	dh = dccp_zeroed_hdr(skb, dccp_hdr_reset_len);
+	dh->dccph_type	= DCCP_PKT_RESET;
+	dh->dccph_sport	= rxdh->dccph_dport;
+	dh->dccph_dport	= rxdh->dccph_sport;
+	dh->dccph_doff	= dccp_hdr_reset_len / 4;
+	dh->dccph_x	= 1;
+
+	dhr = dccp_hdr_reset(skb);
+	dhr->dccph_reset_code = dcb->dccpd_reset_code;
+
+	switch (dcb->dccpd_reset_code) {
+	case DCCP_RESET_CODE_PACKET_ERROR:
+		dhr->dccph_reset_data[0] = rxdh->dccph_type;
+		break;
+	case DCCP_RESET_CODE_OPTION_ERROR:	/* fall through */
+	case DCCP_RESET_CODE_MANDATORY_ERROR:
+		memcpy(dhr->dccph_reset_data, dcb->dccpd_reset_data, 3);
+		break;
+	}
+	/*
+	 * From RFC 4340, 8.3.1:
+	 *   If P.ackno exists, set R.seqno := P.ackno + 1.
+	 *   Else set R.seqno := 0.
+	 */
+	if (dcb->dccpd_ack_seq != DCCP_PKT_WITHOUT_ACK_SEQ)
+		dccp_hdr_set_seq(dh, ADD48(dcb->dccpd_ack_seq, 1));
+	dccp_hdr_set_ack(dccp_hdr_ack_bits(skb), dcb->dccpd_seq);
+
+	dccp_csum_outgoing(skb);
+	return skb;
+}
+
+EXPORT_SYMBOL_GPL(dccp_ctl_make_reset);
+
 /* send Reset on established socket, to close or abort the connection */
 int dccp_send_reset(struct sock *sk, enum dccp_reset_codes code)
 {

commit ee1a15922d356aff0e31bf9bb9088ab346b8033a
Author: Gerrit Renker <gerrit@erg.abdn.ac.uk>
Date:   Wed Sep 26 11:30:02 2007 -0300

    [DCCP]: Remove duplicate code for Reset from connected socket
    
    In this patch, duplicated code is removed for the case when a Reset packet is
    sent from a connected socket. This code duplication is between dccp_make_reset
    and dccp_transmit_skb, which already contained an (up to now entirely unused)
    switch statement to fill in the reset code from the DCCP_SKB_CB.
    
    The only thing that has been removed is the call to dst_clone(dst), since
    the queue_xmit functions use sk_dst_cache anyway.
    
    I wasn't sure which purpose inet_sk_rebuild_header served, so I left it in.
    
    Signed-off-by: Gerrit Renker <gerrit@erg.abdn.ac.uk>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@ghostprotocols.net>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index d0c9ec6494bf..f4bde2056204 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -61,6 +61,7 @@ static int dccp_transmit_skb(struct sock *sk, struct sk_buff *skb)
 			set_ack = 0;
 			/* fall through */
 		case DCCP_PKT_DATAACK:
+		case DCCP_PKT_RESET:
 			break;
 
 		case DCCP_PKT_REQUEST:
@@ -73,8 +74,10 @@ static int dccp_transmit_skb(struct sock *sk, struct sk_buff *skb)
 			/* fall through */
 		default:
 			/*
-			 * Only data packets should come through with skb->sk
-			 * set.
+			 * Set owner/destructor: some skbs are allocated via
+			 * alloc_skb (e.g. when retransmission may happen).
+			 * Only Data, DataAck, and Reset packets should come
+			 * through here with skb->sk set.
 			 */
 			WARN_ON(skb->sk);
 			skb_set_owner_w(skb, sk);
@@ -324,72 +327,29 @@ struct sk_buff *dccp_make_response(struct sock *sk, struct dst_entry *dst,
 
 EXPORT_SYMBOL_GPL(dccp_make_response);
 
-static struct sk_buff *dccp_make_reset(struct sock *sk, struct dst_entry *dst,
-				       const enum dccp_reset_codes code)
-{
-	struct dccp_hdr *dh;
-	struct dccp_sock *dp = dccp_sk(sk);
-	const u32 dccp_header_size = sizeof(struct dccp_hdr) +
-				     sizeof(struct dccp_hdr_ext) +
-				     sizeof(struct dccp_hdr_reset);
-	struct sk_buff *skb = sock_wmalloc(sk, sk->sk_prot->max_header, 1,
-					   GFP_ATOMIC);
-	if (skb == NULL)
-		return NULL;
-
-	/* Reserve space for headers. */
-	skb_reserve(skb, sk->sk_prot->max_header);
-
-	skb->dst = dst_clone(dst);
-
-	dccp_inc_seqno(&dp->dccps_gss);
-
-	DCCP_SKB_CB(skb)->dccpd_reset_code = code;
-	DCCP_SKB_CB(skb)->dccpd_type	   = DCCP_PKT_RESET;
-	DCCP_SKB_CB(skb)->dccpd_seq	   = dp->dccps_gss;
-
-	if (dccp_insert_options(sk, skb)) {
-		kfree_skb(skb);
-		return NULL;
-	}
-
-	dh = dccp_zeroed_hdr(skb, dccp_header_size);
-
-	dh->dccph_sport	= inet_sk(sk)->sport;
-	dh->dccph_dport	= inet_sk(sk)->dport;
-	dh->dccph_doff	= (dccp_header_size +
-			   DCCP_SKB_CB(skb)->dccpd_opt_len) / 4;
-	dh->dccph_type	= DCCP_PKT_RESET;
-	dh->dccph_x	= 1;
-	dccp_hdr_set_seq(dh, dp->dccps_gss);
-	dccp_hdr_set_ack(dccp_hdr_ack_bits(skb), dp->dccps_gsr);
-
-	dccp_hdr_reset(skb)->dccph_reset_code = code;
-	inet_csk(sk)->icsk_af_ops->send_check(sk, 0, skb);
-
-	DCCP_INC_STATS(DCCP_MIB_OUTSEGS);
-	return skb;
-}
-
+/* send Reset on established socket, to close or abort the connection */
 int dccp_send_reset(struct sock *sk, enum dccp_reset_codes code)
 {
+	struct sk_buff *skb;
 	/*
 	 * FIXME: what if rebuild_header fails?
 	 * Should we be doing a rebuild_header here?
 	 */
 	int err = inet_sk_rebuild_header(sk);
 
-	if (err == 0) {
-		struct sk_buff *skb = dccp_make_reset(sk, sk->sk_dst_cache,
-						      code);
-		if (skb != NULL) {
-			memset(&(IPCB(skb)->opt), 0, sizeof(IPCB(skb)->opt));
-			err = inet_csk(sk)->icsk_af_ops->queue_xmit(skb, 0);
-			return net_xmit_eval(err);
-		}
-	}
+	if (err != 0)
+		return err;
+
+	skb = sock_wmalloc(sk, sk->sk_prot->max_header, 1, GFP_ATOMIC);
+	if (skb == NULL)
+		return -ENOBUFS;
+
+	/* Reserve space for headers and prepare control bits. */
+	skb_reserve(skb, sk->sk_prot->max_header);
+	DCCP_SKB_CB(skb)->dccpd_type	   = DCCP_PKT_RESET;
+	DCCP_SKB_CB(skb)->dccpd_reset_code = code;
 
-	return err;
+	return dccp_transmit_skb(sk, skb);
 }
 
 /*

commit 727ecc5faaf6e976fc841649821c865ebd1e822d
Author: Gerrit Renker <gerrit@erg.abdn.ac.uk>
Date:   Wed Sep 26 11:26:04 2007 -0300

    [DCCP]: Add FIXME for send_delayed_ack
    
    This adds a FIXME to signal that the function dccp_send_delayed_ack is nowhere
    used in the entire DCCP/CCID code.
    
    Using a delayed Ack timer is suggested in 11.3 of RFC 4340, but it has also
    rather subtle implications for the Ack-Ratio-accounting.
    
    CCID2 does not use this (maybe it should).
    
    I think leaving the function in is good, in case someone wants to implement
    this.
    
    Signed-off-by: Gerrit Renker <gerrit@erg.abdn.ac.uk>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@ghostprotocols.net>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index 6e23d5b57e79..d0c9ec6494bf 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -477,6 +477,7 @@ void dccp_send_ack(struct sock *sk)
 
 EXPORT_SYMBOL_GPL(dccp_send_ack);
 
+/* FIXME: Is this still necessary (11.3) - currently nowhere used by DCCP. */
 void dccp_send_delayed_ack(struct sock *sk)
 {
 	struct inet_connection_sock *icsk = inet_csk(sk);

commit b0d045ca45a44d9f8bd66d0a10558b10c60f895a
Author: Gerrit Renker <gerrit@erg.abdn.ac.uk>
Date:   Tue Sep 25 22:42:27 2007 -0700

    [DCCP]: Parameter renaming
    
    The parameter `seq' of dccp_send_sync() is in fact an acknowledgement number
    and not a sequence number - thus renamed by this patch into `ackno'.
    
    Secondly, a `critical' warning is added when a Sync/SyncAck could not be sent.
    
    Sanity: I have checked all other functions that are called in dccp_transmit_skb,
            there are no clashes with the use of dccpd_ack_seq; no other function is
            using this slot at the same time.
    
    Signed-off-by: Gerrit Renker <gerrit@erg.abdn.ac.uk>
    Signed-off-by: Ian McDonald <ian.mcdonald@jandi.co.nz>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@ghostprotocols.net>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index c8d843e983fc..6e23d5b57e79 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -69,7 +69,7 @@ static int dccp_transmit_skb(struct sock *sk, struct sk_buff *skb)
 
 		case DCCP_PKT_SYNC:
 		case DCCP_PKT_SYNCACK:
-			ackno = dcb->dccpd_seq;
+			ackno = dcb->dccpd_ack_seq;
 			/* fall through */
 		default:
 			/*
@@ -507,7 +507,7 @@ void dccp_send_delayed_ack(struct sock *sk)
 	sk_reset_timer(sk, &icsk->icsk_delack_timer, timeout);
 }
 
-void dccp_send_sync(struct sock *sk, const u64 seq,
+void dccp_send_sync(struct sock *sk, const u64 ackno,
 		    const enum dccp_pkt_type pkt_type)
 {
 	/*
@@ -517,14 +517,16 @@ void dccp_send_sync(struct sock *sk, const u64 seq,
 	 */
 	struct sk_buff *skb = alloc_skb(sk->sk_prot->max_header, GFP_ATOMIC);
 
-	if (skb == NULL)
+	if (skb == NULL) {
 		/* FIXME: how to make sure the sync is sent? */
+		DCCP_CRIT("could not send %s", dccp_packet_name(pkt_type));
 		return;
+	}
 
 	/* Reserve space for headers and prepare control bits. */
 	skb_reserve(skb, sk->sk_prot->max_header);
 	DCCP_SKB_CB(skb)->dccpd_type = pkt_type;
-	DCCP_SKB_CB(skb)->dccpd_seq = seq;
+	DCCP_SKB_CB(skb)->dccpd_ack_seq = ackno;
 
 	dccp_transmit_skb(sk, skb);
 }

commit 6626e3628fe42837f733d103e194c6b4473d8669
Author: Gerrit Renker <gerrit@erg.abdn.ac.uk>
Date:   Tue Mar 20 15:00:28 2007 -0300

    [DCCP]: More debug information for dccp_wait_for_ccid
    
    This adds more detail in the wait_for_ccid packet scheduling loop.
    In particular, it informs about (i) when delay is used and (ii) why
    a packet is discarded.
    
    Signed-off-by: Gerrit Renker <gerrit@erg.abdn.ac.uk>
    Signed-off-by: Ian McDonald <ian.mcdonald@jandi.co.nz>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index aa21cc4de37f..c8d843e983fc 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -194,6 +194,7 @@ static int dccp_wait_for_ccid(struct sock *sk, struct sk_buff *skb)
 		rc = ccid_hc_tx_send_packet(dp->dccps_hc_tx_ccid, sk, skb);
 		if (rc <= 0)
 			break;
+		dccp_pr_debug("delayed send by %d msec\n", rc);
 		delay = msecs_to_jiffies(rc);
 		sk->sk_write_pending++;
 		release_sock(sk);
@@ -255,7 +256,7 @@ void dccp_write_xmit(struct sock *sk, int block)
 				DCCP_BUG("err=%d after ccid_hc_tx_packet_sent",
 					 err);
 		} else {
-			dccp_pr_debug("packet discarded\n");
+			dccp_pr_debug("packet discarded due to err=%d\n", err);
 			kfree_skb(skb);
 		}
 	}

commit aabb601b0f08b909b650f1a7bfa1e8d9b5a8d999
Author: Gerrit Renker <gerrit@erg.abdn.ac.uk>
Date:   Fri Mar 9 13:47:58 2007 -0800

    [DCCP]: Initialise write_xmit_timer also on passive sockets
    
    The TX CCID needs the write_xmit_timer for delaying packet sends. Previously
    this timer was only activated on active (connecting) sockets.
    
    This patch initialises the write_xmit_timer in sync with the other timers, i.e.
    the timer will be ready on any socket. This is used by applications with a
    listening socket which start to stream after receiving an initiation by the
    client.  The write_xmit_timer is stopped when the application closes, as before.
    
    Was tested to work and to remove the timer bug reported on dccp@vger.
    
    Also moved timer initialisation into timer.c (static).
    
    Signed-off-by: Gerrit Renker <gerrit@erg.abdn.ac.uk>
    Acked-by: Ian McDonald <ian.mcdonald@jandi.co.nz>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index 3282f2f2291b..aa21cc4de37f 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -213,19 +213,6 @@ static int dccp_wait_for_ccid(struct sock *sk, struct sk_buff *skb)
 	goto out;
 }
 
-static void dccp_write_xmit_timer(unsigned long data) {
-	struct sock *sk = (struct sock *)data;
-	struct dccp_sock *dp = dccp_sk(sk);
-
-	bh_lock_sock(sk);
-	if (sock_owned_by_user(sk))
-		sk_reset_timer(sk, &dp->dccps_xmit_timer, jiffies+1);
-	else
-		dccp_write_xmit(sk, 0);
-	bh_unlock_sock(sk);
-	sock_put(sk);
-}
-
 void dccp_write_xmit(struct sock *sk, int block)
 {
 	struct dccp_sock *dp = dccp_sk(sk);
@@ -434,9 +421,6 @@ static inline void dccp_connect_init(struct sock *sk)
 	dp->dccps_gar = dp->dccps_iss;
 
 	icsk->icsk_retransmits = 0;
-	init_timer(&dp->dccps_xmit_timer);
-	dp->dccps_xmit_timer.data = (unsigned long)sk;
-	dp->dccps_xmit_timer.function = dccp_write_xmit_timer;
 }
 
 int dccp_connect(struct sock *sk)

commit b08d5840d2c5a6ac0bce172f4c861974d718e34b
Author: Patrick McHardy <kaber@trash.net>
Date:   Tue Feb 27 09:57:37 2007 -0800

    [NET]: Fix kfree(skb)
    
    Signed-off-by: Patrick McHardy <kaber@trash.net>
    Acked-by: Paul Moore <paul.moore@hp.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index f5c6aca1dfa4..3282f2f2291b 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -269,7 +269,7 @@ void dccp_write_xmit(struct sock *sk, int block)
 					 err);
 		} else {
 			dccp_pr_debug("packet discarded\n");
-			kfree(skb);
+			kfree_skb(skb);
 		}
 	}
 }

commit c9eaf17341834de00351bf79f16b2d879c8aea96
Author: YOSHIFUJI Hideaki <yoshfuji@linux-ipv6.org>
Date:   Fri Feb 9 23:24:38 2007 +0900

    [NET] DCCP: Fix whitespace errors.
    
    Signed-off-by: YOSHIFUJI Hideaki <yoshfuji@linux-ipv6.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index 3435542e9652..f5c6aca1dfa4 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -87,7 +87,7 @@ static int dccp_transmit_skb(struct sock *sk, struct sk_buff *skb)
 			kfree_skb(skb);
 			return -EPROTO;
 		}
-		
+
 
 		/* Build DCCP header and checksum it. */
 		dh = dccp_zeroed_hdr(skb, dccp_header_size);
@@ -415,7 +415,7 @@ static inline void dccp_connect_init(struct sock *sk)
 
 	sk->sk_err = 0;
 	sock_reset_flag(sk, SOCK_DONE);
-	
+
 	dccp_sync_mss(sk, dst_mtu(dst));
 
 	/*

commit e89862f4c5b3c4ac9afcd8cb1365d2f1e16ddc3b
Author: David S. Miller <davem@sunset.davemloft.net>
Date:   Fri Jan 26 01:04:55 2007 -0800

    [TCP]: Restore SKB socket owner setting in tcp_transmit_skb().
    
    Revert 931731123a103cfb3f70ac4b7abfc71d94ba1f03
    
    We can't elide the skb_set_owner_w() here because things like certain
    netfilter targets (such as owner MATCH) need a socket to be set on the
    SKB for correct operation.
    
    Thanks to Jan Engelhardt and other netfilter list members for
    pointing this out.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index 824569659083..3435542e9652 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -124,7 +124,7 @@ static int dccp_transmit_skb(struct sock *sk, struct sk_buff *skb)
 		DCCP_INC_STATS(DCCP_MIB_OUTSEGS);
 
 		memset(&(IPCB(skb)->opt), 0, sizeof(IPCB(skb)->opt));
-		err = icsk->icsk_af_ops->queue_xmit(skb, sk, 0);
+		err = icsk->icsk_af_ops->queue_xmit(skb, 0);
 		return net_xmit_eval(err);
 	}
 	return -ENOBUFS;
@@ -396,7 +396,7 @@ int dccp_send_reset(struct sock *sk, enum dccp_reset_codes code)
 						      code);
 		if (skb != NULL) {
 			memset(&(IPCB(skb)->opt), 0, sizeof(IPCB(skb)->opt));
-			err = inet_csk(sk)->icsk_af_ops->queue_xmit(skb, sk, 0);
+			err = inet_csk(sk)->icsk_af_ops->queue_xmit(skb, 0);
 			return net_xmit_eval(err);
 		}
 	}

commit 8109b02b5397ed52a32c116163a62a34f4768b26
Author: Arnaldo Carvalho de Melo <acme@mandriva.com>
Date:   Sun Dec 10 16:01:18 2006 -0200

    [DCCP]: Whitespace cleanups
    
    That accumulated over the last months hackaton, shame on me for not
    using git-apply whitespace helping hand, will do that from now on.
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@mandriva.com>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index b4df12b24161..824569659083 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -1,6 +1,6 @@
 /*
  *  net/dccp/output.c
- * 
+ *
  *  An implementation of the DCCP protocol
  *  Arnaldo Carvalho de Melo <acme@conectiva.com.br>
  *
@@ -338,7 +338,6 @@ EXPORT_SYMBOL_GPL(dccp_make_response);
 
 static struct sk_buff *dccp_make_reset(struct sock *sk, struct dst_entry *dst,
 				       const enum dccp_reset_codes code)
-				   
 {
 	struct dccp_hdr *dh;
 	struct dccp_sock *dp = dccp_sk(sk);
@@ -419,14 +418,14 @@ static inline void dccp_connect_init(struct sock *sk)
 	
 	dccp_sync_mss(sk, dst_mtu(dst));
 
- 	/*
+	/*
 	 * SWL and AWL are initially adjusted so that they are not less than
 	 * the initial Sequence Numbers received and sent, respectively:
 	 *	SWL := max(GSR + 1 - floor(W/4), ISR),
 	 *	AWL := max(GSS - W' + 1, ISS).
 	 * These adjustments MUST be applied only at the beginning of the
 	 * connection.
- 	 */
+	 */
 	dccp_update_gss(sk, dp->dccps_iss);
 	dccp_set_seqno(&dp->dccps_awl, max48(dp->dccps_awl, dp->dccps_iss));
 

commit f6282f4da5eb67e08eff94d73a1911c3a008846a
Author: Gerrit Renker <gerrit@erg.abdn.ac.uk>
Date:   Sun Dec 10 00:05:12 2006 -0200

    [DCCP]: Warn when discarding packet due to internal errors
    
    This adds a (debug) warning message which is triggered whenever a packet is
    discarded due to send failure.
    
    It also adds a conditional, so that an interruption during dccp_wait_for_ccid
    is not treated as a `BUG': the rationale is that interruptions are external,
    whereas bug warnings are concerned with the internals.
    
    Signed-off-by: Gerrit Renker <gerrit@erg.abdn.ac.uk>
    Acked-by: Ian McDonald <ian.mcdonald@jandi.co.nz>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@mandriva.com>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index 29a8e8508462..b4df12b24161 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -241,7 +241,7 @@ void dccp_write_xmit(struct sock *sk, int block)
 				break;
 			} else
 				err = dccp_wait_for_ccid(sk, skb);
-			if (err)
+			if (err && err != -EINTR)
 				DCCP_BUG("err=%d after dccp_wait_for_ccid", err);
 		}
 
@@ -267,8 +267,10 @@ void dccp_write_xmit(struct sock *sk, int block)
 			if (err)
 				DCCP_BUG("err=%d after ccid_hc_tx_packet_sent",
 					 err);
-		} else
+		} else {
+			dccp_pr_debug("packet discarded\n");
 			kfree(skb);
+		}
 	}
 }
 

commit 5cc3741d6cc9f07d8ddd9c45cb5088460ce3364f
Author: Ian McDonald <ian.mcdonald@jandi.co.nz>
Date:   Sat Dec 9 23:56:09 2006 -0200

    [DCCP]: Remove timeo from output.c
    
    It simplifies waiting for the CCID module to signal that a packet
    is ready to be sent.  Other simplifications flow on from this such as
    removing constants.
    
    As a result of this EAGAIN is not returned any more by dccp_wait_for_ccid
    (which would otherwise lead to unnecessarily discarding the packet in
    dccp_write_xmit).
    
    Signed-off-by: Ian McDonald <ian.mcdonald@jandi.co.nz>
    Signed-off-by: Gerrit Renker <gerrit@erg.abdn.ac.uk>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@mandriva.com>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index 400c30b6fcae..29a8e8508462 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -175,14 +175,12 @@ void dccp_write_space(struct sock *sk)
 /**
  * dccp_wait_for_ccid - Wait for ccid to tell us we can send a packet
  * @sk: socket to wait for
- * @timeo: for how long
  */
-static int dccp_wait_for_ccid(struct sock *sk, struct sk_buff *skb,
-			      long *timeo)
+static int dccp_wait_for_ccid(struct sock *sk, struct sk_buff *skb)
 {
 	struct dccp_sock *dp = dccp_sk(sk);
 	DEFINE_WAIT(wait);
-	long delay;
+	unsigned long delay;
 	int rc;
 
 	while (1) {
@@ -190,8 +188,6 @@ static int dccp_wait_for_ccid(struct sock *sk, struct sk_buff *skb,
 
 		if (sk->sk_err)
 			goto do_error;
-		if (!*timeo)
-			goto do_nonblock;
 		if (signal_pending(current))
 			goto do_interrupted;
 
@@ -199,12 +195,9 @@ static int dccp_wait_for_ccid(struct sock *sk, struct sk_buff *skb,
 		if (rc <= 0)
 			break;
 		delay = msecs_to_jiffies(rc);
-		if (delay > *timeo || delay < 0)
-			goto do_nonblock;
-
 		sk->sk_write_pending++;
 		release_sock(sk);
-		*timeo -= schedule_timeout(delay);
+		schedule_timeout(delay);
 		lock_sock(sk);
 		sk->sk_write_pending--;
 	}
@@ -215,11 +208,8 @@ static int dccp_wait_for_ccid(struct sock *sk, struct sk_buff *skb,
 do_error:
 	rc = -EPIPE;
 	goto out;
-do_nonblock:
-	rc = -EAGAIN;
-	goto out;
 do_interrupted:
-	rc = sock_intr_errno(*timeo);
+	rc = -EINTR;
 	goto out;
 }
 
@@ -240,8 +230,6 @@ void dccp_write_xmit(struct sock *sk, int block)
 {
 	struct dccp_sock *dp = dccp_sk(sk);
 	struct sk_buff *skb;
-	long timeo = DCCP_XMIT_TIMEO; 	/* If a packet is taking longer than
-					   this we have other issues */
 
 	while ((skb = skb_peek(&sk->sk_write_queue))) {
 		int err = ccid_hc_tx_send_packet(dp->dccps_hc_tx_ccid, sk, skb);
@@ -251,10 +239,8 @@ void dccp_write_xmit(struct sock *sk, int block)
 				sk_reset_timer(sk, &dp->dccps_xmit_timer,
 						msecs_to_jiffies(err)+jiffies);
 				break;
-			} else {
-				err = dccp_wait_for_ccid(sk, skb, &timeo);
-				timeo = DCCP_XMIT_TIMEO;
-			}
+			} else
+				err = dccp_wait_for_ccid(sk, skb);
 			if (err)
 				DCCP_BUG("err=%d after dccp_wait_for_ccid", err);
 		}

commit 6b57c93dc3aa0115b589cb89ef862d46ab9bd95e
Author: Gerrit Renker <gerrit@erg.abdn.ac.uk>
Date:   Tue Nov 28 19:55:06 2006 -0200

    [DCCP]: Use `unsigned' for packet lengths
    
    This patch implements a suggestion by Ian McDonald and
    
     1) Avoids tests against negative packet lengths by using unsigned int
        for packet payload lengths in the CCID send_packet()/packet_sent() routines
    
     2) As a consequence, it removes an now unnecessary test with regard to `len > 0'
        in ccid3_hc_tx_packet_sent: that condition is always true, since
          * negative packet lengths are avoided
          * ccid3_hc_tx_send_packet flags an error whenever the payload length is 0.
            As a consequence, ccid3_hc_tx_packet_sent is never called as all errors
            returned by ccid_hc_tx_send_packet are caught in dccp_write_xmit
    
     3) Removes the third argument of ccid_hc_tx_send_packet (the `len' parameter),
        since it is currently always set to skb->len. The code is updated with regard
        to this parameter change.
    
    Signed-off-by: Gerrit Renker <gerrit@erg.abdn.ac.uk>
    Signed-off-by: Ian McDonald <ian.mcdonald@jandi.co.nz>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@mandriva.com>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index bfd9c5757897..400c30b6fcae 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -195,8 +195,7 @@ static int dccp_wait_for_ccid(struct sock *sk, struct sk_buff *skb,
 		if (signal_pending(current))
 			goto do_interrupted;
 
-		rc = ccid_hc_tx_send_packet(dp->dccps_hc_tx_ccid, sk, skb,
-					    skb->len);
+		rc = ccid_hc_tx_send_packet(dp->dccps_hc_tx_ccid, sk, skb);
 		if (rc <= 0)
 			break;
 		delay = msecs_to_jiffies(rc);
@@ -245,8 +244,7 @@ void dccp_write_xmit(struct sock *sk, int block)
 					   this we have other issues */
 
 	while ((skb = skb_peek(&sk->sk_write_queue))) {
-		int err = ccid_hc_tx_send_packet(dp->dccps_hc_tx_ccid, sk, skb,
-					 skb->len);
+		int err = ccid_hc_tx_send_packet(dp->dccps_hc_tx_ccid, sk, skb);
 
 		if (err > 0) {
 			if (!block) {

commit 59348b19efebfd6a8d0791ff81d207b16594c94b
Author: Gerrit Renker <gerrit@erg.abdn.ac.uk>
Date:   Mon Nov 20 18:39:23 2006 -0200

    [DCCP]: Simplified conditions due to use of enum:8 states
    
    This reaps the benefit of the earlier patch, which changed the type of
    CCID 3 states to use enums, in that many conditions are now simplified
    and the number of possible (unexpected) values is greatly reduced.
    
    In a few instances, this also allowed to simplify pre-conditions; where
    care has been taken to retain logical equivalence.
    
    [DCCP]: Introduce a consistent BUG/WARN message scheme
    
    This refines the existing set of DCCP messages so that
     * BUG(), BUG_ON(), WARN_ON() have meaningful DCCP-specific counterparts
     * DCCP_CRIT (for severe warnings) is not rate-limited
     * DCCP_WARN() is introduced as rate-limited wrapper
    
    Using these allows a faster and cleaner transition to their original
    counterparts once the code has matured into a full DCCP implementation.
    
    Signed-off-by: Gerrit Renker <gerrit@erg.abdn.ac.uk>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@mandriva.com>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index c34eada7f025..bfd9c5757897 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -257,11 +257,8 @@ void dccp_write_xmit(struct sock *sk, int block)
 				err = dccp_wait_for_ccid(sk, skb, &timeo);
 				timeo = DCCP_XMIT_TIMEO;
 			}
-			if (err) {
-				printk(KERN_CRIT "%s:err at dccp_wait_for_ccid"
-						 " %d\n", __FUNCTION__, err);
-				dump_stack();
-			}
+			if (err)
+				DCCP_BUG("err=%d after dccp_wait_for_ccid", err);
 		}
 
 		skb_dequeue(&sk->sk_write_queue);
@@ -283,12 +280,9 @@ void dccp_write_xmit(struct sock *sk, int block)
 
 			err = dccp_transmit_skb(sk, skb);
 			ccid_hc_tx_packet_sent(dp->dccps_hc_tx_ccid, sk, 0, len);
-			if (err) {
-				printk(KERN_CRIT "%s:err from "
-					         "ccid_hc_tx_packet_sent %d\n",
-					         __FUNCTION__, err);
-				dump_stack();
-			}
+			if (err)
+				DCCP_BUG("err=%d after ccid_hc_tx_packet_sent",
+					 err);
 		} else
 			kfree(skb);
 	}

commit 09dbc3895e3242346bd434dae743c456fd28fc6a
Author: Gerrit Renker <gerrit@erg.abdn.ac.uk>
Date:   Tue Nov 14 12:57:34 2006 -0200

    [DCCP]: Miscellaneous code tidy-ups
    
    This patch does not change code; it performs some trivial clean/tidy-ups:
    
      * removal of a `debug_prefix' string in favour of the
        already existing dccp_role(sk)
    
      * add documentation of structures and constants
    
      * separated out the cases for invalid packets (step 1
        of the packet validation)
    
      * removing duplicate statements
    
      * combining declaration & initialisation
    
    Signed-off-by: Gerrit Renker <gerrit@erg.abdn.ac.uk>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@mandriva.com>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index ef22f3cc791a..c34eada7f025 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -333,6 +333,7 @@ struct sk_buff *dccp_make_response(struct sock *sk, struct dst_entry *dst,
 		return NULL;
 	}
 
+	/* Build and checksum header */
 	dh = dccp_zeroed_hdr(skb, dccp_header_size);
 
 	dh->dccph_sport	= inet_sk(sk)->sport;

commit b9df3cb8cf9a96e63dfdcd3056a9cbc71f2459e7
Author: Gerrit Renker <gerrit@erg.abdn.ac.uk>
Date:   Tue Nov 14 11:21:36 2006 -0200

    [TCP/DCCP]: Introduce net_xmit_eval
    
    Throughout the TCP/DCCP (and tunnelling) code, it often happens that the
    return code of a transmit function needs to be tested against NET_XMIT_CN
    which is a value that does not indicate a strict error condition.
    
    This patch uses a macro for these recurring situations which is consistent
    with the already existing macro net_xmit_errno, saving on duplicated code.
    
    Signed-off-by: Gerrit Renker <gerrit@erg.abdn.ac.uk>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@mandriva.com>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index 0994b13f0f15..ef22f3cc791a 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -125,16 +125,7 @@ static int dccp_transmit_skb(struct sock *sk, struct sk_buff *skb)
 
 		memset(&(IPCB(skb)->opt), 0, sizeof(IPCB(skb)->opt));
 		err = icsk->icsk_af_ops->queue_xmit(skb, sk, 0);
-		if (err <= 0)
-			return err;
-
-		/* NET_XMIT_CN is special. It does not guarantee,
-		 * that this packet is lost. It tells that device
-		 * is about to start to drop packets or already
-		 * drops some packets of the same priority and
-		 * invokes us to send less aggressively.
-		 */
-		return err == NET_XMIT_CN ? 0 : err;
+		return net_xmit_eval(err);
 	}
 	return -ENOBUFS;
 }
@@ -426,8 +417,7 @@ int dccp_send_reset(struct sock *sk, enum dccp_reset_codes code)
 		if (skb != NULL) {
 			memset(&(IPCB(skb)->opt), 0, sizeof(IPCB(skb)->opt));
 			err = inet_csk(sk)->icsk_af_ops->queue_xmit(skb, sk, 0);
-			if (err == NET_XMIT_CN)
-				err = 0;
+			return net_xmit_eval(err);
 		}
 	}
 

commit d7f7365f5776723da6df73540d855069c2daaa5c
Author: Gerrit Renker <gerrit@erg.abdn.ac.uk>
Date:   Mon Nov 13 13:34:38 2006 -0200

    [DCCPv6]: Choose a genuine initial sequence number
    
    This
            * resolves a FIXME - DCCPv6 connections started all with
              an initial sequence number of 1;
            * provides a redirection `secure_dccpv6_sequence_number'
              in case the init_sequence_v6 code should be updated later;
            * concentrates the update of S.GAR into dccp_connect_init();
            * removes a duplicate dccp_update_gss() in ipv4.c;
            * uses inet->dport instead of usin->sin_port, due to the
              following assignment in dccp_v4_connect():
                    inet->dport = usin->sin_port;
    
    Signed-off-by: Gerrit Renker <gerrit@erg.abdn.ac.uk>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@mandriva.com>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index 08ee5547a2f2..0994b13f0f15 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -448,7 +448,6 @@ static inline void dccp_connect_init(struct sock *sk)
 	
 	dccp_sync_mss(sk, dst_mtu(dst));
 
-	dccp_update_gss(sk, dp->dccps_iss);
  	/*
 	 * SWL and AWL are initially adjusted so that they are not less than
 	 * the initial Sequence Numbers received and sent, respectively:
@@ -457,8 +456,13 @@ static inline void dccp_connect_init(struct sock *sk)
 	 * These adjustments MUST be applied only at the beginning of the
 	 * connection.
  	 */
+	dccp_update_gss(sk, dp->dccps_iss);
 	dccp_set_seqno(&dp->dccps_awl, max48(dp->dccps_awl, dp->dccps_iss));
 
+	/* S.GAR - greatest valid acknowledgement number received on a non-Sync;
+	 *         initialized to S.ISS (sec. 8.5)                            */
+	dp->dccps_gar = dp->dccps_iss;
+
 	icsk->icsk_retransmits = 0;
 	init_timer(&dp->dccps_xmit_timer);
 	dp->dccps_xmit_timer.data = (unsigned long)sk;

commit e11d9d30802278af22e78d8c10f348b683670cd9
Author: Gerrit Renker <gerrit@erg.abdn.ac.uk>
Date:   Mon Nov 13 13:12:07 2006 -0200

    [DCCP]: Increment sequence numbers on retransmitted Response packets
    
    Problem:

diff --git a/net/dccp/output.c b/net/dccp/output.c
index 992caedd7725..08ee5547a2f2 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -332,6 +332,8 @@ struct sk_buff *dccp_make_response(struct sock *sk, struct dst_entry *dst,
 	skb->dst = dst_clone(dst);
 
 	dreq = dccp_rsk(req);
+	if (inet_rsk(req)->acked)	/* increase ISS upon retransmission */
+		dccp_inc_seqno(&dreq->dreq_iss);
 	DCCP_SKB_CB(skb)->dccpd_type = DCCP_PKT_RESPONSE;
 	DCCP_SKB_CB(skb)->dccpd_seq  = dreq->dreq_iss;
 
@@ -354,6 +356,8 @@ struct sk_buff *dccp_make_response(struct sock *sk, struct dst_entry *dst,
 
 	dccp_csum_outgoing(skb);
 
+	/* We use `acked' to remember that a Response was already sent. */
+	inet_rsk(req)->acked = 1;
 	DCCP_INC_STATS(DCCP_MIB_OUTSEGS);
 	return skb;
 }

commit 6f4e5fff1e4d46714ea554fd83e44eab534e8b11
Author: Gerrit Renker <gerrit@erg.abdn.ac.uk>
Date:   Fri Nov 10 17:43:06 2006 -0200

    [DCCP]: Support for partial checksums (RFC 4340, sec. 9.2)
    
    This patch does the following:
      a) introduces variable-length checksums as specified in [RFC 4340, sec. 9.2]
      b) provides necessary socket options and documentation as to how to use them
      c) basic support and infrastructure for the Minimum Checksum Coverage feature
         [RFC 4340, sec. 9.2.1]: acceptability tests, user notification and user
         interface
    
    In addition, it
    
     (1) fixes two bugs in the DCCPv4 checksum computation:
            * pseudo-header used checksum_len instead of skb->len
            * incorrect checksum coverage calculation based on dccph_x
     (2) removes dccp_v4_verify_checksum() since it reduplicates code of the
         checksum computation; code calling this function is updated accordingly.
     (3) now uses skb_checksum(), which is safer than checksum_partial() if the
         sk_buff has is a non-linear buffer (has pages attached to it).
     (4) fixes an outstanding TODO item:
            * If P.CsCov is too large for the packet size, drop packet and return.
    
    The code has been tested with applications, the latest version of tcpdump now
    comes with support for partial DCCP checksums.
    
    Signed-off-by: Gerrit Renker <gerrit@erg.abdn.ac.uk>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@mandriva.com>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index 51654975e8ea..992caedd7725 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -96,6 +96,7 @@ static int dccp_transmit_skb(struct sock *sk, struct sk_buff *skb)
 		dh->dccph_dport	= inet->dport;
 		dh->dccph_doff	= (dccp_header_size + dcb->dccpd_opt_len) / 4;
 		dh->dccph_ccval	= dcb->dccpd_ccval;
+		dh->dccph_cscov = dp->dccps_pcslen;
 		/* XXX For now we're using only 48 bits sequence numbers */
 		dh->dccph_x	= 1;
 
@@ -115,7 +116,7 @@ static int dccp_transmit_skb(struct sock *sk, struct sk_buff *skb)
 			break;
 		}
 
-		icsk->icsk_af_ops->send_check(sk, skb->len, skb);
+		icsk->icsk_af_ops->send_check(sk, 0, skb);
 
 		if (set_ack)
 			dccp_event_ack_sent(sk);
@@ -329,7 +330,6 @@ struct sk_buff *dccp_make_response(struct sock *sk, struct dst_entry *dst,
 	skb_reserve(skb, sk->sk_prot->max_header);
 
 	skb->dst = dst_clone(dst);
-	skb->csum = 0;
 
 	dreq = dccp_rsk(req);
 	DCCP_SKB_CB(skb)->dccpd_type = DCCP_PKT_RESPONSE;
@@ -352,6 +352,8 @@ struct sk_buff *dccp_make_response(struct sock *sk, struct dst_entry *dst,
 	dccp_hdr_set_ack(dccp_hdr_ack_bits(skb), dreq->dreq_isr);
 	dccp_hdr_response(skb)->dccph_resp_service = dreq->dreq_service;
 
+	dccp_csum_outgoing(skb);
+
 	DCCP_INC_STATS(DCCP_MIB_OUTSEGS);
 	return skb;
 }
@@ -376,7 +378,6 @@ static struct sk_buff *dccp_make_reset(struct sock *sk, struct dst_entry *dst,
 	skb_reserve(skb, sk->sk_prot->max_header);
 
 	skb->dst = dst_clone(dst);
-	skb->csum = 0;
 
 	dccp_inc_seqno(&dp->dccps_gss);
 
@@ -401,7 +402,7 @@ static struct sk_buff *dccp_make_reset(struct sock *sk, struct dst_entry *dst,
 	dccp_hdr_set_ack(dccp_hdr_ack_bits(skb), dp->dccps_gsr);
 
 	dccp_hdr_reset(skb)->dccph_reset_code = code;
-	inet_csk(sk)->icsk_af_ops->send_check(sk, skb->len, skb);
+	inet_csk(sk)->icsk_af_ops->send_check(sk, 0, skb);
 
 	DCCP_INC_STATS(DCCP_MIB_OUTSEGS);
 	return skb;
@@ -475,7 +476,6 @@ int dccp_connect(struct sock *sk)
 	skb_reserve(skb, sk->sk_prot->max_header);
 
 	DCCP_SKB_CB(skb)->dccpd_type = DCCP_PKT_REQUEST;
-	skb->csum = 0;
 
 	dccp_skb_entail(sk, skb);
 	dccp_transmit_skb(sk, skb_clone(skb, GFP_KERNEL));
@@ -507,7 +507,6 @@ void dccp_send_ack(struct sock *sk)
 
 		/* Reserve space for headers */
 		skb_reserve(skb, sk->sk_prot->max_header);
-		skb->csum = 0;
 		DCCP_SKB_CB(skb)->dccpd_type = DCCP_PKT_ACK;
 		dccp_transmit_skb(sk, skb);
 	}
@@ -561,7 +560,6 @@ void dccp_send_sync(struct sock *sk, const u64 seq,
 
 	/* Reserve space for headers and prepare control bits. */
 	skb_reserve(skb, sk->sk_prot->max_header);
-	skb->csum = 0;
 	DCCP_SKB_CB(skb)->dccpd_type = pkt_type;
 	DCCP_SKB_CB(skb)->dccpd_seq = seq;
 
@@ -587,7 +585,6 @@ void dccp_send_close(struct sock *sk, const int active)
 
 	/* Reserve space for headers and prepare control bits. */
 	skb_reserve(skb, sk->sk_prot->max_header);
-	skb->csum = 0;
 	DCCP_SKB_CB(skb)->dccpd_type = dp->dccps_role == DCCP_ROLE_CLIENT ?
 					DCCP_PKT_CLOSE : DCCP_PKT_CLOSEREQ;
 

commit f45b3ec481581f24719d8ab0bc812c02fcedc2bc
Author: Ian McDonald <ian.mcdonald@jandi.co.nz>
Date:   Fri Nov 10 13:09:10 2006 -0200

    [DCCP]: Fix logfile overflow
    
    This patch fixes data being spewed into the logs continually. As the
    code stood if there was a large queue and long delays timeo would go
    down to zero and never get reset.
    
    This fixes it by resetting timeo. Put constant into header as well.
    
    Signed-off-by: Ian McDonald <ian.mcdonald@jandi.co.nz>
    Signed-off-by: Gerrit Renker <gerrit@erg.abdn.ac.uk>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@mandriva.com>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index 1ae2248557c6..51654975e8ea 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -249,8 +249,8 @@ void dccp_write_xmit(struct sock *sk, int block)
 {
 	struct dccp_sock *dp = dccp_sk(sk);
 	struct sk_buff *skb;
-	long timeo = 30000; 	/* If a packet is taking longer than 2 secs
-				   we have other issues */
+	long timeo = DCCP_XMIT_TIMEO; 	/* If a packet is taking longer than
+					   this we have other issues */
 
 	while ((skb = skb_peek(&sk->sk_write_queue))) {
 		int err = ccid_hc_tx_send_packet(dp->dccps_hc_tx_ccid, sk, skb,
@@ -261,8 +261,10 @@ void dccp_write_xmit(struct sock *sk, int block)
 				sk_reset_timer(sk, &dp->dccps_xmit_timer,
 						msecs_to_jiffies(err)+jiffies);
 				break;
-			} else
+			} else {
 				err = dccp_wait_for_ccid(sk, skb, &timeo);
+				timeo = DCCP_XMIT_TIMEO;
+			}
 			if (err) {
 				printk(KERN_CRIT "%s:err at dccp_wait_for_ccid"
 						 " %d\n", __FUNCTION__, err);

commit 9b42078ed6edfe04e9dc9a59b946ad912aeef717
Author: Gerrit Renker <gerrit@erg.abdn.ac.uk>
Date:   Fri Nov 10 11:22:32 2006 -0200

    [DCCP]: Combine allocating & zeroing header space on skb
    
    This is a code simplification:
    it combines three often recurring operations into one inline function,
    
            * allocate `len' bytes header space in skb
            * fill these `len' bytes with zeroes
            * cast the start of this header space as dccp_hdr
    
    Signed-off-by: Gerrit Renker <gerrit@erg.abdn.ac.uk>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@mandriva.com>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index 2cc4f4b2a9dd..1ae2248557c6 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -88,11 +88,9 @@ static int dccp_transmit_skb(struct sock *sk, struct sk_buff *skb)
 			return -EPROTO;
 		}
 		
-		skb->h.raw = skb_push(skb, dccp_header_size);
-		dh = dccp_hdr(skb);
 
 		/* Build DCCP header and checksum it. */
-		memset(dh, 0, dccp_header_size);
+		dh = dccp_zeroed_hdr(skb, dccp_header_size);
 		dh->dccph_type	= dcb->dccpd_type;
 		dh->dccph_sport	= inet->sport;
 		dh->dccph_dport	= inet->dport;
@@ -340,10 +338,7 @@ struct sk_buff *dccp_make_response(struct sock *sk, struct dst_entry *dst,
 		return NULL;
 	}
 
-	skb->h.raw = skb_push(skb, dccp_header_size);
-
-	dh = dccp_hdr(skb);
-	memset(dh, 0, dccp_header_size);
+	dh = dccp_zeroed_hdr(skb, dccp_header_size);
 
 	dh->dccph_sport	= inet_sk(sk)->sport;
 	dh->dccph_dport	= inet_rsk(req)->rmt_port;
@@ -392,10 +387,7 @@ static struct sk_buff *dccp_make_reset(struct sock *sk, struct dst_entry *dst,
 		return NULL;
 	}
 
-	skb->h.raw = skb_push(skb, dccp_header_size);
-
-	dh = dccp_hdr(skb);
-	memset(dh, 0, dccp_header_size);
+	dh = dccp_zeroed_hdr(skb, dccp_header_size);
 
 	dh->dccph_sport	= inet_sk(sk)->sport;
 	dh->dccph_dport	= inet_sk(sk)->dport;

commit 931731123a103cfb3f70ac4b7abfc71d94ba1f03
Author: David S. Miller <davem@sunset.davemloft.net>
Date:   Thu Nov 9 19:58:25 2006 -0800

    [TCP]: Don't set SKB owner in tcp_transmit_skb().
    
    The data itself is already charged to the SKB, doing
    the skb_set_owner_w() just generates a lot of noise and
    extra atomics we don't really need.
    
    Lmbench improvements on lat_tcp are minimal:
    
    before:
    TCP latency using localhost: 23.2701 microseconds
    TCP latency using localhost: 23.1994 microseconds
    TCP latency using localhost: 23.2257 microseconds
    
    after:
    TCP latency using localhost: 22.8380 microseconds
    TCP latency using localhost: 22.9465 microseconds
    TCP latency using localhost: 22.8462 microseconds
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index 7102e3aed4ca..2cc4f4b2a9dd 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -125,7 +125,7 @@ static int dccp_transmit_skb(struct sock *sk, struct sk_buff *skb)
 		DCCP_INC_STATS(DCCP_MIB_OUTSEGS);
 
 		memset(&(IPCB(skb)->opt), 0, sizeof(IPCB(skb)->opt));
-		err = icsk->icsk_af_ops->queue_xmit(skb, 0);
+		err = icsk->icsk_af_ops->queue_xmit(skb, sk, 0);
 		if (err <= 0)
 			return err;
 
@@ -426,7 +426,7 @@ int dccp_send_reset(struct sock *sk, enum dccp_reset_codes code)
 						      code);
 		if (skb != NULL) {
 			memset(&(IPCB(skb)->opt), 0, sizeof(IPCB(skb)->opt));
-			err = inet_csk(sk)->icsk_af_ops->queue_xmit(skb, 0);
+			err = inet_csk(sk)->icsk_af_ops->queue_xmit(skb, sk, 0);
 			if (err == NET_XMIT_CN)
 				err = 0;
 		}

commit 97e5848dd39e7e76bd6077735ebb5473763ab9c5
Author: Ian McDonald <ian.mcdonald@jandi.co.nz>
Date:   Sat Aug 26 19:16:45 2006 -0700

    [DCCP]: Introduce tx buffering
    
    This adds transmit buffering to DCCP.
    
    I have tested with CCID2/3 and with loss and rate limiting.
    
    Signed off by: Ian McDonald <ian.mcdonald@jandi.co.nz>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index 58669beee132..7102e3aed4ca 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -198,7 +198,7 @@ static int dccp_wait_for_ccid(struct sock *sk, struct sk_buff *skb,
 	while (1) {
 		prepare_to_wait(sk->sk_sleep, &wait, TASK_INTERRUPTIBLE);
 
-		if (sk->sk_err || (sk->sk_shutdown & SEND_SHUTDOWN))
+		if (sk->sk_err)
 			goto do_error;
 		if (!*timeo)
 			goto do_nonblock;
@@ -234,37 +234,72 @@ static int dccp_wait_for_ccid(struct sock *sk, struct sk_buff *skb,
 	goto out;
 }
 
-int dccp_write_xmit(struct sock *sk, struct sk_buff *skb, long *timeo)
+static void dccp_write_xmit_timer(unsigned long data) {
+	struct sock *sk = (struct sock *)data;
+	struct dccp_sock *dp = dccp_sk(sk);
+
+	bh_lock_sock(sk);
+	if (sock_owned_by_user(sk))
+		sk_reset_timer(sk, &dp->dccps_xmit_timer, jiffies+1);
+	else
+		dccp_write_xmit(sk, 0);
+	bh_unlock_sock(sk);
+	sock_put(sk);
+}
+
+void dccp_write_xmit(struct sock *sk, int block)
 {
-	const struct dccp_sock *dp = dccp_sk(sk);
-	int err = ccid_hc_tx_send_packet(dp->dccps_hc_tx_ccid, sk, skb,
+	struct dccp_sock *dp = dccp_sk(sk);
+	struct sk_buff *skb;
+	long timeo = 30000; 	/* If a packet is taking longer than 2 secs
+				   we have other issues */
+
+	while ((skb = skb_peek(&sk->sk_write_queue))) {
+		int err = ccid_hc_tx_send_packet(dp->dccps_hc_tx_ccid, sk, skb,
 					 skb->len);
 
-	if (err > 0)
-		err = dccp_wait_for_ccid(sk, skb, timeo);
+		if (err > 0) {
+			if (!block) {
+				sk_reset_timer(sk, &dp->dccps_xmit_timer,
+						msecs_to_jiffies(err)+jiffies);
+				break;
+			} else
+				err = dccp_wait_for_ccid(sk, skb, &timeo);
+			if (err) {
+				printk(KERN_CRIT "%s:err at dccp_wait_for_ccid"
+						 " %d\n", __FUNCTION__, err);
+				dump_stack();
+			}
+		}
 
-	if (err == 0) {
-		struct dccp_skb_cb *dcb = DCCP_SKB_CB(skb);
-		const int len = skb->len;
+		skb_dequeue(&sk->sk_write_queue);
+		if (err == 0) {
+			struct dccp_skb_cb *dcb = DCCP_SKB_CB(skb);
+			const int len = skb->len;
 
-		if (sk->sk_state == DCCP_PARTOPEN) {
-			/* See 8.1.5.  Handshake Completion */
-			inet_csk_schedule_ack(sk);
-			inet_csk_reset_xmit_timer(sk, ICSK_TIME_DACK,
+			if (sk->sk_state == DCCP_PARTOPEN) {
+				/* See 8.1.5.  Handshake Completion */
+				inet_csk_schedule_ack(sk);
+				inet_csk_reset_xmit_timer(sk, ICSK_TIME_DACK,
 						  inet_csk(sk)->icsk_rto,
 						  DCCP_RTO_MAX);
-			dcb->dccpd_type = DCCP_PKT_DATAACK;
-		} else if (dccp_ack_pending(sk))
-			dcb->dccpd_type = DCCP_PKT_DATAACK;
-		else
-			dcb->dccpd_type = DCCP_PKT_DATA;
-
-		err = dccp_transmit_skb(sk, skb);
-		ccid_hc_tx_packet_sent(dp->dccps_hc_tx_ccid, sk, 0, len);
-	} else
-		kfree_skb(skb);
-
-	return err;
+				dcb->dccpd_type = DCCP_PKT_DATAACK;
+			} else if (dccp_ack_pending(sk))
+				dcb->dccpd_type = DCCP_PKT_DATAACK;
+			else
+				dcb->dccpd_type = DCCP_PKT_DATA;
+
+			err = dccp_transmit_skb(sk, skb);
+			ccid_hc_tx_packet_sent(dp->dccps_hc_tx_ccid, sk, 0, len);
+			if (err) {
+				printk(KERN_CRIT "%s:err from "
+					         "ccid_hc_tx_packet_sent %d\n",
+					         __FUNCTION__, err);
+				dump_stack();
+			}
+		} else
+			kfree(skb);
+	}
 }
 
 int dccp_retransmit_skb(struct sock *sk, struct sk_buff *skb)
@@ -426,6 +461,9 @@ static inline void dccp_connect_init(struct sock *sk)
 	dccp_set_seqno(&dp->dccps_awl, max48(dp->dccps_awl, dp->dccps_iss));
 
 	icsk->icsk_retransmits = 0;
+	init_timer(&dp->dccps_xmit_timer);
+	dp->dccps_xmit_timer.data = (unsigned long)sk;
+	dp->dccps_xmit_timer.function = dccp_write_xmit_timer;
 }
 
 int dccp_connect(struct sock *sk)
@@ -560,8 +598,10 @@ void dccp_send_close(struct sock *sk, const int active)
 					DCCP_PKT_CLOSE : DCCP_PKT_CLOSEREQ;
 
 	if (active) {
+		dccp_write_xmit(sk, 1);
 		dccp_skb_entail(sk, skb);
 		dccp_transmit_skb(sk, skb_clone(skb, prio));
+		/* FIXME do we need a retransmit timer here? */
 	} else
 		dccp_transmit_skb(sk, skb);
 }

commit 6ab3d5624e172c553004ecc862bfeac16d9d68b7
Author: Jrn Engel <joern@wohnheim.fh-wedel.de>
Date:   Fri Jun 30 19:25:36 2006 +0200

    Remove obsolete #include <linux/config.h>
    
    Signed-off-by: Jrn Engel <joern@wohnheim.fh-wedel.de>
    Signed-off-by: Adrian Bunk <bunk@stusta.de>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index 7409e4a3abdf..58669beee132 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -10,7 +10,6 @@
  *	2 of the License, or (at your option) any later version.
  */
 
-#include <linux/config.h>
 #include <linux/dccp.h>
 #include <linux/kernel.h>
 #include <linux/skbuff.h>

commit 2d0817d11eaec57435feb61493331a763f732a2b
Author: Arnaldo Carvalho de Melo <acme@mandriva.com>
Date:   Mon Mar 20 22:32:06 2006 -0800

    [DCCP] options: Make dccp_insert_options & friends yell on error
    
    And not the silly LIMIT_NETDEBUG and silently return without inserting
    the option requested.
    
    Also drop some old debugging messages associated to option insertion.
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@mandriva.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index 2975e3d7a48c..7409e4a3abdf 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -83,7 +83,11 @@ static int dccp_transmit_skb(struct sock *sk, struct sk_buff *skb)
 		}
 
 		dcb->dccpd_seq = dp->dccps_gss;
-		dccp_insert_options(sk, skb);
+
+		if (dccp_insert_options(sk, skb)) {
+			kfree_skb(skb);
+			return -EPROTO;
+		}
 		
 		skb->h.raw = skb_push(skb, dccp_header_size);
 		dh = dccp_hdr(skb);
@@ -296,7 +300,11 @@ struct sk_buff *dccp_make_response(struct sock *sk, struct dst_entry *dst,
 	dreq = dccp_rsk(req);
 	DCCP_SKB_CB(skb)->dccpd_type = DCCP_PKT_RESPONSE;
 	DCCP_SKB_CB(skb)->dccpd_seq  = dreq->dreq_iss;
-	dccp_insert_options(sk, skb);
+
+	if (dccp_insert_options(sk, skb)) {
+		kfree_skb(skb);
+		return NULL;
+	}
 
 	skb->h.raw = skb_push(skb, dccp_header_size);
 
@@ -344,7 +352,11 @@ static struct sk_buff *dccp_make_reset(struct sock *sk, struct dst_entry *dst,
 	DCCP_SKB_CB(skb)->dccpd_reset_code = code;
 	DCCP_SKB_CB(skb)->dccpd_type	   = DCCP_PKT_RESET;
 	DCCP_SKB_CB(skb)->dccpd_seq	   = dp->dccps_gss;
-	dccp_insert_options(sk, skb);
+
+	if (dccp_insert_options(sk, skb)) {
+		kfree_skb(skb);
+		return NULL;
+	}
 
 	skb->h.raw = skb_push(skb, dccp_header_size);
 

commit 118b2c9532c853ebdf15c21128d30a343b89ea45
Author: Arnaldo Carvalho de Melo <acme@mandriva.com>
Date:   Mon Mar 20 22:31:09 2006 -0800

    [DCCP]: Use sk->sk_prot->max_header consistently for non-data packets
    
    Using this also provides opportunities for introducing
    inet_csk_alloc_skb that would call alloc_skb, account it to the sock
    and skb_reserve(max_header), but I'll leave this for later, for now
    using sk_prot->max_header consistently is enough.
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@mandriva.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index 6f3a5f02a39a..2975e3d7a48c 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -49,7 +49,7 @@ static int dccp_transmit_skb(struct sock *sk, struct sk_buff *skb)
 		struct dccp_skb_cb *dcb = DCCP_SKB_CB(skb);
 		struct dccp_hdr *dh;
 		/* XXX For now we're using only 48 bits sequence numbers */
-		const int dccp_header_size = sizeof(*dh) +
+		const u32 dccp_header_size = sizeof(*dh) +
 					     sizeof(struct dccp_hdr_ext) +
 					  dccp_packet_hdr_len(dcb->dccpd_type);
 		int err, set_ack = 1;
@@ -279,17 +279,16 @@ struct sk_buff *dccp_make_response(struct sock *sk, struct dst_entry *dst,
 {
 	struct dccp_hdr *dh;
 	struct dccp_request_sock *dreq;
-	const int dccp_header_size = sizeof(struct dccp_hdr) +
+	const u32 dccp_header_size = sizeof(struct dccp_hdr) +
 				     sizeof(struct dccp_hdr_ext) +
 				     sizeof(struct dccp_hdr_response);
-	struct sk_buff *skb = sock_wmalloc(sk, MAX_HEADER + DCCP_MAX_OPT_LEN +
-					       dccp_header_size, 1,
+	struct sk_buff *skb = sock_wmalloc(sk, sk->sk_prot->max_header, 1,
 					   GFP_ATOMIC);
 	if (skb == NULL)
 		return NULL;
 
 	/* Reserve space for headers. */
-	skb_reserve(skb, MAX_HEADER + DCCP_MAX_OPT_LEN + dccp_header_size);
+	skb_reserve(skb, sk->sk_prot->max_header);
 
 	skb->dst = dst_clone(dst);
 	skb->csum = 0;
@@ -326,17 +325,16 @@ static struct sk_buff *dccp_make_reset(struct sock *sk, struct dst_entry *dst,
 {
 	struct dccp_hdr *dh;
 	struct dccp_sock *dp = dccp_sk(sk);
-	const int dccp_header_size = sizeof(struct dccp_hdr) +
+	const u32 dccp_header_size = sizeof(struct dccp_hdr) +
 				     sizeof(struct dccp_hdr_ext) +
 				     sizeof(struct dccp_hdr_reset);
-	struct sk_buff *skb = sock_wmalloc(sk, MAX_HEADER + DCCP_MAX_OPT_LEN +
-					       dccp_header_size, 1,
+	struct sk_buff *skb = sock_wmalloc(sk, sk->sk_prot->max_header, 1,
 					   GFP_ATOMIC);
 	if (skb == NULL)
 		return NULL;
 
 	/* Reserve space for headers. */
-	skb_reserve(skb, MAX_HEADER + DCCP_MAX_OPT_LEN + dccp_header_size);
+	skb_reserve(skb, sk->sk_prot->max_header);
 
 	skb->dst = dst_clone(dst);
 	skb->csum = 0;
@@ -426,12 +424,12 @@ int dccp_connect(struct sock *sk)
 
 	dccp_connect_init(sk);
 
-	skb = alloc_skb(MAX_DCCP_HEADER + 15, sk->sk_allocation);
+	skb = alloc_skb(sk->sk_prot->max_header, sk->sk_allocation);
 	if (unlikely(skb == NULL))
 		return -ENOBUFS;
 
 	/* Reserve space for headers. */
-	skb_reserve(skb, MAX_DCCP_HEADER);
+	skb_reserve(skb, sk->sk_prot->max_header);
 
 	DCCP_SKB_CB(skb)->dccpd_type = DCCP_PKT_REQUEST;
 	skb->csum = 0;
@@ -452,7 +450,8 @@ void dccp_send_ack(struct sock *sk)
 {
 	/* If we have been reset, we may not send again. */
 	if (sk->sk_state != DCCP_CLOSED) {
-		struct sk_buff *skb = alloc_skb(MAX_DCCP_HEADER, GFP_ATOMIC);
+		struct sk_buff *skb = alloc_skb(sk->sk_prot->max_header,
+						GFP_ATOMIC);
 
 		if (skb == NULL) {
 			inet_csk_schedule_ack(sk);
@@ -464,7 +463,7 @@ void dccp_send_ack(struct sock *sk)
 		}
 
 		/* Reserve space for headers */
-		skb_reserve(skb, MAX_DCCP_HEADER);
+		skb_reserve(skb, sk->sk_prot->max_header);
 		skb->csum = 0;
 		DCCP_SKB_CB(skb)->dccpd_type = DCCP_PKT_ACK;
 		dccp_transmit_skb(sk, skb);
@@ -511,14 +510,14 @@ void dccp_send_sync(struct sock *sk, const u64 seq,
 	 * dccp_transmit_skb() will set the ownership to this
 	 * sock.
 	 */
-	struct sk_buff *skb = alloc_skb(MAX_DCCP_HEADER, GFP_ATOMIC);
+	struct sk_buff *skb = alloc_skb(sk->sk_prot->max_header, GFP_ATOMIC);
 
 	if (skb == NULL)
 		/* FIXME: how to make sure the sync is sent? */
 		return;
 
 	/* Reserve space for headers and prepare control bits. */
-	skb_reserve(skb, MAX_DCCP_HEADER);
+	skb_reserve(skb, sk->sk_prot->max_header);
 	skb->csum = 0;
 	DCCP_SKB_CB(skb)->dccpd_type = pkt_type;
 	DCCP_SKB_CB(skb)->dccpd_seq = seq;

commit c25a18ba347f091d1ce620ba33e6772b60a528e1
Author: Arnaldo Carvalho de Melo <acme@mandriva.com>
Date:   Mon Mar 20 21:58:56 2006 -0800

    [DCCP]: Uninline some functions
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@mandriva.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index 8c83aa51572e..6f3a5f02a39a 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -27,7 +27,7 @@ static inline void dccp_event_ack_sent(struct sock *sk)
 	inet_csk_clear_xmit_timer(sk, ICSK_TIME_DACK);
 }
 
-static inline void dccp_skb_entail(struct sock *sk, struct sk_buff *skb)
+static void dccp_skb_entail(struct sock *sk, struct sk_buff *skb)
 {
 	skb_set_owner_w(skb, sk);
 	WARN_ON(sk->sk_send_head);

commit b61fafc4ef3faf54236d57e3b230ca19167663bf
Author: Arnaldo Carvalho de Melo <acme@mandriva.com>
Date:   Mon Mar 20 21:25:11 2006 -0800

    [DCCP]: Move the IPv4 specific bits from proto.c to ipv4.c
    
    With this patch in place we can break down the complexity by better
    compartmentalizing the code that is common to ipv6 and ipv4.
    
    Now we have these modules:
    Module                  Size  Used by
    dccp_diag               1344  0
    inet_diag               9448  1 dccp_diag
    dccp_ccid3             15856  0
    dccp_tfrc_lib          12320  1 dccp_ccid3
    dccp_ccid2              5764  0
    dccp_ipv4              16996  2
    dccp                   48208  4 dccp_diag,dccp_ccid3,dccp_ccid2,dccp_ipv4
    
    dccp_ipv6 still requires dccp_ipv4 due to dccp_ipv6_mapped, that is
    the next target to work on the "hey, ipv4 is legacy, I only want ipv6
    dude!" direction.
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@mandriva.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index 6bd21e37686e..8c83aa51572e 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -526,6 +526,8 @@ void dccp_send_sync(struct sock *sk, const u64 seq,
 	dccp_transmit_skb(sk, skb);
 }
 
+EXPORT_SYMBOL_GPL(dccp_send_sync);
+
 /*
  * Send a DCCP_PKT_CLOSE/CLOSEREQ. The caller locks the socket for us. This
  * cannot be allowed to fail queueing a DCCP_PKT_CLOSE/CLOSEREQ frame under

commit 0a1ec676ddbee712e1c1da679be4bdc529caf215
Author: Arnaldo Carvalho de Melo <acme@mandriva.com>
Date:   Mon Mar 20 21:23:59 2006 -0800

    [DCCP]: Dont use dccp_v4_checksum in dccp_make_response
    
    dccp_make_response is shared by ipv4/6 and the ipv6 code was
    recalculating the checksum, not good, so move the dccp_v4_checksum
    call to dccp_v4_send_response.
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@mandriva.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index 9922d2696b9c..6bd21e37686e 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -314,9 +314,6 @@ struct sk_buff *dccp_make_response(struct sock *sk, struct dst_entry *dst,
 	dccp_hdr_set_ack(dccp_hdr_ack_bits(skb), dreq->dreq_isr);
 	dccp_hdr_response(skb)->dccph_resp_service = dreq->dreq_service;
 
-	dh->dccph_checksum = dccp_v4_checksum(skb, inet_rsk(req)->loc_addr,
-					      inet_rsk(req)->rmt_addr);
-
 	DCCP_INC_STATS(DCCP_MIB_OUTSEGS);
 	return skb;
 }

commit 017487d7d1e905a5bb529f6a2bc8cf8ea14e2307
Author: Arnaldo Carvalho de Melo <acme@mandriva.com>
Date:   Mon Mar 20 19:25:24 2006 -0800

    [DCCP]: Generalize dccp_v4_send_reset
    
    Renaming it to dccp_send_reset and moving it from the ipv4 specific
    code to the core dccp code.
    
    This fixes some bugs in IPV6 where timers would send v4 resets, etc.
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@mandriva.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index 0cc2bcf56522..9922d2696b9c 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -323,8 +323,8 @@ struct sk_buff *dccp_make_response(struct sock *sk, struct dst_entry *dst,
 
 EXPORT_SYMBOL_GPL(dccp_make_response);
 
-struct sk_buff *dccp_make_reset(struct sock *sk, struct dst_entry *dst,
-				const enum dccp_reset_codes code)
+static struct sk_buff *dccp_make_reset(struct sock *sk, struct dst_entry *dst,
+				       const enum dccp_reset_codes code)
 				   
 {
 	struct dccp_hdr *dh;
@@ -366,14 +366,34 @@ struct sk_buff *dccp_make_reset(struct sock *sk, struct dst_entry *dst,
 	dccp_hdr_set_ack(dccp_hdr_ack_bits(skb), dp->dccps_gsr);
 
 	dccp_hdr_reset(skb)->dccph_reset_code = code;
-
-	dh->dccph_checksum = dccp_v4_checksum(skb, inet_sk(sk)->saddr,
-					      inet_sk(sk)->daddr);
+	inet_csk(sk)->icsk_af_ops->send_check(sk, skb->len, skb);
 
 	DCCP_INC_STATS(DCCP_MIB_OUTSEGS);
 	return skb;
 }
 
+int dccp_send_reset(struct sock *sk, enum dccp_reset_codes code)
+{
+	/*
+	 * FIXME: what if rebuild_header fails?
+	 * Should we be doing a rebuild_header here?
+	 */
+	int err = inet_sk_rebuild_header(sk);
+
+	if (err == 0) {
+		struct sk_buff *skb = dccp_make_reset(sk, sk->sk_dst_cache,
+						      code);
+		if (skb != NULL) {
+			memset(&(IPCB(skb)->opt), 0, sizeof(IPCB(skb)->opt));
+			err = inet_csk(sk)->icsk_af_ops->queue_xmit(skb, 0);
+			if (err == NET_XMIT_CN)
+				err = 0;
+		}
+	}
+
+	return err;
+}
+
 /*
  * Do all connect socket setups that can be done AF independent.
  */

commit afe00251dd9b53d51de91ff0099961f42bbf3754
Author: Andrea Bittau <a.bittau@cs.ucl.ac.uk>
Date:   Mon Mar 20 17:43:56 2006 -0800

    [DCCP]: Initial feature negotiation implementation
    
    Still needs more work, but boots and doesn't crashes, even
    does some negotiation!
    
    18:38:52.174934  127.0.0.1.43458 > 127.0.0.1.5001: request <change_l ack_ratio 2, change_r ccid 2, change_l ccid 2>
    18:38:52.218526  127.0.0.1.5001 > 127.0.0.1.43458: response <nop, nop, change_l ack_ratio 2, confirm_r ccid 2 2, confirm_l ccid 2 2, confirm_r ack_ratio 2>
    18:38:52.185398  127.0.0.1.43458 > 127.0.0.1.5001: <nop, confirm_r ack_ratio 2, ack_vector0 0x00, elapsed_time 212>
    
    :-)
    
    Signed-off-by: Andrea Bittau <a.bittau@cs.ucl.ac.uk>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@mandriva.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index efd7ffb903a1..0cc2bcf56522 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -64,6 +64,10 @@ static int dccp_transmit_skb(struct sock *sk, struct sk_buff *skb)
 		case DCCP_PKT_DATAACK:
 			break;
 
+		case DCCP_PKT_REQUEST:
+			set_ack = 0;
+			/* fall through */
+
 		case DCCP_PKT_SYNC:
 		case DCCP_PKT_SYNCACK:
 			ackno = dcb->dccpd_seq;

commit 14c850212ed8f8cbb5972ad6b8812e08a0bc901c
Author: Arnaldo Carvalho de Melo <acme@mandriva.com>
Date:   Tue Dec 27 02:43:12 2005 -0200

    [INET_SOCK]: Move struct inet_sock & helper functions to net/inet_sock.h
    
    To help in reducing the number of include dependencies, several files were
    touched as they were getting needed headers indirectly for stuff they use.
    
    Thanks also to Alan Menegotto for pointing out that net/dccp/proto.c had
    linux/dccp.h include twice.
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@mandriva.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index 95a3c2c6a3ce..efd7ffb903a1 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -15,6 +15,7 @@
 #include <linux/kernel.h>
 #include <linux/skbuff.h>
 
+#include <net/inet_sock.h>
 #include <net/sock.h>
 
 #include "ackvec.h"

commit d83d8461f902c672bc1bd8fbc6a94e19f092da97
Author: Arnaldo Carvalho de Melo <acme@mandriva.com>
Date:   Tue Dec 13 23:26:10 2005 -0800

    [IP_SOCKGLUE]: Remove most of the tcp specific calls
    
    As DCCP needs to be called in the same spots.
    
    Now we have a member in inet_sock (is_icsk), set at sock creation time from
    struct inet_protosw->flags (if INET_PROTOSW_ICSK is set, like for TCP and
    DCCP) to see if a struct sock instance is a inet_connection_sock for places
    like the ones in ip_sockglue.c (v4 and v6) where we previously were looking if
    sk_type was SOCK_STREAM, that is insufficient because we now use the same code
    for DCCP, that has sk_type SOCK_DCCP.
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@mandriva.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index c40f7f8a328b..95a3c2c6a3ce 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -134,12 +134,13 @@ static int dccp_transmit_skb(struct sock *sk, struct sk_buff *skb)
 
 unsigned int dccp_sync_mss(struct sock *sk, u32 pmtu)
 {
+	struct inet_connection_sock *icsk = inet_csk(sk);
 	struct dccp_sock *dp = dccp_sk(sk);
-	int mss_now = (pmtu - inet_csk(sk)->icsk_af_ops->net_header_len -
+	int mss_now = (pmtu - icsk->icsk_af_ops->net_header_len -
 		       sizeof(struct dccp_hdr) - sizeof(struct dccp_hdr_ext));
 
 	/* Now subtract optional transport overhead */
-	mss_now -= dp->dccps_ext_header_len;
+	mss_now -= icsk->icsk_ext_hdr_len;
 
 	/*
 	 * FIXME: this should come from the CCID infrastructure, where, say,
@@ -152,7 +153,7 @@ unsigned int dccp_sync_mss(struct sock *sk, u32 pmtu)
 	mss_now -= ((5 + 6 + 10 + 6 + 6 + 6 + 3) / 4) * 4;
 
 	/* And store cached results */
-	dp->dccps_pmtu_cookie = pmtu;
+	icsk->icsk_pmtu_cookie = pmtu;
 	dp->dccps_mss_cache = mss_now;
 
 	return mss_now;

commit f21e68caa0ddffddf98a1e729e734a470957b6ec
Author: Arnaldo Carvalho de Melo <acme@mandriva.com>
Date:   Tue Dec 13 23:24:16 2005 -0800

    [DCCP]: Prepare the AF agnostic core for the introduction of DCCPv6
    
    Basically exports a similar set of functions as the one exported by
    the non-AF specific TCP code.
    
    In the process moved some non-AF specific code from dccp_v4_connect to
    dccp_connect_init and moved the checksum verification from
    dccp_invalid_packet to dccp_v4_rcv, so as to use it in dccp_v6_rcv
    too.
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@mandriva.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index f35880503bb8..c40f7f8a328b 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -135,12 +135,6 @@ static int dccp_transmit_skb(struct sock *sk, struct sk_buff *skb)
 unsigned int dccp_sync_mss(struct sock *sk, u32 pmtu)
 {
 	struct dccp_sock *dp = dccp_sk(sk);
-	/*
-	 * FIXME: we really should be using the af_specific thing to support
-	 * 	  IPv6.
-	 * mss_now = pmtu - tp->af_specific->net_header_len -
-	 * 	     sizeof(struct dccp_hdr) - sizeof(struct dccp_hdr_ext);
-	 */
 	int mss_now = (pmtu - inet_csk(sk)->icsk_af_ops->net_header_len -
 		       sizeof(struct dccp_hdr) - sizeof(struct dccp_hdr_ext));
 
@@ -164,6 +158,8 @@ unsigned int dccp_sync_mss(struct sock *sk, u32 pmtu)
 	return mss_now;
 }
 
+EXPORT_SYMBOL_GPL(dccp_sync_mss);
+
 void dccp_write_space(struct sock *sk)
 {
 	read_lock(&sk->sk_callback_lock);
@@ -319,6 +315,8 @@ struct sk_buff *dccp_make_response(struct sock *sk, struct dst_entry *dst,
 	return skb;
 }
 
+EXPORT_SYMBOL_GPL(dccp_make_response);
+
 struct sk_buff *dccp_make_reset(struct sock *sk, struct dst_entry *dst,
 				const enum dccp_reset_codes code)
 				   
@@ -375,6 +373,7 @@ struct sk_buff *dccp_make_reset(struct sock *sk, struct dst_entry *dst,
  */
 static inline void dccp_connect_init(struct sock *sk)
 {
+	struct dccp_sock *dp = dccp_sk(sk);
 	struct dst_entry *dst = __sk_dst_get(sk);
 	struct inet_connection_sock *icsk = inet_csk(sk);
 
@@ -383,10 +382,16 @@ static inline void dccp_connect_init(struct sock *sk)
 	
 	dccp_sync_mss(sk, dst_mtu(dst));
 
-	/*
-	 * FIXME: set dp->{dccps_swh,dccps_swl}, with
-	 * something like dccp_inc_seq
-	 */
+	dccp_update_gss(sk, dp->dccps_iss);
+ 	/*
+	 * SWL and AWL are initially adjusted so that they are not less than
+	 * the initial Sequence Numbers received and sent, respectively:
+	 *	SWL := max(GSR + 1 - floor(W/4), ISR),
+	 *	AWL := max(GSS - W' + 1, ISS).
+	 * These adjustments MUST be applied only at the beginning of the
+	 * connection.
+ 	 */
+	dccp_set_seqno(&dp->dccps_awl, max48(dp->dccps_awl, dp->dccps_iss));
 
 	icsk->icsk_retransmits = 0;
 }
@@ -418,6 +423,8 @@ int dccp_connect(struct sock *sk)
 	return 0;
 }
 
+EXPORT_SYMBOL_GPL(dccp_connect);
+
 void dccp_send_ack(struct sock *sk)
 {
 	/* If we have been reset, we may not send again. */

commit 57cca05af1e20fdc65b55be52c042c234f86c866
Author: Arnaldo Carvalho de Melo <acme@mandriva.com>
Date:   Tue Dec 13 23:16:16 2005 -0800

    [DCCP]: Introduce dccp_ipv4_af_ops
    
    And make the core DCCP code AF agnostic, just like TCP, now its time
    to work on net/dccp/ipv6.c, we are close to the end!
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@mandriva.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index 74ff87025878..f35880503bb8 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -43,6 +43,7 @@ static int dccp_transmit_skb(struct sock *sk, struct sk_buff *skb)
 {
 	if (likely(skb != NULL)) {
 		const struct inet_sock *inet = inet_sk(sk);
+		const struct inet_connection_sock *icsk = inet_csk(sk);
 		struct dccp_sock *dp = dccp_sk(sk);
 		struct dccp_skb_cb *dcb = DCCP_SKB_CB(skb);
 		struct dccp_hdr *dh;
@@ -108,8 +109,7 @@ static int dccp_transmit_skb(struct sock *sk, struct sk_buff *skb)
 			break;
 		}
 
-		dh->dccph_checksum = dccp_v4_checksum(skb, inet->saddr,
-						      inet->daddr);
+		icsk->icsk_af_ops->send_check(sk, skb->len, skb);
 
 		if (set_ack)
 			dccp_event_ack_sent(sk);
@@ -117,7 +117,7 @@ static int dccp_transmit_skb(struct sock *sk, struct sk_buff *skb)
 		DCCP_INC_STATS(DCCP_MIB_OUTSEGS);
 
 		memset(&(IPCB(skb)->opt), 0, sizeof(IPCB(skb)->opt));
-		err = ip_queue_xmit(skb, 0);
+		err = icsk->icsk_af_ops->queue_xmit(skb, 0);
 		if (err <= 0)
 			return err;
 
@@ -135,16 +135,14 @@ static int dccp_transmit_skb(struct sock *sk, struct sk_buff *skb)
 unsigned int dccp_sync_mss(struct sock *sk, u32 pmtu)
 {
 	struct dccp_sock *dp = dccp_sk(sk);
-	int mss_now;
-
 	/*
 	 * FIXME: we really should be using the af_specific thing to support
 	 * 	  IPv6.
 	 * mss_now = pmtu - tp->af_specific->net_header_len -
 	 * 	     sizeof(struct dccp_hdr) - sizeof(struct dccp_hdr_ext);
 	 */
-	mss_now = pmtu - sizeof(struct iphdr) - sizeof(struct dccp_hdr) -
-		  sizeof(struct dccp_hdr_ext);
+	int mss_now = (pmtu - inet_csk(sk)->icsk_af_ops->net_header_len -
+		       sizeof(struct dccp_hdr) - sizeof(struct dccp_hdr_ext));
 
 	/* Now subtract optional transport overhead */
 	mss_now -= dp->dccps_ext_header_len;
@@ -266,7 +264,7 @@ int dccp_write_xmit(struct sock *sk, struct sk_buff *skb, long *timeo)
 
 int dccp_retransmit_skb(struct sock *sk, struct sk_buff *skb)
 {
-	if (inet_sk_rebuild_header(sk) != 0)
+	if (inet_csk(sk)->icsk_af_ops->rebuild_header(sk) != 0)
 		return -EHOSTUNREACH; /* Routing failure or similar. */
 
 	return dccp_transmit_skb(sk, (skb_cloned(skb) ?

commit edc9e81917157d1e73bf081d4fbcad7c34d32783
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Sun Oct 30 11:20:59 2005 +1100

    [DCCP]: Set socket owner iff packet is not data
    
    Here is a complimentary insurance policy for those feeling a bit insecure.
    You don't have to accept this.  However, if you do, you can't blame me for
    it :)
    
    > 1) dccp_transmit_skb sets the owner for all packets except data packets.
    
    We can actually verify this by looking at pkt_type.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@mandriva.com>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index c25b0423887a..74ff87025878 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -58,10 +58,21 @@ static int dccp_transmit_skb(struct sock *sk, struct sk_buff *skb)
 		switch (dcb->dccpd_type) {
 		case DCCP_PKT_DATA:
 			set_ack = 0;
+			/* fall through */
+		case DCCP_PKT_DATAACK:
 			break;
+
 		case DCCP_PKT_SYNC:
 		case DCCP_PKT_SYNCACK:
 			ackno = dcb->dccpd_seq;
+			/* fall through */
+		default:
+			/*
+			 * Only data packets should come through with skb->sk
+			 * set.
+			 */
+			WARN_ON(skb->sk);
+			skb_set_owner_w(skb, sk);
 			break;
 		}
 
@@ -71,12 +82,6 @@ static int dccp_transmit_skb(struct sock *sk, struct sk_buff *skb)
 		skb->h.raw = skb_push(skb, dccp_header_size);
 		dh = dccp_hdr(skb);
 
-		/*
-		 * Only data packets should come through with skb->sk set.
-		 */
-		if (!skb->sk)
-			skb_set_owner_w(skb, sk);
-
 		/* Build DCCP header and checksum it. */
 		memset(dh, 0, dccp_header_size);
 		dh->dccph_type	= dcb->dccpd_type;

commit 48918a4dbd6c599d6af30bd64cb355fadca708eb
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Sun Oct 30 11:20:59 2005 +1100

    [DCCP]: Simplify skb_set_owner_w semantics
    
    While we're at it let's reorganise the set_owner_w calls a little so that:
    
    1) dccp_transmit_skb sets the owner for all packets except data packets.
    2) Add dccp_skb_entail to set owner for packets queued for retransmission.
    3) Make dccp_transmit_skb static.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@mandriva.com>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index d59f86f7ceab..c25b0423887a 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -12,6 +12,7 @@
 
 #include <linux/config.h>
 #include <linux/dccp.h>
+#include <linux/kernel.h>
 #include <linux/skbuff.h>
 
 #include <net/sock.h>
@@ -25,13 +26,20 @@ static inline void dccp_event_ack_sent(struct sock *sk)
 	inet_csk_clear_xmit_timer(sk, ICSK_TIME_DACK);
 }
 
+static inline void dccp_skb_entail(struct sock *sk, struct sk_buff *skb)
+{
+	skb_set_owner_w(skb, sk);
+	WARN_ON(sk->sk_send_head);
+	sk->sk_send_head = skb;
+}
+
 /*
  * All SKB's seen here are completely headerless. It is our
  * job to build the DCCP header, and pass the packet down to
  * IP so it can do the same plus pass the packet off to the
  * device.
  */
-int dccp_transmit_skb(struct sock *sk, struct sk_buff *skb)
+static int dccp_transmit_skb(struct sock *sk, struct sk_buff *skb)
 {
 	if (likely(skb != NULL)) {
 		const struct inet_sock *inet = inet_sk(sk);
@@ -63,6 +71,9 @@ int dccp_transmit_skb(struct sock *sk, struct sk_buff *skb)
 		skb->h.raw = skb_push(skb, dccp_header_size);
 		dh = dccp_hdr(skb);
 
+		/*
+		 * Only data packets should come through with skb->sk set.
+		 */
 		if (!skb->sk)
 			skb_set_owner_w(skb, sk);
 
@@ -393,10 +404,8 @@ int dccp_connect(struct sock *sk)
 
 	DCCP_SKB_CB(skb)->dccpd_type = DCCP_PKT_REQUEST;
 	skb->csum = 0;
-	skb_set_owner_w(skb, sk);
 
-	BUG_TRAP(sk->sk_send_head == NULL);
-	sk->sk_send_head = skb;
+	dccp_skb_entail(sk, skb);
 	dccp_transmit_skb(sk, skb_clone(skb, GFP_KERNEL));
 	DCCP_INC_STATS(DCCP_MIB_ACTIVEOPENS);
 
@@ -425,7 +434,6 @@ void dccp_send_ack(struct sock *sk)
 		skb_reserve(skb, MAX_DCCP_HEADER);
 		skb->csum = 0;
 		DCCP_SKB_CB(skb)->dccpd_type = DCCP_PKT_ACK;
-		skb_set_owner_w(skb, sk);
 		dccp_transmit_skb(sk, skb);
 	}
 }
@@ -482,7 +490,6 @@ void dccp_send_sync(struct sock *sk, const u64 seq,
 	DCCP_SKB_CB(skb)->dccpd_type = pkt_type;
 	DCCP_SKB_CB(skb)->dccpd_seq = seq;
 
-	skb_set_owner_w(skb, sk);
 	dccp_transmit_skb(sk, skb);
 }
 
@@ -507,10 +514,8 @@ void dccp_send_close(struct sock *sk, const int active)
 	DCCP_SKB_CB(skb)->dccpd_type = dp->dccps_role == DCCP_ROLE_CLIENT ?
 					DCCP_PKT_CLOSE : DCCP_PKT_CLOSEREQ;
 
-	skb_set_owner_w(skb, sk);
 	if (active) {
-		BUG_TRAP(sk->sk_send_head == NULL);
-		sk->sk_send_head = skb;
+		dccp_skb_entail(sk, skb);
 		dccp_transmit_skb(sk, skb_clone(skb, prio));
 	} else
 		dccp_transmit_skb(sk, skb);

commit 7d877f3bda870ab5f001bd92528654471d5966b3
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Fri Oct 21 03:20:43 2005 -0400

    [PATCH] gfp_t: net/*
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index 29250749f16f..d59f86f7ceab 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -495,7 +495,7 @@ void dccp_send_close(struct sock *sk, const int active)
 {
 	struct dccp_sock *dp = dccp_sk(sk);
 	struct sk_buff *skb;
-	const unsigned int prio = active ? GFP_KERNEL : GFP_ATOMIC;
+	const gfp_t prio = active ? GFP_KERNEL : GFP_ATOMIC;
 
 	skb = alloc_skb(sk->sk_prot->max_header, prio);
 	if (skb == NULL)

commit 49c5bfaffe8ae6e6440dc4bf78b03800960d93f5
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Tue Oct 18 12:03:28 2005 +1000

    [DCCP]: Clear the IPCB area
    
    Turns out the problem has nothing to do with use-after-free or double-free.
    It's just that we're not clearing the CB area and DCCP unlike TCP uses a CB
    format that's incompatible with IP.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: Ian McDonald <imcdnzl@gmail.com>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@mandriva.com>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index 7006549f7050..29250749f16f 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -100,6 +100,7 @@ int dccp_transmit_skb(struct sock *sk, struct sk_buff *skb)
 
 		DCCP_INC_STATS(DCCP_MIB_OUTSEGS);
 
+		memset(&(IPCB(skb)->opt), 0, sizeof(IPCB(skb)->opt));
 		err = ip_queue_xmit(skb, 0);
 		if (err <= 0)
 			return err;

commit ffa29347dfbc158d1f47f5925324a6f5713659c1
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Sun Oct 16 21:08:46 2005 +1000

    [DCCP]: Make dccp_write_xmit always free the packet
    
    icmp_send doesn't use skb->sk at all so even if skb->sk has already
    been freed it can't cause crash there (it would've crashed somewhere
    else first, e.g., ip_queue_xmit).
    
    I found a double-free on an skb that could explain this though.
    dccp_sendmsg and dccp_write_xmit are a little confused as to what
    should free the packet when something goes wrong.  Sometimes they
    both go for the ball and end up in each other's way.
    
    This patch makes dccp_write_xmit always free the packet no matter
    what.  This makes sense since dccp_transmit_skb which in turn comes
    from the fact that ip_queue_xmit always frees the packet.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@mandriva.com>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index 946ec2db75de..7006549f7050 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -241,7 +241,8 @@ int dccp_write_xmit(struct sock *sk, struct sk_buff *skb, long *timeo)
 
 		err = dccp_transmit_skb(sk, skb);
 		ccid_hc_tx_packet_sent(dp->dccps_hc_tx_ccid, sk, 0, len);
-	}
+	} else
+		kfree_skb(skb);
 
 	return err;
 }

commit fda0fd6c5b722cc48e904e0daafedca275d332af
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Fri Oct 14 16:38:49 2005 +1000

    [DCCP]: Use skb_set_owner_w in dccp_transmit_skb when skb->sk is NULL
    
    David S. Miller <davem@davemloft.net> wrote:
    > One thing you can probably do for this bug is to mark data packets
    > explicitly somehow, perhaps in the SKB control block DCCP already
    > uses for other data.  Put some boolean in there, set it true for
    > data packets.  Then change the test in dccp_transmit_skb() as
    > appropriate to test the boolean flag instead of "skb_cloned(skb)".
    
    I agree.  In fact we already have that flag, it's called skb->sk.
    So here is patch to test that instead of skb_cloned().
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
    Acked-by: Ian McDonald <imcdnzl@gmail.com>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@mandriva.com>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index 4786bdcddcc9..946ec2db75de 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -62,10 +62,8 @@ int dccp_transmit_skb(struct sock *sk, struct sk_buff *skb)
 		
 		skb->h.raw = skb_push(skb, dccp_header_size);
 		dh = dccp_hdr(skb);
-		/*
-		 * Data packets are not cloned as they are never retransmitted
-		 */
-		if (skb_cloned(skb))
+
+		if (!skb->sk)
 			skb_set_owner_w(skb, sk);
 
 		/* Build DCCP header and checksum it. */

commit ae31c3399d17b1f7bc1742724f70476b5417744f
Author: Arnaldo Carvalho de Melo <acme@mandriva.com>
Date:   Sun Sep 18 00:17:51 2005 -0700

    [DCCP]: Move the ack vector code to net/dccp/ackvec.[ch]
    
    Isolating it, that will be used when we introduce a CCID2 (TCP-Like)
    implementation.
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@mandriva.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index 156b1d29a156..4786bdcddcc9 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -16,6 +16,7 @@
 
 #include <net/sock.h>
 
+#include "ackvec.h"
 #include "ccid.h"
 #include "dccp.h"
 
@@ -225,7 +226,6 @@ int dccp_write_xmit(struct sock *sk, struct sk_buff *skb, long *timeo)
 		err = dccp_wait_for_ccid(sk, skb, timeo);
 
 	if (err == 0) {
-		const struct dccp_ackpkts *ap = dp->dccps_hc_rx_ackpkts;
 		struct dccp_skb_cb *dcb = DCCP_SKB_CB(skb);
 		const int len = skb->len;
 
@@ -236,15 +236,7 @@ int dccp_write_xmit(struct sock *sk, struct sk_buff *skb, long *timeo)
 						  inet_csk(sk)->icsk_rto,
 						  DCCP_RTO_MAX);
 			dcb->dccpd_type = DCCP_PKT_DATAACK;
-			/*
-			 * FIXME: we really should have a
-			 * dccps_ack_pending or use icsk.
-			 */
-		} else if (inet_csk_ack_scheduled(sk) ||
-			   dp->dccps_timestamp_echo != 0 ||
-			   (dp->dccps_options.dccpo_send_ack_vector &&
-			    ap->dccpap_buf_ackno != DCCP_MAX_SEQNO + 1 &&
-			    ap->dccpap_ack_seqno == DCCP_MAX_SEQNO + 1))
+		} else if (dccp_ack_pending(sk))
 			dcb->dccpd_type = DCCP_PKT_DATAACK;
 		else
 			dcb->dccpd_type = DCCP_PKT_DATA;

commit 67e6b629212fa9ffb7420e8a88a41806af637e28
Author: Arnaldo Carvalho de Melo <acme@mandriva.com>
Date:   Fri Sep 16 16:58:40 2005 -0700

    [DCCP]: Introduce DCCP_SOCKOPT_SERVICE
    
    As discussed in the dccp@vger mailing list:
    
    Now applications have to use setsockopt(DCCP_SOCKOPT_SERVICE, service[s]),
    prior to calling listen() and connect().
    
    An array of unsigned ints can be passed meaning that the listening sock accepts
    connection requests for several services.
    
    With this we can ditch struct sockaddr_dccp and use only sockaddr_in (and
    sockaddr_in6 in the future).
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@mandriva.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index ea6d0e91e511..156b1d29a156 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -85,7 +85,7 @@ int dccp_transmit_skb(struct sock *sk, struct sk_buff *skb)
 		switch (dcb->dccpd_type) {
 		case DCCP_PKT_REQUEST:
 			dccp_hdr_request(skb)->dccph_req_service =
-							dcb->dccpd_service;
+							dp->dccps_service;
 			break;
 		case DCCP_PKT_RESET:
 			dccp_hdr_reset(skb)->dccph_reset_code =
@@ -270,6 +270,7 @@ struct sk_buff *dccp_make_response(struct sock *sk, struct dst_entry *dst,
 				   struct request_sock *req)
 {
 	struct dccp_hdr *dh;
+	struct dccp_request_sock *dreq;
 	const int dccp_header_size = sizeof(struct dccp_hdr) +
 				     sizeof(struct dccp_hdr_ext) +
 				     sizeof(struct dccp_hdr_response);
@@ -285,8 +286,9 @@ struct sk_buff *dccp_make_response(struct sock *sk, struct dst_entry *dst,
 	skb->dst = dst_clone(dst);
 	skb->csum = 0;
 
+	dreq = dccp_rsk(req);
 	DCCP_SKB_CB(skb)->dccpd_type = DCCP_PKT_RESPONSE;
-	DCCP_SKB_CB(skb)->dccpd_seq  = dccp_rsk(req)->dreq_iss;
+	DCCP_SKB_CB(skb)->dccpd_seq  = dreq->dreq_iss;
 	dccp_insert_options(sk, skb);
 
 	skb->h.raw = skb_push(skb, dccp_header_size);
@@ -300,8 +302,9 @@ struct sk_buff *dccp_make_response(struct sock *sk, struct dst_entry *dst,
 			   DCCP_SKB_CB(skb)->dccpd_opt_len) / 4;
 	dh->dccph_type	= DCCP_PKT_RESPONSE;
 	dh->dccph_x	= 1;
-	dccp_hdr_set_seq(dh, dccp_rsk(req)->dreq_iss);
-	dccp_hdr_set_ack(dccp_hdr_ack_bits(skb), dccp_rsk(req)->dreq_isr);
+	dccp_hdr_set_seq(dh, dreq->dreq_iss);
+	dccp_hdr_set_ack(dccp_hdr_ack_bits(skb), dreq->dreq_isr);
+	dccp_hdr_response(skb)->dccph_resp_service = dreq->dreq_service;
 
 	dh->dccph_checksum = dccp_v4_checksum(skb, inet_rsk(req)->loc_addr,
 					      inet_rsk(req)->rmt_addr);
@@ -397,9 +400,6 @@ int dccp_connect(struct sock *sk)
 	skb_reserve(skb, MAX_DCCP_HEADER);
 
 	DCCP_SKB_CB(skb)->dccpd_type = DCCP_PKT_REQUEST;
-	/* FIXME: set service to something meaningful, coming
-	 * from userspace*/
-	DCCP_SKB_CB(skb)->dccpd_service = 0;
 	skb->csum = 0;
 	skb_set_owner_w(skb, sk);
 

commit dc19336c76d213fd9ae7b6a352e837f509418012
Author: Arnaldo Carvalho de Melo <acme@mandriva.com>
Date:   Fri Sep 9 19:59:26 2005 -0300

    [DCCP] Only call the HC _exit() routines in dccp_v4_destroy_sock
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@mandriva.com>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index 28de157a4326..ea6d0e91e511 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -522,7 +522,4 @@ void dccp_send_close(struct sock *sk, const int active)
 		dccp_transmit_skb(sk, skb_clone(skb, prio));
 	} else
 		dccp_transmit_skb(sk, skb);
-
-	ccid_hc_rx_exit(dp->dccps_hc_rx_ccid, sk);
-	ccid_hc_tx_exit(dp->dccps_hc_tx_ccid, sk);
 }

commit c530cfb1ce1e8f230744c3f3bd86771f50725053
Author: Arnaldo Carvalho de Melo <acme@mandriva.com>
Date:   Mon Aug 29 02:15:54 2005 -0300

    [CCID3]: Call sk->sk_write_space(sk) when receiving a feedback packet
    
    This makes the send rate calculations behave way more closely to what
    is specified, with the jitter previously seen on x and x_recv
    disappearing completely on non lossy setups.
    
    This resembles the tcp_data_snd_check code, that possibly we'll end up
    using in DCCP as well, perhaps moving this code to
    inet_connection_sock.
    
    For now I'm doing the simplest implementation tho.
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@mandriva.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index 116f6db5678d..28de157a4326 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -150,6 +150,19 @@ unsigned int dccp_sync_mss(struct sock *sk, u32 pmtu)
 	return mss_now;
 }
 
+void dccp_write_space(struct sock *sk)
+{
+	read_lock(&sk->sk_callback_lock);
+
+	if (sk->sk_sleep && waitqueue_active(sk->sk_sleep))
+		wake_up_interruptible(sk->sk_sleep);
+	/* Should agree with poll, otherwise some programs break */
+	if (sock_writeable(sk))
+		sk_wake_async(sk, 2, POLL_OUT);
+
+	read_unlock(&sk->sk_callback_lock);
+}
+
 /**
  * dccp_wait_for_ccid - Wait for ccid to tell us we can send a packet
  * @sk: socket to wait for

commit d6809c12b3334a929c39bf08ea63bd819e0500f7
Author: Arnaldo Carvalho de Melo <acme@mandriva.com>
Date:   Sat Aug 27 03:06:35 2005 -0300

    [DCCP]: Introduce dccp_wait_for_ccid and use it in dccp_write_xmit
    
    This is not quite what I think we should have long term but improves
    performance for now, so lets use it till we get CCID3 working well,
    then we can think about using sk_write_queue, perhaps using some ideas
    from Juwen Lai's old stack for 2.4.20.
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@mandriva.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index f96dedd3ad5e..116f6db5678d 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -150,14 +150,71 @@ unsigned int dccp_sync_mss(struct sock *sk, u32 pmtu)
 	return mss_now;
 }
 
-int dccp_write_xmit(struct sock *sk, struct sk_buff *skb, const int len)
+/**
+ * dccp_wait_for_ccid - Wait for ccid to tell us we can send a packet
+ * @sk: socket to wait for
+ * @timeo: for how long
+ */
+static int dccp_wait_for_ccid(struct sock *sk, struct sk_buff *skb,
+			      long *timeo)
+{
+	struct dccp_sock *dp = dccp_sk(sk);
+	DEFINE_WAIT(wait);
+	long delay;
+	int rc;
+
+	while (1) {
+		prepare_to_wait(sk->sk_sleep, &wait, TASK_INTERRUPTIBLE);
+
+		if (sk->sk_err || (sk->sk_shutdown & SEND_SHUTDOWN))
+			goto do_error;
+		if (!*timeo)
+			goto do_nonblock;
+		if (signal_pending(current))
+			goto do_interrupted;
+
+		rc = ccid_hc_tx_send_packet(dp->dccps_hc_tx_ccid, sk, skb,
+					    skb->len);
+		if (rc <= 0)
+			break;
+		delay = msecs_to_jiffies(rc);
+		if (delay > *timeo || delay < 0)
+			goto do_nonblock;
+
+		sk->sk_write_pending++;
+		release_sock(sk);
+		*timeo -= schedule_timeout(delay);
+		lock_sock(sk);
+		sk->sk_write_pending--;
+	}
+out:
+	finish_wait(sk->sk_sleep, &wait);
+	return rc;
+
+do_error:
+	rc = -EPIPE;
+	goto out;
+do_nonblock:
+	rc = -EAGAIN;
+	goto out;
+do_interrupted:
+	rc = sock_intr_errno(*timeo);
+	goto out;
+}
+
+int dccp_write_xmit(struct sock *sk, struct sk_buff *skb, long *timeo)
 {
 	const struct dccp_sock *dp = dccp_sk(sk);
-	int err = ccid_hc_tx_send_packet(dp->dccps_hc_tx_ccid, sk, skb, len);
+	int err = ccid_hc_tx_send_packet(dp->dccps_hc_tx_ccid, sk, skb,
+					 skb->len);
+
+	if (err > 0)
+		err = dccp_wait_for_ccid(sk, skb, timeo);
 
 	if (err == 0) {
 		const struct dccp_ackpkts *ap = dp->dccps_hc_rx_ackpkts;
 		struct dccp_skb_cb *dcb = DCCP_SKB_CB(skb);
+		const int len = skb->len;
 
 		if (sk->sk_state == DCCP_PARTOPEN) {
 			/* See 8.1.5.  Handshake Completion */

commit a4beb1b64f5846e216bf2c439022df480151902a
Author: Arnaldo Carvalho de Melo <acme@mandriva.com>
Date:   Tue Aug 23 21:50:45 2005 -0700

    [DCCP]: Send a DATAACK packet when we have a TIMESTAMP_ECHO pending
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@mandriva.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index 630ca7741022..f96dedd3ad5e 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -171,6 +171,7 @@ int dccp_write_xmit(struct sock *sk, struct sk_buff *skb, const int len)
 			 * dccps_ack_pending or use icsk.
 			 */
 		} else if (inet_csk_ack_scheduled(sk) ||
+			   dp->dccps_timestamp_echo != 0 ||
 			   (dp->dccps_options.dccpo_send_ack_vector &&
 			    ap->dccpap_buf_ackno != DCCP_MAX_SEQNO + 1 &&
 			    ap->dccpap_ack_seqno == DCCP_MAX_SEQNO + 1))

commit 7ad07e7cf343181002c10c39d3f57a88e4903d4f
Author: Arnaldo Carvalho de Melo <acme@mandriva.com>
Date:   Tue Aug 23 21:50:06 2005 -0700

    [DCCP]: Implement the CLOSING timer
    
    So that we retransmit CLOSE/CLOSEREQ packets till they elicit an
    answer or we hit a timeout.
    
    Most of the machinery uses TCP approaches, this code has to be
    polished & audited, but this is better than we had before.
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@mandriva.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index 708fc3c0a969..630ca7741022 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -96,8 +96,7 @@ int dccp_transmit_skb(struct sock *sk, struct sk_buff *skb)
 		dh->dccph_checksum = dccp_v4_checksum(skb, inet->saddr,
 						      inet->daddr);
 
-		if (dcb->dccpd_type == DCCP_PKT_ACK ||
-		    dcb->dccpd_type == DCCP_PKT_DATAACK)
+		if (set_ack)
 			dccp_event_ack_sent(sk);
 
 		DCCP_INC_STATS(DCCP_MIB_OUTSEGS);
@@ -429,18 +428,15 @@ void dccp_send_sync(struct sock *sk, const u64 seq,
  * cannot be allowed to fail queueing a DCCP_PKT_CLOSE/CLOSEREQ frame under
  * any circumstances.
  */
-void dccp_send_close(struct sock *sk)
+void dccp_send_close(struct sock *sk, const int active)
 {
 	struct dccp_sock *dp = dccp_sk(sk);
 	struct sk_buff *skb;
+	const unsigned int prio = active ? GFP_KERNEL : GFP_ATOMIC;
 
-	/* Socket is locked, keep trying until memory is available. */
-	for (;;) {
-		skb = alloc_skb(sk->sk_prot->max_header, GFP_KERNEL);
-		if (skb != NULL)
-			break;
-		yield();
-	}
+	skb = alloc_skb(sk->sk_prot->max_header, prio);
+	if (skb == NULL)
+		return;
 
 	/* Reserve space for headers and prepare control bits. */
 	skb_reserve(skb, sk->sk_prot->max_header);
@@ -449,7 +445,12 @@ void dccp_send_close(struct sock *sk)
 					DCCP_PKT_CLOSE : DCCP_PKT_CLOSEREQ;
 
 	skb_set_owner_w(skb, sk);
-	dccp_transmit_skb(sk, skb);
+	if (active) {
+		BUG_TRAP(sk->sk_send_head == NULL);
+		sk->sk_send_head = skb;
+		dccp_transmit_skb(sk, skb_clone(skb, prio));
+	} else
+		dccp_transmit_skb(sk, skb);
 
 	ccid_hc_rx_exit(dp->dccps_hc_rx_ccid, sk);
 	ccid_hc_tx_exit(dp->dccps_hc_tx_ccid, sk);

commit 24117727b753426d85ba09671c24854834f81b2c
Author: Arnaldo Carvalho de Melo <acme@mandriva.com>
Date:   Sun Aug 21 05:40:16 2005 -0300

    [DCCP]: Fix ackno setting in SYNC/SYNCACK packets
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@mandriva.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index 384fd0920983..708fc3c0a969 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -44,15 +44,8 @@ int dccp_transmit_skb(struct sock *sk, struct sk_buff *skb)
 		int err, set_ack = 1;
 		u64 ackno = dp->dccps_gsr;
 
-		/*
-		 * FIXME: study DCCP_PKT_SYNC[ACK] to see what is the right
-		 * thing to do here...
-		 */
 		dccp_inc_seqno(&dp->dccps_gss);
 
-		dcb->dccpd_seq = dp->dccps_gss;
-		dccp_insert_options(sk, skb);
-
 		switch (dcb->dccpd_type) {
 		case DCCP_PKT_DATA:
 			set_ack = 0;
@@ -62,6 +55,9 @@ int dccp_transmit_skb(struct sock *sk, struct sk_buff *skb)
 			ackno = dcb->dccpd_seq;
 			break;
 		}
+
+		dcb->dccpd_seq = dp->dccps_gss;
+		dccp_insert_options(sk, skb);
 		
 		skb->h.raw = skb_push(skb, dccp_header_size);
 		dh = dccp_hdr(skb);

commit e92ae93a8aa66aea12935420cb22d4df1c18d023
Author: Arnaldo Carvalho de Melo <acme@mandriva.com>
Date:   Wed Aug 17 03:10:59 2005 -0300

    [DCCP]: Send SYNCACK packets in response to SYNC packets
    
    Also fix step 6 when receiving SYNC or SYNCACK packets, i.e. we were not using
    the updated swl.
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@mandriva.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index dcc061bed924..384fd0920983 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -404,7 +404,8 @@ void dccp_send_delayed_ack(struct sock *sk)
 	sk_reset_timer(sk, &icsk->icsk_delack_timer, timeout);
 }
 
-void dccp_send_sync(struct sock *sk, u64 seq)
+void dccp_send_sync(struct sock *sk, const u64 seq,
+		    const enum dccp_pkt_type pkt_type)
 {
 	/*
 	 * We are not putting this on the write queue, so
@@ -420,7 +421,7 @@ void dccp_send_sync(struct sock *sk, u64 seq)
 	/* Reserve space for headers and prepare control bits. */
 	skb_reserve(skb, MAX_DCCP_HEADER);
 	skb->csum = 0;
-	DCCP_SKB_CB(skb)->dccpd_type = DCCP_PKT_SYNC;
+	DCCP_SKB_CB(skb)->dccpd_type = pkt_type;
 	DCCP_SKB_CB(skb)->dccpd_seq = seq;
 
 	skb_set_owner_w(skb, sk);

commit 7690af3fff7633e40b1b9950eb8489129251d074
Author: Arnaldo Carvalho de Melo <acme@mandriva.com>
Date:   Sat Aug 13 20:34:54 2005 -0300

    [DCCP]: Just reflow the source code to fit in 80 columns
    
    Andrew Morton should be happy now 8)
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@mandriva.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index 50292c0605fb..dcc061bed924 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -40,13 +40,13 @@ int dccp_transmit_skb(struct sock *sk, struct sk_buff *skb)
 		/* XXX For now we're using only 48 bits sequence numbers */
 		const int dccp_header_size = sizeof(*dh) +
 					     sizeof(struct dccp_hdr_ext) +
-					     dccp_packet_hdr_len(dcb->dccpd_type);
+					  dccp_packet_hdr_len(dcb->dccpd_type);
 		int err, set_ack = 1;
 		u64 ackno = dp->dccps_gsr;
 
 		/*
-		 * FIXME: study DCCP_PKT_SYNC[ACK] to see what is the right thing 
-		 * to do here...
+		 * FIXME: study DCCP_PKT_SYNC[ACK] to see what is the right
+		 * thing to do here...
 		 */
 		dccp_inc_seqno(&dp->dccps_gss);
 
@@ -65,7 +65,9 @@ int dccp_transmit_skb(struct sock *sk, struct sk_buff *skb)
 		
 		skb->h.raw = skb_push(skb, dccp_header_size);
 		dh = dccp_hdr(skb);
-		/* Data packets are not cloned as they are never retransmitted */
+		/*
+		 * Data packets are not cloned as they are never retransmitted
+		 */
 		if (skb_cloned(skb))
 			skb_set_owner_w(skb, sk);
 
@@ -86,10 +88,12 @@ int dccp_transmit_skb(struct sock *sk, struct sk_buff *skb)
 
 		switch (dcb->dccpd_type) {
 		case DCCP_PKT_REQUEST:
-			dccp_hdr_request(skb)->dccph_req_service = dcb->dccpd_service;
+			dccp_hdr_request(skb)->dccph_req_service =
+							dcb->dccpd_service;
 			break;
 		case DCCP_PKT_RESET:
-			dccp_hdr_reset(skb)->dccph_reset_code = dcb->dccpd_reset_code;
+			dccp_hdr_reset(skb)->dccph_reset_code =
+							dcb->dccpd_reset_code;
 			break;
 		}
 
@@ -123,10 +127,13 @@ unsigned int dccp_sync_mss(struct sock *sk, u32 pmtu)
 	int mss_now;
 
 	/*
-	 * FIXME: we really should be using the af_specific thing to support IPv6.
-	 * mss_now = pmtu - tp->af_specific->net_header_len - sizeof(struct dccp_hdr) - sizeof(struct dccp_hdr_ext);
+	 * FIXME: we really should be using the af_specific thing to support
+	 * 	  IPv6.
+	 * mss_now = pmtu - tp->af_specific->net_header_len -
+	 * 	     sizeof(struct dccp_hdr) - sizeof(struct dccp_hdr_ext);
 	 */
-	mss_now = pmtu - sizeof(struct iphdr) - sizeof(struct dccp_hdr) - sizeof(struct dccp_hdr_ext);
+	mss_now = pmtu - sizeof(struct iphdr) - sizeof(struct dccp_hdr) -
+		  sizeof(struct dccp_hdr_ext);
 
 	/* Now subtract optional transport overhead */
 	mss_now -= dp->dccps_ext_header_len;
@@ -223,7 +230,8 @@ struct sk_buff *dccp_make_response(struct sock *sk, struct dst_entry *dst,
 
 	dh->dccph_sport	= inet_sk(sk)->sport;
 	dh->dccph_dport	= inet_rsk(req)->rmt_port;
-	dh->dccph_doff	= (dccp_header_size + DCCP_SKB_CB(skb)->dccpd_opt_len) / 4;
+	dh->dccph_doff	= (dccp_header_size +
+			   DCCP_SKB_CB(skb)->dccpd_opt_len) / 4;
 	dh->dccph_type	= DCCP_PKT_RESPONSE;
 	dh->dccph_x	= 1;
 	dccp_hdr_set_seq(dh, dccp_rsk(req)->dreq_iss);
@@ -271,7 +279,8 @@ struct sk_buff *dccp_make_reset(struct sock *sk, struct dst_entry *dst,
 
 	dh->dccph_sport	= inet_sk(sk)->sport;
 	dh->dccph_dport	= inet_sk(sk)->dport;
-	dh->dccph_doff	= (dccp_header_size + DCCP_SKB_CB(skb)->dccpd_opt_len) / 4;
+	dh->dccph_doff	= (dccp_header_size +
+			   DCCP_SKB_CB(skb)->dccpd_opt_len) / 4;
 	dh->dccph_type	= DCCP_PKT_RESET;
 	dh->dccph_x	= 1;
 	dccp_hdr_set_seq(dh, dp->dccps_gss);
@@ -348,7 +357,9 @@ void dccp_send_ack(struct sock *sk)
 		if (skb == NULL) {
 			inet_csk_schedule_ack(sk);
 			inet_csk(sk)->icsk_ack.ato = TCP_ATO_MIN;
-			inet_csk_reset_xmit_timer(sk, ICSK_TIME_DACK, TCP_DELACK_MAX, TCP_RTO_MAX);
+			inet_csk_reset_xmit_timer(sk, ICSK_TIME_DACK,
+						  TCP_DELACK_MAX,
+						  DCCP_RTO_MAX);
 			return;
 		}
 
@@ -416,8 +427,10 @@ void dccp_send_sync(struct sock *sk, u64 seq)
 	dccp_transmit_skb(sk, skb);
 }
 
-/* Send a DCCP_PKT_CLOSE/CLOSEREQ.  The caller locks the socket for us.  This cannot be
- * allowed to fail queueing a DCCP_PKT_CLOSE/CLOSEREQ frame under any circumstances.
+/*
+ * Send a DCCP_PKT_CLOSE/CLOSEREQ. The caller locks the socket for us. This
+ * cannot be allowed to fail queueing a DCCP_PKT_CLOSE/CLOSEREQ frame under
+ * any circumstances.
  */
 void dccp_send_close(struct sock *sk)
 {
@@ -435,7 +448,8 @@ void dccp_send_close(struct sock *sk)
 	/* Reserve space for headers and prepare control bits. */
 	skb_reserve(skb, sk->sk_prot->max_header);
 	skb->csum = 0;
-	DCCP_SKB_CB(skb)->dccpd_type = dp->dccps_role == DCCP_ROLE_CLIENT ? DCCP_PKT_CLOSE : DCCP_PKT_CLOSEREQ;
+	DCCP_SKB_CB(skb)->dccpd_type = dp->dccps_role == DCCP_ROLE_CLIENT ?
+					DCCP_PKT_CLOSE : DCCP_PKT_CLOSEREQ;
 
 	skb_set_owner_w(skb, sk);
 	dccp_transmit_skb(sk, skb);

commit 27258ee54f8cd4a43d09319aa5448145afc2cb8d
Author: Arnaldo Carvalho de Melo <acme@mandriva.com>
Date:   Tue Aug 9 20:30:56 2005 -0700

    [DCCP]: Introduce dccp_write_xmit from code in dccp_sendmsg
    
    This way it gets closer to the TCP flow, where congestion window
    checks are done, it seems we can map ccid_hc_tx_send_packet in
    dccp_write_xmit to tcp_snd_wnd_test in tcp_write_xmit, a CCID2
    decision should just fit in here as well...
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@mandriva.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index 4945eaa9d1a4..50292c0605fb 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -148,6 +148,41 @@ unsigned int dccp_sync_mss(struct sock *sk, u32 pmtu)
 	return mss_now;
 }
 
+int dccp_write_xmit(struct sock *sk, struct sk_buff *skb, const int len)
+{
+	const struct dccp_sock *dp = dccp_sk(sk);
+	int err = ccid_hc_tx_send_packet(dp->dccps_hc_tx_ccid, sk, skb, len);
+
+	if (err == 0) {
+		const struct dccp_ackpkts *ap = dp->dccps_hc_rx_ackpkts;
+		struct dccp_skb_cb *dcb = DCCP_SKB_CB(skb);
+
+		if (sk->sk_state == DCCP_PARTOPEN) {
+			/* See 8.1.5.  Handshake Completion */
+			inet_csk_schedule_ack(sk);
+			inet_csk_reset_xmit_timer(sk, ICSK_TIME_DACK,
+						  inet_csk(sk)->icsk_rto,
+						  DCCP_RTO_MAX);
+			dcb->dccpd_type = DCCP_PKT_DATAACK;
+			/*
+			 * FIXME: we really should have a
+			 * dccps_ack_pending or use icsk.
+			 */
+		} else if (inet_csk_ack_scheduled(sk) ||
+			   (dp->dccps_options.dccpo_send_ack_vector &&
+			    ap->dccpap_buf_ackno != DCCP_MAX_SEQNO + 1 &&
+			    ap->dccpap_ack_seqno == DCCP_MAX_SEQNO + 1))
+			dcb->dccpd_type = DCCP_PKT_DATAACK;
+		else
+			dcb->dccpd_type = DCCP_PKT_DATA;
+
+		err = dccp_transmit_skb(sk, skb);
+		ccid_hc_tx_packet_sent(dp->dccps_hc_tx_ccid, sk, 0, len);
+	}
+
+	return err;
+}
+
 int dccp_retransmit_skb(struct sock *sk, struct sk_buff *skb)
 {
 	if (inet_sk_rebuild_header(sk) != 0)
@@ -299,7 +334,8 @@ int dccp_connect(struct sock *sk)
 	DCCP_INC_STATS(DCCP_MIB_ACTIVEOPENS);
 
 	/* Timer for repeating the REQUEST until an answer. */
-	inet_csk_reset_xmit_timer(sk, ICSK_TIME_RETRANS, icsk->icsk_rto, TCP_RTO_MAX);
+	inet_csk_reset_xmit_timer(sk, ICSK_TIME_RETRANS,
+				  icsk->icsk_rto, DCCP_RTO_MAX);
 	return 0;
 }
 

commit 95b81ef794278c835b321f6376b0522cd5df59b7
Author: Yoshifumi Nishida <nishida@csl.sony.co.jp>
Date:   Tue Aug 9 20:15:35 2005 -0700

    [DCCP]: Fix checksum routines
    
    Signed-off-by: Yoshifumi Nishida <nishida@csl.sony.co.jp>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@ghostprotocols.net>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dccp/output.c b/net/dccp/output.c
index 22ca2910d4f2..4945eaa9d1a4 100644
--- a/net/dccp/output.c
+++ b/net/dccp/output.c
@@ -93,7 +93,8 @@ int dccp_transmit_skb(struct sock *sk, struct sk_buff *skb)
 			break;
 		}
 
-		dh->dccph_checksum = dccp_v4_checksum(skb);
+		dh->dccph_checksum = dccp_v4_checksum(skb, inet->saddr,
+						      inet->daddr);
 
 		if (dcb->dccpd_type == DCCP_PKT_ACK ||
 		    dcb->dccpd_type == DCCP_PKT_DATAACK)
@@ -193,7 +194,8 @@ struct sk_buff *dccp_make_response(struct sock *sk, struct dst_entry *dst,
 	dccp_hdr_set_seq(dh, dccp_rsk(req)->dreq_iss);
 	dccp_hdr_set_ack(dccp_hdr_ack_bits(skb), dccp_rsk(req)->dreq_isr);
 
-	dh->dccph_checksum = dccp_v4_checksum(skb);
+	dh->dccph_checksum = dccp_v4_checksum(skb, inet_rsk(req)->loc_addr,
+					      inet_rsk(req)->rmt_addr);
 
 	DCCP_INC_STATS(DCCP_MIB_OUTSEGS);
 	return skb;
@@ -242,7 +244,8 @@ struct sk_buff *dccp_make_reset(struct sock *sk, struct dst_entry *dst,
 
 	dccp_hdr_reset(skb)->dccph_reset_code = code;
 
-	dh->dccph_checksum = dccp_v4_checksum(skb);
+	dh->dccph_checksum = dccp_v4_checksum(skb, inet_sk(sk)->saddr,
+					      inet_sk(sk)->daddr);
 
 	DCCP_INC_STATS(DCCP_MIB_OUTSEGS);
 	return skb;

commit 7c657876b63cb1d8a2ec06f8fc6c37bb8412e66c
Author: Arnaldo Carvalho de Melo <acme@ghostprotocols.net>
Date:   Tue Aug 9 20:14:34 2005 -0700

    [DCCP]: Initial implementation
    
    Development to this point was done on a subversion repository at:
    
    http://oops.ghostprotocols.net:81/cgi-bin/viewcvs.cgi/dccp-2.6/
    
    This repository will be kept at this site for the foreseable future,
    so that interested parties can see the history of this code,
    attributions, etc.
    
    If I ever decide to take this offline I'll provide the full history at
    some other suitable place.
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@ghostprotocols.net>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/dccp/output.c b/net/dccp/output.c
new file mode 100644
index 000000000000..22ca2910d4f2
--- /dev/null
+++ b/net/dccp/output.c
@@ -0,0 +1,406 @@
+/*
+ *  net/dccp/output.c
+ * 
+ *  An implementation of the DCCP protocol
+ *  Arnaldo Carvalho de Melo <acme@conectiva.com.br>
+ *
+ *	This program is free software; you can redistribute it and/or
+ *	modify it under the terms of the GNU General Public License
+ *	as published by the Free Software Foundation; either version
+ *	2 of the License, or (at your option) any later version.
+ */
+
+#include <linux/config.h>
+#include <linux/dccp.h>
+#include <linux/skbuff.h>
+
+#include <net/sock.h>
+
+#include "ccid.h"
+#include "dccp.h"
+
+static inline void dccp_event_ack_sent(struct sock *sk)
+{
+	inet_csk_clear_xmit_timer(sk, ICSK_TIME_DACK);
+}
+
+/*
+ * All SKB's seen here are completely headerless. It is our
+ * job to build the DCCP header, and pass the packet down to
+ * IP so it can do the same plus pass the packet off to the
+ * device.
+ */
+int dccp_transmit_skb(struct sock *sk, struct sk_buff *skb)
+{
+	if (likely(skb != NULL)) {
+		const struct inet_sock *inet = inet_sk(sk);
+		struct dccp_sock *dp = dccp_sk(sk);
+		struct dccp_skb_cb *dcb = DCCP_SKB_CB(skb);
+		struct dccp_hdr *dh;
+		/* XXX For now we're using only 48 bits sequence numbers */
+		const int dccp_header_size = sizeof(*dh) +
+					     sizeof(struct dccp_hdr_ext) +
+					     dccp_packet_hdr_len(dcb->dccpd_type);
+		int err, set_ack = 1;
+		u64 ackno = dp->dccps_gsr;
+
+		/*
+		 * FIXME: study DCCP_PKT_SYNC[ACK] to see what is the right thing 
+		 * to do here...
+		 */
+		dccp_inc_seqno(&dp->dccps_gss);
+
+		dcb->dccpd_seq = dp->dccps_gss;
+		dccp_insert_options(sk, skb);
+
+		switch (dcb->dccpd_type) {
+		case DCCP_PKT_DATA:
+			set_ack = 0;
+			break;
+		case DCCP_PKT_SYNC:
+		case DCCP_PKT_SYNCACK:
+			ackno = dcb->dccpd_seq;
+			break;
+		}
+		
+		skb->h.raw = skb_push(skb, dccp_header_size);
+		dh = dccp_hdr(skb);
+		/* Data packets are not cloned as they are never retransmitted */
+		if (skb_cloned(skb))
+			skb_set_owner_w(skb, sk);
+
+		/* Build DCCP header and checksum it. */
+		memset(dh, 0, dccp_header_size);
+		dh->dccph_type	= dcb->dccpd_type;
+		dh->dccph_sport	= inet->sport;
+		dh->dccph_dport	= inet->dport;
+		dh->dccph_doff	= (dccp_header_size + dcb->dccpd_opt_len) / 4;
+		dh->dccph_ccval	= dcb->dccpd_ccval;
+		/* XXX For now we're using only 48 bits sequence numbers */
+		dh->dccph_x	= 1;
+
+		dp->dccps_awh = dp->dccps_gss;
+		dccp_hdr_set_seq(dh, dp->dccps_gss);
+		if (set_ack)
+			dccp_hdr_set_ack(dccp_hdr_ack_bits(skb), ackno);
+
+		switch (dcb->dccpd_type) {
+		case DCCP_PKT_REQUEST:
+			dccp_hdr_request(skb)->dccph_req_service = dcb->dccpd_service;
+			break;
+		case DCCP_PKT_RESET:
+			dccp_hdr_reset(skb)->dccph_reset_code = dcb->dccpd_reset_code;
+			break;
+		}
+
+		dh->dccph_checksum = dccp_v4_checksum(skb);
+
+		if (dcb->dccpd_type == DCCP_PKT_ACK ||
+		    dcb->dccpd_type == DCCP_PKT_DATAACK)
+			dccp_event_ack_sent(sk);
+
+		DCCP_INC_STATS(DCCP_MIB_OUTSEGS);
+
+		err = ip_queue_xmit(skb, 0);
+		if (err <= 0)
+			return err;
+
+		/* NET_XMIT_CN is special. It does not guarantee,
+		 * that this packet is lost. It tells that device
+		 * is about to start to drop packets or already
+		 * drops some packets of the same priority and
+		 * invokes us to send less aggressively.
+		 */
+		return err == NET_XMIT_CN ? 0 : err;
+	}
+	return -ENOBUFS;
+}
+
+unsigned int dccp_sync_mss(struct sock *sk, u32 pmtu)
+{
+	struct dccp_sock *dp = dccp_sk(sk);
+	int mss_now;
+
+	/*
+	 * FIXME: we really should be using the af_specific thing to support IPv6.
+	 * mss_now = pmtu - tp->af_specific->net_header_len - sizeof(struct dccp_hdr) - sizeof(struct dccp_hdr_ext);
+	 */
+	mss_now = pmtu - sizeof(struct iphdr) - sizeof(struct dccp_hdr) - sizeof(struct dccp_hdr_ext);
+
+	/* Now subtract optional transport overhead */
+	mss_now -= dp->dccps_ext_header_len;
+
+	/*
+	 * FIXME: this should come from the CCID infrastructure, where, say,
+	 * TFRC will say it wants TIMESTAMPS, ELAPSED time, etc, for now lets
+	 * put a rough estimate for NDP + TIMESTAMP + TIMESTAMP_ECHO + ELAPSED
+	 * TIME + TFRC_OPT_LOSS_EVENT_RATE + TFRC_OPT_RECEIVE_RATE + padding to
+	 * make it a multiple of 4
+	 */
+
+	mss_now -= ((5 + 6 + 10 + 6 + 6 + 6 + 3) / 4) * 4;
+
+	/* And store cached results */
+	dp->dccps_pmtu_cookie = pmtu;
+	dp->dccps_mss_cache = mss_now;
+
+	return mss_now;
+}
+
+int dccp_retransmit_skb(struct sock *sk, struct sk_buff *skb)
+{
+	if (inet_sk_rebuild_header(sk) != 0)
+		return -EHOSTUNREACH; /* Routing failure or similar. */
+
+	return dccp_transmit_skb(sk, (skb_cloned(skb) ?
+				      pskb_copy(skb, GFP_ATOMIC):
+				      skb_clone(skb, GFP_ATOMIC)));
+}
+
+struct sk_buff *dccp_make_response(struct sock *sk, struct dst_entry *dst,
+				   struct request_sock *req)
+{
+	struct dccp_hdr *dh;
+	const int dccp_header_size = sizeof(struct dccp_hdr) +
+				     sizeof(struct dccp_hdr_ext) +
+				     sizeof(struct dccp_hdr_response);
+	struct sk_buff *skb = sock_wmalloc(sk, MAX_HEADER + DCCP_MAX_OPT_LEN +
+					       dccp_header_size, 1,
+					   GFP_ATOMIC);
+	if (skb == NULL)
+		return NULL;
+
+	/* Reserve space for headers. */
+	skb_reserve(skb, MAX_HEADER + DCCP_MAX_OPT_LEN + dccp_header_size);
+
+	skb->dst = dst_clone(dst);
+	skb->csum = 0;
+
+	DCCP_SKB_CB(skb)->dccpd_type = DCCP_PKT_RESPONSE;
+	DCCP_SKB_CB(skb)->dccpd_seq  = dccp_rsk(req)->dreq_iss;
+	dccp_insert_options(sk, skb);
+
+	skb->h.raw = skb_push(skb, dccp_header_size);
+
+	dh = dccp_hdr(skb);
+	memset(dh, 0, dccp_header_size);
+
+	dh->dccph_sport	= inet_sk(sk)->sport;
+	dh->dccph_dport	= inet_rsk(req)->rmt_port;
+	dh->dccph_doff	= (dccp_header_size + DCCP_SKB_CB(skb)->dccpd_opt_len) / 4;
+	dh->dccph_type	= DCCP_PKT_RESPONSE;
+	dh->dccph_x	= 1;
+	dccp_hdr_set_seq(dh, dccp_rsk(req)->dreq_iss);
+	dccp_hdr_set_ack(dccp_hdr_ack_bits(skb), dccp_rsk(req)->dreq_isr);
+
+	dh->dccph_checksum = dccp_v4_checksum(skb);
+
+	DCCP_INC_STATS(DCCP_MIB_OUTSEGS);
+	return skb;
+}
+
+struct sk_buff *dccp_make_reset(struct sock *sk, struct dst_entry *dst,
+				const enum dccp_reset_codes code)
+				   
+{
+	struct dccp_hdr *dh;
+	struct dccp_sock *dp = dccp_sk(sk);
+	const int dccp_header_size = sizeof(struct dccp_hdr) +
+				     sizeof(struct dccp_hdr_ext) +
+				     sizeof(struct dccp_hdr_reset);
+	struct sk_buff *skb = sock_wmalloc(sk, MAX_HEADER + DCCP_MAX_OPT_LEN +
+					       dccp_header_size, 1,
+					   GFP_ATOMIC);
+	if (skb == NULL)
+		return NULL;
+
+	/* Reserve space for headers. */
+	skb_reserve(skb, MAX_HEADER + DCCP_MAX_OPT_LEN + dccp_header_size);
+
+	skb->dst = dst_clone(dst);
+	skb->csum = 0;
+
+	dccp_inc_seqno(&dp->dccps_gss);
+
+	DCCP_SKB_CB(skb)->dccpd_reset_code = code;
+	DCCP_SKB_CB(skb)->dccpd_type	   = DCCP_PKT_RESET;
+	DCCP_SKB_CB(skb)->dccpd_seq	   = dp->dccps_gss;
+	dccp_insert_options(sk, skb);
+
+	skb->h.raw = skb_push(skb, dccp_header_size);
+
+	dh = dccp_hdr(skb);
+	memset(dh, 0, dccp_header_size);
+
+	dh->dccph_sport	= inet_sk(sk)->sport;
+	dh->dccph_dport	= inet_sk(sk)->dport;
+	dh->dccph_doff	= (dccp_header_size + DCCP_SKB_CB(skb)->dccpd_opt_len) / 4;
+	dh->dccph_type	= DCCP_PKT_RESET;
+	dh->dccph_x	= 1;
+	dccp_hdr_set_seq(dh, dp->dccps_gss);
+	dccp_hdr_set_ack(dccp_hdr_ack_bits(skb), dp->dccps_gsr);
+
+	dccp_hdr_reset(skb)->dccph_reset_code = code;
+
+	dh->dccph_checksum = dccp_v4_checksum(skb);
+
+	DCCP_INC_STATS(DCCP_MIB_OUTSEGS);
+	return skb;
+}
+
+/*
+ * Do all connect socket setups that can be done AF independent.
+ */
+static inline void dccp_connect_init(struct sock *sk)
+{
+	struct dst_entry *dst = __sk_dst_get(sk);
+	struct inet_connection_sock *icsk = inet_csk(sk);
+
+	sk->sk_err = 0;
+	sock_reset_flag(sk, SOCK_DONE);
+	
+	dccp_sync_mss(sk, dst_mtu(dst));
+
+	/*
+	 * FIXME: set dp->{dccps_swh,dccps_swl}, with
+	 * something like dccp_inc_seq
+	 */
+
+	icsk->icsk_retransmits = 0;
+}
+
+int dccp_connect(struct sock *sk)
+{
+	struct sk_buff *skb;
+	struct inet_connection_sock *icsk = inet_csk(sk);
+
+	dccp_connect_init(sk);
+
+	skb = alloc_skb(MAX_DCCP_HEADER + 15, sk->sk_allocation);
+	if (unlikely(skb == NULL))
+		return -ENOBUFS;
+
+	/* Reserve space for headers. */
+	skb_reserve(skb, MAX_DCCP_HEADER);
+
+	DCCP_SKB_CB(skb)->dccpd_type = DCCP_PKT_REQUEST;
+	/* FIXME: set service to something meaningful, coming
+	 * from userspace*/
+	DCCP_SKB_CB(skb)->dccpd_service = 0;
+	skb->csum = 0;
+	skb_set_owner_w(skb, sk);
+
+	BUG_TRAP(sk->sk_send_head == NULL);
+	sk->sk_send_head = skb;
+	dccp_transmit_skb(sk, skb_clone(skb, GFP_KERNEL));
+	DCCP_INC_STATS(DCCP_MIB_ACTIVEOPENS);
+
+	/* Timer for repeating the REQUEST until an answer. */
+	inet_csk_reset_xmit_timer(sk, ICSK_TIME_RETRANS, icsk->icsk_rto, TCP_RTO_MAX);
+	return 0;
+}
+
+void dccp_send_ack(struct sock *sk)
+{
+	/* If we have been reset, we may not send again. */
+	if (sk->sk_state != DCCP_CLOSED) {
+		struct sk_buff *skb = alloc_skb(MAX_DCCP_HEADER, GFP_ATOMIC);
+
+		if (skb == NULL) {
+			inet_csk_schedule_ack(sk);
+			inet_csk(sk)->icsk_ack.ato = TCP_ATO_MIN;
+			inet_csk_reset_xmit_timer(sk, ICSK_TIME_DACK, TCP_DELACK_MAX, TCP_RTO_MAX);
+			return;
+		}
+
+		/* Reserve space for headers */
+		skb_reserve(skb, MAX_DCCP_HEADER);
+		skb->csum = 0;
+		DCCP_SKB_CB(skb)->dccpd_type = DCCP_PKT_ACK;
+		skb_set_owner_w(skb, sk);
+		dccp_transmit_skb(sk, skb);
+	}
+}
+
+EXPORT_SYMBOL_GPL(dccp_send_ack);
+
+void dccp_send_delayed_ack(struct sock *sk)
+{
+	struct inet_connection_sock *icsk = inet_csk(sk);
+	/*
+	 * FIXME: tune this timer. elapsed time fixes the skew, so no problem
+	 * with using 2s, and active senders also piggyback the ACK into a
+	 * DATAACK packet, so this is really for quiescent senders.
+	 */
+	unsigned long timeout = jiffies + 2 * HZ;
+
+	/* Use new timeout only if there wasn't a older one earlier. */
+	if (icsk->icsk_ack.pending & ICSK_ACK_TIMER) {
+		/* If delack timer was blocked or is about to expire,
+		 * send ACK now.
+		 *
+		 * FIXME: check the "about to expire" part
+		 */
+		if (icsk->icsk_ack.blocked) {
+			dccp_send_ack(sk);
+			return;
+		}
+
+		if (!time_before(timeout, icsk->icsk_ack.timeout))
+			timeout = icsk->icsk_ack.timeout;
+	}
+	icsk->icsk_ack.pending |= ICSK_ACK_SCHED | ICSK_ACK_TIMER;
+	icsk->icsk_ack.timeout = timeout;
+	sk_reset_timer(sk, &icsk->icsk_delack_timer, timeout);
+}
+
+void dccp_send_sync(struct sock *sk, u64 seq)
+{
+	/*
+	 * We are not putting this on the write queue, so
+	 * dccp_transmit_skb() will set the ownership to this
+	 * sock.
+	 */
+	struct sk_buff *skb = alloc_skb(MAX_DCCP_HEADER, GFP_ATOMIC);
+
+	if (skb == NULL)
+		/* FIXME: how to make sure the sync is sent? */
+		return;
+
+	/* Reserve space for headers and prepare control bits. */
+	skb_reserve(skb, MAX_DCCP_HEADER);
+	skb->csum = 0;
+	DCCP_SKB_CB(skb)->dccpd_type = DCCP_PKT_SYNC;
+	DCCP_SKB_CB(skb)->dccpd_seq = seq;
+
+	skb_set_owner_w(skb, sk);
+	dccp_transmit_skb(sk, skb);
+}
+
+/* Send a DCCP_PKT_CLOSE/CLOSEREQ.  The caller locks the socket for us.  This cannot be
+ * allowed to fail queueing a DCCP_PKT_CLOSE/CLOSEREQ frame under any circumstances.
+ */
+void dccp_send_close(struct sock *sk)
+{
+	struct dccp_sock *dp = dccp_sk(sk);
+	struct sk_buff *skb;
+
+	/* Socket is locked, keep trying until memory is available. */
+	for (;;) {
+		skb = alloc_skb(sk->sk_prot->max_header, GFP_KERNEL);
+		if (skb != NULL)
+			break;
+		yield();
+	}
+
+	/* Reserve space for headers and prepare control bits. */
+	skb_reserve(skb, sk->sk_prot->max_header);
+	skb->csum = 0;
+	DCCP_SKB_CB(skb)->dccpd_type = dp->dccps_role == DCCP_ROLE_CLIENT ? DCCP_PKT_CLOSE : DCCP_PKT_CLOSEREQ;
+
+	skb_set_owner_w(skb, sk);
+	dccp_transmit_skb(sk, skb);
+
+	ccid_hc_rx_exit(dp->dccps_hc_rx_ccid, sk);
+	ccid_hc_tx_exit(dp->dccps_hc_tx_ccid, sk);
+}
